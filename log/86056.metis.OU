GPU: True
80
start training 2022-05-29 15:29:21.748394
Epoch:[ 1 0 ] loss: 0.7185320854187012 2022-05-29 15:29:53.035064
Epoch:[ 1 1 ] loss: 0.7089637517929077 2022-05-29 15:29:53.851529
Epoch:[ 1 2 ] loss: 0.7094594836235046 2022-05-29 15:29:54.627595
Epoch:[ 1 3 ] loss: 0.7080013155937195 2022-05-29 15:29:55.398392
Epoch:[ 1 4 ] loss: 0.6981760859489441 2022-05-29 15:29:56.168964
Epoch:[ 1 5 ] loss: 0.6915629506111145 2022-05-29 15:29:56.936549
Epoch:[ 1 6 ] loss: 0.6873893737792969 2022-05-29 15:29:57.706161
Epoch:[ 1 7 ] loss: 0.6827874183654785 2022-05-29 15:29:58.478885
Epoch:[ 1 8 ] loss: 0.6785496473312378 2022-05-29 15:29:59.247984
Epoch:[ 1 9 ] loss: 0.6739060878753662 2022-05-29 15:30:00.016508
Epoch:[ 1 10 ] loss: 0.670818030834198 2022-05-29 15:30:00.785777
Epoch:[ 1 11 ] loss: 0.6679786443710327 2022-05-29 15:30:01.553374
Epoch:[ 1 12 ] loss: 0.6640187501907349 2022-05-29 15:30:02.323474
Epoch:[ 1 13 ] loss: 0.6622626781463623 2022-05-29 15:30:03.093829
Epoch:[ 1 14 ] loss: 0.6568185687065125 2022-05-29 15:30:03.861243
Epoch:[ 1 15 ] loss: 0.6541059613227844 2022-05-29 15:30:04.627794
Epoch:[ 1 16 ] loss: 0.6511911153793335 2022-05-29 15:30:06.258407
Epoch:[ 1 17 ] loss: 0.6499099135398865 2022-05-29 15:30:07.026519
Epoch:[ 1 18 ] loss: 0.6466773748397827 2022-05-29 15:30:07.797709
Epoch:[ 1 19 ] loss: 0.6450326442718506 2022-05-29 15:30:08.562755
Training_Epoch:[ 1 ] Training_loss: 0.6763070940971374 2022-05-29 15:30:08.563381
learning rate:  0.002
val: 1 0.6838021278381348
val: 2 0.6827279329299927
val: 3 0.6843096613883972
val: 4 0.6846959590911865
val: 5 0.6832733154296875
val: 6 0.6832966804504395
val: 7 0.6845008730888367
val: 8 0.6824074387550354
val: 9 0.6839958429336548
val: 10 0.6828835606575012
val: 11 0.6854239702224731
val: 12 0.684870719909668
val: 13 0.683694064617157
val: 14 0.683586061000824
val: 15 0.6841204166412354
val: 16 0.6846662163734436
val: 17 0.6817499399185181
val: 18 0.6837471127510071
val: 19 0.6843830943107605
val: 20 0.6841425895690918
val_Epoch:[ 1 ] val_loss: 0.6838138788938523 2022-05-29 15:30:14.774088
start training 2022-05-29 15:30:14.882141
Epoch:[ 2 0 ] loss: 0.641804575920105 2022-05-29 15:30:40.099541
Epoch:[ 2 1 ] loss: 0.6407382488250732 2022-05-29 15:30:40.916743
Epoch:[ 2 2 ] loss: 0.6360711455345154 2022-05-29 15:30:41.682981
Epoch:[ 2 3 ] loss: 0.6383169293403625 2022-05-29 15:30:42.446479
Epoch:[ 2 4 ] loss: 0.6348069310188293 2022-05-29 15:30:43.209903
Epoch:[ 2 5 ] loss: 0.6311144828796387 2022-05-29 15:30:43.976069
Epoch:[ 2 6 ] loss: 0.6284863352775574 2022-05-29 15:30:44.742474
Epoch:[ 2 7 ] loss: 0.6273192763328552 2022-05-29 15:30:45.507655
Epoch:[ 2 8 ] loss: 0.6248041391372681 2022-05-29 15:30:46.272071
Epoch:[ 2 9 ] loss: 0.6249054670333862 2022-05-29 15:30:47.035913
Epoch:[ 2 10 ] loss: 0.6221976280212402 2022-05-29 15:30:47.800120
Epoch:[ 2 11 ] loss: 0.621430516242981 2022-05-29 15:30:48.563517
Epoch:[ 2 12 ] loss: 0.6182496547698975 2022-05-29 15:30:49.326941
Epoch:[ 2 13 ] loss: 0.6176924109458923 2022-05-29 15:30:50.093595
Epoch:[ 2 14 ] loss: 0.6161302328109741 2022-05-29 15:30:50.860879
Epoch:[ 2 15 ] loss: 0.614851713180542 2022-05-29 15:30:51.627588
Epoch:[ 2 16 ] loss: 0.6132947206497192 2022-05-29 15:30:59.269556
Epoch:[ 2 17 ] loss: 0.6113715767860413 2022-05-29 15:31:00.036660
Epoch:[ 2 18 ] loss: 0.6122580766677856 2022-05-29 15:31:00.809030
Epoch:[ 2 19 ] loss: 0.6104195713996887 2022-05-29 15:31:01.573104
Training_Epoch:[ 2 ] Training_loss: 0.6243131816387176 2022-05-29 15:31:01.573878
learning rate:  0.002
netparams have been saved once 2
val: 1 0.6093537211418152
val: 2 0.6136481165885925
val: 3 0.6037136912345886
val: 4 0.6130488514900208
val: 5 0.6076339483261108
val: 6 0.6169259548187256
val: 7 0.6133872270584106
val: 8 0.6071880459785461
val: 9 0.6131463050842285
val: 10 0.6121207475662231
val: 11 0.6173659563064575
val: 12 0.6102389097213745
val: 13 0.6066469550132751
val: 14 0.6093049645423889
val: 15 0.6174391508102417
val: 16 0.6099880337715149
val: 17 0.6147239804267883
val: 18 0.6116475462913513
val: 19 0.6136680245399475
val: 20 0.6061215996742249
val_Epoch:[ 2 ] val_loss: 0.6113655865192413 2022-05-29 15:31:07.291774
start training 2022-05-29 15:31:07.392938
Epoch:[ 3 0 ] loss: 0.6071666479110718 2022-05-29 15:31:32.623752
Epoch:[ 3 1 ] loss: 0.6053370237350464 2022-05-29 15:31:33.397252
Epoch:[ 3 2 ] loss: 0.6060304641723633 2022-05-29 15:31:34.164841
Epoch:[ 3 3 ] loss: 0.6059120297431946 2022-05-29 15:31:34.933221
Epoch:[ 3 4 ] loss: 0.6029120087623596 2022-05-29 15:31:35.699508
Epoch:[ 3 5 ] loss: 0.6002658605575562 2022-05-29 15:31:36.467152
Epoch:[ 3 6 ] loss: 0.5997086763381958 2022-05-29 15:31:37.235026
Epoch:[ 3 7 ] loss: 0.600196123123169 2022-05-29 15:31:38.026596
Epoch:[ 3 8 ] loss: 0.5929285287857056 2022-05-29 15:31:38.794085
Epoch:[ 3 9 ] loss: 0.5939216613769531 2022-05-29 15:31:39.561334
Epoch:[ 3 10 ] loss: 0.5972186326980591 2022-05-29 15:31:40.329310
Epoch:[ 3 11 ] loss: 0.5946115255355835 2022-05-29 15:31:41.095745
Epoch:[ 3 12 ] loss: 0.59344482421875 2022-05-29 15:31:41.880467
Epoch:[ 3 13 ] loss: 0.5933327674865723 2022-05-29 15:31:42.647793
Epoch:[ 3 14 ] loss: 0.5930653214454651 2022-05-29 15:31:43.416207
Epoch:[ 3 15 ] loss: 0.5857431292533875 2022-05-29 15:31:44.183197
Epoch:[ 3 16 ] loss: 0.5882384777069092 2022-05-29 15:31:51.780110
Epoch:[ 3 17 ] loss: 0.5872332453727722 2022-05-29 15:31:52.547755
Epoch:[ 3 18 ] loss: 0.5911983847618103 2022-05-29 15:31:53.317077
Epoch:[ 3 19 ] loss: 0.586699366569519 2022-05-29 15:31:54.082166
Training_Epoch:[ 3 ] Training_loss: 0.5962582349777221 2022-05-29 15:31:54.082985
learning rate:  0.002
val: 1 0.5969189405441284
val: 2 0.5966779589653015
val: 3 0.5843775868415833
val: 4 0.5929899215698242
val: 5 0.5896216034889221
val: 6 0.5962150692939758
val: 7 0.5928271412849426
val: 8 0.5890485644340515
val: 9 0.5901203155517578
val: 10 0.6008731722831726
val: 11 0.5951155424118042
val: 12 0.5882506966590881
val: 13 0.5893972516059875
val: 14 0.6000451445579529
val: 15 0.5913797616958618
val: 16 0.5972117781639099
val: 17 0.6041634678840637
val: 18 0.5941364765167236
val: 19 0.590354323387146
val: 20 0.5948275327682495
val_Epoch:[ 3 ] val_loss: 0.5937276124954224 2022-05-29 15:31:59.782449
start training 2022-05-29 15:31:59.885619
Epoch:[ 4 0 ] loss: 0.5872532725334167 2022-05-29 15:32:25.493273
Epoch:[ 4 1 ] loss: 0.5877830982208252 2022-05-29 15:32:26.259874
Epoch:[ 4 2 ] loss: 0.583794355392456 2022-05-29 15:32:27.026834
Epoch:[ 4 3 ] loss: 0.5817114114761353 2022-05-29 15:32:27.792558
Epoch:[ 4 4 ] loss: 0.5826832056045532 2022-05-29 15:32:28.557469
Epoch:[ 4 5 ] loss: 0.5804177522659302 2022-05-29 15:32:29.323004
Epoch:[ 4 6 ] loss: 0.5812942385673523 2022-05-29 15:32:30.087094
Epoch:[ 4 7 ] loss: 0.5784657001495361 2022-05-29 15:32:30.851479
Epoch:[ 4 8 ] loss: 0.5783995389938354 2022-05-29 15:32:31.618178
Epoch:[ 4 9 ] loss: 0.5787569880485535 2022-05-29 15:32:32.383863
Epoch:[ 4 10 ] loss: 0.5767143964767456 2022-05-29 15:32:33.148973
Epoch:[ 4 11 ] loss: 0.5812690258026123 2022-05-29 15:32:33.916048
Epoch:[ 4 12 ] loss: 0.5821553468704224 2022-05-29 15:32:34.680467
Epoch:[ 4 13 ] loss: 0.5758355259895325 2022-05-29 15:32:35.446124
Epoch:[ 4 14 ] loss: 0.5757071375846863 2022-05-29 15:32:36.211342
Epoch:[ 4 15 ] loss: 0.5740652084350586 2022-05-29 15:32:36.978134
Epoch:[ 4 16 ] loss: 0.5771397352218628 2022-05-29 15:32:47.859800
Epoch:[ 4 17 ] loss: 0.5785737633705139 2022-05-29 15:32:48.624766
Epoch:[ 4 18 ] loss: 0.5740325450897217 2022-05-29 15:32:49.407586
Epoch:[ 4 19 ] loss: 0.575566828250885 2022-05-29 15:32:50.171791
Training_Epoch:[ 4 ] Training_loss: 0.5795809537172317 2022-05-29 15:32:50.172499
learning rate:  0.002
netparams have been saved once 4
val: 1 0.6157535314559937
val: 2 0.6040337681770325
val: 3 0.6151770353317261
val: 4 0.6085835099220276
val: 5 0.609204888343811
val: 6 0.6069791913032532
val: 7 0.6047115921974182
val: 8 0.6170576810836792
val: 9 0.6076080203056335
val: 10 0.6092830300331116
val: 11 0.6121188998222351
val: 12 0.6109110713005066
val: 13 0.6027941107749939
val: 14 0.6087092161178589
val: 15 0.5935899615287781
val: 16 0.6162722706794739
val: 17 0.6199190616607666
val: 18 0.6168186068534851
val: 19 0.6042745113372803
val: 20 0.5972650647163391
val_Epoch:[ 4 ] val_loss: 0.6090532511472702 2022-05-29 15:32:55.859190
start training 2022-05-29 15:32:55.955248
Epoch:[ 5 0 ] loss: 0.5719645619392395 2022-05-29 15:33:20.554283
Epoch:[ 5 1 ] loss: 0.5711021423339844 2022-05-29 15:33:21.320499
Epoch:[ 5 2 ] loss: 0.5711817741394043 2022-05-29 15:33:22.086206
Epoch:[ 5 3 ] loss: 0.5728497505187988 2022-05-29 15:33:22.853298
Epoch:[ 5 4 ] loss: 0.5745212435722351 2022-05-29 15:33:23.618357
Epoch:[ 5 5 ] loss: 0.5734089612960815 2022-05-29 15:33:24.384218
Epoch:[ 5 6 ] loss: 0.5698292255401611 2022-05-29 15:33:25.149787
Epoch:[ 5 7 ] loss: 0.5676116347312927 2022-05-29 15:33:25.914217
Epoch:[ 5 8 ] loss: 0.5711719989776611 2022-05-29 15:33:26.680099
Epoch:[ 5 9 ] loss: 0.5723579525947571 2022-05-29 15:33:27.447260
Epoch:[ 5 10 ] loss: 0.5699113607406616 2022-05-29 15:33:28.214731
Epoch:[ 5 11 ] loss: 0.570464551448822 2022-05-29 15:33:28.979227
Epoch:[ 5 12 ] loss: 0.5695352554321289 2022-05-29 15:33:29.746533
Epoch:[ 5 13 ] loss: 0.5722920894622803 2022-05-29 15:33:30.512032
Epoch:[ 5 14 ] loss: 0.5696133375167847 2022-05-29 15:33:31.277664
Epoch:[ 5 15 ] loss: 0.569581151008606 2022-05-29 15:33:32.040924
Epoch:[ 5 16 ] loss: 0.5676262974739075 2022-05-29 15:33:39.663584
Epoch:[ 5 17 ] loss: 0.5722559094429016 2022-05-29 15:33:40.433345
Epoch:[ 5 18 ] loss: 0.5696552991867065 2022-05-29 15:33:41.602032
Epoch:[ 5 19 ] loss: 0.5685651898384094 2022-05-29 15:33:42.368516
Training_Epoch:[ 5 ] Training_loss: 0.5707749843597412 2022-05-29 15:33:42.369359
learning rate:  0.002
val: 1 0.5823445320129395
val: 2 0.5686503648757935
val: 3 0.5704333782196045
val: 4 0.5681495666503906
val: 5 0.5685474872589111
val: 6 0.5727060437202454
val: 7 0.5853936076164246
val: 8 0.5671160817146301
val: 9 0.5792981386184692
val: 10 0.5683257579803467
val: 11 0.5644373893737793
val: 12 0.5741308331489563
val: 13 0.5774694681167603
val: 14 0.580949068069458
val: 15 0.5705589652061462
val: 16 0.5922974348068237
val: 17 0.595643937587738
val: 18 0.5955560803413391
val: 19 0.5707200765609741
val: 20 0.567374587059021
val_Epoch:[ 5 ] val_loss: 0.5760051399469376 2022-05-29 15:33:48.237929
start training 2022-05-29 15:33:48.341410
Epoch:[ 6 0 ] loss: 0.5631325244903564 2022-05-29 15:34:12.975162
Epoch:[ 6 1 ] loss: 0.5639190673828125 2022-05-29 15:34:13.890459
Epoch:[ 6 2 ] loss: 0.5636180639266968 2022-05-29 15:34:14.695294
Epoch:[ 6 3 ] loss: 0.5716450214385986 2022-05-29 15:34:15.459491
Epoch:[ 6 4 ] loss: 0.5646200180053711 2022-05-29 15:34:16.225490
Epoch:[ 6 5 ] loss: 0.5667935013771057 2022-05-29 15:34:16.992908
Epoch:[ 6 6 ] loss: 0.5638912320137024 2022-05-29 15:34:17.759844
Epoch:[ 6 7 ] loss: 0.5650209188461304 2022-05-29 15:34:18.526734
Epoch:[ 6 8 ] loss: 0.5693594217300415 2022-05-29 15:34:19.294626
Epoch:[ 6 9 ] loss: 0.5725604891777039 2022-05-29 15:34:20.059803
Epoch:[ 6 10 ] loss: 0.5677845478057861 2022-05-29 15:34:20.824778
Epoch:[ 6 11 ] loss: 0.5672324895858765 2022-05-29 15:34:21.590223
Epoch:[ 6 12 ] loss: 0.5697203278541565 2022-05-29 15:34:22.355801
Epoch:[ 6 13 ] loss: 0.5691244006156921 2022-05-29 15:34:23.120476
Epoch:[ 6 14 ] loss: 0.5641657710075378 2022-05-29 15:34:23.887410
Epoch:[ 6 15 ] loss: 0.5604090094566345 2022-05-29 15:34:24.651604
Epoch:[ 6 16 ] loss: 0.5627487897872925 2022-05-29 15:34:32.722272
Epoch:[ 6 17 ] loss: 0.5662623047828674 2022-05-29 15:34:33.487238
Epoch:[ 6 18 ] loss: 0.5629996657371521 2022-05-29 15:34:34.269718
Epoch:[ 6 19 ] loss: 0.5665890574455261 2022-05-29 15:34:35.033900
Training_Epoch:[ 6 ] Training_loss: 0.566079831123352 2022-05-29 15:34:35.034668
learning rate:  0.002
netparams have been saved once 6
val: 1 0.5603713989257812
val: 2 0.5750489830970764
val: 3 0.5668477416038513
val: 4 0.5500580072402954
val: 5 0.563854455947876
val: 6 0.5836751461029053
val: 7 0.562722384929657
val: 8 0.5618045926094055
val: 9 0.5798316597938538
val: 10 0.5479910373687744
val: 11 0.5854965448379517
val: 12 0.5742989182472229
val: 13 0.5753805637359619
val: 14 0.5614367127418518
val: 15 0.5645621418952942
val: 16 0.558721125125885
val: 17 0.5708820223808289
val: 18 0.5706678628921509
val: 19 0.5655621886253357
val: 20 0.5781890749931335
val_Epoch:[ 6 ] val_loss: 0.5678701281547547 2022-05-29 15:34:40.713254
start training 2022-05-29 15:34:40.831011
Epoch:[ 7 0 ] loss: 0.5657272934913635 2022-05-29 15:35:05.990911
Epoch:[ 7 1 ] loss: 0.5620253086090088 2022-05-29 15:35:06.757027
Epoch:[ 7 2 ] loss: 0.5648772716522217 2022-05-29 15:35:07.523780
Epoch:[ 7 3 ] loss: 0.5628935098648071 2022-05-29 15:35:08.287976
Epoch:[ 7 4 ] loss: 0.5634613633155823 2022-05-29 15:35:09.055513
Epoch:[ 7 5 ] loss: 0.5623630881309509 2022-05-29 15:35:09.825070
Epoch:[ 7 6 ] loss: 0.5634539127349854 2022-05-29 15:35:10.590251
Epoch:[ 7 7 ] loss: 0.5608257055282593 2022-05-29 15:35:11.357179
Epoch:[ 7 8 ] loss: 0.5625237226486206 2022-05-29 15:35:12.121943
Epoch:[ 7 9 ] loss: 0.5614617466926575 2022-05-29 15:35:12.887995
Epoch:[ 7 10 ] loss: 0.5606873631477356 2022-05-29 15:35:13.653014
Epoch:[ 7 11 ] loss: 0.5635599493980408 2022-05-29 15:35:14.421216
Epoch:[ 7 12 ] loss: 0.5664730668067932 2022-05-29 15:35:15.187930
Epoch:[ 7 13 ] loss: 0.5652891993522644 2022-05-29 15:35:15.953578
Epoch:[ 7 14 ] loss: 0.5653972625732422 2022-05-29 15:35:16.721291
Epoch:[ 7 15 ] loss: 0.5680294036865234 2022-05-29 15:35:17.486770
Epoch:[ 7 16 ] loss: 0.5610398650169373 2022-05-29 15:35:25.109884
Epoch:[ 7 17 ] loss: 0.5591946840286255 2022-05-29 15:35:25.878658
Epoch:[ 7 18 ] loss: 0.5685259103775024 2022-05-29 15:35:26.649434
Epoch:[ 7 19 ] loss: 0.5627484321594238 2022-05-29 15:35:27.417407
Training_Epoch:[ 7 ] Training_loss: 0.5635279029607773 2022-05-29 15:35:27.418258
learning rate:  0.002
val: 1 0.5673553347587585
val: 2 0.564702033996582
val: 3 0.5629608631134033
val: 4 0.5735384225845337
val: 5 0.5729799866676331
val: 6 0.5769715905189514
val: 7 0.577251136302948
val: 8 0.5881776213645935
val: 9 0.5851900577545166
val: 10 0.5498275756835938
val: 11 0.57399982213974
val: 12 0.5750790238380432
val: 13 0.5816618204116821
val: 14 0.58673495054245
val: 15 0.5596240162849426
val: 16 0.5693875551223755
val: 17 0.5790401101112366
val: 18 0.5725791454315186
val: 19 0.5921782851219177
val: 20 0.5657671689987183
val_Epoch:[ 7 ] val_loss: 0.5737503260374069 2022-05-29 15:35:33.254768
start training 2022-05-29 15:35:33.356269
Epoch:[ 8 0 ] loss: 0.5570032596588135 2022-05-29 15:35:57.647672
Epoch:[ 8 1 ] loss: 0.5609491467475891 2022-05-29 15:35:58.830192
Epoch:[ 8 2 ] loss: 0.5559870004653931 2022-05-29 15:35:59.594909
Epoch:[ 8 3 ] loss: 0.5637444853782654 2022-05-29 15:36:00.359994
Epoch:[ 8 4 ] loss: 0.5598662495613098 2022-05-29 15:36:01.125565
Epoch:[ 8 5 ] loss: 0.5635592341423035 2022-05-29 15:36:01.893968
Epoch:[ 8 6 ] loss: 0.5616387724876404 2022-05-29 15:36:02.659715
Epoch:[ 8 7 ] loss: 0.5591180920600891 2022-05-29 15:36:03.426155
Epoch:[ 8 8 ] loss: 0.5653123259544373 2022-05-29 15:36:04.190405
Epoch:[ 8 9 ] loss: 0.5658450126647949 2022-05-29 15:36:04.955494
Epoch:[ 8 10 ] loss: 0.563521683216095 2022-05-29 15:36:05.722174
Epoch:[ 8 11 ] loss: 0.5592193603515625 2022-05-29 15:36:06.487950
Epoch:[ 8 12 ] loss: 0.5643122792243958 2022-05-29 15:36:07.254886
Epoch:[ 8 13 ] loss: 0.5671492218971252 2022-05-29 15:36:08.022619
Epoch:[ 8 14 ] loss: 0.565717339515686 2022-05-29 15:36:08.790992
Epoch:[ 8 15 ] loss: 0.5624163150787354 2022-05-29 15:36:09.554698
Epoch:[ 8 16 ] loss: 0.5646418929100037 2022-05-29 15:36:17.071904
Epoch:[ 8 17 ] loss: 0.560009241104126 2022-05-29 15:36:19.249569
Epoch:[ 8 18 ] loss: 0.5576071739196777 2022-05-29 15:36:20.017680
Epoch:[ 8 19 ] loss: 0.5562348365783691 2022-05-29 15:36:20.783738
Training_Epoch:[ 8 ] Training_loss: 0.5616926461458206 2022-05-29 15:36:20.784466
learning rate:  0.002
netparams have been saved once 8
val: 1 0.5772049427032471
val: 2 0.5631805062294006
val: 3 0.5774786472320557
val: 4 0.554054856300354
val: 5 0.553858757019043
val: 6 0.555202305316925
val: 7 0.5615081787109375
val: 8 0.5635339021682739
val: 9 0.5483797192573547
val: 10 0.5627945065498352
val: 11 0.5694973468780518
val: 12 0.5543561577796936
val: 13 0.5524325370788574
val: 14 0.5738698244094849
val: 15 0.5753577351570129
val: 16 0.570136547088623
val: 17 0.5576926469802856
val: 18 0.5521358847618103
val: 19 0.5726732611656189
val: 20 0.5730028748512268
val_Epoch:[ 8 ] val_loss: 0.5634175568819046 2022-05-29 15:36:26.565354
start training 2022-05-29 15:36:26.663768
Epoch:[ 9 0 ] loss: 0.5585181713104248 2022-05-29 15:36:51.476668
Epoch:[ 9 1 ] loss: 0.5590375661849976 2022-05-29 15:36:52.245874
Epoch:[ 9 2 ] loss: 0.5606541633605957 2022-05-29 15:36:53.012738
Epoch:[ 9 3 ] loss: 0.5635136961936951 2022-05-29 15:36:53.779592
Epoch:[ 9 4 ] loss: 0.5609641075134277 2022-05-29 15:36:54.547802
Epoch:[ 9 5 ] loss: 0.5628646016120911 2022-05-29 15:36:55.314504
Epoch:[ 9 6 ] loss: 0.5647153258323669 2022-05-29 15:36:56.081827
Epoch:[ 9 7 ] loss: 0.558198869228363 2022-05-29 15:36:56.850536
Epoch:[ 9 8 ] loss: 0.5588789582252502 2022-05-29 15:36:57.619968
Epoch:[ 9 9 ] loss: 0.564622700214386 2022-05-29 15:36:58.387124
Epoch:[ 9 10 ] loss: 0.5580559372901917 2022-05-29 15:36:59.152562
Epoch:[ 9 11 ] loss: 0.5605347752571106 2022-05-29 15:36:59.920042
Epoch:[ 9 12 ] loss: 0.556321382522583 2022-05-29 15:37:00.683917
Epoch:[ 9 13 ] loss: 0.5592248439788818 2022-05-29 15:37:01.451075
Epoch:[ 9 14 ] loss: 0.5588244199752808 2022-05-29 15:37:02.220171
Epoch:[ 9 15 ] loss: 0.5619933009147644 2022-05-29 15:37:02.988202
Epoch:[ 9 16 ] loss: 0.5599026083946228 2022-05-29 15:37:10.382790
Epoch:[ 9 17 ] loss: 0.5674287676811218 2022-05-29 15:37:11.146381
Epoch:[ 9 18 ] loss: 0.5602893233299255 2022-05-29 15:37:11.916940
Epoch:[ 9 19 ] loss: 0.557647168636322 2022-05-29 15:37:12.680141
Training_Epoch:[ 9 ] Training_loss: 0.5606095343828201 2022-05-29 15:37:12.680863
learning rate:  0.002
val: 1 0.571373701095581
val: 2 0.5739513039588928
val: 3 0.5841080546379089
val: 4 0.5449619889259338
val: 5 0.5529769062995911
val: 6 0.5531577467918396
val: 7 0.5753703117370605
val: 8 0.577038049697876
val: 9 0.5672425627708435
val: 10 0.566769003868103
val: 11 0.5775676369667053
val: 12 0.5592758655548096
val: 13 0.5507953763008118
val: 14 0.5492579936981201
val: 15 0.5588551163673401
val: 16 0.5886696577072144
val: 17 0.5809191465377808
val: 18 0.5699397325515747
val: 19 0.5596621632575989
val: 20 0.5575130581855774
val_Epoch:[ 9 ] val_loss: 0.5659702688455581 2022-05-29 15:37:18.336610
start training 2022-05-29 15:37:18.438190
Epoch:[ 10 0 ] loss: 0.5597679615020752 2022-05-29 15:37:42.355439
Epoch:[ 10 1 ] loss: 0.5599724650382996 2022-05-29 15:37:43.726681
Epoch:[ 10 2 ] loss: 0.5601034760475159 2022-05-29 15:37:44.491907
Epoch:[ 10 3 ] loss: 0.5601709485054016 2022-05-29 15:37:45.261411
Epoch:[ 10 4 ] loss: 0.5624979734420776 2022-05-29 15:37:46.026128
Epoch:[ 10 5 ] loss: 0.5593656897544861 2022-05-29 15:37:46.797129
Epoch:[ 10 6 ] loss: 0.5628120303153992 2022-05-29 15:37:47.562645
Epoch:[ 10 7 ] loss: 0.5611164569854736 2022-05-29 15:37:48.330712
Epoch:[ 10 8 ] loss: 0.5579627156257629 2022-05-29 15:37:49.098124
Epoch:[ 10 9 ] loss: 0.5569797158241272 2022-05-29 15:37:49.863753
Epoch:[ 10 10 ] loss: 0.562702476978302 2022-05-29 15:37:50.630213
Epoch:[ 10 11 ] loss: 0.5614205002784729 2022-05-29 15:37:51.394725
Epoch:[ 10 12 ] loss: 0.5556218028068542 2022-05-29 15:37:52.161540
Epoch:[ 10 13 ] loss: 0.5602365136146545 2022-05-29 15:37:52.928909
Epoch:[ 10 14 ] loss: 0.5566170811653137 2022-05-29 15:37:53.697232
Epoch:[ 10 15 ] loss: 0.5563889145851135 2022-05-29 15:37:54.464343
Epoch:[ 10 16 ] loss: 0.5586638450622559 2022-05-29 15:38:01.996559
Epoch:[ 10 17 ] loss: 0.5557877421379089 2022-05-29 15:38:02.766862
Epoch:[ 10 18 ] loss: 0.5562666058540344 2022-05-29 15:38:03.534345
Epoch:[ 10 19 ] loss: 0.555110514163971 2022-05-29 15:38:05.997463
Training_Epoch:[ 10 ] Training_loss: 0.558978271484375 2022-05-29 15:38:05.998260
learning rate:  0.002
netparams have been saved once 10
val: 1 0.5546030402183533
val: 2 0.5561537146568298
val: 3 0.5499477982521057
val: 4 0.5678203105926514
val: 5 0.5693809390068054
val: 6 0.5677825808525085
val: 7 0.5659438967704773
val: 8 0.5656001567840576
val: 9 0.5533950924873352
val: 10 0.5698916912078857
val: 11 0.5547635555267334
val: 12 0.5652548670768738
val: 13 0.5594242215156555
val: 14 0.5704227685928345
val: 15 0.5385172367095947
val: 16 0.5646481513977051
val: 17 0.5564680099487305
val: 18 0.5640867352485657
val: 19 0.5571731328964233
val: 20 0.5587551593780518
val_Epoch:[ 10 ] val_loss: 0.560501652956009 2022-05-29 15:38:11.664900
start training 2022-05-29 15:38:11.759001
Epoch:[ 11 0 ] loss: 0.5603585839271545 2022-05-29 15:38:36.174739
Epoch:[ 11 1 ] loss: 0.5593993663787842 2022-05-29 15:38:36.972183
Epoch:[ 11 2 ] loss: 0.5581218004226685 2022-05-29 15:38:37.738878
Epoch:[ 11 3 ] loss: 0.5619615316390991 2022-05-29 15:38:38.506216
Epoch:[ 11 4 ] loss: 0.5547068119049072 2022-05-29 15:38:39.273927
Epoch:[ 11 5 ] loss: 0.5589505434036255 2022-05-29 15:38:40.040067
Epoch:[ 11 6 ] loss: 0.5535874366760254 2022-05-29 15:38:40.804858
Epoch:[ 11 7 ] loss: 0.5593127608299255 2022-05-29 15:38:41.570231
Epoch:[ 11 8 ] loss: 0.5572025775909424 2022-05-29 15:38:42.336045
Epoch:[ 11 9 ] loss: 0.554724395275116 2022-05-29 15:38:43.138807
Epoch:[ 11 10 ] loss: 0.5559747815132141 2022-05-29 15:38:43.905222
Epoch:[ 11 11 ] loss: 0.5564146041870117 2022-05-29 15:38:44.670618
Epoch:[ 11 12 ] loss: 0.5596086382865906 2022-05-29 15:38:45.436596
Epoch:[ 11 13 ] loss: 0.5562722682952881 2022-05-29 15:38:46.203306
Epoch:[ 11 14 ] loss: 0.5590126514434814 2022-05-29 15:38:46.969982
Epoch:[ 11 15 ] loss: 0.5579712986946106 2022-05-29 15:38:47.735381
Epoch:[ 11 16 ] loss: 0.560183584690094 2022-05-29 15:38:55.525924
Epoch:[ 11 17 ] loss: 0.5537463426589966 2022-05-29 15:38:56.293635
Epoch:[ 11 18 ] loss: 0.5580546259880066 2022-05-29 15:38:57.063563
Epoch:[ 11 19 ] loss: 0.5558211207389832 2022-05-29 15:38:57.827608
Training_Epoch:[ 11 ] Training_loss: 0.5575692862272262 2022-05-29 15:38:57.828407
learning rate:  0.0016
val: 1 0.5528125166893005
val: 2 0.5661869645118713
val: 3 0.557481586933136
val: 4 0.564755916595459
val: 5 0.5439406037330627
val: 6 0.5546312928199768
val: 7 0.5657153725624084
val: 8 0.5659663081169128
val: 9 0.5586825013160706
val: 10 0.5624821186065674
val: 11 0.556191086769104
val: 12 0.5386228561401367
val: 13 0.5610625147819519
val: 14 0.5637485980987549
val: 15 0.5661492347717285
val: 16 0.5552849769592285
val: 17 0.5626755356788635
val: 18 0.5703132748603821
val: 19 0.5674837827682495
val: 20 0.5707389116287231
val_Epoch:[ 11 ] val_loss: 0.5602462977170944 2022-05-29 15:39:03.397118
start training 2022-05-29 15:39:03.493193
Epoch:[ 12 0 ] loss: 0.561069130897522 2022-05-29 15:39:28.082286
Epoch:[ 12 1 ] loss: 0.5533176064491272 2022-05-29 15:39:28.883267
Epoch:[ 12 2 ] loss: 0.5549145340919495 2022-05-29 15:39:29.649720
Epoch:[ 12 3 ] loss: 0.5496731996536255 2022-05-29 15:39:30.417852
Epoch:[ 12 4 ] loss: 0.5575564503669739 2022-05-29 15:39:31.183909
Epoch:[ 12 5 ] loss: 0.5597801804542542 2022-05-29 15:39:31.948846
Epoch:[ 12 6 ] loss: 0.5573130249977112 2022-05-29 15:39:32.713708
Epoch:[ 12 7 ] loss: 0.5554309487342834 2022-05-29 15:39:33.480861
Epoch:[ 12 8 ] loss: 0.5577863454818726 2022-05-29 15:39:34.245746
Epoch:[ 12 9 ] loss: 0.5575571060180664 2022-05-29 15:39:35.012285
Epoch:[ 12 10 ] loss: 0.5547022223472595 2022-05-29 15:39:35.779256
Epoch:[ 12 11 ] loss: 0.5618177056312561 2022-05-29 15:39:36.545831
Epoch:[ 12 12 ] loss: 0.561043381690979 2022-05-29 15:39:37.310261
Epoch:[ 12 13 ] loss: 0.553835928440094 2022-05-29 15:39:38.076764
Epoch:[ 12 14 ] loss: 0.5542234778404236 2022-05-29 15:39:38.842459
Epoch:[ 12 15 ] loss: 0.5490627288818359 2022-05-29 15:39:39.606731
Epoch:[ 12 16 ] loss: 0.562122642993927 2022-05-29 15:39:47.546700
Epoch:[ 12 17 ] loss: 0.5560321807861328 2022-05-29 15:39:48.314325
Epoch:[ 12 18 ] loss: 0.5540409088134766 2022-05-29 15:39:49.079590
Epoch:[ 12 19 ] loss: 0.5517975687980652 2022-05-29 15:39:51.006568
Training_Epoch:[ 12 ] Training_loss: 0.5561538636684418 2022-05-29 15:39:51.007330
learning rate:  0.0016
netparams have been saved once 12
val: 1 0.5622329115867615
val: 2 0.5555307865142822
val: 3 0.558144211769104
val: 4 0.5508067011833191
val: 5 0.549548864364624
val: 6 0.5385053753852844
val: 7 0.5643096566200256
val: 8 0.5575437545776367
val: 9 0.569495677947998
val: 10 0.5693113803863525
val: 11 0.5473243594169617
val: 12 0.5603757500648499
val: 13 0.5632303953170776
val: 14 0.5737981796264648
val: 15 0.5639713406562805
val: 16 0.566538393497467
val: 17 0.561785101890564
val: 18 0.5554472804069519
val: 19 0.5675146579742432
val: 20 0.5613933801651001
val_Epoch:[ 12 ] val_loss: 0.5598404079675674 2022-05-29 15:39:56.962222
start training 2022-05-29 15:39:57.061558
Epoch:[ 13 0 ] loss: 0.5563271641731262 2022-05-29 15:40:22.277674
Epoch:[ 13 1 ] loss: 0.5538594126701355 2022-05-29 15:40:23.045344
Epoch:[ 13 2 ] loss: 0.5557937026023865 2022-05-29 15:40:23.811657
Epoch:[ 13 3 ] loss: 0.5547619462013245 2022-05-29 15:40:24.576104
Epoch:[ 13 4 ] loss: 0.5523150563240051 2022-05-29 15:40:25.342838
Epoch:[ 13 5 ] loss: 0.5558571219444275 2022-05-29 15:40:26.108078
Epoch:[ 13 6 ] loss: 0.5560818910598755 2022-05-29 15:40:26.873167
Epoch:[ 13 7 ] loss: 0.5530222654342651 2022-05-29 15:40:27.637450
Epoch:[ 13 8 ] loss: 0.5549678206443787 2022-05-29 15:40:28.401656
Epoch:[ 13 9 ] loss: 0.5546056628227234 2022-05-29 15:40:29.165806
Epoch:[ 13 10 ] loss: 0.5547406673431396 2022-05-29 15:40:29.933040
Epoch:[ 13 11 ] loss: 0.555250346660614 2022-05-29 15:40:30.700062
Epoch:[ 13 12 ] loss: 0.5547112822532654 2022-05-29 15:40:31.464789
Epoch:[ 13 13 ] loss: 0.5525034666061401 2022-05-29 15:40:32.231943
Epoch:[ 13 14 ] loss: 0.5500304102897644 2022-05-29 15:40:32.997357
Epoch:[ 13 15 ] loss: 0.5496987700462341 2022-05-29 15:40:33.760899
Epoch:[ 13 16 ] loss: 0.5513846278190613 2022-05-29 15:40:41.200493
Epoch:[ 13 17 ] loss: 0.5593191981315613 2022-05-29 15:40:41.965540
Epoch:[ 13 18 ] loss: 0.5542452335357666 2022-05-29 15:40:45.198236
Epoch:[ 13 19 ] loss: 0.5523542165756226 2022-05-29 15:40:45.964550
Training_Epoch:[ 13 ] Training_loss: 0.5540915131568909 2022-05-29 15:40:45.965349
learning rate:  0.0016
val: 1 0.552135169506073
val: 2 0.5583735108375549
val: 3 0.543587863445282
val: 4 0.564201295375824
val: 5 0.5614575147628784
val: 6 0.5582179427146912
val: 7 0.5460185408592224
val: 8 0.5531232953071594
val: 9 0.5681939721107483
val: 10 0.5466225147247314
val: 11 0.5691749453544617
val: 12 0.5425747036933899
val: 13 0.5629366040229797
val: 14 0.5529796481132507
val: 15 0.5653878450393677
val: 16 0.555559515953064
val: 17 0.5536211133003235
val: 18 0.5757413506507874
val: 19 0.561453640460968
val: 20 0.5558369159698486
val_Epoch:[ 13 ] val_loss: 0.5573598951101303 2022-05-29 15:40:51.832105
start training 2022-05-29 15:40:51.927503
Epoch:[ 14 0 ] loss: 0.5535181760787964 2022-05-29 15:41:15.795218
Epoch:[ 14 1 ] loss: 0.5456084609031677 2022-05-29 15:41:16.742288
Epoch:[ 14 2 ] loss: 0.5488415956497192 2022-05-29 15:41:17.507936
Epoch:[ 14 3 ] loss: 0.5555573105812073 2022-05-29 15:41:18.275407
Epoch:[ 14 4 ] loss: 0.5506152510643005 2022-05-29 15:41:19.043466
Epoch:[ 14 5 ] loss: 0.5637831091880798 2022-05-29 15:41:19.810041
Epoch:[ 14 6 ] loss: 0.547508180141449 2022-05-29 15:41:20.575672
Epoch:[ 14 7 ] loss: 0.5481477379798889 2022-05-29 15:41:21.341432
Epoch:[ 14 8 ] loss: 0.5524699091911316 2022-05-29 15:41:22.106031
Epoch:[ 14 9 ] loss: 0.5532412528991699 2022-05-29 15:41:22.870673
Epoch:[ 14 10 ] loss: 0.5541903972625732 2022-05-29 15:41:23.634211
Epoch:[ 14 11 ] loss: 0.5557078719139099 2022-05-29 15:41:24.399056
Epoch:[ 14 12 ] loss: 0.554377019405365 2022-05-29 15:41:25.164385
Epoch:[ 14 13 ] loss: 0.5555737018585205 2022-05-29 15:41:25.930159
Epoch:[ 14 14 ] loss: 0.5518298745155334 2022-05-29 15:41:26.693434
Epoch:[ 14 15 ] loss: 0.5528749227523804 2022-05-29 15:41:27.458343
Epoch:[ 14 16 ] loss: 0.5496102571487427 2022-05-29 15:41:35.561663
Epoch:[ 14 17 ] loss: 0.5491759777069092 2022-05-29 15:41:36.326458
Epoch:[ 14 18 ] loss: 0.5504665374755859 2022-05-29 15:41:39.279678
Epoch:[ 14 19 ] loss: 0.5496774911880493 2022-05-29 15:41:40.046292
Training_Epoch:[ 14 ] Training_loss: 0.552138751745224 2022-05-29 15:41:40.046954
learning rate:  0.0016
netparams have been saved once 14
val: 1 0.5590736865997314
val: 2 0.5688356161117554
val: 3 0.5421165823936462
val: 4 0.5706160068511963
val: 5 0.5502528548240662
val: 6 0.5506239533424377
val: 7 0.5635197162628174
val: 8 0.5547072291374207
val: 9 0.5637049078941345
val: 10 0.5681315064430237
val: 11 0.5696799755096436
val: 12 0.5630543828010559
val: 13 0.5503106713294983
val: 14 0.528343141078949
val: 15 0.5604155659675598
val: 16 0.5623914003372192
val: 17 0.5790953040122986
val: 18 0.5515950322151184
val: 19 0.5726054906845093
val: 20 0.555000901222229
val_Epoch:[ 14 ] val_loss: 0.5592036962509155 2022-05-29 15:41:45.737784
start training 2022-05-29 15:41:45.836622
Epoch:[ 15 0 ] loss: 0.5457825660705566 2022-05-29 15:42:11.689961
Epoch:[ 15 1 ] loss: 0.5502703189849854 2022-05-29 15:42:12.456321
Epoch:[ 15 2 ] loss: 0.5491624474525452 2022-05-29 15:42:13.219532
Epoch:[ 15 3 ] loss: 0.5498830080032349 2022-05-29 15:42:13.982764
Epoch:[ 15 4 ] loss: 0.5493529438972473 2022-05-29 15:42:14.748754
Epoch:[ 15 5 ] loss: 0.5439487099647522 2022-05-29 15:42:15.514754
Epoch:[ 15 6 ] loss: 0.5526511669158936 2022-05-29 15:42:16.281562
Epoch:[ 15 7 ] loss: 0.5458136200904846 2022-05-29 15:42:17.046253
Epoch:[ 15 8 ] loss: 0.5533645749092102 2022-05-29 15:42:17.813432
Epoch:[ 15 9 ] loss: 0.5451655387878418 2022-05-29 15:42:18.577491
Epoch:[ 15 10 ] loss: 0.5509994626045227 2022-05-29 15:42:19.341659
Epoch:[ 15 11 ] loss: 0.5509986877441406 2022-05-29 15:42:20.106273
Epoch:[ 15 12 ] loss: 0.5450385212898254 2022-05-29 15:42:20.870925
Epoch:[ 15 13 ] loss: 0.5481991767883301 2022-05-29 15:42:21.636872
Epoch:[ 15 14 ] loss: 0.5553992986679077 2022-05-29 15:42:22.401678
Epoch:[ 15 15 ] loss: 0.544540524482727 2022-05-29 15:42:23.165568
Epoch:[ 15 16 ] loss: 0.5535547733306885 2022-05-29 15:42:33.488158
Epoch:[ 15 17 ] loss: 0.5466529726982117 2022-05-29 15:42:34.253736
Epoch:[ 15 18 ] loss: 0.5467795729637146 2022-05-29 15:42:35.035171
Epoch:[ 15 19 ] loss: 0.5484470129013062 2022-05-29 15:42:35.800373
Training_Epoch:[ 15 ] Training_loss: 0.5488002449274063 2022-05-29 15:42:35.801113
learning rate:  0.0016
val: 1 0.5672551393508911
val: 2 0.5361619591712952
val: 3 0.5522268414497375
val: 4 0.5552809238433838
val: 5 0.5484577417373657
val: 6 0.5636646151542664
val: 7 0.5691843628883362
val: 8 0.5845497250556946
val: 9 0.5348541140556335
val: 10 0.5491588711738586
val: 11 0.541864812374115
val: 12 0.5382763147354126
val: 13 0.5523366928100586
val: 14 0.5636999607086182
val: 15 0.5710923075675964
val: 16 0.544959306716919
val: 17 0.5659313201904297
val: 18 0.5573219656944275
val: 19 0.5648714303970337
val: 20 0.578517496585846
val_Epoch:[ 15 ] val_loss: 0.556983295083046 2022-05-29 15:42:41.402899
start training 2022-05-29 15:42:41.500880
Epoch:[ 16 0 ] loss: 0.5445719361305237 2022-05-29 15:43:05.468818
Epoch:[ 16 1 ] loss: 0.5513880848884583 2022-05-29 15:43:07.125125
Epoch:[ 16 2 ] loss: 0.5465021729469299 2022-05-29 15:43:07.893381
Epoch:[ 16 3 ] loss: 0.5454908609390259 2022-05-29 15:43:08.659336
Epoch:[ 16 4 ] loss: 0.5541650056838989 2022-05-29 15:43:09.425966
Epoch:[ 16 5 ] loss: 0.5417818427085876 2022-05-29 15:43:10.190470
Epoch:[ 16 6 ] loss: 0.5494587421417236 2022-05-29 15:43:10.955761
Epoch:[ 16 7 ] loss: 0.5449495315551758 2022-05-29 15:43:11.723857
Epoch:[ 16 8 ] loss: 0.5479932427406311 2022-05-29 15:43:12.488035
Epoch:[ 16 9 ] loss: 0.5486060380935669 2022-05-29 15:43:13.254116
Epoch:[ 16 10 ] loss: 0.5446963310241699 2022-05-29 15:43:14.018922
Epoch:[ 16 11 ] loss: 0.5499638915061951 2022-05-29 15:43:14.785004
Epoch:[ 16 12 ] loss: 0.5439550876617432 2022-05-29 15:43:15.550126
Epoch:[ 16 13 ] loss: 0.5418096780776978 2022-05-29 15:43:16.318691
Epoch:[ 16 14 ] loss: 0.5448963046073914 2022-05-29 15:43:17.084878
Epoch:[ 16 15 ] loss: 0.5459067821502686 2022-05-29 15:43:17.851452
Epoch:[ 16 16 ] loss: 0.5426156520843506 2022-05-29 15:43:25.639201
Epoch:[ 16 17 ] loss: 0.5520634651184082 2022-05-29 15:43:28.924648
Epoch:[ 16 18 ] loss: 0.5418670773506165 2022-05-29 15:43:29.693560
Epoch:[ 16 19 ] loss: 0.5420725345611572 2022-05-29 15:43:30.462982
Training_Epoch:[ 16 ] Training_loss: 0.546237713098526 2022-05-29 15:43:30.463777
learning rate:  0.0016
netparams have been saved once 16
val: 1 0.5411546230316162
val: 2 0.5401585698127747
val: 3 0.5464253425598145
val: 4 0.5607389211654663
val: 5 0.554325520992279
val: 6 0.5473456978797913
val: 7 0.555033802986145
val: 8 0.5567427277565002
val: 9 0.5529627799987793
val: 10 0.5588626265525818
val: 11 0.5585773587226868
val: 12 0.5695987939834595
val: 13 0.5547025799751282
val: 14 0.5466675758361816
val: 15 0.5540220141410828
val: 16 0.5329879522323608
val: 17 0.5486654043197632
val: 18 0.5467913746833801
val: 19 0.5359085202217102
val: 20 0.534108579158783
val_Epoch:[ 16 ] val_loss: 0.5497890383005142 2022-05-29 15:43:36.495443
start training 2022-05-29 15:43:36.614057
Epoch:[ 17 0 ] loss: 0.5453770756721497 2022-05-29 15:44:01.893089
Epoch:[ 17 1 ] loss: 0.5447884798049927 2022-05-29 15:44:02.660469
Epoch:[ 17 2 ] loss: 0.5411604046821594 2022-05-29 15:44:03.428600
Epoch:[ 17 3 ] loss: 0.5436896085739136 2022-05-29 15:44:04.196106
Epoch:[ 17 4 ] loss: 0.5465621948242188 2022-05-29 15:44:04.960497
Epoch:[ 17 5 ] loss: 0.5362306833267212 2022-05-29 15:44:05.727545
Epoch:[ 17 6 ] loss: 0.5427786111831665 2022-05-29 15:44:06.492773
Epoch:[ 17 7 ] loss: 0.5410188436508179 2022-05-29 15:44:07.262827
Epoch:[ 17 8 ] loss: 0.5434741973876953 2022-05-29 15:44:08.033008
Epoch:[ 17 9 ] loss: 0.5392711162567139 2022-05-29 15:44:08.802275
Epoch:[ 17 10 ] loss: 0.5465644001960754 2022-05-29 15:44:09.570711
Epoch:[ 17 11 ] loss: 0.5409315824508667 2022-05-29 15:44:10.336208
Epoch:[ 17 12 ] loss: 0.5400459170341492 2022-05-29 15:44:11.103007
Epoch:[ 17 13 ] loss: 0.5389832854270935 2022-05-29 15:44:11.872500
Epoch:[ 17 14 ] loss: 0.5422420501708984 2022-05-29 15:44:12.638583
Epoch:[ 17 15 ] loss: 0.5432749390602112 2022-05-29 15:44:13.406535
Epoch:[ 17 16 ] loss: 0.5434991121292114 2022-05-29 15:44:21.844814
Epoch:[ 17 17 ] loss: 0.5441389679908752 2022-05-29 15:44:22.612086
Epoch:[ 17 18 ] loss: 0.5440719723701477 2022-05-29 15:44:23.380645
Epoch:[ 17 19 ] loss: 0.5423985123634338 2022-05-29 15:44:24.145870
Training_Epoch:[ 17 ] Training_loss: 0.5425250977277756 2022-05-29 15:44:24.146655
learning rate:  0.0016
val: 1 0.5661797523498535
val: 2 0.5842621326446533
val: 3 0.5991739630699158
val: 4 0.577904462814331
val: 5 0.5805755853652954
val: 6 0.5795934200286865
val: 7 0.5727342963218689
val: 8 0.5840592980384827
val: 9 0.5721432566642761
val: 10 0.5838688611984253
val: 11 0.575104832649231
val: 12 0.5660120844841003
val: 13 0.5717357993125916
val: 14 0.5845018029212952
val: 15 0.5670616030693054
val: 16 0.5819078683853149
val: 17 0.5702627301216125
val: 18 0.5547696948051453
val: 19 0.5704256296157837
val: 20 0.5654391646385193
val_Epoch:[ 17 ] val_loss: 0.5753858119249344 2022-05-29 15:44:29.798735
start training 2022-05-29 15:44:29.901626
Epoch:[ 18 0 ] loss: 0.5345715284347534 2022-05-29 15:44:55.283110
Epoch:[ 18 1 ] loss: 0.5385878682136536 2022-05-29 15:44:56.050540
Epoch:[ 18 2 ] loss: 0.5413933992385864 2022-05-29 15:44:56.816338
Epoch:[ 18 3 ] loss: 0.5367683172225952 2022-05-29 15:44:57.578798
Epoch:[ 18 4 ] loss: 0.5453977584838867 2022-05-29 15:44:58.344339
Epoch:[ 18 5 ] loss: 0.5438809394836426 2022-05-29 15:44:59.109880
Epoch:[ 18 6 ] loss: 0.543717622756958 2022-05-29 15:44:59.874282
Epoch:[ 18 7 ] loss: 0.5452138781547546 2022-05-29 15:45:00.637435
Epoch:[ 18 8 ] loss: 0.5434843301773071 2022-05-29 15:45:01.402502
Epoch:[ 18 9 ] loss: 0.5396298766136169 2022-05-29 15:45:02.168794
Epoch:[ 18 10 ] loss: 0.5407108664512634 2022-05-29 15:45:02.936062
Epoch:[ 18 11 ] loss: 0.5413023233413696 2022-05-29 15:45:03.702450
Epoch:[ 18 12 ] loss: 0.5353232622146606 2022-05-29 15:45:04.466074
Epoch:[ 18 13 ] loss: 0.544946551322937 2022-05-29 15:45:05.230683
Epoch:[ 18 14 ] loss: 0.543508768081665 2022-05-29 15:45:05.995040
Epoch:[ 18 15 ] loss: 0.5413102507591248 2022-05-29 15:45:06.760622
Epoch:[ 18 16 ] loss: 0.5358428359031677 2022-05-29 15:45:18.259306
Epoch:[ 18 17 ] loss: 0.5410869717597961 2022-05-29 15:45:19.024613
Epoch:[ 18 18 ] loss: 0.5430411100387573 2022-05-29 15:45:19.810048
Epoch:[ 18 19 ] loss: 0.5436168909072876 2022-05-29 15:45:20.573772
Training_Epoch:[ 18 ] Training_loss: 0.5411667674779892 2022-05-29 15:45:20.574452
learning rate:  0.0016
netparams have been saved once 18
val: 1 0.5499435067176819
val: 2 0.5340952277183533
val: 3 0.5653576254844666
val: 4 0.5459616780281067
val: 5 0.5436124801635742
val: 6 0.5357800722122192
val: 7 0.5667315721511841
val: 8 0.544874906539917
val: 9 0.5598230361938477
val: 10 0.5502039194107056
val: 11 0.5398735404014587
val: 12 0.5512120723724365
val: 13 0.5564490556716919
val: 14 0.552492082118988
val: 15 0.5549429059028625
val: 16 0.5480467677116394
val: 17 0.5656530857086182
val: 18 0.5524296760559082
val: 19 0.5434737205505371
val: 20 0.5513661503791809
val_Epoch:[ 18 ] val_loss: 0.5506161540746689 2022-05-29 15:45:26.508060
start training 2022-05-29 15:45:26.628801
Epoch:[ 19 0 ] loss: 0.5375497341156006 2022-05-29 15:45:51.591592
Epoch:[ 19 1 ] loss: 0.5434619188308716 2022-05-29 15:45:52.354433
Epoch:[ 19 2 ] loss: 0.5423222780227661 2022-05-29 15:45:53.117924
Epoch:[ 19 3 ] loss: 0.536849319934845 2022-05-29 15:45:53.885226
Epoch:[ 19 4 ] loss: 0.538956880569458 2022-05-29 15:45:54.648032
Epoch:[ 19 5 ] loss: 0.5429229140281677 2022-05-29 15:45:55.414372
Epoch:[ 19 6 ] loss: 0.5385733842849731 2022-05-29 15:45:56.179555
Epoch:[ 19 7 ] loss: 0.5408812761306763 2022-05-29 15:45:56.944928
Epoch:[ 19 8 ] loss: 0.5433063507080078 2022-05-29 15:45:57.709837
Epoch:[ 19 9 ] loss: 0.5366354584693909 2022-05-29 15:45:58.475126
Epoch:[ 19 10 ] loss: 0.5401939749717712 2022-05-29 15:45:59.239712
Epoch:[ 19 11 ] loss: 0.5390505194664001 2022-05-29 15:46:00.006714
Epoch:[ 19 12 ] loss: 0.5351166725158691 2022-05-29 15:46:00.772898
Epoch:[ 19 13 ] loss: 0.5317015647888184 2022-05-29 15:46:01.537494
Epoch:[ 19 14 ] loss: 0.5372190475463867 2022-05-29 15:46:02.302219
Epoch:[ 19 15 ] loss: 0.5358556509017944 2022-05-29 15:46:03.066639
Epoch:[ 19 16 ] loss: 0.5376502871513367 2022-05-29 15:46:10.741381
Epoch:[ 19 17 ] loss: 0.536926805973053 2022-05-29 15:46:11.507294
Epoch:[ 19 18 ] loss: 0.538423478603363 2022-05-29 15:46:12.275082
Epoch:[ 19 19 ] loss: 0.5385646820068359 2022-05-29 15:46:13.038316
Training_Epoch:[ 19 ] Training_loss: 0.5386081099510193 2022-05-29 15:46:13.039112
learning rate:  0.0016
val: 1 0.5426921248435974
val: 2 0.539060652256012
val: 3 0.5372333526611328
val: 4 0.5432294607162476
val: 5 0.5273584723472595
val: 6 0.5333873629570007
val: 7 0.5438467860221863
val: 8 0.544109582901001
val: 9 0.5487454533576965
val: 10 0.5378342866897583
val: 11 0.530983567237854
val: 12 0.5589109659194946
val: 13 0.5320164561271667
val: 14 0.5522128343582153
val: 15 0.5438575744628906
val: 16 0.5393068790435791
val: 17 0.5331153869628906
val: 18 0.5381682515144348
val: 19 0.5365409255027771
val: 20 0.5353783369064331
val_Epoch:[ 19 ] val_loss: 0.5398994356393814 2022-05-29 15:46:18.660810
start training 2022-05-29 15:46:18.763590
Epoch:[ 20 0 ] loss: 0.5399051904678345 2022-05-29 15:46:44.034410
Epoch:[ 20 1 ] loss: 0.5359874367713928 2022-05-29 15:46:44.800257
Epoch:[ 20 2 ] loss: 0.5359786152839661 2022-05-29 15:46:45.567000
Epoch:[ 20 3 ] loss: 0.5342445969581604 2022-05-29 15:46:46.334327
Epoch:[ 20 4 ] loss: 0.5353736281394958 2022-05-29 15:46:47.101866
Epoch:[ 20 5 ] loss: 0.5362429022789001 2022-05-29 15:46:47.869745
Epoch:[ 20 6 ] loss: 0.537960946559906 2022-05-29 15:46:48.636833
Epoch:[ 20 7 ] loss: 0.534381091594696 2022-05-29 15:46:49.402490
Epoch:[ 20 8 ] loss: 0.5403576493263245 2022-05-29 15:46:50.169763
Epoch:[ 20 9 ] loss: 0.5350626111030579 2022-05-29 15:46:50.934892
Epoch:[ 20 10 ] loss: 0.5340918898582458 2022-05-29 15:46:51.700623
Epoch:[ 20 11 ] loss: 0.5344882011413574 2022-05-29 15:46:52.467672
Epoch:[ 20 12 ] loss: 0.5355324745178223 2022-05-29 15:46:53.231000
Epoch:[ 20 13 ] loss: 0.5352051258087158 2022-05-29 15:46:53.996547
Epoch:[ 20 14 ] loss: 0.5321188569068909 2022-05-29 15:46:54.761388
Epoch:[ 20 15 ] loss: 0.5399751663208008 2022-05-29 15:46:55.527496
Epoch:[ 20 16 ] loss: 0.5324041247367859 2022-05-29 15:47:06.186912
Epoch:[ 20 17 ] loss: 0.535417914390564 2022-05-29 15:47:06.952744
Epoch:[ 20 18 ] loss: 0.5307602882385254 2022-05-29 15:47:07.721306
Epoch:[ 20 19 ] loss: 0.5371884703636169 2022-05-29 15:47:08.484713
Training_Epoch:[ 20 ] Training_loss: 0.5356338590383529 2022-05-29 15:47:08.485365
learning rate:  0.0016
netparams have been saved once 20
val: 1 0.5292317867279053
val: 2 0.5457909107208252
val: 3 0.5392810106277466
val: 4 0.5341334342956543
val: 5 0.5598688125610352
val: 6 0.5495821833610535
val: 7 0.5570178031921387
val: 8 0.5447456240653992
val: 9 0.5605615377426147
val: 10 0.5485868453979492
val: 11 0.5506213903427124
val: 12 0.5464144945144653
val: 13 0.5515305399894714
val: 14 0.5477407574653625
val: 15 0.5389630198478699
val: 16 0.5430039763450623
val: 17 0.5548108816146851
val: 18 0.5604861378669739
val: 19 0.549595057964325
val: 20 0.5488391518592834
val_Epoch:[ 20 ] val_loss: 0.5480402678251266 2022-05-29 15:47:14.135628
start training 2022-05-29 15:47:14.242962
Epoch:[ 21 0 ] loss: 0.5343747138977051 2022-05-29 15:47:38.271710
Epoch:[ 21 1 ] loss: 0.5328922271728516 2022-05-29 15:47:39.286267
Epoch:[ 21 2 ] loss: 0.5343273878097534 2022-05-29 15:47:40.049807
Epoch:[ 21 3 ] loss: 0.5372856855392456 2022-05-29 15:47:40.812752
Epoch:[ 21 4 ] loss: 0.5348545908927917 2022-05-29 15:47:41.577941
Epoch:[ 21 5 ] loss: 0.5339673757553101 2022-05-29 15:47:42.345662
Epoch:[ 21 6 ] loss: 0.5404248237609863 2022-05-29 15:47:43.112165
Epoch:[ 21 7 ] loss: 0.5354068279266357 2022-05-29 15:47:43.877792
Epoch:[ 21 8 ] loss: 0.5343798398971558 2022-05-29 15:47:44.642533
Epoch:[ 21 9 ] loss: 0.5311776399612427 2022-05-29 15:47:45.408202
Epoch:[ 21 10 ] loss: 0.5344530940055847 2022-05-29 15:47:46.174428
Epoch:[ 21 11 ] loss: 0.5317561030387878 2022-05-29 15:47:46.938806
Epoch:[ 21 12 ] loss: 0.5284180045127869 2022-05-29 15:47:47.705795
Epoch:[ 21 13 ] loss: 0.5313364863395691 2022-05-29 15:47:48.470495
Epoch:[ 21 14 ] loss: 0.5326821804046631 2022-05-29 15:47:49.236585
Epoch:[ 21 15 ] loss: 0.531464159488678 2022-05-29 15:47:50.002473
Epoch:[ 21 16 ] loss: 0.5306192636489868 2022-05-29 15:47:57.820001
Epoch:[ 21 17 ] loss: 0.5372290015220642 2022-05-29 15:48:01.734302
Epoch:[ 21 18 ] loss: 0.5330792665481567 2022-05-29 15:48:02.505277
Epoch:[ 21 19 ] loss: 0.5308365225791931 2022-05-29 15:48:03.275335
Training_Epoch:[ 21 ] Training_loss: 0.5335482597351074 2022-05-29 15:48:03.276087
learning rate:  0.00128
val: 1 0.5475146174430847
val: 2 0.536518394947052
val: 3 0.543121874332428
val: 4 0.5318835973739624
val: 5 0.5465982556343079
val: 6 0.5240077376365662
val: 7 0.5211966633796692
val: 8 0.5392919182777405
val: 9 0.536356508731842
val: 10 0.532293975353241
val: 11 0.5232937335968018
val: 12 0.5452252626419067
val: 13 0.5480928421020508
val: 14 0.5212813019752502
val: 15 0.5311717987060547
val: 16 0.5357240438461304
val: 17 0.5279662013053894
val: 18 0.550480306148529
val: 19 0.5389605164527893
val: 20 0.525406539440155
val_Epoch:[ 21 ] val_loss: 0.5353193044662475 2022-05-29 15:48:09.025409
start training 2022-05-29 15:48:09.128356
Epoch:[ 22 0 ] loss: 0.5306500196456909 2022-05-29 15:48:34.477414
Epoch:[ 22 1 ] loss: 0.5331777930259705 2022-05-29 15:48:35.245466
Epoch:[ 22 2 ] loss: 0.5338017344474792 2022-05-29 15:48:36.012180
Epoch:[ 22 3 ] loss: 0.5292067527770996 2022-05-29 15:48:36.777292
Epoch:[ 22 4 ] loss: 0.5364237427711487 2022-05-29 15:48:37.542624
Epoch:[ 22 5 ] loss: 0.5301315188407898 2022-05-29 15:48:38.309409
Epoch:[ 22 6 ] loss: 0.5310247540473938 2022-05-29 15:48:39.077061
Epoch:[ 22 7 ] loss: 0.5331349968910217 2022-05-29 15:48:39.842888
Epoch:[ 22 8 ] loss: 0.5337973833084106 2022-05-29 15:48:40.608303
Epoch:[ 22 9 ] loss: 0.530418872833252 2022-05-29 15:48:41.373374
Epoch:[ 22 10 ] loss: 0.5350289940834045 2022-05-29 15:48:42.139375
Epoch:[ 22 11 ] loss: 0.5329563021659851 2022-05-29 15:48:42.904031
Epoch:[ 22 12 ] loss: 0.5314672589302063 2022-05-29 15:48:43.670362
Epoch:[ 22 13 ] loss: 0.5354225039482117 2022-05-29 15:48:44.437445
Epoch:[ 22 14 ] loss: 0.5324984788894653 2022-05-29 15:48:45.204531
Epoch:[ 22 15 ] loss: 0.524235725402832 2022-05-29 15:48:45.971933
Epoch:[ 22 16 ] loss: 0.5261625647544861 2022-05-29 15:48:56.519779
Epoch:[ 22 17 ] loss: 0.5296493768692017 2022-05-29 15:48:57.285483
Epoch:[ 22 18 ] loss: 0.5266720056533813 2022-05-29 15:48:58.067156
Epoch:[ 22 19 ] loss: 0.5322077870368958 2022-05-29 15:48:58.832924
Training_Epoch:[ 22 ] Training_loss: 0.5314034283161163 2022-05-29 15:48:58.833601
learning rate:  0.00128
netparams have been saved once 22
val: 1 0.5333553552627563
val: 2 0.5341216921806335
val: 3 0.5413756370544434
val: 4 0.522250771522522
val: 5 0.5286386013031006
val: 6 0.5472959280014038
val: 7 0.5306142568588257
val: 8 0.5426129698753357
val: 9 0.5420989990234375
val: 10 0.527379035949707
val: 11 0.5577471256256104
val: 12 0.5438238978385925
val: 13 0.5502467155456543
val: 14 0.5369476079940796
val: 15 0.5291951894760132
val: 16 0.5493712425231934
val: 17 0.5227680206298828
val: 18 0.552954912185669
val: 19 0.5476458072662354
val: 20 0.534989595413208
val_Epoch:[ 22 ] val_loss: 0.5387716680765152 2022-05-29 15:49:04.528608
start training 2022-05-29 15:49:04.630177
Epoch:[ 23 0 ] loss: 0.5288714170455933 2022-05-29 15:49:30.310724
Epoch:[ 23 1 ] loss: 0.5285065174102783 2022-05-29 15:49:31.078852
Epoch:[ 23 2 ] loss: 0.5342186689376831 2022-05-29 15:49:31.844866
Epoch:[ 23 3 ] loss: 0.5287927985191345 2022-05-29 15:49:32.610324
Epoch:[ 23 4 ] loss: 0.5291344523429871 2022-05-29 15:49:33.377408
Epoch:[ 23 5 ] loss: 0.5275321006774902 2022-05-29 15:49:34.142466
Epoch:[ 23 6 ] loss: 0.5247474312782288 2022-05-29 15:49:34.908685
Epoch:[ 23 7 ] loss: 0.5267122387886047 2022-05-29 15:49:35.674197
Epoch:[ 23 8 ] loss: 0.5293620228767395 2022-05-29 15:49:36.440778
Epoch:[ 23 9 ] loss: 0.5353283882141113 2022-05-29 15:49:37.205803
Epoch:[ 23 10 ] loss: 0.5287057161331177 2022-05-29 15:49:37.972281
Epoch:[ 23 11 ] loss: 0.5280650854110718 2022-05-29 15:49:38.737883
Epoch:[ 23 12 ] loss: 0.5331034064292908 2022-05-29 15:49:39.503586
Epoch:[ 23 13 ] loss: 0.5319516658782959 2022-05-29 15:49:40.269927
Epoch:[ 23 14 ] loss: 0.5319594144821167 2022-05-29 15:49:41.035771
Epoch:[ 23 15 ] loss: 0.519692063331604 2022-05-29 15:49:41.801999
Epoch:[ 23 16 ] loss: 0.5270236134529114 2022-05-29 15:49:52.377032
Epoch:[ 23 17 ] loss: 0.5318483710289001 2022-05-29 15:49:53.142469
Epoch:[ 23 18 ] loss: 0.5253045558929443 2022-05-29 15:49:53.913052
Epoch:[ 23 19 ] loss: 0.5287415385246277 2022-05-29 15:49:54.676947
Training_Epoch:[ 23 ] Training_loss: 0.5289800733327865 2022-05-29 15:49:54.677773
learning rate:  0.00128
val: 1 0.5425136685371399
val: 2 0.5247675180435181
val: 3 0.5293372273445129
val: 4 0.5261743664741516
val: 5 0.5400890707969666
val: 6 0.5450318455696106
val: 7 0.5320172905921936
val: 8 0.5254205465316772
val: 9 0.5149574279785156
val: 10 0.5307747721672058
val: 11 0.5338122844696045
val: 12 0.5302932858467102
val: 13 0.539836585521698
val: 14 0.552648663520813
val: 15 0.5217697620391846
val: 16 0.5481469035148621
val: 17 0.5507346987724304
val: 18 0.5300222635269165
val: 19 0.534434974193573
val: 20 0.5369617342948914
val_Epoch:[ 23 ] val_loss: 0.5344872444868087 2022-05-29 15:50:00.259312
start training 2022-05-29 15:50:00.358083
Epoch:[ 24 0 ] loss: 0.5283809900283813 2022-05-29 15:50:25.526919
Epoch:[ 24 1 ] loss: 0.5263775587081909 2022-05-29 15:50:26.293361
Epoch:[ 24 2 ] loss: 0.526794970035553 2022-05-29 15:50:27.059131
Epoch:[ 24 3 ] loss: 0.5224217176437378 2022-05-29 15:50:27.826217
Epoch:[ 24 4 ] loss: 0.5336380004882812 2022-05-29 15:50:28.592779
Epoch:[ 24 5 ] loss: 0.5298826694488525 2022-05-29 15:50:29.359798
Epoch:[ 24 6 ] loss: 0.5282130241394043 2022-05-29 15:50:30.123800
Epoch:[ 24 7 ] loss: 0.5333276987075806 2022-05-29 15:50:30.890138
Epoch:[ 24 8 ] loss: 0.5232055187225342 2022-05-29 15:50:31.657771
Epoch:[ 24 9 ] loss: 0.5228977799415588 2022-05-29 15:50:32.422776
Epoch:[ 24 10 ] loss: 0.530767023563385 2022-05-29 15:50:33.186768
Epoch:[ 24 11 ] loss: 0.5297785997390747 2022-05-29 15:50:33.951213
Epoch:[ 24 12 ] loss: 0.5291136503219604 2022-05-29 15:50:34.715693
Epoch:[ 24 13 ] loss: 0.529724657535553 2022-05-29 15:50:35.479877
Epoch:[ 24 14 ] loss: 0.5347020030021667 2022-05-29 15:50:36.246377
Epoch:[ 24 15 ] loss: 0.5353237986564636 2022-05-29 15:50:37.012410
Epoch:[ 24 16 ] loss: 0.5308241844177246 2022-05-29 15:50:44.387771
Epoch:[ 24 17 ] loss: 0.5264053344726562 2022-05-29 15:50:45.152067
Epoch:[ 24 18 ] loss: 0.5277426242828369 2022-05-29 15:50:45.935311
Epoch:[ 24 19 ] loss: 0.526655912399292 2022-05-29 15:50:46.698902
Training_Epoch:[ 24 ] Training_loss: 0.5288088858127594 2022-05-29 15:50:46.699585
learning rate:  0.00128
netparams have been saved once 24
val: 1 0.5445740818977356
val: 2 0.5232740044593811
val: 3 0.5330449342727661
val: 4 0.5127549767494202
val: 5 0.5572099685668945
val: 6 0.5456152558326721
val: 7 0.5434854030609131
val: 8 0.5400052070617676
val: 9 0.5475850105285645
val: 10 0.5384818315505981
val: 11 0.5538170337677002
val: 12 0.5405644774436951
val: 13 0.55466228723526
val: 14 0.5287025570869446
val: 15 0.5426062345504761
val: 16 0.542018711566925
val: 17 0.5327103734016418
val: 18 0.5497425198554993
val: 19 0.5219610929489136
val: 20 0.5411241054534912
val_Epoch:[ 24 ] val_loss: 0.5396970033645629 2022-05-29 15:50:52.402038
start training 2022-05-29 15:50:52.506801
Epoch:[ 25 0 ] loss: 0.5305176377296448 2022-05-29 15:51:17.749587
Epoch:[ 25 1 ] loss: 0.5309305191040039 2022-05-29 15:51:18.516413
Epoch:[ 25 2 ] loss: 0.5285061001777649 2022-05-29 15:51:19.283684
Epoch:[ 25 3 ] loss: 0.52182537317276 2022-05-29 15:51:20.046810
Epoch:[ 25 4 ] loss: 0.5340398550033569 2022-05-29 15:51:20.811084
Epoch:[ 25 5 ] loss: 0.5263460874557495 2022-05-29 15:51:21.574658
Epoch:[ 25 6 ] loss: 0.5238909721374512 2022-05-29 15:51:22.338388
Epoch:[ 25 7 ] loss: 0.5231462717056274 2022-05-29 15:51:23.102765
Epoch:[ 25 8 ] loss: 0.5311115384101868 2022-05-29 15:51:23.869236
Epoch:[ 25 9 ] loss: 0.5261262059211731 2022-05-29 15:51:24.635110
Epoch:[ 25 10 ] loss: 0.5273391604423523 2022-05-29 15:51:25.402329
Epoch:[ 25 11 ] loss: 0.5271132588386536 2022-05-29 15:51:26.167012
Epoch:[ 25 12 ] loss: 0.5263304114341736 2022-05-29 15:51:26.931619
Epoch:[ 25 13 ] loss: 0.52546226978302 2022-05-29 15:51:27.696752
Epoch:[ 25 14 ] loss: 0.5311487317085266 2022-05-29 15:51:28.461542
Epoch:[ 25 15 ] loss: 0.5260404944419861 2022-05-29 15:51:29.226290
Epoch:[ 25 16 ] loss: 0.5259760022163391 2022-05-29 15:51:38.024040
Epoch:[ 25 17 ] loss: 0.5280073881149292 2022-05-29 15:51:38.787644
Epoch:[ 25 18 ] loss: 0.5223369598388672 2022-05-29 15:51:39.558623
Epoch:[ 25 19 ] loss: 0.5374914407730103 2022-05-29 15:51:40.321999
Training_Epoch:[ 25 ] Training_loss: 0.5276843339204789 2022-05-29 15:51:40.322713
learning rate:  0.00128
val: 1 0.5281468629837036
val: 2 0.5321407318115234
val: 3 0.5416907072067261
val: 4 0.5354117155075073
val: 5 0.5360023379325867
val: 6 0.5307455658912659
val: 7 0.5338444113731384
val: 8 0.5379865169525146
val: 9 0.5159563422203064
val: 10 0.5336983799934387
val: 11 0.5247134566307068
val: 12 0.5398370623588562
val: 13 0.5288633108139038
val: 14 0.5512059926986694
val: 15 0.5367623567581177
val: 16 0.5314282774925232
val: 17 0.5367923974990845
val: 18 0.5369707942008972
val: 19 0.5315840840339661
val: 20 0.5367187857627869
val_Epoch:[ 25 ] val_loss: 0.5340250045061111 2022-05-29 15:51:45.987705
start training 2022-05-29 15:51:46.089040
Epoch:[ 26 0 ] loss: 0.5276157855987549 2022-05-29 15:52:11.686193
Epoch:[ 26 1 ] loss: 0.523546040058136 2022-05-29 15:52:12.451694
Epoch:[ 26 2 ] loss: 0.5282682180404663 2022-05-29 15:52:13.219744
Epoch:[ 26 3 ] loss: 0.5227846503257751 2022-05-29 15:52:13.986499
Epoch:[ 26 4 ] loss: 0.5240129828453064 2022-05-29 15:52:14.750558
Epoch:[ 26 5 ] loss: 0.530898928642273 2022-05-29 15:52:15.516850
Epoch:[ 26 6 ] loss: 0.5216031670570374 2022-05-29 15:52:16.283870
Epoch:[ 26 7 ] loss: 0.5261610746383667 2022-05-29 15:52:17.048257
Epoch:[ 26 8 ] loss: 0.5261001586914062 2022-05-29 15:52:17.812656
Epoch:[ 26 9 ] loss: 0.5241339206695557 2022-05-29 15:52:18.580701
Epoch:[ 26 10 ] loss: 0.5273260474205017 2022-05-29 15:52:19.346827
Epoch:[ 26 11 ] loss: 0.5253719687461853 2022-05-29 15:52:20.113249
Epoch:[ 26 12 ] loss: 0.5199176669120789 2022-05-29 15:52:20.880463
Epoch:[ 26 13 ] loss: 0.5260159969329834 2022-05-29 15:52:21.644713
Epoch:[ 26 14 ] loss: 0.5265927314758301 2022-05-29 15:52:22.408948
Epoch:[ 26 15 ] loss: 0.5243660807609558 2022-05-29 15:52:23.170846
Epoch:[ 26 16 ] loss: 0.5256557464599609 2022-05-29 15:52:32.104837
Epoch:[ 26 17 ] loss: 0.5247541666030884 2022-05-29 15:52:33.811624
Epoch:[ 26 18 ] loss: 0.5190591812133789 2022-05-29 15:52:34.579045
Epoch:[ 26 19 ] loss: 0.5304731130599976 2022-05-29 15:52:35.344203
Training_Epoch:[ 26 ] Training_loss: 0.5252328813076019 2022-05-29 15:52:35.344874
learning rate:  0.00128
netparams have been saved once 26
val: 1 0.5363296270370483
val: 2 0.5353941917419434
val: 3 0.5449241995811462
val: 4 0.5664554238319397
val: 5 0.5760065913200378
val: 6 0.5570568442344666
val: 7 0.5657824873924255
val: 8 0.5661872029304504
val: 9 0.5456537008285522
val: 10 0.5484267473220825
val: 11 0.5456075668334961
val: 12 0.5457965135574341
val: 13 0.5495328307151794
val: 14 0.540367841720581
val: 15 0.5516945719718933
val: 16 0.5331639051437378
val: 17 0.5591481328010559
val: 18 0.5533148646354675
val: 19 0.5492566227912903
val: 20 0.5710136294364929
val_Epoch:[ 26 ] val_loss: 0.5520556747913361 2022-05-29 15:52:41.139820
start training 2022-05-29 15:52:41.242157
Epoch:[ 27 0 ] loss: 0.5258453488349915 2022-05-29 15:53:06.140984
Epoch:[ 27 1 ] loss: 0.5309368968009949 2022-05-29 15:53:06.936461
Epoch:[ 27 2 ] loss: 0.521885335445404 2022-05-29 15:53:07.700962
Epoch:[ 27 3 ] loss: 0.5235580205917358 2022-05-29 15:53:08.468798
Epoch:[ 27 4 ] loss: 0.5265991687774658 2022-05-29 15:53:09.234728
Epoch:[ 27 5 ] loss: 0.5186951160430908 2022-05-29 15:53:10.002183
Epoch:[ 27 6 ] loss: 0.5238575339317322 2022-05-29 15:53:10.771050
Epoch:[ 27 7 ] loss: 0.5267694592475891 2022-05-29 15:53:11.536658
Epoch:[ 27 8 ] loss: 0.5298869609832764 2022-05-29 15:53:12.301120
Epoch:[ 27 9 ] loss: 0.5279139876365662 2022-05-29 15:53:13.067649
Epoch:[ 27 10 ] loss: 0.5223010778427124 2022-05-29 15:53:13.834146
Epoch:[ 27 11 ] loss: 0.5205667018890381 2022-05-29 15:53:14.601910
Epoch:[ 27 12 ] loss: 0.5253610014915466 2022-05-29 15:53:15.366644
Epoch:[ 27 13 ] loss: 0.5189116597175598 2022-05-29 15:53:16.133458
Epoch:[ 27 14 ] loss: 0.5289733409881592 2022-05-29 15:53:16.899687
Epoch:[ 27 15 ] loss: 0.5168721079826355 2022-05-29 15:53:17.665391
Epoch:[ 27 16 ] loss: 0.5288227200508118 2022-05-29 15:53:25.322055
Epoch:[ 27 17 ] loss: 0.5187891721725464 2022-05-29 15:53:26.088261
Epoch:[ 27 18 ] loss: 0.5279123187065125 2022-05-29 15:53:29.163798
Epoch:[ 27 19 ] loss: 0.5215424299240112 2022-05-29 15:53:29.933288
Training_Epoch:[ 27 ] Training_loss: 0.524300017952919 2022-05-29 15:53:29.934004
learning rate:  0.00128
val: 1 0.5434567928314209
val: 2 0.5462192296981812
val: 3 0.5363186001777649
val: 4 0.544114887714386
val: 5 0.5360603332519531
val: 6 0.5319672226905823
val: 7 0.5319444537162781
val: 8 0.5445135831832886
val: 9 0.5314798951148987
val: 10 0.5329088568687439
val: 11 0.5513802170753479
val: 12 0.552413284778595
val: 13 0.5536050796508789
val: 14 0.5386579036712646
val: 15 0.5408232808113098
val: 16 0.5227319598197937
val: 17 0.5237716436386108
val: 18 0.5446613430976868
val: 19 0.536912202835083
val: 20 0.5380744338035583
val_Epoch:[ 27 ] val_loss: 0.5391007602214813 2022-05-29 15:53:35.473499
start training 2022-05-29 15:53:35.577378
Epoch:[ 28 0 ] loss: 0.519752562046051 2022-05-29 15:54:01.127359
Epoch:[ 28 1 ] loss: 0.5157610774040222 2022-05-29 15:54:01.892170
Epoch:[ 28 2 ] loss: 0.5213145017623901 2022-05-29 15:54:02.656644
Epoch:[ 28 3 ] loss: 0.5254039764404297 2022-05-29 15:54:03.425741
Epoch:[ 28 4 ] loss: 0.5226242542266846 2022-05-29 15:54:04.191299
Epoch:[ 28 5 ] loss: 0.5208155512809753 2022-05-29 15:54:04.959954
Epoch:[ 28 6 ] loss: 0.5275462865829468 2022-05-29 15:54:05.726672
Epoch:[ 28 7 ] loss: 0.5174068212509155 2022-05-29 15:54:06.497751
Epoch:[ 28 8 ] loss: 0.5230709910392761 2022-05-29 15:54:07.262307
Epoch:[ 28 9 ] loss: 0.524574875831604 2022-05-29 15:54:08.028128
Epoch:[ 28 10 ] loss: 0.5231806635856628 2022-05-29 15:54:08.792353
Epoch:[ 28 11 ] loss: 0.5259657502174377 2022-05-29 15:54:09.557371
Epoch:[ 28 12 ] loss: 0.5213663578033447 2022-05-29 15:54:10.324700
Epoch:[ 28 13 ] loss: 0.5271761417388916 2022-05-29 15:54:11.091259
Epoch:[ 28 14 ] loss: 0.5233021378517151 2022-05-29 15:54:11.856805
Epoch:[ 28 15 ] loss: 0.523741602897644 2022-05-29 15:54:12.621463
Epoch:[ 28 16 ] loss: 0.5214840769767761 2022-05-29 15:54:23.328636
Epoch:[ 28 17 ] loss: 0.517325222492218 2022-05-29 15:54:24.091553
Epoch:[ 28 18 ] loss: 0.5231987237930298 2022-05-29 15:54:24.860656
Epoch:[ 28 19 ] loss: 0.5216652154922485 2022-05-29 15:54:25.626416
Training_Epoch:[ 28 ] Training_loss: 0.5223338395357132 2022-05-29 15:54:25.627120
learning rate:  0.00128
netparams have been saved once 28
val: 1 0.5210472345352173
val: 2 0.5296832323074341
val: 3 0.5381263494491577
val: 4 0.5438951253890991
val: 5 0.548050045967102
val: 6 0.552722692489624
val: 7 0.5259487628936768
val: 8 0.5475106835365295
val: 9 0.5358773469924927
val: 10 0.548981249332428
val: 11 0.5465049147605896
val: 12 0.5447150468826294
val: 13 0.5471010804176331
val: 14 0.5476478934288025
val: 15 0.5371630787849426
val: 16 0.5428915619850159
val: 17 0.5498273372650146
val: 18 0.5383268594741821
val: 19 0.5491768717765808
val: 20 0.5288499593734741
val_Epoch:[ 28 ] val_loss: 0.5412023663520813 2022-05-29 15:54:31.388079
start training 2022-05-29 15:54:31.490270
Epoch:[ 29 0 ] loss: 0.5236080288887024 2022-05-29 15:54:56.974041
Epoch:[ 29 1 ] loss: 0.5175415277481079 2022-05-29 15:54:57.740586
Epoch:[ 29 2 ] loss: 0.5213562250137329 2022-05-29 15:54:58.506508
Epoch:[ 29 3 ] loss: 0.52230304479599 2022-05-29 15:54:59.272992
Epoch:[ 29 4 ] loss: 0.5190728902816772 2022-05-29 15:55:00.035831
Epoch:[ 29 5 ] loss: 0.5260341167449951 2022-05-29 15:55:00.801916
Epoch:[ 29 6 ] loss: 0.518612802028656 2022-05-29 15:55:01.567872
Epoch:[ 29 7 ] loss: 0.5207076668739319 2022-05-29 15:55:02.333000
Epoch:[ 29 8 ] loss: 0.5148446559906006 2022-05-29 15:55:03.100577
Epoch:[ 29 9 ] loss: 0.5188319087028503 2022-05-29 15:55:03.866365
Epoch:[ 29 10 ] loss: 0.5253241062164307 2022-05-29 15:55:04.631091
Epoch:[ 29 11 ] loss: 0.518791675567627 2022-05-29 15:55:05.394772
Epoch:[ 29 12 ] loss: 0.5186905264854431 2022-05-29 15:55:06.160718
Epoch:[ 29 13 ] loss: 0.5203341841697693 2022-05-29 15:55:06.927482
Epoch:[ 29 14 ] loss: 0.5179792046546936 2022-05-29 15:55:07.691172
Epoch:[ 29 15 ] loss: 0.52178955078125 2022-05-29 15:55:08.454757
Epoch:[ 29 16 ] loss: 0.5154224634170532 2022-05-29 15:55:19.003659
Epoch:[ 29 17 ] loss: 0.5222867131233215 2022-05-29 15:55:19.768812
Epoch:[ 29 18 ] loss: 0.5185003280639648 2022-05-29 15:55:20.536126
Epoch:[ 29 19 ] loss: 0.5203937292098999 2022-05-29 15:55:21.301080
Training_Epoch:[ 29 ] Training_loss: 0.5201212674379349 2022-05-29 15:55:21.301737
learning rate:  0.00128
val: 1 0.5321962833404541
val: 2 0.5255495309829712
val: 3 0.5416502356529236
val: 4 0.5185630917549133
val: 5 0.5138930082321167
val: 6 0.5428560376167297
val: 7 0.5389431118965149
val: 8 0.548850953578949
val: 9 0.5259424448013306
val: 10 0.5251370668411255
val: 11 0.5400168895721436
val: 12 0.5253992080688477
val: 13 0.5415836572647095
val: 14 0.5342687964439392
val: 15 0.5233148336410522
val: 16 0.5375921726226807
val: 17 0.5289521813392639
val: 18 0.5187063813209534
val: 19 0.5442243814468384
val: 20 0.5414767265319824
val_Epoch:[ 29 ] val_loss: 0.532455849647522 2022-05-29 15:55:26.910434
start training 2022-05-29 15:55:27.011178
Epoch:[ 30 0 ] loss: 0.5191209316253662 2022-05-29 15:55:52.155300
Epoch:[ 30 1 ] loss: 0.5172685384750366 2022-05-29 15:55:52.923389
Epoch:[ 30 2 ] loss: 0.5209587812423706 2022-05-29 15:55:53.689841
Epoch:[ 30 3 ] loss: 0.5194092988967896 2022-05-29 15:55:54.455779
Epoch:[ 30 4 ] loss: 0.5221929550170898 2022-05-29 15:55:55.222909
Epoch:[ 30 5 ] loss: 0.5198251008987427 2022-05-29 15:55:55.988791
Epoch:[ 30 6 ] loss: 0.5167942047119141 2022-05-29 15:55:56.754817
Epoch:[ 30 7 ] loss: 0.5211904048919678 2022-05-29 15:55:57.521751
Epoch:[ 30 8 ] loss: 0.5204117298126221 2022-05-29 15:55:58.290483
Epoch:[ 30 9 ] loss: 0.5144716501235962 2022-05-29 15:55:59.057677
Epoch:[ 30 10 ] loss: 0.5163389444351196 2022-05-29 15:55:59.823847
Epoch:[ 30 11 ] loss: 0.5218358635902405 2022-05-29 15:56:00.590652
Epoch:[ 30 12 ] loss: 0.5147057175636292 2022-05-29 15:56:01.355854
Epoch:[ 30 13 ] loss: 0.5218135714530945 2022-05-29 15:56:02.121356
Epoch:[ 30 14 ] loss: 0.5213314294815063 2022-05-29 15:56:02.888884
Epoch:[ 30 15 ] loss: 0.5204691886901855 2022-05-29 15:56:03.656124
Epoch:[ 30 16 ] loss: 0.5207905769348145 2022-05-29 15:56:12.014860
Epoch:[ 30 17 ] loss: 0.5158565640449524 2022-05-29 15:56:12.778971
Epoch:[ 30 18 ] loss: 0.5196332931518555 2022-05-29 15:56:15.110915
Epoch:[ 30 19 ] loss: 0.5170165300369263 2022-05-29 15:56:15.874676
Training_Epoch:[ 30 ] Training_loss: 0.519071763753891 2022-05-29 15:56:15.875439
learning rate:  0.00128
netparams have been saved once 30
val: 1 0.5393975973129272
val: 2 0.5423091053962708
val: 3 0.5345765948295593
val: 4 0.5475412011146545
val: 5 0.5244296193122864
val: 6 0.5371798276901245
val: 7 0.5317901372909546
val: 8 0.5592166185379028
val: 9 0.5531030297279358
val: 10 0.5630903840065002
val: 11 0.5460907220840454
val: 12 0.5235134959220886
val: 13 0.5412774085998535
val: 14 0.5459451079368591
val: 15 0.537110447883606
val: 16 0.5260359644889832
val: 17 0.5349403619766235
val: 18 0.5506530404090881
val: 19 0.5440948605537415
val: 20 0.5271499156951904
val_Epoch:[ 30 ] val_loss: 0.5404722720384598 2022-05-29 15:56:21.553290
start training 2022-05-29 15:56:21.652429
Epoch:[ 31 0 ] loss: 0.5156481266021729 2022-05-29 15:56:47.119587
Epoch:[ 31 1 ] loss: 0.5121439695358276 2022-05-29 15:56:47.886380
Epoch:[ 31 2 ] loss: 0.5100576877593994 2022-05-29 15:56:48.653317
Epoch:[ 31 3 ] loss: 0.5165718197822571 2022-05-29 15:56:49.417388
Epoch:[ 31 4 ] loss: 0.5213508009910583 2022-05-29 15:56:50.181906
Epoch:[ 31 5 ] loss: 0.5153518915176392 2022-05-29 15:56:50.946777
Epoch:[ 31 6 ] loss: 0.5162449479103088 2022-05-29 15:56:51.712908
Epoch:[ 31 7 ] loss: 0.5129932761192322 2022-05-29 15:56:52.476500
Epoch:[ 31 8 ] loss: 0.5212032198905945 2022-05-29 15:56:53.242901
Epoch:[ 31 9 ] loss: 0.517245352268219 2022-05-29 15:56:54.009558
Epoch:[ 31 10 ] loss: 0.5137909650802612 2022-05-29 15:56:54.775602
Epoch:[ 31 11 ] loss: 0.516046941280365 2022-05-29 15:56:55.540027
Epoch:[ 31 12 ] loss: 0.520799994468689 2022-05-29 15:56:56.303902
Epoch:[ 31 13 ] loss: 0.5241053104400635 2022-05-29 15:56:57.069753
Epoch:[ 31 14 ] loss: 0.5122032761573792 2022-05-29 15:56:57.835782
Epoch:[ 31 15 ] loss: 0.5188941955566406 2022-05-29 15:56:58.603741
Epoch:[ 31 16 ] loss: 0.517373263835907 2022-05-29 15:57:08.647759
Epoch:[ 31 17 ] loss: 0.5169834494590759 2022-05-29 15:57:09.413279
Epoch:[ 31 18 ] loss: 0.5143834948539734 2022-05-29 15:57:10.194661
Epoch:[ 31 19 ] loss: 0.5121151804924011 2022-05-29 15:57:10.958391
Training_Epoch:[ 31 ] Training_loss: 0.5162753582000732 2022-05-29 15:57:10.959158
learning rate:  0.0010240000000000002
val: 1 0.5217476487159729
val: 2 0.5285658836364746
val: 3 0.5216995477676392
val: 4 0.5249605178833008
val: 5 0.518857479095459
val: 6 0.5280539989471436
val: 7 0.5302800536155701
val: 8 0.5489873290061951
val: 9 0.5242118835449219
val: 10 0.5307139158248901
val: 11 0.5319043397903442
val: 12 0.5214043855667114
val: 13 0.5203445553779602
val: 14 0.5321651697158813
val: 15 0.5229687690734863
val: 16 0.5321844220161438
val: 17 0.5453894734382629
val: 18 0.5245293974876404
val: 19 0.5438570976257324
val: 20 0.5300584435462952
val_Epoch:[ 31 ] val_loss: 0.5291442155838013 2022-05-29 15:57:16.624556
start training 2022-05-29 15:57:16.722409
Epoch:[ 32 0 ] loss: 0.5124858617782593 2022-05-29 15:57:41.152603
Epoch:[ 32 1 ] loss: 0.5115776062011719 2022-05-29 15:57:42.002594
Epoch:[ 32 2 ] loss: 0.5136423707008362 2022-05-29 15:57:42.814772
Epoch:[ 32 3 ] loss: 0.5156735181808472 2022-05-29 15:57:43.577973
Epoch:[ 32 4 ] loss: 0.516629159450531 2022-05-29 15:57:44.344328
Epoch:[ 32 5 ] loss: 0.5178027749061584 2022-05-29 15:57:45.111074
Epoch:[ 32 6 ] loss: 0.5173290371894836 2022-05-29 15:57:45.875375
Epoch:[ 32 7 ] loss: 0.5135261416435242 2022-05-29 15:57:46.642250
Epoch:[ 32 8 ] loss: 0.5103941559791565 2022-05-29 15:57:47.409023
Epoch:[ 32 9 ] loss: 0.5112916231155396 2022-05-29 15:57:48.175786
Epoch:[ 32 10 ] loss: 0.5204882025718689 2022-05-29 15:57:48.941975
Epoch:[ 32 11 ] loss: 0.5161364674568176 2022-05-29 15:57:49.708499
Epoch:[ 32 12 ] loss: 0.507729172706604 2022-05-29 15:57:50.474629
Epoch:[ 32 13 ] loss: 0.5134686231613159 2022-05-29 15:57:51.324078
Epoch:[ 32 14 ] loss: 0.5140197277069092 2022-05-29 15:57:52.093469
Epoch:[ 32 15 ] loss: 0.5135906338691711 2022-05-29 15:57:52.860301
Epoch:[ 32 16 ] loss: 0.5210069417953491 2022-05-29 15:58:00.983554
Epoch:[ 32 17 ] loss: 0.5186038613319397 2022-05-29 15:58:01.855041
Epoch:[ 32 18 ] loss: 0.5115482807159424 2022-05-29 15:58:02.732084
Epoch:[ 32 19 ] loss: 0.5129185914993286 2022-05-29 15:58:03.606089
Training_Epoch:[ 32 ] Training_loss: 0.5144931375980377 2022-05-29 15:58:03.606775
learning rate:  0.0010240000000000002
netparams have been saved once 32
val: 1 0.5269838571548462
val: 2 0.5236763954162598
val: 3 0.5190872550010681
val: 4 0.5367811918258667
val: 5 0.5317059755325317
val: 6 0.5316822528839111
val: 7 0.5298190712928772
val: 8 0.5261268615722656
val: 9 0.5317939519882202
val: 10 0.5420100688934326
val: 11 0.5419718623161316
val: 12 0.5283694863319397
val: 13 0.5149292349815369
val: 14 0.522882878780365
val: 15 0.507265031337738
val: 16 0.5241190195083618
val: 17 0.531801164150238
val: 18 0.5283203125
val: 19 0.5189937949180603
val: 20 0.5238536596298218
val_Epoch:[ 32 ] val_loss: 0.5271086663007736 2022-05-29 15:58:09.206580
start training 2022-05-29 15:58:09.305639
Epoch:[ 33 0 ] loss: 0.5115283131599426 2022-05-29 15:58:33.778357
Epoch:[ 33 1 ] loss: 0.5165084004402161 2022-05-29 15:58:34.543353
Epoch:[ 33 2 ] loss: 0.5130417346954346 2022-05-29 15:58:35.308593
Epoch:[ 33 3 ] loss: 0.517880916595459 2022-05-29 15:58:36.073279
Epoch:[ 33 4 ] loss: 0.5075214505195618 2022-05-29 15:58:36.839050
Epoch:[ 33 5 ] loss: 0.5109505653381348 2022-05-29 15:58:37.602096
Epoch:[ 33 6 ] loss: 0.5094127058982849 2022-05-29 15:58:38.365987
Epoch:[ 33 7 ] loss: 0.5139834880828857 2022-05-29 15:58:39.129150
Epoch:[ 33 8 ] loss: 0.5138850808143616 2022-05-29 15:58:39.893327
Epoch:[ 33 9 ] loss: 0.5148233771324158 2022-05-29 15:58:40.657647
Epoch:[ 33 10 ] loss: 0.51051265001297 2022-05-29 15:58:41.423539
Epoch:[ 33 11 ] loss: 0.5131361484527588 2022-05-29 15:58:42.188558
Epoch:[ 33 12 ] loss: 0.510446310043335 2022-05-29 15:58:42.954300
Epoch:[ 33 13 ] loss: 0.5173249840736389 2022-05-29 15:58:43.719094
Epoch:[ 33 14 ] loss: 0.5136598348617554 2022-05-29 15:58:44.481939
Epoch:[ 33 15 ] loss: 0.5170039534568787 2022-05-29 15:58:45.245292
Epoch:[ 33 16 ] loss: 0.5146321654319763 2022-05-29 15:58:52.594977
Epoch:[ 33 17 ] loss: 0.5070986747741699 2022-05-29 15:58:53.359580
Epoch:[ 33 18 ] loss: 0.5103680491447449 2022-05-29 15:58:54.129789
Epoch:[ 33 19 ] loss: 0.5073662996292114 2022-05-29 15:58:54.902477
Training_Epoch:[ 33 ] Training_loss: 0.5125542551279068 2022-05-29 15:58:54.903238
learning rate:  0.0010240000000000002
val: 1 0.5396406650543213
val: 2 0.5466773509979248
val: 3 0.551596999168396
val: 4 0.5363545417785645
val: 5 0.5316656827926636
val: 6 0.5175020098686218
val: 7 0.5253061652183533
val: 8 0.5420422554016113
val: 9 0.5269247889518738
val: 10 0.5460411310195923
val: 11 0.5284960269927979
val: 12 0.5359710454940796
val: 13 0.5227464437484741
val: 14 0.5165975689888
val: 15 0.5312497615814209
val: 16 0.5352082848548889
val: 17 0.5246019959449768
val: 18 0.5364852547645569
val: 19 0.5366958975791931
val: 20 0.5291289687156677
val_Epoch:[ 33 ] val_loss: 0.533046641945839 2022-05-29 15:59:00.546033
start training 2022-05-29 15:59:00.642830
Epoch:[ 34 0 ] loss: 0.5067788362503052 2022-05-29 15:59:23.980167
Epoch:[ 34 1 ] loss: 0.5102019906044006 2022-05-29 15:59:24.745493
Epoch:[ 34 2 ] loss: 0.5105717182159424 2022-05-29 15:59:25.509927
Epoch:[ 34 3 ] loss: 0.5113630890846252 2022-05-29 15:59:26.274467
Epoch:[ 34 4 ] loss: 0.5147140622138977 2022-05-29 15:59:27.041558
Epoch:[ 34 5 ] loss: 0.5120320320129395 2022-05-29 15:59:27.805713
Epoch:[ 34 6 ] loss: 0.5135015845298767 2022-05-29 15:59:28.568837
Epoch:[ 34 7 ] loss: 0.5105237364768982 2022-05-29 15:59:29.333173
Epoch:[ 34 8 ] loss: 0.5085272789001465 2022-05-29 15:59:30.096295
Epoch:[ 34 9 ] loss: 0.5107086896896362 2022-05-29 15:59:30.863630
Epoch:[ 34 10 ] loss: 0.5171535611152649 2022-05-29 15:59:31.627544
Epoch:[ 34 11 ] loss: 0.5079799294471741 2022-05-29 15:59:32.395046
Epoch:[ 34 12 ] loss: 0.5093729496002197 2022-05-29 15:59:33.159594
Epoch:[ 34 13 ] loss: 0.5118188261985779 2022-05-29 15:59:33.926862
Epoch:[ 34 14 ] loss: 0.5106717944145203 2022-05-29 15:59:34.692475
Epoch:[ 34 15 ] loss: 0.5067225694656372 2022-05-29 15:59:35.456187
Epoch:[ 34 16 ] loss: 0.5093915462493896 2022-05-29 15:59:42.996832
Epoch:[ 34 17 ] loss: 0.5121568441390991 2022-05-29 15:59:43.761746
Epoch:[ 34 18 ] loss: 0.5132837295532227 2022-05-29 15:59:44.531168
Epoch:[ 34 19 ] loss: 0.5219815969467163 2022-05-29 15:59:45.296238
Training_Epoch:[ 34 ] Training_loss: 0.5114728182554245 2022-05-29 15:59:45.296967
learning rate:  0.0010240000000000002
netparams have been saved once 34
val: 1 0.6147520542144775
val: 2 0.6123424172401428
val: 3 0.6137472987174988
val: 4 0.5983491539955139
val: 5 0.5978536009788513
val: 6 0.6145963668823242
val: 7 0.5972416400909424
val: 8 0.6046598553657532
val: 9 0.5966116786003113
val: 10 0.6223857402801514
val: 11 0.6080240607261658
val: 12 0.6047669649124146
val: 13 0.6090186238288879
val: 14 0.6108449697494507
val: 15 0.5941569805145264
val: 16 0.5976420044898987
val: 17 0.6107088327407837
val: 18 0.6130385994911194
val: 19 0.6089485287666321
val: 20 0.6061121821403503
val_Epoch:[ 34 ] val_loss: 0.6067900776863098 2022-05-29 15:59:50.906923
start training 2022-05-29 15:59:51.007351
Epoch:[ 35 0 ] loss: 0.5195406675338745 2022-05-29 16:00:14.658715
Epoch:[ 35 1 ] loss: 0.5098462700843811 2022-05-29 16:00:15.422073
Epoch:[ 35 2 ] loss: 0.5096326470375061 2022-05-29 16:00:16.185945
Epoch:[ 35 3 ] loss: 0.5150331854820251 2022-05-29 16:00:16.947814
Epoch:[ 35 4 ] loss: 0.5112068057060242 2022-05-29 16:00:17.712132
Epoch:[ 35 5 ] loss: 0.5122542977333069 2022-05-29 16:00:18.477197
Epoch:[ 35 6 ] loss: 0.5195136070251465 2022-05-29 16:00:19.240725
Epoch:[ 35 7 ] loss: 0.5156108140945435 2022-05-29 16:00:20.006238
Epoch:[ 35 8 ] loss: 0.5124596357345581 2022-05-29 16:00:20.769235
Epoch:[ 35 9 ] loss: 0.5071080327033997 2022-05-29 16:00:21.534107
Epoch:[ 35 10 ] loss: 0.5136393904685974 2022-05-29 16:00:22.296602
Epoch:[ 35 11 ] loss: 0.51125168800354 2022-05-29 16:00:23.061461
Epoch:[ 35 12 ] loss: 0.5139939188957214 2022-05-29 16:00:23.828151
Epoch:[ 35 13 ] loss: 0.515202522277832 2022-05-29 16:00:24.592253
Epoch:[ 35 14 ] loss: 0.513748824596405 2022-05-29 16:00:25.354830
Epoch:[ 35 15 ] loss: 0.5108442902565002 2022-05-29 16:00:26.117479
Epoch:[ 35 16 ] loss: 0.5108222365379333 2022-05-29 16:00:34.101980
Epoch:[ 35 17 ] loss: 0.5141162872314453 2022-05-29 16:00:34.866001
Epoch:[ 35 18 ] loss: 0.5092647671699524 2022-05-29 16:00:35.637242
Epoch:[ 35 19 ] loss: 0.5164785981178284 2022-05-29 16:00:36.403659
Training_Epoch:[ 35 ] Training_loss: 0.5130784243345261 2022-05-29 16:00:36.404394
learning rate:  0.0010240000000000002
val: 1 0.5245429277420044
val: 2 0.5182926058769226
val: 3 0.5178229808807373
val: 4 0.535895049571991
val: 5 0.511807918548584
val: 6 0.5426993370056152
val: 7 0.5377517938613892
val: 8 0.5254630446434021
val: 9 0.5201783180236816
val: 10 0.5218686461448669
val: 11 0.5275161862373352
val: 12 0.5273065567016602
val: 13 0.5298959016799927
val: 14 0.5430940985679626
val: 15 0.5378525257110596
val: 16 0.5343788862228394
val: 17 0.5119374394416809
val: 18 0.5237348675727844
val: 19 0.4991040527820587
val: 20 0.521333634853363
val_Epoch:[ 35 ] val_loss: 0.5256238386034966 2022-05-29 16:00:42.016114
start training 2022-05-29 16:00:42.119647
Epoch:[ 36 0 ] loss: 0.5005778670310974 2022-05-29 16:01:05.485465
Epoch:[ 36 1 ] loss: 0.5100528001785278 2022-05-29 16:01:06.303684
Epoch:[ 36 2 ] loss: 0.5111563801765442 2022-05-29 16:01:07.068341
Epoch:[ 36 3 ] loss: 0.5092611312866211 2022-05-29 16:01:07.834633
Epoch:[ 36 4 ] loss: 0.5035327672958374 2022-05-29 16:01:08.600011
Epoch:[ 36 5 ] loss: 0.5133801698684692 2022-05-29 16:01:09.366700
Epoch:[ 36 6 ] loss: 0.5099496841430664 2022-05-29 16:01:10.134063
Epoch:[ 36 7 ] loss: 0.5138717293739319 2022-05-29 16:01:10.897564
Epoch:[ 36 8 ] loss: 0.5176806449890137 2022-05-29 16:01:11.664758
Epoch:[ 36 9 ] loss: 0.5127701163291931 2022-05-29 16:01:12.431486
Epoch:[ 36 10 ] loss: 0.5151732563972473 2022-05-29 16:01:13.196108
Epoch:[ 36 11 ] loss: 0.5106831789016724 2022-05-29 16:01:13.960814
Epoch:[ 36 12 ] loss: 0.5135195255279541 2022-05-29 16:01:14.726061
Epoch:[ 36 13 ] loss: 0.5134540796279907 2022-05-29 16:01:15.492267
Epoch:[ 36 14 ] loss: 0.5150672197341919 2022-05-29 16:01:16.258606
Epoch:[ 36 15 ] loss: 0.5093739628791809 2022-05-29 16:01:17.025454
Epoch:[ 36 16 ] loss: 0.5123950839042664 2022-05-29 16:01:24.618178
Epoch:[ 36 17 ] loss: 0.5140793919563293 2022-05-29 16:01:25.383064
Epoch:[ 36 18 ] loss: 0.5154854655265808 2022-05-29 16:01:26.151616
Epoch:[ 36 19 ] loss: 0.5106268525123596 2022-05-29 16:01:26.916551
Training_Epoch:[ 36 ] Training_loss: 0.5116045653820038 2022-05-29 16:01:26.917299
learning rate:  0.0010240000000000002
netparams have been saved once 36
val: 1 0.5387895703315735
val: 2 0.527557373046875
val: 3 0.5372027158737183
val: 4 0.5268272757530212
val: 5 0.543364405632019
val: 6 0.5233702659606934
val: 7 0.5360910892486572
val: 8 0.5222816467285156
val: 9 0.5381090641021729
val: 10 0.5266695618629456
val: 11 0.5337135791778564
val: 12 0.5418614149093628
val: 13 0.534783124923706
val: 14 0.5440582633018494
val: 15 0.5342252850532532
val: 16 0.5452063679695129
val: 17 0.5375863313674927
val: 18 0.5407750010490417
val: 19 0.5476552844047546
val: 20 0.5265005826950073
val_Epoch:[ 36 ] val_loss: 0.5353314101696014 2022-05-29 16:01:32.641925
start training 2022-05-29 16:01:32.744989
Epoch:[ 37 0 ] loss: 0.5155527591705322 2022-05-29 16:01:55.931571
Epoch:[ 37 1 ] loss: 0.5080956816673279 2022-05-29 16:01:56.697725
Epoch:[ 37 2 ] loss: 0.5119451284408569 2022-05-29 16:01:57.463162
Epoch:[ 37 3 ] loss: 0.5118747353553772 2022-05-29 16:01:58.226943
Epoch:[ 37 4 ] loss: 0.5066933035850525 2022-05-29 16:01:58.990644
Epoch:[ 37 5 ] loss: 0.5127564668655396 2022-05-29 16:01:59.752822
Epoch:[ 37 6 ] loss: 0.5100447535514832 2022-05-29 16:02:00.517186
Epoch:[ 37 7 ] loss: 0.5166690349578857 2022-05-29 16:02:01.282993
Epoch:[ 37 8 ] loss: 0.515465497970581 2022-05-29 16:02:02.046161
Epoch:[ 37 9 ] loss: 0.5071309208869934 2022-05-29 16:02:02.810025
Epoch:[ 37 10 ] loss: 0.510516345500946 2022-05-29 16:02:03.573710
Epoch:[ 37 11 ] loss: 0.5083430409431458 2022-05-29 16:02:04.339107
Epoch:[ 37 12 ] loss: 0.5077610611915588 2022-05-29 16:02:05.102576
Epoch:[ 37 13 ] loss: 0.5061140060424805 2022-05-29 16:02:05.869350
Epoch:[ 37 14 ] loss: 0.5117693543434143 2022-05-29 16:02:06.635518
Epoch:[ 37 15 ] loss: 0.5072693228721619 2022-05-29 16:02:07.401399
Epoch:[ 37 16 ] loss: 0.509618878364563 2022-05-29 16:02:14.931836
Epoch:[ 37 17 ] loss: 0.5113465785980225 2022-05-29 16:02:15.695022
Epoch:[ 37 18 ] loss: 0.509861409664154 2022-05-29 16:02:16.462563
Epoch:[ 37 19 ] loss: 0.5120638608932495 2022-05-29 16:02:17.226616
Training_Epoch:[ 37 ] Training_loss: 0.5105446070432663 2022-05-29 16:02:17.227318
learning rate:  0.0010240000000000002
val: 1 0.5279263257980347
val: 2 0.5191524028778076
val: 3 0.5318689346313477
val: 4 0.5089192390441895
val: 5 0.5055922865867615
val: 6 0.5419971942901611
val: 7 0.5206822156906128
val: 8 0.5119783878326416
val: 9 0.5449446439743042
val: 10 0.5348824262619019
val: 11 0.5231801867485046
val: 12 0.537552535533905
val: 13 0.5341165065765381
val: 14 0.5233288407325745
val: 15 0.5274204611778259
val: 16 0.515967607498169
val: 17 0.5246553421020508
val: 18 0.5372147560119629
val: 19 0.5223436951637268
val: 20 0.5364518761634827
val_Epoch:[ 37 ] val_loss: 0.5265087932348251 2022-05-29 16:02:22.765729
start training 2022-05-29 16:02:22.865159
Epoch:[ 38 0 ] loss: 0.5084294080734253 2022-05-29 16:02:45.817503
Epoch:[ 38 1 ] loss: 0.5053236484527588 2022-05-29 16:02:47.136188
Epoch:[ 38 2 ] loss: 0.5032917261123657 2022-05-29 16:02:47.904151
Epoch:[ 38 3 ] loss: 0.505516529083252 2022-05-29 16:02:48.670709
Epoch:[ 38 4 ] loss: 0.5074673295021057 2022-05-29 16:02:49.434645
Epoch:[ 38 5 ] loss: 0.5047335624694824 2022-05-29 16:02:50.258650
Epoch:[ 38 6 ] loss: 0.5031347870826721 2022-05-29 16:02:51.134670
Epoch:[ 38 7 ] loss: 0.5082448124885559 2022-05-29 16:02:52.008500
Epoch:[ 38 8 ] loss: 0.5031907558441162 2022-05-29 16:02:52.848469
Epoch:[ 38 9 ] loss: 0.510534942150116 2022-05-29 16:02:53.723526
Epoch:[ 38 10 ] loss: 0.5008765459060669 2022-05-29 16:02:54.600427
Epoch:[ 38 11 ] loss: 0.5020712018013 2022-05-29 16:02:55.475362
Epoch:[ 38 12 ] loss: 0.5069974064826965 2022-05-29 16:02:56.351472
Epoch:[ 38 13 ] loss: 0.505669355392456 2022-05-29 16:02:57.118538
Epoch:[ 38 14 ] loss: 0.5045285224914551 2022-05-29 16:02:57.886389
Epoch:[ 38 15 ] loss: 0.5139322876930237 2022-05-29 16:02:58.653918
Epoch:[ 38 16 ] loss: 0.5065618753433228 2022-05-29 16:03:05.490629
Epoch:[ 38 17 ] loss: 0.5079194903373718 2022-05-29 16:03:06.878530
Epoch:[ 38 18 ] loss: 0.5076315999031067 2022-05-29 16:03:07.664673
Epoch:[ 38 19 ] loss: 0.505311906337738 2022-05-29 16:03:08.433890
Training_Epoch:[ 38 ] Training_loss: 0.5060683846473694 2022-05-29 16:03:08.434683
learning rate:  0.0010240000000000002
netparams have been saved once 38
val: 1 0.5517369508743286
val: 2 0.5653602480888367
val: 3 0.5255177021026611
val: 4 0.5515671372413635
val: 5 0.5394701957702637
val: 6 0.5415559411048889
val: 7 0.534429669380188
val: 8 0.5366880893707275
val: 9 0.5356194376945496
val: 10 0.5424032807350159
val: 11 0.5384547710418701
val: 12 0.5240868926048279
val: 13 0.5192356109619141
val: 14 0.5677642822265625
val: 15 0.548373281955719
val: 16 0.5321746468544006
val: 17 0.5611757040023804
val: 18 0.5359908938407898
val: 19 0.5408653020858765
val: 20 0.5401694774627686
val_Epoch:[ 38 ] val_loss: 0.5416319757699967 2022-05-29 16:03:14.719779
start training 2022-05-29 16:03:14.847664
Epoch:[ 39 0 ] loss: 0.5059872269630432 2022-05-29 16:03:42.573165
Epoch:[ 39 1 ] loss: 0.5023777484893799 2022-05-29 16:03:43.341120
Epoch:[ 39 2 ] loss: 0.5078108310699463 2022-05-29 16:03:44.107823
Epoch:[ 39 3 ] loss: 0.5005326867103577 2022-05-29 16:03:44.875383
Epoch:[ 39 4 ] loss: 0.5065715909004211 2022-05-29 16:03:45.643138
Epoch:[ 39 5 ] loss: 0.5026547312736511 2022-05-29 16:03:46.411805
Epoch:[ 39 6 ] loss: 0.5092072486877441 2022-05-29 16:03:47.178442
Epoch:[ 39 7 ] loss: 0.5030776262283325 2022-05-29 16:03:47.943407
Epoch:[ 39 8 ] loss: 0.5071958899497986 2022-05-29 16:03:48.712371
Epoch:[ 39 9 ] loss: 0.5056810975074768 2022-05-29 16:03:49.481451
Epoch:[ 39 10 ] loss: 0.5057401061058044 2022-05-29 16:03:50.248981
Epoch:[ 39 11 ] loss: 0.5079339146614075 2022-05-29 16:03:51.017253
Epoch:[ 39 12 ] loss: 0.5042043328285217 2022-05-29 16:03:51.783231
Epoch:[ 39 13 ] loss: 0.5089653730392456 2022-05-29 16:03:52.553313
Epoch:[ 39 14 ] loss: 0.5054358243942261 2022-05-29 16:03:53.322148
Epoch:[ 39 15 ] loss: 0.5061374306678772 2022-05-29 16:03:54.089620
Epoch:[ 39 16 ] loss: 0.5033574104309082 2022-05-29 16:04:03.400797
Epoch:[ 39 17 ] loss: 0.504929780960083 2022-05-29 16:04:04.167789
Epoch:[ 39 18 ] loss: 0.5053374171257019 2022-05-29 16:04:04.953832
Epoch:[ 39 19 ] loss: 0.5101315975189209 2022-05-29 16:04:05.719504
Training_Epoch:[ 39 ] Training_loss: 0.5056634932756424 2022-05-29 16:04:05.720171
learning rate:  0.0010240000000000002
val: 1 0.5267159938812256
val: 2 0.5240203142166138
val: 3 0.5404273867607117
val: 4 0.5277442932128906
val: 5 0.5123946666717529
val: 6 0.523537814617157
val: 7 0.530204176902771
val: 8 0.5174114108085632
val: 9 0.5412497520446777
val: 10 0.5331870317459106
val: 11 0.5101963877677917
val: 12 0.5362460613250732
val: 13 0.5201227068901062
val: 14 0.5122588872909546
val: 15 0.5344192981719971
val: 16 0.5144571661949158
val: 17 0.5420711040496826
val: 18 0.5355829000473022
val: 19 0.5177966952323914
val: 20 0.525112509727478
val_Epoch:[ 39 ] val_loss: 0.5262578278779984 2022-05-29 16:04:11.272596
start training 2022-05-29 16:04:11.376668
Epoch:[ 40 0 ] loss: 0.5066825747489929 2022-05-29 16:04:37.566010
Epoch:[ 40 1 ] loss: 0.5033841729164124 2022-05-29 16:04:38.331076
Epoch:[ 40 2 ] loss: 0.5023525357246399 2022-05-29 16:04:39.097186
Epoch:[ 40 3 ] loss: 0.5076090693473816 2022-05-29 16:04:39.866176
Epoch:[ 40 4 ] loss: 0.5040004849433899 2022-05-29 16:04:40.632561
Epoch:[ 40 5 ] loss: 0.5024248957633972 2022-05-29 16:04:41.400050
Epoch:[ 40 6 ] loss: 0.507401704788208 2022-05-29 16:04:42.167295
Epoch:[ 40 7 ] loss: 0.5070430636405945 2022-05-29 16:04:42.932001
Epoch:[ 40 8 ] loss: 0.5100335478782654 2022-05-29 16:04:43.696548
Epoch:[ 40 9 ] loss: 0.4987426698207855 2022-05-29 16:04:44.463420
Epoch:[ 40 10 ] loss: 0.5070801377296448 2022-05-29 16:04:45.231048
Epoch:[ 40 11 ] loss: 0.5100277662277222 2022-05-29 16:04:45.998684
Epoch:[ 40 12 ] loss: 0.5049387812614441 2022-05-29 16:04:46.765221
Epoch:[ 40 13 ] loss: 0.5050561428070068 2022-05-29 16:04:47.530579
Epoch:[ 40 14 ] loss: 0.5058304071426392 2022-05-29 16:04:48.295538
Epoch:[ 40 15 ] loss: 0.5081539154052734 2022-05-29 16:04:49.058611
Epoch:[ 40 16 ] loss: 0.5056576728820801 2022-05-29 16:04:59.778823
Epoch:[ 40 17 ] loss: 0.5046463012695312 2022-05-29 16:05:00.549639
Epoch:[ 40 18 ] loss: 0.508536696434021 2022-05-29 16:05:01.441274
Epoch:[ 40 19 ] loss: 0.5056759715080261 2022-05-29 16:05:02.315529
Training_Epoch:[ 40 ] Training_loss: 0.5057639256119728 2022-05-29 16:05:02.316232
learning rate:  0.0010240000000000002
netparams have been saved once 40
val: 1 0.5178878903388977
val: 2 0.5382217764854431
val: 3 0.5376309752464294
val: 4 0.5176409482955933
val: 5 0.5295147895812988
val: 6 0.5316212177276611
val: 7 0.5419186353683472
val: 8 0.5324338674545288
val: 9 0.5599446296691895
val: 10 0.5304322838783264
val: 11 0.5341292023658752
val: 12 0.5420371890068054
val: 13 0.5296586751937866
val: 14 0.5353962182998657
val: 15 0.5105438828468323
val: 16 0.5356387495994568
val: 17 0.5328862071037292
val: 18 0.5340998768806458
val: 19 0.5386806726455688
val: 20 0.5218988060951233
val_Epoch:[ 40 ] val_loss: 0.5326108247041702 2022-05-29 16:05:08.173134
start training 2022-05-29 16:05:08.280945
Epoch:[ 41 0 ] loss: 0.5060974955558777 2022-05-29 16:05:33.229130
Epoch:[ 41 1 ] loss: 0.5049002170562744 2022-05-29 16:05:34.010462
Epoch:[ 41 2 ] loss: 0.5070043206214905 2022-05-29 16:05:34.774320
Epoch:[ 41 3 ] loss: 0.500029981136322 2022-05-29 16:05:35.539690
Epoch:[ 41 4 ] loss: 0.4977453052997589 2022-05-29 16:05:36.307891
Epoch:[ 41 5 ] loss: 0.49923545122146606 2022-05-29 16:05:37.073050
Epoch:[ 41 6 ] loss: 0.5079861283302307 2022-05-29 16:05:37.840166
Epoch:[ 41 7 ] loss: 0.505927562713623 2022-05-29 16:05:38.603322
Epoch:[ 41 8 ] loss: 0.49674558639526367 2022-05-29 16:05:39.367301
Epoch:[ 41 9 ] loss: 0.49719980359077454 2022-05-29 16:05:40.132839
Epoch:[ 41 10 ] loss: 0.5017341375350952 2022-05-29 16:05:40.900029
Epoch:[ 41 11 ] loss: 0.5009562373161316 2022-05-29 16:05:41.667596
Epoch:[ 41 12 ] loss: 0.4998045563697815 2022-05-29 16:05:42.435764
Epoch:[ 41 13 ] loss: 0.49923694133758545 2022-05-29 16:05:43.203278
Epoch:[ 41 14 ] loss: 0.5014761686325073 2022-05-29 16:05:43.982589
Epoch:[ 41 15 ] loss: 0.49891799688339233 2022-05-29 16:05:44.746025
Epoch:[ 41 16 ] loss: 0.49981123208999634 2022-05-29 16:05:52.558128
Epoch:[ 41 17 ] loss: 0.5070077776908875 2022-05-29 16:05:57.182458
Epoch:[ 41 18 ] loss: 0.4985574185848236 2022-05-29 16:05:57.961312
Epoch:[ 41 19 ] loss: 0.5020668506622314 2022-05-29 16:05:58.727551
Training_Epoch:[ 41 ] Training_loss: 0.5016220584511757 2022-05-29 16:05:58.728303
learning rate:  0.0008192000000000002
val: 1 0.5296700596809387
val: 2 0.536107063293457
val: 3 0.5244273543357849
val: 4 0.5249423980712891
val: 5 0.5130038261413574
val: 6 0.5318211317062378
val: 7 0.5306631922721863
val: 8 0.5285346508026123
val: 9 0.5010523796081543
val: 10 0.5341945290565491
val: 11 0.5334346890449524
val: 12 0.526294469833374
val: 13 0.535568356513977
val: 14 0.5240245461463928
val: 15 0.5463067293167114
val: 16 0.5367569327354431
val: 17 0.5436388850212097
val: 18 0.5239622592926025
val: 19 0.5295771360397339
val: 20 0.5389717817306519
val_Epoch:[ 41 ] val_loss: 0.5296476185321808 2022-05-29 16:06:04.269411
start training 2022-05-29 16:06:04.379866
Epoch:[ 42 0 ] loss: 0.4999185800552368 2022-05-29 16:06:30.107764
Epoch:[ 42 1 ] loss: 0.4958493709564209 2022-05-29 16:06:30.879090
Epoch:[ 42 2 ] loss: 0.5006541609764099 2022-05-29 16:06:31.646780
Epoch:[ 42 3 ] loss: 0.5008965134620667 2022-05-29 16:06:32.412913
Epoch:[ 42 4 ] loss: 0.4914509654045105 2022-05-29 16:06:33.181264
Epoch:[ 42 5 ] loss: 0.5029634237289429 2022-05-29 16:06:33.948910
Epoch:[ 42 6 ] loss: 0.4985513985157013 2022-05-29 16:06:34.714444
Epoch:[ 42 7 ] loss: 0.4987459182739258 2022-05-29 16:06:35.482038
Epoch:[ 42 8 ] loss: 0.4998849332332611 2022-05-29 16:06:36.252642
Epoch:[ 42 9 ] loss: 0.5002909898757935 2022-05-29 16:06:37.022453
Epoch:[ 42 10 ] loss: 0.49842074513435364 2022-05-29 16:06:37.791276
Epoch:[ 42 11 ] loss: 0.4985763430595398 2022-05-29 16:06:38.561236
Epoch:[ 42 12 ] loss: 0.49698951840400696 2022-05-29 16:06:39.331837
Epoch:[ 42 13 ] loss: 0.4982677400112152 2022-05-29 16:06:40.103653
Epoch:[ 42 14 ] loss: 0.49832215905189514 2022-05-29 16:06:40.876320
Epoch:[ 42 15 ] loss: 0.4973500370979309 2022-05-29 16:06:41.645731
Epoch:[ 42 16 ] loss: 0.49880772829055786 2022-05-29 16:06:51.703298
Epoch:[ 42 17 ] loss: 0.5010215044021606 2022-05-29 16:06:52.468635
Epoch:[ 42 18 ] loss: 0.4986133873462677 2022-05-29 16:06:53.242129
Epoch:[ 42 19 ] loss: 0.503272533416748 2022-05-29 16:06:54.010735
Training_Epoch:[ 42 ] Training_loss: 0.49894239753484726 2022-05-29 16:06:54.011633
learning rate:  0.0008192000000000002
netparams have been saved once 42
val: 1 0.523224949836731
val: 2 0.534340500831604
val: 3 0.5261273384094238
val: 4 0.5379089117050171
val: 5 0.5164026021957397
val: 6 0.5382866859436035
val: 7 0.5320797562599182
val: 8 0.5148717164993286
val: 9 0.5232410430908203
val: 10 0.5216576457023621
val: 11 0.5395122170448303
val: 12 0.5211809277534485
val: 13 0.5169472098350525
val: 14 0.5396714210510254
val: 15 0.5229904651641846
val: 16 0.5231671929359436
val: 17 0.5311740636825562
val: 18 0.5227891802787781
val: 19 0.5149319767951965
val: 20 0.5271263718605042
val_Epoch:[ 42 ] val_loss: 0.5263816088438034 2022-05-29 16:06:59.952264
start training 2022-05-29 16:07:00.052910
Epoch:[ 43 0 ] loss: 0.4984423816204071 2022-05-29 16:07:26.290375
Epoch:[ 43 1 ] loss: 0.4982337951660156 2022-05-29 16:07:27.058375
Epoch:[ 43 2 ] loss: 0.505380392074585 2022-05-29 16:07:27.825568
Epoch:[ 43 3 ] loss: 0.4920305907726288 2022-05-29 16:07:28.590730
Epoch:[ 43 4 ] loss: 0.49854108691215515 2022-05-29 16:07:29.355271
Epoch:[ 43 5 ] loss: 0.4955235421657562 2022-05-29 16:07:30.123024
Epoch:[ 43 6 ] loss: 0.5016568303108215 2022-05-29 16:07:30.889996
Epoch:[ 43 7 ] loss: 0.49443942308425903 2022-05-29 16:07:31.655912
Epoch:[ 43 8 ] loss: 0.4874284565448761 2022-05-29 16:07:32.423344
Epoch:[ 43 9 ] loss: 0.4943452477455139 2022-05-29 16:07:33.191809
Epoch:[ 43 10 ] loss: 0.5042611360549927 2022-05-29 16:07:33.957276
Epoch:[ 43 11 ] loss: 0.5031112432479858 2022-05-29 16:07:34.719967
Epoch:[ 43 12 ] loss: 0.49591735005378723 2022-05-29 16:07:35.488040
Epoch:[ 43 13 ] loss: 0.49915191531181335 2022-05-29 16:07:36.254149
Epoch:[ 43 14 ] loss: 0.500097930431366 2022-05-29 16:07:37.023626
Epoch:[ 43 15 ] loss: 0.49793416261672974 2022-05-29 16:07:37.792366
Epoch:[ 43 16 ] loss: 0.4977167546749115 2022-05-29 16:07:48.281656
Epoch:[ 43 17 ] loss: 0.49743643403053284 2022-05-29 16:07:49.046879
Epoch:[ 43 18 ] loss: 0.5027834177017212 2022-05-29 16:07:49.813597
Epoch:[ 43 19 ] loss: 0.4921519458293915 2022-05-29 16:07:50.580248
Training_Epoch:[ 43 ] Training_loss: 0.4978292018175125 2022-05-29 16:07:50.581137
learning rate:  0.0008192000000000002
val: 1 0.5255047678947449
val: 2 0.5147766470909119
val: 3 0.5122702121734619
val: 4 0.5436394810676575
val: 5 0.5155594944953918
val: 6 0.526109516620636
val: 7 0.5081490278244019
val: 8 0.5253971815109253
val: 9 0.5367122888565063
val: 10 0.5128553509712219
val: 11 0.5182700157165527
val: 12 0.5407888293266296
val: 13 0.5255019664764404
val: 14 0.533940315246582
val: 15 0.5249204635620117
val: 16 0.5021116733551025
val: 17 0.495964378118515
val: 18 0.5094212889671326
val: 19 0.5159692764282227
val: 20 0.5218402147293091
val_Epoch:[ 43 ] val_loss: 0.5204851195216179 2022-05-29 16:07:56.153376
start training 2022-05-29 16:07:56.257518
Epoch:[ 44 0 ] loss: 0.4980328679084778 2022-05-29 16:08:21.303961
Epoch:[ 44 1 ] loss: 0.49868127703666687 2022-05-29 16:08:22.091583
Epoch:[ 44 2 ] loss: 0.4966622591018677 2022-05-29 16:08:22.858676
Epoch:[ 44 3 ] loss: 0.4932296872138977 2022-05-29 16:08:23.623386
Epoch:[ 44 4 ] loss: 0.5007781982421875 2022-05-29 16:08:24.388001
Epoch:[ 44 5 ] loss: 0.49045222997665405 2022-05-29 16:08:25.153122
Epoch:[ 44 6 ] loss: 0.49624955654144287 2022-05-29 16:08:25.919318
Epoch:[ 44 7 ] loss: 0.4954290986061096 2022-05-29 16:08:26.686363
Epoch:[ 44 8 ] loss: 0.49543702602386475 2022-05-29 16:08:27.449121
Epoch:[ 44 9 ] loss: 0.49624666571617126 2022-05-29 16:08:28.213819
Epoch:[ 44 10 ] loss: 0.4953691363334656 2022-05-29 16:08:28.979311
Epoch:[ 44 11 ] loss: 0.4953455328941345 2022-05-29 16:08:29.745111
Epoch:[ 44 12 ] loss: 0.5009225606918335 2022-05-29 16:08:30.511539
Epoch:[ 44 13 ] loss: 0.49451151490211487 2022-05-29 16:08:31.279009
Epoch:[ 44 14 ] loss: 0.49187833070755005 2022-05-29 16:08:32.045666
Epoch:[ 44 15 ] loss: 0.4938817620277405 2022-05-29 16:08:32.813355
Epoch:[ 44 16 ] loss: 0.4904667139053345 2022-05-29 16:08:40.692001
Epoch:[ 44 17 ] loss: 0.4959392249584198 2022-05-29 16:08:41.458986
Epoch:[ 44 18 ] loss: 0.49174147844314575 2022-05-29 16:08:42.231862
Epoch:[ 44 19 ] loss: 0.4982259273529053 2022-05-29 16:08:43.001966
Training_Epoch:[ 44 ] Training_loss: 0.49547405242919923 2022-05-29 16:08:43.002859
learning rate:  0.0008192000000000002
netparams have been saved once 44
val: 1 0.5233213901519775
val: 2 0.5283820629119873
val: 3 0.5232448577880859
val: 4 0.5362602472305298
val: 5 0.5331177711486816
val: 6 0.5264767408370972
val: 7 0.5308406352996826
val: 8 0.5242655873298645
val: 9 0.5355312824249268
val: 10 0.5335847735404968
val: 11 0.5236028432846069
val: 12 0.5120983123779297
val: 13 0.5225751996040344
val: 14 0.5408975481987
val: 15 0.533155620098114
val: 16 0.5186339616775513
val: 17 0.5287408828735352
val: 18 0.5278386473655701
val: 19 0.5171301960945129
val: 20 0.5024641156196594
val_Epoch:[ 44 ] val_loss: 0.5261081337928772 2022-05-29 16:08:48.905166
start training 2022-05-29 16:08:49.007173
Epoch:[ 45 0 ] loss: 0.49612927436828613 2022-05-29 16:09:14.788659
Epoch:[ 45 1 ] loss: 0.49503400921821594 2022-05-29 16:09:15.557000
Epoch:[ 45 2 ] loss: 0.49149778485298157 2022-05-29 16:09:16.326505
Epoch:[ 45 3 ] loss: 0.4934053122997284 2022-05-29 16:09:17.096759
Epoch:[ 45 4 ] loss: 0.49432995915412903 2022-05-29 16:09:17.861364
Epoch:[ 45 5 ] loss: 0.4934709966182709 2022-05-29 16:09:18.631753
Epoch:[ 45 6 ] loss: 0.49255990982055664 2022-05-29 16:09:19.399551
Epoch:[ 45 7 ] loss: 0.4946514666080475 2022-05-29 16:09:20.167292
Epoch:[ 45 8 ] loss: 0.4994318187236786 2022-05-29 16:09:20.936901
Epoch:[ 45 9 ] loss: 0.4964599609375 2022-05-29 16:09:21.706994
Epoch:[ 45 10 ] loss: 0.49462783336639404 2022-05-29 16:09:22.473544
Epoch:[ 45 11 ] loss: 0.4934398829936981 2022-05-29 16:09:23.241922
Epoch:[ 45 12 ] loss: 0.491182804107666 2022-05-29 16:09:24.009904
Epoch:[ 45 13 ] loss: 0.492022842168808 2022-05-29 16:09:24.776410
Epoch:[ 45 14 ] loss: 0.49484750628471375 2022-05-29 16:09:25.546545
Epoch:[ 45 15 ] loss: 0.4904026985168457 2022-05-29 16:09:26.316757
Epoch:[ 45 16 ] loss: 0.4945128858089447 2022-05-29 16:09:35.094317
Epoch:[ 45 17 ] loss: 0.4930489957332611 2022-05-29 16:09:35.861861
Epoch:[ 45 18 ] loss: 0.49061664938926697 2022-05-29 16:09:36.629182
Epoch:[ 45 19 ] loss: 0.4913841485977173 2022-05-29 16:09:37.673352
Training_Epoch:[ 45 ] Training_loss: 0.49365283697843554 2022-05-29 16:09:37.674171
learning rate:  0.0008192000000000002
val: 1 0.5161847472190857
val: 2 0.5280288457870483
val: 3 0.5274378061294556
val: 4 0.5156729221343994
val: 5 0.5132599472999573
val: 6 0.535265326499939
val: 7 0.5244872570037842
val: 8 0.5271019339561462
val: 9 0.5271391272544861
val: 10 0.5175852179527283
val: 11 0.5295252799987793
val: 12 0.521811306476593
val: 13 0.5137913823127747
val: 14 0.5448969006538391
val: 15 0.5205388069152832
val: 16 0.5078038573265076
val: 17 0.534909188747406
val: 18 0.5350098013877869
val: 19 0.5220423340797424
val: 20 0.5248782634735107
val_Epoch:[ 45 ] val_loss: 0.5243685126304627 2022-05-29 16:09:43.797456
start training 2022-05-29 16:09:43.917044
Epoch:[ 46 0 ] loss: 0.48109906911849976 2022-05-29 16:10:10.485723
Epoch:[ 46 1 ] loss: 0.48918360471725464 2022-05-29 16:10:11.258128
Epoch:[ 46 2 ] loss: 0.48940175771713257 2022-05-29 16:10:12.028446
Epoch:[ 46 3 ] loss: 0.49063387513160706 2022-05-29 16:10:12.794821
Epoch:[ 46 4 ] loss: 0.486955463886261 2022-05-29 16:10:13.563464
Epoch:[ 46 5 ] loss: 0.4922139346599579 2022-05-29 16:10:14.328478
Epoch:[ 46 6 ] loss: 0.49407750368118286 2022-05-29 16:10:15.096425
Epoch:[ 46 7 ] loss: 0.487097829580307 2022-05-29 16:10:15.863080
Epoch:[ 46 8 ] loss: 0.49043595790863037 2022-05-29 16:10:16.629072
Epoch:[ 46 9 ] loss: 0.4939955472946167 2022-05-29 16:10:17.400025
Epoch:[ 46 10 ] loss: 0.48795759677886963 2022-05-29 16:10:18.168587
Epoch:[ 46 11 ] loss: 0.49499601125717163 2022-05-29 16:10:18.934788
Epoch:[ 46 12 ] loss: 0.4924134612083435 2022-05-29 16:10:19.702871
Epoch:[ 46 13 ] loss: 0.4922110140323639 2022-05-29 16:10:20.470351
Epoch:[ 46 14 ] loss: 0.49311327934265137 2022-05-29 16:10:21.236838
Epoch:[ 46 15 ] loss: 0.49358949065208435 2022-05-29 16:10:22.006635
Epoch:[ 46 16 ] loss: 0.4918743371963501 2022-05-29 16:10:32.514950
Epoch:[ 46 17 ] loss: 0.4864371418952942 2022-05-29 16:10:33.281533
Epoch:[ 46 18 ] loss: 0.494668573141098 2022-05-29 16:10:34.054683
Epoch:[ 46 19 ] loss: 0.4928094446659088 2022-05-29 16:10:34.822018
Training_Epoch:[ 46 ] Training_loss: 0.4907582446932793 2022-05-29 16:10:34.822856
learning rate:  0.0008192000000000002
netparams have been saved once 46
val: 1 0.5373559594154358
val: 2 0.5223104357719421
val: 3 0.5241068005561829
val: 4 0.5339508056640625
val: 5 0.5333330035209656
val: 6 0.524340808391571
val: 7 0.5301804542541504
val: 8 0.5048284530639648
val: 9 0.5314139723777771
val: 10 0.5186558961868286
val: 11 0.5337252616882324
val: 12 0.525139331817627
val: 13 0.5314315557479858
val: 14 0.5338782668113708
val: 15 0.5245229601860046
val: 16 0.5412508249282837
val: 17 0.5298771858215332
val: 18 0.5144633054733276
val: 19 0.5126358866691589
val: 20 0.5280432105064392
val_Epoch:[ 46 ] val_loss: 0.5267722189426423 2022-05-29 16:10:41.003449
start training 2022-05-29 16:10:41.124295
Epoch:[ 47 0 ] loss: 0.4926092326641083 2022-05-29 16:11:09.536600
Epoch:[ 47 1 ] loss: 0.48587897419929504 2022-05-29 16:11:10.332128
Epoch:[ 47 2 ] loss: 0.49641838669776917 2022-05-29 16:11:11.147448
Epoch:[ 47 3 ] loss: 0.49003010988235474 2022-05-29 16:11:11.920296
Epoch:[ 47 4 ] loss: 0.48747801780700684 2022-05-29 16:11:12.690582
Epoch:[ 47 5 ] loss: 0.49282699823379517 2022-05-29 16:11:13.459108
Epoch:[ 47 6 ] loss: 0.49108120799064636 2022-05-29 16:11:14.230416
Epoch:[ 47 7 ] loss: 0.48877573013305664 2022-05-29 16:11:14.999406
Epoch:[ 47 8 ] loss: 0.49198901653289795 2022-05-29 16:11:15.770610
Epoch:[ 47 9 ] loss: 0.49354636669158936 2022-05-29 16:11:16.540370
Epoch:[ 47 10 ] loss: 0.49401938915252686 2022-05-29 16:11:17.310919
Epoch:[ 47 11 ] loss: 0.4920538663864136 2022-05-29 16:11:18.082821
Epoch:[ 47 12 ] loss: 0.4898388385772705 2022-05-29 16:11:18.853815
Epoch:[ 47 13 ] loss: 0.49755731225013733 2022-05-29 16:11:19.625285
Epoch:[ 47 14 ] loss: 0.49269816279411316 2022-05-29 16:11:20.395707
Epoch:[ 47 15 ] loss: 0.4901120364665985 2022-05-29 16:11:21.197132
Epoch:[ 47 16 ] loss: 0.49313074350357056 2022-05-29 16:11:32.044755
Epoch:[ 47 17 ] loss: 0.49448683857917786 2022-05-29 16:11:32.840454
Epoch:[ 47 18 ] loss: 0.4849227964878082 2022-05-29 16:11:33.661985
Epoch:[ 47 19 ] loss: 0.49350348114967346 2022-05-29 16:11:34.466642
Training_Epoch:[ 47 ] Training_loss: 0.49164787530899046 2022-05-29 16:11:34.467513
learning rate:  0.0008192000000000002
val: 1 0.5239177942276001
val: 2 0.5112723112106323
val: 3 0.5336528420448303
val: 4 0.5287018418312073
val: 5 0.510422945022583
val: 6 0.5161490440368652
val: 7 0.5117135643959045
val: 8 0.5186302065849304
val: 9 0.5275776386260986
val: 10 0.5206269025802612
val: 11 0.5223664045333862
val: 12 0.5259013175964355
val: 13 0.5269197821617126
val: 14 0.5067360401153564
val: 15 0.5261116027832031
val: 16 0.5369457602500916
val: 17 0.5223409533500671
val: 18 0.5249100923538208
val: 19 0.5283253788948059
val: 20 0.524742841720581
val_Epoch:[ 47 ] val_loss: 0.5223982632160187 2022-05-29 16:11:40.771119
start training 2022-05-29 16:11:40.891058
Epoch:[ 48 0 ] loss: 0.48849794268608093 2022-05-29 16:12:09.116504
Epoch:[ 48 1 ] loss: 0.4872162938117981 2022-05-29 16:12:09.934465
Epoch:[ 48 2 ] loss: 0.4910843074321747 2022-05-29 16:12:10.747072
Epoch:[ 48 3 ] loss: 0.4888555705547333 2022-05-29 16:12:11.548626
Epoch:[ 48 4 ] loss: 0.4902392029762268 2022-05-29 16:12:12.348682
Epoch:[ 48 5 ] loss: 0.48856067657470703 2022-05-29 16:12:13.146637
Epoch:[ 48 6 ] loss: 0.4881736636161804 2022-05-29 16:12:13.942514
Epoch:[ 48 7 ] loss: 0.4843733012676239 2022-05-29 16:12:14.739497
Epoch:[ 48 8 ] loss: 0.4929690659046173 2022-05-29 16:12:15.538071
Epoch:[ 48 9 ] loss: 0.49397513270378113 2022-05-29 16:12:16.334165
Epoch:[ 48 10 ] loss: 0.4876439571380615 2022-05-29 16:12:17.131078
Epoch:[ 48 11 ] loss: 0.48863205313682556 2022-05-29 16:12:17.928647
Epoch:[ 48 12 ] loss: 0.4938150942325592 2022-05-29 16:12:18.724734
Epoch:[ 48 13 ] loss: 0.49224796891212463 2022-05-29 16:12:19.521061
Epoch:[ 48 14 ] loss: 0.4898965656757355 2022-05-29 16:12:20.319414
Epoch:[ 48 15 ] loss: 0.4914020895957947 2022-05-29 16:12:21.117073
Epoch:[ 48 16 ] loss: 0.48645615577697754 2022-05-29 16:12:31.073563
Epoch:[ 48 17 ] loss: 0.4922570288181305 2022-05-29 16:12:32.045631
Epoch:[ 48 18 ] loss: 0.4930039346218109 2022-05-29 16:12:32.898620
Epoch:[ 48 19 ] loss: 0.48895689845085144 2022-05-29 16:12:33.694570
Training_Epoch:[ 48 ] Training_loss: 0.48991284519433975 2022-05-29 16:12:33.695345
learning rate:  0.0008192000000000002
netparams have been saved once 48
val: 1 0.5095134377479553
val: 2 0.5331178307533264
val: 3 0.5299050211906433
val: 4 0.5145294070243835
val: 5 0.5278693437576294
val: 6 0.5360937118530273
val: 7 0.5197900533676147
val: 8 0.5310781598091125
val: 9 0.5196930766105652
val: 10 0.5214217901229858
val: 11 0.5268034338951111
val: 12 0.539497435092926
val: 13 0.5359175205230713
val: 14 0.5544211268424988
val: 15 0.5259522199630737
val: 16 0.5351096391677856
val: 17 0.5465657711029053
val: 18 0.539779782295227
val: 19 0.5256357192993164
val: 20 0.5348443388938904
val_Epoch:[ 48 ] val_loss: 0.5303769409656525 2022-05-29 16:12:39.639727
start training 2022-05-29 16:12:39.742030
Epoch:[ 49 0 ] loss: 0.4930226504802704 2022-05-29 16:13:04.859917
Epoch:[ 49 1 ] loss: 0.48610857129096985 2022-05-29 16:13:05.905302
Epoch:[ 49 2 ] loss: 0.48922663927078247 2022-05-29 16:13:06.750694
Epoch:[ 49 3 ] loss: 0.48566943407058716 2022-05-29 16:13:07.547872
Epoch:[ 49 4 ] loss: 0.4867255389690399 2022-05-29 16:13:08.349879
Epoch:[ 49 5 ] loss: 0.48257189989089966 2022-05-29 16:13:09.152148
Epoch:[ 49 6 ] loss: 0.4840620458126068 2022-05-29 16:13:09.950031
Epoch:[ 49 7 ] loss: 0.4868352711200714 2022-05-29 16:13:10.748936
Epoch:[ 49 8 ] loss: 0.4839053452014923 2022-05-29 16:13:11.547500
Epoch:[ 49 9 ] loss: 0.48604393005371094 2022-05-29 16:13:12.345501
Epoch:[ 49 10 ] loss: 0.48831552267074585 2022-05-29 16:13:13.142998
Epoch:[ 49 11 ] loss: 0.48287129402160645 2022-05-29 16:13:13.949750
Epoch:[ 49 12 ] loss: 0.48957619071006775 2022-05-29 16:13:14.753238
Epoch:[ 49 13 ] loss: 0.4960252344608307 2022-05-29 16:13:15.551366
Epoch:[ 49 14 ] loss: 0.49063143134117126 2022-05-29 16:13:16.345611
Epoch:[ 49 15 ] loss: 0.48931458592414856 2022-05-29 16:13:17.135122
Epoch:[ 49 16 ] loss: 0.48622938990592957 2022-05-29 16:13:25.802699
Epoch:[ 49 17 ] loss: 0.4923548102378845 2022-05-29 16:13:27.177428
Epoch:[ 49 18 ] loss: 0.4908052980899811 2022-05-29 16:13:28.059427
Epoch:[ 49 19 ] loss: 0.49607405066490173 2022-05-29 16:13:28.860569
Training_Epoch:[ 49 ] Training_loss: 0.4883184567093849 2022-05-29 16:13:28.861428
learning rate:  0.0008192000000000002
val: 1 0.5479776263237
val: 2 0.5306521058082581
val: 3 0.535435676574707
val: 4 0.5412991642951965
val: 5 0.5325778126716614
val: 6 0.5343862771987915
val: 7 0.5338180661201477
val: 8 0.5239660739898682
val: 9 0.5431936979293823
val: 10 0.525960385799408
val: 11 0.5236441493034363
val: 12 0.5414745211601257
val: 13 0.5352773070335388
val: 14 0.5294697880744934
val: 15 0.5368970036506653
val: 16 0.523283839225769
val: 17 0.5496779680252075
val: 18 0.5436450242996216
val: 19 0.5367444753646851
val: 20 0.5294498801231384
val_Epoch:[ 49 ] val_loss: 0.5349415421485901 2022-05-29 16:13:34.803724
start training 2022-05-29 16:13:34.919158
Epoch:[ 50 0 ] loss: 0.491873174905777 2022-05-29 16:13:59.031359
Epoch:[ 50 1 ] loss: 0.49059978127479553 2022-05-29 16:13:59.904838
Epoch:[ 50 2 ] loss: 0.4885244369506836 2022-05-29 16:14:00.701548
Epoch:[ 50 3 ] loss: 0.4905377924442291 2022-05-29 16:14:01.499121
Epoch:[ 50 4 ] loss: 0.4898681044578552 2022-05-29 16:14:02.293549
Epoch:[ 50 5 ] loss: 0.4907490015029907 2022-05-29 16:14:03.091848
Epoch:[ 50 6 ] loss: 0.4908936619758606 2022-05-29 16:14:03.890061
Epoch:[ 50 7 ] loss: 0.48960840702056885 2022-05-29 16:14:04.686702
Epoch:[ 50 8 ] loss: 0.4925469160079956 2022-05-29 16:14:05.486563
Epoch:[ 50 9 ] loss: 0.48899391293525696 2022-05-29 16:14:06.286618
Epoch:[ 50 10 ] loss: 0.48390865325927734 2022-05-29 16:14:07.081277
Epoch:[ 50 11 ] loss: 0.486786812543869 2022-05-29 16:14:07.873745
Epoch:[ 50 12 ] loss: 0.4859289824962616 2022-05-29 16:14:08.665381
Epoch:[ 50 13 ] loss: 0.4913371205329895 2022-05-29 16:14:09.461659
Epoch:[ 50 14 ] loss: 0.4895290732383728 2022-05-29 16:14:10.259788
Epoch:[ 50 15 ] loss: 0.49026545882225037 2022-05-29 16:14:11.053391
Epoch:[ 50 16 ] loss: 0.48952075839042664 2022-05-29 16:14:19.909543
Epoch:[ 50 17 ] loss: 0.4853745996952057 2022-05-29 16:14:20.699188
Epoch:[ 50 18 ] loss: 0.4830789864063263 2022-05-29 16:14:21.633191
Epoch:[ 50 19 ] loss: 0.4871279299259186 2022-05-29 16:14:22.439982
Training_Epoch:[ 50 ] Training_loss: 0.48885267823934553 2022-05-29 16:14:22.440837
learning rate:  0.0008192000000000002
netparams have been saved once 50
val: 1 0.5311705470085144
val: 2 0.5243584513664246
val: 3 0.5202131271362305
val: 4 0.5213295221328735
val: 5 0.526736319065094
val: 6 0.5362905859947205
val: 7 0.5243815183639526
val: 8 0.5221955180168152
val: 9 0.524122953414917
val: 10 0.5292240381240845
val: 11 0.5230348706245422
val: 12 0.5319948196411133
val: 13 0.5322569608688354
val: 14 0.5324072241783142
val: 15 0.5115498304367065
val: 16 0.5359692573547363
val: 17 0.5193756222724915
val: 18 0.5174168348312378
val: 19 0.526198148727417
val: 20 0.5329468250274658
val_Epoch:[ 50 ] val_loss: 0.5261586487293244 2022-05-29 16:14:28.942789
start training 2022-05-29 16:14:29.068304
Epoch:[ 51 0 ] loss: 0.48928481340408325 2022-05-29 16:14:57.002253
Epoch:[ 51 1 ] loss: 0.48487982153892517 2022-05-29 16:14:57.830148
Epoch:[ 51 2 ] loss: 0.48087337613105774 2022-05-29 16:14:58.634995
Epoch:[ 51 3 ] loss: 0.48208338022232056 2022-05-29 16:14:59.437994
Epoch:[ 51 4 ] loss: 0.4879801571369171 2022-05-29 16:15:00.236356
Epoch:[ 51 5 ] loss: 0.4840920865535736 2022-05-29 16:15:01.030497
Epoch:[ 51 6 ] loss: 0.48316922783851624 2022-05-29 16:15:01.829346
Epoch:[ 51 7 ] loss: 0.4841892421245575 2022-05-29 16:15:02.629238
Epoch:[ 51 8 ] loss: 0.47921431064605713 2022-05-29 16:15:03.425366
Epoch:[ 51 9 ] loss: 0.4846387207508087 2022-05-29 16:15:04.222623
Epoch:[ 51 10 ] loss: 0.48388808965682983 2022-05-29 16:15:05.019228
Epoch:[ 51 11 ] loss: 0.48207730054855347 2022-05-29 16:15:05.816091
Epoch:[ 51 12 ] loss: 0.4804636538028717 2022-05-29 16:15:06.611029
Epoch:[ 51 13 ] loss: 0.4833400845527649 2022-05-29 16:15:07.409733
Epoch:[ 51 14 ] loss: 0.48050302267074585 2022-05-29 16:15:08.208008
Epoch:[ 51 15 ] loss: 0.48609331250190735 2022-05-29 16:15:09.005047
Epoch:[ 51 16 ] loss: 0.48246505856513977 2022-05-29 16:15:19.525494
Epoch:[ 51 17 ] loss: 0.4803011119365692 2022-05-29 16:15:20.322379
Epoch:[ 51 18 ] loss: 0.48147672414779663 2022-05-29 16:15:21.139419
Epoch:[ 51 19 ] loss: 0.4841613471508026 2022-05-29 16:15:21.950203
Training_Epoch:[ 51 ] Training_loss: 0.4832587420940399 2022-05-29 16:15:21.951401
learning rate:  0.0006553600000000002
val: 1 0.5128674507141113
val: 2 0.538611114025116
val: 3 0.5008239150047302
val: 4 0.5163707733154297
val: 5 0.5055591464042664
val: 6 0.5207376480102539
val: 7 0.5267427563667297
val: 8 0.521347165107727
val: 9 0.514263927936554
val: 10 0.529562771320343
val: 11 0.5271199941635132
val: 12 0.534488320350647
val: 13 0.5351446270942688
val: 14 0.512448251247406
val: 15 0.51812744140625
val: 16 0.5259044170379639
val: 17 0.5178247690200806
val: 18 0.5371123552322388
val: 19 0.5193012356758118
val: 20 0.49689921736717224
val_Epoch:[ 51 ] val_loss: 0.5205628648400307 2022-05-29 16:15:28.027449
start training 2022-05-29 16:15:28.144787
Epoch:[ 52 0 ] loss: 0.48096683621406555 2022-05-29 16:15:54.653996
Epoch:[ 52 1 ] loss: 0.4794241487979889 2022-05-29 16:15:55.484403
Epoch:[ 52 2 ] loss: 0.48213136196136475 2022-05-29 16:15:56.291582
Epoch:[ 52 3 ] loss: 0.4812096059322357 2022-05-29 16:15:57.098625
Epoch:[ 52 4 ] loss: 0.4774983525276184 2022-05-29 16:15:57.906738
Epoch:[ 52 5 ] loss: 0.4780290424823761 2022-05-29 16:15:58.712383
Epoch:[ 52 6 ] loss: 0.4821016490459442 2022-05-29 16:15:59.517761
Epoch:[ 52 7 ] loss: 0.4743635058403015 2022-05-29 16:16:00.323512
Epoch:[ 52 8 ] loss: 0.4806821942329407 2022-05-29 16:16:01.130132
Epoch:[ 52 9 ] loss: 0.4781492054462433 2022-05-29 16:16:01.935393
Epoch:[ 52 10 ] loss: 0.4792068302631378 2022-05-29 16:16:02.740562
Epoch:[ 52 11 ] loss: 0.47831404209136963 2022-05-29 16:16:03.544734
Epoch:[ 52 12 ] loss: 0.47817081212997437 2022-05-29 16:16:04.349931
Epoch:[ 52 13 ] loss: 0.4819665849208832 2022-05-29 16:16:05.153725
Epoch:[ 52 14 ] loss: 0.4838097393512726 2022-05-29 16:16:05.960905
Epoch:[ 52 15 ] loss: 0.4775870442390442 2022-05-29 16:16:06.768259
Epoch:[ 52 16 ] loss: 0.47891342639923096 2022-05-29 16:16:16.763801
Epoch:[ 52 17 ] loss: 0.4824603497982025 2022-05-29 16:16:17.560080
Epoch:[ 52 18 ] loss: 0.47641444206237793 2022-05-29 16:16:18.376853
Epoch:[ 52 19 ] loss: 0.48170527815818787 2022-05-29 16:16:19.193114
Training_Epoch:[ 52 ] Training_loss: 0.47965522259473803 2022-05-29 16:16:19.194177
learning rate:  0.0006553600000000002
netparams have been saved once 52
val: 1 0.5094268321990967
val: 2 0.5095934867858887
val: 3 0.5339983105659485
val: 4 0.5125475525856018
val: 5 0.5120048522949219
val: 6 0.5262295007705688
val: 7 0.5184498429298401
val: 8 0.5243150591850281
val: 9 0.5166829228401184
val: 10 0.5163307785987854
val: 11 0.5284903645515442
val: 12 0.5282070636749268
val: 13 0.5210877656936646
val: 14 0.5162904262542725
val: 15 0.5202614665031433
val: 16 0.5310444235801697
val: 17 0.5242767333984375
val: 18 0.5155565142631531
val: 19 0.5201922059059143
val: 20 0.5275946259498596
val_Epoch:[ 52 ] val_loss: 0.5206290364265442 2022-05-29 16:16:25.480243
start training 2022-05-29 16:16:25.602485
Epoch:[ 53 0 ] loss: 0.4818060100078583 2022-05-29 16:16:53.917920
Epoch:[ 53 1 ] loss: 0.47753018140792847 2022-05-29 16:16:54.722500
Epoch:[ 53 2 ] loss: 0.47969743609428406 2022-05-29 16:16:55.525296
Epoch:[ 53 3 ] loss: 0.47538888454437256 2022-05-29 16:16:57.178020
Epoch:[ 53 4 ] loss: 0.47702473402023315 2022-05-29 16:16:57.978618
Epoch:[ 53 5 ] loss: 0.4802553951740265 2022-05-29 16:16:58.773796
Epoch:[ 53 6 ] loss: 0.4735046327114105 2022-05-29 16:16:59.584128
Epoch:[ 53 7 ] loss: 0.4783441722393036 2022-05-29 16:17:00.394220
Epoch:[ 53 8 ] loss: 0.47397199273109436 2022-05-29 16:17:01.206480
Epoch:[ 53 9 ] loss: 0.47596415877342224 2022-05-29 16:17:02.018950
Epoch:[ 53 10 ] loss: 0.4816136956214905 2022-05-29 16:17:02.829451
Epoch:[ 53 11 ] loss: 0.4735284149646759 2022-05-29 16:17:03.627281
Epoch:[ 53 12 ] loss: 0.4814739525318146 2022-05-29 16:17:04.423430
Epoch:[ 53 13 ] loss: 0.47796913981437683 2022-05-29 16:17:05.217879
Epoch:[ 53 14 ] loss: 0.481917142868042 2022-05-29 16:17:06.013711
Epoch:[ 53 15 ] loss: 0.4776025712490082 2022-05-29 16:17:06.809593
Epoch:[ 53 16 ] loss: 0.48386210203170776 2022-05-29 16:17:16.456270
Epoch:[ 53 17 ] loss: 0.47484004497528076 2022-05-29 16:17:17.254479
Epoch:[ 53 18 ] loss: 0.4799935519695282 2022-05-29 16:17:18.718279
Epoch:[ 53 19 ] loss: 0.474599689245224 2022-05-29 16:17:20.149344
Training_Epoch:[ 53 ] Training_loss: 0.47804439514875413 2022-05-29 16:17:20.150242
learning rate:  0.0006553600000000002
val: 1 0.5279114842414856
val: 2 0.5119674205780029
val: 3 0.5121750235557556
val: 4 0.5176203846931458
val: 5 0.5125589966773987
val: 6 0.534183144569397
val: 7 0.5074211359024048
val: 8 0.519589364528656
val: 9 0.5160859823226929
val: 10 0.536002516746521
val: 11 0.49832209944725037
val: 12 0.5112279057502747
val: 13 0.5046029090881348
val: 14 0.5120155811309814
val: 15 0.5207333564758301
val: 16 0.5303089618682861
val: 17 0.5199947953224182
val: 18 0.5251464247703552
val: 19 0.5238214135169983
val: 20 0.5329591035842896
val_Epoch:[ 53 ] val_loss: 0.518732400238514 2022-05-29 16:17:26.278184
start training 2022-05-29 16:17:26.391833
Epoch:[ 54 0 ] loss: 0.47283461689949036 2022-05-29 16:17:54.972662
Epoch:[ 54 1 ] loss: 0.47677916288375854 2022-05-29 16:17:55.807076
Epoch:[ 54 2 ] loss: 0.47459694743156433 2022-05-29 16:17:56.612272
Epoch:[ 54 3 ] loss: 0.4728861451148987 2022-05-29 16:17:57.419272
Epoch:[ 54 4 ] loss: 0.477938175201416 2022-05-29 16:17:58.223315
Epoch:[ 54 5 ] loss: 0.4744167625904083 2022-05-29 16:17:59.026413
Epoch:[ 54 6 ] loss: 0.4823061227798462 2022-05-29 16:17:59.826193
Epoch:[ 54 7 ] loss: 0.474163681268692 2022-05-29 16:18:00.628137
Epoch:[ 54 8 ] loss: 0.4766855239868164 2022-05-29 16:18:01.426295
Epoch:[ 54 9 ] loss: 0.4756069481372833 2022-05-29 16:18:02.228427
Epoch:[ 54 10 ] loss: 0.47616440057754517 2022-05-29 16:18:03.030454
Epoch:[ 54 11 ] loss: 0.4801503121852875 2022-05-29 16:18:03.830157
Epoch:[ 54 12 ] loss: 0.4723944067955017 2022-05-29 16:18:04.627408
Epoch:[ 54 13 ] loss: 0.47410282492637634 2022-05-29 16:18:05.422625
Epoch:[ 54 14 ] loss: 0.47716280817985535 2022-05-29 16:18:06.219733
Epoch:[ 54 15 ] loss: 0.4709096848964691 2022-05-29 16:18:07.017235
Epoch:[ 54 16 ] loss: 0.4773727357387543 2022-05-29 16:18:16.437062
Epoch:[ 54 17 ] loss: 0.47672829031944275 2022-05-29 16:18:17.240319
Epoch:[ 54 18 ] loss: 0.47349607944488525 2022-05-29 16:18:18.147479
Epoch:[ 54 19 ] loss: 0.4774308502674103 2022-05-29 16:18:18.949135
Training_Epoch:[ 54 ] Training_loss: 0.4757063239812851 2022-05-29 16:18:18.950037
learning rate:  0.0006553600000000002
netparams have been saved once 54
val: 1 0.5313402414321899
val: 2 0.5209290385246277
val: 3 0.5328356027603149
val: 4 0.5225454568862915
val: 5 0.5088412761688232
val: 6 0.5064902901649475
val: 7 0.5257229208946228
val: 8 0.5295011401176453
val: 9 0.5263776779174805
val: 10 0.5102503895759583
val: 11 0.5324567556381226
val: 12 0.5095356702804565
val: 13 0.5238496661186218
val: 14 0.5099554657936096
val: 15 0.5296589732170105
val: 16 0.517505407333374
val: 17 0.5102906823158264
val: 18 0.5054168701171875
val: 19 0.5164111256599426
val: 20 0.5136416554450989
val_Epoch:[ 54 ] val_loss: 0.5191778153181076 2022-05-29 16:18:25.012763
start training 2022-05-29 16:18:25.112526
Epoch:[ 55 0 ] loss: 0.4692925810813904 2022-05-29 16:18:49.768977
Epoch:[ 55 1 ] loss: 0.4728390574455261 2022-05-29 16:18:52.376928
Epoch:[ 55 2 ] loss: 0.478308767080307 2022-05-29 16:18:53.178558
Epoch:[ 55 3 ] loss: 0.47447797656059265 2022-05-29 16:18:53.974893
Epoch:[ 55 4 ] loss: 0.46818089485168457 2022-05-29 16:18:54.771990
Epoch:[ 55 5 ] loss: 0.47107478976249695 2022-05-29 16:18:55.572659
Epoch:[ 55 6 ] loss: 0.4749830365180969 2022-05-29 16:18:56.370089
Epoch:[ 55 7 ] loss: 0.4713097810745239 2022-05-29 16:18:57.164859
Epoch:[ 55 8 ] loss: 0.4712962210178375 2022-05-29 16:18:57.956748
Epoch:[ 55 9 ] loss: 0.4754233956336975 2022-05-29 16:18:58.757205
Epoch:[ 55 10 ] loss: 0.4779472053050995 2022-05-29 16:18:59.558459
Epoch:[ 55 11 ] loss: 0.47799068689346313 2022-05-29 16:19:00.356358
Epoch:[ 55 12 ] loss: 0.480601042509079 2022-05-29 16:19:01.152112
Epoch:[ 55 13 ] loss: 0.4739793837070465 2022-05-29 16:19:01.947539
Epoch:[ 55 14 ] loss: 0.47894150018692017 2022-05-29 16:19:02.750382
Epoch:[ 55 15 ] loss: 0.4754650592803955 2022-05-29 16:19:03.555416
Epoch:[ 55 16 ] loss: 0.47386935353279114 2022-05-29 16:19:10.493488
Epoch:[ 55 17 ] loss: 0.4787386655807495 2022-05-29 16:19:13.754271
Epoch:[ 55 18 ] loss: 0.48032504320144653 2022-05-29 16:19:14.588180
Epoch:[ 55 19 ] loss: 0.48002371191978455 2022-05-29 16:19:15.406351
Training_Epoch:[ 55 ] Training_loss: 0.47525340765714646 2022-05-29 16:19:15.407507
learning rate:  0.0006553600000000002
val: 1 0.5101878046989441
val: 2 0.5085992813110352
val: 3 0.5248147249221802
val: 4 0.5344188809394836
val: 5 0.5325107574462891
val: 6 0.5255125164985657
val: 7 0.5303020477294922
val: 8 0.5430853366851807
val: 9 0.5185992121696472
val: 10 0.5367589592933655
val: 11 0.5205856561660767
val: 12 0.5239055156707764
val: 13 0.5152291655540466
val: 14 0.5015473365783691
val: 15 0.517219603061676
val: 16 0.5243748426437378
val: 17 0.5036122798919678
val: 18 0.5191048383712769
val: 19 0.5130598545074463
val: 20 0.5185487270355225
val_Epoch:[ 55 ] val_loss: 0.521098867058754 2022-05-29 16:19:21.773977
start training 2022-05-29 16:19:21.887323
