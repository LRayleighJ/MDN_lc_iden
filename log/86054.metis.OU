GPU: True
80
start training 2022-05-29 13:35:02.152526
Epoch:[ 1 0 ] loss: 0.720440685749054 2022-05-29 13:35:34.860744
Epoch:[ 1 1 ] loss: 0.7042726874351501 2022-05-29 13:35:35.671237
Epoch:[ 1 2 ] loss: 0.7128136157989502 2022-05-29 13:35:36.447098
Epoch:[ 1 3 ] loss: 0.702904999256134 2022-05-29 13:35:37.216672
Epoch:[ 1 4 ] loss: 0.6898890137672424 2022-05-29 13:35:37.984266
Epoch:[ 1 5 ] loss: 0.6821784377098083 2022-05-29 13:35:38.750839
Epoch:[ 1 6 ] loss: 0.675218403339386 2022-05-29 13:35:39.517632
Epoch:[ 1 7 ] loss: 0.6698371767997742 2022-05-29 13:35:40.284273
Epoch:[ 1 8 ] loss: 0.6641009449958801 2022-05-29 13:35:41.050858
Epoch:[ 1 9 ] loss: 0.659250795841217 2022-05-29 13:35:41.817242
Epoch:[ 1 10 ] loss: 0.6533933877944946 2022-05-29 13:35:42.583921
Epoch:[ 1 11 ] loss: 0.6498889327049255 2022-05-29 13:35:43.350168
Epoch:[ 1 12 ] loss: 0.6453335881233215 2022-05-29 13:35:44.115161
Epoch:[ 1 13 ] loss: 0.6430838108062744 2022-05-29 13:35:44.895483
Epoch:[ 1 14 ] loss: 0.6371406316757202 2022-05-29 13:35:45.660765
Epoch:[ 1 15 ] loss: 0.6324796080589294 2022-05-29 13:35:46.438948
Epoch:[ 1 16 ] loss: 0.6303077936172485 2022-05-29 13:35:50.957573
Epoch:[ 1 17 ] loss: 0.6237571239471436 2022-05-29 13:35:51.734324
Epoch:[ 1 18 ] loss: 0.6229588985443115 2022-05-29 13:35:53.756417
Epoch:[ 1 19 ] loss: 0.6172410249710083 2022-05-29 13:35:54.521542
Training_Epoch:[ 1 ] Training_loss: 0.6618245780467987 2022-05-29 13:35:54.522247
learning rate:  0.005
val: 1 0.6538955569267273
val: 2 0.6596037745475769
val: 3 0.6463752388954163
val: 4 0.6610069870948792
val: 5 0.6562513113021851
val: 6 0.6554275751113892
val: 7 0.6499285697937012
val: 8 0.6598939299583435
val: 9 0.6561720967292786
val: 10 0.6584856510162354
val: 11 0.6592415571212769
val: 12 0.6465712785720825
val: 13 0.6576738357543945
val: 14 0.6563078165054321
val: 15 0.6598182320594788
val: 16 0.6554946899414062
val: 17 0.6585261821746826
val: 18 0.6522952914237976
val: 19 0.6511797904968262
val: 20 0.6572625041007996
val_Epoch:[ 1 ] val_loss: 0.6555705934762954 2022-05-29 13:36:02.272590
start training 2022-05-29 13:36:02.382611
Epoch:[ 2 0 ] loss: 0.6177663207054138 2022-05-29 13:36:28.786747
Epoch:[ 2 1 ] loss: 0.6141316890716553 2022-05-29 13:36:29.661275
Epoch:[ 2 2 ] loss: 0.6093121767044067 2022-05-29 13:36:30.429153
Epoch:[ 2 3 ] loss: 0.6035980582237244 2022-05-29 13:36:31.196556
Epoch:[ 2 4 ] loss: 0.6163902878761292 2022-05-29 13:36:31.961357
Epoch:[ 2 5 ] loss: 0.603736937046051 2022-05-29 13:36:32.727978
Epoch:[ 2 6 ] loss: 0.6019570231437683 2022-05-29 13:36:33.494999
Epoch:[ 2 7 ] loss: 0.5989626049995422 2022-05-29 13:36:34.275246
Epoch:[ 2 8 ] loss: 0.5951910018920898 2022-05-29 13:36:35.043596
Epoch:[ 2 9 ] loss: 0.5964222550392151 2022-05-29 13:36:35.812135
Epoch:[ 2 10 ] loss: 0.596185564994812 2022-05-29 13:36:36.578377
Epoch:[ 2 11 ] loss: 0.5924972295761108 2022-05-29 13:36:37.344719
Epoch:[ 2 12 ] loss: 0.5924643278121948 2022-05-29 13:36:38.111726
Epoch:[ 2 13 ] loss: 0.5871983766555786 2022-05-29 13:36:38.878777
Epoch:[ 2 14 ] loss: 0.5880724787712097 2022-05-29 13:36:39.647076
Epoch:[ 2 15 ] loss: 0.587618887424469 2022-05-29 13:36:40.425707
Epoch:[ 2 16 ] loss: 0.5828445553779602 2022-05-29 13:36:49.656203
Epoch:[ 2 17 ] loss: 0.5838910341262817 2022-05-29 13:36:50.435138
Epoch:[ 2 18 ] loss: 0.5791381001472473 2022-05-29 13:36:51.206169
Epoch:[ 2 19 ] loss: 0.5812431573867798 2022-05-29 13:36:51.972046
Training_Epoch:[ 2 ] Training_loss: 0.596431103348732 2022-05-29 13:36:51.972781
learning rate:  0.005
netparams have been saved once 2
val: 1 0.5892433524131775
val: 2 0.586233377456665
val: 3 0.6033563613891602
val: 4 0.5893170833587646
val: 5 0.5950002074241638
val: 6 0.5857526063919067
val: 7 0.5790081024169922
val: 8 0.5933820009231567
val: 9 0.5958282947540283
val: 10 0.580992579460144
val: 11 0.5932305455207825
val: 12 0.5767325758934021
val: 13 0.6010818481445312
val: 14 0.585321307182312
val: 15 0.5892819762229919
val: 16 0.600962221622467
val: 17 0.5836195945739746
val: 18 0.5899138450622559
val: 19 0.5823325514793396
val: 20 0.5796521902084351
val_Epoch:[ 2 ] val_loss: 0.5890121310949326 2022-05-29 13:36:57.707246
start training 2022-05-29 13:36:57.807748
Epoch:[ 3 0 ] loss: 0.5800554156303406 2022-05-29 13:37:23.613868
Epoch:[ 3 1 ] loss: 0.5741198062896729 2022-05-29 13:37:24.379755
Epoch:[ 3 2 ] loss: 0.5784929990768433 2022-05-29 13:37:25.146079
Epoch:[ 3 3 ] loss: 0.5780943632125854 2022-05-29 13:37:25.913302
Epoch:[ 3 4 ] loss: 0.5747882723808289 2022-05-29 13:37:26.677974
Epoch:[ 3 5 ] loss: 0.5740258693695068 2022-05-29 13:37:27.456416
Epoch:[ 3 6 ] loss: 0.5730245113372803 2022-05-29 13:37:28.220084
Epoch:[ 3 7 ] loss: 0.5734972357749939 2022-05-29 13:37:28.985434
Epoch:[ 3 8 ] loss: 0.5757456421852112 2022-05-29 13:37:29.751270
Epoch:[ 3 9 ] loss: 0.5755299925804138 2022-05-29 13:37:30.531957
Epoch:[ 3 10 ] loss: 0.569518506526947 2022-05-29 13:37:31.297913
Epoch:[ 3 11 ] loss: 0.5703197717666626 2022-05-29 13:37:32.061878
Epoch:[ 3 12 ] loss: 0.5759231448173523 2022-05-29 13:37:32.826945
Epoch:[ 3 13 ] loss: 0.5726155042648315 2022-05-29 13:37:33.591956
Epoch:[ 3 14 ] loss: 0.5658149123191833 2022-05-29 13:37:34.357493
Epoch:[ 3 15 ] loss: 0.567091166973114 2022-05-29 13:37:35.124061
Epoch:[ 3 16 ] loss: 0.5684186220169067 2022-05-29 13:37:45.044813
Epoch:[ 3 17 ] loss: 0.568773090839386 2022-05-29 13:37:45.809970
Epoch:[ 3 18 ] loss: 0.5702354311943054 2022-05-29 13:37:46.580696
Epoch:[ 3 19 ] loss: 0.5644803643226624 2022-05-29 13:37:47.346337
Training_Epoch:[ 3 ] Training_loss: 0.5725282311439515 2022-05-29 13:37:47.347046
learning rate:  0.005
val: 1 0.6471978425979614
val: 2 0.6512214541435242
val: 3 0.6400361061096191
val: 4 0.6393442153930664
val: 5 0.6368246674537659
val: 6 0.6305429935455322
val: 7 0.6319782733917236
val: 8 0.641683042049408
val: 9 0.6400730609893799
val: 10 0.6406247019767761
val: 11 0.6481268405914307
val: 12 0.6357642412185669
val: 13 0.6457498073577881
val: 14 0.6459927558898926
val: 15 0.6382858753204346
val: 16 0.6262961626052856
val: 17 0.638702929019928
val: 18 0.6498019695281982
val: 19 0.6433297991752625
val: 20 0.6479530334472656
val_Epoch:[ 3 ] val_loss: 0.6409764885902405 2022-05-29 13:37:52.806324
start training 2022-05-29 13:37:52.907593
Epoch:[ 4 0 ] loss: 0.5630306005477905 2022-05-29 13:38:17.414352
Epoch:[ 4 1 ] loss: 0.5689380168914795 2022-05-29 13:38:18.360981
Epoch:[ 4 2 ] loss: 0.5667651295661926 2022-05-29 13:38:19.128818
Epoch:[ 4 3 ] loss: 0.5704295039176941 2022-05-29 13:38:19.894726
Epoch:[ 4 4 ] loss: 0.5686477422714233 2022-05-29 13:38:20.661504
Epoch:[ 4 5 ] loss: 0.5664932727813721 2022-05-29 13:38:21.429215
Epoch:[ 4 6 ] loss: 0.5664069652557373 2022-05-29 13:38:22.205935
Epoch:[ 4 7 ] loss: 0.5642337799072266 2022-05-29 13:38:22.987535
Epoch:[ 4 8 ] loss: 0.5612792372703552 2022-05-29 13:38:23.752466
Epoch:[ 4 9 ] loss: 0.5708621144294739 2022-05-29 13:38:24.522157
Epoch:[ 4 10 ] loss: 0.56305992603302 2022-05-29 13:38:25.286898
Epoch:[ 4 11 ] loss: 0.5626845955848694 2022-05-29 13:38:26.055638
Epoch:[ 4 12 ] loss: 0.5666733980178833 2022-05-29 13:38:26.821230
Epoch:[ 4 13 ] loss: 0.5688287019729614 2022-05-29 13:38:27.586130
Epoch:[ 4 14 ] loss: 0.5643598437309265 2022-05-29 13:38:28.352864
Epoch:[ 4 15 ] loss: 0.5668157339096069 2022-05-29 13:38:29.117238
Epoch:[ 4 16 ] loss: 0.5633196830749512 2022-05-29 13:38:37.027779
Epoch:[ 4 17 ] loss: 0.5596350431442261 2022-05-29 13:38:37.793394
Epoch:[ 4 18 ] loss: 0.5605754852294922 2022-05-29 13:38:38.563627
Epoch:[ 4 19 ] loss: 0.5707404017448425 2022-05-29 13:38:40.433790
Training_Epoch:[ 4 ] Training_loss: 0.5656889587640762 2022-05-29 13:38:40.434572
learning rate:  0.005
netparams have been saved once 4
val: 1 0.5801326036453247
val: 2 0.5677473545074463
val: 3 0.572626531124115
val: 4 0.565676212310791
val: 5 0.5727750062942505
val: 6 0.5784370303153992
val: 7 0.5842490196228027
val: 8 0.55620276927948
val: 9 0.5755881071090698
val: 10 0.5548620223999023
val: 11 0.597602903842926
val: 12 0.5823529362678528
val: 13 0.5811797380447388
val: 14 0.5754815936088562
val: 15 0.5750998854637146
val: 16 0.581366777420044
val: 17 0.5805919170379639
val: 18 0.5740569829940796
val: 19 0.580616295337677
val: 20 0.5648162961006165
val_Epoch:[ 4 ] val_loss: 0.5750730991363525 2022-05-29 13:38:46.013092
start training 2022-05-29 13:38:46.121268
Epoch:[ 5 0 ] loss: 0.5607924461364746 2022-05-29 13:39:10.667099
Epoch:[ 5 1 ] loss: 0.5680709481239319 2022-05-29 13:39:12.748757
Epoch:[ 5 2 ] loss: 0.5630422830581665 2022-05-29 13:39:13.517113
Epoch:[ 5 3 ] loss: 0.5607950687408447 2022-05-29 13:39:14.284515
Epoch:[ 5 4 ] loss: 0.5663773417472839 2022-05-29 13:39:15.048766
Epoch:[ 5 5 ] loss: 0.5651638507843018 2022-05-29 13:39:15.815439
Epoch:[ 5 6 ] loss: 0.5614252090454102 2022-05-29 13:39:16.581170
Epoch:[ 5 7 ] loss: 0.56377112865448 2022-05-29 13:39:17.360737
Epoch:[ 5 8 ] loss: 0.5660334229469299 2022-05-29 13:39:18.126417
Epoch:[ 5 9 ] loss: 0.5640084743499756 2022-05-29 13:39:18.892870
Epoch:[ 5 10 ] loss: 0.5656518340110779 2022-05-29 13:39:19.660769
Epoch:[ 5 11 ] loss: 0.5636684894561768 2022-05-29 13:39:20.427114
Epoch:[ 5 12 ] loss: 0.5590357780456543 2022-05-29 13:39:21.192374
Epoch:[ 5 13 ] loss: 0.5614337921142578 2022-05-29 13:39:21.960761
Epoch:[ 5 14 ] loss: 0.5641727447509766 2022-05-29 13:39:22.727820
Epoch:[ 5 15 ] loss: 0.5633245706558228 2022-05-29 13:39:23.507798
Epoch:[ 5 16 ] loss: 0.5606002807617188 2022-05-29 13:39:30.250282
Epoch:[ 5 17 ] loss: 0.5629100203514099 2022-05-29 13:39:31.536677
Epoch:[ 5 18 ] loss: 0.5591403245925903 2022-05-29 13:39:33.774341
Epoch:[ 5 19 ] loss: 0.5662266612052917 2022-05-29 13:39:34.541605
Training_Epoch:[ 5 ] Training_loss: 0.5632822334766387 2022-05-29 13:39:34.542339
learning rate:  0.005
val: 1 0.5639157295227051
val: 2 0.5631387233734131
val: 3 0.5733711123466492
val: 4 0.5822327136993408
val: 5 0.5682769417762756
val: 6 0.5571108460426331
val: 7 0.5725946426391602
val: 8 0.5664088726043701
val: 9 0.5516815185546875
val: 10 0.5654886364936829
val: 11 0.5545211434364319
val: 12 0.5564706921577454
val: 13 0.5560480952262878
val: 14 0.5699777007102966
val: 15 0.5696770548820496
val: 16 0.5685831308364868
val: 17 0.5658451914787292
val: 18 0.5574415922164917
val: 19 0.5751659870147705
val: 20 0.5637959241867065
val_Epoch:[ 5 ] val_loss: 0.5650873124599457 2022-05-29 13:39:40.113184
start training 2022-05-29 13:39:40.216628
Epoch:[ 6 0 ] loss: 0.5666192770004272 2022-05-29 13:40:06.146055
Epoch:[ 6 1 ] loss: 0.5612573027610779 2022-05-29 13:40:06.913176
Epoch:[ 6 2 ] loss: 0.5654107928276062 2022-05-29 13:40:07.680597
Epoch:[ 6 3 ] loss: 0.5635756850242615 2022-05-29 13:40:08.447364
Epoch:[ 6 4 ] loss: 0.5593734979629517 2022-05-29 13:40:09.227087
Epoch:[ 6 5 ] loss: 0.5592665076255798 2022-05-29 13:40:09.995450
Epoch:[ 6 6 ] loss: 0.5609744191169739 2022-05-29 13:40:10.763389
Epoch:[ 6 7 ] loss: 0.5596363544464111 2022-05-29 13:40:11.529836
Epoch:[ 6 8 ] loss: 0.5630523562431335 2022-05-29 13:40:12.294635
Epoch:[ 6 9 ] loss: 0.5619977712631226 2022-05-29 13:40:13.060682
Epoch:[ 6 10 ] loss: 0.5602080225944519 2022-05-29 13:40:13.824772
Epoch:[ 6 11 ] loss: 0.5578805208206177 2022-05-29 13:40:14.590870
Epoch:[ 6 12 ] loss: 0.5668560862541199 2022-05-29 13:40:15.373104
Epoch:[ 6 13 ] loss: 0.5643397569656372 2022-05-29 13:40:16.137043
Epoch:[ 6 14 ] loss: 0.5628378987312317 2022-05-29 13:40:16.902214
Epoch:[ 6 15 ] loss: 0.558075487613678 2022-05-29 13:40:17.668278
Epoch:[ 6 16 ] loss: 0.5654070377349854 2022-05-29 13:40:26.254032
Epoch:[ 6 17 ] loss: 0.5627958178520203 2022-05-29 13:40:27.459318
Epoch:[ 6 18 ] loss: 0.563437283039093 2022-05-29 13:40:28.230536
Epoch:[ 6 19 ] loss: 0.5578488707542419 2022-05-29 13:40:28.995036
Training_Epoch:[ 6 ] Training_loss: 0.5620425373315812 2022-05-29 13:40:28.995779
learning rate:  0.005
netparams have been saved once 6
val: 1 0.5631629824638367
val: 2 0.5820377469062805
val: 3 0.5725990533828735
val: 4 0.5714399814605713
val: 5 0.5832058191299438
val: 6 0.5626327991485596
val: 7 0.5724789500236511
val: 8 0.5733955502510071
val: 9 0.5721361637115479
val: 10 0.5635143518447876
val: 11 0.5662014484405518
val: 12 0.5722619295120239
val: 13 0.5633679628372192
val: 14 0.5607964992523193
val: 15 0.5659054517745972
val: 16 0.5862321853637695
val: 17 0.5683302283287048
val: 18 0.5617943406105042
val: 19 0.5762503743171692
val: 20 0.5657711625099182
val_Epoch:[ 6 ] val_loss: 0.5701757490634918 2022-05-29 13:40:34.590543
start training 2022-05-29 13:40:34.688083
Epoch:[ 7 0 ] loss: 0.5620434880256653 2022-05-29 13:40:58.600170
Epoch:[ 7 1 ] loss: 0.572136640548706 2022-05-29 13:40:59.452044
Epoch:[ 7 2 ] loss: 0.5584826469421387 2022-05-29 13:41:00.219037
Epoch:[ 7 3 ] loss: 0.5640296936035156 2022-05-29 13:41:00.985471
Epoch:[ 7 4 ] loss: 0.5678388476371765 2022-05-29 13:41:01.754213
Epoch:[ 7 5 ] loss: 0.560777485370636 2022-05-29 13:41:02.521843
Epoch:[ 7 6 ] loss: 0.560852587223053 2022-05-29 13:41:03.287661
Epoch:[ 7 7 ] loss: 0.5589283108711243 2022-05-29 13:41:04.053497
Epoch:[ 7 8 ] loss: 0.5607070326805115 2022-05-29 13:41:04.821246
Epoch:[ 7 9 ] loss: 0.5616052746772766 2022-05-29 13:41:05.588181
Epoch:[ 7 10 ] loss: 0.5657155513763428 2022-05-29 13:41:06.368727
Epoch:[ 7 11 ] loss: 0.553978681564331 2022-05-29 13:41:07.135066
Epoch:[ 7 12 ] loss: 0.5631105899810791 2022-05-29 13:41:07.903855
Epoch:[ 7 13 ] loss: 0.5587010383605957 2022-05-29 13:41:08.669648
Epoch:[ 7 14 ] loss: 0.5546582341194153 2022-05-29 13:41:09.437059
Epoch:[ 7 15 ] loss: 0.5601378083229065 2022-05-29 13:41:10.214492
Epoch:[ 7 16 ] loss: 0.5589163899421692 2022-05-29 13:41:18.181101
Epoch:[ 7 17 ] loss: 0.5576577186584473 2022-05-29 13:41:18.960266
Epoch:[ 7 18 ] loss: 0.558509349822998 2022-05-29 13:41:19.730530
Epoch:[ 7 19 ] loss: 0.558239221572876 2022-05-29 13:41:20.497490
Training_Epoch:[ 7 ] Training_loss: 0.5608513295650482 2022-05-29 13:41:20.498479
learning rate:  0.005
val: 1 0.5789735913276672
val: 2 0.5592480301856995
val: 3 0.5469971895217896
val: 4 0.5801171660423279
val: 5 0.5808936357498169
val: 6 0.5692015290260315
val: 7 0.555925190448761
val: 8 0.5692146420478821
val: 9 0.5840819478034973
val: 10 0.579894483089447
val: 11 0.5847453474998474
val: 12 0.5671782493591309
val: 13 0.5805296301841736
val: 14 0.5726167559623718
val: 15 0.5614300966262817
val: 16 0.579444408416748
val: 17 0.5727322697639465
val: 18 0.5819768309593201
val: 19 0.5657119750976562
val: 20 0.5667444467544556
val_Epoch:[ 7 ] val_loss: 0.5718828707933425 2022-05-29 13:41:26.062842
start training 2022-05-29 13:41:26.166415
Epoch:[ 8 0 ] loss: 0.5561084151268005 2022-05-29 13:41:50.647878
Epoch:[ 8 1 ] loss: 0.5578755736351013 2022-05-29 13:41:51.645877
Epoch:[ 8 2 ] loss: 0.5642186999320984 2022-05-29 13:41:52.424476
Epoch:[ 8 3 ] loss: 0.5567587018013 2022-05-29 13:41:53.190046
Epoch:[ 8 4 ] loss: 0.5622393488883972 2022-05-29 13:41:53.955538
Epoch:[ 8 5 ] loss: 0.5562351942062378 2022-05-29 13:41:54.722087
Epoch:[ 8 6 ] loss: 0.5606553554534912 2022-05-29 13:41:55.490340
Epoch:[ 8 7 ] loss: 0.5600740313529968 2022-05-29 13:41:56.255492
Epoch:[ 8 8 ] loss: 0.5573123693466187 2022-05-29 13:41:57.024100
Epoch:[ 8 9 ] loss: 0.5559303760528564 2022-05-29 13:41:57.790189
Epoch:[ 8 10 ] loss: 0.5586572289466858 2022-05-29 13:41:58.555701
Epoch:[ 8 11 ] loss: 0.5582943558692932 2022-05-29 13:41:59.323018
Epoch:[ 8 12 ] loss: 0.5548165440559387 2022-05-29 13:42:00.101652
Epoch:[ 8 13 ] loss: 0.5618485808372498 2022-05-29 13:42:00.869001
Epoch:[ 8 14 ] loss: 0.5612502694129944 2022-05-29 13:42:01.639470
Epoch:[ 8 15 ] loss: 0.5577970743179321 2022-05-29 13:42:02.405595
Epoch:[ 8 16 ] loss: 0.5641105771064758 2022-05-29 13:42:10.411357
Epoch:[ 8 17 ] loss: 0.5602688789367676 2022-05-29 13:42:12.407511
Epoch:[ 8 18 ] loss: 0.5574079155921936 2022-05-29 13:42:13.177818
Epoch:[ 8 19 ] loss: 0.5564838647842407 2022-05-29 13:42:13.941382
Training_Epoch:[ 8 ] Training_loss: 0.5589171677827836 2022-05-29 13:42:13.942193
learning rate:  0.005
netparams have been saved once 8
val: 1 0.5668949484825134
val: 2 0.5599711537361145
val: 3 0.5492112040519714
val: 4 0.5449607968330383
val: 5 0.571724534034729
val: 6 0.539974570274353
val: 7 0.5689419507980347
val: 8 0.5617574453353882
val: 9 0.5545394420623779
val: 10 0.5755606293678284
val: 11 0.5602821707725525
val: 12 0.5567072033882141
val: 13 0.5577954649925232
val: 14 0.5632372498512268
val: 15 0.5451168417930603
val: 16 0.5545647740364075
val: 17 0.5570110082626343
val: 18 0.5487369894981384
val: 19 0.5731194019317627
val: 20 0.560818076133728
val_Epoch:[ 8 ] val_loss: 0.5585462927818299 2022-05-29 13:42:19.559310
start training 2022-05-29 13:42:19.664062
Epoch:[ 9 0 ] loss: 0.5561155080795288 2022-05-29 13:42:45.144975
Epoch:[ 9 1 ] loss: 0.5622051954269409 2022-05-29 13:42:46.259967
Epoch:[ 9 2 ] loss: 0.5606687664985657 2022-05-29 13:42:47.029452
Epoch:[ 9 3 ] loss: 0.5566900372505188 2022-05-29 13:42:47.795085
Epoch:[ 9 4 ] loss: 0.5580145120620728 2022-05-29 13:42:48.559641
Epoch:[ 9 5 ] loss: 0.5521024465560913 2022-05-29 13:42:49.325899
Epoch:[ 9 6 ] loss: 0.5613673329353333 2022-05-29 13:42:50.093193
Epoch:[ 9 7 ] loss: 0.5524857044219971 2022-05-29 13:42:50.859975
Epoch:[ 9 8 ] loss: 0.558137834072113 2022-05-29 13:42:51.625883
Epoch:[ 9 9 ] loss: 0.5580279231071472 2022-05-29 13:42:52.391352
Epoch:[ 9 10 ] loss: 0.5613232254981995 2022-05-29 13:42:53.160494
Epoch:[ 9 11 ] loss: 0.5568947792053223 2022-05-29 13:42:53.944728
Epoch:[ 9 12 ] loss: 0.5633458495140076 2022-05-29 13:42:54.709170
Epoch:[ 9 13 ] loss: 0.563829243183136 2022-05-29 13:42:55.475045
Epoch:[ 9 14 ] loss: 0.5576952695846558 2022-05-29 13:42:56.241882
Epoch:[ 9 15 ] loss: 0.5546212792396545 2022-05-29 13:42:57.021460
Epoch:[ 9 16 ] loss: 0.5567259788513184 2022-05-29 13:43:05.773953
Epoch:[ 9 17 ] loss: 0.5580092072486877 2022-05-29 13:43:06.597817
Epoch:[ 9 18 ] loss: 0.5607746243476868 2022-05-29 13:43:07.383107
Epoch:[ 9 19 ] loss: 0.554839551448822 2022-05-29 13:43:08.145102
Training_Epoch:[ 9 ] Training_loss: 0.55819371342659 2022-05-29 13:43:08.145875
learning rate:  0.005
val: 1 0.5598723888397217
val: 2 0.5533439517021179
val: 3 0.5440125465393066
val: 4 0.5526038408279419
val: 5 0.5567049980163574
val: 6 0.5555387735366821
val: 7 0.5662976503372192
val: 8 0.5510156154632568
val: 9 0.5599466562271118
val: 10 0.5718892812728882
val: 11 0.5688174962997437
val: 12 0.5711454749107361
val: 13 0.5558910369873047
val: 14 0.5624329447746277
val: 15 0.5600662231445312
val: 16 0.5542753338813782
val: 17 0.5649235248565674
val: 18 0.5582936406135559
val: 19 0.5460304021835327
val: 20 0.5639602541923523
val_Epoch:[ 9 ] val_loss: 0.5588531017303466 2022-05-29 13:43:13.711322
start training 2022-05-29 13:43:13.813764
Epoch:[ 10 0 ] loss: 0.5540125966072083 2022-05-29 13:43:39.353185
Epoch:[ 10 1 ] loss: 0.557274341583252 2022-05-29 13:43:40.120232
Epoch:[ 10 2 ] loss: 0.5618717074394226 2022-05-29 13:43:40.885444
Epoch:[ 10 3 ] loss: 0.5586061477661133 2022-05-29 13:43:41.652649
Epoch:[ 10 4 ] loss: 0.5538290143013 2022-05-29 13:43:42.418582
Epoch:[ 10 5 ] loss: 0.5537172555923462 2022-05-29 13:43:43.182833
Epoch:[ 10 6 ] loss: 0.5578424334526062 2022-05-29 13:43:43.949493
Epoch:[ 10 7 ] loss: 0.5557390451431274 2022-05-29 13:43:44.714901
Epoch:[ 10 8 ] loss: 0.5565394163131714 2022-05-29 13:43:45.480130
Epoch:[ 10 9 ] loss: 0.561220109462738 2022-05-29 13:43:46.244637
Epoch:[ 10 10 ] loss: 0.5613999366760254 2022-05-29 13:43:47.021670
Epoch:[ 10 11 ] loss: 0.5588211417198181 2022-05-29 13:43:47.786799
Epoch:[ 10 12 ] loss: 0.5612537264823914 2022-05-29 13:43:48.551778
Epoch:[ 10 13 ] loss: 0.5565395951271057 2022-05-29 13:43:49.318994
Epoch:[ 10 14 ] loss: 0.5595919489860535 2022-05-29 13:43:50.083492
Epoch:[ 10 15 ] loss: 0.5604270100593567 2022-05-29 13:43:50.848796
Epoch:[ 10 16 ] loss: 0.5556477904319763 2022-05-29 13:44:00.055009
Epoch:[ 10 17 ] loss: 0.5577608346939087 2022-05-29 13:44:01.464507
Epoch:[ 10 18 ] loss: 0.5554932951927185 2022-05-29 13:44:02.236894
Epoch:[ 10 19 ] loss: 0.5583693981170654 2022-05-29 13:44:03.003183
Training_Epoch:[ 10 ] Training_loss: 0.5577978372573853 2022-05-29 13:44:03.004024
learning rate:  0.005
netparams have been saved once 10
val: 1 0.5586323142051697
val: 2 0.5494254231452942
val: 3 0.5597875118255615
val: 4 0.5481604337692261
val: 5 0.5586706399917603
val: 6 0.5555748343467712
val: 7 0.5604258179664612
val: 8 0.5644104480743408
val: 9 0.5444940328598022
val: 10 0.5429400205612183
val: 11 0.5627228617668152
val: 12 0.5633779168128967
val: 13 0.5512502193450928
val: 14 0.544805645942688
val: 15 0.5553531646728516
val: 16 0.5647586584091187
val: 17 0.5658280253410339
val: 18 0.5640164613723755
val: 19 0.5747093558311462
val: 20 0.5633451342582703
val_Epoch:[ 10 ] val_loss: 0.5576344460248948 2022-05-29 13:44:08.838321
start training 2022-05-29 13:44:08.936882
Epoch:[ 11 0 ] loss: 0.5647265315055847 2022-05-29 13:44:36.048874
Epoch:[ 11 1 ] loss: 0.5576516389846802 2022-05-29 13:44:36.847369
Epoch:[ 11 2 ] loss: 0.5587220191955566 2022-05-29 13:44:37.615465
Epoch:[ 11 3 ] loss: 0.5563052296638489 2022-05-29 13:44:38.384879
Epoch:[ 11 4 ] loss: 0.5561171770095825 2022-05-29 13:44:39.154902
Epoch:[ 11 5 ] loss: 0.5568457245826721 2022-05-29 13:44:39.925324
Epoch:[ 11 6 ] loss: 0.5566226840019226 2022-05-29 13:44:40.693715
Epoch:[ 11 7 ] loss: 0.5543307662010193 2022-05-29 13:44:41.461245
Epoch:[ 11 8 ] loss: 0.5581937432289124 2022-05-29 13:44:42.239805
Epoch:[ 11 9 ] loss: 0.5547974109649658 2022-05-29 13:44:43.006525
Epoch:[ 11 10 ] loss: 0.5558567643165588 2022-05-29 13:44:43.774344
Epoch:[ 11 11 ] loss: 0.5528041124343872 2022-05-29 13:44:44.542459
Epoch:[ 11 12 ] loss: 0.554319441318512 2022-05-29 13:44:45.308368
Epoch:[ 11 13 ] loss: 0.558040976524353 2022-05-29 13:44:46.075475
Epoch:[ 11 14 ] loss: 0.5530164241790771 2022-05-29 13:44:46.851608
Epoch:[ 11 15 ] loss: 0.5563112497329712 2022-05-29 13:44:47.615662
Epoch:[ 11 16 ] loss: 0.5534980297088623 2022-05-29 13:44:56.166979
Epoch:[ 11 17 ] loss: 0.5598726868629456 2022-05-29 13:44:56.931303
Epoch:[ 11 18 ] loss: 0.5579612255096436 2022-05-29 13:44:57.710526
Epoch:[ 11 19 ] loss: 0.5599240064620972 2022-05-29 13:44:58.475881
Training_Epoch:[ 11 ] Training_loss: 0.5567958921194076 2022-05-29 13:44:58.476650
learning rate:  0.0034999999999999996
val: 1 0.5668916702270508
val: 2 0.5493220686912537
val: 3 0.5617867112159729
val: 4 0.5551678538322449
val: 5 0.5653690099716187
val: 6 0.5419017672538757
val: 7 0.5732502937316895
val: 8 0.5424184203147888
val: 9 0.5510674715042114
val: 10 0.5700691342353821
val: 11 0.546527624130249
val: 12 0.5390772223472595
val: 13 0.5523107051849365
val: 14 0.5627468228340149
val: 15 0.5667793154716492
val: 16 0.551459014415741
val: 17 0.5632880926132202
val: 18 0.5611116886138916
val: 19 0.5577043294906616
val: 20 0.564728856086731
val_Epoch:[ 11 ] val_loss: 0.5571489036083221 2022-05-29 13:45:04.037441
start training 2022-05-29 13:45:04.132167
Epoch:[ 12 0 ] loss: 0.555730938911438 2022-05-29 13:45:29.522649
Epoch:[ 12 1 ] loss: 0.5542041063308716 2022-05-29 13:45:30.348990
Epoch:[ 12 2 ] loss: 0.5590621829032898 2022-05-29 13:45:31.115899
Epoch:[ 12 3 ] loss: 0.5604792237281799 2022-05-29 13:45:31.895406
Epoch:[ 12 4 ] loss: 0.5540106296539307 2022-05-29 13:45:32.675698
Epoch:[ 12 5 ] loss: 0.5603123307228088 2022-05-29 13:45:33.441267
Epoch:[ 12 6 ] loss: 0.5595567226409912 2022-05-29 13:45:34.208001
Epoch:[ 12 7 ] loss: 0.5531344413757324 2022-05-29 13:45:34.973632
Epoch:[ 12 8 ] loss: 0.5550245642662048 2022-05-29 13:45:35.738715
Epoch:[ 12 9 ] loss: 0.5559079051017761 2022-05-29 13:45:36.505519
Epoch:[ 12 10 ] loss: 0.5578432083129883 2022-05-29 13:45:37.272818
Epoch:[ 12 11 ] loss: 0.560640811920166 2022-05-29 13:45:38.041282
Epoch:[ 12 12 ] loss: 0.5559163689613342 2022-05-29 13:45:38.807068
Epoch:[ 12 13 ] loss: 0.5583202242851257 2022-05-29 13:45:39.574690
Epoch:[ 12 14 ] loss: 0.5553489923477173 2022-05-29 13:45:40.340236
Epoch:[ 12 15 ] loss: 0.5569035410881042 2022-05-29 13:45:41.108900
Epoch:[ 12 16 ] loss: 0.5561658143997192 2022-05-29 13:45:48.592813
Epoch:[ 12 17 ] loss: 0.5545716285705566 2022-05-29 13:45:49.358939
Epoch:[ 12 18 ] loss: 0.5538364052772522 2022-05-29 13:45:50.123062
Epoch:[ 12 19 ] loss: 0.5514445304870605 2022-05-29 13:45:51.252669
Training_Epoch:[ 12 ] Training_loss: 0.5564207285642624 2022-05-29 13:45:51.253429
learning rate:  0.0034999999999999996
netparams have been saved once 12
val: 1 0.5446757078170776
val: 2 0.5382063388824463
val: 3 0.5723983645439148
val: 4 0.5600110292434692
val: 5 0.5632350444793701
val: 6 0.5640875697135925
val: 7 0.5807321071624756
val: 8 0.5608735084533691
val: 9 0.5590037107467651
val: 10 0.5565201044082642
val: 11 0.5584824085235596
val: 12 0.5635161399841309
val: 13 0.5424841046333313
val: 14 0.5526019334793091
val: 15 0.5507559776306152
val: 16 0.549987256526947
val: 17 0.5559220314025879
val: 18 0.5611871480941772
val: 19 0.5538633465766907
val: 20 0.5452153086662292
val_Epoch:[ 12 ] val_loss: 0.5566879570484161 2022-05-29 13:45:56.875024
start training 2022-05-29 13:45:56.970316
Epoch:[ 13 0 ] loss: 0.5520990490913391 2022-05-29 13:46:22.461685
Epoch:[ 13 1 ] loss: 0.5578574538230896 2022-05-29 13:46:23.225706
Epoch:[ 13 2 ] loss: 0.553774356842041 2022-05-29 13:46:23.988524
Epoch:[ 13 3 ] loss: 0.5596184730529785 2022-05-29 13:46:24.751642
Epoch:[ 13 4 ] loss: 0.5575302839279175 2022-05-29 13:46:25.518852
Epoch:[ 13 5 ] loss: 0.5564351677894592 2022-05-29 13:46:26.296794
Epoch:[ 13 6 ] loss: 0.5607165694236755 2022-05-29 13:46:27.062553
Epoch:[ 13 7 ] loss: 0.5560863614082336 2022-05-29 13:46:27.828980
Epoch:[ 13 8 ] loss: 0.5608903169631958 2022-05-29 13:46:28.595740
Epoch:[ 13 9 ] loss: 0.5541175007820129 2022-05-29 13:46:29.358507
Epoch:[ 13 10 ] loss: 0.5599298477172852 2022-05-29 13:46:30.124386
Epoch:[ 13 11 ] loss: 0.5544583201408386 2022-05-29 13:46:30.889572
Epoch:[ 13 12 ] loss: 0.5586301684379578 2022-05-29 13:46:31.653602
Epoch:[ 13 13 ] loss: 0.558229923248291 2022-05-29 13:46:32.417689
Epoch:[ 13 14 ] loss: 0.5551519989967346 2022-05-29 13:46:33.197241
Epoch:[ 13 15 ] loss: 0.5513803958892822 2022-05-29 13:46:33.963825
Epoch:[ 13 16 ] loss: 0.5549991726875305 2022-05-29 13:46:43.907095
Epoch:[ 13 17 ] loss: 0.5490567088127136 2022-05-29 13:46:44.673996
Epoch:[ 13 18 ] loss: 0.5547389984130859 2022-05-29 13:46:45.444381
Epoch:[ 13 19 ] loss: 0.5567799210548401 2022-05-29 13:46:46.221899
Training_Epoch:[ 13 ] Training_loss: 0.5561240494251252 2022-05-29 13:46:46.222611
learning rate:  0.0034999999999999996
val: 1 0.5739774703979492
val: 2 0.5728517174720764
val: 3 0.5675302147865295
val: 4 0.558372437953949
val: 5 0.551842987537384
val: 6 0.5561663508415222
val: 7 0.563414990901947
val: 8 0.5709043741226196
val: 9 0.5620357990264893
val: 10 0.5549851059913635
val: 11 0.5799464583396912
val: 12 0.5580844283103943
val: 13 0.5616707801818848
val: 14 0.5591736435890198
val: 15 0.5661247372627258
val: 16 0.5561389327049255
val: 17 0.5739542841911316
val: 18 0.5587068796157837
val: 19 0.568928062915802
val: 20 0.5766733288764954
val_Epoch:[ 13 ] val_loss: 0.5645741492509841 2022-05-29 13:46:51.727808
start training 2022-05-29 13:46:51.829018
Epoch:[ 14 0 ] loss: 0.5550972819328308 2022-05-29 13:47:17.052834
Epoch:[ 14 1 ] loss: 0.5568342804908752 2022-05-29 13:47:17.821785
Epoch:[ 14 2 ] loss: 0.5559078454971313 2022-05-29 13:47:18.649866
Epoch:[ 14 3 ] loss: 0.5586527585983276 2022-05-29 13:47:19.429364
Epoch:[ 14 4 ] loss: 0.550049901008606 2022-05-29 13:47:20.194715
Epoch:[ 14 5 ] loss: 0.558800220489502 2022-05-29 13:47:20.975328
Epoch:[ 14 6 ] loss: 0.5598563551902771 2022-05-29 13:47:21.741625
Epoch:[ 14 7 ] loss: 0.5597944855690002 2022-05-29 13:47:22.508291
Epoch:[ 14 8 ] loss: 0.5547470450401306 2022-05-29 13:47:23.274189
Epoch:[ 14 9 ] loss: 0.5559606552124023 2022-05-29 13:47:24.039742
Epoch:[ 14 10 ] loss: 0.5534443259239197 2022-05-29 13:47:24.806054
Epoch:[ 14 11 ] loss: 0.5568616986274719 2022-05-29 13:47:25.574300
Epoch:[ 14 12 ] loss: 0.5530550479888916 2022-05-29 13:47:26.343738
Epoch:[ 14 13 ] loss: 0.55501389503479 2022-05-29 13:47:27.109714
Epoch:[ 14 14 ] loss: 0.5561994910240173 2022-05-29 13:47:27.879574
Epoch:[ 14 15 ] loss: 0.5556604266166687 2022-05-29 13:47:28.643954
Epoch:[ 14 16 ] loss: 0.5520235300064087 2022-05-29 13:47:36.454861
Epoch:[ 14 17 ] loss: 0.5583248138427734 2022-05-29 13:47:37.218729
Epoch:[ 14 18 ] loss: 0.5531622171401978 2022-05-29 13:47:37.990275
Epoch:[ 14 19 ] loss: 0.5557847023010254 2022-05-29 13:47:38.768615
Training_Epoch:[ 14 ] Training_loss: 0.5557615488767624 2022-05-29 13:47:38.769479
learning rate:  0.0034999999999999996
netparams have been saved once 14
val: 1 0.5498865246772766
val: 2 0.5675293207168579
val: 3 0.5694696307182312
val: 4 0.5706906318664551
val: 5 0.576769232749939
val: 6 0.5810443162918091
val: 7 0.5619944334030151
val: 8 0.5666412115097046
val: 9 0.5646244883537292
val: 10 0.5678571462631226
val: 11 0.562708854675293
val: 12 0.5714983940124512
val: 13 0.5668761730194092
val: 14 0.5556222796440125
val: 15 0.5573732852935791
val: 16 0.5733262896537781
val: 17 0.5555647611618042
val: 18 0.56095290184021
val: 19 0.5669806599617004
val: 20 0.5461694002151489
val_Epoch:[ 14 ] val_loss: 0.5646789968013763 2022-05-29 13:47:44.411726
start training 2022-05-29 13:47:44.510836
Epoch:[ 15 0 ] loss: 0.5559841990470886 2022-05-29 13:48:09.949427
Epoch:[ 15 1 ] loss: 0.555810809135437 2022-05-29 13:48:10.953198
Epoch:[ 15 2 ] loss: 0.5518986582756042 2022-05-29 13:48:11.706497
Epoch:[ 15 3 ] loss: 0.5572409629821777 2022-05-29 13:48:12.466016
Epoch:[ 15 4 ] loss: 0.553977370262146 2022-05-29 13:48:13.212613
Epoch:[ 15 5 ] loss: 0.5555965900421143 2022-05-29 13:48:13.961872
Epoch:[ 15 6 ] loss: 0.5558336973190308 2022-05-29 13:48:14.709897
Epoch:[ 15 7 ] loss: 0.5530443787574768 2022-05-29 13:48:15.457501
Epoch:[ 15 8 ] loss: 0.5533669590950012 2022-05-29 13:48:16.217639
Epoch:[ 15 9 ] loss: 0.5607204437255859 2022-05-29 13:48:16.965023
Epoch:[ 15 10 ] loss: 0.5529190897941589 2022-05-29 13:48:17.715161
Epoch:[ 15 11 ] loss: 0.5562145709991455 2022-05-29 13:48:18.462696
Epoch:[ 15 12 ] loss: 0.5564361810684204 2022-05-29 13:48:19.210707
Epoch:[ 15 13 ] loss: 0.5523319840431213 2022-05-29 13:48:19.978864
Epoch:[ 15 14 ] loss: 0.5597590804100037 2022-05-29 13:48:20.746612
Epoch:[ 15 15 ] loss: 0.5558704137802124 2022-05-29 13:48:21.515346
Epoch:[ 15 16 ] loss: 0.5548758506774902 2022-05-29 13:48:29.634430
Epoch:[ 15 17 ] loss: 0.5547917485237122 2022-05-29 13:48:30.412459
Epoch:[ 15 18 ] loss: 0.5528333783149719 2022-05-29 13:48:31.183117
Epoch:[ 15 19 ] loss: 0.5603325366973877 2022-05-29 13:48:31.947474
Training_Epoch:[ 15 ] Training_loss: 0.5554919451475143 2022-05-29 13:48:31.948349
learning rate:  0.0034999999999999996
val: 1 0.575158953666687
val: 2 0.5470474362373352
val: 3 0.5588337779045105
val: 4 0.5590927004814148
val: 5 0.5511849522590637
val: 6 0.5734744071960449
val: 7 0.5713209509849548
val: 8 0.5660011172294617
val: 9 0.5729683041572571
val: 10 0.5518060326576233
val: 11 0.5591986775398254
val: 12 0.5602152943611145
val: 13 0.5605071783065796
val: 14 0.5690412521362305
val: 15 0.5717813968658447
val: 16 0.5589469075202942
val: 17 0.5514929294586182
val: 18 0.5694529414176941
val: 19 0.5532206892967224
val: 20 0.564202606678009
val_Epoch:[ 15 ] val_loss: 0.5622474253177643 2022-05-29 13:48:37.507150
start training 2022-05-29 13:48:37.606452
Epoch:[ 16 0 ] loss: 0.5550832152366638 2022-05-29 13:49:02.210677
Epoch:[ 16 1 ] loss: 0.5552500486373901 2022-05-29 13:49:03.725745
Epoch:[ 16 2 ] loss: 0.5522286295890808 2022-05-29 13:49:04.475375
Epoch:[ 16 3 ] loss: 0.5528993010520935 2022-05-29 13:49:05.225749
Epoch:[ 16 4 ] loss: 0.554885745048523 2022-05-29 13:49:05.973616
Epoch:[ 16 5 ] loss: 0.5538477301597595 2022-05-29 13:49:06.721300
Epoch:[ 16 6 ] loss: 0.5573114156723022 2022-05-29 13:49:07.479911
Epoch:[ 16 7 ] loss: 0.5585737824440002 2022-05-29 13:49:08.229373
Epoch:[ 16 8 ] loss: 0.5507400035858154 2022-05-29 13:49:08.975329
Epoch:[ 16 9 ] loss: 0.5570386648178101 2022-05-29 13:49:09.741521
Epoch:[ 16 10 ] loss: 0.5518630146980286 2022-05-29 13:49:10.507143
Epoch:[ 16 11 ] loss: 0.5576612949371338 2022-05-29 13:49:11.271085
Epoch:[ 16 12 ] loss: 0.5551721453666687 2022-05-29 13:49:12.037288
Epoch:[ 16 13 ] loss: 0.5542888045310974 2022-05-29 13:49:12.801529
Epoch:[ 16 14 ] loss: 0.5568163394927979 2022-05-29 13:49:13.568829
Epoch:[ 16 15 ] loss: 0.5534171462059021 2022-05-29 13:49:14.333421
Epoch:[ 16 16 ] loss: 0.5549412965774536 2022-05-29 13:49:22.089163
Epoch:[ 16 17 ] loss: 0.55501788854599 2022-05-29 13:49:25.177948
Epoch:[ 16 18 ] loss: 0.5536148548126221 2022-05-29 13:49:25.946969
Epoch:[ 16 19 ] loss: 0.5553029775619507 2022-05-29 13:49:26.710718
Training_Epoch:[ 16 ] Training_loss: 0.5547977149486542 2022-05-29 13:49:26.711439
learning rate:  0.0034999999999999996
netparams have been saved once 16
val: 1 0.5513834357261658
val: 2 0.5656305551528931
val: 3 0.5475069284439087
val: 4 0.549643337726593
val: 5 0.5475197434425354
val: 6 0.5584661364555359
val: 7 0.5639738440513611
val: 8 0.563486635684967
val: 9 0.5768833160400391
val: 10 0.544769287109375
val: 11 0.5500758290290833
val: 12 0.5508332848548889
val: 13 0.5296635031700134
val: 14 0.5438248515129089
val: 15 0.5495648980140686
val: 16 0.5612952709197998
val: 17 0.5520414710044861
val: 18 0.5557799339294434
val: 19 0.5575220584869385
val: 20 0.5536205172538757
val_Epoch:[ 16 ] val_loss: 0.553674241900444 2022-05-29 13:49:32.204580
start training 2022-05-29 13:49:32.304063
Epoch:[ 17 0 ] loss: 0.5531263947486877 2022-05-29 13:49:57.232462
Epoch:[ 17 1 ] loss: 0.5518502593040466 2022-05-29 13:49:58.101678
Epoch:[ 17 2 ] loss: 0.556031346321106 2022-05-29 13:49:58.868229
Epoch:[ 17 3 ] loss: 0.5555322766304016 2022-05-29 13:49:59.634024
Epoch:[ 17 4 ] loss: 0.5548778176307678 2022-05-29 13:50:00.401298
Epoch:[ 17 5 ] loss: 0.5559626817703247 2022-05-29 13:50:01.166578
Epoch:[ 17 6 ] loss: 0.5485468506813049 2022-05-29 13:50:01.931565
Epoch:[ 17 7 ] loss: 0.5509383082389832 2022-05-29 13:50:02.708438
Epoch:[ 17 8 ] loss: 0.5554273128509521 2022-05-29 13:50:03.473909
Epoch:[ 17 9 ] loss: 0.5545625686645508 2022-05-29 13:50:04.239214
Epoch:[ 17 10 ] loss: 0.5579988360404968 2022-05-29 13:50:05.006724
Epoch:[ 17 11 ] loss: 0.55665522813797 2022-05-29 13:50:05.772672
Epoch:[ 17 12 ] loss: 0.548917829990387 2022-05-29 13:50:06.538568
Epoch:[ 17 13 ] loss: 0.5577747225761414 2022-05-29 13:50:07.318122
Epoch:[ 17 14 ] loss: 0.5550658702850342 2022-05-29 13:50:08.084582
Epoch:[ 17 15 ] loss: 0.5532283782958984 2022-05-29 13:50:08.853372
Epoch:[ 17 16 ] loss: 0.5496668815612793 2022-05-29 13:50:17.006583
Epoch:[ 17 17 ] loss: 0.5551167130470276 2022-05-29 13:50:17.773507
Epoch:[ 17 18 ] loss: 0.5530027747154236 2022-05-29 13:50:19.361939
Epoch:[ 17 19 ] loss: 0.5604134798049927 2022-05-29 13:50:20.132924
Training_Epoch:[ 17 ] Training_loss: 0.5542348265647888 2022-05-29 13:50:20.133655
learning rate:  0.0034999999999999996
val: 1 0.5612512826919556
val: 2 0.5752525925636292
val: 3 0.5752127766609192
val: 4 0.5701571106910706
val: 5 0.5425678491592407
val: 6 0.5794821381568909
val: 7 0.5681330561637878
val: 8 0.5916831493377686
val: 9 0.5806592106819153
val: 10 0.5763527750968933
val: 11 0.5504005551338196
val: 12 0.5792319178581238
val: 13 0.565633237361908
val: 14 0.5589565634727478
val: 15 0.5680451393127441
val: 16 0.5562463402748108
val: 17 0.5716071128845215
val: 18 0.563581109046936
val: 19 0.5713205933570862
val: 20 0.575637698173523
val_Epoch:[ 17 ] val_loss: 0.5690706104040146 2022-05-29 13:50:25.587544
start training 2022-05-29 13:50:25.687029
Epoch:[ 18 0 ] loss: 0.552786648273468 2022-05-29 13:50:51.295430
Epoch:[ 18 1 ] loss: 0.553046703338623 2022-05-29 13:50:52.108115
Epoch:[ 18 2 ] loss: 0.5527771711349487 2022-05-29 13:50:52.888570
Epoch:[ 18 3 ] loss: 0.5557866096496582 2022-05-29 13:50:53.654355
Epoch:[ 18 4 ] loss: 0.5533601641654968 2022-05-29 13:50:54.421788
Epoch:[ 18 5 ] loss: 0.557327926158905 2022-05-29 13:50:55.189272
Epoch:[ 18 6 ] loss: 0.5499761700630188 2022-05-29 13:50:55.968458
Epoch:[ 18 7 ] loss: 0.5534209609031677 2022-05-29 13:50:56.734940
Epoch:[ 18 8 ] loss: 0.549108624458313 2022-05-29 13:50:57.501306
Epoch:[ 18 9 ] loss: 0.5534836649894714 2022-05-29 13:50:58.269546
Epoch:[ 18 10 ] loss: 0.5532165169715881 2022-05-29 13:50:59.037310
Epoch:[ 18 11 ] loss: 0.5554470419883728 2022-05-29 13:50:59.805501
Epoch:[ 18 12 ] loss: 0.5538459420204163 2022-05-29 13:51:00.572732
Epoch:[ 18 13 ] loss: 0.5553345084190369 2022-05-29 13:51:01.337708
Epoch:[ 18 14 ] loss: 0.5544155240058899 2022-05-29 13:51:02.102722
Epoch:[ 18 15 ] loss: 0.5528745055198669 2022-05-29 13:51:02.868724
Epoch:[ 18 16 ] loss: 0.5482562780380249 2022-05-29 13:51:10.415690
Epoch:[ 18 17 ] loss: 0.5569042563438416 2022-05-29 13:51:11.194718
Epoch:[ 18 18 ] loss: 0.5547850131988525 2022-05-29 13:51:11.983411
Epoch:[ 18 19 ] loss: 0.550414502620697 2022-05-29 13:51:12.749328
Training_Epoch:[ 18 ] Training_loss: 0.5533284366130828 2022-05-29 13:51:12.750105
learning rate:  0.0034999999999999996
netparams have been saved once 18
val: 1 0.5801645517349243
val: 2 0.5752655863761902
val: 3 0.5740413665771484
val: 4 0.5760020017623901
val: 5 0.5795856714248657
val: 6 0.5750323534011841
val: 7 0.5704807639122009
val: 8 0.5795676112174988
val: 9 0.5630154013633728
val: 10 0.5845239758491516
val: 11 0.5671854615211487
val: 12 0.5758477449417114
val: 13 0.5748389959335327
val: 14 0.567479133605957
val: 15 0.5716727375984192
val: 16 0.5770845413208008
val: 17 0.589880645275116
val: 18 0.5918064713478088
val: 19 0.5786463618278503
val: 20 0.5714085102081299
val_Epoch:[ 18 ] val_loss: 0.5761764943599701 2022-05-29 13:51:18.320725
start training 2022-05-29 13:51:18.419753
Epoch:[ 19 0 ] loss: 0.5590311288833618 2022-05-29 13:51:44.181661
Epoch:[ 19 1 ] loss: 0.55002760887146 2022-05-29 13:51:44.946338
Epoch:[ 19 2 ] loss: 0.5532883405685425 2022-05-29 13:51:45.694266
Epoch:[ 19 3 ] loss: 0.5582481622695923 2022-05-29 13:51:46.461971
Epoch:[ 19 4 ] loss: 0.5514910817146301 2022-05-29 13:51:47.214256
Epoch:[ 19 5 ] loss: 0.5502431392669678 2022-05-29 13:51:47.981812
Epoch:[ 19 6 ] loss: 0.5534061789512634 2022-05-29 13:51:48.745045
Epoch:[ 19 7 ] loss: 0.554396390914917 2022-05-29 13:51:49.511957
Epoch:[ 19 8 ] loss: 0.5463430881500244 2022-05-29 13:51:50.257128
Epoch:[ 19 9 ] loss: 0.5543515682220459 2022-05-29 13:51:51.024317
Epoch:[ 19 10 ] loss: 0.5503323078155518 2022-05-29 13:51:51.793856
Epoch:[ 19 11 ] loss: 0.5501580834388733 2022-05-29 13:51:52.576461
Epoch:[ 19 12 ] loss: 0.550580620765686 2022-05-29 13:51:53.345145
Epoch:[ 19 13 ] loss: 0.5563294887542725 2022-05-29 13:51:54.111336
Epoch:[ 19 14 ] loss: 0.5500797629356384 2022-05-29 13:51:54.879716
Epoch:[ 19 15 ] loss: 0.5544201731681824 2022-05-29 13:51:55.647801
Epoch:[ 19 16 ] loss: 0.5571029186248779 2022-05-29 13:52:03.296736
Epoch:[ 19 17 ] loss: 0.5527032613754272 2022-05-29 13:52:04.064856
Epoch:[ 19 18 ] loss: 0.5534420013427734 2022-05-29 13:52:04.858450
Epoch:[ 19 19 ] loss: 0.5549753308296204 2022-05-29 13:52:05.626174
Training_Epoch:[ 19 ] Training_loss: 0.5530475318431854 2022-05-29 13:52:05.626996
learning rate:  0.0034999999999999996
val: 1 0.5433241724967957
val: 2 0.54966801404953
val: 3 0.5555928349494934
val: 4 0.5585193037986755
val: 5 0.5640630125999451
val: 6 0.5536484122276306
val: 7 0.5517787337303162
val: 8 0.5348855257034302
val: 9 0.5422478318214417
val: 10 0.5533311367034912
val: 11 0.5547099113464355
val: 12 0.5420792698860168
val: 13 0.5435321927070618
val: 14 0.571175217628479
val: 15 0.5443133115768433
val: 16 0.5676180720329285
val: 17 0.55405592918396
val: 18 0.5494799613952637
val: 19 0.5466726422309875
val: 20 0.5466629862785339
val_Epoch:[ 19 ] val_loss: 0.551367923617363 2022-05-29 13:52:11.135373
start training 2022-05-29 13:52:11.234885
Epoch:[ 20 0 ] loss: 0.5543868541717529 2022-05-29 13:52:36.361994
Epoch:[ 20 1 ] loss: 0.5508233308792114 2022-05-29 13:52:38.352493
Epoch:[ 20 2 ] loss: 0.5478588342666626 2022-05-29 13:52:39.115826
Epoch:[ 20 3 ] loss: 0.551163375377655 2022-05-29 13:52:39.872565
Epoch:[ 20 4 ] loss: 0.5515666604042053 2022-05-29 13:52:40.623490
Epoch:[ 20 5 ] loss: 0.5488433241844177 2022-05-29 13:52:41.373502
Epoch:[ 20 6 ] loss: 0.5558971762657166 2022-05-29 13:52:42.123460
Epoch:[ 20 7 ] loss: 0.5563826560974121 2022-05-29 13:52:42.873552
Epoch:[ 20 8 ] loss: 0.5501008033752441 2022-05-29 13:52:43.640296
Epoch:[ 20 9 ] loss: 0.54777991771698 2022-05-29 13:52:44.407375
Epoch:[ 20 10 ] loss: 0.5521816611289978 2022-05-29 13:52:45.171417
Epoch:[ 20 11 ] loss: 0.5504701137542725 2022-05-29 13:52:45.951015
Epoch:[ 20 12 ] loss: 0.5521168112754822 2022-05-29 13:52:46.717566
Epoch:[ 20 13 ] loss: 0.5532056093215942 2022-05-29 13:52:47.484759
Epoch:[ 20 14 ] loss: 0.5506038069725037 2022-05-29 13:52:48.263530
Epoch:[ 20 15 ] loss: 0.5535091161727905 2022-05-29 13:52:49.029771
Epoch:[ 20 16 ] loss: 0.5467431545257568 2022-05-29 13:52:56.123439
Epoch:[ 20 17 ] loss: 0.5511581301689148 2022-05-29 13:52:59.214974
Epoch:[ 20 18 ] loss: 0.5517966151237488 2022-05-29 13:52:59.998498
Epoch:[ 20 19 ] loss: 0.5539801120758057 2022-05-29 13:53:00.747199
Training_Epoch:[ 20 ] Training_loss: 0.5515284031629563 2022-05-29 13:53:00.747952
learning rate:  0.0034999999999999996
netparams have been saved once 20
val: 1 0.5774136185646057
val: 2 0.5717962980270386
val: 3 0.5826671719551086
val: 4 0.5825278759002686
val: 5 0.5789817571640015
val: 6 0.5695081949234009
val: 7 0.5939837098121643
val: 8 0.5786629319190979
val: 9 0.5775744318962097
val: 10 0.5903841257095337
val: 11 0.5731362104415894
val: 12 0.5674735307693481
val: 13 0.5570632219314575
val: 14 0.573333740234375
val: 15 0.5741690993309021
val: 16 0.5753511190414429
val: 17 0.5875139236450195
val: 18 0.5823336839675903
val: 19 0.5820873975753784
val: 20 0.5738219618797302
val_Epoch:[ 20 ] val_loss: 0.5774892002344132 2022-05-29 13:53:06.506669
start training 2022-05-29 13:53:06.609511
Epoch:[ 21 0 ] loss: 0.5479374527931213 2022-05-29 13:53:32.521602
Epoch:[ 21 1 ] loss: 0.5525556802749634 2022-05-29 13:53:33.287171
Epoch:[ 21 2 ] loss: 0.546768069267273 2022-05-29 13:53:34.051812
Epoch:[ 21 3 ] loss: 0.549618661403656 2022-05-29 13:53:34.816702
Epoch:[ 21 4 ] loss: 0.5518709421157837 2022-05-29 13:53:35.583348
Epoch:[ 21 5 ] loss: 0.5488057732582092 2022-05-29 13:53:36.362501
Epoch:[ 21 6 ] loss: 0.5547392964363098 2022-05-29 13:53:37.126440
Epoch:[ 21 7 ] loss: 0.5517382621765137 2022-05-29 13:53:37.904567
Epoch:[ 21 8 ] loss: 0.5497563481330872 2022-05-29 13:53:38.670503
Epoch:[ 21 9 ] loss: 0.5521444082260132 2022-05-29 13:53:39.435556
Epoch:[ 21 10 ] loss: 0.5477283000946045 2022-05-29 13:53:40.199327
Epoch:[ 21 11 ] loss: 0.5503896474838257 2022-05-29 13:53:40.964143
Epoch:[ 21 12 ] loss: 0.5517399311065674 2022-05-29 13:53:41.732061
Epoch:[ 21 13 ] loss: 0.5504745244979858 2022-05-29 13:53:42.498025
Epoch:[ 21 14 ] loss: 0.5567744970321655 2022-05-29 13:53:43.264750
Epoch:[ 21 15 ] loss: 0.5495843291282654 2022-05-29 13:53:44.030114
Epoch:[ 21 16 ] loss: 0.5501775741577148 2022-05-29 13:53:52.987743
Epoch:[ 21 17 ] loss: 0.5562486052513123 2022-05-29 13:53:53.753040
Epoch:[ 21 18 ] loss: 0.550112247467041 2022-05-29 13:53:54.522563
Epoch:[ 21 19 ] loss: 0.5494154691696167 2022-05-29 13:53:55.299399
Training_Epoch:[ 21 ] Training_loss: 0.5509290009737015 2022-05-29 13:53:55.300143
learning rate:  0.0024499999999999995
val: 1 0.5472202897071838
val: 2 0.5515100955963135
val: 3 0.5586429834365845
val: 4 0.551876425743103
val: 5 0.5508697628974915
val: 6 0.5570104718208313
val: 7 0.5467392802238464
val: 8 0.5399341583251953
val: 9 0.5444220900535583
val: 10 0.5538766384124756
val: 11 0.5534207224845886
val: 12 0.5447032451629639
val: 13 0.5436835289001465
val: 14 0.5707513093948364
val: 15 0.5512756109237671
val: 16 0.5621225237846375
val: 17 0.5531434416770935
val: 18 0.5530880093574524
val: 19 0.5499982237815857
val: 20 0.5587150454521179
val_Epoch:[ 21 ] val_loss: 0.5521501928567887 2022-05-29 13:54:00.778574
start training 2022-05-29 13:54:00.880644
Epoch:[ 22 0 ] loss: 0.5490120053291321 2022-05-29 13:54:25.641641
Epoch:[ 22 1 ] loss: 0.5502192378044128 2022-05-29 13:54:27.212462
Epoch:[ 22 2 ] loss: 0.5508753061294556 2022-05-29 13:54:27.991450
Epoch:[ 22 3 ] loss: 0.5479845404624939 2022-05-29 13:54:28.757210
Epoch:[ 22 4 ] loss: 0.5508862733840942 2022-05-29 13:54:29.521562
Epoch:[ 22 5 ] loss: 0.5492971539497375 2022-05-29 13:54:30.288373
Epoch:[ 22 6 ] loss: 0.5462754964828491 2022-05-29 13:54:31.053403
Epoch:[ 22 7 ] loss: 0.5512768626213074 2022-05-29 13:54:31.816958
Epoch:[ 22 8 ] loss: 0.5519794225692749 2022-05-29 13:54:32.583533
Epoch:[ 22 9 ] loss: 0.5502663850784302 2022-05-29 13:54:33.351096
Epoch:[ 22 10 ] loss: 0.5515145063400269 2022-05-29 13:54:34.115491
Epoch:[ 22 11 ] loss: 0.5463231801986694 2022-05-29 13:54:34.879956
Epoch:[ 22 12 ] loss: 0.5506709218025208 2022-05-29 13:54:35.645913
Epoch:[ 22 13 ] loss: 0.5482120513916016 2022-05-29 13:54:36.424802
Epoch:[ 22 14 ] loss: 0.5474065542221069 2022-05-29 13:54:37.189096
Epoch:[ 22 15 ] loss: 0.5486434102058411 2022-05-29 13:54:37.954655
Epoch:[ 22 16 ] loss: 0.5422342419624329 2022-05-29 13:54:44.967997
Epoch:[ 22 17 ] loss: 0.5472399592399597 2022-05-29 13:54:46.809431
Epoch:[ 22 18 ] loss: 0.550370454788208 2022-05-29 13:54:47.578290
Epoch:[ 22 19 ] loss: 0.5553768277168274 2022-05-29 13:54:48.343616
Training_Epoch:[ 22 ] Training_loss: 0.5493032395839691 2022-05-29 13:54:48.344371
learning rate:  0.0024499999999999995
netparams have been saved once 22
val: 1 0.5527340769767761
val: 2 0.5380768179893494
val: 3 0.546481192111969
val: 4 0.5527399778366089
val: 5 0.5477756857872009
val: 6 0.5588075518608093
val: 7 0.5701571106910706
val: 8 0.5645906329154968
val: 9 0.5412446856498718
val: 10 0.5600957870483398
val: 11 0.5671517848968506
val: 12 0.5518050789833069
val: 13 0.5542071461677551
val: 14 0.5571693778038025
val: 15 0.5580809712409973
val: 16 0.5460071563720703
val: 17 0.5504246354103088
val: 18 0.5455014705657959
val: 19 0.5593429803848267
val: 20 0.559975266456604
val_Epoch:[ 22 ] val_loss: 0.5541184693574905 2022-05-29 13:54:53.946689
start training 2022-05-29 13:54:54.046195
Epoch:[ 23 0 ] loss: 0.5478784441947937 2022-05-29 13:55:18.993513
Epoch:[ 23 1 ] loss: 0.5431079268455505 2022-05-29 13:55:19.798777
Epoch:[ 23 2 ] loss: 0.555423378944397 2022-05-29 13:55:20.568567
Epoch:[ 23 3 ] loss: 0.5468860268592834 2022-05-29 13:55:21.337798
Epoch:[ 23 4 ] loss: 0.5506868958473206 2022-05-29 13:55:22.104867
Epoch:[ 23 5 ] loss: 0.5481409430503845 2022-05-29 13:55:22.881038
Epoch:[ 23 6 ] loss: 0.5551368594169617 2022-05-29 13:55:23.647155
Epoch:[ 23 7 ] loss: 0.5400509834289551 2022-05-29 13:55:24.414877
Epoch:[ 23 8 ] loss: 0.5458831191062927 2022-05-29 13:55:25.194803
Epoch:[ 23 9 ] loss: 0.5466387867927551 2022-05-29 13:55:25.960814
Epoch:[ 23 10 ] loss: 0.5468870401382446 2022-05-29 13:55:26.728118
Epoch:[ 23 11 ] loss: 0.5499956607818604 2022-05-29 13:55:27.497720
Epoch:[ 23 12 ] loss: 0.5499847531318665 2022-05-29 13:55:28.262314
Epoch:[ 23 13 ] loss: 0.5522631406784058 2022-05-29 13:55:29.029197
Epoch:[ 23 14 ] loss: 0.5499520897865295 2022-05-29 13:55:29.799180
Epoch:[ 23 15 ] loss: 0.5467196702957153 2022-05-29 13:55:30.566732
Epoch:[ 23 16 ] loss: 0.5515645146369934 2022-05-29 13:55:38.570320
Epoch:[ 23 17 ] loss: 0.5523729920387268 2022-05-29 13:55:39.349605
Epoch:[ 23 18 ] loss: 0.5456015467643738 2022-05-29 13:55:40.121612
Epoch:[ 23 19 ] loss: 0.546925961971283 2022-05-29 13:55:40.884565
Training_Epoch:[ 23 ] Training_loss: 0.5486050367355346 2022-05-29 13:55:40.885372
learning rate:  0.0024499999999999995
val: 1 0.552329421043396
val: 2 0.522517740726471
val: 3 0.5659992694854736
val: 4 0.5452461242675781
val: 5 0.57285475730896
val: 6 0.5623221397399902
val: 7 0.544399619102478
val: 8 0.5333051085472107
val: 9 0.5407417416572571
val: 10 0.5516370534896851
val: 11 0.5342366099357605
val: 12 0.548820972442627
val: 13 0.5437752604484558
val: 14 0.5430693626403809
val: 15 0.5591154098510742
val: 16 0.5356782078742981
val: 17 0.55094313621521
val: 18 0.5507636070251465
val: 19 0.5518648624420166
val: 20 0.5555064082145691
val_Epoch:[ 23 ] val_loss: 0.548256340622902 2022-05-29 13:55:46.487460
start training 2022-05-29 13:55:46.587307
Epoch:[ 24 0 ] loss: 0.5465115904808044 2022-05-29 13:56:11.368578
Epoch:[ 24 1 ] loss: 0.5471956729888916 2022-05-29 13:56:12.181303
Epoch:[ 24 2 ] loss: 0.5532179474830627 2022-05-29 13:56:12.977195
Epoch:[ 24 3 ] loss: 0.544843316078186 2022-05-29 13:56:13.743879
Epoch:[ 24 4 ] loss: 0.5454376339912415 2022-05-29 13:56:14.511755
Epoch:[ 24 5 ] loss: 0.5506270527839661 2022-05-29 13:56:15.291081
Epoch:[ 24 6 ] loss: 0.5494416952133179 2022-05-29 13:56:16.073879
Epoch:[ 24 7 ] loss: 0.5466112494468689 2022-05-29 13:56:16.840778
Epoch:[ 24 8 ] loss: 0.5410394668579102 2022-05-29 13:56:17.607379
Epoch:[ 24 9 ] loss: 0.5419039726257324 2022-05-29 13:56:18.372377
Epoch:[ 24 10 ] loss: 0.549487829208374 2022-05-29 13:56:19.138678
Epoch:[ 24 11 ] loss: 0.5422543883323669 2022-05-29 13:56:19.907553
Epoch:[ 24 12 ] loss: 0.5447331070899963 2022-05-29 13:56:20.671732
Epoch:[ 24 13 ] loss: 0.5473392605781555 2022-05-29 13:56:21.438344
Epoch:[ 24 14 ] loss: 0.5491040349006653 2022-05-29 13:56:22.206271
Epoch:[ 24 15 ] loss: 0.5515745282173157 2022-05-29 13:56:22.975141
Epoch:[ 24 16 ] loss: 0.5501845479011536 2022-05-29 13:56:30.976278
Epoch:[ 24 17 ] loss: 0.5480054020881653 2022-05-29 13:56:31.741211
Epoch:[ 24 18 ] loss: 0.5436118841171265 2022-05-29 13:56:32.505797
Epoch:[ 24 19 ] loss: 0.5473990440368652 2022-05-29 13:56:34.244050
Training_Epoch:[ 24 ] Training_loss: 0.5470261812210083 2022-05-29 13:56:34.244754
learning rate:  0.0024499999999999995
netparams have been saved once 24
val: 1 0.5673133730888367
val: 2 0.5675787329673767
val: 3 0.562481701374054
val: 4 0.5612524747848511
val: 5 0.5426344275474548
val: 6 0.5616521835327148
val: 7 0.5614854693412781
val: 8 0.5614627003669739
val: 9 0.556827187538147
val: 10 0.5513646006584167
val: 11 0.5550010800361633
val: 12 0.5749236345291138
val: 13 0.5465294718742371
val: 14 0.5685942769050598
val: 15 0.5642423033714294
val: 16 0.5511552095413208
val: 17 0.5475917458534241
val: 18 0.5618247985839844
val: 19 0.5715993046760559
val: 20 0.5656734108924866
val_Epoch:[ 24 ] val_loss: 0.5600594043731689 2022-05-29 13:56:40.109772
start training 2022-05-29 13:56:40.207162
Epoch:[ 25 0 ] loss: 0.5439624190330505 2022-05-29 13:57:06.643618
Epoch:[ 25 1 ] loss: 0.5462692975997925 2022-05-29 13:57:07.410443
Epoch:[ 25 2 ] loss: 0.54496169090271 2022-05-29 13:57:08.179615
Epoch:[ 25 3 ] loss: 0.5471051335334778 2022-05-29 13:57:08.946169
Epoch:[ 25 4 ] loss: 0.5465365648269653 2022-05-29 13:57:09.712664
Epoch:[ 25 5 ] loss: 0.5459949970245361 2022-05-29 13:57:10.493673
Epoch:[ 25 6 ] loss: 0.5509788393974304 2022-05-29 13:57:11.259762
Epoch:[ 25 7 ] loss: 0.553449273109436 2022-05-29 13:57:12.024500
Epoch:[ 25 8 ] loss: 0.5444414615631104 2022-05-29 13:57:12.790765
Epoch:[ 25 9 ] loss: 0.5474693775177002 2022-05-29 13:57:13.569750
Epoch:[ 25 10 ] loss: 0.5553995966911316 2022-05-29 13:57:14.337887
Epoch:[ 25 11 ] loss: 0.5468989014625549 2022-05-29 13:57:15.104133
Epoch:[ 25 12 ] loss: 0.5451720356941223 2022-05-29 13:57:15.872348
Epoch:[ 25 13 ] loss: 0.5488267540931702 2022-05-29 13:57:16.640383
Epoch:[ 25 14 ] loss: 0.5451931357383728 2022-05-29 13:57:17.406681
Epoch:[ 25 15 ] loss: 0.5468469858169556 2022-05-29 13:57:18.172410
Epoch:[ 25 16 ] loss: 0.5439856648445129 2022-05-29 13:57:28.094712
Epoch:[ 25 17 ] loss: 0.5464287400245667 2022-05-29 13:57:28.856765
Epoch:[ 25 18 ] loss: 0.546302318572998 2022-05-29 13:57:29.638190
Epoch:[ 25 19 ] loss: 0.5502294898033142 2022-05-29 13:57:30.402114
Training_Epoch:[ 25 ] Training_loss: 0.5473226338624955 2022-05-29 13:57:30.402919
learning rate:  0.0024499999999999995
val: 1 0.5473613142967224
val: 2 0.5534586310386658
val: 3 0.5586715936660767
val: 4 0.568967342376709
val: 5 0.5356557369232178
val: 6 0.5404432415962219
val: 7 0.5521824359893799
val: 8 0.5438970327377319
val: 9 0.5624344348907471
val: 10 0.5590698719024658
val: 11 0.5600712299346924
val: 12 0.5663531422615051
val: 13 0.550637423992157
val: 14 0.5490262508392334
val: 15 0.5605152249336243
val: 16 0.5467696189880371
val: 17 0.5519751310348511
val: 18 0.5585652589797974
val: 19 0.5638819336891174
val: 20 0.5610682964324951
val_Epoch:[ 25 ] val_loss: 0.5545502573251724 2022-05-29 13:57:36.219244
start training 2022-05-29 13:57:36.318175
Epoch:[ 26 0 ] loss: 0.5476009845733643 2022-05-29 13:58:03.358350
Epoch:[ 26 1 ] loss: 0.5496543049812317 2022-05-29 13:58:04.123263
Epoch:[ 26 2 ] loss: 0.5466282367706299 2022-05-29 13:58:04.889288
Epoch:[ 26 3 ] loss: 0.545107901096344 2022-05-29 13:58:05.654980
Epoch:[ 26 4 ] loss: 0.5453263521194458 2022-05-29 13:58:06.433031
Epoch:[ 26 5 ] loss: 0.5516260266304016 2022-05-29 13:58:07.196362
Epoch:[ 26 6 ] loss: 0.5486189126968384 2022-05-29 13:58:07.962303
Epoch:[ 26 7 ] loss: 0.5463274717330933 2022-05-29 13:58:08.731311
Epoch:[ 26 8 ] loss: 0.5441120862960815 2022-05-29 13:58:09.499995
Epoch:[ 26 9 ] loss: 0.5459269881248474 2022-05-29 13:58:10.268301
Epoch:[ 26 10 ] loss: 0.5403255820274353 2022-05-29 13:58:11.038247
Epoch:[ 26 11 ] loss: 0.5468248724937439 2022-05-29 13:58:11.807359
Epoch:[ 26 12 ] loss: 0.5519023537635803 2022-05-29 13:58:12.588549
Epoch:[ 26 13 ] loss: 0.5412144064903259 2022-05-29 13:58:13.354339
Epoch:[ 26 14 ] loss: 0.5435146689414978 2022-05-29 13:58:14.120854
Epoch:[ 26 15 ] loss: 0.5382923483848572 2022-05-29 13:58:14.889270
Epoch:[ 26 16 ] loss: 0.541912317276001 2022-05-29 13:58:24.055922
Epoch:[ 26 17 ] loss: 0.5460522770881653 2022-05-29 13:58:24.821751
Epoch:[ 26 18 ] loss: 0.5423170924186707 2022-05-29 13:58:25.604947
Epoch:[ 26 19 ] loss: 0.5446879267692566 2022-05-29 13:58:26.370697
Training_Epoch:[ 26 ] Training_loss: 0.5453986555337906 2022-05-29 13:58:26.371620
learning rate:  0.0024499999999999995
netparams have been saved once 26
val: 1 0.5600340962409973
val: 2 0.547694981098175
val: 3 0.5573487281799316
val: 4 0.5325524210929871
val: 5 0.5355807542800903
val: 6 0.5538901686668396
val: 7 0.5207653641700745
val: 8 0.5439838767051697
val: 9 0.5464842915534973
val: 10 0.5452325344085693
val: 11 0.5552909970283508
val: 12 0.542783260345459
val: 13 0.5454860925674438
val: 14 0.5491804480552673
val: 15 0.5300922393798828
val: 16 0.5558044910430908
val: 17 0.557217538356781
val: 18 0.5448338389396667
val: 19 0.5410333275794983
val: 20 0.5483691096305847
val_Epoch:[ 26 ] val_loss: 0.5456829279661178 2022-05-29 13:58:31.993606
start training 2022-05-29 13:58:32.094260
Epoch:[ 27 0 ] loss: 0.5441878437995911 2022-05-29 13:58:58.234280
Epoch:[ 27 1 ] loss: 0.5466002225875854 2022-05-29 13:58:59.043463
Epoch:[ 27 2 ] loss: 0.5476265549659729 2022-05-29 13:58:59.807438
Epoch:[ 27 3 ] loss: 0.5475265383720398 2022-05-29 13:59:00.584843
Epoch:[ 27 4 ] loss: 0.548305869102478 2022-05-29 13:59:01.350950
Epoch:[ 27 5 ] loss: 0.5416958332061768 2022-05-29 13:59:02.116287
Epoch:[ 27 6 ] loss: 0.5432836413383484 2022-05-29 13:59:02.894658
Epoch:[ 27 7 ] loss: 0.5483412742614746 2022-05-29 13:59:03.662319
Epoch:[ 27 8 ] loss: 0.5447656512260437 2022-05-29 13:59:04.428756
Epoch:[ 27 9 ] loss: 0.546482264995575 2022-05-29 13:59:05.190032
Epoch:[ 27 10 ] loss: 0.5377295017242432 2022-05-29 13:59:05.954445
Epoch:[ 27 11 ] loss: 0.5476546883583069 2022-05-29 13:59:06.720572
Epoch:[ 27 12 ] loss: 0.5509766936302185 2022-05-29 13:59:07.486080
Epoch:[ 27 13 ] loss: 0.5422393083572388 2022-05-29 13:59:08.251559
Epoch:[ 27 14 ] loss: 0.5427972078323364 2022-05-29 13:59:09.015601
Epoch:[ 27 15 ] loss: 0.5498550534248352 2022-05-29 13:59:09.781277
Epoch:[ 27 16 ] loss: 0.5476956963539124 2022-05-29 13:59:17.082322
Epoch:[ 27 17 ] loss: 0.5431095361709595 2022-05-29 13:59:20.201805
Epoch:[ 27 18 ] loss: 0.5490471124649048 2022-05-29 13:59:20.973498
Epoch:[ 27 19 ] loss: 0.5408976674079895 2022-05-29 13:59:21.740040
Training_Epoch:[ 27 ] Training_loss: 0.5455409079790116 2022-05-29 13:59:21.740792
learning rate:  0.0024499999999999995
val: 1 0.5581610202789307
val: 2 0.5577852129936218
val: 3 0.554772675037384
val: 4 0.5716705322265625
val: 5 0.5590235590934753
val: 6 0.5599894523620605
val: 7 0.5690507292747498
val: 8 0.5765120387077332
val: 9 0.5688045620918274
val: 10 0.5717372298240662
val: 11 0.5664381980895996
val: 12 0.5498962998390198
val: 13 0.561562180519104
val: 14 0.5598097443580627
val: 15 0.5686962604522705
val: 16 0.5468941926956177
val: 17 0.5746387839317322
val: 18 0.57170569896698
val: 19 0.5583801865577698
val: 20 0.5815747380256653
val_Epoch:[ 27 ] val_loss: 0.5643551647663116 2022-05-29 13:59:27.425108
start training 2022-05-29 13:59:27.529061
Epoch:[ 28 0 ] loss: 0.5435935854911804 2022-05-29 13:59:54.334245
Epoch:[ 28 1 ] loss: 0.5439753532409668 2022-05-29 13:59:55.099913
Epoch:[ 28 2 ] loss: 0.5460265874862671 2022-05-29 13:59:55.866569
Epoch:[ 28 3 ] loss: 0.5468834042549133 2022-05-29 13:59:56.630854
Epoch:[ 28 4 ] loss: 0.5431116819381714 2022-05-29 13:59:57.408639
Epoch:[ 28 5 ] loss: 0.5480486750602722 2022-05-29 13:59:58.176427
Epoch:[ 28 6 ] loss: 0.540992259979248 2022-05-29 13:59:58.941096
Epoch:[ 28 7 ] loss: 0.5538982152938843 2022-05-29 13:59:59.711931
Epoch:[ 28 8 ] loss: 0.5433210134506226 2022-05-29 14:00:00.493935
Epoch:[ 28 9 ] loss: 0.5451483130455017 2022-05-29 14:00:01.259309
Epoch:[ 28 10 ] loss: 0.5386330485343933 2022-05-29 14:00:02.029185
Epoch:[ 28 11 ] loss: 0.5388591885566711 2022-05-29 14:00:02.798061
Epoch:[ 28 12 ] loss: 0.5445038676261902 2022-05-29 14:00:03.565978
Epoch:[ 28 13 ] loss: 0.5467934012413025 2022-05-29 14:00:04.332262
Epoch:[ 28 14 ] loss: 0.5488145351409912 2022-05-29 14:00:05.100410
Epoch:[ 28 15 ] loss: 0.5479542016983032 2022-05-29 14:00:05.867325
Epoch:[ 28 16 ] loss: 0.5420733690261841 2022-05-29 14:00:14.546696
Epoch:[ 28 17 ] loss: 0.5432000756263733 2022-05-29 14:00:15.313558
Epoch:[ 28 18 ] loss: 0.5460044741630554 2022-05-29 14:00:16.080745
Epoch:[ 28 19 ] loss: 0.5485919117927551 2022-05-29 14:00:16.848204
Training_Epoch:[ 28 ] Training_loss: 0.5450213581323624 2022-05-29 14:00:16.849031
learning rate:  0.0024499999999999995
netparams have been saved once 28
val: 1 0.5812907218933105
val: 2 0.5895960330963135
val: 3 0.5889186263084412
val: 4 0.5973134636878967
val: 5 0.5938606858253479
val: 6 0.5775856375694275
val: 7 0.5892389416694641
val: 8 0.5746919512748718
val: 9 0.5617429614067078
val: 10 0.5731496810913086
val: 11 0.5713614225387573
val: 12 0.6021280884742737
val: 13 0.5779542922973633
val: 14 0.5810979008674622
val: 15 0.5845662355422974
val: 16 0.559361457824707
val: 17 0.5959444642066956
val: 18 0.5911712646484375
val: 19 0.5717371702194214
val: 20 0.5786214470863342
val_Epoch:[ 28 ] val_loss: 0.5820666223764419 2022-05-29 14:00:22.680878
start training 2022-05-29 14:00:22.783281
Epoch:[ 29 0 ] loss: 0.5419487357139587 2022-05-29 14:00:48.502601
Epoch:[ 29 1 ] loss: 0.543368935585022 2022-05-29 14:00:49.294211
Epoch:[ 29 2 ] loss: 0.5390672087669373 2022-05-29 14:00:50.058664
Epoch:[ 29 3 ] loss: 0.5419021248817444 2022-05-29 14:00:50.823165
Epoch:[ 29 4 ] loss: 0.5415747761726379 2022-05-29 14:00:51.587961
Epoch:[ 29 5 ] loss: 0.5420620441436768 2022-05-29 14:00:52.354615
Epoch:[ 29 6 ] loss: 0.5425688028335571 2022-05-29 14:00:53.120852
Epoch:[ 29 7 ] loss: 0.541351318359375 2022-05-29 14:00:53.885547
Epoch:[ 29 8 ] loss: 0.5301730036735535 2022-05-29 14:00:54.662522
Epoch:[ 29 9 ] loss: 0.5467652678489685 2022-05-29 14:00:55.427036
Epoch:[ 29 10 ] loss: 0.5429945588111877 2022-05-29 14:00:56.190883
Epoch:[ 29 11 ] loss: 0.5440540909767151 2022-05-29 14:00:56.957463
Epoch:[ 29 12 ] loss: 0.5420277118682861 2022-05-29 14:00:57.724208
Epoch:[ 29 13 ] loss: 0.5393530130386353 2022-05-29 14:00:58.491592
Epoch:[ 29 14 ] loss: 0.5424532890319824 2022-05-29 14:00:59.269612
Epoch:[ 29 15 ] loss: 0.5461498498916626 2022-05-29 14:01:00.035926
Epoch:[ 29 16 ] loss: 0.5470882058143616 2022-05-29 14:01:07.637403
Epoch:[ 29 17 ] loss: 0.5461192727088928 2022-05-29 14:01:08.402999
Epoch:[ 29 18 ] loss: 0.5402646660804749 2022-05-29 14:01:10.952703
Epoch:[ 29 19 ] loss: 0.5425373911857605 2022-05-29 14:01:11.717590
Training_Epoch:[ 29 ] Training_loss: 0.5421912133693695 2022-05-29 14:01:11.718393
learning rate:  0.0024499999999999995
val: 1 0.5566264986991882
val: 2 0.5447651147842407
val: 3 0.5440523028373718
val: 4 0.5544000864028931
val: 5 0.5331955552101135
val: 6 0.5385194420814514
val: 7 0.5508802533149719
val: 8 0.5460190773010254
val: 9 0.5411792397499084
val: 10 0.551948070526123
val: 11 0.5418466329574585
val: 12 0.5324771404266357
val: 13 0.5421477556228638
val: 14 0.5421931147575378
val: 15 0.5467628240585327
val: 16 0.5361687541007996
val: 17 0.5495578646659851
val: 18 0.5232225656509399
val: 19 0.5435139536857605
val: 20 0.5378711819648743
val_Epoch:[ 29 ] val_loss: 0.5428673714399338 2022-05-29 14:01:17.479081
start training 2022-05-29 14:01:17.586519
Epoch:[ 30 0 ] loss: 0.5422266721725464 2022-05-29 14:01:43.612644
Epoch:[ 30 1 ] loss: 0.5401942133903503 2022-05-29 14:01:44.378865
Epoch:[ 30 2 ] loss: 0.5420637726783752 2022-05-29 14:01:45.144210
Epoch:[ 30 3 ] loss: 0.5424573421478271 2022-05-29 14:01:45.910554
Epoch:[ 30 4 ] loss: 0.5395660996437073 2022-05-29 14:01:46.677881
Epoch:[ 30 5 ] loss: 0.538434624671936 2022-05-29 14:01:47.447694
Epoch:[ 30 6 ] loss: 0.5395549535751343 2022-05-29 14:01:48.214018
Epoch:[ 30 7 ] loss: 0.5366826057434082 2022-05-29 14:01:48.981472
Epoch:[ 30 8 ] loss: 0.5429351925849915 2022-05-29 14:01:49.761105
Epoch:[ 30 9 ] loss: 0.5455965995788574 2022-05-29 14:01:50.528439
Epoch:[ 30 10 ] loss: 0.5447498559951782 2022-05-29 14:01:51.294803
Epoch:[ 30 11 ] loss: 0.5405517220497131 2022-05-29 14:01:52.072391
Epoch:[ 30 12 ] loss: 0.5397708415985107 2022-05-29 14:01:52.839505
Epoch:[ 30 13 ] loss: 0.5430593490600586 2022-05-29 14:01:53.606005
Epoch:[ 30 14 ] loss: 0.5434486865997314 2022-05-29 14:01:54.372846
Epoch:[ 30 15 ] loss: 0.5389272570610046 2022-05-29 14:01:55.139225
Epoch:[ 30 16 ] loss: 0.5452509522438049 2022-05-29 14:02:02.831820
Epoch:[ 30 17 ] loss: 0.5424941182136536 2022-05-29 14:02:03.599103
Epoch:[ 30 18 ] loss: 0.5388613939285278 2022-05-29 14:02:04.362102
Epoch:[ 30 19 ] loss: 0.5421450734138489 2022-05-29 14:02:05.128377
Training_Epoch:[ 30 ] Training_loss: 0.5414485663175583 2022-05-29 14:02:05.129223
learning rate:  0.0024499999999999995
netparams have been saved once 30
val: 1 0.5271879434585571
val: 2 0.5379971265792847
val: 3 0.5406484007835388
val: 4 0.5415394306182861
val: 5 0.5417015552520752
val: 6 0.5579540729522705
val: 7 0.5622690320014954
val: 8 0.5681496262550354
val: 9 0.5387592911720276
val: 10 0.5472820401191711
val: 11 0.5603957176208496
val: 12 0.5312102437019348
val: 13 0.5284484028816223
val: 14 0.5468302369117737
val: 15 0.5408346056938171
val: 16 0.5296407341957092
val: 17 0.5403666496276855
val: 18 0.5495671033859253
val: 19 0.5381495356559753
val: 20 0.5343336462974548
val_Epoch:[ 30 ] val_loss: 0.5431632697582245 2022-05-29 14:02:11.042794
start training 2022-05-29 14:02:11.158238
Epoch:[ 31 0 ] loss: 0.5461580753326416 2022-05-29 14:02:37.122703
Epoch:[ 31 1 ] loss: 0.5401381254196167 2022-05-29 14:02:37.965395
Epoch:[ 31 2 ] loss: 0.5378484129905701 2022-05-29 14:02:38.730171
Epoch:[ 31 3 ] loss: 0.5379405617713928 2022-05-29 14:02:39.496653
Epoch:[ 31 4 ] loss: 0.5365555286407471 2022-05-29 14:02:40.276512
Epoch:[ 31 5 ] loss: 0.5366044044494629 2022-05-29 14:02:41.041509
Epoch:[ 31 6 ] loss: 0.5454553365707397 2022-05-29 14:02:41.805818
Epoch:[ 31 7 ] loss: 0.5358714461326599 2022-05-29 14:02:42.573560
Epoch:[ 31 8 ] loss: 0.5349208116531372 2022-05-29 14:02:43.340779
Epoch:[ 31 9 ] loss: 0.5451420545578003 2022-05-29 14:02:44.108630
Epoch:[ 31 10 ] loss: 0.5392053127288818 2022-05-29 14:02:44.877298
Epoch:[ 31 11 ] loss: 0.5428429245948792 2022-05-29 14:02:45.643199
Epoch:[ 31 12 ] loss: 0.5396003127098083 2022-05-29 14:02:46.408309
Epoch:[ 31 13 ] loss: 0.5387107133865356 2022-05-29 14:02:47.187392
Epoch:[ 31 14 ] loss: 0.5399431586265564 2022-05-29 14:02:47.953929
Epoch:[ 31 15 ] loss: 0.5372684597969055 2022-05-29 14:02:48.721746
Epoch:[ 31 16 ] loss: 0.5366462469100952 2022-05-29 14:02:56.145102
Epoch:[ 31 17 ] loss: 0.5403150320053101 2022-05-29 14:02:56.909084
Epoch:[ 31 18 ] loss: 0.5387850999832153 2022-05-29 14:02:57.674660
Epoch:[ 31 19 ] loss: 0.5384959578514099 2022-05-29 14:02:59.182168
Training_Epoch:[ 31 ] Training_loss: 0.5394223988056183 2022-05-29 14:02:59.182938
learning rate:  0.0017149999999999995
val: 1 0.5513059496879578
val: 2 0.5402833819389343
val: 3 0.5393261313438416
val: 4 0.5476651787757874
val: 5 0.542732834815979
val: 6 0.5233466625213623
val: 7 0.558501660823822
val: 8 0.5541197061538696
val: 9 0.5410804748535156
val: 10 0.5334604382514954
val: 11 0.5368605852127075
val: 12 0.5559044480323792
val: 13 0.5341533422470093
val: 14 0.5419745445251465
val: 15 0.544103741645813
val: 16 0.5494747757911682
val: 17 0.539804220199585
val: 18 0.5498254895210266
val: 19 0.5335257649421692
val: 20 0.5539091229438782
val_Epoch:[ 31 ] val_loss: 0.5435679227113723 2022-05-29 14:03:04.865251
start training 2022-05-29 14:03:04.972226
Epoch:[ 32 0 ] loss: 0.5359706282615662 2022-05-29 14:03:31.332828
Epoch:[ 32 1 ] loss: 0.538116455078125 2022-05-29 14:03:32.099962
Epoch:[ 32 2 ] loss: 0.535906195640564 2022-05-29 14:03:32.868354
Epoch:[ 32 3 ] loss: 0.5362221598625183 2022-05-29 14:03:33.632608
Epoch:[ 32 4 ] loss: 0.5440428853034973 2022-05-29 14:03:34.411951
Epoch:[ 32 5 ] loss: 0.5416469573974609 2022-05-29 14:03:35.177522
Epoch:[ 32 6 ] loss: 0.5403599739074707 2022-05-29 14:03:35.944450
Epoch:[ 32 7 ] loss: 0.5415757894515991 2022-05-29 14:03:36.710483
Epoch:[ 32 8 ] loss: 0.5339986681938171 2022-05-29 14:03:37.477681
Epoch:[ 32 9 ] loss: 0.5321897268295288 2022-05-29 14:03:38.244794
Epoch:[ 32 10 ] loss: 0.536527693271637 2022-05-29 14:03:39.010128
Epoch:[ 32 11 ] loss: 0.540617048740387 2022-05-29 14:03:39.776589
Epoch:[ 32 12 ] loss: 0.5358012914657593 2022-05-29 14:03:40.542681
Epoch:[ 32 13 ] loss: 0.5386924743652344 2022-05-29 14:03:41.309249
Epoch:[ 32 14 ] loss: 0.5375425219535828 2022-05-29 14:03:42.076993
Epoch:[ 32 15 ] loss: 0.5373739004135132 2022-05-29 14:03:42.843120
Epoch:[ 32 16 ] loss: 0.5333182215690613 2022-05-29 14:03:50.853253
Epoch:[ 32 17 ] loss: 0.5383533239364624 2022-05-29 14:03:51.618712
Epoch:[ 32 18 ] loss: 0.5393989682197571 2022-05-29 14:03:52.390166
Epoch:[ 32 19 ] loss: 0.5427149534225464 2022-05-29 14:03:53.153642
Training_Epoch:[ 32 ] Training_loss: 0.5380184918642044 2022-05-29 14:03:53.154385
learning rate:  0.0017149999999999995
netparams have been saved once 32
val: 1 0.5587080717086792
val: 2 0.5674512386322021
val: 3 0.5746777653694153
val: 4 0.5707928538322449
val: 5 0.5621195435523987
val: 6 0.5711632966995239
val: 7 0.5701080560684204
val: 8 0.5588836073875427
val: 9 0.5733669400215149
val: 10 0.5664409399032593
val: 11 0.5732868313789368
val: 12 0.5618070960044861
val: 13 0.5739248394966125
val: 14 0.5642980933189392
val: 15 0.5510138869285583
val: 16 0.564276397228241
val: 17 0.5622185468673706
val: 18 0.5741336941719055
val: 19 0.5641026496887207
val: 20 0.5559929013252258
val_Epoch:[ 32 ] val_loss: 0.5659383624792099 2022-05-29 14:03:59.061115
start training 2022-05-29 14:03:59.163057
Epoch:[ 33 0 ] loss: 0.5370587110519409 2022-05-29 14:04:24.099183
Epoch:[ 33 1 ] loss: 0.5356735587120056 2022-05-29 14:04:24.913651
Epoch:[ 33 2 ] loss: 0.5346354246139526 2022-05-29 14:04:25.704080
Epoch:[ 33 3 ] loss: 0.5380615592002869 2022-05-29 14:04:26.469779
Epoch:[ 33 4 ] loss: 0.5433465242385864 2022-05-29 14:04:27.236195
Epoch:[ 33 5 ] loss: 0.53456050157547 2022-05-29 14:04:28.003403
Epoch:[ 33 6 ] loss: 0.5409389138221741 2022-05-29 14:04:28.769066
Epoch:[ 33 7 ] loss: 0.5393643975257874 2022-05-29 14:04:29.534911
Epoch:[ 33 8 ] loss: 0.5360937714576721 2022-05-29 14:04:30.299234
Epoch:[ 33 9 ] loss: 0.5320743918418884 2022-05-29 14:04:31.065740
Epoch:[ 33 10 ] loss: 0.5345370769500732 2022-05-29 14:04:31.832255
Epoch:[ 33 11 ] loss: 0.5370942950248718 2022-05-29 14:04:32.598709
Epoch:[ 33 12 ] loss: 0.5360197424888611 2022-05-29 14:04:33.376681
Epoch:[ 33 13 ] loss: 0.5380565524101257 2022-05-29 14:04:34.143706
Epoch:[ 33 14 ] loss: 0.5364607572555542 2022-05-29 14:04:34.923477
Epoch:[ 33 15 ] loss: 0.5402900576591492 2022-05-29 14:04:35.690037
Epoch:[ 33 16 ] loss: 0.5402688980102539 2022-05-29 14:04:44.282617
Epoch:[ 33 17 ] loss: 0.5407039523124695 2022-05-29 14:04:45.049471
Epoch:[ 33 18 ] loss: 0.5410094261169434 2022-05-29 14:04:46.109028
Epoch:[ 33 19 ] loss: 0.5391689538955688 2022-05-29 14:04:46.879282
Training_Epoch:[ 33 ] Training_loss: 0.5377708733081817 2022-05-29 14:04:46.880145
learning rate:  0.0017149999999999995
val: 1 0.559885561466217
val: 2 0.5548044443130493
val: 3 0.5670693516731262
val: 4 0.5490970015525818
val: 5 0.5606897473335266
val: 6 0.551632821559906
val: 7 0.5752560496330261
val: 8 0.5577442646026611
val: 9 0.581261932849884
val: 10 0.5532462000846863
val: 11 0.5763754844665527
val: 12 0.5612083077430725
val: 13 0.5712903738021851
val: 14 0.5545937418937683
val: 15 0.5542413592338562
val: 16 0.5607890486717224
val: 17 0.568246066570282
val: 18 0.5678117871284485
val: 19 0.5796891450881958
val: 20 0.5657888054847717
val_Epoch:[ 33 ] val_loss: 0.5635360747575759 2022-05-29 14:04:52.537036
start training 2022-05-29 14:04:52.643998
Epoch:[ 34 0 ] loss: 0.5329836010932922 2022-05-29 14:05:18.463942
Epoch:[ 34 1 ] loss: 0.5348085761070251 2022-05-29 14:05:19.627225
Epoch:[ 34 2 ] loss: 0.5340275764465332 2022-05-29 14:05:20.393780
Epoch:[ 34 3 ] loss: 0.5397596955299377 2022-05-29 14:05:21.161308
Epoch:[ 34 4 ] loss: 0.5328121781349182 2022-05-29 14:05:21.928900
Epoch:[ 34 5 ] loss: 0.535780131816864 2022-05-29 14:05:22.707003
Epoch:[ 34 6 ] loss: 0.5420602560043335 2022-05-29 14:05:23.474601
Epoch:[ 34 7 ] loss: 0.5396667122840881 2022-05-29 14:05:24.240184
Epoch:[ 34 8 ] loss: 0.5371683835983276 2022-05-29 14:05:25.006438
Epoch:[ 34 9 ] loss: 0.5360158085823059 2022-05-29 14:05:25.775070
Epoch:[ 34 10 ] loss: 0.5352057814598083 2022-05-29 14:05:26.542617
Epoch:[ 34 11 ] loss: 0.5348369479179382 2022-05-29 14:05:27.309385
Epoch:[ 34 12 ] loss: 0.5369123816490173 2022-05-29 14:05:28.075429
Epoch:[ 34 13 ] loss: 0.5396728515625 2022-05-29 14:05:28.854723
Epoch:[ 34 14 ] loss: 0.5363648533821106 2022-05-29 14:05:29.620462
Epoch:[ 34 15 ] loss: 0.5409610867500305 2022-05-29 14:05:30.386117
Epoch:[ 34 16 ] loss: 0.5343733429908752 2022-05-29 14:05:38.014723
Epoch:[ 34 17 ] loss: 0.5379300117492676 2022-05-29 14:05:40.816238
Epoch:[ 34 18 ] loss: 0.5366064310073853 2022-05-29 14:05:41.588598
Epoch:[ 34 19 ] loss: 0.5334839224815369 2022-05-29 14:05:42.407465
Training_Epoch:[ 34 ] Training_loss: 0.5365715265274048 2022-05-29 14:05:42.408253
learning rate:  0.0017149999999999995
netparams have been saved once 34
val: 1 0.534343421459198
val: 2 0.5343477129936218
val: 3 0.5334133505821228
val: 4 0.5436487197875977
val: 5 0.5273431539535522
val: 6 0.5352739691734314
val: 7 0.5335953831672668
val: 8 0.5371054410934448
val: 9 0.5435282588005066
val: 10 0.5487363338470459
val: 11 0.5313957333564758
val: 12 0.5355266332626343
val: 13 0.564684271812439
val: 14 0.5412175059318542
val: 15 0.5333779454231262
val: 16 0.5308558940887451
val: 17 0.5315472483634949
val: 18 0.5206654667854309
val: 19 0.5497013926506042
val: 20 0.5423451066017151
val_Epoch:[ 34 ] val_loss: 0.5376326471567154 2022-05-29 14:05:48.039054
start training 2022-05-29 14:05:48.147088
Epoch:[ 35 0 ] loss: 0.5370692014694214 2022-05-29 14:06:15.254095
Epoch:[ 35 1 ] loss: 0.5335397124290466 2022-05-29 14:06:16.020787
Epoch:[ 35 2 ] loss: 0.5388275980949402 2022-05-29 14:06:16.788108
Epoch:[ 35 3 ] loss: 0.5356021523475647 2022-05-29 14:06:17.566713
Epoch:[ 35 4 ] loss: 0.537822961807251 2022-05-29 14:06:18.330340
Epoch:[ 35 5 ] loss: 0.5316466093063354 2022-05-29 14:06:19.097070
Epoch:[ 35 6 ] loss: 0.5389751195907593 2022-05-29 14:06:19.861809
Epoch:[ 35 7 ] loss: 0.5345556735992432 2022-05-29 14:06:20.626918
Epoch:[ 35 8 ] loss: 0.5327945351600647 2022-05-29 14:06:21.394597
Epoch:[ 35 9 ] loss: 0.5378169417381287 2022-05-29 14:06:22.158731
Epoch:[ 35 10 ] loss: 0.5324788689613342 2022-05-29 14:06:22.923343
Epoch:[ 35 11 ] loss: 0.5330098867416382 2022-05-29 14:06:23.690207
Epoch:[ 35 12 ] loss: 0.5371760725975037 2022-05-29 14:06:24.469467
Epoch:[ 35 13 ] loss: 0.53587406873703 2022-05-29 14:06:25.233916
Epoch:[ 35 14 ] loss: 0.5331563949584961 2022-05-29 14:06:26.001973
Epoch:[ 35 15 ] loss: 0.5344639420509338 2022-05-29 14:06:26.770252
Epoch:[ 35 16 ] loss: 0.536135196685791 2022-05-29 14:06:35.554447
Epoch:[ 35 17 ] loss: 0.5299468636512756 2022-05-29 14:06:36.337839
Epoch:[ 35 18 ] loss: 0.5335721373558044 2022-05-29 14:06:37.109870
Epoch:[ 35 19 ] loss: 0.5386192202568054 2022-05-29 14:06:37.879254
Training_Epoch:[ 35 ] Training_loss: 0.5351541578769684 2022-05-29 14:06:37.880093
learning rate:  0.0017149999999999995
val: 1 0.5687412619590759
val: 2 0.5714065432548523
val: 3 0.5852165818214417
val: 4 0.5480279922485352
val: 5 0.5500273108482361
val: 6 0.5694136023521423
val: 7 0.5720916390419006
val: 8 0.5595943331718445
val: 9 0.5691121816635132
val: 10 0.5573226809501648
val: 11 0.5561314225196838
val: 12 0.5673612952232361
val: 13 0.5629846453666687
val: 14 0.5737667679786682
val: 15 0.5645455718040466
val: 16 0.5713483095169067
val: 17 0.5648179650306702
val: 18 0.5642755031585693
val: 19 0.5686079263687134
val: 20 0.5563175678253174
val_Epoch:[ 35 ] val_loss: 0.5650555551052093 2022-05-29 14:06:43.466212
start training 2022-05-29 14:06:43.571355
Epoch:[ 36 0 ] loss: 0.538995623588562 2022-05-29 14:07:10.573535
Epoch:[ 36 1 ] loss: 0.5354209542274475 2022-05-29 14:07:11.339018
Epoch:[ 36 2 ] loss: 0.533050000667572 2022-05-29 14:07:12.103496
Epoch:[ 36 3 ] loss: 0.5390741229057312 2022-05-29 14:07:12.870205
Epoch:[ 36 4 ] loss: 0.5307447910308838 2022-05-29 14:07:13.646754
Epoch:[ 36 5 ] loss: 0.5356392860412598 2022-05-29 14:07:14.412242
Epoch:[ 36 6 ] loss: 0.5378695130348206 2022-05-29 14:07:15.179205
Epoch:[ 36 7 ] loss: 0.5355265736579895 2022-05-29 14:07:15.945598
Epoch:[ 36 8 ] loss: 0.5365940928459167 2022-05-29 14:07:16.712963
Epoch:[ 36 9 ] loss: 0.535923182964325 2022-05-29 14:07:17.478907
Epoch:[ 36 10 ] loss: 0.5368306636810303 2022-05-29 14:07:18.247484
Epoch:[ 36 11 ] loss: 0.5385252833366394 2022-05-29 14:07:19.017068
Epoch:[ 36 12 ] loss: 0.5398349165916443 2022-05-29 14:07:19.797831
Epoch:[ 36 13 ] loss: 0.5362452268600464 2022-05-29 14:07:20.568082
Epoch:[ 36 14 ] loss: 0.5337672829627991 2022-05-29 14:07:21.335529
Epoch:[ 36 15 ] loss: 0.5396292209625244 2022-05-29 14:07:22.107304
Epoch:[ 36 16 ] loss: 0.5342644453048706 2022-05-29 14:07:30.201246
Epoch:[ 36 17 ] loss: 0.5365326404571533 2022-05-29 14:07:30.981146
Epoch:[ 36 18 ] loss: 0.5401044487953186 2022-05-29 14:07:31.769430
Epoch:[ 36 19 ] loss: 0.5332074761390686 2022-05-29 14:07:32.535592
Training_Epoch:[ 36 ] Training_loss: 0.5363889873027802 2022-05-29 14:07:32.536324
learning rate:  0.0017149999999999995
netparams have been saved once 36
val: 1 0.5350866317749023
val: 2 0.5343406200408936
val: 3 0.5244842767715454
val: 4 0.5367583632469177
val: 5 0.5407721400260925
val: 6 0.5375745892524719
val: 7 0.5443825125694275
val: 8 0.5423218011856079
val: 9 0.5279207825660706
val: 10 0.5343621969223022
val: 11 0.5386120676994324
val: 12 0.5506137609481812
val: 13 0.5393151044845581
val: 14 0.5357091426849365
val: 15 0.5348817706108093
val: 16 0.5419751405715942
val: 17 0.5281308889389038
val: 18 0.5374960899353027
val: 19 0.5389797687530518
val: 20 0.5477087497711182
val_Epoch:[ 36 ] val_loss: 0.537571319937706 2022-05-29 14:07:38.126078
start training 2022-05-29 14:07:38.231979
Epoch:[ 37 0 ] loss: 0.534190833568573 2022-05-29 14:08:04.300414
Epoch:[ 37 1 ] loss: 0.5329135060310364 2022-05-29 14:08:05.099885
Epoch:[ 37 2 ] loss: 0.532447099685669 2022-05-29 14:08:05.867648
Epoch:[ 37 3 ] loss: 0.5351789593696594 2022-05-29 14:08:06.632466
Epoch:[ 37 4 ] loss: 0.5328602194786072 2022-05-29 14:08:07.397431
Epoch:[ 37 5 ] loss: 0.5355400443077087 2022-05-29 14:08:08.172453
Epoch:[ 37 6 ] loss: 0.5378326177597046 2022-05-29 14:08:08.938705
Epoch:[ 37 7 ] loss: 0.5319792032241821 2022-05-29 14:08:09.705775
Epoch:[ 37 8 ] loss: 0.5331614017486572 2022-05-29 14:08:10.475067
Epoch:[ 37 9 ] loss: 0.5338029861450195 2022-05-29 14:08:11.240699
Epoch:[ 37 10 ] loss: 0.5288977026939392 2022-05-29 14:08:12.008193
Epoch:[ 37 11 ] loss: 0.5260825753211975 2022-05-29 14:08:12.786711
Epoch:[ 37 12 ] loss: 0.5287731885910034 2022-05-29 14:08:13.550991
Epoch:[ 37 13 ] loss: 0.5350791215896606 2022-05-29 14:08:14.318051
Epoch:[ 37 14 ] loss: 0.5382137298583984 2022-05-29 14:08:15.084920
Epoch:[ 37 15 ] loss: 0.5323019623756409 2022-05-29 14:08:15.850618
Epoch:[ 37 16 ] loss: 0.5345301628112793 2022-05-29 14:08:23.328630
Epoch:[ 37 17 ] loss: 0.5338975191116333 2022-05-29 14:08:24.092000
Epoch:[ 37 18 ] loss: 0.5331865549087524 2022-05-29 14:08:26.173152
Epoch:[ 37 19 ] loss: 0.5357009768486023 2022-05-29 14:08:26.937067
Training_Epoch:[ 37 ] Training_loss: 0.5333285182714462 2022-05-29 14:08:26.937818
learning rate:  0.0017149999999999995
val: 1 0.5342686772346497
val: 2 0.5507858395576477
val: 3 0.5506491661071777
val: 4 0.5457758903503418
val: 5 0.5343208909034729
val: 6 0.5465365052223206
val: 7 0.5397928357124329
val: 8 0.5533272624015808
val: 9 0.5499288439750671
val: 10 0.5552828311920166
val: 11 0.5661888718605042
val: 12 0.5557357668876648
val: 13 0.5598944425582886
val: 14 0.5432520508766174
val: 15 0.5409833788871765
val: 16 0.5388880968093872
val: 17 0.5637552738189697
val: 18 0.5472834706306458
val: 19 0.5489869713783264
val: 20 0.5510096549987793
val_Epoch:[ 37 ] val_loss: 0.5488323360681534 2022-05-29 14:08:32.421235
start training 2022-05-29 14:08:32.530015
Epoch:[ 38 0 ] loss: 0.5320994257926941 2022-05-29 14:08:58.583420
Epoch:[ 38 1 ] loss: 0.5360518097877502 2022-05-29 14:08:59.351534
Epoch:[ 38 2 ] loss: 0.5316219925880432 2022-05-29 14:09:00.116969
Epoch:[ 38 3 ] loss: 0.5345906019210815 2022-05-29 14:09:00.882630
Epoch:[ 38 4 ] loss: 0.5378909707069397 2022-05-29 14:09:01.647659
Epoch:[ 38 5 ] loss: 0.5358480215072632 2022-05-29 14:09:02.413108
Epoch:[ 38 6 ] loss: 0.5376031994819641 2022-05-29 14:09:03.188567
Epoch:[ 38 7 ] loss: 0.531797468662262 2022-05-29 14:09:03.965104
Epoch:[ 38 8 ] loss: 0.5298689007759094 2022-05-29 14:09:04.731792
Epoch:[ 38 9 ] loss: 0.529256284236908 2022-05-29 14:09:05.497095
Epoch:[ 38 10 ] loss: 0.527852475643158 2022-05-29 14:09:06.262939
Epoch:[ 38 11 ] loss: 0.5316533446311951 2022-05-29 14:09:07.028674
Epoch:[ 38 12 ] loss: 0.5360977649688721 2022-05-29 14:09:07.794294
Epoch:[ 38 13 ] loss: 0.5337443947792053 2022-05-29 14:09:08.558935
Epoch:[ 38 14 ] loss: 0.5342445373535156 2022-05-29 14:09:09.323839
Epoch:[ 38 15 ] loss: 0.5266599059104919 2022-05-29 14:09:10.088974
Epoch:[ 38 16 ] loss: 0.532629668712616 2022-05-29 14:09:17.302605
Epoch:[ 38 17 ] loss: 0.5320837497711182 2022-05-29 14:09:20.007502
Epoch:[ 38 18 ] loss: 0.5333238244056702 2022-05-29 14:09:20.776713
Epoch:[ 38 19 ] loss: 0.5355387330055237 2022-05-29 14:09:21.539438
Training_Epoch:[ 38 ] Training_loss: 0.5330228537321091 2022-05-29 14:09:21.540197
learning rate:  0.0017149999999999995
netparams have been saved once 38
val: 1 0.5369488596916199
val: 2 0.5375980734825134
val: 3 0.516985297203064
val: 4 0.5481143593788147
val: 5 0.5352160334587097
val: 6 0.512140691280365
val: 7 0.5369540452957153
val: 8 0.538366436958313
val: 9 0.5260893106460571
val: 10 0.5222901105880737
val: 11 0.5432875156402588
val: 12 0.5428977012634277
val: 13 0.5385197401046753
val: 14 0.549133837223053
val: 15 0.540264904499054
val: 16 0.5430683493614197
val: 17 0.5445160269737244
val: 18 0.5428215265274048
val: 19 0.5290299654006958
val: 20 0.5286983251571655
val_Epoch:[ 38 ] val_loss: 0.5356470555067062 2022-05-29 14:09:27.110500
start training 2022-05-29 14:09:27.218979
Epoch:[ 39 0 ] loss: 0.5272007584571838 2022-05-29 14:09:53.885148
Epoch:[ 39 1 ] loss: 0.527776300907135 2022-05-29 14:09:54.650064
Epoch:[ 39 2 ] loss: 0.5290482044219971 2022-05-29 14:09:55.416259
Epoch:[ 39 3 ] loss: 0.5374030470848083 2022-05-29 14:09:56.179898
Epoch:[ 39 4 ] loss: 0.5324039459228516 2022-05-29 14:09:56.946669
Epoch:[ 39 5 ] loss: 0.5302295088768005 2022-05-29 14:09:57.712634
Epoch:[ 39 6 ] loss: 0.533111572265625 2022-05-29 14:09:58.476963
Epoch:[ 39 7 ] loss: 0.5323558449745178 2022-05-29 14:09:59.243089
Epoch:[ 39 8 ] loss: 0.5309780240058899 2022-05-29 14:10:00.007945
Epoch:[ 39 9 ] loss: 0.5354948043823242 2022-05-29 14:10:00.787166
Epoch:[ 39 10 ] loss: 0.5310147404670715 2022-05-29 14:10:01.551609
Epoch:[ 39 11 ] loss: 0.536073625087738 2022-05-29 14:10:02.318968
Epoch:[ 39 12 ] loss: 0.5331034660339355 2022-05-29 14:10:03.099809
Epoch:[ 39 13 ] loss: 0.5317634344100952 2022-05-29 14:10:03.864887
Epoch:[ 39 14 ] loss: 0.5313993692398071 2022-05-29 14:10:04.629917
Epoch:[ 39 15 ] loss: 0.5311225652694702 2022-05-29 14:10:05.393445
Epoch:[ 39 16 ] loss: 0.5323245525360107 2022-05-29 14:10:14.824340
Epoch:[ 39 17 ] loss: 0.5333113670349121 2022-05-29 14:10:15.588257
Epoch:[ 39 18 ] loss: 0.5335091352462769 2022-05-29 14:10:16.376567
Epoch:[ 39 19 ] loss: 0.5289928913116455 2022-05-29 14:10:17.140650
Training_Epoch:[ 39 ] Training_loss: 0.5319308578968048 2022-05-29 14:10:17.141472
learning rate:  0.0017149999999999995
val: 1 0.5429091453552246
val: 2 0.5313576459884644
val: 3 0.5480049252510071
val: 4 0.5449835658073425
val: 5 0.5543377995491028
val: 6 0.5436844825744629
val: 7 0.5303421020507812
val: 8 0.532941997051239
val: 9 0.542088508605957
val: 10 0.5398826003074646
val: 11 0.5587900280952454
val: 12 0.5391755104064941
val: 13 0.5204306840896606
val: 14 0.5360403656959534
val: 15 0.5495682954788208
val: 16 0.5403484106063843
val: 17 0.5466122627258301
val: 18 0.5451568961143494
val: 19 0.5335764288902283
val: 20 0.5646216869354248
val_Epoch:[ 39 ] val_loss: 0.5422426670789718 2022-05-29 14:10:22.729291
start training 2022-05-29 14:10:22.841868
Epoch:[ 40 0 ] loss: 0.5332549810409546 2022-05-29 14:10:48.636568
Epoch:[ 40 1 ] loss: 0.530266284942627 2022-05-29 14:10:49.420060
Epoch:[ 40 2 ] loss: 0.5266809463500977 2022-05-29 14:10:50.184376
Epoch:[ 40 3 ] loss: 0.5389300584793091 2022-05-29 14:10:50.952300
Epoch:[ 40 4 ] loss: 0.5328510999679565 2022-05-29 14:10:51.729665
Epoch:[ 40 5 ] loss: 0.5275379419326782 2022-05-29 14:10:52.506841
Epoch:[ 40 6 ] loss: 0.5304169654846191 2022-05-29 14:10:53.270020
Epoch:[ 40 7 ] loss: 0.5315223932266235 2022-05-29 14:10:54.037220
Epoch:[ 40 8 ] loss: 0.5334782004356384 2022-05-29 14:10:54.801252
Epoch:[ 40 9 ] loss: 0.5308282375335693 2022-05-29 14:10:55.566382
Epoch:[ 40 10 ] loss: 0.5288407206535339 2022-05-29 14:10:56.332927
Epoch:[ 40 11 ] loss: 0.5302398800849915 2022-05-29 14:10:57.098398
Epoch:[ 40 12 ] loss: 0.5327786207199097 2022-05-29 14:10:57.863498
Epoch:[ 40 13 ] loss: 0.5345030426979065 2022-05-29 14:10:58.628517
Epoch:[ 40 14 ] loss: 0.5339841246604919 2022-05-29 14:10:59.394386
Epoch:[ 40 15 ] loss: 0.5325881838798523 2022-05-29 14:11:00.160072
Epoch:[ 40 16 ] loss: 0.537950336933136 2022-05-29 14:11:08.047434
Epoch:[ 40 17 ] loss: 0.5296752452850342 2022-05-29 14:11:08.812955
Epoch:[ 40 18 ] loss: 0.5329249501228333 2022-05-29 14:11:09.578049
Epoch:[ 40 19 ] loss: 0.5291844010353088 2022-05-29 14:11:10.738206
Training_Epoch:[ 40 ] Training_loss: 0.5319218307733535 2022-05-29 14:11:10.738941
learning rate:  0.0017149999999999995
netparams have been saved once 40
val: 1 0.5539060831069946
val: 2 0.5547562837600708
val: 3 0.5439782738685608
val: 4 0.5517542362213135
val: 5 0.5468412637710571
val: 6 0.5472421050071716
val: 7 0.5505282282829285
val: 8 0.5626682639122009
val: 9 0.5587806105613708
val: 10 0.5493086576461792
val: 11 0.5457366704940796
val: 12 0.5508636832237244
val: 13 0.5428141355514526
val: 14 0.5476494431495667
val: 15 0.5447234511375427
val: 16 0.5543505549430847
val: 17 0.533994197845459
val: 18 0.5403673052787781
val: 19 0.5496050119400024
val: 20 0.557836651802063
val_Epoch:[ 40 ] val_loss: 0.54938525557518 2022-05-29 14:11:16.697858
start training 2022-05-29 14:11:16.812441
Epoch:[ 41 0 ] loss: 0.530197024345398 2022-05-29 14:11:41.654307
Epoch:[ 41 1 ] loss: 0.5302125215530396 2022-05-29 14:11:43.163460
Epoch:[ 41 2 ] loss: 0.5310801267623901 2022-05-29 14:11:43.928708
Epoch:[ 41 3 ] loss: 0.5328851342201233 2022-05-29 14:11:44.693127
Epoch:[ 41 4 ] loss: 0.5288636684417725 2022-05-29 14:11:45.470306
Epoch:[ 41 5 ] loss: 0.5294234156608582 2022-05-29 14:11:46.237681
Epoch:[ 41 6 ] loss: 0.525935709476471 2022-05-29 14:11:47.006985
Epoch:[ 41 7 ] loss: 0.5302042365074158 2022-05-29 14:11:47.772659
Epoch:[ 41 8 ] loss: 0.525773286819458 2022-05-29 14:11:48.536128
Epoch:[ 41 9 ] loss: 0.5300772190093994 2022-05-29 14:11:49.301274
Epoch:[ 41 10 ] loss: 0.5239768028259277 2022-05-29 14:11:50.068044
Epoch:[ 41 11 ] loss: 0.5307697653770447 2022-05-29 14:11:50.835395
Epoch:[ 41 12 ] loss: 0.5268470644950867 2022-05-29 14:11:51.602435
Epoch:[ 41 13 ] loss: 0.5306547284126282 2022-05-29 14:11:52.369524
Epoch:[ 41 14 ] loss: 0.5284844636917114 2022-05-29 14:11:53.137355
Epoch:[ 41 15 ] loss: 0.5322328209877014 2022-05-29 14:11:53.905852
Epoch:[ 41 16 ] loss: 0.5255705118179321 2022-05-29 14:12:02.983251
Epoch:[ 41 17 ] loss: 0.5246124267578125 2022-05-29 14:12:03.749988
Epoch:[ 41 18 ] loss: 0.5291475653648376 2022-05-29 14:12:04.518905
Epoch:[ 41 19 ] loss: 0.5268650054931641 2022-05-29 14:12:05.285997
Training_Epoch:[ 41 ] Training_loss: 0.5286906749010086 2022-05-29 14:12:05.286742
learning rate:  0.0012004999999999995
val: 1 0.5369678735733032
val: 2 0.5313567519187927
val: 3 0.5441000461578369
val: 4 0.5472401976585388
val: 5 0.518863320350647
val: 6 0.5517137050628662
val: 7 0.554401159286499
val: 8 0.5348180532455444
val: 9 0.5467670559883118
val: 10 0.523490846157074
val: 11 0.5257734656333923
val: 12 0.5311862230300903
val: 13 0.5318220853805542
val: 14 0.5276936292648315
val: 15 0.536374032497406
val: 16 0.5282092094421387
val: 17 0.5475988388061523
val: 18 0.5369303822517395
val: 19 0.5391257405281067
val: 20 0.5308495163917542
val_Epoch:[ 41 ] val_loss: 0.536264106631279 2022-05-29 14:12:10.862879
start training 2022-05-29 14:12:10.973207
Epoch:[ 42 0 ] loss: 0.5271368026733398 2022-05-29 14:12:36.660285
Epoch:[ 42 1 ] loss: 0.5255529284477234 2022-05-29 14:12:37.471694
Epoch:[ 42 2 ] loss: 0.5257587432861328 2022-05-29 14:12:38.239487
Epoch:[ 42 3 ] loss: 0.5269508957862854 2022-05-29 14:12:39.004799
Epoch:[ 42 4 ] loss: 0.5256403088569641 2022-05-29 14:12:39.770043
Epoch:[ 42 5 ] loss: 0.5283085107803345 2022-05-29 14:12:40.537512
Epoch:[ 42 6 ] loss: 0.5260410904884338 2022-05-29 14:12:41.303205
Epoch:[ 42 7 ] loss: 0.5324088335037231 2022-05-29 14:12:42.068184
Epoch:[ 42 8 ] loss: 0.5277711153030396 2022-05-29 14:12:42.833917
Epoch:[ 42 9 ] loss: 0.5202702879905701 2022-05-29 14:12:43.599958
Epoch:[ 42 10 ] loss: 0.5301879644393921 2022-05-29 14:12:44.375441
Epoch:[ 42 11 ] loss: 0.5289028882980347 2022-05-29 14:12:45.138969
Epoch:[ 42 12 ] loss: 0.5216708779335022 2022-05-29 14:12:45.905985
Epoch:[ 42 13 ] loss: 0.5259482860565186 2022-05-29 14:12:46.672321
Epoch:[ 42 14 ] loss: 0.5255835056304932 2022-05-29 14:12:47.438631
Epoch:[ 42 15 ] loss: 0.5291633009910583 2022-05-29 14:12:48.205532
Epoch:[ 42 16 ] loss: 0.5244781374931335 2022-05-29 14:12:55.910740
Epoch:[ 42 17 ] loss: 0.5270854234695435 2022-05-29 14:12:56.676249
Epoch:[ 42 18 ] loss: 0.5301305055618286 2022-05-29 14:12:57.461031
Epoch:[ 42 19 ] loss: 0.5266870260238647 2022-05-29 14:12:58.226212
Training_Epoch:[ 42 ] Training_loss: 0.5267838716506958 2022-05-29 14:12:58.227002
learning rate:  0.0012004999999999995
netparams have been saved once 42
val: 1 0.5360613465309143
val: 2 0.5336528420448303
val: 3 0.5365197658538818
val: 4 0.5437280535697937
val: 5 0.5384575128555298
val: 6 0.5427886247634888
val: 7 0.5269260406494141
val: 8 0.5146927833557129
val: 9 0.5395781993865967
val: 10 0.5235332250595093
val: 11 0.5202602744102478
val: 12 0.5419286489486694
val: 13 0.5297604203224182
val: 14 0.5291154980659485
val: 15 0.5250552892684937
val: 16 0.5255980491638184
val: 17 0.5200991630554199
val: 18 0.5398858189582825
val: 19 0.5458086133003235
val: 20 0.5293195247650146
val_Epoch:[ 42 ] val_loss: 0.5321384847164154 2022-05-29 14:13:03.892072
start training 2022-05-29 14:13:03.991434
Epoch:[ 43 0 ] loss: 0.5266015529632568 2022-05-29 14:13:29.335588
Epoch:[ 43 1 ] loss: 0.526567816734314 2022-05-29 14:13:30.143298
Epoch:[ 43 2 ] loss: 0.5249404907226562 2022-05-29 14:13:30.909544
Epoch:[ 43 3 ] loss: 0.525373637676239 2022-05-29 14:13:31.673923
Epoch:[ 43 4 ] loss: 0.5332533717155457 2022-05-29 14:13:32.441869
Epoch:[ 43 5 ] loss: 0.526875376701355 2022-05-29 14:13:33.207746
Epoch:[ 43 6 ] loss: 0.5276116132736206 2022-05-29 14:13:33.973412
Epoch:[ 43 7 ] loss: 0.5240915417671204 2022-05-29 14:13:34.738917
Epoch:[ 43 8 ] loss: 0.5286070108413696 2022-05-29 14:13:35.506265
Epoch:[ 43 9 ] loss: 0.5270829200744629 2022-05-29 14:13:36.271782
Epoch:[ 43 10 ] loss: 0.5242098569869995 2022-05-29 14:13:37.036142
Epoch:[ 43 11 ] loss: 0.5257334113121033 2022-05-29 14:13:37.813165
Epoch:[ 43 12 ] loss: 0.5180705785751343 2022-05-29 14:13:38.580323
Epoch:[ 43 13 ] loss: 0.5198556184768677 2022-05-29 14:13:39.345953
Epoch:[ 43 14 ] loss: 0.5261673331260681 2022-05-29 14:13:40.124510
Epoch:[ 43 15 ] loss: 0.5255395770072937 2022-05-29 14:13:40.889998
Epoch:[ 43 16 ] loss: 0.5217198729515076 2022-05-29 14:13:48.881316
Epoch:[ 43 17 ] loss: 0.5270520448684692 2022-05-29 14:13:49.646590
Epoch:[ 43 18 ] loss: 0.5252552032470703 2022-05-29 14:13:50.429307
Epoch:[ 43 19 ] loss: 0.5267595648765564 2022-05-29 14:13:51.194716
Training_Epoch:[ 43 ] Training_loss: 0.5255684196949005 2022-05-29 14:13:51.195479
learning rate:  0.0012004999999999995
val: 1 0.5338916182518005
val: 2 0.5362082123756409
val: 3 0.5379551649093628
val: 4 0.5303314328193665
val: 5 0.5201916098594666
val: 6 0.5414963960647583
val: 7 0.5378270149230957
val: 8 0.5267776250839233
val: 9 0.5282930135726929
val: 10 0.526265561580658
val: 11 0.5453692674636841
val: 12 0.5182409286499023
val: 13 0.5194137692451477
val: 14 0.5309603214263916
val: 15 0.5215859413146973
val: 16 0.5284059047698975
val: 17 0.5314462184906006
val: 18 0.5345722436904907
val: 19 0.5481249094009399
val: 20 0.5208786725997925
val_Epoch:[ 43 ] val_loss: 0.5309117913246155 2022-05-29 14:13:56.788090
start training 2022-05-29 14:13:56.894110
Epoch:[ 44 0 ] loss: 0.5311838388442993 2022-05-29 14:14:22.761215
Epoch:[ 44 1 ] loss: 0.5245979428291321 2022-05-29 14:14:23.598973
Epoch:[ 44 2 ] loss: 0.5261759757995605 2022-05-29 14:14:24.365552
Epoch:[ 44 3 ] loss: 0.532351016998291 2022-05-29 14:14:25.132976
Epoch:[ 44 4 ] loss: 0.5194039940834045 2022-05-29 14:14:25.899537
Epoch:[ 44 5 ] loss: 0.5260887145996094 2022-05-29 14:14:26.664907
Epoch:[ 44 6 ] loss: 0.5243289470672607 2022-05-29 14:14:27.432820
Epoch:[ 44 7 ] loss: 0.5215026140213013 2022-05-29 14:14:28.201257
Epoch:[ 44 8 ] loss: 0.5216859579086304 2022-05-29 14:14:28.967492
Epoch:[ 44 9 ] loss: 0.5229342579841614 2022-05-29 14:14:29.744609
Epoch:[ 44 10 ] loss: 0.5249247550964355 2022-05-29 14:14:30.511116
Epoch:[ 44 11 ] loss: 0.522275447845459 2022-05-29 14:14:31.278243
Epoch:[ 44 12 ] loss: 0.5269389152526855 2022-05-29 14:14:32.043078
Epoch:[ 44 13 ] loss: 0.5277183651924133 2022-05-29 14:14:32.809462
Epoch:[ 44 14 ] loss: 0.5194559693336487 2022-05-29 14:14:33.578548
Epoch:[ 44 15 ] loss: 0.5246466398239136 2022-05-29 14:14:34.361502
Epoch:[ 44 16 ] loss: 0.5245922803878784 2022-05-29 14:14:42.068467
Epoch:[ 44 17 ] loss: 0.5217461585998535 2022-05-29 14:14:42.856298
Epoch:[ 44 18 ] loss: 0.5247794985771179 2022-05-29 14:14:44.844823
Epoch:[ 44 19 ] loss: 0.5213173627853394 2022-05-29 14:14:45.608595
Training_Epoch:[ 44 ] Training_loss: 0.5244324326515197 2022-05-29 14:14:45.609328
learning rate:  0.0012004999999999995
netparams have been saved once 44
val: 1 0.5322422385215759
val: 2 0.545978307723999
val: 3 0.5402336120605469
val: 4 0.5450490117073059
val: 5 0.5504483580589294
val: 6 0.5498332381248474
val: 7 0.5450596809387207
val: 8 0.5457457900047302
val: 9 0.5494825839996338
val: 10 0.5390006899833679
val: 11 0.5333471894264221
val: 12 0.558724045753479
val: 13 0.5502955317497253
val: 14 0.5429474115371704
val: 15 0.5636072158813477
val: 16 0.5414710640907288
val: 17 0.5461660623550415
val: 18 0.5516389012336731
val: 19 0.5406064391136169
val: 20 0.528713047504425
val_Epoch:[ 44 ] val_loss: 0.5450295209884644 2022-05-29 14:14:51.274275
start training 2022-05-29 14:14:51.377897
Epoch:[ 45 0 ] loss: 0.5260632634162903 2022-05-29 14:15:17.221390
Epoch:[ 45 1 ] loss: 0.516386866569519 2022-05-29 14:15:18.038208
Epoch:[ 45 2 ] loss: 0.5258176326751709 2022-05-29 14:15:18.806627
Epoch:[ 45 3 ] loss: 0.525635838508606 2022-05-29 14:15:19.572687
Epoch:[ 45 4 ] loss: 0.5247400999069214 2022-05-29 14:15:20.339939
Epoch:[ 45 5 ] loss: 0.5225863456726074 2022-05-29 14:15:21.104792
Epoch:[ 45 6 ] loss: 0.5219805240631104 2022-05-29 14:15:21.868400
Epoch:[ 45 7 ] loss: 0.5212905406951904 2022-05-29 14:15:22.635503
Epoch:[ 45 8 ] loss: 0.5264445543289185 2022-05-29 14:15:23.403384
Epoch:[ 45 9 ] loss: 0.5289031863212585 2022-05-29 14:15:24.168606
Epoch:[ 45 10 ] loss: 0.5215234160423279 2022-05-29 14:15:24.936956
Epoch:[ 45 11 ] loss: 0.5262420773506165 2022-05-29 14:15:25.715357
Epoch:[ 45 12 ] loss: 0.5258983373641968 2022-05-29 14:15:26.480383
Epoch:[ 45 13 ] loss: 0.527125358581543 2022-05-29 14:15:27.244804
Epoch:[ 45 14 ] loss: 0.5226234197616577 2022-05-29 14:15:28.012175
Epoch:[ 45 15 ] loss: 0.5260959267616272 2022-05-29 14:15:28.779817
Epoch:[ 45 16 ] loss: 0.52976393699646 2022-05-29 14:15:36.509124
Epoch:[ 45 17 ] loss: 0.5218167901039124 2022-05-29 14:15:37.272203
Epoch:[ 45 18 ] loss: 0.5284538865089417 2022-05-29 14:15:38.041670
Epoch:[ 45 19 ] loss: 0.523345947265625 2022-05-29 14:15:38.806687
Training_Epoch:[ 45 ] Training_loss: 0.5246368974447251 2022-05-29 14:15:38.807463
learning rate:  0.0012004999999999995
val: 1 0.5391062498092651
val: 2 0.5412065386772156
val: 3 0.54798424243927
val: 4 0.5362222790718079
val: 5 0.5404572486877441
val: 6 0.525638997554779
val: 7 0.5375255346298218
val: 8 0.5277117490768433
val: 9 0.5247047543525696
val: 10 0.5539859533309937
val: 11 0.5501916408538818
val: 12 0.5387919545173645
val: 13 0.5400114059448242
val: 14 0.5315609574317932
val: 15 0.5352163314819336
val: 16 0.5367611050605774
val: 17 0.5234556794166565
val: 18 0.5305381417274475
val: 19 0.558408796787262
val: 20 0.5252033472061157
val_Epoch:[ 45 ] val_loss: 0.5372341454029084 2022-05-29 14:15:44.524740
start training 2022-05-29 14:15:44.627388
Epoch:[ 46 0 ] loss: 0.5194146037101746 2022-05-29 14:16:10.339300
Epoch:[ 46 1 ] loss: 0.5204368233680725 2022-05-29 14:16:11.139802
Epoch:[ 46 2 ] loss: 0.5282164812088013 2022-05-29 14:16:11.920297
Epoch:[ 46 3 ] loss: 0.5242428779602051 2022-05-29 14:16:12.685971
Epoch:[ 46 4 ] loss: 0.5267059803009033 2022-05-29 14:16:13.452321
Epoch:[ 46 5 ] loss: 0.5235657095909119 2022-05-29 14:16:14.218752
Epoch:[ 46 6 ] loss: 0.5229864120483398 2022-05-29 14:16:14.990057
Epoch:[ 46 7 ] loss: 0.5234791040420532 2022-05-29 14:16:15.756166
Epoch:[ 46 8 ] loss: 0.5247766375541687 2022-05-29 14:16:16.523271
Epoch:[ 46 9 ] loss: 0.5204921960830688 2022-05-29 14:16:17.291212
Epoch:[ 46 10 ] loss: 0.5198581218719482 2022-05-29 14:16:18.059196
Epoch:[ 46 11 ] loss: 0.5182140469551086 2022-05-29 14:16:18.826296
Epoch:[ 46 12 ] loss: 0.5179182887077332 2022-05-29 14:16:19.603568
Epoch:[ 46 13 ] loss: 0.5202934741973877 2022-05-29 14:16:20.368125
Epoch:[ 46 14 ] loss: 0.5221726894378662 2022-05-29 14:16:21.135367
Epoch:[ 46 15 ] loss: 0.5218342542648315 2022-05-29 14:16:21.901895
Epoch:[ 46 16 ] loss: 0.5241591334342957 2022-05-29 14:16:29.503101
Epoch:[ 46 17 ] loss: 0.5186034440994263 2022-05-29 14:16:30.267756
Epoch:[ 46 18 ] loss: 0.5211193561553955 2022-05-29 14:16:31.037558
Epoch:[ 46 19 ] loss: 0.5244712829589844 2022-05-29 14:16:31.802363
Training_Epoch:[ 46 ] Training_loss: 0.5221480458974839 2022-05-29 14:16:31.803079
learning rate:  0.0012004999999999995
netparams have been saved once 46
val: 1 0.5483484268188477
val: 2 0.5247958302497864
val: 3 0.5314632654190063
val: 4 0.5426750183105469
val: 5 0.5398144721984863
val: 6 0.526053249835968
val: 7 0.5454598069190979
val: 8 0.5215212106704712
val: 9 0.5323449373245239
val: 10 0.5414684414863586
val: 11 0.5306341648101807
val: 12 0.5444451570510864
val: 13 0.52901691198349
val: 14 0.5358424186706543
val: 15 0.5371984243392944
val: 16 0.5403035283088684
val: 17 0.533065676689148
val: 18 0.5440515279769897
val: 19 0.5239446759223938
val: 20 0.5419647097587585
val_Epoch:[ 46 ] val_loss: 0.5357205927371979 2022-05-29 14:16:37.464683
start training 2022-05-29 14:16:37.568713
Epoch:[ 47 0 ] loss: 0.5240945219993591 2022-05-29 14:17:04.163828
Epoch:[ 47 1 ] loss: 0.5156744718551636 2022-05-29 14:17:04.928837
Epoch:[ 47 2 ] loss: 0.5253872871398926 2022-05-29 14:17:05.693354
Epoch:[ 47 3 ] loss: 0.5248506665229797 2022-05-29 14:17:06.459636
Epoch:[ 47 4 ] loss: 0.5182892084121704 2022-05-29 14:17:07.225182
Epoch:[ 47 5 ] loss: 0.5254311561584473 2022-05-29 14:17:07.992446
Epoch:[ 47 6 ] loss: 0.5232059359550476 2022-05-29 14:17:08.758291
Epoch:[ 47 7 ] loss: 0.5235559344291687 2022-05-29 14:17:09.525928
Epoch:[ 47 8 ] loss: 0.5220089554786682 2022-05-29 14:17:10.293429
Epoch:[ 47 9 ] loss: 0.5269985198974609 2022-05-29 14:17:11.072158
Epoch:[ 47 10 ] loss: 0.5204443335533142 2022-05-29 14:17:11.839398
Epoch:[ 47 11 ] loss: 0.5269869565963745 2022-05-29 14:17:12.608169
Epoch:[ 47 12 ] loss: 0.5236461162567139 2022-05-29 14:17:13.374019
Epoch:[ 47 13 ] loss: 0.5173823833465576 2022-05-29 14:17:14.140083
Epoch:[ 47 14 ] loss: 0.5221976637840271 2022-05-29 14:17:14.907472
Epoch:[ 47 15 ] loss: 0.5190438032150269 2022-05-29 14:17:15.673713
Epoch:[ 47 16 ] loss: 0.5247321724891663 2022-05-29 14:17:25.169158
Epoch:[ 47 17 ] loss: 0.5179185271263123 2022-05-29 14:17:25.935474
Epoch:[ 47 18 ] loss: 0.5285666584968567 2022-05-29 14:17:26.704598
Epoch:[ 47 19 ] loss: 0.5254892110824585 2022-05-29 14:17:27.503249
Training_Epoch:[ 47 ] Training_loss: 0.5227952241897583 2022-05-29 14:17:27.504028
learning rate:  0.0012004999999999995
val: 1 0.5318818092346191
val: 2 0.5399627685546875
val: 3 0.5419605374336243
val: 4 0.5358810424804688
val: 5 0.5563660860061646
val: 6 0.5326737761497498
val: 7 0.5336704850196838
val: 8 0.5327351093292236
val: 9 0.5346983075141907
val: 10 0.5472270846366882
val: 11 0.5283849239349365
val: 12 0.5322110652923584
val: 13 0.5473642945289612
val: 14 0.5500541925430298
val: 15 0.5303366780281067
val: 16 0.5329381823539734
val: 17 0.546585738658905
val: 18 0.5256786346435547
val: 19 0.5310556888580322
val: 20 0.5497565269470215
val_Epoch:[ 47 ] val_loss: 0.538071146607399 2022-05-29 14:17:33.115615
start training 2022-05-29 14:17:33.220528
Epoch:[ 48 0 ] loss: 0.5247199535369873 2022-05-29 14:17:59.030084
Epoch:[ 48 1 ] loss: 0.5213041305541992 2022-05-29 14:17:59.870808
Epoch:[ 48 2 ] loss: 0.5254355072975159 2022-05-29 14:18:00.636849
Epoch:[ 48 3 ] loss: 0.5204308032989502 2022-05-29 14:18:01.404069
Epoch:[ 48 4 ] loss: 0.5269245505332947 2022-05-29 14:18:02.173789
Epoch:[ 48 5 ] loss: 0.5214619040489197 2022-05-29 14:18:02.955702
Epoch:[ 48 6 ] loss: 0.522234320640564 2022-05-29 14:18:03.723738
Epoch:[ 48 7 ] loss: 0.5162832736968994 2022-05-29 14:18:04.491062
Epoch:[ 48 8 ] loss: 0.5199364423751831 2022-05-29 14:18:05.258410
Epoch:[ 48 9 ] loss: 0.5209121108055115 2022-05-29 14:18:06.024489
Epoch:[ 48 10 ] loss: 0.5181653499603271 2022-05-29 14:18:06.791548
Epoch:[ 48 11 ] loss: 0.530339777469635 2022-05-29 14:18:07.560434
Epoch:[ 48 12 ] loss: 0.5180625915527344 2022-05-29 14:18:08.339116
Epoch:[ 48 13 ] loss: 0.5263047814369202 2022-05-29 14:18:09.106629
Epoch:[ 48 14 ] loss: 0.5221769213676453 2022-05-29 14:18:09.872667
Epoch:[ 48 15 ] loss: 0.5263935923576355 2022-05-29 14:18:10.639999
Epoch:[ 48 16 ] loss: 0.520558774471283 2022-05-29 14:18:17.961330
Epoch:[ 48 17 ] loss: 0.5167154669761658 2022-05-29 14:18:18.726051
Epoch:[ 48 18 ] loss: 0.5226313471794128 2022-05-29 14:18:19.513861
Epoch:[ 48 19 ] loss: 0.5200579762458801 2022-05-29 14:18:20.277748
Training_Epoch:[ 48 ] Training_loss: 0.5220524787902832 2022-05-29 14:18:20.278516
learning rate:  0.0012004999999999995
netparams have been saved once 48
val: 1 0.5273343920707703
val: 2 0.5159915685653687
val: 3 0.540866494178772
val: 4 0.5419430732727051
val: 5 0.5351300239562988
val: 6 0.5059718489646912
val: 7 0.5324108004570007
val: 8 0.5486204028129578
val: 9 0.5326839685440063
val: 10 0.5291069149971008
val: 11 0.5446289777755737
val: 12 0.5212981104850769
val: 13 0.5258858799934387
val: 14 0.5287348031997681
val: 15 0.5299761891365051
val: 16 0.5415955781936646
val: 17 0.5284767150878906
val: 18 0.537268877029419
val: 19 0.539808988571167
val: 20 0.5223171710968018
val_Epoch:[ 48 ] val_loss: 0.5315025389194489 2022-05-29 14:18:25.966818
start training 2022-05-29 14:18:26.066940
Epoch:[ 49 0 ] loss: 0.5193330645561218 2022-05-29 14:18:52.327897
Epoch:[ 49 1 ] loss: 0.5194241404533386 2022-05-29 14:18:53.135257
Epoch:[ 49 2 ] loss: 0.5262947082519531 2022-05-29 14:18:53.901478
Epoch:[ 49 3 ] loss: 0.5190737247467041 2022-05-29 14:18:54.668819
Epoch:[ 49 4 ] loss: 0.5179452300071716 2022-05-29 14:18:55.436129
Epoch:[ 49 5 ] loss: 0.5203964710235596 2022-05-29 14:18:56.205367
Epoch:[ 49 6 ] loss: 0.5225549936294556 2022-05-29 14:18:56.986927
Epoch:[ 49 7 ] loss: 0.5203081369400024 2022-05-29 14:18:57.755962
Epoch:[ 49 8 ] loss: 0.5223900079727173 2022-05-29 14:18:58.525301
Epoch:[ 49 9 ] loss: 0.5220970511436462 2022-05-29 14:18:59.291052
Epoch:[ 49 10 ] loss: 0.5230000615119934 2022-05-29 14:19:00.057460
Epoch:[ 49 11 ] loss: 0.5159022808074951 2022-05-29 14:19:00.821935
Epoch:[ 49 12 ] loss: 0.5186979174613953 2022-05-29 14:19:01.590023
Epoch:[ 49 13 ] loss: 0.5203554034233093 2022-05-29 14:19:02.368540
Epoch:[ 49 14 ] loss: 0.5258917212486267 2022-05-29 14:19:03.136217
Epoch:[ 49 15 ] loss: 0.5164226293563843 2022-05-29 14:19:03.902614
Epoch:[ 49 16 ] loss: 0.519208550453186 2022-05-29 14:19:11.455258
Epoch:[ 49 17 ] loss: 0.5190772414207458 2022-05-29 14:19:12.216702
Epoch:[ 49 18 ] loss: 0.5215035676956177 2022-05-29 14:19:12.987099
Epoch:[ 49 19 ] loss: 0.5172534584999084 2022-05-29 14:19:13.751540
Training_Epoch:[ 49 ] Training_loss: 0.5203565180301666 2022-05-29 14:19:13.752349
learning rate:  0.0012004999999999995
val: 1 0.5348637104034424
val: 2 0.5425420999526978
val: 3 0.5111247897148132
val: 4 0.5212915539741516
val: 5 0.5100062489509583
val: 6 0.517143964767456
val: 7 0.5334526300430298
val: 8 0.5332261323928833
val: 9 0.5246948003768921
val: 10 0.5235773324966431
val: 11 0.5427566170692444
val: 12 0.5206181406974792
val: 13 0.5375428795814514
val: 14 0.5232062935829163
val: 15 0.5190045237541199
val: 16 0.5128229260444641
val: 17 0.5091027617454529
val: 18 0.5229285955429077
val: 19 0.5216875672340393
val: 20 0.5341638326644897
val_Epoch:[ 49 ] val_loss: 0.5247878700494766 2022-05-29 14:19:19.316821
start training 2022-05-29 14:19:19.421302
Epoch:[ 50 0 ] loss: 0.5196706652641296 2022-05-29 14:19:44.705256
Epoch:[ 50 1 ] loss: 0.5167251825332642 2022-05-29 14:19:46.142032
Epoch:[ 50 2 ] loss: 0.517666220664978 2022-05-29 14:19:46.918184
Epoch:[ 50 3 ] loss: 0.5210175514221191 2022-05-29 14:19:47.684794
Epoch:[ 50 4 ] loss: 0.520158052444458 2022-05-29 14:19:48.449288
Epoch:[ 50 5 ] loss: 0.519842803478241 2022-05-29 14:19:49.214978
Epoch:[ 50 6 ] loss: 0.518949568271637 2022-05-29 14:19:49.980781
Epoch:[ 50 7 ] loss: 0.5189548134803772 2022-05-29 14:19:50.745176
Epoch:[ 50 8 ] loss: 0.5162237882614136 2022-05-29 14:19:51.511652
Epoch:[ 50 9 ] loss: 0.5193592309951782 2022-05-29 14:19:52.292337
Epoch:[ 50 10 ] loss: 0.5171002149581909 2022-05-29 14:19:53.060493
Epoch:[ 50 11 ] loss: 0.5203170776367188 2022-05-29 14:19:53.826291
Epoch:[ 50 12 ] loss: 0.5169752240180969 2022-05-29 14:19:54.591924
Epoch:[ 50 13 ] loss: 0.5175239443778992 2022-05-29 14:19:55.360623
Epoch:[ 50 14 ] loss: 0.5167316794395447 2022-05-29 14:19:56.128876
Epoch:[ 50 15 ] loss: 0.5202552080154419 2022-05-29 14:19:56.899795
Epoch:[ 50 16 ] loss: 0.5198729634284973 2022-05-29 14:20:05.080920
Epoch:[ 50 17 ] loss: 0.5184013247489929 2022-05-29 14:20:06.776359
Epoch:[ 50 18 ] loss: 0.522896409034729 2022-05-29 14:20:07.549338
Epoch:[ 50 19 ] loss: 0.5182304382324219 2022-05-29 14:20:08.313203
Training_Epoch:[ 50 ] Training_loss: 0.5188436180353164 2022-05-29 14:20:08.313971
learning rate:  0.0012004999999999995
netparams have been saved once 50
val: 1 0.5289028882980347
val: 2 0.5240316390991211
val: 3 0.5267807841300964
val: 4 0.5199938416481018
val: 5 0.5083039999008179
val: 6 0.5071941018104553
val: 7 0.5273503661155701
val: 8 0.5348065495491028
val: 9 0.5217670798301697
val: 10 0.5291491746902466
val: 11 0.537787139415741
val: 12 0.5543233752250671
val: 13 0.5303360223770142
val: 14 0.5209486484527588
val: 15 0.5205904245376587
val: 16 0.5090906023979187
val: 17 0.5424908995628357
val: 18 0.5308150053024292
val: 19 0.5203256607055664
val: 20 0.5270487070083618
val_Epoch:[ 50 ] val_loss: 0.5261018455028534 2022-05-29 14:20:13.923472
start training 2022-05-29 14:20:14.026346
Epoch:[ 51 0 ] loss: 0.5220127105712891 2022-05-29 14:20:40.191529
Epoch:[ 51 1 ] loss: 0.5154590010643005 2022-05-29 14:20:40.955792
Epoch:[ 51 2 ] loss: 0.5158865451812744 2022-05-29 14:20:41.723066
Epoch:[ 51 3 ] loss: 0.5158975720405579 2022-05-29 14:20:42.504353
Epoch:[ 51 4 ] loss: 0.5173854231834412 2022-05-29 14:20:43.267674
Epoch:[ 51 5 ] loss: 0.5195620059967041 2022-05-29 14:20:44.031245
Epoch:[ 51 6 ] loss: 0.5204892754554749 2022-05-29 14:20:44.795124
Epoch:[ 51 7 ] loss: 0.5200709700584412 2022-05-29 14:20:45.560707
Epoch:[ 51 8 ] loss: 0.5135495066642761 2022-05-29 14:20:46.324595
Epoch:[ 51 9 ] loss: 0.5178863406181335 2022-05-29 14:20:47.092056
Epoch:[ 51 10 ] loss: 0.5185163617134094 2022-05-29 14:20:47.855451
Epoch:[ 51 11 ] loss: 0.5153848528862 2022-05-29 14:20:48.620924
Epoch:[ 51 12 ] loss: 0.5168015360832214 2022-05-29 14:20:49.399582
Epoch:[ 51 13 ] loss: 0.5183287858963013 2022-05-29 14:20:50.163978
Epoch:[ 51 14 ] loss: 0.5176115036010742 2022-05-29 14:20:50.932351
Epoch:[ 51 15 ] loss: 0.514210045337677 2022-05-29 14:20:51.697214
Epoch:[ 51 16 ] loss: 0.5135883688926697 2022-05-29 14:20:59.191152
Epoch:[ 51 17 ] loss: 0.5164937376976013 2022-05-29 14:21:01.815922
Epoch:[ 51 18 ] loss: 0.5179084539413452 2022-05-29 14:21:02.597136
Epoch:[ 51 19 ] loss: 0.5154380798339844 2022-05-29 14:21:03.363384
Training_Epoch:[ 51 ] Training_loss: 0.5171240538358688 2022-05-29 14:21:03.364171
learning rate:  0.0008403499999999996
val: 1 0.4968503713607788
val: 2 0.5364314913749695
val: 3 0.5269741415977478
val: 4 0.5213210582733154
val: 5 0.5345334410667419
val: 6 0.5268133282661438
val: 7 0.523586094379425
val: 8 0.5055163502693176
val: 9 0.5350477695465088
val: 10 0.5418793559074402
val: 11 0.5275084376335144
val: 12 0.5382562875747681
val: 13 0.5105170607566833
val: 14 0.5140829086303711
val: 15 0.52101069688797
val: 16 0.5363196134567261
val: 17 0.5254366993904114
val: 18 0.5200338959693909
val: 19 0.5286145210266113
val: 20 0.513848602771759
val_Epoch:[ 51 ] val_loss: 0.5242291063070297 2022-05-29 14:21:08.815179
start training 2022-05-29 14:21:08.918808
Epoch:[ 52 0 ] loss: 0.5170356035232544 2022-05-29 14:21:35.794026
Epoch:[ 52 1 ] loss: 0.5182594060897827 2022-05-29 14:21:36.560468
Epoch:[ 52 2 ] loss: 0.5093287229537964 2022-05-29 14:21:37.326934
Epoch:[ 52 3 ] loss: 0.523359477519989 2022-05-29 14:21:38.094611
Epoch:[ 52 4 ] loss: 0.5146328210830688 2022-05-29 14:21:38.874216
Epoch:[ 52 5 ] loss: 0.5171693563461304 2022-05-29 14:21:39.653458
Epoch:[ 52 6 ] loss: 0.5186758041381836 2022-05-29 14:21:40.419554
Epoch:[ 52 7 ] loss: 0.5159587264060974 2022-05-29 14:21:41.184439
Epoch:[ 52 8 ] loss: 0.5197687149047852 2022-05-29 14:21:41.950084
Epoch:[ 52 9 ] loss: 0.5165088772773743 2022-05-29 14:21:42.715578
Epoch:[ 52 10 ] loss: 0.5143319964408875 2022-05-29 14:21:43.482944
Epoch:[ 52 11 ] loss: 0.5117542743682861 2022-05-29 14:21:44.247592
Epoch:[ 52 12 ] loss: 0.5159978866577148 2022-05-29 14:21:45.014207
Epoch:[ 52 13 ] loss: 0.5135257244110107 2022-05-29 14:21:45.778920
Epoch:[ 52 14 ] loss: 0.5155093669891357 2022-05-29 14:21:46.544493
Epoch:[ 52 15 ] loss: 0.5154687166213989 2022-05-29 14:21:47.311225
Epoch:[ 52 16 ] loss: 0.5145549178123474 2022-05-29 14:21:56.755071
Epoch:[ 52 17 ] loss: 0.5168460011482239 2022-05-29 14:21:57.519207
Epoch:[ 52 18 ] loss: 0.5187327265739441 2022-05-29 14:21:58.286869
Epoch:[ 52 19 ] loss: 0.5098513960838318 2022-05-29 14:21:59.052073
Training_Epoch:[ 52 ] Training_loss: 0.5158635258674622 2022-05-29 14:21:59.052774
learning rate:  0.0008403499999999996
netparams have been saved once 52
val: 1 0.5275341272354126
val: 2 0.5229918360710144
val: 3 0.5258753895759583
val: 4 0.5222073197364807
val: 5 0.5232356190681458
val: 6 0.5210359692573547
val: 7 0.5201118588447571
val: 8 0.5197901129722595
val: 9 0.5435300469398499
val: 10 0.5125633478164673
val: 11 0.5396841764450073
val: 12 0.5076467394828796
val: 13 0.5158929824829102
val: 14 0.525542140007019
val: 15 0.5265592336654663
val: 16 0.533866286277771
val: 17 0.5311188697814941
val: 18 0.5300379991531372
val: 19 0.5035476684570312
val: 20 0.5326014757156372
val_Epoch:[ 52 ] val_loss: 0.5242686599493027 2022-05-29 14:22:04.744191
start training 2022-05-29 14:22:04.850301
Epoch:[ 53 0 ] loss: 0.5140595436096191 2022-05-29 14:22:30.717946
Epoch:[ 53 1 ] loss: 0.514000415802002 2022-05-29 14:22:31.484851
Epoch:[ 53 2 ] loss: 0.5147234201431274 2022-05-29 14:22:32.252281
Epoch:[ 53 3 ] loss: 0.5131077766418457 2022-05-29 14:22:33.018191
Epoch:[ 53 4 ] loss: 0.5138648152351379 2022-05-29 14:22:33.784454
Epoch:[ 53 5 ] loss: 0.5101398229598999 2022-05-29 14:22:34.550044
Epoch:[ 53 6 ] loss: 0.5149645209312439 2022-05-29 14:22:35.315234
Epoch:[ 53 7 ] loss: 0.5087065100669861 2022-05-29 14:22:36.082911
Epoch:[ 53 8 ] loss: 0.5146485567092896 2022-05-29 14:22:36.848660
Epoch:[ 53 9 ] loss: 0.5222285389900208 2022-05-29 14:22:37.615224
Epoch:[ 53 10 ] loss: 0.5143898129463196 2022-05-29 14:22:38.394901
Epoch:[ 53 11 ] loss: 0.5106056928634644 2022-05-29 14:22:39.176590
Epoch:[ 53 12 ] loss: 0.513647735118866 2022-05-29 14:22:39.942672
Epoch:[ 53 13 ] loss: 0.5148123502731323 2022-05-29 14:22:40.707542
Epoch:[ 53 14 ] loss: 0.5144978761672974 2022-05-29 14:22:41.472896
Epoch:[ 53 15 ] loss: 0.515969455242157 2022-05-29 14:22:42.240037
Epoch:[ 53 16 ] loss: 0.5165886282920837 2022-05-29 14:22:51.658932
Epoch:[ 53 17 ] loss: 0.5182096362113953 2022-05-29 14:22:52.423198
Epoch:[ 53 18 ] loss: 0.5224488377571106 2022-05-29 14:22:53.196558
Epoch:[ 53 19 ] loss: 0.5208797454833984 2022-05-29 14:22:53.960456
Training_Epoch:[ 53 ] Training_loss: 0.5151246845722198 2022-05-29 14:22:53.961195
learning rate:  0.0008403499999999996
val: 1 0.5138642191886902
val: 2 0.5235447883605957
val: 3 0.5290282368659973
val: 4 0.49995920062065125
val: 5 0.522853672504425
val: 6 0.5304557085037231
val: 7 0.5346634984016418
val: 8 0.5343372225761414
val: 9 0.5380228161811829
val: 10 0.5271109342575073
val: 11 0.5258824229240417
val: 12 0.5321182608604431
val: 13 0.5309267640113831
val: 14 0.5286698937416077
val: 15 0.5446287989616394
val: 16 0.532168447971344
val: 17 0.518600583076477
val: 18 0.5399788618087769
val: 19 0.5183549523353577
val: 20 0.5268739461898804
val_Epoch:[ 53 ] val_loss: 0.5276021614670754 2022-05-29 14:22:59.497421
start training 2022-05-29 14:22:59.602420
Epoch:[ 54 0 ] loss: 0.5143013000488281 2022-05-29 14:23:26.372204
Epoch:[ 54 1 ] loss: 0.5129026770591736 2022-05-29 14:23:27.136784
Epoch:[ 54 2 ] loss: 0.5153604745864868 2022-05-29 14:23:27.901224
Epoch:[ 54 3 ] loss: 0.5160051584243774 2022-05-29 14:23:28.669116
Epoch:[ 54 4 ] loss: 0.5169656276702881 2022-05-29 14:23:29.446638
Epoch:[ 54 5 ] loss: 0.5139439105987549 2022-05-29 14:23:30.210841
Epoch:[ 54 6 ] loss: 0.5147271752357483 2022-05-29 14:23:30.988067
Epoch:[ 54 7 ] loss: 0.5106115341186523 2022-05-29 14:23:31.755341
Epoch:[ 54 8 ] loss: 0.5135992169380188 2022-05-29 14:23:32.520013
Epoch:[ 54 9 ] loss: 0.5140449404716492 2022-05-29 14:23:33.285959
Epoch:[ 54 10 ] loss: 0.510145902633667 2022-05-29 14:23:34.052035
Epoch:[ 54 11 ] loss: 0.5220158100128174 2022-05-29 14:23:34.818782
Epoch:[ 54 12 ] loss: 0.5149607062339783 2022-05-29 14:23:35.584249
Epoch:[ 54 13 ] loss: 0.5163506865501404 2022-05-29 14:23:36.351687
Epoch:[ 54 14 ] loss: 0.5128656625747681 2022-05-29 14:23:37.117966
Epoch:[ 54 15 ] loss: 0.5097789168357849 2022-05-29 14:23:37.881942
Epoch:[ 54 16 ] loss: 0.5093826651573181 2022-05-29 14:23:47.386675
Epoch:[ 54 17 ] loss: 0.5158194899559021 2022-05-29 14:23:48.152291
Epoch:[ 54 18 ] loss: 0.5152893662452698 2022-05-29 14:23:48.922094
Epoch:[ 54 19 ] loss: 0.5164413452148438 2022-05-29 14:23:49.688599
Training_Epoch:[ 54 ] Training_loss: 0.5142756283283234 2022-05-29 14:23:49.689353
learning rate:  0.0008403499999999996
netparams have been saved once 54
val: 1 0.5243250727653503
val: 2 0.5238521695137024
val: 3 0.5326758623123169
val: 4 0.5209500193595886
val: 5 0.5246402621269226
val: 6 0.5244221687316895
val: 7 0.5320835113525391
val: 8 0.5375638008117676
val: 9 0.5181111693382263
val: 10 0.5502521991729736
val: 11 0.5283653736114502
val: 12 0.5228853821754456
val: 13 0.5296578407287598
val: 14 0.5158315896987915
val: 15 0.5253309011459351
val: 16 0.5334355235099792
val: 17 0.5252230167388916
val: 18 0.533053457736969
val: 19 0.5286715626716614
val: 20 0.5169433951377869
val_Epoch:[ 54 ] val_loss: 0.5274137139320374 2022-05-29 14:23:55.411143
start training 2022-05-29 14:23:55.513070
Epoch:[ 55 0 ] loss: 0.518113911151886 2022-05-29 14:24:20.412179
Epoch:[ 55 1 ] loss: 0.513501763343811 2022-05-29 14:24:21.355238
Epoch:[ 55 2 ] loss: 0.5151197910308838 2022-05-29 14:24:22.162236
Epoch:[ 55 3 ] loss: 0.5161312818527222 2022-05-29 14:24:22.927037
Epoch:[ 55 4 ] loss: 0.5167770385742188 2022-05-29 14:24:23.694793
Epoch:[ 55 5 ] loss: 0.5145723819732666 2022-05-29 14:24:24.471291
Epoch:[ 55 6 ] loss: 0.5151687860488892 2022-05-29 14:24:25.237320
Epoch:[ 55 7 ] loss: 0.5105088949203491 2022-05-29 14:24:26.004079
Epoch:[ 55 8 ] loss: 0.5174313187599182 2022-05-29 14:24:26.770892
Epoch:[ 55 9 ] loss: 0.5111942887306213 2022-05-29 14:24:27.533560
Epoch:[ 55 10 ] loss: 0.5131686329841614 2022-05-29 14:24:28.299959
Epoch:[ 55 11 ] loss: 0.5136327147483826 2022-05-29 14:24:29.066781
Epoch:[ 55 12 ] loss: 0.5144331455230713 2022-05-29 14:24:29.834596
Epoch:[ 55 13 ] loss: 0.5128915905952454 2022-05-29 14:24:30.614670
Epoch:[ 55 14 ] loss: 0.5171035528182983 2022-05-29 14:24:31.380890
Epoch:[ 55 15 ] loss: 0.5123887658119202 2022-05-29 14:24:32.147587
Epoch:[ 55 16 ] loss: 0.5146063566207886 2022-05-29 14:24:40.165650
Epoch:[ 55 17 ] loss: 0.5095002055168152 2022-05-29 14:24:40.930952
Epoch:[ 55 18 ] loss: 0.5170997977256775 2022-05-29 14:24:41.700893
Epoch:[ 55 19 ] loss: 0.5094538331031799 2022-05-29 14:24:42.467699
Training_Epoch:[ 55 ] Training_loss: 0.5141399025917053 2022-05-29 14:24:42.468434
learning rate:  0.0008403499999999996
val: 1 0.5165076851844788
val: 2 0.5230075120925903
val: 3 0.5189114212989807
val: 4 0.5192459225654602
val: 5 0.5169191360473633
val: 6 0.5335879325866699
val: 7 0.5167019963264465
val: 8 0.5290592312812805
val: 9 0.5346726179122925
val: 10 0.5109798908233643
val: 11 0.5378759503364563
val: 12 0.5161683559417725
val: 13 0.5288826823234558
val: 14 0.5302861928939819
val: 15 0.5272272825241089
val: 16 0.5181973576545715
val: 17 0.5260306000709534
val: 18 0.5139451622962952
val: 19 0.5041810274124146
val: 20 0.5290064215660095
val_Epoch:[ 55 ] val_loss: 0.5225697189569474 2022-05-29 14:24:48.053460
start training 2022-05-29 14:24:48.161276
Epoch:[ 56 0 ] loss: 0.5080530643463135 2022-05-29 14:25:14.146668
Epoch:[ 56 1 ] loss: 0.5107007026672363 2022-05-29 14:25:14.976224
Epoch:[ 56 2 ] loss: 0.5125196576118469 2022-05-29 14:25:15.743913
Epoch:[ 56 3 ] loss: 0.507235586643219 2022-05-29 14:25:16.510709
Epoch:[ 56 4 ] loss: 0.5101737976074219 2022-05-29 14:25:17.277886
Epoch:[ 56 5 ] loss: 0.5104876756668091 2022-05-29 14:25:18.046160
Epoch:[ 56 6 ] loss: 0.5134298801422119 2022-05-29 14:25:18.812859
Epoch:[ 56 7 ] loss: 0.5142405033111572 2022-05-29 14:25:19.582063
Epoch:[ 56 8 ] loss: 0.5137109756469727 2022-05-29 14:25:20.349493
Epoch:[ 56 9 ] loss: 0.5076990723609924 2022-05-29 14:25:21.130063
Epoch:[ 56 10 ] loss: 0.5130392909049988 2022-05-29 14:25:21.897568
Epoch:[ 56 11 ] loss: 0.5062193274497986 2022-05-29 14:25:22.665395
Epoch:[ 56 12 ] loss: 0.5134600400924683 2022-05-29 14:25:23.431693
Epoch:[ 56 13 ] loss: 0.5121508240699768 2022-05-29 14:25:24.200451
Epoch:[ 56 14 ] loss: 0.5167868137359619 2022-05-29 14:25:24.966082
Epoch:[ 56 15 ] loss: 0.5145576000213623 2022-05-29 14:25:25.731954
Epoch:[ 56 16 ] loss: 0.5116605758666992 2022-05-29 14:25:33.444175
Epoch:[ 56 17 ] loss: 0.5153791904449463 2022-05-29 14:25:34.211077
Epoch:[ 56 18 ] loss: 0.5127142667770386 2022-05-29 14:25:34.976191
Epoch:[ 56 19 ] loss: 0.5129688382148743 2022-05-29 14:25:36.107637
Training_Epoch:[ 56 ] Training_loss: 0.5118593841791153 2022-05-29 14:25:36.108395
learning rate:  0.0008403499999999996
netparams have been saved once 56
val: 1 0.5259079933166504
val: 2 0.518653154373169
val: 3 0.5207495093345642
val: 4 0.5400484800338745
val: 5 0.523748517036438
val: 6 0.5267950892448425
val: 7 0.5365788340568542
val: 8 0.5195239782333374
val: 9 0.5291765928268433
val: 10 0.521003246307373
val: 11 0.5058270692825317
val: 12 0.5254544019699097
val: 13 0.519110918045044
val: 14 0.5115553140640259
val: 15 0.5250322818756104
val: 16 0.5244669914245605
val: 17 0.5224106907844543
val: 18 0.5276161432266235
val: 19 0.5326189994812012
val: 20 0.5189521312713623
val_Epoch:[ 56 ] val_loss: 0.5237615168094635 2022-05-29 14:25:41.757749
start training 2022-05-29 14:25:41.863617
Epoch:[ 57 0 ] loss: 0.5071204900741577 2022-05-29 14:26:07.418922
Epoch:[ 57 1 ] loss: 0.5138081312179565 2022-05-29 14:26:08.220310
Epoch:[ 57 2 ] loss: 0.5066017508506775 2022-05-29 14:26:08.987154
Epoch:[ 57 3 ] loss: 0.5143372416496277 2022-05-29 14:26:09.754272
Epoch:[ 57 4 ] loss: 0.5097779035568237 2022-05-29 14:26:10.519716
Epoch:[ 57 5 ] loss: 0.5140976905822754 2022-05-29 14:26:11.286363
Epoch:[ 57 6 ] loss: 0.5060305595397949 2022-05-29 14:26:12.067110
Epoch:[ 57 7 ] loss: 0.5121977925300598 2022-05-29 14:26:12.833754
Epoch:[ 57 8 ] loss: 0.511858344078064 2022-05-29 14:26:13.600429
Epoch:[ 57 9 ] loss: 0.5134456753730774 2022-05-29 14:26:14.380197
Epoch:[ 57 10 ] loss: 0.5138853192329407 2022-05-29 14:26:15.145806
Epoch:[ 57 11 ] loss: 0.5142707228660583 2022-05-29 14:26:15.912509
Epoch:[ 57 12 ] loss: 0.5110093355178833 2022-05-29 14:26:16.678958
Epoch:[ 57 13 ] loss: 0.510533332824707 2022-05-29 14:26:17.447993
Epoch:[ 57 14 ] loss: 0.5219972133636475 2022-05-29 14:26:18.214431
Epoch:[ 57 15 ] loss: 0.5140030384063721 2022-05-29 14:26:18.983083
Epoch:[ 57 16 ] loss: 0.5218707919120789 2022-05-29 14:26:26.474987
Epoch:[ 57 17 ] loss: 0.5143941640853882 2022-05-29 14:26:27.242021
Epoch:[ 57 18 ] loss: 0.5179337859153748 2022-05-29 14:26:28.009752
Epoch:[ 57 19 ] loss: 0.513957142829895 2022-05-29 14:26:28.775811
Training_Epoch:[ 57 ] Training_loss: 0.5131565213203431 2022-05-29 14:26:28.776518
learning rate:  0.0008403499999999996
val: 1 0.523966372013092
val: 2 0.5176591277122498
val: 3 0.5169335007667542
val: 4 0.5202025175094604
val: 5 0.515355110168457
val: 6 0.5194865465164185
val: 7 0.520667314529419
val: 8 0.5596845149993896
val: 9 0.514162003993988
val: 10 0.5168328881263733
val: 11 0.5267173647880554
val: 12 0.5368834137916565
val: 13 0.5169131755828857
val: 14 0.5191037058830261
val: 15 0.5282018184661865
val: 16 0.5217360854148865
val: 17 0.5235333442687988
val: 18 0.5302087664604187
val: 19 0.53873610496521
val: 20 0.5211483836174011
val_Epoch:[ 57 ] val_loss: 0.5244066029787063 2022-05-29 14:26:34.404381
start training 2022-05-29 14:26:34.510470
Epoch:[ 58 0 ] loss: 0.5156430006027222 2022-05-29 14:27:00.199452
Epoch:[ 58 1 ] loss: 0.510108232498169 2022-05-29 14:27:01.426913
Epoch:[ 58 2 ] loss: 0.5112143754959106 2022-05-29 14:27:02.196519
Epoch:[ 58 3 ] loss: 0.5163567662239075 2022-05-29 14:27:02.962138
Epoch:[ 58 4 ] loss: 0.5199418663978577 2022-05-29 14:27:03.729063
Epoch:[ 58 5 ] loss: 0.5117284655570984 2022-05-29 14:27:04.506362
Epoch:[ 58 6 ] loss: 0.5195750594139099 2022-05-29 14:27:05.272987
Epoch:[ 58 7 ] loss: 0.5114986896514893 2022-05-29 14:27:06.039486
Epoch:[ 58 8 ] loss: 0.5126011371612549 2022-05-29 14:27:06.804124
Epoch:[ 58 9 ] loss: 0.5168210864067078 2022-05-29 14:27:07.571495
Epoch:[ 58 10 ] loss: 0.5094271302223206 2022-05-29 14:27:08.351718
Epoch:[ 58 11 ] loss: 0.5132381916046143 2022-05-29 14:27:09.120321
Epoch:[ 58 12 ] loss: 0.506907045841217 2022-05-29 14:27:09.886621
Epoch:[ 58 13 ] loss: 0.5110930800437927 2022-05-29 14:27:10.654103
Epoch:[ 58 14 ] loss: 0.5094174742698669 2022-05-29 14:27:11.423425
Epoch:[ 58 15 ] loss: 0.5102875828742981 2022-05-29 14:27:12.192127
Epoch:[ 58 16 ] loss: 0.5131699442863464 2022-05-29 14:27:19.297929
Epoch:[ 58 17 ] loss: 0.5121025443077087 2022-05-29 14:27:22.402795
Epoch:[ 58 18 ] loss: 0.509556233882904 2022-05-29 14:27:23.173178
Epoch:[ 58 19 ] loss: 0.5115907192230225 2022-05-29 14:27:23.937733
Training_Epoch:[ 58 ] Training_loss: 0.5126139312982559 2022-05-29 14:27:23.938524
learning rate:  0.0008403499999999996
netparams have been saved once 58
val: 1 0.5556892156600952
val: 2 0.5359693765640259
val: 3 0.5447242259979248
val: 4 0.5246090292930603
val: 5 0.5100811123847961
val: 6 0.543963611125946
val: 7 0.5343096852302551
val: 8 0.5266916155815125
val: 9 0.5354049801826477
val: 10 0.5293384790420532
val: 11 0.5305531620979309
val: 12 0.5410996079444885
val: 13 0.5311657190322876
val: 14 0.518873393535614
val: 15 0.528084397315979
val: 16 0.5442927479743958
val: 17 0.5407801866531372
val: 18 0.534193217754364
val: 19 0.5328578352928162
val: 20 0.5185115337371826
val_Epoch:[ 58 ] val_loss: 0.5330596566200256 2022-05-29 14:27:29.657791
start training 2022-05-29 14:27:29.763601
Epoch:[ 59 0 ] loss: 0.5072889924049377 2022-05-29 14:27:54.703471
Epoch:[ 59 1 ] loss: 0.5064648985862732 2022-05-29 14:27:56.525613
Epoch:[ 59 2 ] loss: 0.5078336596488953 2022-05-29 14:27:57.291294
Epoch:[ 59 3 ] loss: 0.5090287327766418 2022-05-29 14:27:58.058728
Epoch:[ 59 4 ] loss: 0.5131192207336426 2022-05-29 14:27:58.825446
Epoch:[ 59 5 ] loss: 0.5096791982650757 2022-05-29 14:27:59.592462
Epoch:[ 59 6 ] loss: 0.5091144442558289 2022-05-29 14:28:00.361610
Epoch:[ 59 7 ] loss: 0.5085010528564453 2022-05-29 14:28:01.128362
Epoch:[ 59 8 ] loss: 0.5049899816513062 2022-05-29 14:28:01.895967
Epoch:[ 59 9 ] loss: 0.5114407539367676 2022-05-29 14:28:02.674103
Epoch:[ 59 10 ] loss: 0.5108043551445007 2022-05-29 14:28:03.440648
Epoch:[ 59 11 ] loss: 0.5114453434944153 2022-05-29 14:28:04.206221
Epoch:[ 59 12 ] loss: 0.5145078897476196 2022-05-29 14:28:04.974792
Epoch:[ 59 13 ] loss: 0.5115323066711426 2022-05-29 14:28:05.740970
Epoch:[ 59 14 ] loss: 0.5134038925170898 2022-05-29 14:28:06.506463
Epoch:[ 59 15 ] loss: 0.5137374401092529 2022-05-29 14:28:07.274144
Epoch:[ 59 16 ] loss: 0.5112882852554321 2022-05-29 14:28:14.162224
Epoch:[ 59 17 ] loss: 0.5141722559928894 2022-05-29 14:28:15.274425
Epoch:[ 59 18 ] loss: 0.513918399810791 2022-05-29 14:28:16.044304
Epoch:[ 59 19 ] loss: 0.5111098289489746 2022-05-29 14:28:16.809689
Training_Epoch:[ 59 ] Training_loss: 0.5106690466403961 2022-05-29 14:28:16.810469
learning rate:  0.0008403499999999996
val: 1 0.5409298539161682
val: 2 0.5328025817871094
val: 3 0.519463300704956
val: 4 0.5205839276313782
val: 5 0.5326375961303711
val: 6 0.5300815105438232
val: 7 0.5335220694541931
val: 8 0.5177680850028992
val: 9 0.5410008430480957
val: 10 0.5383873581886292
val: 11 0.5297585725784302
val: 12 0.5520357489585876
val: 13 0.5126743316650391
val: 14 0.5204750299453735
val: 15 0.5437202453613281
val: 16 0.546705961227417
val: 17 0.5376837849617004
val: 18 0.5132560133934021
val: 19 0.5233282446861267
val: 20 0.5142873525619507
val_Epoch:[ 59 ] val_loss: 0.5300551205873489 2022-05-29 14:28:22.543289
start training 2022-05-29 14:28:22.650338
Epoch:[ 60 0 ] loss: 0.5098058581352234 2022-05-29 14:28:49.027641
Epoch:[ 60 1 ] loss: 0.5136938095092773 2022-05-29 14:28:49.795481
Epoch:[ 60 2 ] loss: 0.5121338963508606 2022-05-29 14:28:50.562508
Epoch:[ 60 3 ] loss: 0.5103134512901306 2022-05-29 14:28:51.332427
Epoch:[ 60 4 ] loss: 0.5073533058166504 2022-05-29 14:28:52.113409
Epoch:[ 60 5 ] loss: 0.49916478991508484 2022-05-29 14:28:52.881834
Epoch:[ 60 6 ] loss: 0.5049980878829956 2022-05-29 14:28:53.650247
Epoch:[ 60 7 ] loss: 0.510978639125824 2022-05-29 14:28:54.416012
Epoch:[ 60 8 ] loss: 0.5107245445251465 2022-05-29 14:28:55.182823
Epoch:[ 60 9 ] loss: 0.5091615319252014 2022-05-29 14:28:55.951055
Epoch:[ 60 10 ] loss: 0.5069759488105774 2022-05-29 14:28:56.718428
Epoch:[ 60 11 ] loss: 0.5100473165512085 2022-05-29 14:28:57.484543
Epoch:[ 60 12 ] loss: 0.5154547095298767 2022-05-29 14:28:58.250950
Epoch:[ 60 13 ] loss: 0.5107129812240601 2022-05-29 14:28:59.017701
Epoch:[ 60 14 ] loss: 0.5119853019714355 2022-05-29 14:28:59.797007
Epoch:[ 60 15 ] loss: 0.5054212808609009 2022-05-29 14:29:00.562390
Epoch:[ 60 16 ] loss: 0.5096386671066284 2022-05-29 14:29:07.649579
Epoch:[ 60 17 ] loss: 0.5094466805458069 2022-05-29 14:29:10.004881
Epoch:[ 60 18 ] loss: 0.5130431056022644 2022-05-29 14:29:10.789693
Epoch:[ 60 19 ] loss: 0.5082707405090332 2022-05-29 14:29:11.553312
Training_Epoch:[ 60 ] Training_loss: 0.5094662323594094 2022-05-29 14:29:11.554085
learning rate:  0.0008403499999999996
netparams have been saved once 60
val: 1 0.5182178020477295
val: 2 0.5182340145111084
val: 3 0.5100613832473755
val: 4 0.5116810202598572
val: 5 0.5099188089370728
val: 6 0.5279619693756104
val: 7 0.5287972688674927
val: 8 0.5246100425720215
val: 9 0.5210941433906555
val: 10 0.530269980430603
val: 11 0.5210039019584656
val: 12 0.5035658478736877
val: 13 0.5261956453323364
val: 14 0.5463001132011414
val: 15 0.5369599461555481
val: 16 0.5205223560333252
val: 17 0.5176676511764526
val: 18 0.5094549059867859
val: 19 0.5165715217590332
val: 20 0.5256471037864685
val_Epoch:[ 60 ] val_loss: 0.5212367713451386 2022-05-29 14:29:17.280379
start training 2022-05-29 14:29:17.393946
Epoch:[ 61 0 ] loss: 0.5090389847755432 2022-05-29 14:29:43.940089
Epoch:[ 61 1 ] loss: 0.5081656575202942 2022-05-29 14:29:44.707241
Epoch:[ 61 2 ] loss: 0.4987172782421112 2022-05-29 14:29:45.472946
Epoch:[ 61 3 ] loss: 0.5139011144638062 2022-05-29 14:29:46.241189
Epoch:[ 61 4 ] loss: 0.5067038536071777 2022-05-29 14:29:47.008119
Epoch:[ 61 5 ] loss: 0.507282555103302 2022-05-29 14:29:47.775166
Epoch:[ 61 6 ] loss: 0.5072952508926392 2022-05-29 14:29:48.540904
Epoch:[ 61 7 ] loss: 0.5089911818504333 2022-05-29 14:29:49.304795
Epoch:[ 61 8 ] loss: 0.5107139945030212 2022-05-29 14:29:50.072073
Epoch:[ 61 9 ] loss: 0.5068178772926331 2022-05-29 14:29:50.838030
Epoch:[ 61 10 ] loss: 0.5057926177978516 2022-05-29 14:29:51.617740
Epoch:[ 61 11 ] loss: 0.5068606734275818 2022-05-29 14:29:52.382398
Epoch:[ 61 12 ] loss: 0.5055251121520996 2022-05-29 14:29:53.149322
Epoch:[ 61 13 ] loss: 0.5062270760536194 2022-05-29 14:29:53.928123
Epoch:[ 61 14 ] loss: 0.50832599401474 2022-05-29 14:29:54.692239
Epoch:[ 61 15 ] loss: 0.5110663771629333 2022-05-29 14:29:55.459469
Epoch:[ 61 16 ] loss: 0.5036237239837646 2022-05-29 14:30:04.727673
Epoch:[ 61 17 ] loss: 0.5063835978507996 2022-05-29 14:30:05.496605
Epoch:[ 61 18 ] loss: 0.5039793252944946 2022-05-29 14:30:06.265993
Epoch:[ 61 19 ] loss: 0.50218266248703 2022-05-29 14:30:07.031039
Training_Epoch:[ 61 ] Training_loss: 0.5068797454237938 2022-05-29 14:30:07.031808
learning rate:  0.0005882449999999997
val: 1 0.5173201560974121
val: 2 0.5407077074050903
val: 3 0.5279104709625244
val: 4 0.5165367126464844
val: 5 0.5315329432487488
val: 6 0.5463640689849854
val: 7 0.5248140096664429
val: 8 0.5179861783981323
val: 9 0.5286819338798523
val: 10 0.5057920813560486
val: 11 0.5255707502365112
val: 12 0.5168455839157104
val: 13 0.5156468152999878
val: 14 0.5260857939720154
val: 15 0.5416085124015808
val: 16 0.5453532338142395
val: 17 0.5234194397926331
val: 18 0.5386707782745361
val: 19 0.5375844240188599
val: 20 0.5306559801101685
val_Epoch:[ 61 ] val_loss: 0.5279543787240982 2022-05-29 14:30:12.580379
start training 2022-05-29 14:30:12.687527
Epoch:[ 62 0 ] loss: 0.5069441199302673 2022-05-29 14:30:39.315863
Epoch:[ 62 1 ] loss: 0.5071340799331665 2022-05-29 14:30:40.081217
Epoch:[ 62 2 ] loss: 0.5040358304977417 2022-05-29 14:30:40.847258
Epoch:[ 62 3 ] loss: 0.5038595795631409 2022-05-29 14:30:41.611917
Epoch:[ 62 4 ] loss: 0.5062352418899536 2022-05-29 14:30:42.391849
Epoch:[ 62 5 ] loss: 0.5018376111984253 2022-05-29 14:30:43.159279
Epoch:[ 62 6 ] loss: 0.5096362829208374 2022-05-29 14:30:43.926027
Epoch:[ 62 7 ] loss: 0.5090758204460144 2022-05-29 14:30:44.692282
Epoch:[ 62 8 ] loss: 0.5124975442886353 2022-05-29 14:30:45.461425
Epoch:[ 62 9 ] loss: 0.5048841238021851 2022-05-29 14:30:46.239794
Epoch:[ 62 10 ] loss: 0.5151253342628479 2022-05-29 14:30:47.006194
Epoch:[ 62 11 ] loss: 0.5046105980873108 2022-05-29 14:30:47.774256
Epoch:[ 62 12 ] loss: 0.5084967613220215 2022-05-29 14:30:48.537964
Epoch:[ 62 13 ] loss: 0.5099400877952576 2022-05-29 14:30:49.303676
Epoch:[ 62 14 ] loss: 0.5108767151832581 2022-05-29 14:30:50.069039
Epoch:[ 62 15 ] loss: 0.49983662366867065 2022-05-29 14:30:50.835971
Epoch:[ 62 16 ] loss: 0.5023695826530457 2022-05-29 14:31:00.039737
Epoch:[ 62 17 ] loss: 0.505752444267273 2022-05-29 14:31:00.806146
Epoch:[ 62 18 ] loss: 0.5040318369865417 2022-05-29 14:31:01.582848
Epoch:[ 62 19 ] loss: 0.5065805315971375 2022-05-29 14:31:02.347092
Training_Epoch:[ 62 ] Training_loss: 0.5066880375146866 2022-05-29 14:31:02.347897
learning rate:  0.0005882449999999997
netparams have been saved once 62
val: 1 0.5247588753700256
val: 2 0.5164399743080139
val: 3 0.5111252069473267
val: 4 0.5261443853378296
val: 5 0.5123715996742249
val: 6 0.5183565020561218
val: 7 0.5124828219413757
val: 8 0.5346001982688904
val: 9 0.5197564959526062
val: 10 0.5319197177886963
val: 11 0.5282110571861267
val: 12 0.5398674607276917
val: 13 0.5020690560340881
val: 14 0.5032817721366882
val: 15 0.5117128491401672
val: 16 0.5135743618011475
val: 17 0.5178946852684021
val: 18 0.5143687725067139
val: 19 0.5133664011955261
val: 20 0.5149794220924377
val_Epoch:[ 62 ] val_loss: 0.518364080786705 2022-05-29 14:31:07.966719
start training 2022-05-29 14:31:08.074750
Epoch:[ 63 0 ] loss: 0.4998525381088257 2022-05-29 14:31:33.108189
Epoch:[ 63 1 ] loss: 0.5057266354560852 2022-05-29 14:31:34.824179
Epoch:[ 63 2 ] loss: 0.5051801204681396 2022-05-29 14:31:35.588225
Epoch:[ 63 3 ] loss: 0.502816915512085 2022-05-29 14:31:36.353066
Epoch:[ 63 4 ] loss: 0.5038274526596069 2022-05-29 14:31:37.118874
Epoch:[ 63 5 ] loss: 0.5055493712425232 2022-05-29 14:31:37.896612
Epoch:[ 63 6 ] loss: 0.5035772919654846 2022-05-29 14:31:38.662990
Epoch:[ 63 7 ] loss: 0.5070909857749939 2022-05-29 14:31:39.427457
Epoch:[ 63 8 ] loss: 0.5022359490394592 2022-05-29 14:31:40.192571
Epoch:[ 63 9 ] loss: 0.5070196390151978 2022-05-29 14:31:40.968658
Epoch:[ 63 10 ] loss: 0.5084336400032043 2022-05-29 14:31:41.735192
Epoch:[ 63 11 ] loss: 0.5087625980377197 2022-05-29 14:31:42.501181
Epoch:[ 63 12 ] loss: 0.5068278312683105 2022-05-29 14:31:43.267629
Epoch:[ 63 13 ] loss: 0.5039299726486206 2022-05-29 14:31:44.032687
Epoch:[ 63 14 ] loss: 0.5008853077888489 2022-05-29 14:31:44.799591
Epoch:[ 63 15 ] loss: 0.5080089569091797 2022-05-29 14:31:45.564925
Epoch:[ 63 16 ] loss: 0.5101475715637207 2022-05-29 14:31:52.539903
Epoch:[ 63 17 ] loss: 0.5048165321350098 2022-05-29 14:31:54.914937
Epoch:[ 63 18 ] loss: 0.507051944732666 2022-05-29 14:31:55.684322
Epoch:[ 63 19 ] loss: 0.5088312029838562 2022-05-29 14:31:56.448747
Training_Epoch:[ 63 ] Training_loss: 0.5055286228656769 2022-05-29 14:31:56.449483
learning rate:  0.0005882449999999997
val: 1 0.5172935724258423
val: 2 0.5288706421852112
val: 3 0.5111236572265625
val: 4 0.5298343300819397
val: 5 0.517764687538147
val: 6 0.5205720663070679
val: 7 0.5280479788780212
val: 8 0.5195711851119995
val: 9 0.5298453569412231
val: 10 0.5170433521270752
val: 11 0.5124741792678833
val: 12 0.5320327877998352
val: 13 0.5250105857849121
val: 14 0.5072434544563293
val: 15 0.5167744159698486
val: 16 0.518927276134491
val: 17 0.5305129885673523
val: 18 0.5061149001121521
val: 19 0.5101016163825989
val: 20 0.5157040953636169
val_Epoch:[ 63 ] val_loss: 0.5197431564331054 2022-05-29 14:32:02.005841
start training 2022-05-29 14:32:02.116914
Epoch:[ 64 0 ] loss: 0.5060839056968689 2022-05-29 14:32:27.113163
Epoch:[ 64 1 ] loss: 0.5057655572891235 2022-05-29 14:32:27.935520
Epoch:[ 64 2 ] loss: 0.5074012875556946 2022-05-29 14:32:28.701006
Epoch:[ 64 3 ] loss: 0.5012348890304565 2022-05-29 14:32:29.479433
Epoch:[ 64 4 ] loss: 0.5039148330688477 2022-05-29 14:32:30.244073
Epoch:[ 64 5 ] loss: 0.5060061812400818 2022-05-29 14:32:31.009926
Epoch:[ 64 6 ] loss: 0.5007431507110596 2022-05-29 14:32:31.776684
Epoch:[ 64 7 ] loss: 0.5046443343162537 2022-05-29 14:32:32.542224
Epoch:[ 64 8 ] loss: 0.5079376101493835 2022-05-29 14:32:33.307961
Epoch:[ 64 9 ] loss: 0.5005702972412109 2022-05-29 14:32:34.071707
Epoch:[ 64 10 ] loss: 0.5097345113754272 2022-05-29 14:32:34.838095
Epoch:[ 64 11 ] loss: 0.5044752359390259 2022-05-29 14:32:35.602773
Epoch:[ 64 12 ] loss: 0.508982241153717 2022-05-29 14:32:36.368910
Epoch:[ 64 13 ] loss: 0.5018137097358704 2022-05-29 14:32:37.148871
Epoch:[ 64 14 ] loss: 0.5138171911239624 2022-05-29 14:32:37.913211
Epoch:[ 64 15 ] loss: 0.508454442024231 2022-05-29 14:32:38.679637
Epoch:[ 64 16 ] loss: 0.5061532258987427 2022-05-29 14:32:46.376077
Epoch:[ 64 17 ] loss: 0.5018022060394287 2022-05-29 14:32:47.140214
Epoch:[ 64 18 ] loss: 0.5043535828590393 2022-05-29 14:32:47.907098
Epoch:[ 64 19 ] loss: 0.5022115707397461 2022-05-29 14:32:48.673263
Training_Epoch:[ 64 ] Training_loss: 0.5053049981594085 2022-05-29 14:32:48.674030
learning rate:  0.0005882449999999997
netparams have been saved once 64
val: 1 0.515479326248169
val: 2 0.5075534582138062
val: 3 0.5223264694213867
val: 4 0.5284361243247986
val: 5 0.5145531296730042
val: 6 0.51390540599823
val: 7 0.5153630375862122
val: 8 0.5168607831001282
val: 9 0.5185507535934448
val: 10 0.4998372197151184
val: 11 0.5173834562301636
val: 12 0.524592399597168
val: 13 0.5210515260696411
val: 14 0.5290668606758118
val: 15 0.5250703692436218
val: 16 0.5131007432937622
val: 17 0.5318490266799927
val: 18 0.5208829045295715
val: 19 0.5133531093597412
val: 20 0.5372239947319031
val_Epoch:[ 64 ] val_loss: 0.5193220049142837 2022-05-29 14:32:54.417433
start training 2022-05-29 14:32:54.526856
Epoch:[ 65 0 ] loss: 0.5042569637298584 2022-05-29 14:33:20.022349
Epoch:[ 65 1 ] loss: 0.5019569993019104 2022-05-29 14:33:20.785892
Epoch:[ 65 2 ] loss: 0.5028538107872009 2022-05-29 14:33:21.551415
Epoch:[ 65 3 ] loss: 0.5143204927444458 2022-05-29 14:33:22.317966
Epoch:[ 65 4 ] loss: 0.5064651370048523 2022-05-29 14:33:23.085802
Epoch:[ 65 5 ] loss: 0.5053327679634094 2022-05-29 14:33:23.849953
Epoch:[ 65 6 ] loss: 0.5134517550468445 2022-05-29 14:33:24.614195
Epoch:[ 65 7 ] loss: 0.5031540989875793 2022-05-29 14:33:25.378552
Epoch:[ 65 8 ] loss: 0.5018326640129089 2022-05-29 14:33:26.143783
Epoch:[ 65 9 ] loss: 0.5047222375869751 2022-05-29 14:33:26.908356
Epoch:[ 65 10 ] loss: 0.5054514408111572 2022-05-29 14:33:27.686770
Epoch:[ 65 11 ] loss: 0.5024109482765198 2022-05-29 14:33:28.453631
Epoch:[ 65 12 ] loss: 0.5027642846107483 2022-05-29 14:33:29.233311
Epoch:[ 65 13 ] loss: 0.4985545575618744 2022-05-29 14:33:30.000640
Epoch:[ 65 14 ] loss: 0.5035101175308228 2022-05-29 14:33:30.766142
Epoch:[ 65 15 ] loss: 0.5015600323677063 2022-05-29 14:33:31.533481
Epoch:[ 65 16 ] loss: 0.5077896118164062 2022-05-29 14:33:39.364757
Epoch:[ 65 17 ] loss: 0.5031915903091431 2022-05-29 14:33:40.532218
Epoch:[ 65 18 ] loss: 0.5078752040863037 2022-05-29 14:33:41.302975
Epoch:[ 65 19 ] loss: 0.5017647743225098 2022-05-29 14:33:42.065675
Training_Epoch:[ 65 ] Training_loss: 0.5046609744429589 2022-05-29 14:33:42.066422
learning rate:  0.0005882449999999997
val: 1 0.526222825050354
val: 2 0.5191757082939148
val: 3 0.5221270322799683
val: 4 0.5076501965522766
val: 5 0.5065995454788208
val: 6 0.5187668204307556
val: 7 0.5150192975997925
val: 8 0.5181038975715637
val: 9 0.5362448692321777
val: 10 0.5085626840591431
val: 11 0.5076895952224731
val: 12 0.5112571120262146
val: 13 0.5051038861274719
val: 14 0.5039281845092773
val: 15 0.519794225692749
val: 16 0.5209048986434937
val: 17 0.527920663356781
val: 18 0.5089228749275208
val: 19 0.517305850982666
val: 20 0.5249126553535461
val_Epoch:[ 65 ] val_loss: 0.5163106411695481 2022-05-29 14:33:47.586134
start training 2022-05-29 14:33:47.695042
Epoch:[ 66 0 ] loss: 0.501379132270813 2022-05-29 14:34:14.555662
Epoch:[ 66 1 ] loss: 0.5059003829956055 2022-05-29 14:34:15.336714
Epoch:[ 66 2 ] loss: 0.5069507956504822 2022-05-29 14:34:16.103343
Epoch:[ 66 3 ] loss: 0.5006817579269409 2022-05-29 14:34:16.870812
Epoch:[ 66 4 ] loss: 0.49918150901794434 2022-05-29 14:34:17.638869
Epoch:[ 66 5 ] loss: 0.4944433569908142 2022-05-29 14:34:18.405752
Epoch:[ 66 6 ] loss: 0.5035731196403503 2022-05-29 14:34:19.170977
Epoch:[ 66 7 ] loss: 0.49890851974487305 2022-05-29 14:34:19.937611
Epoch:[ 66 8 ] loss: 0.5060743093490601 2022-05-29 14:34:20.703982
Epoch:[ 66 9 ] loss: 0.5019321441650391 2022-05-29 14:34:21.471547
Epoch:[ 66 10 ] loss: 0.502042829990387 2022-05-29 14:34:22.239087
Epoch:[ 66 11 ] loss: 0.49984797835350037 2022-05-29 14:34:23.004301
Epoch:[ 66 12 ] loss: 0.5023974180221558 2022-05-29 14:34:23.772760
Epoch:[ 66 13 ] loss: 0.503592312335968 2022-05-29 14:34:24.535992
Epoch:[ 66 14 ] loss: 0.5004233717918396 2022-05-29 14:34:25.317046
Epoch:[ 66 15 ] loss: 0.5040212273597717 2022-05-29 14:34:26.084314
Epoch:[ 66 16 ] loss: 0.5033788681030273 2022-05-29 14:34:35.287814
Epoch:[ 66 17 ] loss: 0.5044019222259521 2022-05-29 14:34:36.051585
Epoch:[ 66 18 ] loss: 0.5039815902709961 2022-05-29 14:34:36.820497
Epoch:[ 66 19 ] loss: 0.5098274350166321 2022-05-29 14:34:37.588098
Training_Epoch:[ 66 ] Training_loss: 0.5026469990611077 2022-05-29 14:34:37.588891
learning rate:  0.0005882449999999997
netparams have been saved once 66
val: 1 0.5113937854766846
val: 2 0.5027274489402771
val: 3 0.5257208943367004
val: 4 0.5129223465919495
val: 5 0.5102916955947876
val: 6 0.5146303772926331
val: 7 0.514870822429657
val: 8 0.4995560348033905
val: 9 0.5167627334594727
val: 10 0.5088199377059937
val: 11 0.5340662598609924
val: 12 0.5302727818489075
val: 13 0.5064267516136169
val: 14 0.5304163694381714
val: 15 0.5279728770256042
val: 16 0.5131186246871948
val: 17 0.5221692323684692
val: 18 0.5303765535354614
val: 19 0.5193617343902588
val: 20 0.5056762099266052
val_Epoch:[ 66 ] val_loss: 0.5168776735663414 2022-05-29 14:34:43.509535
start training 2022-05-29 14:34:43.615875
Epoch:[ 67 0 ] loss: 0.503529965877533 2022-05-29 14:35:09.064792
Epoch:[ 67 1 ] loss: 0.49893248081207275 2022-05-29 14:35:09.831995
Epoch:[ 67 2 ] loss: 0.4939540922641754 2022-05-29 14:35:10.612549
Epoch:[ 67 3 ] loss: 0.5035563111305237 2022-05-29 14:35:11.379210
Epoch:[ 67 4 ] loss: 0.49716562032699585 2022-05-29 14:35:12.146587
Epoch:[ 67 5 ] loss: 0.5007330775260925 2022-05-29 14:35:12.913940
Epoch:[ 67 6 ] loss: 0.5044963955879211 2022-05-29 14:35:13.680233
Epoch:[ 67 7 ] loss: 0.49836447834968567 2022-05-29 14:35:14.458130
Epoch:[ 67 8 ] loss: 0.5064657926559448 2022-05-29 14:35:15.223612
Epoch:[ 67 9 ] loss: 0.4995097219944 2022-05-29 14:35:15.991644
Epoch:[ 67 10 ] loss: 0.5004100203514099 2022-05-29 14:35:16.757229
Epoch:[ 67 11 ] loss: 0.50237637758255 2022-05-29 14:35:17.523574
Epoch:[ 67 12 ] loss: 0.5018672943115234 2022-05-29 14:35:18.290859
Epoch:[ 67 13 ] loss: 0.5028921961784363 2022-05-29 14:35:19.057483
Epoch:[ 67 14 ] loss: 0.5012925863265991 2022-05-29 14:35:19.825002
Epoch:[ 67 15 ] loss: 0.5010029673576355 2022-05-29 14:35:20.592204
Epoch:[ 67 16 ] loss: 0.5044730305671692 2022-05-29 14:35:28.230316
Epoch:[ 67 17 ] loss: 0.49791696667671204 2022-05-29 14:35:28.994165
Epoch:[ 67 18 ] loss: 0.5094210505485535 2022-05-29 14:35:29.763452
Epoch:[ 67 19 ] loss: 0.5104528665542603 2022-05-29 14:35:31.700292
Training_Epoch:[ 67 ] Training_loss: 0.5019406646490097 2022-05-29 14:35:31.701049
learning rate:  0.0005882449999999997
val: 1 0.507455587387085
val: 2 0.5170341730117798
val: 3 0.5106066465377808
val: 4 0.5089669227600098
val: 5 0.4977637529373169
val: 6 0.5232868194580078
val: 7 0.5187357664108276
val: 8 0.5269289016723633
val: 9 0.5213084816932678
val: 10 0.5214753746986389
val: 11 0.5147367119789124
val: 12 0.52048659324646
val: 13 0.5222281813621521
val: 14 0.5042073726654053
val: 15 0.5255065560340881
val: 16 0.5226751565933228
val: 17 0.5204973220825195
val: 18 0.526077151298523
val: 19 0.5202251672744751
val: 20 0.5242556929588318
val_Epoch:[ 67 ] val_loss: 0.5177229166030883 2022-05-29 14:35:37.241909
start training 2022-05-29 14:35:37.350360
Epoch:[ 68 0 ] loss: 0.5018906593322754 2022-05-29 14:36:05.150076
Epoch:[ 68 1 ] loss: 0.4990859031677246 2022-05-29 14:36:05.915695
Epoch:[ 68 2 ] loss: 0.496683806180954 2022-05-29 14:36:06.692929
Epoch:[ 68 3 ] loss: 0.49755704402923584 2022-05-29 14:36:07.473853
Epoch:[ 68 4 ] loss: 0.5031639337539673 2022-05-29 14:36:08.239866
Epoch:[ 68 5 ] loss: 0.5040380954742432 2022-05-29 14:36:09.006635
Epoch:[ 68 6 ] loss: 0.5036464333534241 2022-05-29 14:36:09.774066
Epoch:[ 68 7 ] loss: 0.5011687278747559 2022-05-29 14:36:10.540017
Epoch:[ 68 8 ] loss: 0.5024247169494629 2022-05-29 14:36:11.308404
Epoch:[ 68 9 ] loss: 0.4986467659473419 2022-05-29 14:36:12.074498
Epoch:[ 68 10 ] loss: 0.5022767186164856 2022-05-29 14:36:12.841919
Epoch:[ 68 11 ] loss: 0.49878937005996704 2022-05-29 14:36:13.606999
Epoch:[ 68 12 ] loss: 0.5032488107681274 2022-05-29 14:36:14.374432
Epoch:[ 68 13 ] loss: 0.5022662281990051 2022-05-29 14:36:15.140375
Epoch:[ 68 14 ] loss: 0.501318097114563 2022-05-29 14:36:15.907717
Epoch:[ 68 15 ] loss: 0.5037429332733154 2022-05-29 14:36:16.674710
Epoch:[ 68 16 ] loss: 0.49977830052375793 2022-05-29 14:36:23.494130
Epoch:[ 68 17 ] loss: 0.5019479393959045 2022-05-29 14:36:24.261917
Epoch:[ 68 18 ] loss: 0.5013338327407837 2022-05-29 14:36:25.061745
Epoch:[ 68 19 ] loss: 0.5016443133354187 2022-05-29 14:36:25.827383
Training_Epoch:[ 68 ] Training_loss: 0.5012326315045357 2022-05-29 14:36:25.828197
learning rate:  0.0005882449999999997
netparams have been saved once 68
val: 1 0.5280700325965881
val: 2 0.5324398279190063
val: 3 0.5335145592689514
val: 4 0.5054088234901428
val: 5 0.5086104869842529
val: 6 0.5108789205551147
val: 7 0.5368941426277161
val: 8 0.5045933723449707
val: 9 0.5291444063186646
val: 10 0.5175212621688843
val: 11 0.4965066611766815
val: 12 0.5071350932121277
val: 13 0.49468275904655457
val: 14 0.5146855115890503
val: 15 0.5242554545402527
val: 16 0.5347012877464294
val: 17 0.5162214636802673
val: 18 0.510242760181427
val: 19 0.5252677798271179
val: 20 0.5275964736938477
val_Epoch:[ 68 ] val_loss: 0.5179185539484024 2022-05-29 14:36:31.533641
start training 2022-05-29 14:36:31.645880
Epoch:[ 69 0 ] loss: 0.4993545413017273 2022-05-29 14:36:56.635345
Epoch:[ 69 1 ] loss: 0.5004727244377136 2022-05-29 14:36:57.444754
Epoch:[ 69 2 ] loss: 0.5017880201339722 2022-05-29 14:36:58.324614
Epoch:[ 69 3 ] loss: 0.5056549906730652 2022-05-29 14:36:59.089374
Epoch:[ 69 4 ] loss: 0.5071128010749817 2022-05-29 14:36:59.854972
Epoch:[ 69 5 ] loss: 0.4996383488178253 2022-05-29 14:37:00.619417
Epoch:[ 69 6 ] loss: 0.5002061724662781 2022-05-29 14:37:01.387146
Epoch:[ 69 7 ] loss: 0.4968400299549103 2022-05-29 14:37:02.155168
Epoch:[ 69 8 ] loss: 0.5041900277137756 2022-05-29 14:37:02.920956
Epoch:[ 69 9 ] loss: 0.4988667666912079 2022-05-29 14:37:03.690089
Epoch:[ 69 10 ] loss: 0.49794238805770874 2022-05-29 14:37:04.468928
Epoch:[ 69 11 ] loss: 0.5005202889442444 2022-05-29 14:37:05.235017
Epoch:[ 69 12 ] loss: 0.49729955196380615 2022-05-29 14:37:06.002803
Epoch:[ 69 13 ] loss: 0.5007284283638 2022-05-29 14:37:06.768165
Epoch:[ 69 14 ] loss: 0.5001441836357117 2022-05-29 14:37:07.534407
Epoch:[ 69 15 ] loss: 0.504298746585846 2022-05-29 14:37:08.299852
Epoch:[ 69 16 ] loss: 0.5014027953147888 2022-05-29 14:37:16.111525
Epoch:[ 69 17 ] loss: 0.5035807490348816 2022-05-29 14:37:16.877068
Epoch:[ 69 18 ] loss: 0.5013573169708252 2022-05-29 14:37:18.798448
Epoch:[ 69 19 ] loss: 0.5003257393836975 2022-05-29 14:37:20.404956
Training_Epoch:[ 69 ] Training_loss: 0.5010862305760384 2022-05-29 14:37:20.405775
learning rate:  0.0005882449999999997
val: 1 0.5148754119873047
val: 2 0.513847291469574
val: 3 0.5135595202445984
val: 4 0.5149466395378113
val: 5 0.5109455585479736
val: 6 0.5370538234710693
val: 7 0.5105412602424622
val: 8 0.5176153779029846
val: 9 0.5054084062576294
val: 10 0.5203357934951782
val: 11 0.5175688862800598
val: 12 0.5087209343910217
val: 13 0.5248337984085083
val: 14 0.5193206071853638
val: 15 0.5214961171150208
val: 16 0.5156527757644653
val: 17 0.5175954699516296
val: 18 0.5230763554573059
val: 19 0.5134915709495544
val: 20 0.5327415466308594
val_Epoch:[ 69 ] val_loss: 0.5176813572645187 2022-05-29 14:37:25.921974
start training 2022-05-29 14:37:26.030098
Epoch:[ 70 0 ] loss: 0.5021522045135498 2022-05-29 14:37:51.910681
Epoch:[ 70 1 ] loss: 0.502251148223877 2022-05-29 14:37:52.714280
Epoch:[ 70 2 ] loss: 0.5033755898475647 2022-05-29 14:37:53.490707
Epoch:[ 70 3 ] loss: 0.5006029009819031 2022-05-29 14:37:54.256395
Epoch:[ 70 4 ] loss: 0.5124378800392151 2022-05-29 14:37:55.021537
Epoch:[ 70 5 ] loss: 0.5010242462158203 2022-05-29 14:37:55.788314
Epoch:[ 70 6 ] loss: 0.5017392039299011 2022-05-29 14:37:56.555048
Epoch:[ 70 7 ] loss: 0.501501739025116 2022-05-29 14:37:57.333361
Epoch:[ 70 8 ] loss: 0.504435658454895 2022-05-29 14:37:58.099667
Epoch:[ 70 9 ] loss: 0.5019007325172424 2022-05-29 14:37:58.865321
Epoch:[ 70 10 ] loss: 0.498466819524765 2022-05-29 14:37:59.630993
Epoch:[ 70 11 ] loss: 0.5045201778411865 2022-05-29 14:38:00.395699
Epoch:[ 70 12 ] loss: 0.5015141367912292 2022-05-29 14:38:01.163086
Epoch:[ 70 13 ] loss: 0.5029946565628052 2022-05-29 14:38:01.927569
Epoch:[ 70 14 ] loss: 0.5008276700973511 2022-05-29 14:38:02.695168
Epoch:[ 70 15 ] loss: 0.5016888976097107 2022-05-29 14:38:03.459961
Epoch:[ 70 16 ] loss: 0.5012854933738708 2022-05-29 14:38:11.430062
Epoch:[ 70 17 ] loss: 0.5004416704177856 2022-05-29 14:38:12.193686
Epoch:[ 70 18 ] loss: 0.502241849899292 2022-05-29 14:38:12.956363
Epoch:[ 70 19 ] loss: 0.5050808787345886 2022-05-29 14:38:13.724551
Training_Epoch:[ 70 ] Training_loss: 0.5025241777300835 2022-05-29 14:38:13.725405
learning rate:  0.0005882449999999997
netparams have been saved once 70
val: 1 0.5121920704841614
val: 2 0.517674446105957
val: 3 0.51891028881073
val: 4 0.522316575050354
val: 5 0.5033785700798035
val: 6 0.5286328196525574
val: 7 0.5313653349876404
val: 8 0.5082883834838867
val: 9 0.5112758874893188
val: 10 0.5105015635490417
val: 11 0.5199623107910156
val: 12 0.49645134806632996
val: 13 0.5282592177391052
val: 14 0.5197529792785645
val: 15 0.5078279972076416
val: 16 0.5255113840103149
val: 17 0.5126858949661255
val: 18 0.5252910852432251
val: 19 0.516018271446228
val: 20 0.5138886570930481
val_Epoch:[ 70 ] val_loss: 0.5165092542767524 2022-05-29 14:38:19.463466
start training 2022-05-29 14:38:19.570814
Epoch:[ 71 0 ] loss: 0.5069370865821838 2022-05-29 14:38:46.187700
Epoch:[ 71 1 ] loss: 0.5006817579269409 2022-05-29 14:38:46.953774
Epoch:[ 71 2 ] loss: 0.5002896785736084 2022-05-29 14:38:47.719663
Epoch:[ 71 3 ] loss: 0.49925005435943604 2022-05-29 14:38:48.484476
Epoch:[ 71 4 ] loss: 0.49854418635368347 2022-05-29 14:38:49.247746
Epoch:[ 71 5 ] loss: 0.5003451704978943 2022-05-29 14:38:50.013724
Epoch:[ 71 6 ] loss: 0.4985073208808899 2022-05-29 14:38:50.780433
Epoch:[ 71 7 ] loss: 0.4985547363758087 2022-05-29 14:38:51.544274
Epoch:[ 71 8 ] loss: 0.49418774247169495 2022-05-29 14:38:52.320650
Epoch:[ 71 9 ] loss: 0.4982930123806 2022-05-29 14:38:53.089142
Epoch:[ 71 10 ] loss: 0.5024768710136414 2022-05-29 14:38:53.866060
Epoch:[ 71 11 ] loss: 0.5009503960609436 2022-05-29 14:38:54.630824
Epoch:[ 71 12 ] loss: 0.4920840263366699 2022-05-29 14:38:55.394754
Epoch:[ 71 13 ] loss: 0.49898597598075867 2022-05-29 14:38:56.159374
Epoch:[ 71 14 ] loss: 0.49789896607398987 2022-05-29 14:38:56.923852
Epoch:[ 71 15 ] loss: 0.49954164028167725 2022-05-29 14:38:57.692327
Epoch:[ 71 16 ] loss: 0.49570363759994507 2022-05-29 14:39:06.313414
Epoch:[ 71 17 ] loss: 0.49519824981689453 2022-05-29 14:39:07.527157
Epoch:[ 71 18 ] loss: 0.49655261635780334 2022-05-29 14:39:08.298539
Epoch:[ 71 19 ] loss: 0.4998537003993988 2022-05-29 14:39:09.062853
Training_Epoch:[ 71 ] Training_loss: 0.4987418413162231 2022-05-29 14:39:09.063623
learning rate:  0.0004117714999999998
val: 1 0.525109589099884
val: 2 0.5055851340293884
val: 3 0.5106645822525024
val: 4 0.5180050730705261
val: 5 0.5217543840408325
val: 6 0.5167554020881653
val: 7 0.5172136425971985
val: 8 0.5263374447822571
val: 9 0.5359926819801331
val: 10 0.5069805383682251
val: 11 0.5133016109466553
val: 12 0.5292052626609802
val: 13 0.5213132500648499
val: 14 0.5261523127555847
val: 15 0.5106084942817688
val: 16 0.5306034088134766
val: 17 0.5118467807769775
val: 18 0.5186421871185303
val: 19 0.498992919921875
val: 20 0.5354917645454407
val_Epoch:[ 71 ] val_loss: 0.5190278232097626 2022-05-29 14:39:14.564506
start training 2022-05-29 14:39:14.672378
Epoch:[ 72 0 ] loss: 0.49539822340011597 2022-05-29 14:39:40.954440
Epoch:[ 72 1 ] loss: 0.4978288412094116 2022-05-29 14:39:41.719962
Epoch:[ 72 2 ] loss: 0.5015057921409607 2022-05-29 14:39:42.486732
Epoch:[ 72 3 ] loss: 0.4973071217536926 2022-05-29 14:39:43.252218
Epoch:[ 72 4 ] loss: 0.4989107549190521 2022-05-29 14:39:44.029814
Epoch:[ 72 5 ] loss: 0.49886640906333923 2022-05-29 14:39:44.792838
Epoch:[ 72 6 ] loss: 0.5021180510520935 2022-05-29 14:39:45.558661
Epoch:[ 72 7 ] loss: 0.49771806597709656 2022-05-29 14:39:46.323904
Epoch:[ 72 8 ] loss: 0.4967929422855377 2022-05-29 14:39:47.090037
Epoch:[ 72 9 ] loss: 0.49609652161598206 2022-05-29 14:39:47.855849
Epoch:[ 72 10 ] loss: 0.4958741068840027 2022-05-29 14:39:48.620474
Epoch:[ 72 11 ] loss: 0.4979460537433624 2022-05-29 14:39:49.385397
Epoch:[ 72 12 ] loss: 0.4960383474826813 2022-05-29 14:39:50.162131
Epoch:[ 72 13 ] loss: 0.49703407287597656 2022-05-29 14:39:50.928938
Epoch:[ 72 14 ] loss: 0.4956878423690796 2022-05-29 14:39:51.696142
Epoch:[ 72 15 ] loss: 0.4985779821872711 2022-05-29 14:39:52.460951
Epoch:[ 72 16 ] loss: 0.4979832172393799 2022-05-29 14:40:00.094526
Epoch:[ 72 17 ] loss: 0.4988700747489929 2022-05-29 14:40:00.860083
Epoch:[ 72 18 ] loss: 0.49631842970848083 2022-05-29 14:40:02.477876
Epoch:[ 72 19 ] loss: 0.49773868918418884 2022-05-29 14:40:03.243774
Training_Epoch:[ 72 ] Training_loss: 0.49773057699203493 2022-05-29 14:40:03.244589
learning rate:  0.0004117714999999998
netparams have been saved once 72
val: 1 0.5257740616798401
val: 2 0.5320077538490295
val: 3 0.5326471328735352
val: 4 0.508897066116333
val: 5 0.5284382104873657
val: 6 0.47835564613342285
val: 7 0.5174323320388794
val: 8 0.5190429091453552
val: 9 0.5174332857131958
val: 10 0.5225986838340759
val: 11 0.5034435987472534
val: 12 0.5144221186637878
val: 13 0.5177710056304932
val: 14 0.4999643564224243
val: 15 0.510389506816864
val: 16 0.5160015821456909
val: 17 0.508726954460144
val: 18 0.5117594599723816
val: 19 0.5102965235710144
val: 20 0.5257889032363892
val_Epoch:[ 72 ] val_loss: 0.5150595545768738 2022-05-29 14:40:08.935875
start training 2022-05-29 14:40:09.041599
Epoch:[ 73 0 ] loss: 0.49608251452445984 2022-05-29 14:40:35.007170
Epoch:[ 73 1 ] loss: 0.49693968892097473 2022-05-29 14:40:35.776765
Epoch:[ 73 2 ] loss: 0.49478551745414734 2022-05-29 14:40:36.557259
Epoch:[ 73 3 ] loss: 0.4963887333869934 2022-05-29 14:40:37.326544
Epoch:[ 73 4 ] loss: 0.4972985088825226 2022-05-29 14:40:38.092188
Epoch:[ 73 5 ] loss: 0.4947003424167633 2022-05-29 14:40:38.856457
Epoch:[ 73 6 ] loss: 0.4971911609172821 2022-05-29 14:40:39.623898
Epoch:[ 73 7 ] loss: 0.5009145736694336 2022-05-29 14:40:40.389763
Epoch:[ 73 8 ] loss: 0.4980414807796478 2022-05-29 14:40:41.154446
Epoch:[ 73 9 ] loss: 0.4924495220184326 2022-05-29 14:40:41.930679
Epoch:[ 73 10 ] loss: 0.4943692684173584 2022-05-29 14:40:42.695166
Epoch:[ 73 11 ] loss: 0.4996943175792694 2022-05-29 14:40:43.460185
Epoch:[ 73 12 ] loss: 0.49711257219314575 2022-05-29 14:40:44.223679
Epoch:[ 73 13 ] loss: 0.4944279193878174 2022-05-29 14:40:44.987137
Epoch:[ 73 14 ] loss: 0.4978248178958893 2022-05-29 14:40:45.752629
Epoch:[ 73 15 ] loss: 0.495963990688324 2022-05-29 14:40:46.518649
Epoch:[ 73 16 ] loss: 0.5017615556716919 2022-05-29 14:40:54.752431
Epoch:[ 73 17 ] loss: 0.4966839551925659 2022-05-29 14:40:55.516670
Epoch:[ 73 18 ] loss: 0.5019825100898743 2022-05-29 14:40:56.300923
Epoch:[ 73 19 ] loss: 0.49366968870162964 2022-05-29 14:40:57.067993
Training_Epoch:[ 73 ] Training_loss: 0.49691413193941114 2022-05-29 14:40:57.068758
learning rate:  0.0004117714999999998
val: 1 0.5366032719612122
val: 2 0.5152716636657715
val: 3 0.5363088250160217
val: 4 0.5248041152954102
val: 5 0.5230389833450317
val: 6 0.5437424778938293
val: 7 0.5376008749008179
val: 8 0.5138612389564514
val: 9 0.5145530104637146
val: 10 0.5152188539505005
val: 11 0.5047165751457214
val: 12 0.5048174858093262
val: 13 0.5142919421195984
val: 14 0.5044968724250793
val: 15 0.5131582021713257
val: 16 0.5270597338676453
val: 17 0.527127742767334
val: 18 0.5422990322113037
val: 19 0.52907794713974
val: 20 0.5298432111740112
val_Epoch:[ 73 ] val_loss: 0.5228946030139923 2022-05-29 14:41:02.690640
start training 2022-05-29 14:41:02.798913
Epoch:[ 74 0 ] loss: 0.49931636452674866 2022-05-29 14:41:28.834080
Epoch:[ 74 1 ] loss: 0.4934578537940979 2022-05-29 14:41:29.649843
Epoch:[ 74 2 ] loss: 0.4963498115539551 2022-05-29 14:41:30.418231
Epoch:[ 74 3 ] loss: 0.4923500418663025 2022-05-29 14:41:31.184158
Epoch:[ 74 4 ] loss: 0.4945504665374756 2022-05-29 14:41:31.950127
Epoch:[ 74 5 ] loss: 0.5020079612731934 2022-05-29 14:41:32.730697
Epoch:[ 74 6 ] loss: 0.49485915899276733 2022-05-29 14:41:33.497119
Epoch:[ 74 7 ] loss: 0.49493375420570374 2022-05-29 14:41:34.263917
Epoch:[ 74 8 ] loss: 0.4980640411376953 2022-05-29 14:41:35.031025
Epoch:[ 74 9 ] loss: 0.49458053708076477 2022-05-29 14:41:35.800014
Epoch:[ 74 10 ] loss: 0.4977622628211975 2022-05-29 14:41:36.566963
Epoch:[ 74 11 ] loss: 0.4899630546569824 2022-05-29 14:41:37.334553
Epoch:[ 74 12 ] loss: 0.49830254912376404 2022-05-29 14:41:38.100454
Epoch:[ 74 13 ] loss: 0.4953267574310303 2022-05-29 14:41:38.867154
Epoch:[ 74 14 ] loss: 0.4955490529537201 2022-05-29 14:41:39.632209
Epoch:[ 74 15 ] loss: 0.4964260160923004 2022-05-29 14:41:40.399689
Epoch:[ 74 16 ] loss: 0.4944821894168854 2022-05-29 14:41:47.971998
Epoch:[ 74 17 ] loss: 0.49574029445648193 2022-05-29 14:41:49.960770
Epoch:[ 74 18 ] loss: 0.49250370264053345 2022-05-29 14:41:50.731051
Epoch:[ 74 19 ] loss: 0.49586376547813416 2022-05-29 14:41:51.495324
Training_Epoch:[ 74 ] Training_loss: 0.49561948180198667 2022-05-29 14:41:51.496109
learning rate:  0.0004117714999999998
netparams have been saved once 74
val: 1 0.5241594910621643
val: 2 0.5114396214485168
val: 3 0.5077148675918579
val: 4 0.5219095349311829
val: 5 0.5248285531997681
val: 6 0.5206212401390076
val: 7 0.5266615748405457
val: 8 0.5107728242874146
val: 9 0.5005345940589905
val: 10 0.5147097706794739
val: 11 0.5219999551773071
val: 12 0.5288774967193604
val: 13 0.5232273936271667
val: 14 0.5139521360397339
val: 15 0.4905925393104553
val: 16 0.521347165107727
val: 17 0.5208935737609863
val: 18 0.5047298073768616
val: 19 0.496110737323761
val: 20 0.49408987164497375
val_Epoch:[ 74 ] val_loss: 0.5139586374163627 2022-05-29 14:41:57.101972
start training 2022-05-29 14:41:57.207084
Epoch:[ 75 0 ] loss: 0.496672660112381 2022-05-29 14:42:22.393949
Epoch:[ 75 1 ] loss: 0.49406880140304565 2022-05-29 14:42:23.192749
Epoch:[ 75 2 ] loss: 0.4917171895503998 2022-05-29 14:42:24.004302
Epoch:[ 75 3 ] loss: 0.4919091761112213 2022-05-29 14:42:24.784128
Epoch:[ 75 4 ] loss: 0.494340717792511 2022-05-29 14:42:25.551320
Epoch:[ 75 5 ] loss: 0.4949951171875 2022-05-29 14:42:26.317215
Epoch:[ 75 6 ] loss: 0.49603188037872314 2022-05-29 14:42:27.081635
Epoch:[ 75 7 ] loss: 0.4968772530555725 2022-05-29 14:42:27.848356
Epoch:[ 75 8 ] loss: 0.4988427460193634 2022-05-29 14:42:28.611819
Epoch:[ 75 9 ] loss: 0.4937097728252411 2022-05-29 14:42:29.376636
Epoch:[ 75 10 ] loss: 0.49485093355178833 2022-05-29 14:42:30.143201
Epoch:[ 75 11 ] loss: 0.4992682933807373 2022-05-29 14:42:30.910264
Epoch:[ 75 12 ] loss: 0.4914323687553406 2022-05-29 14:42:31.674185
Epoch:[ 75 13 ] loss: 0.4966641962528229 2022-05-29 14:42:32.451571
Epoch:[ 75 14 ] loss: 0.49469292163848877 2022-05-29 14:42:33.215834
Epoch:[ 75 15 ] loss: 0.496085524559021 2022-05-29 14:42:33.982489
Epoch:[ 75 16 ] loss: 0.4996071755886078 2022-05-29 14:42:41.764280
Epoch:[ 75 17 ] loss: 0.49482008814811707 2022-05-29 14:42:42.529413
Epoch:[ 75 18 ] loss: 0.49585044384002686 2022-05-29 14:42:43.294825
Epoch:[ 75 19 ] loss: 0.4979144036769867 2022-05-29 14:42:44.532765
Training_Epoch:[ 75 ] Training_loss: 0.49551758319139483 2022-05-29 14:42:44.533532
learning rate:  0.0004117714999999998
val: 1 0.5171793103218079
val: 2 0.5302051901817322
val: 3 0.5318731665611267
val: 4 0.5295698642730713
val: 5 0.5345554351806641
val: 6 0.5185570120811462
val: 7 0.5321878790855408
val: 8 0.5257055163383484
val: 9 0.5331144332885742
val: 10 0.5203930139541626
val: 11 0.5291462540626526
val: 12 0.54012531042099
val: 13 0.5200363993644714
val: 14 0.5313811898231506
val: 15 0.5532234311103821
val: 16 0.5262863039970398
val: 17 0.5255333185195923
val: 18 0.5202233195304871
val: 19 0.5438260436058044
val: 20 0.542580783367157
val_Epoch:[ 75 ] val_loss: 0.5302851587533951 2022-05-29 14:42:50.024994
start training 2022-05-29 14:42:50.134360
Epoch:[ 76 0 ] loss: 0.4909018576145172 2022-05-29 14:43:15.791036
Epoch:[ 76 1 ] loss: 0.4964195489883423 2022-05-29 14:43:16.608491
Epoch:[ 76 2 ] loss: 0.4997682571411133 2022-05-29 14:43:17.372450
Epoch:[ 76 3 ] loss: 0.5020122528076172 2022-05-29 14:43:18.136036
Epoch:[ 76 4 ] loss: 0.4969472289085388 2022-05-29 14:43:18.903439
Epoch:[ 76 5 ] loss: 0.49893680214881897 2022-05-29 14:43:19.669152
Epoch:[ 76 6 ] loss: 0.4964389204978943 2022-05-29 14:43:20.436265
Epoch:[ 76 7 ] loss: 0.48911839723587036 2022-05-29 14:43:21.200639
Epoch:[ 76 8 ] loss: 0.49900102615356445 2022-05-29 14:43:21.966004
Epoch:[ 76 9 ] loss: 0.4917958080768585 2022-05-29 14:43:22.744467
Epoch:[ 76 10 ] loss: 0.4927173852920532 2022-05-29 14:43:23.509314
Epoch:[ 76 11 ] loss: 0.49615246057510376 2022-05-29 14:43:24.276182
Epoch:[ 76 12 ] loss: 0.49225911498069763 2022-05-29 14:43:25.042404
Epoch:[ 76 13 ] loss: 0.49125686287879944 2022-05-29 14:43:25.807144
Epoch:[ 76 14 ] loss: 0.4971141219139099 2022-05-29 14:43:26.573418
Epoch:[ 76 15 ] loss: 0.49438825249671936 2022-05-29 14:43:27.340278
Epoch:[ 76 16 ] loss: 0.49621084332466125 2022-05-29 14:43:35.122341
Epoch:[ 76 17 ] loss: 0.4959985613822937 2022-05-29 14:43:35.886487
Epoch:[ 76 18 ] loss: 0.4930175840854645 2022-05-29 14:43:36.653553
Epoch:[ 76 19 ] loss: 0.4927319884300232 2022-05-29 14:43:37.418962
Training_Epoch:[ 76 ] Training_loss: 0.49515936374664304 2022-05-29 14:43:37.419741
learning rate:  0.0004117714999999998
netparams have been saved once 76
val: 1 0.5233725309371948
val: 2 0.5133953094482422
val: 3 0.5159501433372498
val: 4 0.5260317921638489
val: 5 0.5022912621498108
val: 6 0.5389494895935059
val: 7 0.5146473050117493
val: 8 0.5005823373794556
val: 9 0.499580055475235
val: 10 0.5148662328720093
val: 11 0.5022475719451904
val: 12 0.5223652720451355
val: 13 0.5312723517417908
val: 14 0.5233948826789856
val: 15 0.49981236457824707
val: 16 0.5136939883232117
val: 17 0.5185448527336121
val: 18 0.5000622272491455
val: 19 0.5257092714309692
val: 20 0.5155602097511292
val_Epoch:[ 76 ] val_loss: 0.5151164725422859 2022-05-29 14:43:43.009534
start training 2022-05-29 14:43:43.113024
Epoch:[ 77 0 ] loss: 0.4949283301830292 2022-05-29 14:44:08.184361
Epoch:[ 77 1 ] loss: 0.4941794276237488 2022-05-29 14:44:09.016448
Epoch:[ 77 2 ] loss: 0.4908478558063507 2022-05-29 14:44:09.783881
Epoch:[ 77 3 ] loss: 0.4934226870536804 2022-05-29 14:44:10.549992
Epoch:[ 77 4 ] loss: 0.4930139482021332 2022-05-29 14:44:11.316742
Epoch:[ 77 5 ] loss: 0.493088036775589 2022-05-29 14:44:12.084140
Epoch:[ 77 6 ] loss: 0.4957181513309479 2022-05-29 14:44:12.852747
Epoch:[ 77 7 ] loss: 0.4933243989944458 2022-05-29 14:44:13.622544
Epoch:[ 77 8 ] loss: 0.4969208836555481 2022-05-29 14:44:14.390195
Epoch:[ 77 9 ] loss: 0.4947403073310852 2022-05-29 14:44:15.170548
Epoch:[ 77 10 ] loss: 0.4922995865345001 2022-05-29 14:44:15.940093
Epoch:[ 77 11 ] loss: 0.49730387330055237 2022-05-29 14:44:16.707389
Epoch:[ 77 12 ] loss: 0.4873778522014618 2022-05-29 14:44:17.488276
Epoch:[ 77 13 ] loss: 0.4931209683418274 2022-05-29 14:44:18.257052
Epoch:[ 77 14 ] loss: 0.4996441900730133 2022-05-29 14:44:19.023050
Epoch:[ 77 15 ] loss: 0.4957241714000702 2022-05-29 14:44:19.790839
Epoch:[ 77 16 ] loss: 0.494035005569458 2022-05-29 14:44:27.339314
Epoch:[ 77 17 ] loss: 0.49519082903862 2022-05-29 14:44:28.103615
Epoch:[ 77 18 ] loss: 0.4912780225276947 2022-05-29 14:44:28.873011
Epoch:[ 77 19 ] loss: 0.4932449460029602 2022-05-29 14:44:29.639170
Training_Epoch:[ 77 ] Training_loss: 0.4939701735973358 2022-05-29 14:44:29.639901
learning rate:  0.0004117714999999998
val: 1 0.5119583606719971
val: 2 0.5142784714698792
val: 3 0.5146364569664001
val: 4 0.518954873085022
val: 5 0.5323606729507446
val: 6 0.5028915405273438
val: 7 0.5149791240692139
val: 8 0.5043234825134277
val: 9 0.5144293904304504
val: 10 0.5097699761390686
val: 11 0.519999086856842
val: 12 0.5102506875991821
val: 13 0.502421498298645
val: 14 0.512222170829773
val: 15 0.5198934674263
val: 16 0.49984773993492126
val: 17 0.5281860828399658
val: 18 0.5142943263053894
val: 19 0.5012388229370117
val: 20 0.5070465803146362
val_Epoch:[ 77 ] val_loss: 0.5126991406083107 2022-05-29 14:44:35.260272
start training 2022-05-29 14:44:35.370760
Epoch:[ 78 0 ] loss: 0.4915560185909271 2022-05-29 14:45:00.741337
Epoch:[ 78 1 ] loss: 0.4951022267341614 2022-05-29 14:45:01.585936
Epoch:[ 78 2 ] loss: 0.4941236972808838 2022-05-29 14:45:02.376742
Epoch:[ 78 3 ] loss: 0.48755547404289246 2022-05-29 14:45:03.143171
Epoch:[ 78 4 ] loss: 0.4957033097743988 2022-05-29 14:45:03.906859
Epoch:[ 78 5 ] loss: 0.4911592900753021 2022-05-29 14:45:04.673396
Epoch:[ 78 6 ] loss: 0.49401381611824036 2022-05-29 14:45:05.440662
Epoch:[ 78 7 ] loss: 0.49292367696762085 2022-05-29 14:45:06.205671
Epoch:[ 78 8 ] loss: 0.49273213744163513 2022-05-29 14:45:06.971323
Epoch:[ 78 9 ] loss: 0.49262720346450806 2022-05-29 14:45:07.737111
Epoch:[ 78 10 ] loss: 0.4907165467739105 2022-05-29 14:45:08.516483
Epoch:[ 78 11 ] loss: 0.49787119030952454 2022-05-29 14:45:09.282338
Epoch:[ 78 12 ] loss: 0.4993477463722229 2022-05-29 14:45:10.047042
Epoch:[ 78 13 ] loss: 0.492377907037735 2022-05-29 14:45:10.812903
Epoch:[ 78 14 ] loss: 0.49424004554748535 2022-05-29 14:45:11.580953
Epoch:[ 78 15 ] loss: 0.4933212697505951 2022-05-29 14:45:12.360760
Epoch:[ 78 16 ] loss: 0.4923604726791382 2022-05-29 14:45:20.673970
Epoch:[ 78 17 ] loss: 0.49294763803482056 2022-05-29 14:45:21.439996
Epoch:[ 78 18 ] loss: 0.49115854501724243 2022-05-29 14:45:22.208199
Epoch:[ 78 19 ] loss: 0.49393051862716675 2022-05-29 14:45:22.973065
Training_Epoch:[ 78 ] Training_loss: 0.4932884365320206 2022-05-29 14:45:22.973822
learning rate:  0.0004117714999999998
netparams have been saved once 78
val: 1 0.5034939646720886
val: 2 0.5055940747261047
val: 3 0.5062665939331055
val: 4 0.510590672492981
val: 5 0.5210144519805908
val: 6 0.5171718001365662
val: 7 0.526053786277771
val: 8 0.5048922896385193
val: 9 0.5289915800094604
val: 10 0.5150744915008545
val: 11 0.49998751282691956
val: 12 0.5250719785690308
val: 13 0.5122115612030029
val: 14 0.511161744594574
val: 15 0.5082569122314453
val: 16 0.5126432180404663
val: 17 0.5065774321556091
val: 18 0.5159463286399841
val: 19 0.517505407333374
val: 20 0.5168255567550659
val_Epoch:[ 78 ] val_loss: 0.5132665678858757 2022-05-29 14:45:28.587717
start training 2022-05-29 14:45:28.699525
Epoch:[ 79 0 ] loss: 0.49284663796424866 2022-05-29 14:45:54.602822
Epoch:[ 79 1 ] loss: 0.4926583468914032 2022-05-29 14:45:55.372237
Epoch:[ 79 2 ] loss: 0.4936143755912781 2022-05-29 14:45:56.155546
Epoch:[ 79 3 ] loss: 0.49451297521591187 2022-05-29 14:45:56.922151
Epoch:[ 79 4 ] loss: 0.49275654554367065 2022-05-29 14:45:57.690673
Epoch:[ 79 5 ] loss: 0.4943746328353882 2022-05-29 14:45:58.459001
Epoch:[ 79 6 ] loss: 0.49408474564552307 2022-05-29 14:45:59.225739
Epoch:[ 79 7 ] loss: 0.49855637550354004 2022-05-29 14:45:59.994886
Epoch:[ 79 8 ] loss: 0.49412742257118225 2022-05-29 14:46:00.764574
Epoch:[ 79 9 ] loss: 0.49424776434898376 2022-05-29 14:46:01.529300
Epoch:[ 79 10 ] loss: 0.4883427321910858 2022-05-29 14:46:02.296924
Epoch:[ 79 11 ] loss: 0.4920521378517151 2022-05-29 14:46:03.063856
Epoch:[ 79 12 ] loss: 0.49063944816589355 2022-05-29 14:46:03.882134
Epoch:[ 79 13 ] loss: 0.49204137921333313 2022-05-29 14:46:04.701556
Epoch:[ 79 14 ] loss: 0.49074891209602356 2022-05-29 14:46:05.479780
Epoch:[ 79 15 ] loss: 0.4944911599159241 2022-05-29 14:46:06.288318
Epoch:[ 79 16 ] loss: 0.4939552843570709 2022-05-29 14:46:14.061977
Epoch:[ 79 17 ] loss: 0.49075764417648315 2022-05-29 14:46:14.938818
Epoch:[ 79 18 ] loss: 0.49757125973701477 2022-05-29 14:46:15.833250
Epoch:[ 79 19 ] loss: 0.4899100661277771 2022-05-29 14:46:16.710905
Training_Epoch:[ 79 ] Training_loss: 0.4931144922971725 2022-05-29 14:46:16.711729
learning rate:  0.0004117714999999998
val: 1 0.5212289094924927
val: 2 0.4953749179840088
val: 3 0.5253584980964661
val: 4 0.5187375545501709
val: 5 0.5303346514701843
val: 6 0.5014471411705017
val: 7 0.5190088152885437
val: 8 0.4952425956726074
val: 9 0.5079320073127747
val: 10 0.5257719159126282
val: 11 0.5286401510238647
val: 12 0.5185289978981018
val: 13 0.5272478461265564
val: 14 0.5084599852561951
val: 15 0.5071939826011658
val: 16 0.5187328457832336
val: 17 0.5151346325874329
val: 18 0.5090931057929993
val: 19 0.5048433542251587
val: 20 0.5023289918899536
val_Epoch:[ 79 ] val_loss: 0.514032045006752 2022-05-29 14:46:22.667531
start training 2022-05-29 14:46:22.775693
Epoch:[ 80 0 ] loss: 0.4894906282424927 2022-05-29 14:46:49.737160
Epoch:[ 80 1 ] loss: 0.48656871914863586 2022-05-29 14:46:50.505386
Epoch:[ 80 2 ] loss: 0.49256670475006104 2022-05-29 14:46:51.270787
Epoch:[ 80 3 ] loss: 0.49419569969177246 2022-05-29 14:46:52.039071
Epoch:[ 80 4 ] loss: 0.4884684383869171 2022-05-29 14:46:52.805833
Epoch:[ 80 5 ] loss: 0.4965052604675293 2022-05-29 14:46:53.574382
Epoch:[ 80 6 ] loss: 0.4970785081386566 2022-05-29 14:46:54.355395
Epoch:[ 80 7 ] loss: 0.4950033724308014 2022-05-29 14:46:55.121555
Epoch:[ 80 8 ] loss: 0.4886009693145752 2022-05-29 14:46:55.889546
Epoch:[ 80 9 ] loss: 0.4872918426990509 2022-05-29 14:46:56.654490
Epoch:[ 80 10 ] loss: 0.49623769521713257 2022-05-29 14:46:57.424295
Epoch:[ 80 11 ] loss: 0.4957379400730133 2022-05-29 14:46:58.191343
Epoch:[ 80 12 ] loss: 0.49622538685798645 2022-05-29 14:46:58.957035
Epoch:[ 80 13 ] loss: 0.49315011501312256 2022-05-29 14:46:59.721157
Epoch:[ 80 14 ] loss: 0.49526286125183105 2022-05-29 14:47:00.489668
Epoch:[ 80 15 ] loss: 0.4898276627063751 2022-05-29 14:47:01.272730
Epoch:[ 80 16 ] loss: 0.49028536677360535 2022-05-29 14:47:08.550720
Epoch:[ 80 17 ] loss: 0.49171173572540283 2022-05-29 14:47:09.315661
Epoch:[ 80 18 ] loss: 0.49343177676200867 2022-05-29 14:47:10.085219
Epoch:[ 80 19 ] loss: 0.4977240562438965 2022-05-29 14:47:10.851274
Training_Epoch:[ 80 ] Training_loss: 0.49276823699474337 2022-05-29 14:47:10.852039
learning rate:  0.0004117714999999998
netparams have been saved once 80
val: 1 0.5144140720367432
val: 2 0.5153948664665222
val: 3 0.5310157537460327
val: 4 0.5171924829483032
val: 5 0.5417548418045044
val: 6 0.5136473774909973
val: 7 0.5231984853744507
val: 8 0.5158462524414062
val: 9 0.5394175052642822
val: 10 0.5207364559173584
val: 11 0.515541136264801
val: 12 0.5317986607551575
val: 13 0.5175418257713318
val: 14 0.511690080165863
val: 15 0.5003865957260132
val: 16 0.5237886309623718
val: 17 0.5071853399276733
val: 18 0.5141018033027649
val: 19 0.5121276378631592
val: 20 0.5120667219161987
val_Epoch:[ 80 ] val_loss: 0.5189423263072968 2022-05-29 14:47:16.453523
start training 2022-05-29 14:47:16.561579
Epoch:[ 81 0 ] loss: 0.4912838637828827 2022-05-29 14:47:42.044426
Epoch:[ 81 1 ] loss: 0.4932233691215515 2022-05-29 14:47:43.277985
Epoch:[ 81 2 ] loss: 0.49215036630630493 2022-05-29 14:47:44.046263
Epoch:[ 81 3 ] loss: 0.4904555380344391 2022-05-29 14:47:44.812124
Epoch:[ 81 4 ] loss: 0.4955754578113556 2022-05-29 14:47:45.578471
Epoch:[ 81 5 ] loss: 0.49010971188545227 2022-05-29 14:47:46.346516
Epoch:[ 81 6 ] loss: 0.48835283517837524 2022-05-29 14:47:47.111885
Epoch:[ 81 7 ] loss: 0.4910930097103119 2022-05-29 14:47:47.879772
Epoch:[ 81 8 ] loss: 0.48765918612480164 2022-05-29 14:47:48.660928
Epoch:[ 81 9 ] loss: 0.4913268983364105 2022-05-29 14:47:49.430445
Epoch:[ 81 10 ] loss: 0.4980188012123108 2022-05-29 14:47:50.207963
Epoch:[ 81 11 ] loss: 0.4920787513256073 2022-05-29 14:47:50.976703
Epoch:[ 81 12 ] loss: 0.48956313729286194 2022-05-29 14:47:51.743069
Epoch:[ 81 13 ] loss: 0.4972936511039734 2022-05-29 14:47:52.508357
Epoch:[ 81 14 ] loss: 0.4886148273944855 2022-05-29 14:47:53.277789
Epoch:[ 81 15 ] loss: 0.48307257890701294 2022-05-29 14:47:54.045342
Epoch:[ 81 16 ] loss: 0.49316999316215515 2022-05-29 14:48:01.903186
Epoch:[ 81 17 ] loss: 0.495618999004364 2022-05-29 14:48:04.617088
Epoch:[ 81 18 ] loss: 0.4885663092136383 2022-05-29 14:48:05.388333
Epoch:[ 81 19 ] loss: 0.48597633838653564 2022-05-29 14:48:06.155343
Training_Epoch:[ 81 ] Training_loss: 0.4911601811647415 2022-05-29 14:48:06.156153
learning rate:  0.00028824004999999985
val: 1 0.5287209153175354
val: 2 0.5099779963493347
val: 3 0.5126562714576721
val: 4 0.5254946351051331
val: 5 0.5169200897216797
val: 6 0.5109469890594482
val: 7 0.5054275393486023
val: 8 0.5054510831832886
val: 9 0.5012226700782776
val: 10 0.5075468420982361
val: 11 0.525476336479187
val: 12 0.5106004476547241
val: 13 0.5183383226394653
val: 14 0.5074083805084229
val: 15 0.5113404393196106
val: 16 0.5060118436813354
val: 17 0.5199008584022522
val: 18 0.5141265988349915
val: 19 0.5057110786437988
val: 20 0.51975017786026
val_Epoch:[ 81 ] val_loss: 0.5131514757871628 2022-05-29 14:48:11.760903
start training 2022-05-29 14:48:11.868709
Epoch:[ 82 0 ] loss: 0.4888039529323578 2022-05-29 14:48:37.933783
Epoch:[ 82 1 ] loss: 0.4885372817516327 2022-05-29 14:48:38.737641
Epoch:[ 82 2 ] loss: 0.4941791296005249 2022-05-29 14:48:39.518580
Epoch:[ 82 3 ] loss: 0.4899097979068756 2022-05-29 14:48:40.285307
Epoch:[ 82 4 ] loss: 0.4884227216243744 2022-05-29 14:48:41.053336
Epoch:[ 82 5 ] loss: 0.4941085875034332 2022-05-29 14:48:41.820060
Epoch:[ 82 6 ] loss: 0.48968908190727234 2022-05-29 14:48:42.603079
Epoch:[ 82 7 ] loss: 0.4895154535770416 2022-05-29 14:48:43.369939
Epoch:[ 82 8 ] loss: 0.4882962703704834 2022-05-29 14:48:44.135208
Epoch:[ 82 9 ] loss: 0.4907037019729614 2022-05-29 14:48:44.902997
Epoch:[ 82 10 ] loss: 0.4938051104545593 2022-05-29 14:48:45.671755
Epoch:[ 82 11 ] loss: 0.4861811101436615 2022-05-29 14:48:46.438555
Epoch:[ 82 12 ] loss: 0.4892031252384186 2022-05-29 14:48:47.205646
Epoch:[ 82 13 ] loss: 0.49617892503738403 2022-05-29 14:48:47.972796
Epoch:[ 82 14 ] loss: 0.4892714321613312 2022-05-29 14:48:48.738738
Epoch:[ 82 15 ] loss: 0.4904840290546417 2022-05-29 14:48:49.506111
Epoch:[ 82 16 ] loss: 0.48898205161094666 2022-05-29 14:48:57.209650
Epoch:[ 82 17 ] loss: 0.48906439542770386 2022-05-29 14:48:57.977058
Epoch:[ 82 18 ] loss: 0.49167364835739136 2022-05-29 14:48:59.765603
Epoch:[ 82 19 ] loss: 0.4844006299972534 2022-05-29 14:49:00.531730
Training_Epoch:[ 82 ] Training_loss: 0.49007052183151245 2022-05-29 14:49:00.532463
learning rate:  0.00028824004999999985
netparams have been saved once 82
val: 1 0.5104784369468689
val: 2 0.5106120705604553
val: 3 0.5062934756278992
val: 4 0.5116639137268066
val: 5 0.5340254306793213
val: 6 0.5303269624710083
val: 7 0.5359890460968018
val: 8 0.5060755610466003
val: 9 0.5192764401435852
val: 10 0.516839325428009
val: 11 0.5034809708595276
val: 12 0.4963679909706116
val: 13 0.493583083152771
val: 14 0.5048022866249084
val: 15 0.5160484910011292
val: 16 0.5026238560676575
val: 17 0.5253973603248596
val: 18 0.4956547021865845
val: 19 0.5105206370353699
val: 20 0.49410027265548706
val_Epoch:[ 82 ] val_loss: 0.5112080156803132 2022-05-29 14:49:06.139598
start training 2022-05-29 14:49:06.243974
Epoch:[ 83 0 ] loss: 0.49091845750808716 2022-05-29 14:49:32.093399
Epoch:[ 83 1 ] loss: 0.49028390645980835 2022-05-29 14:49:32.858143
Epoch:[ 83 2 ] loss: 0.4854579567909241 2022-05-29 14:49:33.621214
Epoch:[ 83 3 ] loss: 0.4904586672782898 2022-05-29 14:49:34.386016
Epoch:[ 83 4 ] loss: 0.4930112659931183 2022-05-29 14:49:35.165857
Epoch:[ 83 5 ] loss: 0.4909694790840149 2022-05-29 14:49:35.930946
Epoch:[ 83 6 ] loss: 0.49033036828041077 2022-05-29 14:49:36.696801
Epoch:[ 83 7 ] loss: 0.49029767513275146 2022-05-29 14:49:37.461538
Epoch:[ 83 8 ] loss: 0.48956286907196045 2022-05-29 14:49:38.225873
Epoch:[ 83 9 ] loss: 0.4862937927246094 2022-05-29 14:49:38.992735
Epoch:[ 83 10 ] loss: 0.4868616759777069 2022-05-29 14:49:39.757178
Epoch:[ 83 11 ] loss: 0.4876854419708252 2022-05-29 14:49:40.521713
Epoch:[ 83 12 ] loss: 0.487909197807312 2022-05-29 14:49:41.286886
Epoch:[ 83 13 ] loss: 0.49124372005462646 2022-05-29 14:49:42.053411
Epoch:[ 83 14 ] loss: 0.4848586618900299 2022-05-29 14:49:42.818081
Epoch:[ 83 15 ] loss: 0.48273903131484985 2022-05-29 14:49:43.594118
Epoch:[ 83 16 ] loss: 0.49121028184890747 2022-05-29 14:49:50.811847
Epoch:[ 83 17 ] loss: 0.4869900345802307 2022-05-29 14:49:51.575924
Epoch:[ 83 18 ] loss: 0.49482211470603943 2022-05-29 14:49:52.346612
Epoch:[ 83 19 ] loss: 0.4892485737800598 2022-05-29 14:49:53.110723
Training_Epoch:[ 83 ] Training_loss: 0.4890576586127281 2022-05-29 14:49:53.111489
learning rate:  0.00028824004999999985
val: 1 0.5198597311973572
val: 2 0.5279083251953125
val: 3 0.49476173520088196
val: 4 0.5240964889526367
val: 5 0.5072917938232422
val: 6 0.5207604169845581
val: 7 0.5061599016189575
val: 8 0.503959596157074
val: 9 0.5224123001098633
val: 10 0.535869300365448
val: 11 0.50100177526474
val: 12 0.50778728723526
val: 13 0.5090364217758179
val: 14 0.5175316333770752
val: 15 0.4985065162181854
val: 16 0.5081920623779297
val: 17 0.5113949775695801
val: 18 0.49975815415382385
val: 19 0.5111266374588013
val: 20 0.5010566711425781
val_Epoch:[ 83 ] val_loss: 0.5114235863089561 2022-05-29 14:49:58.726681
start training 2022-05-29 14:49:58.827038
Epoch:[ 84 0 ] loss: 0.4875198304653168 2022-05-29 14:50:24.749686
Epoch:[ 84 1 ] loss: 0.4871378540992737 2022-05-29 14:50:25.560270
Epoch:[ 84 2 ] loss: 0.4902511537075043 2022-05-29 14:50:26.327316
Epoch:[ 84 3 ] loss: 0.48941847681999207 2022-05-29 14:50:27.093919
Epoch:[ 84 4 ] loss: 0.489467591047287 2022-05-29 14:50:27.872322
Epoch:[ 84 5 ] loss: 0.4869775176048279 2022-05-29 14:50:28.639463
Epoch:[ 84 6 ] loss: 0.48436975479125977 2022-05-29 14:50:29.405477
Epoch:[ 84 7 ] loss: 0.4861670136451721 2022-05-29 14:50:30.173549
Epoch:[ 84 8 ] loss: 0.49384626746177673 2022-05-29 14:50:30.942799
Epoch:[ 84 9 ] loss: 0.48987844586372375 2022-05-29 14:50:31.708434
Epoch:[ 84 10 ] loss: 0.4868437945842743 2022-05-29 14:50:32.472762
Epoch:[ 84 11 ] loss: 0.49040958285331726 2022-05-29 14:50:33.240092
Epoch:[ 84 12 ] loss: 0.49007660150527954 2022-05-29 14:50:34.010106
Epoch:[ 84 13 ] loss: 0.48586535453796387 2022-05-29 14:50:34.778507
Epoch:[ 84 14 ] loss: 0.4906209111213684 2022-05-29 14:50:35.560251
Epoch:[ 84 15 ] loss: 0.48686861991882324 2022-05-29 14:50:36.327466
Epoch:[ 84 16 ] loss: 0.4927356243133545 2022-05-29 14:50:44.009512
Epoch:[ 84 17 ] loss: 0.488214910030365 2022-05-29 14:50:44.772024
Epoch:[ 84 18 ] loss: 0.4906347393989563 2022-05-29 14:50:45.542213
Epoch:[ 84 19 ] loss: 0.4905361235141754 2022-05-29 14:50:46.307306
Training_Epoch:[ 84 ] Training_loss: 0.4888920083642006 2022-05-29 14:50:46.307991
learning rate:  0.00028824004999999985
netparams have been saved once 84
val: 1 0.5182868242263794
val: 2 0.5330621600151062
val: 3 0.5189419984817505
val: 4 0.5026236176490784
val: 5 0.508142352104187
val: 6 0.5322893857955933
val: 7 0.5086122155189514
val: 8 0.5234283208847046
val: 9 0.5169677734375
val: 10 0.5072863698005676
val: 11 0.5205342173576355
val: 12 0.5224069952964783
val: 13 0.5007776021957397
val: 14 0.5038952827453613
val: 15 0.4984082877635956
val: 16 0.5146124362945557
val: 17 0.5143933296203613
val: 18 0.5229479670524597
val: 19 0.5249243974685669
val: 20 0.52215176820755
val_Epoch:[ 84 ] val_loss: 0.5157346650958061 2022-05-29 14:50:51.877108
start training 2022-05-29 14:50:51.978530
Epoch:[ 85 0 ] loss: 0.48989760875701904 2022-05-29 14:51:17.334453
Epoch:[ 85 1 ] loss: 0.48547497391700745 2022-05-29 14:51:18.146941
Epoch:[ 85 2 ] loss: 0.4860246479511261 2022-05-29 14:51:18.924609
Epoch:[ 85 3 ] loss: 0.48867884278297424 2022-05-29 14:51:19.703500
Epoch:[ 85 4 ] loss: 0.48419249057769775 2022-05-29 14:51:20.466829
Epoch:[ 85 5 ] loss: 0.4884909689426422 2022-05-29 14:51:21.232186
Epoch:[ 85 6 ] loss: 0.4865122139453888 2022-05-29 14:51:21.996897
Epoch:[ 85 7 ] loss: 0.4905543327331543 2022-05-29 14:51:22.762478
Epoch:[ 85 8 ] loss: 0.48538216948509216 2022-05-29 14:51:23.526925
Epoch:[ 85 9 ] loss: 0.48714005947113037 2022-05-29 14:51:24.292552
Epoch:[ 85 10 ] loss: 0.48650798201560974 2022-05-29 14:51:25.056459
Epoch:[ 85 11 ] loss: 0.48977094888687134 2022-05-29 14:51:25.819952
Epoch:[ 85 12 ] loss: 0.49425044655799866 2022-05-29 14:51:26.585380
Epoch:[ 85 13 ] loss: 0.49074873328208923 2022-05-29 14:51:27.349985
Epoch:[ 85 14 ] loss: 0.49279189109802246 2022-05-29 14:51:28.114680
Epoch:[ 85 15 ] loss: 0.4919627904891968 2022-05-29 14:51:28.881012
Epoch:[ 85 16 ] loss: 0.4888511598110199 2022-05-29 14:51:36.840337
Epoch:[ 85 17 ] loss: 0.4889313876628876 2022-05-29 14:51:37.602625
Epoch:[ 85 18 ] loss: 0.48926302790641785 2022-05-29 14:51:39.899782
Epoch:[ 85 19 ] loss: 0.48971617221832275 2022-05-29 14:51:40.665017
Training_Epoch:[ 85 ] Training_loss: 0.48875714242458346 2022-05-29 14:51:40.665783
learning rate:  0.00028824004999999985
val: 1 0.5105491280555725
val: 2 0.5146698355674744
val: 3 0.5072844624519348
val: 4 0.5070686340332031
val: 5 0.504554033279419
val: 6 0.5239275097846985
val: 7 0.5144209861755371
val: 8 0.5144895911216736
val: 9 0.5093908905982971
val: 10 0.5179135799407959
val: 11 0.5287255048751831
val: 12 0.5019884705543518
val: 13 0.5010281801223755
val: 14 0.514896810054779
val: 15 0.5061736106872559
val: 16 0.5142342448234558
val: 17 0.5267964601516724
val: 18 0.5167417526245117
val: 19 0.5141302943229675
val: 20 0.5119714736938477
val_Epoch:[ 85 ] val_loss: 0.5130477726459504 2022-05-29 14:51:46.370578
start training 2022-05-29 14:51:46.471503
Epoch:[ 86 0 ] loss: 0.4907984137535095 2022-05-29 14:52:12.530602
Epoch:[ 86 1 ] loss: 0.486346036195755 2022-05-29 14:52:13.295191
Epoch:[ 86 2 ] loss: 0.48939061164855957 2022-05-29 14:52:14.060441
Epoch:[ 86 3 ] loss: 0.485480397939682 2022-05-29 14:52:14.826145
Epoch:[ 86 4 ] loss: 0.4895443618297577 2022-05-29 14:52:15.592302
Epoch:[ 86 5 ] loss: 0.4866541922092438 2022-05-29 14:52:16.368303
Epoch:[ 86 6 ] loss: 0.49429750442504883 2022-05-29 14:52:17.133231
Epoch:[ 86 7 ] loss: 0.49394696950912476 2022-05-29 14:52:17.902093
Epoch:[ 86 8 ] loss: 0.4877856373786926 2022-05-29 14:52:18.665550
Epoch:[ 86 9 ] loss: 0.48853206634521484 2022-05-29 14:52:19.432716
Epoch:[ 86 10 ] loss: 0.4835749566555023 2022-05-29 14:52:20.199175
Epoch:[ 86 11 ] loss: 0.4860306680202484 2022-05-29 14:52:20.963325
Epoch:[ 86 12 ] loss: 0.4839213490486145 2022-05-29 14:52:21.727108
Epoch:[ 86 13 ] loss: 0.4872761368751526 2022-05-29 14:52:22.492788
Epoch:[ 86 14 ] loss: 0.49061667919158936 2022-05-29 14:52:23.273199
Epoch:[ 86 15 ] loss: 0.49087342619895935 2022-05-29 14:52:24.039324
Epoch:[ 86 16 ] loss: 0.4904453754425049 2022-05-29 14:52:31.215443
Epoch:[ 86 17 ] loss: 0.4875008165836334 2022-05-29 14:52:31.980479
Epoch:[ 86 18 ] loss: 0.48782214522361755 2022-05-29 14:52:33.509154
Epoch:[ 86 19 ] loss: 0.482751727104187 2022-05-29 14:52:34.274334
Training_Epoch:[ 86 ] Training_loss: 0.4881794735789299 2022-05-29 14:52:34.275047
learning rate:  0.00028824004999999985
netparams have been saved once 86
val: 1 0.5208176374435425
val: 2 0.5125457048416138
val: 3 0.5188781023025513
val: 4 0.5108239650726318
val: 5 0.5315864682197571
val: 6 0.5116549134254456
val: 7 0.525763213634491
val: 8 0.5068756341934204
val: 9 0.5158889889717102
val: 10 0.5162127017974854
val: 11 0.4980061948299408
val: 12 0.513205349445343
val: 13 0.5065381526947021
val: 14 0.5164748430252075
val: 15 0.5292085409164429
val: 16 0.5301625728607178
val: 17 0.5188113451004028
val: 18 0.5141220092773438
val: 19 0.5119163393974304
val: 20 0.5207297801971436
val_Epoch:[ 86 ] val_loss: 0.5165111228823662 2022-05-29 14:52:39.963595
start training 2022-05-29 14:52:40.065277
Epoch:[ 87 0 ] loss: 0.48522520065307617 2022-05-29 14:53:06.856873
Epoch:[ 87 1 ] loss: 0.4863053262233734 2022-05-29 14:53:07.624531
Epoch:[ 87 2 ] loss: 0.48408955335617065 2022-05-29 14:53:08.389272
Epoch:[ 87 3 ] loss: 0.48598694801330566 2022-05-29 14:53:09.171243
Epoch:[ 87 4 ] loss: 0.4884505271911621 2022-05-29 14:53:09.936415
Epoch:[ 87 5 ] loss: 0.48480191826820374 2022-05-29 14:53:10.700858
Epoch:[ 87 6 ] loss: 0.4891338348388672 2022-05-29 14:53:11.463947
Epoch:[ 87 7 ] loss: 0.48256197571754456 2022-05-29 14:53:12.228161
Epoch:[ 87 8 ] loss: 0.48632335662841797 2022-05-29 14:53:12.992791
Epoch:[ 87 9 ] loss: 0.4917256832122803 2022-05-29 14:53:13.757678
Epoch:[ 87 10 ] loss: 0.4883386194705963 2022-05-29 14:53:14.523474
Epoch:[ 87 11 ] loss: 0.48742029070854187 2022-05-29 14:53:15.288607
Epoch:[ 87 12 ] loss: 0.4862063229084015 2022-05-29 14:53:16.055229
Epoch:[ 87 13 ] loss: 0.4864406883716583 2022-05-29 14:53:16.834481
Epoch:[ 87 14 ] loss: 0.49059680104255676 2022-05-29 14:53:17.599573
Epoch:[ 87 15 ] loss: 0.48641422390937805 2022-05-29 14:53:18.365582
Epoch:[ 87 16 ] loss: 0.4864473342895508 2022-05-29 14:53:25.744357
Epoch:[ 87 17 ] loss: 0.4867616295814514 2022-05-29 14:53:26.508683
Epoch:[ 87 18 ] loss: 0.4867081642150879 2022-05-29 14:53:28.410926
Epoch:[ 87 19 ] loss: 0.48304566740989685 2022-05-29 14:53:29.174600
Training_Epoch:[ 87 ] Training_loss: 0.48664920330047606 2022-05-29 14:53:29.175288
learning rate:  0.00028824004999999985
val: 1 0.5189281702041626
val: 2 0.5027490258216858
val: 3 0.5163198709487915
val: 4 0.5059174299240112
val: 5 0.5263416171073914
val: 6 0.495189368724823
val: 7 0.503049910068512
val: 8 0.52195805311203
val: 9 0.513993501663208
val: 10 0.5204023718833923
val: 11 0.5320911407470703
val: 12 0.5164483189582825
val: 13 0.5156505107879639
val: 14 0.5034691691398621
val: 15 0.5192850232124329
val: 16 0.5005448460578918
val: 17 0.5050479769706726
val: 18 0.5003094673156738
val: 19 0.518256425857544
val: 20 0.49645864963531494
val_Epoch:[ 87 ] val_loss: 0.5116205424070358 2022-05-29 14:53:34.818111
start training 2022-05-29 14:53:34.924293
Epoch:[ 88 0 ] loss: 0.48446547985076904 2022-05-29 14:54:00.952269
Epoch:[ 88 1 ] loss: 0.4842229187488556 2022-05-29 14:54:01.749613
Epoch:[ 88 2 ] loss: 0.48455700278282166 2022-05-29 14:54:02.516817
Epoch:[ 88 3 ] loss: 0.4877929091453552 2022-05-29 14:54:03.285175
Epoch:[ 88 4 ] loss: 0.4878357946872711 2022-05-29 14:54:04.051169
Epoch:[ 88 5 ] loss: 0.4874937832355499 2022-05-29 14:54:04.817785
Epoch:[ 88 6 ] loss: 0.4842930734157562 2022-05-29 14:54:05.596539
Epoch:[ 88 7 ] loss: 0.4866255819797516 2022-05-29 14:54:06.362131
Epoch:[ 88 8 ] loss: 0.48799172043800354 2022-05-29 14:54:07.128117
Epoch:[ 88 9 ] loss: 0.48854148387908936 2022-05-29 14:54:07.894274
Epoch:[ 88 10 ] loss: 0.479416161775589 2022-05-29 14:54:08.659693
Epoch:[ 88 11 ] loss: 0.48763346672058105 2022-05-29 14:54:09.429171
Epoch:[ 88 12 ] loss: 0.47904226183891296 2022-05-29 14:54:10.196932
Epoch:[ 88 13 ] loss: 0.48532766103744507 2022-05-29 14:54:10.973987
Epoch:[ 88 14 ] loss: 0.48732832074165344 2022-05-29 14:54:11.739600
Epoch:[ 88 15 ] loss: 0.48777011036872864 2022-05-29 14:54:12.505711
Epoch:[ 88 16 ] loss: 0.4887887239456177 2022-05-29 14:54:20.151225
Epoch:[ 88 17 ] loss: 0.4868462085723877 2022-05-29 14:54:20.918125
Epoch:[ 88 18 ] loss: 0.48869359493255615 2022-05-29 14:54:21.688970
Epoch:[ 88 19 ] loss: 0.4919639527797699 2022-05-29 14:54:22.452647
Training_Epoch:[ 88 ] Training_loss: 0.48633151054382323 2022-05-29 14:54:22.453466
learning rate:  0.00028824004999999985
netparams have been saved once 88
val: 1 0.4927605390548706
val: 2 0.5157694220542908
val: 3 0.5049098134040833
val: 4 0.4989044964313507
val: 5 0.5052137970924377
val: 6 0.5207475423812866
val: 7 0.5174654126167297
val: 8 0.5100861191749573
val: 9 0.5039779543876648
val: 10 0.5001406073570251
val: 11 0.5110250115394592
val: 12 0.5132929682731628
val: 13 0.5168834328651428
val: 14 0.5145555138587952
val: 15 0.508405327796936
val: 16 0.5177168846130371
val: 17 0.5230721235275269
val: 18 0.508352518081665
val: 19 0.5210680961608887
val: 20 0.507071852684021
val_Epoch:[ 88 ] val_loss: 0.5105709716677665 2022-05-29 14:54:28.188079
start training 2022-05-29 14:54:28.287654
Epoch:[ 89 0 ] loss: 0.47830596566200256 2022-05-29 14:54:54.116717
Epoch:[ 89 1 ] loss: 0.4838051199913025 2022-05-29 14:54:54.879874
Epoch:[ 89 2 ] loss: 0.4892372786998749 2022-05-29 14:54:55.659362
Epoch:[ 89 3 ] loss: 0.48760786652565 2022-05-29 14:54:56.425294
Epoch:[ 89 4 ] loss: 0.48707160353660583 2022-05-29 14:54:57.190380
Epoch:[ 89 5 ] loss: 0.4899683892726898 2022-05-29 14:54:57.954688
Epoch:[ 89 6 ] loss: 0.48180022835731506 2022-05-29 14:54:58.719171
Epoch:[ 89 7 ] loss: 0.4877275228500366 2022-05-29 14:54:59.486268
Epoch:[ 89 8 ] loss: 0.4830387234687805 2022-05-29 14:55:00.251784
Epoch:[ 89 9 ] loss: 0.4857120215892792 2022-05-29 14:55:01.017761
Epoch:[ 89 10 ] loss: 0.48354947566986084 2022-05-29 14:55:01.785470
Epoch:[ 89 11 ] loss: 0.48734307289123535 2022-05-29 14:55:02.548845
Epoch:[ 89 12 ] loss: 0.48721906542778015 2022-05-29 14:55:03.314724
Epoch:[ 89 13 ] loss: 0.48548340797424316 2022-05-29 14:55:04.080421
Epoch:[ 89 14 ] loss: 0.4839076101779938 2022-05-29 14:55:04.860007
Epoch:[ 89 15 ] loss: 0.48983103036880493 2022-05-29 14:55:05.627443
Epoch:[ 89 16 ] loss: 0.491326242685318 2022-05-29 14:55:12.866370
Epoch:[ 89 17 ] loss: 0.4907945692539215 2022-05-29 14:55:13.633307
Epoch:[ 89 18 ] loss: 0.4853796362876892 2022-05-29 14:55:14.396767
Epoch:[ 89 19 ] loss: 0.48256686329841614 2022-05-29 14:55:15.160936
Training_Epoch:[ 89 ] Training_loss: 0.48608378469944 2022-05-29 14:55:15.161618
learning rate:  0.00028824004999999985
val: 1 0.49956828355789185
val: 2 0.5061224699020386
val: 3 0.5014433264732361
val: 4 0.5150712728500366
val: 5 0.5092491507530212
val: 6 0.5278810262680054
val: 7 0.502496600151062
val: 8 0.515911340713501
val: 9 0.49924618005752563
val: 10 0.5009050369262695
val: 11 0.5149731040000916
val: 12 0.5237004160881042
val: 13 0.5135635137557983
val: 14 0.5164618492126465
val: 15 0.5166088342666626
val: 16 0.5073208808898926
val: 17 0.5175435543060303
val: 18 0.5119175314903259
val: 19 0.5196930766105652
val: 20 0.5132644772529602
val_Epoch:[ 89 ] val_loss: 0.5116470962762832 2022-05-29 14:55:20.693487
start training 2022-05-29 14:55:20.795451
Epoch:[ 90 0 ] loss: 0.485463947057724 2022-05-29 14:55:47.309257
Epoch:[ 90 1 ] loss: 0.49039241671562195 2022-05-29 14:55:48.073129
Epoch:[ 90 2 ] loss: 0.48860394954681396 2022-05-29 14:55:48.837059
Epoch:[ 90 3 ] loss: 0.48322778940200806 2022-05-29 14:55:49.601013
Epoch:[ 90 4 ] loss: 0.48147454857826233 2022-05-29 14:55:50.366873
Epoch:[ 90 5 ] loss: 0.4842745363712311 2022-05-29 14:55:51.130545
Epoch:[ 90 6 ] loss: 0.48425397276878357 2022-05-29 14:55:51.896544
Epoch:[ 90 7 ] loss: 0.48259177803993225 2022-05-29 14:55:52.660687
Epoch:[ 90 8 ] loss: 0.48612844944000244 2022-05-29 14:55:53.425384
Epoch:[ 90 9 ] loss: 0.4843551516532898 2022-05-29 14:55:54.200108
Epoch:[ 90 10 ] loss: 0.4910201132297516 2022-05-29 14:55:54.964797
Epoch:[ 90 11 ] loss: 0.4827888607978821 2022-05-29 14:55:55.730539
Epoch:[ 90 12 ] loss: 0.487158864736557 2022-05-29 14:55:56.495056
Epoch:[ 90 13 ] loss: 0.4837067723274231 2022-05-29 14:55:57.258285
Epoch:[ 90 14 ] loss: 0.48739540576934814 2022-05-29 14:55:58.036025
Epoch:[ 90 15 ] loss: 0.4850727915763855 2022-05-29 14:55:58.801285
Epoch:[ 90 16 ] loss: 0.4812219738960266 2022-05-29 14:56:08.577491
Epoch:[ 90 17 ] loss: 0.48779430985450745 2022-05-29 14:56:09.343273
Epoch:[ 90 18 ] loss: 0.48728641867637634 2022-05-29 14:56:10.112422
Epoch:[ 90 19 ] loss: 0.48323890566825867 2022-05-29 14:56:10.879235
Training_Epoch:[ 90 ] Training_loss: 0.4853725478053093 2022-05-29 14:56:10.879990
learning rate:  0.00028824004999999985
netparams have been saved once 90
val: 1 0.50075763463974
val: 2 0.4985566735267639
val: 3 0.5078137516975403
val: 4 0.5176461935043335
val: 5 0.5318130850791931
val: 6 0.5212389826774597
val: 7 0.5209359526634216
val: 8 0.5367065668106079
val: 9 0.504900336265564
val: 10 0.5174676179885864
val: 11 0.49784865975379944
val: 12 0.513505220413208
val: 13 0.5148844718933105
val: 14 0.49903392791748047
val: 15 0.518709659576416
val: 16 0.500150203704834
val: 17 0.5090363025665283
val: 18 0.5154771208763123
val: 19 0.5055968761444092
val: 20 0.5241333246231079
val_Epoch:[ 90 ] val_loss: 0.5128106281161309 2022-05-29 14:56:16.754713
start training 2022-05-29 14:56:16.856421
Epoch:[ 91 0 ] loss: 0.4904518723487854 2022-05-29 14:56:42.541717
Epoch:[ 91 1 ] loss: 0.48066446185112 2022-05-29 14:56:43.327473
Epoch:[ 91 2 ] loss: 0.48149919509887695 2022-05-29 14:56:44.095011
Epoch:[ 91 3 ] loss: 0.48193031549453735 2022-05-29 14:56:44.860076
Epoch:[ 91 4 ] loss: 0.4895525574684143 2022-05-29 14:56:45.625208
Epoch:[ 91 5 ] loss: 0.47998812794685364 2022-05-29 14:56:46.392676
Epoch:[ 91 6 ] loss: 0.487569659948349 2022-05-29 14:56:47.158216
Epoch:[ 91 7 ] loss: 0.4841126799583435 2022-05-29 14:56:47.936871
Epoch:[ 91 8 ] loss: 0.48171383142471313 2022-05-29 14:56:48.703003
Epoch:[ 91 9 ] loss: 0.48677241802215576 2022-05-29 14:56:49.467116
Epoch:[ 91 10 ] loss: 0.48615872859954834 2022-05-29 14:56:50.233874
Epoch:[ 91 11 ] loss: 0.48480087518692017 2022-05-29 14:56:50.998469
Epoch:[ 91 12 ] loss: 0.4845716059207916 2022-05-29 14:56:51.776550
Epoch:[ 91 13 ] loss: 0.48530223965644836 2022-05-29 14:56:52.540585
Epoch:[ 91 14 ] loss: 0.48711958527565 2022-05-29 14:56:53.306457
Epoch:[ 91 15 ] loss: 0.4790762960910797 2022-05-29 14:56:54.072834
Epoch:[ 91 16 ] loss: 0.48453888297080994 2022-05-29 14:57:01.765400
Epoch:[ 91 17 ] loss: 0.48481401801109314 2022-05-29 14:57:02.533629
Epoch:[ 91 18 ] loss: 0.485501766204834 2022-05-29 14:57:04.279015
Epoch:[ 91 19 ] loss: 0.4808531701564789 2022-05-29 14:57:05.044044
Training_Epoch:[ 91 ] Training_loss: 0.48434961438179014 2022-05-29 14:57:05.044770
learning rate:  0.00020176803499999987
val: 1 0.5146158933639526
val: 2 0.5275787115097046
val: 3 0.5063939094543457
val: 4 0.5090835690498352
val: 5 0.5066935420036316
val: 6 0.5120381116867065
val: 7 0.514706015586853
val: 8 0.500404953956604
val: 9 0.5151203274726868
val: 10 0.5107221007347107
val: 11 0.5120182633399963
val: 12 0.5234318971633911
val: 13 0.5209376811981201
val: 14 0.5060737729072571
val: 15 0.5077652335166931
val: 16 0.49631690979003906
val: 17 0.5009670257568359
val: 18 0.507514476776123
val: 19 0.5077000260353088
val: 20 0.5287188291549683
val_Epoch:[ 91 ] val_loss: 0.5114400625228882 2022-05-29 14:57:10.658102
start training 2022-05-29 14:57:10.758895
Epoch:[ 92 0 ] loss: 0.4854053258895874 2022-05-29 14:57:34.380133
Epoch:[ 92 1 ] loss: 0.4815928637981415 2022-05-29 14:57:35.196887
Epoch:[ 92 2 ] loss: 0.4848097264766693 2022-05-29 14:57:36.011974
Epoch:[ 92 3 ] loss: 0.4761338531970978 2022-05-29 14:57:36.790012
Epoch:[ 92 4 ] loss: 0.48416867852211 2022-05-29 14:57:37.557032
Epoch:[ 92 5 ] loss: 0.48336556553840637 2022-05-29 14:57:38.322117
Epoch:[ 92 6 ] loss: 0.48500633239746094 2022-05-29 14:57:39.089301
Epoch:[ 92 7 ] loss: 0.4856833815574646 2022-05-29 14:57:39.854226
Epoch:[ 92 8 ] loss: 0.48335492610931396 2022-05-29 14:57:40.622565
Epoch:[ 92 9 ] loss: 0.48621875047683716 2022-05-29 14:57:41.386602
Epoch:[ 92 10 ] loss: 0.48246726393699646 2022-05-29 14:57:42.149084
Epoch:[ 92 11 ] loss: 0.4810912311077118 2022-05-29 14:57:42.912320
Epoch:[ 92 12 ] loss: 0.47941675782203674 2022-05-29 14:57:43.677179
Epoch:[ 92 13 ] loss: 0.48294419050216675 2022-05-29 14:57:44.442855
Epoch:[ 92 14 ] loss: 0.4840453863143921 2022-05-29 14:57:45.210452
Epoch:[ 92 15 ] loss: 0.48472705483436584 2022-05-29 14:57:45.988687
Epoch:[ 92 16 ] loss: 0.48008278012275696 2022-05-29 14:57:53.759993
Epoch:[ 92 17 ] loss: 0.4838734567165375 2022-05-29 14:57:54.524233
Epoch:[ 92 18 ] loss: 0.4843694567680359 2022-05-29 14:57:55.306847
Epoch:[ 92 19 ] loss: 0.4818168878555298 2022-05-29 14:57:56.070231
Training_Epoch:[ 92 ] Training_loss: 0.4830286934971809 2022-05-29 14:57:56.071072
learning rate:  0.00020176803499999987
netparams have been saved once 92
val: 1 0.5071021318435669
val: 2 0.5144342184066772
val: 3 0.5188189148902893
val: 4 0.5061022043228149
val: 5 0.5015190243721008
val: 6 0.5081830024719238
val: 7 0.5143088102340698
val: 8 0.5061980485916138
val: 9 0.5073635578155518
val: 10 0.5004311800003052
val: 11 0.5304842591285706
val: 12 0.5114259719848633
val: 13 0.5155584812164307
val: 14 0.511646568775177
val: 15 0.5068188905715942
val: 16 0.5051625967025757
val: 17 0.5244248509407043
val: 18 0.509903609752655
val: 19 0.5102760791778564
val: 20 0.5229418277740479
val_Epoch:[ 92 ] val_loss: 0.5116552114486694 2022-05-29 14:58:01.509877
start training 2022-05-29 14:58:01.609986
Epoch:[ 93 0 ] loss: 0.48082005977630615 2022-05-29 14:58:25.924305
Epoch:[ 93 1 ] loss: 0.48569589853286743 2022-05-29 14:58:26.687233
Epoch:[ 93 2 ] loss: 0.47870197892189026 2022-05-29 14:58:27.452802
Epoch:[ 93 3 ] loss: 0.4801994264125824 2022-05-29 14:58:28.215942
Epoch:[ 93 4 ] loss: 0.48101475834846497 2022-05-29 14:58:28.981560
Epoch:[ 93 5 ] loss: 0.48461073637008667 2022-05-29 14:58:29.745911
Epoch:[ 93 6 ] loss: 0.483373761177063 2022-05-29 14:58:30.521636
Epoch:[ 93 7 ] loss: 0.4838535189628601 2022-05-29 14:58:31.298383
Epoch:[ 93 8 ] loss: 0.48706817626953125 2022-05-29 14:58:32.065793
Epoch:[ 93 9 ] loss: 0.4824259877204895 2022-05-29 14:58:32.827395
Epoch:[ 93 10 ] loss: 0.4808412194252014 2022-05-29 14:58:33.593989
Epoch:[ 93 11 ] loss: 0.48190200328826904 2022-05-29 14:58:34.359221
Epoch:[ 93 12 ] loss: 0.48043373227119446 2022-05-29 14:58:35.123141
Epoch:[ 93 13 ] loss: 0.4812176525592804 2022-05-29 14:58:35.888690
Epoch:[ 93 14 ] loss: 0.4803812801837921 2022-05-29 14:58:36.654108
Epoch:[ 93 15 ] loss: 0.4821596145629883 2022-05-29 14:58:37.419455
Epoch:[ 93 16 ] loss: 0.4796992540359497 2022-05-29 14:58:44.779466
Epoch:[ 93 17 ] loss: 0.48387059569358826 2022-05-29 14:58:45.542750
Epoch:[ 93 18 ] loss: 0.48334547877311707 2022-05-29 14:58:46.311648
Epoch:[ 93 19 ] loss: 0.4826502203941345 2022-05-29 14:58:47.073318
Training_Epoch:[ 93 ] Training_loss: 0.48221326768398287 2022-05-29 14:58:47.074069
learning rate:  0.00020176803499999987
val: 1 0.5035022497177124
val: 2 0.509077250957489
val: 3 0.5109164118766785
val: 4 0.5114138126373291
val: 5 0.5047285556793213
val: 6 0.517531156539917
val: 7 0.5181898474693298
val: 8 0.49624037742614746
val: 9 0.519096851348877
val: 10 0.5113171935081482
val: 11 0.5029729604721069
val: 12 0.5077541470527649
val: 13 0.5056201815605164
val: 14 0.5156811475753784
val: 15 0.521118700504303
val: 16 0.5100818276405334
val: 17 0.508133053779602
val: 18 0.5131550431251526
val: 19 0.5166516304016113
val: 20 0.5076704025268555
val_Epoch:[ 93 ] val_loss: 0.5105426400899887 2022-05-29 14:58:52.481194
start training 2022-05-29 14:58:52.580869
Epoch:[ 94 0 ] loss: 0.4802488684654236 2022-05-29 14:59:16.189458
Epoch:[ 94 1 ] loss: 0.47928789258003235 2022-05-29 14:59:16.999665
Epoch:[ 94 2 ] loss: 0.47969329357147217 2022-05-29 14:59:17.763745
Epoch:[ 94 3 ] loss: 0.4832291901111603 2022-05-29 14:59:18.528592
Epoch:[ 94 4 ] loss: 0.48333579301834106 2022-05-29 14:59:19.292783
Epoch:[ 94 5 ] loss: 0.4796667993068695 2022-05-29 14:59:20.057833
Epoch:[ 94 6 ] loss: 0.4846554100513458 2022-05-29 14:59:20.821094
Epoch:[ 94 7 ] loss: 0.47736701369285583 2022-05-29 14:59:21.587717
Epoch:[ 94 8 ] loss: 0.4816083014011383 2022-05-29 14:59:22.352591
Epoch:[ 94 9 ] loss: 0.48600053787231445 2022-05-29 14:59:23.128934
Epoch:[ 94 10 ] loss: 0.4845164716243744 2022-05-29 14:59:23.894593
Epoch:[ 94 11 ] loss: 0.48428961634635925 2022-05-29 14:59:24.671765
Epoch:[ 94 12 ] loss: 0.47851964831352234 2022-05-29 14:59:25.436382
Epoch:[ 94 13 ] loss: 0.48407667875289917 2022-05-29 14:59:26.200652
Epoch:[ 94 14 ] loss: 0.47977858781814575 2022-05-29 14:59:26.967027
Epoch:[ 94 15 ] loss: 0.48025912046432495 2022-05-29 14:59:27.731628
Epoch:[ 94 16 ] loss: 0.4827601909637451 2022-05-29 14:59:35.163388
Epoch:[ 94 17 ] loss: 0.4794628918170929 2022-05-29 14:59:35.928755
Epoch:[ 94 18 ] loss: 0.48210111260414124 2022-05-29 14:59:36.699234
Epoch:[ 94 19 ] loss: 0.4828576445579529 2022-05-29 14:59:37.463853
Training_Epoch:[ 94 ] Training_loss: 0.48168575316667556 2022-05-29 14:59:37.464573
learning rate:  0.00020176803499999987
netparams have been saved once 94
val: 1 0.5147780776023865
val: 2 0.49355605244636536
val: 3 0.5112860798835754
val: 4 0.512592077255249
val: 5 0.498872309923172
val: 6 0.5037623047828674
val: 7 0.5011675953865051
val: 8 0.5092324614524841
val: 9 0.5125877261161804
val: 10 0.5192899107933044
val: 11 0.5118330717086792
val: 12 0.5121158957481384
val: 13 0.5143783688545227
val: 14 0.5079882740974426
val: 15 0.507010817527771
val: 16 0.5134843587875366
val: 17 0.5052675008773804
val: 18 0.5194306969642639
val: 19 0.5076748132705688
val: 20 0.5200343132019043
val_Epoch:[ 94 ] val_loss: 0.5098171353340148 2022-05-29 14:59:42.964931
start training 2022-05-29 14:59:43.069596
Epoch:[ 95 0 ] loss: 0.48168328404426575 2022-05-29 15:00:05.442992
Epoch:[ 95 1 ] loss: 0.4770680367946625 2022-05-29 15:00:06.832629
Epoch:[ 95 2 ] loss: 0.4756937623023987 2022-05-29 15:00:07.599045
Epoch:[ 95 3 ] loss: 0.4820944368839264 2022-05-29 15:00:08.362192
Epoch:[ 95 4 ] loss: 0.48476335406303406 2022-05-29 15:00:09.124281
Epoch:[ 95 5 ] loss: 0.4869990944862366 2022-05-29 15:00:09.889571
Epoch:[ 95 6 ] loss: 0.47884127497673035 2022-05-29 15:00:10.656103
Epoch:[ 95 7 ] loss: 0.4813980460166931 2022-05-29 15:00:11.420453
Epoch:[ 95 8 ] loss: 0.47972673177719116 2022-05-29 15:00:12.197479
Epoch:[ 95 9 ] loss: 0.48248565196990967 2022-05-29 15:00:12.963315
Epoch:[ 95 10 ] loss: 0.48423129320144653 2022-05-29 15:00:13.729190
Epoch:[ 95 11 ] loss: 0.4813566505908966 2022-05-29 15:00:14.495538
Epoch:[ 95 12 ] loss: 0.48758459091186523 2022-05-29 15:00:15.259905
Epoch:[ 95 13 ] loss: 0.48168811202049255 2022-05-29 15:00:16.022101
Epoch:[ 95 14 ] loss: 0.4784155786037445 2022-05-29 15:00:16.787395
Epoch:[ 95 15 ] loss: 0.4782906174659729 2022-05-29 15:00:17.563394
Epoch:[ 95 16 ] loss: 0.4795164167881012 2022-05-29 15:00:25.565474
Epoch:[ 95 17 ] loss: 0.483890175819397 2022-05-29 15:00:26.331474
Epoch:[ 95 18 ] loss: 0.48160502314567566 2022-05-29 15:00:27.102498
Epoch:[ 95 19 ] loss: 0.47857192158699036 2022-05-29 15:00:27.868419
Training_Epoch:[ 95 ] Training_loss: 0.48129520267248155 2022-05-29 15:00:27.869128
learning rate:  0.00020176803499999987
val: 1 0.4865173399448395
val: 2 0.5088085532188416
val: 3 0.5083998441696167
val: 4 0.5054370164871216
val: 5 0.5184091925621033
val: 6 0.5166861414909363
val: 7 0.5153760313987732
val: 8 0.49942871928215027
val: 9 0.5007940530776978
val: 10 0.48875004053115845
val: 11 0.5143145322799683
val: 12 0.5060635209083557
val: 13 0.5004167556762695
val: 14 0.5310623645782471
val: 15 0.5168637037277222
val: 16 0.5413204431533813
val: 17 0.4939737915992737
val: 18 0.5227621793746948
val: 19 0.5216801166534424
val: 20 0.5252013206481934
val_Epoch:[ 95 ] val_loss: 0.5111132830381393 2022-05-29 15:00:33.491864
start training 2022-05-29 15:00:33.593797
Epoch:[ 96 0 ] loss: 0.48464977741241455 2022-05-29 15:00:57.896267
Epoch:[ 96 1 ] loss: 0.4815514385700226 2022-05-29 15:00:58.662695
Epoch:[ 96 2 ] loss: 0.48011747002601624 2022-05-29 15:00:59.428509
Epoch:[ 96 3 ] loss: 0.47455936670303345 2022-05-29 15:01:00.207191
Epoch:[ 96 4 ] loss: 0.4795342981815338 2022-05-29 15:01:00.971458
Epoch:[ 96 5 ] loss: 0.48066627979278564 2022-05-29 15:01:01.749126
Epoch:[ 96 6 ] loss: 0.47876274585723877 2022-05-29 15:01:02.515035
Epoch:[ 96 7 ] loss: 0.4802716374397278 2022-05-29 15:01:03.279017
Epoch:[ 96 8 ] loss: 0.4815238416194916 2022-05-29 15:01:04.043834
Epoch:[ 96 9 ] loss: 0.48068860173225403 2022-05-29 15:01:04.810915
Epoch:[ 96 10 ] loss: 0.48345813155174255 2022-05-29 15:01:05.579102
Epoch:[ 96 11 ] loss: 0.47933369874954224 2022-05-29 15:01:06.343860
Epoch:[ 96 12 ] loss: 0.4756920337677002 2022-05-29 15:01:07.111826
Epoch:[ 96 13 ] loss: 0.48167988657951355 2022-05-29 15:01:07.878667
Epoch:[ 96 14 ] loss: 0.4876355528831482 2022-05-29 15:01:08.643295
Epoch:[ 96 15 ] loss: 0.4795527458190918 2022-05-29 15:01:09.407668
Epoch:[ 96 16 ] loss: 0.48113375902175903 2022-05-29 15:01:16.294433
Epoch:[ 96 17 ] loss: 0.4837416708469391 2022-05-29 15:01:17.058741
Epoch:[ 96 18 ] loss: 0.48146122694015503 2022-05-29 15:01:17.828013
Epoch:[ 96 19 ] loss: 0.48088598251342773 2022-05-29 15:01:18.593269
Training_Epoch:[ 96 ] Training_loss: 0.4808450073003769 2022-05-29 15:01:18.593974
learning rate:  0.00020176803499999987
netparams have been saved once 96
val: 1 0.5065864324569702
val: 2 0.5073485970497131
val: 3 0.5008465051651001
val: 4 0.5194034576416016
val: 5 0.5119762420654297
val: 6 0.516592264175415
val: 7 0.5274631381034851
val: 8 0.508176863193512
val: 9 0.5226218700408936
val: 10 0.523784339427948
val: 11 0.4875854551792145
val: 12 0.5211618542671204
val: 13 0.5193348526954651
val: 14 0.5089967250823975
val: 15 0.5035111904144287
val: 16 0.5206406712532043
val: 17 0.4975164830684662
val: 18 0.4999278783798218
val: 19 0.5114295482635498
val: 20 0.5087510347366333
val_Epoch:[ 96 ] val_loss: 0.5111827701330185 2022-05-29 15:01:24.037244
start training 2022-05-29 15:01:24.141489
Epoch:[ 97 0 ] loss: 0.48020827770233154 2022-05-29 15:01:46.951151
Epoch:[ 97 1 ] loss: 0.4752609133720398 2022-05-29 15:01:47.745213
Epoch:[ 97 2 ] loss: 0.47985443472862244 2022-05-29 15:01:48.511438
Epoch:[ 97 3 ] loss: 0.4831008017063141 2022-05-29 15:01:49.277685
Epoch:[ 97 4 ] loss: 0.47814029455184937 2022-05-29 15:01:50.044478
Epoch:[ 97 5 ] loss: 0.48244142532348633 2022-05-29 15:01:50.807795
Epoch:[ 97 6 ] loss: 0.48120856285095215 2022-05-29 15:01:51.571923
Epoch:[ 97 7 ] loss: 0.47978106141090393 2022-05-29 15:01:52.348711
Epoch:[ 97 8 ] loss: 0.4769064784049988 2022-05-29 15:01:53.114658
Epoch:[ 97 9 ] loss: 0.47830379009246826 2022-05-29 15:01:53.876877
Epoch:[ 97 10 ] loss: 0.4815994203090668 2022-05-29 15:01:54.641292
Epoch:[ 97 11 ] loss: 0.48406562209129333 2022-05-29 15:01:55.407247
Epoch:[ 97 12 ] loss: 0.4788777828216553 2022-05-29 15:01:56.171982
Epoch:[ 97 13 ] loss: 0.48396265506744385 2022-05-29 15:01:56.950476
Epoch:[ 97 14 ] loss: 0.48013365268707275 2022-05-29 15:01:57.716166
Epoch:[ 97 15 ] loss: 0.4834164083003998 2022-05-29 15:01:58.482564
Epoch:[ 97 16 ] loss: 0.48184746503829956 2022-05-29 15:02:06.278998
Epoch:[ 97 17 ] loss: 0.48325103521347046 2022-05-29 15:02:07.043647
Epoch:[ 97 18 ] loss: 0.4808167815208435 2022-05-29 15:02:07.813204
Epoch:[ 97 19 ] loss: 0.4818410575389862 2022-05-29 15:02:08.575187
Training_Epoch:[ 97 ] Training_loss: 0.4807508960366249 2022-05-29 15:02:08.575979
learning rate:  0.00020176803499999987
val: 1 0.5094470381736755
val: 2 0.5192228555679321
val: 3 0.5153192281723022
val: 4 0.5175002217292786
val: 5 0.5221934914588928
val: 6 0.50658118724823
val: 7 0.5145506262779236
val: 8 0.5121257901191711
val: 9 0.5182192921638489
val: 10 0.5316925644874573
val: 11 0.5061502456665039
val: 12 0.5042715668678284
val: 13 0.5362405776977539
val: 14 0.5152139663696289
val: 15 0.488936185836792
val: 16 0.4971943199634552
val: 17 0.5174667835235596
val: 18 0.50421541929245
val: 19 0.525514543056488
val: 20 0.5067765712738037
val_Epoch:[ 97 ] val_loss: 0.5134416237473488 2022-05-29 15:02:13.971179
start training 2022-05-29 15:02:14.075449
Epoch:[ 98 0 ] loss: 0.4796597957611084 2022-05-29 15:02:36.794263
Epoch:[ 98 1 ] loss: 0.4817752242088318 2022-05-29 15:02:37.987147
Epoch:[ 98 2 ] loss: 0.4828641712665558 2022-05-29 15:02:38.752310
Epoch:[ 98 3 ] loss: 0.47988858819007874 2022-05-29 15:02:39.519696
Epoch:[ 98 4 ] loss: 0.4804583787918091 2022-05-29 15:02:40.282376
Epoch:[ 98 5 ] loss: 0.47916024923324585 2022-05-29 15:02:41.049461
Epoch:[ 98 6 ] loss: 0.47896608710289 2022-05-29 15:02:41.814216
Epoch:[ 98 7 ] loss: 0.4765471816062927 2022-05-29 15:02:42.593135
Epoch:[ 98 8 ] loss: 0.48357322812080383 2022-05-29 15:02:43.357647
Epoch:[ 98 9 ] loss: 0.4817803204059601 2022-05-29 15:02:44.122594
Epoch:[ 98 10 ] loss: 0.4781492352485657 2022-05-29 15:02:44.885404
Epoch:[ 98 11 ] loss: 0.47581973671913147 2022-05-29 15:02:45.649561
Epoch:[ 98 12 ] loss: 0.48163318634033203 2022-05-29 15:02:46.416134
Epoch:[ 98 13 ] loss: 0.47751325368881226 2022-05-29 15:02:47.182984
Epoch:[ 98 14 ] loss: 0.48708003759384155 2022-05-29 15:02:47.948935
Epoch:[ 98 15 ] loss: 0.4832055866718292 2022-05-29 15:02:48.714140
Epoch:[ 98 16 ] loss: 0.4797649681568146 2022-05-29 15:02:56.401809
Epoch:[ 98 17 ] loss: 0.4784604609012604 2022-05-29 15:02:57.164607
Epoch:[ 98 18 ] loss: 0.4809567332267761 2022-05-29 15:02:57.933197
Epoch:[ 98 19 ] loss: 0.4823616147041321 2022-05-29 15:02:58.697846
Training_Epoch:[ 98 ] Training_loss: 0.4804809018969536 2022-05-29 15:02:58.698584
learning rate:  0.00020176803499999987
netparams have been saved once 98
val: 1 0.5079017877578735
val: 2 0.5041248798370361
val: 3 0.5350422859191895
val: 4 0.5187333226203918
val: 5 0.5060634016990662
val: 6 0.5153825879096985
val: 7 0.5045141577720642
val: 8 0.522980809211731
val: 9 0.5194423794746399
val: 10 0.5078799724578857
val: 11 0.517105758190155
val: 12 0.5020071864128113
val: 13 0.4999425709247589
val: 14 0.5252538323402405
val: 15 0.5214850306510925
val: 16 0.5053819417953491
val: 17 0.4884026348590851
val: 18 0.5035433769226074
val: 19 0.49292251467704773
val: 20 0.510707676410675
val_Epoch:[ 98 ] val_loss: 0.5104409053921699 2022-05-29 15:03:04.217719
start training 2022-05-29 15:03:04.320692
Epoch:[ 99 0 ] loss: 0.47862938046455383 2022-05-29 15:03:26.832081
Epoch:[ 99 1 ] loss: 0.4750082790851593 2022-05-29 15:03:28.149315
Epoch:[ 99 2 ] loss: 0.48049113154411316 2022-05-29 15:03:28.913028
Epoch:[ 99 3 ] loss: 0.4762786328792572 2022-05-29 15:03:29.677206
Epoch:[ 99 4 ] loss: 0.47552987933158875 2022-05-29 15:03:30.442494
Epoch:[ 99 5 ] loss: 0.4801997244358063 2022-05-29 15:03:31.208224
Epoch:[ 99 6 ] loss: 0.47900354862213135 2022-05-29 15:03:31.974967
Epoch:[ 99 7 ] loss: 0.4824099540710449 2022-05-29 15:03:32.741907
Epoch:[ 99 8 ] loss: 0.48140865564346313 2022-05-29 15:03:33.506305
Epoch:[ 99 9 ] loss: 0.47914832830429077 2022-05-29 15:03:34.271784
Epoch:[ 99 10 ] loss: 0.47931039333343506 2022-05-29 15:03:35.038260
Epoch:[ 99 11 ] loss: 0.48128992319107056 2022-05-29 15:03:35.803840
Epoch:[ 99 12 ] loss: 0.4794231355190277 2022-05-29 15:03:36.582905
Epoch:[ 99 13 ] loss: 0.478482186794281 2022-05-29 15:03:37.351078
Epoch:[ 99 14 ] loss: 0.47537100315093994 2022-05-29 15:03:38.114835
Epoch:[ 99 15 ] loss: 0.477596640586853 2022-05-29 15:03:38.892440
Epoch:[ 99 16 ] loss: 0.48406532406806946 2022-05-29 15:03:46.553544
Epoch:[ 99 17 ] loss: 0.48296916484832764 2022-05-29 15:03:47.317817
Epoch:[ 99 18 ] loss: 0.48397430777549744 2022-05-29 15:03:48.088546
Epoch:[ 99 19 ] loss: 0.48223647475242615 2022-05-29 15:03:48.851592
Training_Epoch:[ 99 ] Training_loss: 0.47964130342006683 2022-05-29 15:03:48.852319
learning rate:  0.00020176803499999987
val: 1 0.5115095376968384
val: 2 0.4844350814819336
val: 3 0.5086296200752258
val: 4 0.5078608393669128
val: 5 0.5019116401672363
val: 6 0.5121852159500122
val: 7 0.5080175399780273
val: 8 0.5041536092758179
val: 9 0.5255218148231506
val: 10 0.5203856229782104
val: 11 0.5043939352035522
val: 12 0.5300875306129456
val: 13 0.4939391016960144
val: 14 0.5065373182296753
val: 15 0.5104203224182129
val: 16 0.5149315595626831
val: 17 0.5319963097572327
val: 18 0.5229812264442444
val: 19 0.5189535617828369
val: 20 0.5091919302940369
val_Epoch:[ 99 ] val_loss: 0.51140216588974 2022-05-29 15:03:54.294420
start training 2022-05-29 15:03:54.396049
Epoch:[ 100 0 ] loss: 0.47666794061660767 2022-05-29 15:04:17.694539
Epoch:[ 100 1 ] loss: 0.4770885705947876 2022-05-29 15:04:18.460208
Epoch:[ 100 2 ] loss: 0.4784141480922699 2022-05-29 15:04:19.238927
Epoch:[ 100 3 ] loss: 0.4795495569705963 2022-05-29 15:04:20.004424
Epoch:[ 100 4 ] loss: 0.47891440987586975 2022-05-29 15:04:20.767771
Epoch:[ 100 5 ] loss: 0.4799906611442566 2022-05-29 15:04:21.530025
Epoch:[ 100 6 ] loss: 0.4763821065425873 2022-05-29 15:04:22.295878
Epoch:[ 100 7 ] loss: 0.47465384006500244 2022-05-29 15:04:23.060411
Epoch:[ 100 8 ] loss: 0.48154422640800476 2022-05-29 15:04:23.824824
Epoch:[ 100 9 ] loss: 0.4790421426296234 2022-05-29 15:04:24.591005
Epoch:[ 100 10 ] loss: 0.4808158874511719 2022-05-29 15:04:25.355707
Epoch:[ 100 11 ] loss: 0.4839917719364166 2022-05-29 15:04:26.120342
Epoch:[ 100 12 ] loss: 0.48136451840400696 2022-05-29 15:04:26.884726
Epoch:[ 100 13 ] loss: 0.478528767824173 2022-05-29 15:04:27.651661
Epoch:[ 100 14 ] loss: 0.48068368434906006 2022-05-29 15:04:28.428988
Epoch:[ 100 15 ] loss: 0.4822886884212494 2022-05-29 15:04:29.192379
Epoch:[ 100 16 ] loss: 0.4831463098526001 2022-05-29 15:04:37.019954
Epoch:[ 100 17 ] loss: 0.4836128056049347 2022-05-29 15:04:37.783010
Epoch:[ 100 18 ] loss: 0.47890523076057434 2022-05-29 15:04:38.550414
Epoch:[ 100 19 ] loss: 0.47687941789627075 2022-05-29 15:04:39.314186
Training_Epoch:[ 100 ] Training_loss: 0.47962323427200315 2022-05-29 15:04:39.314952
learning rate:  0.00020176803499999987
netparams have been saved once 100
val: 1 0.5048079490661621
val: 2 0.5296541452407837
val: 3 0.5195211172103882
val: 4 0.5102044343948364
val: 5 0.5178648233413696
val: 6 0.4894617199897766
val: 7 0.5198549628257751
val: 8 0.5284321308135986
val: 9 0.5032473802566528
val: 10 0.5220223665237427
val: 11 0.5119127631187439
val: 12 0.5210485458374023
val: 13 0.5197341442108154
val: 14 0.5093237161636353
val: 15 0.5135897994041443
val: 16 0.5174233913421631
val: 17 0.4966418147087097
val: 18 0.4984642565250397
val: 19 0.5089550614356995
val: 20 0.5140484571456909
val_Epoch:[ 100 ] val_loss: 0.5128106489777565 2022-05-29 15:04:44.721263
start training 2022-05-29 15:04:44.822428
Epoch:[ 101 0 ] loss: 0.4799688458442688 2022-05-29 15:05:07.218987
Epoch:[ 101 1 ] loss: 0.48057374358177185 2022-05-29 15:05:07.985492
Epoch:[ 101 2 ] loss: 0.47552400827407837 2022-05-29 15:05:09.031377
Epoch:[ 101 3 ] loss: 0.48106110095977783 2022-05-29 15:05:09.796379
Epoch:[ 101 4 ] loss: 0.47727522253990173 2022-05-29 15:05:10.560855
Epoch:[ 101 5 ] loss: 0.4771958589553833 2022-05-29 15:05:11.324561
Epoch:[ 101 6 ] loss: 0.4767419099807739 2022-05-29 15:05:12.098989
Epoch:[ 101 7 ] loss: 0.47842103242874146 2022-05-29 15:05:12.863743
Epoch:[ 101 8 ] loss: 0.47830551862716675 2022-05-29 15:05:13.629448
Epoch:[ 101 9 ] loss: 0.48125404119491577 2022-05-29 15:05:14.393413
Epoch:[ 101 10 ] loss: 0.48302382230758667 2022-05-29 15:05:15.158514
Epoch:[ 101 11 ] loss: 0.4809427857398987 2022-05-29 15:05:15.923486
Epoch:[ 101 12 ] loss: 0.4805370271205902 2022-05-29 15:05:16.688569
Epoch:[ 101 13 ] loss: 0.4796646237373352 2022-05-29 15:05:17.453696
Epoch:[ 101 14 ] loss: 0.4823830723762512 2022-05-29 15:05:18.216606
Epoch:[ 101 15 ] loss: 0.4734460413455963 2022-05-29 15:05:18.983397
Epoch:[ 101 16 ] loss: 0.47394058108329773 2022-05-29 15:05:26.764385
Epoch:[ 101 17 ] loss: 0.47904491424560547 2022-05-29 15:05:27.527285
Epoch:[ 101 18 ] loss: 0.4789808988571167 2022-05-29 15:05:28.294288
Epoch:[ 101 19 ] loss: 0.4786189794540405 2022-05-29 15:05:29.056888
Training_Epoch:[ 101 ] Training_loss: 0.4788452014327049 2022-05-29 15:05:29.057708
learning rate:  0.0001412376244999999
val: 1 0.49851083755493164
val: 2 0.5097490549087524
val: 3 0.5114868879318237
val: 4 0.5002263784408569
val: 5 0.5031327605247498
val: 6 0.5176297426223755
val: 7 0.504370391368866
val: 8 0.514625072479248
val: 9 0.5031337141990662
val: 10 0.49893686175346375
val: 11 0.5307722091674805
val: 12 0.522936999797821
val: 13 0.5252429842948914
val: 14 0.5213472843170166
val: 15 0.5281413197517395
val: 16 0.5210759043693542
val: 17 0.5166592001914978
val: 18 0.500883162021637
val: 19 0.5001407861709595
val: 20 0.5111551880836487
val_Epoch:[ 101 ] val_loss: 0.512007836997509 2022-05-29 15:05:34.522904
start training 2022-05-29 15:05:34.624160
Epoch:[ 102 0 ] loss: 0.4785618185997009 2022-05-29 15:05:58.433253
Epoch:[ 102 1 ] loss: 0.47669145464897156 2022-05-29 15:05:59.199316
Epoch:[ 102 2 ] loss: 0.47516438364982605 2022-05-29 15:05:59.965335
Epoch:[ 102 3 ] loss: 0.483136385679245 2022-05-29 15:06:00.728315
Epoch:[ 102 4 ] loss: 0.4779134690761566 2022-05-29 15:06:01.494416
Epoch:[ 102 5 ] loss: 0.47431057691574097 2022-05-29 15:06:02.259893
Epoch:[ 102 6 ] loss: 0.47986218333244324 2022-05-29 15:06:03.024207
Epoch:[ 102 7 ] loss: 0.4772432744503021 2022-05-29 15:06:03.788319
Epoch:[ 102 8 ] loss: 0.48170986771583557 2022-05-29 15:06:04.553395
Epoch:[ 102 9 ] loss: 0.47666794061660767 2022-05-29 15:06:05.319462
Epoch:[ 102 10 ] loss: 0.47400033473968506 2022-05-29 15:06:06.083891
Epoch:[ 102 11 ] loss: 0.4769810140132904 2022-05-29 15:06:06.861771
Epoch:[ 102 12 ] loss: 0.47705888748168945 2022-05-29 15:06:07.639827
Epoch:[ 102 13 ] loss: 0.476238876581192 2022-05-29 15:06:08.403351
Epoch:[ 102 14 ] loss: 0.4796942174434662 2022-05-29 15:06:09.165954
Epoch:[ 102 15 ] loss: 0.47733792662620544 2022-05-29 15:06:09.931491
Epoch:[ 102 16 ] loss: 0.47667133808135986 2022-05-29 15:06:17.249514
Epoch:[ 102 17 ] loss: 0.4794457256793976 2022-05-29 15:06:18.015963
Epoch:[ 102 18 ] loss: 0.47426778078079224 2022-05-29 15:06:18.786483
Epoch:[ 102 19 ] loss: 0.4731728136539459 2022-05-29 15:06:19.551659
Training_Epoch:[ 102 ] Training_loss: 0.47730651348829267 2022-05-29 15:06:19.552557
learning rate:  0.0001412376244999999
netparams have been saved once 102
val: 1 0.5061318278312683
val: 2 0.49161332845687866
val: 3 0.5190077424049377
val: 4 0.5075728297233582
val: 5 0.517893373966217
val: 6 0.4917038381099701
val: 7 0.5259676575660706
val: 8 0.4978974759578705
val: 9 0.5174813866615295
val: 10 0.5136603116989136
val: 11 0.509694516658783
val: 12 0.5152550339698792
val: 13 0.5180953741073608
val: 14 0.5201878547668457
val: 15 0.5175783634185791
val: 16 0.5086328387260437
val: 17 0.4901633858680725
val: 18 0.51517653465271
val: 19 0.5178930163383484
val: 20 0.5138151049613953
val_Epoch:[ 102 ] val_loss: 0.5107710897922516 2022-05-29 15:06:25.107254
start training 2022-05-29 15:06:25.210178
Epoch:[ 103 0 ] loss: 0.4715711772441864 2022-05-29 15:06:48.505596
Epoch:[ 103 1 ] loss: 0.47692298889160156 2022-05-29 15:06:49.267991
Epoch:[ 103 2 ] loss: 0.4739828407764435 2022-05-29 15:06:50.032690
Epoch:[ 103 3 ] loss: 0.4771668612957001 2022-05-29 15:06:50.798478
Epoch:[ 103 4 ] loss: 0.47311168909072876 2022-05-29 15:06:51.564475
Epoch:[ 103 5 ] loss: 0.47138315439224243 2022-05-29 15:06:52.327242
Epoch:[ 103 6 ] loss: 0.477764755487442 2022-05-29 15:06:53.091076
Epoch:[ 103 7 ] loss: 0.48015350103378296 2022-05-29 15:06:53.856577
Epoch:[ 103 8 ] loss: 0.47942304611206055 2022-05-29 15:06:54.620920
Epoch:[ 103 9 ] loss: 0.47461870312690735 2022-05-29 15:06:55.386758
Epoch:[ 103 10 ] loss: 0.4797096848487854 2022-05-29 15:06:56.165719
Epoch:[ 103 11 ] loss: 0.48323720693588257 2022-05-29 15:06:56.929465
Epoch:[ 103 12 ] loss: 0.47745010256767273 2022-05-29 15:06:57.693671
Epoch:[ 103 13 ] loss: 0.4744988977909088 2022-05-29 15:06:58.470708
Epoch:[ 103 14 ] loss: 0.4780541956424713 2022-05-29 15:06:59.236898
Epoch:[ 103 15 ] loss: 0.4780876338481903 2022-05-29 15:07:00.002402
Epoch:[ 103 16 ] loss: 0.47686174511909485 2022-05-29 15:07:07.801653
Epoch:[ 103 17 ] loss: 0.478298157453537 2022-05-29 15:07:08.565326
Epoch:[ 103 18 ] loss: 0.48127108812332153 2022-05-29 15:07:09.335545
Epoch:[ 103 19 ] loss: 0.4821290075778961 2022-05-29 15:07:10.101492
Training_Epoch:[ 103 ] Training_loss: 0.4772848218679428 2022-05-29 15:07:10.102269
learning rate:  0.0001412376244999999
val: 1 0.5081332325935364
val: 2 0.5043659806251526
val: 3 0.5099431872367859
val: 4 0.5171024799346924
val: 5 0.494814395904541
val: 6 0.5088509917259216
val: 7 0.5233257412910461
val: 8 0.5046050548553467
val: 9 0.5028903484344482
val: 10 0.5200261473655701
val: 11 0.5139082670211792
val: 12 0.5105985999107361
val: 13 0.5178089737892151
val: 14 0.5224140286445618
val: 15 0.5157062411308289
val: 16 0.5036917328834534
val: 17 0.5036640167236328
val: 18 0.520663857460022
val: 19 0.5220745801925659
val: 20 0.5202590227127075
val_Epoch:[ 103 ] val_loss: 0.5122423440217971 2022-05-29 15:07:15.524350
start training 2022-05-29 15:07:15.627784
Epoch:[ 104 0 ] loss: 0.47651973366737366 2022-05-29 15:07:39.058321
Epoch:[ 104 1 ] loss: 0.47810518741607666 2022-05-29 15:07:39.872566
Epoch:[ 104 2 ] loss: 0.47741931676864624 2022-05-29 15:07:40.638161
Epoch:[ 104 3 ] loss: 0.47204574942588806 2022-05-29 15:07:41.403869
Epoch:[ 104 4 ] loss: 0.4792587459087372 2022-05-29 15:07:42.169957
Epoch:[ 104 5 ] loss: 0.4782138168811798 2022-05-29 15:07:42.933556
Epoch:[ 104 6 ] loss: 0.47473788261413574 2022-05-29 15:07:43.697411
Epoch:[ 104 7 ] loss: 0.47567126154899597 2022-05-29 15:07:44.460243
Epoch:[ 104 8 ] loss: 0.47759515047073364 2022-05-29 15:07:45.236896
Epoch:[ 104 9 ] loss: 0.47648125886917114 2022-05-29 15:07:45.999178
Epoch:[ 104 10 ] loss: 0.478660523891449 2022-05-29 15:07:46.764673
Epoch:[ 104 11 ] loss: 0.47381722927093506 2022-05-29 15:07:47.529725
Epoch:[ 104 12 ] loss: 0.4775026738643646 2022-05-29 15:07:48.293805
Epoch:[ 104 13 ] loss: 0.4787476658821106 2022-05-29 15:07:49.056831
Epoch:[ 104 14 ] loss: 0.4759853780269623 2022-05-29 15:07:49.821568
Epoch:[ 104 15 ] loss: 0.4752768874168396 2022-05-29 15:07:50.597762
Epoch:[ 104 16 ] loss: 0.4811835289001465 2022-05-29 15:07:57.852722
Epoch:[ 104 17 ] loss: 0.47679463028907776 2022-05-29 15:07:58.800822
Epoch:[ 104 18 ] loss: 0.47522053122520447 2022-05-29 15:07:59.569867
Epoch:[ 104 19 ] loss: 0.47576284408569336 2022-05-29 15:08:00.333550
Training_Epoch:[ 104 ] Training_loss: 0.47674999982118604 2022-05-29 15:08:00.334297
learning rate:  0.0001412376244999999
netparams have been saved once 104
val: 1 0.5162543654441833
val: 2 0.5173845291137695
val: 3 0.5184786915779114
val: 4 0.5077401995658875
val: 5 0.5132549405097961
val: 6 0.5076748132705688
val: 7 0.5295734405517578
val: 8 0.5100719928741455
val: 9 0.5296502113342285
val: 10 0.5130687355995178
val: 11 0.5237501263618469
val: 12 0.514873206615448
val: 13 0.5206558108329773
val: 14 0.5120996832847595
val: 15 0.5196114778518677
val: 16 0.49712640047073364
val: 17 0.5178542733192444
val: 18 0.49984773993492126
val: 19 0.5186898112297058
val: 20 0.5110453963279724
val_Epoch:[ 104 ] val_loss: 0.5149352923035622 2022-05-29 15:08:05.908500
start training 2022-05-29 15:08:06.008344
Epoch:[ 105 0 ] loss: 0.4782335162162781 2022-05-29 15:08:29.744677
Epoch:[ 105 1 ] loss: 0.47383400797843933 2022-05-29 15:08:30.510323
Epoch:[ 105 2 ] loss: 0.47367197275161743 2022-05-29 15:08:31.273745
Epoch:[ 105 3 ] loss: 0.47303450107574463 2022-05-29 15:08:32.039645
Epoch:[ 105 4 ] loss: 0.47576582431793213 2022-05-29 15:08:32.804465
Epoch:[ 105 5 ] loss: 0.47619399428367615 2022-05-29 15:08:33.570963
Epoch:[ 105 6 ] loss: 0.47829920053482056 2022-05-29 15:08:34.348906
Epoch:[ 105 7 ] loss: 0.47542452812194824 2022-05-29 15:08:35.116054
Epoch:[ 105 8 ] loss: 0.4792085886001587 2022-05-29 15:08:35.881872
Epoch:[ 105 9 ] loss: 0.4750266969203949 2022-05-29 15:08:36.647428
Epoch:[ 105 10 ] loss: 0.4744291305541992 2022-05-29 15:08:37.410263
Epoch:[ 105 11 ] loss: 0.47559887170791626 2022-05-29 15:08:38.173809
Epoch:[ 105 12 ] loss: 0.4725194573402405 2022-05-29 15:08:38.939869
Epoch:[ 105 13 ] loss: 0.47826123237609863 2022-05-29 15:08:39.703682
Epoch:[ 105 14 ] loss: 0.4807939827442169 2022-05-29 15:08:40.469895
Epoch:[ 105 15 ] loss: 0.4795776605606079 2022-05-29 15:08:41.247068
Epoch:[ 105 16 ] loss: 0.4736645519733429 2022-05-29 15:08:48.403068
Epoch:[ 105 17 ] loss: 0.47734686732292175 2022-05-29 15:08:49.167719
Epoch:[ 105 18 ] loss: 0.4792594611644745 2022-05-29 15:08:49.937485
Epoch:[ 105 19 ] loss: 0.4761163592338562 2022-05-29 15:08:50.702777
Training_Epoch:[ 105 ] Training_loss: 0.47631302028894423 2022-05-29 15:08:50.703563
learning rate:  0.0001412376244999999
val: 1 0.5228040814399719
val: 2 0.5083251595497131
val: 3 0.5175312757492065
val: 4 0.5109528303146362
val: 5 0.5181272029876709
val: 6 0.5171229243278503
val: 7 0.5037559270858765
val: 8 0.4987495541572571
val: 9 0.510422945022583
val: 10 0.5023172497749329
val: 11 0.5012244582176208
val: 12 0.5209581255912781
val: 13 0.5078503489494324
val: 14 0.5135987401008606
val: 15 0.5073244571685791
val: 16 0.5212209820747375
val: 17 0.5145123600959778
val: 18 0.5065081119537354
val: 19 0.510792076587677
val: 20 0.5018969774246216
val_Epoch:[ 105 ] val_loss: 0.510799789428711 2022-05-29 15:08:56.114916
start training 2022-05-29 15:08:56.218655
Epoch:[ 106 0 ] loss: 0.4713098108768463 2022-05-29 15:09:19.201095
Epoch:[ 106 1 ] loss: 0.47603416442871094 2022-05-29 15:09:20.107743
Epoch:[ 106 2 ] loss: 0.4733645021915436 2022-05-29 15:09:20.875049
Epoch:[ 106 3 ] loss: 0.4755043387413025 2022-05-29 15:09:21.642641
Epoch:[ 106 4 ] loss: 0.4728827178478241 2022-05-29 15:09:22.407821
Epoch:[ 106 5 ] loss: 0.47739124298095703 2022-05-29 15:09:23.174462
Epoch:[ 106 6 ] loss: 0.47336992621421814 2022-05-29 15:09:23.942698
Epoch:[ 106 7 ] loss: 0.47508108615875244 2022-05-29 15:09:24.707517
Epoch:[ 106 8 ] loss: 0.47708410024642944 2022-05-29 15:09:25.486903
Epoch:[ 106 9 ] loss: 0.4768240749835968 2022-05-29 15:09:26.254539
Epoch:[ 106 10 ] loss: 0.47576260566711426 2022-05-29 15:09:27.020137
Epoch:[ 106 11 ] loss: 0.47382453083992004 2022-05-29 15:09:27.797666
Epoch:[ 106 12 ] loss: 0.48078468441963196 2022-05-29 15:09:28.566323
Epoch:[ 106 13 ] loss: 0.4769902229309082 2022-05-29 15:09:29.334647
Epoch:[ 106 14 ] loss: 0.4765850305557251 2022-05-29 15:09:30.100383
Epoch:[ 106 15 ] loss: 0.48237544298171997 2022-05-29 15:09:30.869076
Epoch:[ 106 16 ] loss: 0.4760347604751587 2022-05-29 15:09:38.523377
Epoch:[ 106 17 ] loss: 0.48015299439430237 2022-05-29 15:09:39.288884
Epoch:[ 106 18 ] loss: 0.4739449918270111 2022-05-29 15:09:40.055474
Epoch:[ 106 19 ] loss: 0.4717883765697479 2022-05-29 15:09:40.819451
Training_Epoch:[ 106 ] Training_loss: 0.47585448026657107 2022-05-29 15:09:40.820201
learning rate:  0.0001412376244999999
netparams have been saved once 106
val: 1 0.5153753161430359
val: 2 0.5192566514015198
val: 3 0.5126206874847412
val: 4 0.5133378505706787
val: 5 0.5044183135032654
val: 6 0.5029461979866028
val: 7 0.5105681419372559
val: 8 0.5219931602478027
val: 9 0.5080150365829468
val: 10 0.4911178648471832
val: 11 0.517003059387207
val: 12 0.5196306705474854
val: 13 0.5082674026489258
val: 14 0.5114341974258423
val: 15 0.5074767470359802
val: 16 0.5053554177284241
val: 17 0.5137850046157837
val: 18 0.4960689842700958
val: 19 0.529077410697937
val: 20 0.5068919658660889
val_Epoch:[ 106 ] val_loss: 0.5107320040464401 2022-05-29 15:09:46.312757
start training 2022-05-29 15:09:46.414892
Epoch:[ 107 0 ] loss: 0.47358614206314087 2022-05-29 15:10:10.130005
Epoch:[ 107 1 ] loss: 0.4794532358646393 2022-05-29 15:10:10.895949
Epoch:[ 107 2 ] loss: 0.4764152467250824 2022-05-29 15:10:11.661534
Epoch:[ 107 3 ] loss: 0.47367554903030396 2022-05-29 15:10:12.424235
Epoch:[ 107 4 ] loss: 0.4763853847980499 2022-05-29 15:10:13.186993
Epoch:[ 107 5 ] loss: 0.47684377431869507 2022-05-29 15:10:13.948003
Epoch:[ 107 6 ] loss: 0.4761005640029907 2022-05-29 15:10:14.711538
Epoch:[ 107 7 ] loss: 0.47459301352500916 2022-05-29 15:10:15.477504
Epoch:[ 107 8 ] loss: 0.46990540623664856 2022-05-29 15:10:16.240620
Epoch:[ 107 9 ] loss: 0.4769015908241272 2022-05-29 15:10:17.005422
Epoch:[ 107 10 ] loss: 0.46977460384368896 2022-05-29 15:10:17.769891
Epoch:[ 107 11 ] loss: 0.48231396079063416 2022-05-29 15:10:18.547690
Epoch:[ 107 12 ] loss: 0.4753960371017456 2022-05-29 15:10:19.309797
Epoch:[ 107 13 ] loss: 0.478410929441452 2022-05-29 15:10:20.074522
Epoch:[ 107 14 ] loss: 0.4756331145763397 2022-05-29 15:10:20.841530
Epoch:[ 107 15 ] loss: 0.4762522280216217 2022-05-29 15:10:21.616533
Epoch:[ 107 16 ] loss: 0.478817880153656 2022-05-29 15:10:29.706542
Epoch:[ 107 17 ] loss: 0.47843828797340393 2022-05-29 15:10:30.469338
Epoch:[ 107 18 ] loss: 0.47562238574028015 2022-05-29 15:10:31.236858
Epoch:[ 107 19 ] loss: 0.4765360653400421 2022-05-29 15:10:31.999660
Training_Epoch:[ 107 ] Training_loss: 0.4760527700185776 2022-05-29 15:10:32.000373
learning rate:  0.0001412376244999999
val: 1 0.5124457478523254
val: 2 0.5179363489151001
val: 3 0.5366219878196716
val: 4 0.5189025402069092
val: 5 0.5136493444442749
val: 6 0.5175316333770752
val: 7 0.5097577571868896
val: 8 0.5056001543998718
val: 9 0.5119313597679138
val: 10 0.5371633172035217
val: 11 0.4975946247577667
val: 12 0.5016006827354431
val: 13 0.5071233510971069
val: 14 0.5009084939956665
val: 15 0.5170522928237915
val: 16 0.5085269808769226
val: 17 0.5144272446632385
val: 18 0.5070549845695496
val: 19 0.5059230923652649
val: 20 0.4882658123970032
val_Epoch:[ 107 ] val_loss: 0.5115008875727654 2022-05-29 15:10:37.346498
start training 2022-05-29 15:10:37.445439
Epoch:[ 108 0 ] loss: 0.47951027750968933 2022-05-29 15:11:00.884849
Epoch:[ 108 1 ] loss: 0.47153741121292114 2022-05-29 15:11:01.694366
Epoch:[ 108 2 ] loss: 0.47563374042510986 2022-05-29 15:11:02.460862
Epoch:[ 108 3 ] loss: 0.48005539178848267 2022-05-29 15:11:03.225562
Epoch:[ 108 4 ] loss: 0.47637858986854553 2022-05-29 15:11:04.001963
Epoch:[ 108 5 ] loss: 0.4712868332862854 2022-05-29 15:11:04.764655
Epoch:[ 108 6 ] loss: 0.474139004945755 2022-05-29 15:11:05.531350
Epoch:[ 108 7 ] loss: 0.47432294487953186 2022-05-29 15:11:06.296320
Epoch:[ 108 8 ] loss: 0.4723780155181885 2022-05-29 15:11:07.060910
Epoch:[ 108 9 ] loss: 0.4722706079483032 2022-05-29 15:11:07.825263
Epoch:[ 108 10 ] loss: 0.4734138548374176 2022-05-29 15:11:08.591480
Epoch:[ 108 11 ] loss: 0.47983795404434204 2022-05-29 15:11:09.354305
Epoch:[ 108 12 ] loss: 0.476840078830719 2022-05-29 15:11:10.117688
Epoch:[ 108 13 ] loss: 0.47973403334617615 2022-05-29 15:11:10.881914
Epoch:[ 108 14 ] loss: 0.48238083720207214 2022-05-29 15:11:11.646342
Epoch:[ 108 15 ] loss: 0.47639626264572144 2022-05-29 15:11:12.424907
Epoch:[ 108 16 ] loss: 0.47872859239578247 2022-05-29 15:11:19.946915
Epoch:[ 108 17 ] loss: 0.47743678092956543 2022-05-29 15:11:20.710610
Epoch:[ 108 18 ] loss: 0.4785882234573364 2022-05-29 15:11:21.480018
Epoch:[ 108 19 ] loss: 0.47622111439704895 2022-05-29 15:11:22.244074
Training_Epoch:[ 108 ] Training_loss: 0.4763545274734497 2022-05-29 15:11:22.244773
learning rate:  0.0001412376244999999
netparams have been saved once 108
val: 1 0.5107991695404053
val: 2 0.516187846660614
val: 3 0.5221251845359802
val: 4 0.5117741823196411
val: 5 0.5211858749389648
val: 6 0.5135514140129089
val: 7 0.5051395893096924
val: 8 0.5085874795913696
val: 9 0.5037009119987488
val: 10 0.5223312377929688
val: 11 0.5065237283706665
val: 12 0.5223740339279175
val: 13 0.501803994178772
val: 14 0.5003041625022888
val: 15 0.4982820451259613
val: 16 0.5065689086914062
val: 17 0.5294708609580994
val: 18 0.5095661282539368
val: 19 0.5145220756530762
val: 20 0.5207028388977051
val_Epoch:[ 108 ] val_loss: 0.5122750833630562 2022-05-29 15:11:27.744269
start training 2022-05-29 15:11:27.847935
Epoch:[ 109 0 ] loss: 0.47587820887565613 2022-05-29 15:11:51.321065
Epoch:[ 109 1 ] loss: 0.4759199619293213 2022-05-29 15:11:52.411753
Epoch:[ 109 2 ] loss: 0.47556355595588684 2022-05-29 15:11:53.179623
Epoch:[ 109 3 ] loss: 0.47943177819252014 2022-05-29 15:11:53.945565
Epoch:[ 109 4 ] loss: 0.4702383577823639 2022-05-29 15:11:54.713992
Epoch:[ 109 5 ] loss: 0.4768216013908386 2022-05-29 15:11:55.479557
Epoch:[ 109 6 ] loss: 0.4732741415500641 2022-05-29 15:11:56.257416
Epoch:[ 109 7 ] loss: 0.47476711869239807 2022-05-29 15:11:57.023100
Epoch:[ 109 8 ] loss: 0.48227599263191223 2022-05-29 15:11:57.790819
Epoch:[ 109 9 ] loss: 0.47343680262565613 2022-05-29 15:11:58.559467
Epoch:[ 109 10 ] loss: 0.4748515188694 2022-05-29 15:11:59.325579
Epoch:[ 109 11 ] loss: 0.47608256340026855 2022-05-29 15:12:00.105418
Epoch:[ 109 12 ] loss: 0.4714273512363434 2022-05-29 15:12:00.870934
Epoch:[ 109 13 ] loss: 0.47660180926322937 2022-05-29 15:12:01.636449
Epoch:[ 109 14 ] loss: 0.4732688069343567 2022-05-29 15:12:02.400277
Epoch:[ 109 15 ] loss: 0.4783271253108978 2022-05-29 15:12:03.167459
Epoch:[ 109 16 ] loss: 0.47211554646492004 2022-05-29 15:12:11.007203
Epoch:[ 109 17 ] loss: 0.47614556550979614 2022-05-29 15:12:11.770995
Epoch:[ 109 18 ] loss: 0.4738996922969818 2022-05-29 15:12:12.540935
Epoch:[ 109 19 ] loss: 0.474948912858963 2022-05-29 15:12:13.304447
Training_Epoch:[ 109 ] Training_loss: 0.47526382058858874 2022-05-29 15:12:13.305166
learning rate:  0.0001412376244999999
val: 1 0.5045686364173889
val: 2 0.5165190696716309
val: 3 0.5106818675994873
val: 4 0.5007960200309753
val: 5 0.5138655304908752
val: 6 0.5162163972854614
val: 7 0.499360591173172
val: 8 0.5107860565185547
val: 9 0.5113311409950256
val: 10 0.5054517388343811
val: 11 0.5205106735229492
val: 12 0.5034273266792297
val: 13 0.5061652064323425
val: 14 0.5121811628341675
val: 15 0.5148935914039612
val: 16 0.5219907760620117
val: 17 0.5164440870285034
val: 18 0.5238854885101318
val: 19 0.5060794949531555
val: 20 0.5058354139328003
val_Epoch:[ 109 ] val_loss: 0.5110495135188102 2022-05-29 15:12:18.723659
start training 2022-05-29 15:12:18.823903
Epoch:[ 110 0 ] loss: 0.4659133553504944 2022-05-29 15:12:43.068944
Epoch:[ 110 1 ] loss: 0.47049304842948914 2022-05-29 15:12:43.833657
Epoch:[ 110 2 ] loss: 0.47182267904281616 2022-05-29 15:12:44.597445
Epoch:[ 110 3 ] loss: 0.4738945960998535 2022-05-29 15:12:45.363669
Epoch:[ 110 4 ] loss: 0.47673383355140686 2022-05-29 15:12:46.128851
Epoch:[ 110 5 ] loss: 0.4774321913719177 2022-05-29 15:12:46.893915
Epoch:[ 110 6 ] loss: 0.47167256474494934 2022-05-29 15:12:47.658542
Epoch:[ 110 7 ] loss: 0.476140558719635 2022-05-29 15:12:48.423092
Epoch:[ 110 8 ] loss: 0.47434866428375244 2022-05-29 15:12:49.201316
Epoch:[ 110 9 ] loss: 0.47629857063293457 2022-05-29 15:12:49.979177
Epoch:[ 110 10 ] loss: 0.4743340015411377 2022-05-29 15:12:50.745297
Epoch:[ 110 11 ] loss: 0.47244992852211 2022-05-29 15:12:51.510175
Epoch:[ 110 12 ] loss: 0.4757729470729828 2022-05-29 15:12:52.277236
Epoch:[ 110 13 ] loss: 0.47947630286216736 2022-05-29 15:12:53.041574
Epoch:[ 110 14 ] loss: 0.4762074649333954 2022-05-29 15:12:53.806463
Epoch:[ 110 15 ] loss: 0.48253610730171204 2022-05-29 15:12:54.570560
Epoch:[ 110 16 ] loss: 0.47477778792381287 2022-05-29 15:13:02.050488
Epoch:[ 110 17 ] loss: 0.47723066806793213 2022-05-29 15:13:02.815634
Epoch:[ 110 18 ] loss: 0.47462764382362366 2022-05-29 15:13:03.595085
Epoch:[ 110 19 ] loss: 0.4733123481273651 2022-05-29 15:13:04.359702
Training_Epoch:[ 110 ] Training_loss: 0.4747737631201744 2022-05-29 15:13:04.360394
learning rate:  0.0001412376244999999
netparams have been saved once 110
val: 1 0.5169144868850708
val: 2 0.5070663094520569
val: 3 0.5146209597587585
val: 4 0.5057918429374695
val: 5 0.5018063187599182
val: 6 0.5021073222160339
val: 7 0.50706946849823
val: 8 0.5008260011672974
val: 9 0.5186015367507935
val: 10 0.5223134160041809
val: 11 0.519169807434082
val: 12 0.52326899766922
val: 13 0.5074633359909058
val: 14 0.5204704999923706
val: 15 0.5121305584907532
val: 16 0.5104897618293762
val: 17 0.5105821490287781
val: 18 0.4996362030506134
val: 19 0.504144012928009
val: 20 0.506456732749939
val_Epoch:[ 110 ] val_loss: 0.5105464860796929 2022-05-29 15:13:09.937583
start training 2022-05-29 15:13:10.039383
Epoch:[ 111 0 ] loss: 0.4794280230998993 2022-05-29 15:13:32.648931
Epoch:[ 111 1 ] loss: 0.4767504036426544 2022-05-29 15:13:33.764984
Epoch:[ 111 2 ] loss: 0.47443267703056335 2022-05-29 15:13:34.530695
Epoch:[ 111 3 ] loss: 0.47877761721611023 2022-05-29 15:13:35.296436
Epoch:[ 111 4 ] loss: 0.4748319983482361 2022-05-29 15:13:36.063086
Epoch:[ 111 5 ] loss: 0.47128826379776 2022-05-29 15:13:36.830133
Epoch:[ 111 6 ] loss: 0.47310659289360046 2022-05-29 15:13:37.596007
Epoch:[ 111 7 ] loss: 0.4703207314014435 2022-05-29 15:13:38.373020
Epoch:[ 111 8 ] loss: 0.4718787670135498 2022-05-29 15:13:39.139599
Epoch:[ 111 9 ] loss: 0.4722088873386383 2022-05-29 15:13:39.902058
Epoch:[ 111 10 ] loss: 0.4756429195404053 2022-05-29 15:13:40.665200
Epoch:[ 111 11 ] loss: 0.4723959267139435 2022-05-29 15:13:41.432612
Epoch:[ 111 12 ] loss: 0.47020646929740906 2022-05-29 15:13:42.210625
Epoch:[ 111 13 ] loss: 0.4689117968082428 2022-05-29 15:13:42.976644
Epoch:[ 111 14 ] loss: 0.47333428263664246 2022-05-29 15:13:43.741490
Epoch:[ 111 15 ] loss: 0.4711902439594269 2022-05-29 15:13:44.508033
Epoch:[ 111 16 ] loss: 0.4760715365409851 2022-05-29 15:13:52.373063
Epoch:[ 111 17 ] loss: 0.47017425298690796 2022-05-29 15:13:53.136932
Epoch:[ 111 18 ] loss: 0.4754606783390045 2022-05-29 15:13:53.906313
Epoch:[ 111 19 ] loss: 0.47349196672439575 2022-05-29 15:13:54.669856
Training_Epoch:[ 111 ] Training_loss: 0.47349520176649096 2022-05-29 15:13:54.670655
learning rate:  9.886633714999992e-05
val: 1 0.5172713398933411
val: 2 0.508915901184082
val: 3 0.5052492022514343
val: 4 0.500215470790863
val: 5 0.509056031703949
val: 6 0.5055785775184631
val: 7 0.5208356976509094
val: 8 0.5008777379989624
val: 9 0.5204733610153198
val: 10 0.5140132904052734
val: 11 0.5066942572593689
val: 12 0.5249860286712646
val: 13 0.5198923945426941
val: 14 0.5244026184082031
val: 15 0.5055785775184631
val: 16 0.5088571310043335
val: 17 0.5124885439872742
val: 18 0.5079190731048584
val: 19 0.5011563301086426
val: 20 0.510465145111084
val_Epoch:[ 111 ] val_loss: 0.5112463355064392 2022-05-29 15:14:00.208641
start training 2022-05-29 15:14:00.308404
Epoch:[ 112 0 ] loss: 0.474693238735199 2022-05-29 15:14:23.770063
Epoch:[ 112 1 ] loss: 0.4707747995853424 2022-05-29 15:14:24.807408
Epoch:[ 112 2 ] loss: 0.4713144302368164 2022-05-29 15:14:25.573183
Epoch:[ 112 3 ] loss: 0.46800756454467773 2022-05-29 15:14:26.337253
Epoch:[ 112 4 ] loss: 0.47250062227249146 2022-05-29 15:14:27.103511
Epoch:[ 112 5 ] loss: 0.4701908528804779 2022-05-29 15:14:27.883524
Epoch:[ 112 6 ] loss: 0.4756479859352112 2022-05-29 15:14:28.648862
Epoch:[ 112 7 ] loss: 0.4741958677768707 2022-05-29 15:14:29.414356
Epoch:[ 112 8 ] loss: 0.47374996542930603 2022-05-29 15:14:30.181120
Epoch:[ 112 9 ] loss: 0.4742141664028168 2022-05-29 15:14:30.945922
Epoch:[ 112 10 ] loss: 0.4748353064060211 2022-05-29 15:14:31.712883
Epoch:[ 112 11 ] loss: 0.47593817114830017 2022-05-29 15:14:32.478964
Epoch:[ 112 12 ] loss: 0.47310754656791687 2022-05-29 15:14:33.247067
Epoch:[ 112 13 ] loss: 0.48141324520111084 2022-05-29 15:14:34.023599
Epoch:[ 112 14 ] loss: 0.47101184725761414 2022-05-29 15:14:34.790456
Epoch:[ 112 15 ] loss: 0.4679713249206543 2022-05-29 15:14:35.554251
Epoch:[ 112 16 ] loss: 0.4724728763103485 2022-05-29 15:14:43.364297
Epoch:[ 112 17 ] loss: 0.47232362627983093 2022-05-29 15:14:44.126211
Epoch:[ 112 18 ] loss: 0.470293790102005 2022-05-29 15:14:44.895054
Epoch:[ 112 19 ] loss: 0.47487592697143555 2022-05-29 15:14:45.661180
Training_Epoch:[ 112 ] Training_loss: 0.47297665774822234 2022-05-29 15:14:45.661917
learning rate:  9.886633714999992e-05
netparams have been saved once 112
val: 1 0.5142236948013306
val: 2 0.5019533634185791
val: 3 0.515320360660553
val: 4 0.5116055607795715
val: 5 0.5158839821815491
val: 6 0.5074991583824158
val: 7 0.5188137888908386
val: 8 0.5251597166061401
val: 9 0.49427923560142517
val: 10 0.5171722173690796
val: 11 0.5089981555938721
val: 12 0.4922754764556885
val: 13 0.515105664730072
val: 14 0.5094075798988342
val: 15 0.5246546268463135
val: 16 0.5188046097755432
val: 17 0.5172269344329834
val: 18 0.5052613615989685
val: 19 0.5121148824691772
val: 20 0.5071624517440796
val_Epoch:[ 112 ] val_loss: 0.5116461411118507 2022-05-29 15:14:51.208144
start training 2022-05-29 15:14:51.308533
Epoch:[ 113 0 ] loss: 0.4731559157371521 2022-05-29 15:15:14.598890
Epoch:[ 113 1 ] loss: 0.47031253576278687 2022-05-29 15:15:15.400081
Epoch:[ 113 2 ] loss: 0.4724282920360565 2022-05-29 15:15:16.165080
Epoch:[ 113 3 ] loss: 0.4733365476131439 2022-05-29 15:15:16.951907
Epoch:[ 113 4 ] loss: 0.4699365496635437 2022-05-29 15:15:17.737620
Epoch:[ 113 5 ] loss: 0.46638527512550354 2022-05-29 15:15:18.525094
Epoch:[ 113 6 ] loss: 0.47262653708457947 2022-05-29 15:15:19.305597
Epoch:[ 113 7 ] loss: 0.4708267152309418 2022-05-29 15:15:20.083498
Epoch:[ 113 8 ] loss: 0.47330260276794434 2022-05-29 15:15:20.849937
Epoch:[ 113 9 ] loss: 0.47229865193367004 2022-05-29 15:15:21.613872
Epoch:[ 113 10 ] loss: 0.47432079911231995 2022-05-29 15:15:22.381411
Epoch:[ 113 11 ] loss: 0.477407306432724 2022-05-29 15:15:23.144493
Epoch:[ 113 12 ] loss: 0.47763878107070923 2022-05-29 15:15:23.911006
Epoch:[ 113 13 ] loss: 0.4770244061946869 2022-05-29 15:15:24.678814
Epoch:[ 113 14 ] loss: 0.47395390272140503 2022-05-29 15:15:25.444149
Epoch:[ 113 15 ] loss: 0.4687969982624054 2022-05-29 15:15:26.210777
Epoch:[ 113 16 ] loss: 0.47123798727989197 2022-05-29 15:15:33.617161
Epoch:[ 113 17 ] loss: 0.4757668972015381 2022-05-29 15:15:34.382018
Epoch:[ 113 18 ] loss: 0.4696832001209259 2022-05-29 15:15:35.151189
Epoch:[ 113 19 ] loss: 0.473483145236969 2022-05-29 15:15:35.916291
Training_Epoch:[ 113 ] Training_loss: 0.4726961523294449 2022-05-29 15:15:35.917033
learning rate:  9.886633714999992e-05
val: 1 0.5042226910591125
val: 2 0.5338404774665833
val: 3 0.5094544887542725
val: 4 0.5129217505455017
val: 5 0.5034105777740479
val: 6 0.49834802746772766
val: 7 0.5055925846099854
val: 8 0.5108529925346375
val: 9 0.520236611366272
val: 10 0.5197699069976807
val: 11 0.5202550292015076
val: 12 0.4996408224105835
val: 13 0.5097662806510925
val: 14 0.5096451044082642
val: 15 0.5039713382720947
val: 16 0.513812780380249
val: 17 0.5215718746185303
val: 18 0.5170226097106934
val: 19 0.5339922904968262
val: 20 0.49138203263282776
val_Epoch:[ 113 ] val_loss: 0.5119855135679245 2022-05-29 15:15:41.307657
start training 2022-05-29 15:15:41.408713
Epoch:[ 114 0 ] loss: 0.47436419129371643 2022-05-29 15:16:05.894808
Epoch:[ 114 1 ] loss: 0.47326844930648804 2022-05-29 15:16:06.663880
Epoch:[ 114 2 ] loss: 0.4738309383392334 2022-05-29 15:16:07.429150
Epoch:[ 114 3 ] loss: 0.471271276473999 2022-05-29 15:16:08.208327
Epoch:[ 114 4 ] loss: 0.47336772084236145 2022-05-29 15:16:08.974252
Epoch:[ 114 5 ] loss: 0.4730817377567291 2022-05-29 15:16:09.741459
Epoch:[ 114 6 ] loss: 0.4754166305065155 2022-05-29 15:16:10.507533
Epoch:[ 114 7 ] loss: 0.46961498260498047 2022-05-29 15:16:11.274586
Epoch:[ 114 8 ] loss: 0.4699823260307312 2022-05-29 15:16:12.038899
Epoch:[ 114 9 ] loss: 0.4778619110584259 2022-05-29 15:16:12.803644
Epoch:[ 114 10 ] loss: 0.47243043780326843 2022-05-29 15:16:13.580841
Epoch:[ 114 11 ] loss: 0.46456316113471985 2022-05-29 15:16:14.346412
Epoch:[ 114 12 ] loss: 0.4704556465148926 2022-05-29 15:16:15.112892
Epoch:[ 114 13 ] loss: 0.47227925062179565 2022-05-29 15:16:15.878177
Epoch:[ 114 14 ] loss: 0.46897178888320923 2022-05-29 15:16:16.668472
Epoch:[ 114 15 ] loss: 0.4687282145023346 2022-05-29 15:16:17.454465
Epoch:[ 114 16 ] loss: 0.4779271185398102 2022-05-29 15:16:24.323790
Epoch:[ 114 17 ] loss: 0.47155997157096863 2022-05-29 15:16:25.110960
Epoch:[ 114 18 ] loss: 0.4759967029094696 2022-05-29 15:16:25.900207
Epoch:[ 114 19 ] loss: 0.4735679626464844 2022-05-29 15:16:26.687135
Training_Epoch:[ 114 ] Training_loss: 0.4724270209670067 2022-05-29 15:16:26.688081
learning rate:  9.886633714999992e-05
netparams have been saved once 114
val: 1 0.5119447112083435
val: 2 0.49034711718559265
val: 3 0.5071743130683899
val: 4 0.507914662361145
val: 5 0.5200483798980713
val: 6 0.5073239207267761
val: 7 0.4994560778141022
val: 8 0.4984041750431061
val: 9 0.5111696124076843
val: 10 0.5035926103591919
val: 11 0.5157017111778259
val: 12 0.5192034840583801
val: 13 0.5070206522941589
val: 14 0.5248207449913025
val: 15 0.5204629302024841
val: 16 0.520279049873352
val: 17 0.510628879070282
val: 18 0.5114709138870239
val: 19 0.5286038517951965
val: 20 0.5203661918640137
val_Epoch:[ 114 ] val_loss: 0.5117966994643212 2022-05-29 15:16:32.298319
start training 2022-05-29 15:16:32.399043
Epoch:[ 115 0 ] loss: 0.47058340907096863 2022-05-29 15:16:55.625577
Epoch:[ 115 1 ] loss: 0.4732566773891449 2022-05-29 15:16:56.438894
Epoch:[ 115 2 ] loss: 0.4732150733470917 2022-05-29 15:16:57.201779
Epoch:[ 115 3 ] loss: 0.4678820073604584 2022-05-29 15:16:57.968751
Epoch:[ 115 4 ] loss: 0.46867266297340393 2022-05-29 15:16:58.735938
Epoch:[ 115 5 ] loss: 0.468969464302063 2022-05-29 15:16:59.525762
Epoch:[ 115 6 ] loss: 0.4739345908164978 2022-05-29 15:17:00.314449
Epoch:[ 115 7 ] loss: 0.469517320394516 2022-05-29 15:17:01.103710
Epoch:[ 115 8 ] loss: 0.4781060218811035 2022-05-29 15:17:01.895086
Epoch:[ 115 9 ] loss: 0.4738525450229645 2022-05-29 15:17:02.684218
Epoch:[ 115 10 ] loss: 0.47234195470809937 2022-05-29 15:17:03.473855
Epoch:[ 115 11 ] loss: 0.47211092710494995 2022-05-29 15:17:04.259953
Epoch:[ 115 12 ] loss: 0.47033658623695374 2022-05-29 15:17:05.050468
Epoch:[ 115 13 ] loss: 0.4708772599697113 2022-05-29 15:17:05.836284
Epoch:[ 115 14 ] loss: 0.4704251289367676 2022-05-29 15:17:06.626243
Epoch:[ 115 15 ] loss: 0.4723021388053894 2022-05-29 15:17:07.403330
Epoch:[ 115 16 ] loss: 0.47668224573135376 2022-05-29 15:17:14.940167
Epoch:[ 115 17 ] loss: 0.47158053517341614 2022-05-29 15:17:15.728833
Epoch:[ 115 18 ] loss: 0.47568365931510925 2022-05-29 15:17:16.508635
Epoch:[ 115 19 ] loss: 0.47349342703819275 2022-05-29 15:17:17.273676
Training_Epoch:[ 115 ] Training_loss: 0.4721911817789078 2022-05-29 15:17:17.274676
learning rate:  9.886633714999992e-05
val: 1 0.5039343237876892
val: 2 0.5186654925346375
val: 3 0.5149228572845459
val: 4 0.5099148154258728
val: 5 0.515716552734375
val: 6 0.5193600654602051
val: 7 0.5128913521766663
val: 8 0.5279578566551208
val: 9 0.5144741535186768
val: 10 0.5008018612861633
val: 11 0.5011435151100159
val: 12 0.516954779624939
val: 13 0.5040839910507202
val: 14 0.5319749712944031
val: 15 0.5323693752288818
val: 16 0.5063648223876953
val: 17 0.5175753235816956
val: 18 0.49935606122016907
val: 19 0.5036500096321106
val: 20 0.49914830923080444
val_Epoch:[ 115 ] val_loss: 0.5125630244612693 2022-05-29 15:17:22.757597
start training 2022-05-29 15:17:22.857353
Epoch:[ 116 0 ] loss: 0.47194889187812805 2022-05-29 15:17:46.337813
Epoch:[ 116 1 ] loss: 0.4711363613605499 2022-05-29 15:17:47.141414
Epoch:[ 116 2 ] loss: 0.4747282564640045 2022-05-29 15:17:47.908755
Epoch:[ 116 3 ] loss: 0.4733297824859619 2022-05-29 15:17:48.687381
Epoch:[ 116 4 ] loss: 0.4733816385269165 2022-05-29 15:17:49.452970
Epoch:[ 116 5 ] loss: 0.47294703125953674 2022-05-29 15:17:50.218472
Epoch:[ 116 6 ] loss: 0.4681742489337921 2022-05-29 15:17:50.982990
Epoch:[ 116 7 ] loss: 0.47018638253211975 2022-05-29 15:17:51.748158
Epoch:[ 116 8 ] loss: 0.47077158093452454 2022-05-29 15:17:52.526736
Epoch:[ 116 9 ] loss: 0.47505295276641846 2022-05-29 15:17:53.294106
Epoch:[ 116 10 ] loss: 0.46967872977256775 2022-05-29 15:17:54.063258
Epoch:[ 116 11 ] loss: 0.4706476032733917 2022-05-29 15:17:54.830345
Epoch:[ 116 12 ] loss: 0.47256168723106384 2022-05-29 15:17:55.595604
Epoch:[ 116 13 ] loss: 0.4694799780845642 2022-05-29 15:17:56.362866
Epoch:[ 116 14 ] loss: 0.4735540449619293 2022-05-29 15:17:57.129640
Epoch:[ 116 15 ] loss: 0.47231361269950867 2022-05-29 15:17:57.896652
Epoch:[ 116 16 ] loss: 0.47401052713394165 2022-05-29 15:18:05.210662
Epoch:[ 116 17 ] loss: 0.47348275780677795 2022-05-29 15:18:05.975321
Epoch:[ 116 18 ] loss: 0.47050702571868896 2022-05-29 15:18:06.746360
Epoch:[ 116 19 ] loss: 0.4687753915786743 2022-05-29 15:18:07.511444
Training_Epoch:[ 116 ] Training_loss: 0.47183342427015307 2022-05-29 15:18:07.512149
learning rate:  9.886633714999992e-05
netparams have been saved once 116
val: 1 0.5305314660072327
val: 2 0.5072191953659058
val: 3 0.5084757208824158
val: 4 0.5162162780761719
val: 5 0.49292057752609253
val: 6 0.5195590853691101
val: 7 0.5131188035011292
val: 8 0.5173419713973999
val: 9 0.5188915133476257
val: 10 0.504060685634613
val: 11 0.5141952633857727
val: 12 0.5101683139801025
val: 13 0.5117361545562744
val: 14 0.49625077843666077
val: 15 0.5178792476654053
val: 16 0.49100589752197266
val: 17 0.5285199880599976
val: 18 0.508478581905365
val: 19 0.5008437633514404
val: 20 0.5192307829856873
val_Epoch:[ 116 ] val_loss: 0.5113322034478187 2022-05-29 15:18:12.999642
start training 2022-05-29 15:18:13.104482
Epoch:[ 117 0 ] loss: 0.4710632264614105 2022-05-29 15:18:36.279565
Epoch:[ 117 1 ] loss: 0.4719380736351013 2022-05-29 15:18:37.335134
Epoch:[ 117 2 ] loss: 0.4701002836227417 2022-05-29 15:18:38.113471
Epoch:[ 117 3 ] loss: 0.47480443120002747 2022-05-29 15:18:38.881008
Epoch:[ 117 4 ] loss: 0.4697500169277191 2022-05-29 15:18:39.649284
Epoch:[ 117 5 ] loss: 0.4717295169830322 2022-05-29 15:18:40.414240
Epoch:[ 117 6 ] loss: 0.46962499618530273 2022-05-29 15:18:41.180453
Epoch:[ 117 7 ] loss: 0.468347430229187 2022-05-29 15:18:41.945602
Epoch:[ 117 8 ] loss: 0.47358694672584534 2022-05-29 15:18:42.710523
Epoch:[ 117 9 ] loss: 0.4706050455570221 2022-05-29 15:18:43.476829
Epoch:[ 117 10 ] loss: 0.46756160259246826 2022-05-29 15:18:44.242326
Epoch:[ 117 11 ] loss: 0.46971455216407776 2022-05-29 15:18:45.007883
Epoch:[ 117 12 ] loss: 0.470804899930954 2022-05-29 15:18:45.775091
Epoch:[ 117 13 ] loss: 0.4719335436820984 2022-05-29 15:18:46.552523
Epoch:[ 117 14 ] loss: 0.4709569215774536 2022-05-29 15:18:47.318874
Epoch:[ 117 15 ] loss: 0.47232288122177124 2022-05-29 15:18:48.084730
Epoch:[ 117 16 ] loss: 0.47698917984962463 2022-05-29 15:18:55.494889
Epoch:[ 117 17 ] loss: 0.4745776653289795 2022-05-29 15:18:56.260630
Epoch:[ 117 18 ] loss: 0.4741343557834625 2022-05-29 15:18:57.031448
Epoch:[ 117 19 ] loss: 0.4678342938423157 2022-05-29 15:18:57.797707
Training_Epoch:[ 117 ] Training_loss: 0.4714189931750298 2022-05-29 15:18:57.798385
learning rate:  9.886633714999992e-05
val: 1 0.5008533000946045
val: 2 0.513099193572998
val: 3 0.5182132720947266
val: 4 0.5102638602256775
val: 5 0.5102162957191467
val: 6 0.508569598197937
val: 7 0.5219762325286865
val: 8 0.5189201831817627
val: 9 0.5072590708732605
val: 10 0.5053130388259888
val: 11 0.5063911080360413
val: 12 0.509575366973877
val: 13 0.513175904750824
val: 14 0.5111256837844849
val: 15 0.512507975101471
val: 16 0.4958536624908447
val: 17 0.5089537501335144
val: 18 0.5371509790420532
val: 19 0.5197994112968445
val: 20 0.5335904359817505
val_Epoch:[ 117 ] val_loss: 0.5131404161453247 2022-05-29 15:19:03.294592
start training 2022-05-29 15:19:03.397888
Epoch:[ 118 0 ] loss: 0.46917724609375 2022-05-29 15:19:26.105817
Epoch:[ 118 1 ] loss: 0.4732385277748108 2022-05-29 15:19:26.872360
Epoch:[ 118 2 ] loss: 0.4719858467578888 2022-05-29 15:19:27.667109
Epoch:[ 118 3 ] loss: 0.47538724541664124 2022-05-29 15:19:28.432943
Epoch:[ 118 4 ] loss: 0.4687875211238861 2022-05-29 15:19:29.201567
Epoch:[ 118 5 ] loss: 0.46445029973983765 2022-05-29 15:19:29.967861
Epoch:[ 118 6 ] loss: 0.4755752682685852 2022-05-29 15:19:30.735303
Epoch:[ 118 7 ] loss: 0.4676523804664612 2022-05-29 15:19:31.502269
Epoch:[ 118 8 ] loss: 0.4707361161708832 2022-05-29 15:19:32.269690
Epoch:[ 118 9 ] loss: 0.4723173975944519 2022-05-29 15:19:33.036238
Epoch:[ 118 10 ] loss: 0.4706866443157196 2022-05-29 15:19:33.817646
Epoch:[ 118 11 ] loss: 0.4710391163825989 2022-05-29 15:19:34.601238
Epoch:[ 118 12 ] loss: 0.4740730822086334 2022-05-29 15:19:35.368421
Epoch:[ 118 13 ] loss: 0.4703819155693054 2022-05-29 15:19:36.135373
Epoch:[ 118 14 ] loss: 0.4734897017478943 2022-05-29 15:19:36.903475
Epoch:[ 118 15 ] loss: 0.47328436374664307 2022-05-29 15:19:37.671596
Epoch:[ 118 16 ] loss: 0.47415387630462646 2022-05-29 15:19:48.038599
Epoch:[ 118 17 ] loss: 0.47359219193458557 2022-05-29 15:19:48.804228
Epoch:[ 118 18 ] loss: 0.4726774990558624 2022-05-29 15:19:49.588300
Epoch:[ 118 19 ] loss: 0.4710826277732849 2022-05-29 15:19:50.354168
Training_Epoch:[ 118 ] Training_loss: 0.4716884434223175 2022-05-29 15:19:50.354945
learning rate:  9.886633714999992e-05
netparams have been saved once 118
val: 1 0.515036940574646
val: 2 0.4967752695083618
val: 3 0.5131612420082092
val: 4 0.5202300548553467
val: 5 0.5176075100898743
val: 6 0.4922521710395813
val: 7 0.4966447949409485
val: 8 0.52292400598526
val: 9 0.5124704837799072
val: 10 0.4946422576904297
val: 11 0.5247710943222046
val: 12 0.5212528109550476
val: 13 0.5059592127799988
val: 14 0.5183769464492798
val: 15 0.5113025307655334
val: 16 0.515089750289917
val: 17 0.5173479318618774
val: 18 0.52882981300354
val: 19 0.510330319404602
val: 20 0.5068866610527039
val_Epoch:[ 118 ] val_loss: 0.5120945900678635 2022-05-29 15:19:55.889380
start training 2022-05-29 15:19:55.991254
Epoch:[ 119 0 ] loss: 0.4719816744327545 2022-05-29 15:20:21.616861
Epoch:[ 119 1 ] loss: 0.47227776050567627 2022-05-29 15:20:22.383185
Epoch:[ 119 2 ] loss: 0.4710509479045868 2022-05-29 15:20:23.149572
Epoch:[ 119 3 ] loss: 0.47223007678985596 2022-05-29 15:20:23.914014
Epoch:[ 119 4 ] loss: 0.4707971513271332 2022-05-29 15:20:24.679995
Epoch:[ 119 5 ] loss: 0.47156384587287903 2022-05-29 15:20:25.445407
Epoch:[ 119 6 ] loss: 0.4670484662055969 2022-05-29 15:20:26.211325
Epoch:[ 119 7 ] loss: 0.47285234928131104 2022-05-29 15:20:26.978020
Epoch:[ 119 8 ] loss: 0.47413861751556396 2022-05-29 15:20:27.744973
Epoch:[ 119 9 ] loss: 0.4701108932495117 2022-05-29 15:20:28.509820
Epoch:[ 119 10 ] loss: 0.47026142477989197 2022-05-29 15:20:29.276004
Epoch:[ 119 11 ] loss: 0.4712674915790558 2022-05-29 15:20:30.040589
Epoch:[ 119 12 ] loss: 0.4757765829563141 2022-05-29 15:20:30.818148
Epoch:[ 119 13 ] loss: 0.47290313243865967 2022-05-29 15:20:31.582674
Epoch:[ 119 14 ] loss: 0.4717026352882385 2022-05-29 15:20:32.362352
Epoch:[ 119 15 ] loss: 0.4722193777561188 2022-05-29 15:20:33.127759
Epoch:[ 119 16 ] loss: 0.4666782021522522 2022-05-29 15:20:40.667493
Epoch:[ 119 17 ] loss: 0.4722593426704407 2022-05-29 15:20:41.428742
Epoch:[ 119 18 ] loss: 0.4738216996192932 2022-05-29 15:20:42.196607
Epoch:[ 119 19 ] loss: 0.4677980840206146 2022-05-29 15:20:42.961913
Training_Epoch:[ 119 ] Training_loss: 0.47143698781728743 2022-05-29 15:20:42.962678
learning rate:  9.886633714999992e-05
val: 1 0.4891091287136078
val: 2 0.4916874170303345
val: 3 0.509919285774231
val: 4 0.5245004296302795
val: 5 0.49756723642349243
val: 6 0.49640873074531555
val: 7 0.5251491069793701
val: 8 0.5312646627426147
val: 9 0.5166984796524048
val: 10 0.5041370987892151
val: 11 0.510024905204773
val: 12 0.5017639994621277
val: 13 0.5364722609519958
val: 14 0.5260413289070129
val: 15 0.509332001209259
val: 16 0.4949917495250702
val: 17 0.5172304511070251
val: 18 0.5079889893531799
val: 19 0.5171726942062378
val: 20 0.5302978157997131
val_Epoch:[ 119 ] val_loss: 0.511887888610363 2022-05-29 15:20:48.407262
start training 2022-05-29 15:20:48.507960
Epoch:[ 120 0 ] loss: 0.4705754518508911 2022-05-29 15:21:14.385251
Epoch:[ 120 1 ] loss: 0.47377151250839233 2022-05-29 15:21:15.163772
Epoch:[ 120 2 ] loss: 0.46850061416625977 2022-05-29 15:21:15.929978
Epoch:[ 120 3 ] loss: 0.46899232268333435 2022-05-29 15:21:16.695367
Epoch:[ 120 4 ] loss: 0.47116175293922424 2022-05-29 15:21:17.459989
Epoch:[ 120 5 ] loss: 0.471711665391922 2022-05-29 15:21:18.238749
Epoch:[ 120 6 ] loss: 0.4696922302246094 2022-05-29 15:21:19.006481
Epoch:[ 120 7 ] loss: 0.4743938744068146 2022-05-29 15:21:19.772906
Epoch:[ 120 8 ] loss: 0.46644124388694763 2022-05-29 15:21:20.537618
Epoch:[ 120 9 ] loss: 0.46915584802627563 2022-05-29 15:21:21.303323
Epoch:[ 120 10 ] loss: 0.4726239740848541 2022-05-29 15:21:22.067035
Epoch:[ 120 11 ] loss: 0.4685330390930176 2022-05-29 15:21:22.832773
Epoch:[ 120 12 ] loss: 0.4732730984687805 2022-05-29 15:21:23.597404
Epoch:[ 120 13 ] loss: 0.46995583176612854 2022-05-29 15:21:24.365150
Epoch:[ 120 14 ] loss: 0.469890296459198 2022-05-29 15:21:25.129836
Epoch:[ 120 15 ] loss: 0.47403496503829956 2022-05-29 15:21:25.897837
Epoch:[ 120 16 ] loss: 0.47417697310447693 2022-05-29 15:21:33.280507
Epoch:[ 120 17 ] loss: 0.47427013516426086 2022-05-29 15:21:34.045068
Epoch:[ 120 18 ] loss: 0.4688001573085785 2022-05-29 15:21:34.813870
Epoch:[ 120 19 ] loss: 0.4679113030433655 2022-05-29 15:21:35.580053
Training_Epoch:[ 120 ] Training_loss: 0.47089331448078153 2022-05-29 15:21:35.580782
learning rate:  9.886633714999992e-05
netparams have been saved once 120
val: 1 0.51547771692276
val: 2 0.5072930455207825
val: 3 0.5070489645004272
val: 4 0.4990614950656891
val: 5 0.5202159285545349
val: 6 0.5121009349822998
val: 7 0.521885335445404
val: 8 0.5401147603988647
val: 9 0.5112228393554688
val: 10 0.5151007771492004
val: 11 0.4975101351737976
val: 12 0.5107691287994385
val: 13 0.4988172650337219
val: 14 0.5018894672393799
val: 15 0.5256624817848206
val: 16 0.5039263367652893
val: 17 0.5297837257385254
val: 18 0.5164172053337097
val: 19 0.4985778331756592
val: 20 0.5219602584838867
val_Epoch:[ 120 ] val_loss: 0.512741781771183 2022-05-29 15:21:41.092190
start training 2022-05-29 15:21:41.193312
Epoch:[ 121 0 ] loss: 0.4706811308860779 2022-05-29 15:22:07.608634
Epoch:[ 121 1 ] loss: 0.4699837267398834 2022-05-29 15:22:08.376150
Epoch:[ 121 2 ] loss: 0.46947839856147766 2022-05-29 15:22:09.142529
Epoch:[ 121 3 ] loss: 0.4737177789211273 2022-05-29 15:22:09.907598
Epoch:[ 121 4 ] loss: 0.4670206606388092 2022-05-29 15:22:10.672471
Epoch:[ 121 5 ] loss: 0.4711940586566925 2022-05-29 15:22:11.448125
Epoch:[ 121 6 ] loss: 0.4680320918560028 2022-05-29 15:22:12.213875
Epoch:[ 121 7 ] loss: 0.472172349691391 2022-05-29 15:22:12.979578
Epoch:[ 121 8 ] loss: 0.4711952805519104 2022-05-29 15:22:13.744107
Epoch:[ 121 9 ] loss: 0.47256752848625183 2022-05-29 15:22:14.509987
Epoch:[ 121 10 ] loss: 0.46960097551345825 2022-05-29 15:22:15.287299
Epoch:[ 121 11 ] loss: 0.4701247811317444 2022-05-29 15:22:16.054845
Epoch:[ 121 12 ] loss: 0.4677572548389435 2022-05-29 15:22:16.819076
Epoch:[ 121 13 ] loss: 0.4671701490879059 2022-05-29 15:22:17.583992
Epoch:[ 121 14 ] loss: 0.47387662529945374 2022-05-29 15:22:18.351713
Epoch:[ 121 15 ] loss: 0.4726785123348236 2022-05-29 15:22:19.116386
Epoch:[ 121 16 ] loss: 0.4653668701648712 2022-05-29 15:22:26.478649
Epoch:[ 121 17 ] loss: 0.46817052364349365 2022-05-29 15:22:27.870234
Epoch:[ 121 18 ] loss: 0.4668896198272705 2022-05-29 15:22:28.641148
Epoch:[ 121 19 ] loss: 0.47650381922721863 2022-05-29 15:22:29.404874
Training_Epoch:[ 121 ] Training_loss: 0.47020910680294037 2022-05-29 15:22:29.405712
learning rate:  6.920643600499994e-05
val: 1 0.5191259384155273
val: 2 0.5056109428405762
val: 3 0.525175929069519
val: 4 0.5091780424118042
val: 5 0.5188726782798767
val: 6 0.5207147598266602
val: 7 0.49970322847366333
val: 8 0.5201191902160645
val: 9 0.5083129405975342
val: 10 0.5051795244216919
val: 11 0.5287280678749084
val: 12 0.5348032116889954
val: 13 0.5046743154525757
val: 14 0.5164194703102112
val: 15 0.5070251226425171
val: 16 0.5092326402664185
val: 17 0.5140517950057983
val: 18 0.5006883144378662
val: 19 0.5082999467849731
val: 20 0.5026009678840637
val_Epoch:[ 121 ] val_loss: 0.5129258513450623 2022-05-29 15:22:35.093205
start training 2022-05-29 15:22:35.192450
Epoch:[ 122 0 ] loss: 0.47485294938087463 2022-05-29 15:22:59.852897
Epoch:[ 122 1 ] loss: 0.4702198803424835 2022-05-29 15:23:00.667343
Epoch:[ 122 2 ] loss: 0.46969372034072876 2022-05-29 15:23:01.433592
Epoch:[ 122 3 ] loss: 0.46870777010917664 2022-05-29 15:23:02.201044
Epoch:[ 122 4 ] loss: 0.4667015075683594 2022-05-29 15:23:02.966557
Epoch:[ 122 5 ] loss: 0.46953877806663513 2022-05-29 15:23:03.730986
Epoch:[ 122 6 ] loss: 0.4662573039531708 2022-05-29 15:23:04.515288
Epoch:[ 122 7 ] loss: 0.47101861238479614 2022-05-29 15:23:05.298144
Epoch:[ 122 8 ] loss: 0.4722842276096344 2022-05-29 15:23:06.065637
Epoch:[ 122 9 ] loss: 0.47060567140579224 2022-05-29 15:23:06.833250
Epoch:[ 122 10 ] loss: 0.468636155128479 2022-05-29 15:23:07.599060
Epoch:[ 122 11 ] loss: 0.4705950915813446 2022-05-29 15:23:08.364958
Epoch:[ 122 12 ] loss: 0.4728851318359375 2022-05-29 15:23:09.132516
Epoch:[ 122 13 ] loss: 0.4635780453681946 2022-05-29 15:23:09.896260
Epoch:[ 122 14 ] loss: 0.4725853204727173 2022-05-29 15:23:10.661420
Epoch:[ 122 15 ] loss: 0.46910685300827026 2022-05-29 15:23:11.427063
Epoch:[ 122 16 ] loss: 0.4691854417324066 2022-05-29 15:23:19.549662
Epoch:[ 122 17 ] loss: 0.4685741662979126 2022-05-29 15:23:20.316016
Epoch:[ 122 18 ] loss: 0.4732714891433716 2022-05-29 15:23:21.084916
Epoch:[ 122 19 ] loss: 0.4714100956916809 2022-05-29 15:23:21.849169
Training_Epoch:[ 122 ] Training_loss: 0.4699854105710983 2022-05-29 15:23:21.849936
learning rate:  6.920643600499994e-05
netparams have been saved once 122
val: 1 0.5210060477256775
val: 2 0.5194117426872253
val: 3 0.508216142654419
val: 4 0.5315009951591492
val: 5 0.506609320640564
val: 6 0.5198652148246765
val: 7 0.5103264451026917
val: 8 0.5054402947425842
val: 9 0.5143739581108093
val: 10 0.5265741944313049
val: 11 0.5034943222999573
val: 12 0.5043131709098816
val: 13 0.5020645260810852
val: 14 0.5060073733329773
val: 15 0.5206443667411804
val: 16 0.502379298210144
val: 17 0.5125066637992859
val: 18 0.5212449431419373
val: 19 0.5094501376152039
val: 20 0.5111246705055237
val_Epoch:[ 122 ] val_loss: 0.5128276914358139 2022-05-29 15:23:27.591526
start training 2022-05-29 15:23:27.693713
Epoch:[ 123 0 ] loss: 0.47183138132095337 2022-05-29 15:23:52.054676
Epoch:[ 123 1 ] loss: 0.46667641401290894 2022-05-29 15:23:53.723636
Epoch:[ 123 2 ] loss: 0.46918511390686035 2022-05-29 15:23:54.489274
Epoch:[ 123 3 ] loss: 0.47150593996047974 2022-05-29 15:23:55.256135
Epoch:[ 123 4 ] loss: 0.47137072682380676 2022-05-29 15:23:56.024010
Epoch:[ 123 5 ] loss: 0.46836555004119873 2022-05-29 15:23:56.790867
Epoch:[ 123 6 ] loss: 0.4698990285396576 2022-05-29 15:23:57.557669
Epoch:[ 123 7 ] loss: 0.4675017297267914 2022-05-29 15:23:58.338958
Epoch:[ 123 8 ] loss: 0.46572792530059814 2022-05-29 15:23:59.105252
Epoch:[ 123 9 ] loss: 0.47106996178627014 2022-05-29 15:23:59.872788
Epoch:[ 123 10 ] loss: 0.4707195460796356 2022-05-29 15:24:00.638704
Epoch:[ 123 11 ] loss: 0.47158271074295044 2022-05-29 15:24:01.405462
Epoch:[ 123 12 ] loss: 0.4657213091850281 2022-05-29 15:24:02.172616
Epoch:[ 123 13 ] loss: 0.46778324246406555 2022-05-29 15:24:02.939061
Epoch:[ 123 14 ] loss: 0.46766397356987 2022-05-29 15:24:03.704213
Epoch:[ 123 15 ] loss: 0.4666846692562103 2022-05-29 15:24:04.483149
Epoch:[ 123 16 ] loss: 0.4744282364845276 2022-05-29 15:24:11.361877
Epoch:[ 123 17 ] loss: 0.47206342220306396 2022-05-29 15:24:15.192432
Epoch:[ 123 18 ] loss: 0.4668860137462616 2022-05-29 15:24:15.979772
Epoch:[ 123 19 ] loss: 0.47330403327941895 2022-05-29 15:24:16.745484
Training_Epoch:[ 123 ] Training_loss: 0.4694985464215279 2022-05-29 15:24:16.746316
learning rate:  6.920643600499994e-05
val: 1 0.5114508867263794
val: 2 0.5264052748680115
val: 3 0.5130314826965332
val: 4 0.5299469232559204
val: 5 0.5404898524284363
val: 6 0.5217934846878052
val: 7 0.5106479525566101
val: 8 0.49770599603652954
val: 9 0.522055983543396
val: 10 0.5075101256370544
val: 11 0.5011736154556274
val: 12 0.5097339153289795
val: 13 0.5153497457504272
val: 14 0.5247642397880554
val: 15 0.5070711970329285
val: 16 0.5008245706558228
val: 17 0.5154776573181152
val: 18 0.5101954936981201
val: 19 0.48752114176750183
val: 20 0.5158642530441284
val_Epoch:[ 123 ] val_loss: 0.5134506896138191 2022-05-29 15:24:22.176810
start training 2022-05-29 15:24:22.277911
Epoch:[ 124 0 ] loss: 0.46817895770072937 2022-05-29 15:24:47.443520
Epoch:[ 124 1 ] loss: 0.4725043475627899 2022-05-29 15:24:48.221211
Epoch:[ 124 2 ] loss: 0.4690666198730469 2022-05-29 15:24:48.986757
Epoch:[ 124 3 ] loss: 0.4695715308189392 2022-05-29 15:24:49.753661
Epoch:[ 124 4 ] loss: 0.4710698127746582 2022-05-29 15:24:50.517804
Epoch:[ 124 5 ] loss: 0.4709194004535675 2022-05-29 15:24:51.283125
Epoch:[ 124 6 ] loss: 0.4666309356689453 2022-05-29 15:24:52.048586
Epoch:[ 124 7 ] loss: 0.46970078349113464 2022-05-29 15:24:52.814561
Epoch:[ 124 8 ] loss: 0.4656946659088135 2022-05-29 15:24:53.580020
Epoch:[ 124 9 ] loss: 0.4657902717590332 2022-05-29 15:24:54.345940
Epoch:[ 124 10 ] loss: 0.4705910086631775 2022-05-29 15:24:55.113007
Epoch:[ 124 11 ] loss: 0.47071054577827454 2022-05-29 15:24:55.878417
Epoch:[ 124 12 ] loss: 0.4691605567932129 2022-05-29 15:24:56.646414
Epoch:[ 124 13 ] loss: 0.46921205520629883 2022-05-29 15:24:57.426800
Epoch:[ 124 14 ] loss: 0.47162503004074097 2022-05-29 15:24:58.191130
Epoch:[ 124 15 ] loss: 0.47068721055984497 2022-05-29 15:24:58.955550
Epoch:[ 124 16 ] loss: 0.47161436080932617 2022-05-29 15:25:06.712617
Epoch:[ 124 17 ] loss: 0.4707028567790985 2022-05-29 15:25:07.478213
Epoch:[ 124 18 ] loss: 0.4647790789604187 2022-05-29 15:25:08.245884
Epoch:[ 124 19 ] loss: 0.4708271324634552 2022-05-29 15:25:09.010499
Training_Epoch:[ 124 ] Training_loss: 0.4694518581032753 2022-05-29 15:25:09.011196
learning rate:  6.920643600499994e-05
netparams have been saved once 124
val: 1 0.4975036680698395
val: 2 0.5197792053222656
val: 3 0.507416307926178
val: 4 0.5052006244659424
val: 5 0.5176097750663757
val: 6 0.5046384334564209
val: 7 0.5183895230293274
val: 8 0.5141277313232422
val: 9 0.5115821361541748
val: 10 0.516319215297699
val: 11 0.5052549242973328
val: 12 0.537950873374939
val: 13 0.5092215538024902
val: 14 0.508415937423706
val: 15 0.5009865760803223
val: 16 0.5120461583137512
val: 17 0.5315859317779541
val: 18 0.5059108734130859
val: 19 0.506596565246582
val: 20 0.521295964717865
val_Epoch:[ 124 ] val_loss: 0.5125915989279747 2022-05-29 15:25:14.747074
start training 2022-05-29 15:25:14.848860
Epoch:[ 125 0 ] loss: 0.4707747995853424 2022-05-29 15:25:39.759273
Epoch:[ 125 1 ] loss: 0.46623900532722473 2022-05-29 15:25:40.830965
Epoch:[ 125 2 ] loss: 0.47081321477890015 2022-05-29 15:25:41.595005
Epoch:[ 125 3 ] loss: 0.4683181047439575 2022-05-29 15:25:42.360827
Epoch:[ 125 4 ] loss: 0.4723699390888214 2022-05-29 15:25:43.127413
Epoch:[ 125 5 ] loss: 0.46884602308273315 2022-05-29 15:25:43.908560
Epoch:[ 125 6 ] loss: 0.46878865361213684 2022-05-29 15:25:44.677410
Epoch:[ 125 7 ] loss: 0.4720642566680908 2022-05-29 15:25:45.444436
Epoch:[ 125 8 ] loss: 0.4641472399234772 2022-05-29 15:25:46.224913
Epoch:[ 125 9 ] loss: 0.467372864484787 2022-05-29 15:25:46.987435
Epoch:[ 125 10 ] loss: 0.47073185443878174 2022-05-29 15:25:47.753561
Epoch:[ 125 11 ] loss: 0.4659980535507202 2022-05-29 15:25:48.520601
Epoch:[ 125 12 ] loss: 0.46902650594711304 2022-05-29 15:25:49.287982
Epoch:[ 125 13 ] loss: 0.4744872450828552 2022-05-29 15:25:50.053680
Epoch:[ 125 14 ] loss: 0.46933141350746155 2022-05-29 15:25:50.819366
Epoch:[ 125 15 ] loss: 0.4641781151294708 2022-05-29 15:25:51.586519
Epoch:[ 125 16 ] loss: 0.47032901644706726 2022-05-29 15:25:59.053930
Epoch:[ 125 17 ] loss: 0.4698002338409424 2022-05-29 15:26:00.216997
Epoch:[ 125 18 ] loss: 0.47247323393821716 2022-05-29 15:26:01.003807
Epoch:[ 125 19 ] loss: 0.4704315662384033 2022-05-29 15:26:01.767617
Training_Epoch:[ 125 ] Training_loss: 0.4693260669708252 2022-05-29 15:26:01.768348
learning rate:  6.920643600499994e-05
val: 1 0.5078597068786621
val: 2 0.5221432447433472
val: 3 0.5341743230819702
val: 4 0.519278347492218
val: 5 0.502575159072876
val: 6 0.5130355358123779
val: 7 0.5073804259300232
val: 8 0.5009473562240601
val: 9 0.511158287525177
val: 10 0.508911669254303
val: 11 0.5113435387611389
val: 12 0.5158829689025879
val: 13 0.5016319155693054
val: 14 0.5187325477600098
val: 15 0.5153231620788574
val: 16 0.5084121227264404
val: 17 0.5113829374313354
val: 18 0.5023629665374756
val: 19 0.5141890645027161
val: 20 0.5268034338951111
val_Epoch:[ 125 ] val_loss: 0.5126764357089997 2022-05-29 15:26:07.202847
start training 2022-05-29 15:26:07.304731
Epoch:[ 126 0 ] loss: 0.4692995846271515 2022-05-29 15:26:31.829793
Epoch:[ 126 1 ] loss: 0.47102174162864685 2022-05-29 15:26:32.638945
Epoch:[ 126 2 ] loss: 0.47148412466049194 2022-05-29 15:26:33.404883
Epoch:[ 126 3 ] loss: 0.46804821491241455 2022-05-29 15:26:34.171043
Epoch:[ 126 4 ] loss: 0.4746340215206146 2022-05-29 15:26:34.936502
Epoch:[ 126 5 ] loss: 0.46475762128829956 2022-05-29 15:26:35.703066
Epoch:[ 126 6 ] loss: 0.46774688363075256 2022-05-29 15:26:36.469695
Epoch:[ 126 7 ] loss: 0.4673944413661957 2022-05-29 15:26:37.234877
Epoch:[ 126 8 ] loss: 0.46834614872932434 2022-05-29 15:26:37.999916
Epoch:[ 126 9 ] loss: 0.46621906757354736 2022-05-29 15:26:38.763895
Epoch:[ 126 10 ] loss: 0.46844804286956787 2022-05-29 15:26:39.532567
Epoch:[ 126 11 ] loss: 0.4677720069885254 2022-05-29 15:26:40.310148
Epoch:[ 126 12 ] loss: 0.46814337372779846 2022-05-29 15:26:41.076247
Epoch:[ 126 13 ] loss: 0.4695713520050049 2022-05-29 15:26:41.852412
Epoch:[ 126 14 ] loss: 0.4696953594684601 2022-05-29 15:26:42.618845
Epoch:[ 126 15 ] loss: 0.46839532256126404 2022-05-29 15:26:43.384354
Epoch:[ 126 16 ] loss: 0.47049590945243835 2022-05-29 15:26:51.298052
Epoch:[ 126 17 ] loss: 0.47342026233673096 2022-05-29 15:26:52.060101
Epoch:[ 126 18 ] loss: 0.47141480445861816 2022-05-29 15:26:52.829568
Epoch:[ 126 19 ] loss: 0.46257156133651733 2022-05-29 15:26:53.593114
Training_Epoch:[ 126 ] Training_loss: 0.46894399225711825 2022-05-29 15:26:53.593904
learning rate:  6.920643600499994e-05
netparams have been saved once 126
val: 1 0.5306916236877441
val: 2 0.5304964780807495
val: 3 0.504340648651123
val: 4 0.5350105166435242
val: 5 0.5300715565681458
val: 6 0.4912106394767761
val: 7 0.5241398215293884
val: 8 0.49113649129867554
val: 9 0.5036052465438843
val: 10 0.5137378573417664
val: 11 0.5267353057861328
val: 12 0.49935999512672424
val: 13 0.5111110210418701
val: 14 0.5018527507781982
val: 15 0.511929988861084
val: 16 0.5064946413040161
val: 17 0.4976903796195984
val: 18 0.5103318691253662
val: 19 0.5273423194885254
val: 20 0.5072393417358398
val_Epoch:[ 126 ] val_loss: 0.5127264246344566 2022-05-29 15:26:59.221710
start training 2022-05-29 15:26:59.324277
Epoch:[ 127 0 ] loss: 0.46608635783195496 2022-05-29 15:27:25.189707
Epoch:[ 127 1 ] loss: 0.47035425901412964 2022-05-29 15:27:25.956417
Epoch:[ 127 2 ] loss: 0.46792563796043396 2022-05-29 15:27:26.721376
Epoch:[ 127 3 ] loss: 0.4703556299209595 2022-05-29 15:27:27.486271
Epoch:[ 127 4 ] loss: 0.4685682952404022 2022-05-29 15:27:28.249087
Epoch:[ 127 5 ] loss: 0.47092363238334656 2022-05-29 15:27:29.014375
Epoch:[ 127 6 ] loss: 0.47004324197769165 2022-05-29 15:27:29.781669
Epoch:[ 127 7 ] loss: 0.468657523393631 2022-05-29 15:27:30.545836
Epoch:[ 127 8 ] loss: 0.46922630071640015 2022-05-29 15:27:31.310393
Epoch:[ 127 9 ] loss: 0.4702269434928894 2022-05-29 15:27:32.075596
Epoch:[ 127 10 ] loss: 0.4645809233188629 2022-05-29 15:27:32.853539
Epoch:[ 127 11 ] loss: 0.46721240878105164 2022-05-29 15:27:33.619124
Epoch:[ 127 12 ] loss: 0.47228899598121643 2022-05-29 15:27:34.384520
Epoch:[ 127 13 ] loss: 0.46942126750946045 2022-05-29 15:27:35.163316
Epoch:[ 127 14 ] loss: 0.4685293436050415 2022-05-29 15:27:35.927866
Epoch:[ 127 15 ] loss: 0.4657195210456848 2022-05-29 15:27:36.693700
Epoch:[ 127 16 ] loss: 0.46305733919143677 2022-05-29 15:27:47.592036
Epoch:[ 127 17 ] loss: 0.46975037455558777 2022-05-29 15:27:48.357362
Epoch:[ 127 18 ] loss: 0.46998172998428345 2022-05-29 15:27:49.125841
Epoch:[ 127 19 ] loss: 0.47166746854782104 2022-05-29 15:27:49.891254
Training_Epoch:[ 127 ] Training_loss: 0.4687288597226143 2022-05-29 15:27:49.892068
learning rate:  6.920643600499994e-05
val: 1 0.49836936593055725
val: 2 0.5097041130065918
val: 3 0.5180467367172241
val: 4 0.5203680992126465
val: 5 0.5340691804885864
val: 6 0.5220600366592407
val: 7 0.518605649471283
val: 8 0.49501097202301025
val: 9 0.5079339742660522
val: 10 0.4906274080276489
val: 11 0.5251467227935791
val: 12 0.5083133578300476
val: 13 0.5169559121131897
val: 14 0.5199460387229919
val: 15 0.5228914618492126
val: 16 0.5196465253829956
val: 17 0.4959811270236969
val: 18 0.5071873068809509
val: 19 0.5124112963676453
val: 20 0.5056684613227844
val_Epoch:[ 127 ] val_loss: 0.5124471873044968 2022-05-29 15:27:55.356817
start training 2022-05-29 15:27:55.457659
Epoch:[ 128 0 ] loss: 0.46681448817253113 2022-05-29 15:28:21.452066
Epoch:[ 128 1 ] loss: 0.470766544342041 2022-05-29 15:28:22.219924
Epoch:[ 128 2 ] loss: 0.4713682234287262 2022-05-29 15:28:22.999822
Epoch:[ 128 3 ] loss: 0.4609602689743042 2022-05-29 15:28:23.766905
Epoch:[ 128 4 ] loss: 0.4700106680393219 2022-05-29 15:28:24.545656
Epoch:[ 128 5 ] loss: 0.4663578271865845 2022-05-29 15:28:25.313398
Epoch:[ 128 6 ] loss: 0.4652847945690155 2022-05-29 15:28:26.079479
Epoch:[ 128 7 ] loss: 0.4739967882633209 2022-05-29 15:28:26.845197
Epoch:[ 128 8 ] loss: 0.46781104803085327 2022-05-29 15:28:27.611002
Epoch:[ 128 9 ] loss: 0.4691602885723114 2022-05-29 15:28:28.376260
Epoch:[ 128 10 ] loss: 0.4679195284843445 2022-05-29 15:28:29.142809
Epoch:[ 128 11 ] loss: 0.4685932993888855 2022-05-29 15:28:29.908729
Epoch:[ 128 12 ] loss: 0.46862637996673584 2022-05-29 15:28:30.674260
Epoch:[ 128 13 ] loss: 0.46479010581970215 2022-05-29 15:28:31.440089
Epoch:[ 128 14 ] loss: 0.4694521725177765 2022-05-29 15:28:32.206385
Epoch:[ 128 15 ] loss: 0.47132015228271484 2022-05-29 15:28:32.971902
Epoch:[ 128 16 ] loss: 0.4726165533065796 2022-05-29 15:28:41.603494
Epoch:[ 128 17 ] loss: 0.46760860085487366 2022-05-29 15:28:43.248613
Epoch:[ 128 18 ] loss: 0.46928340196609497 2022-05-29 15:28:44.033258
Epoch:[ 128 19 ] loss: 0.4692860543727875 2022-05-29 15:28:44.798147
Training_Epoch:[ 128 ] Training_loss: 0.46860135942697523 2022-05-29 15:28:44.798926
learning rate:  6.920643600499994e-05
netparams have been saved once 128
val: 1 0.5003170967102051
val: 2 0.5215076208114624
val: 3 0.5059190392494202
val: 4 0.5253115892410278
val: 5 0.5171918272972107
val: 6 0.5084079504013062
val: 7 0.5017305016517639
val: 8 0.5121824741363525
val: 9 0.5102900862693787
val: 10 0.5198723077774048
val: 11 0.5212477445602417
val: 12 0.533233642578125
val: 13 0.5243438482284546
val: 14 0.5014058351516724
val: 15 0.48379403352737427
val: 16 0.5044332146644592
val: 17 0.5187992453575134
val: 18 0.5101044178009033
val: 19 0.510535717010498
val: 20 0.5217499732971191
val_Epoch:[ 128 ] val_loss: 0.5126189082860947 2022-05-29 15:28:50.379247
start training 2022-05-29 15:28:50.479170
