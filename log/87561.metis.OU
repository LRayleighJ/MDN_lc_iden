GPU: True
80
start training 2022-07-01 09:22:18.894045
Epoch:[ 1 0 ] loss: 0.4281252920627594 2022-07-01 09:22:41.322172
Epoch:[ 1 1 ] loss: 0.4456958472728729 2022-07-01 09:22:41.758894
Epoch:[ 1 2 ] loss: 0.4292543828487396 2022-07-01 09:22:42.169374
Epoch:[ 1 3 ] loss: 0.4290525019168854 2022-07-01 09:22:42.596445
Epoch:[ 1 4 ] loss: 0.4267796277999878 2022-07-01 09:22:43.015540
Epoch:[ 1 5 ] loss: 0.4289928674697876 2022-07-01 09:22:43.433451
Epoch:[ 1 6 ] loss: 0.42911210656166077 2022-07-01 09:22:43.854978
Epoch:[ 1 7 ] loss: 0.42873415350914 2022-07-01 09:22:44.277450
Epoch:[ 1 8 ] loss: 0.4246939420700073 2022-07-01 09:22:44.691490
Epoch:[ 1 9 ] loss: 0.4244360029697418 2022-07-01 09:22:45.119860
Epoch:[ 1 10 ] loss: 0.4233599305152893 2022-07-01 09:22:45.537506
Epoch:[ 1 11 ] loss: 0.42536255717277527 2022-07-01 09:22:45.994098
Epoch:[ 1 12 ] loss: 0.42592960596084595 2022-07-01 09:22:46.408343
Epoch:[ 1 13 ] loss: 0.42349973320961 2022-07-01 09:22:46.823118
Epoch:[ 1 14 ] loss: 0.4249311685562134 2022-07-01 09:22:47.236856
Epoch:[ 1 15 ] loss: 0.42379000782966614 2022-07-01 09:22:47.650617
Epoch:[ 1 16 ] loss: 0.42383888363838196 2022-07-01 09:22:48.062919
Epoch:[ 1 17 ] loss: 0.42445576190948486 2022-07-01 09:22:48.479407
Epoch:[ 1 18 ] loss: 0.42498311400413513 2022-07-01 09:22:48.899072
Epoch:[ 1 19 ] loss: 0.423028826713562 2022-07-01 09:22:49.313662
Training_Epoch:[ 1 ] Training_loss: 0.42690281569957733 2022-07-01 09:22:49.314363
learning rate:  0.001
val: 1 0.43298518657684326
val: 2 0.44530126452445984
val: 3 0.43711140751838684
val: 4 0.4470387399196625
val: 5 0.43865376710891724
val: 6 0.4452970623970032
val: 7 0.43526893854141235
val: 8 0.4291248619556427
val: 9 0.44524136185646057
val: 10 0.44526761770248413
val: 11 0.4475662112236023
val: 12 0.442358136177063
val: 13 0.43962183594703674
val: 14 0.44246602058410645
val: 15 0.4382683038711548
val: 16 0.43002259731292725
val: 17 0.43729886412620544
val: 18 0.4448722004890442
val: 19 0.445580393075943
val: 20 0.43958133459091187
val_Epoch:[ 1 ] val_loss: 0.44044630527496337 2022-07-01 09:22:52.955009
start training 2022-07-01 09:22:53.068595
Epoch:[ 2 0 ] loss: 0.4218655824661255 2022-07-01 09:23:07.007174
Epoch:[ 2 1 ] loss: 0.42183250188827515 2022-07-01 09:23:08.091591
Epoch:[ 2 2 ] loss: 0.4176184833049774 2022-07-01 09:23:08.506269
Epoch:[ 2 3 ] loss: 0.4234131872653961 2022-07-01 09:23:08.920831
Epoch:[ 2 4 ] loss: 0.4216967225074768 2022-07-01 09:23:09.334921
Epoch:[ 2 5 ] loss: 0.42051881551742554 2022-07-01 09:23:09.754329
Epoch:[ 2 6 ] loss: 0.42343538999557495 2022-07-01 09:23:10.177677
Epoch:[ 2 7 ] loss: 0.4203273355960846 2022-07-01 09:23:10.594776
Epoch:[ 2 8 ] loss: 0.41908544301986694 2022-07-01 09:23:11.010075
Epoch:[ 2 9 ] loss: 0.420947402715683 2022-07-01 09:23:11.423239
Epoch:[ 2 10 ] loss: 0.42090272903442383 2022-07-01 09:23:11.839256
Epoch:[ 2 11 ] loss: 0.42057308554649353 2022-07-01 09:23:12.254931
Epoch:[ 2 12 ] loss: 0.41897153854370117 2022-07-01 09:23:12.671289
Epoch:[ 2 13 ] loss: 0.4224776029586792 2022-07-01 09:23:13.088695
Epoch:[ 2 14 ] loss: 0.4206549823284149 2022-07-01 09:23:13.503655
Epoch:[ 2 15 ] loss: 0.41930100321769714 2022-07-01 09:23:13.927774
Epoch:[ 2 16 ] loss: 0.4221805930137634 2022-07-01 09:23:18.888180
Epoch:[ 2 17 ] loss: 0.4176463782787323 2022-07-01 09:23:19.859645
Epoch:[ 2 18 ] loss: 0.42160457372665405 2022-07-01 09:23:20.273848
Epoch:[ 2 19 ] loss: 0.42164376378059387 2022-07-01 09:23:20.688904
Training_Epoch:[ 2 ] Training_loss: 0.420834855735302 2022-07-01 09:23:20.689861
learning rate:  0.001
netparams have been saved once 2
val: 1 0.4327925145626068
val: 2 0.4381328821182251
val: 3 0.4366087019443512
val: 4 0.4475150406360626
val: 5 0.4392521381378174
val: 6 0.44939666986465454
val: 7 0.44216060638427734
val: 8 0.4417712986469269
val: 9 0.4489256739616394
val: 10 0.45643389225006104
val: 11 0.4460062086582184
val: 12 0.45079323649406433
val: 13 0.43343472480773926
val: 14 0.4414086639881134
val: 15 0.44534432888031006
val: 16 0.4565580487251282
val: 17 0.4560335874557495
val: 18 0.4502807557582855
val: 19 0.4396232068538666
val: 20 0.4368797540664673
val_Epoch:[ 2 ] val_loss: 0.44446759670972824 2022-07-01 09:23:24.655946
start training 2022-07-01 09:23:24.755415
Epoch:[ 3 0 ] loss: 0.4172437787055969 2022-07-01 09:23:40.180854
Epoch:[ 3 1 ] loss: 0.41835817694664 2022-07-01 09:23:40.596614
Epoch:[ 3 2 ] loss: 0.4216517210006714 2022-07-01 09:23:41.016957
Epoch:[ 3 3 ] loss: 0.41736871004104614 2022-07-01 09:23:41.431701
Epoch:[ 3 4 ] loss: 0.42024415731430054 2022-07-01 09:23:41.846297
Epoch:[ 3 5 ] loss: 0.42266809940338135 2022-07-01 09:23:42.257152
Epoch:[ 3 6 ] loss: 0.4187406897544861 2022-07-01 09:23:42.676251
Epoch:[ 3 7 ] loss: 0.42280271649360657 2022-07-01 09:23:43.092581
Epoch:[ 3 8 ] loss: 0.41717228293418884 2022-07-01 09:23:43.512867
Epoch:[ 3 9 ] loss: 0.4173170030117035 2022-07-01 09:23:43.929586
Epoch:[ 3 10 ] loss: 0.4213517904281616 2022-07-01 09:23:44.347836
Epoch:[ 3 11 ] loss: 0.41876330971717834 2022-07-01 09:23:44.759201
Epoch:[ 3 12 ] loss: 0.41883498430252075 2022-07-01 09:23:45.168609
Epoch:[ 3 13 ] loss: 0.4198385775089264 2022-07-01 09:23:45.583362
Epoch:[ 3 14 ] loss: 0.4190466105937958 2022-07-01 09:23:45.998580
Epoch:[ 3 15 ] loss: 0.41803863644599915 2022-07-01 09:23:46.421313
Epoch:[ 3 16 ] loss: 0.42028990387916565 2022-07-01 09:23:51.728929
Epoch:[ 3 17 ] loss: 0.41684359312057495 2022-07-01 09:23:52.136106
Epoch:[ 3 18 ] loss: 0.42458444833755493 2022-07-01 09:23:52.553971
Epoch:[ 3 19 ] loss: 0.4201714098453522 2022-07-01 09:23:52.969788
Training_Epoch:[ 3 ] Training_loss: 0.41956652998924254 2022-07-01 09:23:52.970601
learning rate:  0.001
val: 1 0.43063703179359436
val: 2 0.43441060185432434
val: 3 0.4426840841770172
val: 4 0.441257506608963
val: 5 0.4429214894771576
val: 6 0.43669962882995605
val: 7 0.4433109164237976
val: 8 0.44535520672798157
val: 9 0.43888169527053833
val: 10 0.4363126754760742
val: 11 0.441299706697464
val: 12 0.4402565360069275
val: 13 0.44430971145629883
val: 14 0.44736433029174805
val: 15 0.43745729327201843
val: 16 0.44503700733184814
val: 17 0.44155043363571167
val: 18 0.4303484261035919
val: 19 0.4452694356441498
val: 20 0.4405379295349121
val_Epoch:[ 3 ] val_loss: 0.44029508233070375 2022-07-01 09:23:56.892556
start training 2022-07-01 09:23:56.995473
Epoch:[ 4 0 ] loss: 0.4193296730518341 2022-07-01 09:24:11.799171
Epoch:[ 4 1 ] loss: 0.4196055233478546 2022-07-01 09:24:12.241469
Epoch:[ 4 2 ] loss: 0.41534340381622314 2022-07-01 09:24:12.659213
Epoch:[ 4 3 ] loss: 0.41794106364250183 2022-07-01 09:24:13.073779
Epoch:[ 4 4 ] loss: 0.41894111037254333 2022-07-01 09:24:13.488889
Epoch:[ 4 5 ] loss: 0.4209727942943573 2022-07-01 09:24:13.905388
Epoch:[ 4 6 ] loss: 0.4212420880794525 2022-07-01 09:24:14.323050
Epoch:[ 4 7 ] loss: 0.42120489478111267 2022-07-01 09:24:14.739756
Epoch:[ 4 8 ] loss: 0.41748538613319397 2022-07-01 09:24:15.149779
Epoch:[ 4 9 ] loss: 0.42193248867988586 2022-07-01 09:24:15.570327
Epoch:[ 4 10 ] loss: 0.4195758104324341 2022-07-01 09:24:15.978266
Epoch:[ 4 11 ] loss: 0.41769900918006897 2022-07-01 09:24:16.399359
Epoch:[ 4 12 ] loss: 0.4188019931316376 2022-07-01 09:24:16.814222
Epoch:[ 4 13 ] loss: 0.41925421357154846 2022-07-01 09:24:17.228179
Epoch:[ 4 14 ] loss: 0.41889145970344543 2022-07-01 09:24:17.647045
Epoch:[ 4 15 ] loss: 0.41702380776405334 2022-07-01 09:24:18.062830
Epoch:[ 4 16 ] loss: 0.418647825717926 2022-07-01 09:24:23.729705
Epoch:[ 4 17 ] loss: 0.4174858629703522 2022-07-01 09:24:24.145931
Epoch:[ 4 18 ] loss: 0.41838088631629944 2022-07-01 09:24:24.556817
Epoch:[ 4 19 ] loss: 0.4187591075897217 2022-07-01 09:24:24.970655
Training_Epoch:[ 4 ] Training_loss: 0.41892592012882235 2022-07-01 09:24:24.971281
learning rate:  0.001
netparams have been saved once 4
val: 1 0.43870970606803894
val: 2 0.43793559074401855
val: 3 0.4302609860897064
val: 4 0.43061575293540955
val: 5 0.43727603554725647
val: 6 0.4397917091846466
val: 7 0.4488476514816284
val: 8 0.43398770689964294
val: 9 0.44106802344322205
val: 10 0.4457135498523712
val: 11 0.4330751895904541
val: 12 0.44204843044281006
val: 13 0.4444693922996521
val: 14 0.4464356005191803
val: 15 0.4572737216949463
val: 16 0.4357096254825592
val: 17 0.44364774227142334
val: 18 0.4393402338027954
val: 19 0.437960147857666
val: 20 0.44400331377983093
val_Epoch:[ 4 ] val_loss: 0.44040850549936295 2022-07-01 09:24:28.941008
start training 2022-07-01 09:24:29.039040
Epoch:[ 5 0 ] loss: 0.418516606092453 2022-07-01 09:24:43.245686
Epoch:[ 5 1 ] loss: 0.41877132654190063 2022-07-01 09:24:43.920319
Epoch:[ 5 2 ] loss: 0.41692209243774414 2022-07-01 09:24:44.335528
Epoch:[ 5 3 ] loss: 0.420873761177063 2022-07-01 09:24:44.744274
Epoch:[ 5 4 ] loss: 0.41402363777160645 2022-07-01 09:24:45.158321
Epoch:[ 5 5 ] loss: 0.415399432182312 2022-07-01 09:24:45.576197
Epoch:[ 5 6 ] loss: 0.41731470823287964 2022-07-01 09:24:45.990799
Epoch:[ 5 7 ] loss: 0.41905105113983154 2022-07-01 09:24:46.406602
Epoch:[ 5 8 ] loss: 0.4169781804084778 2022-07-01 09:24:46.821627
Epoch:[ 5 9 ] loss: 0.4177096486091614 2022-07-01 09:24:47.233700
Epoch:[ 5 10 ] loss: 0.4214983284473419 2022-07-01 09:24:47.651731
Epoch:[ 5 11 ] loss: 0.4207562506198883 2022-07-01 09:24:48.072142
Epoch:[ 5 12 ] loss: 0.42169129848480225 2022-07-01 09:24:48.485164
Epoch:[ 5 13 ] loss: 0.41983142495155334 2022-07-01 09:24:48.903851
Epoch:[ 5 14 ] loss: 0.42110031843185425 2022-07-01 09:24:49.316289
Epoch:[ 5 15 ] loss: 0.41773879528045654 2022-07-01 09:24:49.730926
Epoch:[ 5 16 ] loss: 0.41947832703590393 2022-07-01 09:24:55.107573
Epoch:[ 5 17 ] loss: 0.4199742376804352 2022-07-01 09:24:55.522235
Epoch:[ 5 18 ] loss: 0.419021338224411 2022-07-01 09:24:55.947383
Epoch:[ 5 19 ] loss: 0.4159378707408905 2022-07-01 09:24:56.361963
Training_Epoch:[ 5 ] Training_loss: 0.41862943172454836 2022-07-01 09:24:56.362779
learning rate:  0.001
val: 1 0.4385910928249359
val: 2 0.4390660524368286
val: 3 0.4269232451915741
val: 4 0.4386198818683624
val: 5 0.44489333033561707
val: 6 0.43730658292770386
val: 7 0.44460204243659973
val: 8 0.4372303783893585
val: 9 0.4438159465789795
val: 10 0.4442799389362335
val: 11 0.4494606852531433
val: 12 0.43532800674438477
val: 13 0.4454299807548523
val: 14 0.44080138206481934
val: 15 0.4374169409275055
val: 16 0.44017332792282104
val: 17 0.44663363695144653
val: 18 0.42915651202201843
val: 19 0.43470698595046997
val: 20 0.4445000886917114
val_Epoch:[ 5 ] val_loss: 0.4399468019604683 2022-07-01 09:25:00.211000
start training 2022-07-01 09:25:00.315525
Epoch:[ 6 0 ] loss: 0.4208931624889374 2022-07-01 09:25:14.946827
Epoch:[ 6 1 ] loss: 0.41714534163475037 2022-07-01 09:25:15.383371
Epoch:[ 6 2 ] loss: 0.4185340702533722 2022-07-01 09:25:15.796883
Epoch:[ 6 3 ] loss: 0.42105168104171753 2022-07-01 09:25:16.216241
Epoch:[ 6 4 ] loss: 0.4174754321575165 2022-07-01 09:25:16.636035
Epoch:[ 6 5 ] loss: 0.4147004783153534 2022-07-01 09:25:17.048583
Epoch:[ 6 6 ] loss: 0.4242887496948242 2022-07-01 09:25:17.462737
Epoch:[ 6 7 ] loss: 0.42006880044937134 2022-07-01 09:25:17.877444
Epoch:[ 6 8 ] loss: 0.418169230222702 2022-07-01 09:25:18.297352
Epoch:[ 6 9 ] loss: 0.4166041612625122 2022-07-01 09:25:18.711969
Epoch:[ 6 10 ] loss: 0.41757476329803467 2022-07-01 09:25:19.127189
Epoch:[ 6 11 ] loss: 0.4194030165672302 2022-07-01 09:25:19.544227
Epoch:[ 6 12 ] loss: 0.4175187647342682 2022-07-01 09:25:19.958051
Epoch:[ 6 13 ] loss: 0.41537076234817505 2022-07-01 09:25:20.371829
Epoch:[ 6 14 ] loss: 0.41703811287879944 2022-07-01 09:25:20.785608
Epoch:[ 6 15 ] loss: 0.41844531893730164 2022-07-01 09:25:21.200453
Epoch:[ 6 16 ] loss: 0.42017072439193726 2022-07-01 09:25:26.474440
Epoch:[ 6 17 ] loss: 0.41819465160369873 2022-07-01 09:25:26.905221
Epoch:[ 6 18 ] loss: 0.4157249331474304 2022-07-01 09:25:27.334056
Epoch:[ 6 19 ] loss: 0.4157683253288269 2022-07-01 09:25:27.749506
Training_Epoch:[ 6 ] Training_loss: 0.418207024037838 2022-07-01 09:25:27.750387
learning rate:  0.001
netparams have been saved once 6
val: 1 0.4407784342765808
val: 2 0.4399864375591278
val: 3 0.4442317485809326
val: 4 0.44345560669898987
val: 5 0.44269508123397827
val: 6 0.432131290435791
val: 7 0.4452713429927826
val: 8 0.4397100806236267
val: 9 0.44764381647109985
val: 10 0.4393507242202759
val: 11 0.43905577063560486
val: 12 0.44584929943084717
val: 13 0.4328515827655792
val: 14 0.43879422545433044
val: 15 0.4395724833011627
val: 16 0.4388265311717987
val: 17 0.43635210394859314
val: 18 0.4313563108444214
val: 19 0.4539887607097626
val: 20 0.4352971315383911
val_Epoch:[ 6 ] val_loss: 0.4403599381446838 2022-07-01 09:25:31.466530
start training 2022-07-01 09:25:31.566216
Epoch:[ 7 0 ] loss: 0.41752421855926514 2022-07-01 09:25:46.569136
Epoch:[ 7 1 ] loss: 0.41797900199890137 2022-07-01 09:25:46.983744
Epoch:[ 7 2 ] loss: 0.4206906855106354 2022-07-01 09:25:47.400133
Epoch:[ 7 3 ] loss: 0.41489744186401367 2022-07-01 09:25:47.813968
Epoch:[ 7 4 ] loss: 0.41852477192878723 2022-07-01 09:25:48.229329
Epoch:[ 7 5 ] loss: 0.4169979989528656 2022-07-01 09:25:48.639853
Epoch:[ 7 6 ] loss: 0.41955065727233887 2022-07-01 09:25:49.055132
Epoch:[ 7 7 ] loss: 0.41762006282806396 2022-07-01 09:25:49.469958
Epoch:[ 7 8 ] loss: 0.4180713891983032 2022-07-01 09:25:49.884738
Epoch:[ 7 9 ] loss: 0.4175534248352051 2022-07-01 09:25:50.295464
Epoch:[ 7 10 ] loss: 0.41703757643699646 2022-07-01 09:25:50.707935
Epoch:[ 7 11 ] loss: 0.4170084297657013 2022-07-01 09:25:51.122519
Epoch:[ 7 12 ] loss: 0.41764718294143677 2022-07-01 09:25:51.539169
Epoch:[ 7 13 ] loss: 0.4147104322910309 2022-07-01 09:25:51.960167
Epoch:[ 7 14 ] loss: 0.41663849353790283 2022-07-01 09:25:52.372770
Epoch:[ 7 15 ] loss: 0.4161980450153351 2022-07-01 09:25:52.794064
Epoch:[ 7 16 ] loss: 0.41412249207496643 2022-07-01 09:25:58.532296
Epoch:[ 7 17 ] loss: 0.4161166548728943 2022-07-01 09:25:58.937713
Epoch:[ 7 18 ] loss: 0.4163356125354767 2022-07-01 09:25:59.354547
Epoch:[ 7 19 ] loss: 0.41537076234817505 2022-07-01 09:25:59.769943
Training_Epoch:[ 7 ] Training_loss: 0.41702976673841474 2022-07-01 09:25:59.770717
learning rate:  0.001
val: 1 0.43686312437057495
val: 2 0.4472639560699463
val: 3 0.42800724506378174
val: 4 0.4381694793701172
val: 5 0.4414948523044586
val: 6 0.44349896907806396
val: 7 0.453252911567688
val: 8 0.43996864557266235
val: 9 0.44328874349594116
val: 10 0.4352075755596161
val: 11 0.44414442777633667
val: 12 0.4492930769920349
val: 13 0.4483875632286072
val: 14 0.43319809436798096
val: 15 0.44374221563339233
val: 16 0.44401630759239197
val: 17 0.4428233802318573
val: 18 0.45235198736190796
val: 19 0.4378281533718109
val: 20 0.43724796175956726
val_Epoch:[ 7 ] val_loss: 0.4420024335384369 2022-07-01 09:26:03.620150
start training 2022-07-01 09:26:03.718882
Epoch:[ 8 0 ] loss: 0.4136310815811157 2022-07-01 09:26:18.163636
Epoch:[ 8 1 ] loss: 0.41785821318626404 2022-07-01 09:26:18.606027
Epoch:[ 8 2 ] loss: 0.41730645298957825 2022-07-01 09:26:19.043794
Epoch:[ 8 3 ] loss: 0.4153778851032257 2022-07-01 09:26:19.457524
Epoch:[ 8 4 ] loss: 0.41753333806991577 2022-07-01 09:26:19.870677
Epoch:[ 8 5 ] loss: 0.41594815254211426 2022-07-01 09:26:20.285837
Epoch:[ 8 6 ] loss: 0.4143313765525818 2022-07-01 09:26:20.699688
Epoch:[ 8 7 ] loss: 0.41659823060035706 2022-07-01 09:26:21.117707
Epoch:[ 8 8 ] loss: 0.41365107893943787 2022-07-01 09:26:21.534847
Epoch:[ 8 9 ] loss: 0.4144814610481262 2022-07-01 09:26:21.953477
Epoch:[ 8 10 ] loss: 0.4167420566082001 2022-07-01 09:26:22.366490
Epoch:[ 8 11 ] loss: 0.4179486334323883 2022-07-01 09:26:22.779978
Epoch:[ 8 12 ] loss: 0.42148780822753906 2022-07-01 09:26:23.193863
Epoch:[ 8 13 ] loss: 0.4173697531223297 2022-07-01 09:26:23.615239
Epoch:[ 8 14 ] loss: 0.41471800208091736 2022-07-01 09:26:24.030692
Epoch:[ 8 15 ] loss: 0.41744279861450195 2022-07-01 09:26:24.447180
Epoch:[ 8 16 ] loss: 0.4165147542953491 2022-07-01 09:26:30.052771
Epoch:[ 8 17 ] loss: 0.41348889470100403 2022-07-01 09:26:30.466339
Epoch:[ 8 18 ] loss: 0.4172501862049103 2022-07-01 09:26:30.874696
Epoch:[ 8 19 ] loss: 0.4171881377696991 2022-07-01 09:26:31.289000
Training_Epoch:[ 8 ] Training_loss: 0.4163434147834778 2022-07-01 09:26:31.289779
learning rate:  0.001
netparams have been saved once 8
val: 1 0.4346049427986145
val: 2 0.43001261353492737
val: 3 0.4381672441959381
val: 4 0.4332736134529114
val: 5 0.4404234290122986
val: 6 0.43648800253868103
val: 7 0.44778600335121155
val: 8 0.44096502661705017
val: 9 0.43597081303596497
val: 10 0.4445614814758301
val: 11 0.43885719776153564
val: 12 0.44777822494506836
val: 13 0.4469064772129059
val: 14 0.448124498128891
val: 15 0.436568945646286
val: 16 0.44633564352989197
val: 17 0.4419001340866089
val: 18 0.44042935967445374
val: 19 0.44092831015586853
val: 20 0.4389550983905792
val_Epoch:[ 8 ] val_loss: 0.44045185297727585 2022-07-01 09:26:35.254322
start training 2022-07-01 09:26:35.355959
Epoch:[ 9 0 ] loss: 0.42065486311912537 2022-07-01 09:26:49.588300
Epoch:[ 9 1 ] loss: 0.41718536615371704 2022-07-01 09:26:50.058595
Epoch:[ 9 2 ] loss: 0.41555631160736084 2022-07-01 09:26:50.479834
Epoch:[ 9 3 ] loss: 0.41343340277671814 2022-07-01 09:26:50.894530
Epoch:[ 9 4 ] loss: 0.41333937644958496 2022-07-01 09:26:51.308953
Epoch:[ 9 5 ] loss: 0.41797032952308655 2022-07-01 09:26:51.722851
Epoch:[ 9 6 ] loss: 0.4147338271141052 2022-07-01 09:26:52.139097
Epoch:[ 9 7 ] loss: 0.4130236804485321 2022-07-01 09:26:52.557616
Epoch:[ 9 8 ] loss: 0.41643640398979187 2022-07-01 09:26:52.966254
Epoch:[ 9 9 ] loss: 0.416083425283432 2022-07-01 09:26:53.380436
Epoch:[ 9 10 ] loss: 0.41491779685020447 2022-07-01 09:26:53.795794
Epoch:[ 9 11 ] loss: 0.4143625795841217 2022-07-01 09:26:54.209525
Epoch:[ 9 12 ] loss: 0.4171512722969055 2022-07-01 09:26:54.619781
Epoch:[ 9 13 ] loss: 0.42172732949256897 2022-07-01 09:26:55.038123
Epoch:[ 9 14 ] loss: 0.4174547493457794 2022-07-01 09:26:55.454547
Epoch:[ 9 15 ] loss: 0.4193389415740967 2022-07-01 09:26:55.871166
Epoch:[ 9 16 ] loss: 0.4157538414001465 2022-07-01 09:27:01.104144
Epoch:[ 9 17 ] loss: 0.4158901572227478 2022-07-01 09:27:01.518050
Epoch:[ 9 18 ] loss: 0.4162788391113281 2022-07-01 09:27:02.086895
Epoch:[ 9 19 ] loss: 0.41819071769714355 2022-07-01 09:27:02.493838
Training_Epoch:[ 9 ] Training_loss: 0.41647416055202485 2022-07-01 09:27:02.494484
learning rate:  0.001
val: 1 0.4395093321800232
val: 2 0.43982774019241333
val: 3 0.4435237944126129
val: 4 0.44101861119270325
val: 5 0.4409872591495514
val: 6 0.44510307908058167
val: 7 0.4413178265094757
val: 8 0.4570430815219879
val: 9 0.4367738962173462
val: 10 0.4469558894634247
val: 11 0.4528178572654724
val: 12 0.43850597739219666
val: 13 0.45017799735069275
val: 14 0.44468051195144653
val: 15 0.4403705596923828
val: 16 0.4592408239841461
val: 17 0.43612003326416016
val: 18 0.44840890169143677
val: 19 0.43696603178977966
val: 20 0.4515635073184967
val_Epoch:[ 9 ] val_loss: 0.44454563558101656 2022-07-01 09:27:06.289208
start training 2022-07-01 09:27:06.394320
Epoch:[ 10 0 ] loss: 0.4171083867549896 2022-07-01 09:27:21.139863
Epoch:[ 10 1 ] loss: 0.4157881736755371 2022-07-01 09:27:21.549406
Epoch:[ 10 2 ] loss: 0.4152538478374481 2022-07-01 09:27:21.969789
Epoch:[ 10 3 ] loss: 0.41630467772483826 2022-07-01 09:27:22.383789
Epoch:[ 10 4 ] loss: 0.41638049483299255 2022-07-01 09:27:22.798772
Epoch:[ 10 5 ] loss: 0.4157702326774597 2022-07-01 09:27:23.212947
Epoch:[ 10 6 ] loss: 0.4158017933368683 2022-07-01 09:27:23.626511
Epoch:[ 10 7 ] loss: 0.415763258934021 2022-07-01 09:27:24.043878
Epoch:[ 10 8 ] loss: 0.4160520136356354 2022-07-01 09:27:24.465750
Epoch:[ 10 9 ] loss: 0.4173823595046997 2022-07-01 09:27:24.873758
Epoch:[ 10 10 ] loss: 0.4162754416465759 2022-07-01 09:27:25.291845
Epoch:[ 10 11 ] loss: 0.4160067141056061 2022-07-01 09:27:25.710718
Epoch:[ 10 12 ] loss: 0.4191644787788391 2022-07-01 09:27:26.118034
Epoch:[ 10 13 ] loss: 0.4160170257091522 2022-07-01 09:27:26.531311
Epoch:[ 10 14 ] loss: 0.4162623882293701 2022-07-01 09:27:26.945777
Epoch:[ 10 15 ] loss: 0.4171900451183319 2022-07-01 09:27:27.358333
Epoch:[ 10 16 ] loss: 0.4161670506000519 2022-07-01 09:27:32.631978
Epoch:[ 10 17 ] loss: 0.4180169105529785 2022-07-01 09:27:33.200720
Epoch:[ 10 18 ] loss: 0.4149361252784729 2022-07-01 09:27:33.614613
Epoch:[ 10 19 ] loss: 0.41316667199134827 2022-07-01 09:27:34.028759
Training_Epoch:[ 10 ] Training_loss: 0.4162404045462608 2022-07-01 09:27:34.029436
learning rate:  0.001
netparams have been saved once 10
val: 1 0.44739997386932373
val: 2 0.4308820962905884
val: 3 0.4501649737358093
val: 4 0.44118502736091614
val: 5 0.44868147373199463
val: 6 0.43615880608558655
val: 7 0.4430791437625885
val: 8 0.44115546345710754
val: 9 0.4493856728076935
val: 10 0.44284170866012573
val: 11 0.4366738796234131
val: 12 0.4373425543308258
val: 13 0.43801847100257874
val: 14 0.43942463397979736
val: 15 0.43152642250061035
val: 16 0.44592440128326416
val: 17 0.4349886178970337
val: 18 0.4412608742713928
val: 19 0.43443742394447327
val: 20 0.44684484601020813
val_Epoch:[ 10 ] val_loss: 0.44086882323026655 2022-07-01 09:27:37.860150
start training 2022-07-01 09:27:37.959401
Epoch:[ 11 0 ] loss: 0.41413116455078125 2022-07-01 09:27:52.439729
Epoch:[ 11 1 ] loss: 0.41094425320625305 2022-07-01 09:27:52.881610
Epoch:[ 11 2 ] loss: 0.4155004918575287 2022-07-01 09:27:53.298219
Epoch:[ 11 3 ] loss: 0.41532859206199646 2022-07-01 09:27:53.714354
Epoch:[ 11 4 ] loss: 0.41346803307533264 2022-07-01 09:27:54.129406
Epoch:[ 11 5 ] loss: 0.41741040349006653 2022-07-01 09:27:54.542052
Epoch:[ 11 6 ] loss: 0.4157870411872864 2022-07-01 09:27:54.957932
Epoch:[ 11 7 ] loss: 0.4136608839035034 2022-07-01 09:27:55.371120
Epoch:[ 11 8 ] loss: 0.41623204946517944 2022-07-01 09:27:55.786884
Epoch:[ 11 9 ] loss: 0.41412535309791565 2022-07-01 09:27:56.201569
Epoch:[ 11 10 ] loss: 0.415577232837677 2022-07-01 09:27:56.609747
Epoch:[ 11 11 ] loss: 0.416806161403656 2022-07-01 09:27:57.027457
Epoch:[ 11 12 ] loss: 0.4159967005252838 2022-07-01 09:27:57.445495
Epoch:[ 11 13 ] loss: 0.41599124670028687 2022-07-01 09:27:57.859086
Epoch:[ 11 14 ] loss: 0.4149770140647888 2022-07-01 09:27:58.276397
Epoch:[ 11 15 ] loss: 0.41472291946411133 2022-07-01 09:27:58.685482
Epoch:[ 11 16 ] loss: 0.413765549659729 2022-07-01 09:28:04.376938
Epoch:[ 11 17 ] loss: 0.41239506006240845 2022-07-01 09:28:04.795394
Epoch:[ 11 18 ] loss: 0.41225188970565796 2022-07-01 09:28:05.211183
Epoch:[ 11 19 ] loss: 0.4156224727630615 2022-07-01 09:28:05.619346
Training_Epoch:[ 11 ] Training_loss: 0.4147347256541252 2022-07-01 09:28:05.620036
learning rate:  0.0008
val: 1 0.4450511038303375
val: 2 0.435326486825943
val: 3 0.44122248888015747
val: 4 0.4459930956363678
val: 5 0.44499683380126953
val: 6 0.4411928355693817
val: 7 0.45070308446884155
val: 8 0.4533507823944092
val: 9 0.4461382329463959
val: 10 0.44931840896606445
val: 11 0.4466129243373871
val: 12 0.4256298243999481
val: 13 0.4524124264717102
val: 14 0.4439813792705536
val: 15 0.43365365266799927
val: 16 0.44443002343177795
val: 17 0.44010159373283386
val: 18 0.4518430233001709
val: 19 0.4343583583831787
val: 20 0.44117555022239685
val_Epoch:[ 11 ] val_loss: 0.44337460547685625 2022-07-01 09:28:09.380259
start training 2022-07-01 09:28:09.478834
Epoch:[ 12 0 ] loss: 0.41176366806030273 2022-07-01 09:28:24.659634
Epoch:[ 12 1 ] loss: 0.4141644239425659 2022-07-01 09:28:25.074707
Epoch:[ 12 2 ] loss: 0.4139207899570465 2022-07-01 09:28:25.491263
Epoch:[ 12 3 ] loss: 0.41334623098373413 2022-07-01 09:28:25.902178
Epoch:[ 12 4 ] loss: 0.4127957224845886 2022-07-01 09:28:26.319328
Epoch:[ 12 5 ] loss: 0.4139527380466461 2022-07-01 09:28:26.737467
Epoch:[ 12 6 ] loss: 0.41724395751953125 2022-07-01 09:28:27.152191
Epoch:[ 12 7 ] loss: 0.4147590100765228 2022-07-01 09:28:27.570098
Epoch:[ 12 8 ] loss: 0.41402050852775574 2022-07-01 09:28:27.983170
Epoch:[ 12 9 ] loss: 0.4163263142108917 2022-07-01 09:28:28.391565
Epoch:[ 12 10 ] loss: 0.41480836272239685 2022-07-01 09:28:28.810951
Epoch:[ 12 11 ] loss: 0.4151371121406555 2022-07-01 09:28:29.224288
Epoch:[ 12 12 ] loss: 0.41312387585639954 2022-07-01 09:28:29.637150
Epoch:[ 12 13 ] loss: 0.41327574849128723 2022-07-01 09:28:30.049818
Epoch:[ 12 14 ] loss: 0.41461071372032166 2022-07-01 09:28:30.462405
Epoch:[ 12 15 ] loss: 0.4162807762622833 2022-07-01 09:28:30.882743
Epoch:[ 12 16 ] loss: 0.414754182100296 2022-07-01 09:28:36.067027
Epoch:[ 12 17 ] loss: 0.4147661030292511 2022-07-01 09:28:36.481546
Epoch:[ 12 18 ] loss: 0.41433480381965637 2022-07-01 09:28:36.906091
Epoch:[ 12 19 ] loss: 0.4140418767929077 2022-07-01 09:28:37.344336
Training_Epoch:[ 12 ] Training_loss: 0.41437134593725206 2022-07-01 09:28:37.345171
learning rate:  0.0008
netparams have been saved once 12
val: 1 0.4388865530490875
val: 2 0.43467411398887634
val: 3 0.44293662905693054
val: 4 0.45110464096069336
val: 5 0.43546736240386963
val: 6 0.44521623849868774
val: 7 0.4402979910373688
val: 8 0.44056063890457153
val: 9 0.4295383095741272
val: 10 0.437682181596756
val: 11 0.4360104203224182
val: 12 0.4349750280380249
val: 13 0.4459494948387146
val: 14 0.44633787870407104
val: 15 0.44347232580184937
val: 16 0.4321436583995819
val: 17 0.44906991720199585
val: 18 0.44005483388900757
val: 19 0.437955379486084
val: 20 0.44888725876808167
val_Epoch:[ 12 ] val_loss: 0.4405610427260399 2022-07-01 09:28:41.054882
start training 2022-07-01 09:28:41.158412
Epoch:[ 13 0 ] loss: 0.410029798746109 2022-07-01 09:28:55.752494
Epoch:[ 13 1 ] loss: 0.41576650738716125 2022-07-01 09:28:56.170295
Epoch:[ 13 2 ] loss: 0.412224143743515 2022-07-01 09:28:56.584280
Epoch:[ 13 3 ] loss: 0.4126787483692169 2022-07-01 09:28:56.998705
Epoch:[ 13 4 ] loss: 0.4150497317314148 2022-07-01 09:28:57.419157
Epoch:[ 13 5 ] loss: 0.4141993224620819 2022-07-01 09:28:57.828270
Epoch:[ 13 6 ] loss: 0.4137475788593292 2022-07-01 09:28:58.249660
Epoch:[ 13 7 ] loss: 0.41384029388427734 2022-07-01 09:28:58.664847
Epoch:[ 13 8 ] loss: 0.41370752453804016 2022-07-01 09:28:59.078795
Epoch:[ 13 9 ] loss: 0.41461092233657837 2022-07-01 09:28:59.493479
Epoch:[ 13 10 ] loss: 0.4147073030471802 2022-07-01 09:28:59.907954
Epoch:[ 13 11 ] loss: 0.4130515158176422 2022-07-01 09:29:00.325429
Epoch:[ 13 12 ] loss: 0.4144649803638458 2022-07-01 09:29:00.744305
Epoch:[ 13 13 ] loss: 0.41244742274284363 2022-07-01 09:29:01.160861
Epoch:[ 13 14 ] loss: 0.41239461302757263 2022-07-01 09:29:01.581379
Epoch:[ 13 15 ] loss: 0.4135521650314331 2022-07-01 09:29:01.994289
Epoch:[ 13 16 ] loss: 0.412283718585968 2022-07-01 09:29:07.005443
Epoch:[ 13 17 ] loss: 0.4145340025424957 2022-07-01 09:29:07.419216
Epoch:[ 13 18 ] loss: 0.4119488596916199 2022-07-01 09:29:07.835419
Epoch:[ 13 19 ] loss: 0.41414278745651245 2022-07-01 09:29:08.244397
Training_Epoch:[ 13 ] Training_loss: 0.41346909701824186 2022-07-01 09:29:08.245217
learning rate:  0.0008
val: 1 0.44040554761886597
val: 2 0.44359320402145386
val: 3 0.4431477189064026
val: 4 0.44130396842956543
val: 5 0.43031376600265503
val: 6 0.4392114281654358
val: 7 0.44209808111190796
val: 8 0.45047858357429504
val: 9 0.42994973063468933
val: 10 0.4451248049736023
val: 11 0.43571218848228455
val: 12 0.4528493583202362
val: 13 0.4431902766227722
val: 14 0.4401967227458954
val: 15 0.4429471790790558
val: 16 0.43806421756744385
val: 17 0.4299916625022888
val: 18 0.4540453851222992
val: 19 0.43934309482574463
val: 20 0.4393679201602936
val_Epoch:[ 13 ] val_loss: 0.4410667419433594 2022-07-01 09:29:12.046990
start training 2022-07-01 09:29:12.145174
Epoch:[ 14 0 ] loss: 0.4090364873409271 2022-07-01 09:29:26.637239
Epoch:[ 14 1 ] loss: 0.4150863587856293 2022-07-01 09:29:27.241055
Epoch:[ 14 2 ] loss: 0.41162121295928955 2022-07-01 09:29:27.654558
Epoch:[ 14 3 ] loss: 0.41248390078544617 2022-07-01 09:29:28.067149
Epoch:[ 14 4 ] loss: 0.41381052136421204 2022-07-01 09:29:28.483420
Epoch:[ 14 5 ] loss: 0.4130081534385681 2022-07-01 09:29:28.898297
Epoch:[ 14 6 ] loss: 0.4139854311943054 2022-07-01 09:29:29.313997
Epoch:[ 14 7 ] loss: 0.41120898723602295 2022-07-01 09:29:29.728871
Epoch:[ 14 8 ] loss: 0.4137018620967865 2022-07-01 09:29:30.142555
Epoch:[ 14 9 ] loss: 0.41421452164649963 2022-07-01 09:29:30.549640
Epoch:[ 14 10 ] loss: 0.41296350955963135 2022-07-01 09:29:30.962734
Epoch:[ 14 11 ] loss: 0.4146406352519989 2022-07-01 09:29:31.378568
Epoch:[ 14 12 ] loss: 0.4150812327861786 2022-07-01 09:29:31.796121
Epoch:[ 14 13 ] loss: 0.413028359413147 2022-07-01 09:29:32.214593
Epoch:[ 14 14 ] loss: 0.41368740797042847 2022-07-01 09:29:32.623427
Epoch:[ 14 15 ] loss: 0.4128025770187378 2022-07-01 09:29:33.038849
Epoch:[ 14 16 ] loss: 0.4133436977863312 2022-07-01 09:29:38.068729
Epoch:[ 14 17 ] loss: 0.41780781745910645 2022-07-01 09:29:39.036725
Epoch:[ 14 18 ] loss: 0.4132111966609955 2022-07-01 09:29:39.453816
Epoch:[ 14 19 ] loss: 0.41438940167427063 2022-07-01 09:29:39.863639
Training_Epoch:[ 14 ] Training_loss: 0.4134556636214256 2022-07-01 09:29:39.864363
learning rate:  0.0008
netparams have been saved once 14
val: 1 0.43329235911369324
val: 2 0.4377131462097168
val: 3 0.4389491677284241
val: 4 0.4351932108402252
val: 5 0.4368108808994293
val: 6 0.44610539078712463
val: 7 0.44196781516075134
val: 8 0.4503672122955322
val: 9 0.44494062662124634
val: 10 0.44722065329551697
val: 11 0.4504697024822235
val: 12 0.43802669644355774
val: 13 0.4509008526802063
val: 14 0.43098729848861694
val: 15 0.44895243644714355
val: 16 0.4426831305027008
val: 17 0.4368179142475128
val: 18 0.44941532611846924
val: 19 0.4381280839443207
val: 20 0.44350960850715637
val_Epoch:[ 14 ] val_loss: 0.4421225756406784 2022-07-01 09:29:43.716027
start training 2022-07-01 09:29:43.815539
Epoch:[ 15 0 ] loss: 0.4126320481300354 2022-07-01 09:29:58.953717
Epoch:[ 15 1 ] loss: 0.4086933135986328 2022-07-01 09:29:59.367254
Epoch:[ 15 2 ] loss: 0.4114786684513092 2022-07-01 09:29:59.780985
Epoch:[ 15 3 ] loss: 0.41321471333503723 2022-07-01 09:30:00.194504
Epoch:[ 15 4 ] loss: 0.41325029730796814 2022-07-01 09:30:00.601302
Epoch:[ 15 5 ] loss: 0.41419628262519836 2022-07-01 09:30:01.010906
Epoch:[ 15 6 ] loss: 0.412870317697525 2022-07-01 09:30:01.426950
Epoch:[ 15 7 ] loss: 0.41491037607192993 2022-07-01 09:30:01.844111
Epoch:[ 15 8 ] loss: 0.41332972049713135 2022-07-01 09:30:02.261036
Epoch:[ 15 9 ] loss: 0.4125138223171234 2022-07-01 09:30:02.673927
Epoch:[ 15 10 ] loss: 0.41475456953048706 2022-07-01 09:30:03.092708
Epoch:[ 15 11 ] loss: 0.4126782715320587 2022-07-01 09:30:03.507427
Epoch:[ 15 12 ] loss: 0.41321441531181335 2022-07-01 09:30:03.917195
Epoch:[ 15 13 ] loss: 0.4144160747528076 2022-07-01 09:30:04.332099
Epoch:[ 15 14 ] loss: 0.41153982281684875 2022-07-01 09:30:04.746228
Epoch:[ 15 15 ] loss: 0.41436251997947693 2022-07-01 09:30:05.159823
Epoch:[ 15 16 ] loss: 0.4145026206970215 2022-07-01 09:30:10.022148
Epoch:[ 15 17 ] loss: 0.4129490256309509 2022-07-01 09:30:10.435477
Epoch:[ 15 18 ] loss: 0.4129968285560608 2022-07-01 09:30:10.850724
Epoch:[ 15 19 ] loss: 0.41103363037109375 2022-07-01 09:30:11.264187
Training_Epoch:[ 15 ] Training_loss: 0.4129768669605255 2022-07-01 09:30:11.264866
learning rate:  0.0008
val: 1 0.4430464208126068
val: 2 0.43195927143096924
val: 3 0.44720661640167236
val: 4 0.4386592209339142
val: 5 0.4375527799129486
val: 6 0.43771758675575256
val: 7 0.4454694092273712
val: 8 0.4523959159851074
val: 9 0.43628010153770447
val: 10 0.4440973103046417
val: 11 0.44013580679893494
val: 12 0.4444037675857544
val: 13 0.45782187581062317
val: 14 0.4546777009963989
val: 15 0.4358789026737213
val: 16 0.43214574456214905
val: 17 0.45074108242988586
val: 18 0.44576457142829895
val: 19 0.4389445185661316
val: 20 0.4485172927379608
val_Epoch:[ 15 ] val_loss: 0.4431707948446274 2022-07-01 09:30:15.055520
start training 2022-07-01 09:30:15.154987
Epoch:[ 16 0 ] loss: 0.41265037655830383 2022-07-01 09:30:29.413230
Epoch:[ 16 1 ] loss: 0.4104161262512207 2022-07-01 09:30:30.102637
Epoch:[ 16 2 ] loss: 0.4164500832557678 2022-07-01 09:30:30.516488
Epoch:[ 16 3 ] loss: 0.4126128554344177 2022-07-01 09:30:30.931897
Epoch:[ 16 4 ] loss: 0.41139090061187744 2022-07-01 09:30:31.345241
Epoch:[ 16 5 ] loss: 0.4120301604270935 2022-07-01 09:30:31.756713
Epoch:[ 16 6 ] loss: 0.4129253327846527 2022-07-01 09:30:32.179876
Epoch:[ 16 7 ] loss: 0.41310933232307434 2022-07-01 09:30:32.602820
Epoch:[ 16 8 ] loss: 0.41190460324287415 2022-07-01 09:30:33.014651
Epoch:[ 16 9 ] loss: 0.4125668406486511 2022-07-01 09:30:33.435625
Epoch:[ 16 10 ] loss: 0.41128307580947876 2022-07-01 09:30:33.849063
Epoch:[ 16 11 ] loss: 0.4115338921546936 2022-07-01 09:30:34.263301
Epoch:[ 16 12 ] loss: 0.41243141889572144 2022-07-01 09:30:34.676147
Epoch:[ 16 13 ] loss: 0.4108254313468933 2022-07-01 09:30:35.090521
Epoch:[ 16 14 ] loss: 0.4142637550830841 2022-07-01 09:30:35.504619
Epoch:[ 16 15 ] loss: 0.4132258892059326 2022-07-01 09:30:35.918944
Epoch:[ 16 16 ] loss: 0.41405728459358215 2022-07-01 09:30:41.378522
Epoch:[ 16 17 ] loss: 0.41391903162002563 2022-07-01 09:30:41.792222
Epoch:[ 16 18 ] loss: 0.41472142934799194 2022-07-01 09:30:42.202952
Epoch:[ 16 19 ] loss: 0.41494253277778625 2022-07-01 09:30:42.614525
Training_Epoch:[ 16 ] Training_loss: 0.4128630176186562 2022-07-01 09:30:42.615579
learning rate:  0.0008
netparams have been saved once 16
val: 1 0.4448612332344055
val: 2 0.4348311126232147
val: 3 0.4421353042125702
val: 4 0.44804492592811584
val: 5 0.44320541620254517
val: 6 0.4461371600627899
val: 7 0.43967464566230774
val: 8 0.4450821876525879
val: 9 0.4440874457359314
val: 10 0.4314289391040802
val: 11 0.44276657700538635
val: 12 0.43553388118743896
val: 13 0.4430197775363922
val: 14 0.4521726071834564
val: 15 0.4268670678138733
val: 16 0.45681682229042053
val: 17 0.4580860435962677
val: 18 0.44941622018814087
val: 19 0.44915512204170227
val: 20 0.4417075514793396
val_Epoch:[ 16 ] val_loss: 0.44375150203704833 2022-07-01 09:30:46.453927
start training 2022-07-01 09:30:46.554780
Epoch:[ 17 0 ] loss: 0.4115488529205322 2022-07-01 09:31:01.430053
Epoch:[ 17 1 ] loss: 0.41186854243278503 2022-07-01 09:31:01.848575
Epoch:[ 17 2 ] loss: 0.41118884086608887 2022-07-01 09:31:02.266246
Epoch:[ 17 3 ] loss: 0.4120546877384186 2022-07-01 09:31:02.677790
Epoch:[ 17 4 ] loss: 0.41271236538887024 2022-07-01 09:31:03.090553
Epoch:[ 17 5 ] loss: 0.4128246009349823 2022-07-01 09:31:03.508838
Epoch:[ 17 6 ] loss: 0.41042956709861755 2022-07-01 09:31:03.918234
Epoch:[ 17 7 ] loss: 0.4126933515071869 2022-07-01 09:31:04.339433
Epoch:[ 17 8 ] loss: 0.41532644629478455 2022-07-01 09:31:04.756235
Epoch:[ 17 9 ] loss: 0.41186457872390747 2022-07-01 09:31:05.167934
Epoch:[ 17 10 ] loss: 0.4130856692790985 2022-07-01 09:31:05.588250
Epoch:[ 17 11 ] loss: 0.4095004200935364 2022-07-01 09:31:06.001097
Epoch:[ 17 12 ] loss: 0.4130672216415405 2022-07-01 09:31:06.411698
Epoch:[ 17 13 ] loss: 0.4127436578273773 2022-07-01 09:31:06.825482
Epoch:[ 17 14 ] loss: 0.4128398299217224 2022-07-01 09:31:07.248198
Epoch:[ 17 15 ] loss: 0.4115234315395355 2022-07-01 09:31:07.662699
Epoch:[ 17 16 ] loss: 0.41344866156578064 2022-07-01 09:31:12.913272
Epoch:[ 17 17 ] loss: 0.41140156984329224 2022-07-01 09:31:13.326855
Epoch:[ 17 18 ] loss: 0.41444382071495056 2022-07-01 09:31:13.749418
Epoch:[ 17 19 ] loss: 0.4093394875526428 2022-07-01 09:31:14.169897
Training_Epoch:[ 17 ] Training_loss: 0.41219528019428253 2022-07-01 09:31:14.170676
learning rate:  0.0008
val: 1 0.43610474467277527
val: 2 0.44569507241249084
val: 3 0.4377151429653168
val: 4 0.44375285506248474
val: 5 0.44764813780784607
val: 6 0.45894286036491394
val: 7 0.448647677898407
val: 8 0.434211403131485
val: 9 0.44940000772476196
val: 10 0.44259417057037354
val: 11 0.43436264991760254
val: 12 0.43374133110046387
val: 13 0.4325725734233856
val: 14 0.44516852498054504
val: 15 0.4431135952472687
val: 16 0.4412399232387543
val: 17 0.4374522864818573
val: 18 0.4468382000923157
val: 19 0.42828959226608276
val: 20 0.4421505033969879
val_Epoch:[ 17 ] val_loss: 0.4414820626378059 2022-07-01 09:31:18.039750
start training 2022-07-01 09:31:18.145175
Epoch:[ 18 0 ] loss: 0.4103793799877167 2022-07-01 09:31:32.482505
Epoch:[ 18 1 ] loss: 0.40949347615242004 2022-07-01 09:31:32.915822
Epoch:[ 18 2 ] loss: 0.41481006145477295 2022-07-01 09:31:33.346623
Epoch:[ 18 3 ] loss: 0.410675972700119 2022-07-01 09:31:33.763096
Epoch:[ 18 4 ] loss: 0.4128824770450592 2022-07-01 09:31:34.177748
Epoch:[ 18 5 ] loss: 0.411709725856781 2022-07-01 09:31:34.593860
Epoch:[ 18 6 ] loss: 0.41022974252700806 2022-07-01 09:31:35.009513
Epoch:[ 18 7 ] loss: 0.4106394052505493 2022-07-01 09:31:35.419683
Epoch:[ 18 8 ] loss: 0.41245007514953613 2022-07-01 09:31:35.831688
Epoch:[ 18 9 ] loss: 0.408834308385849 2022-07-01 09:31:36.249446
Epoch:[ 18 10 ] loss: 0.40910300612449646 2022-07-01 09:31:36.660915
Epoch:[ 18 11 ] loss: 0.41229167580604553 2022-07-01 09:31:37.074302
Epoch:[ 18 12 ] loss: 0.4117017686367035 2022-07-01 09:31:37.487596
Epoch:[ 18 13 ] loss: 0.41378921270370483 2022-07-01 09:31:37.903883
Epoch:[ 18 14 ] loss: 0.4139721691608429 2022-07-01 09:31:38.320119
Epoch:[ 18 15 ] loss: 0.41121190786361694 2022-07-01 09:31:38.733523
Epoch:[ 18 16 ] loss: 0.41086331009864807 2022-07-01 09:31:44.350598
Epoch:[ 18 17 ] loss: 0.41168642044067383 2022-07-01 09:31:44.767370
Epoch:[ 18 18 ] loss: 0.41036078333854675 2022-07-01 09:31:45.182033
Epoch:[ 18 19 ] loss: 0.4128149449825287 2022-07-01 09:31:45.596399
Training_Epoch:[ 18 ] Training_loss: 0.4114949911832809 2022-07-01 09:31:45.597119
learning rate:  0.0008
netparams have been saved once 18
val: 1 0.43975916504859924
val: 2 0.4414415657520294
val: 3 0.44384536147117615
val: 4 0.435462087392807
val: 5 0.4375004768371582
val: 6 0.42349475622177124
val: 7 0.44495466351509094
val: 8 0.4660986661911011
val: 9 0.43969619274139404
val: 10 0.4416202902793884
val: 11 0.44655874371528625
val: 12 0.44014137983322144
val: 13 0.4420289695262909
val: 14 0.44302523136138916
val: 15 0.4473422169685364
val: 16 0.4345686435699463
val: 17 0.4349454641342163
val: 18 0.43791142106056213
val: 19 0.4366229772567749
val: 20 0.4435485899448395
val_Epoch:[ 18 ] val_loss: 0.44102834314107897 2022-07-01 09:31:49.492010
start training 2022-07-01 09:31:49.597958
Epoch:[ 19 0 ] loss: 0.40928876399993896 2022-07-01 09:32:04.903735
Epoch:[ 19 1 ] loss: 0.4109421670436859 2022-07-01 09:32:05.310338
Epoch:[ 19 2 ] loss: 0.4129347503185272 2022-07-01 09:32:05.725010
Epoch:[ 19 3 ] loss: 0.407495379447937 2022-07-01 09:32:06.139858
Epoch:[ 19 4 ] loss: 0.41185688972473145 2022-07-01 09:32:06.558430
Epoch:[ 19 5 ] loss: 0.407976359128952 2022-07-01 09:32:06.980736
Epoch:[ 19 6 ] loss: 0.41410893201828003 2022-07-01 09:32:07.393667
Epoch:[ 19 7 ] loss: 0.411126971244812 2022-07-01 09:32:07.813382
Epoch:[ 19 8 ] loss: 0.41049376130104065 2022-07-01 09:32:08.229569
Epoch:[ 19 9 ] loss: 0.4116649329662323 2022-07-01 09:32:08.642383
Epoch:[ 19 10 ] loss: 0.41057249903678894 2022-07-01 09:32:09.061634
Epoch:[ 19 11 ] loss: 0.4105910658836365 2022-07-01 09:32:09.476810
Epoch:[ 19 12 ] loss: 0.41251182556152344 2022-07-01 09:32:09.894477
Epoch:[ 19 13 ] loss: 0.4094778597354889 2022-07-01 09:32:10.308715
Epoch:[ 19 14 ] loss: 0.4113512635231018 2022-07-01 09:32:10.724210
Epoch:[ 19 15 ] loss: 0.41119471192359924 2022-07-01 09:32:11.137367
Epoch:[ 19 16 ] loss: 0.4147701561450958 2022-07-01 09:32:16.138121
Epoch:[ 19 17 ] loss: 0.4116564393043518 2022-07-01 09:32:16.546144
Epoch:[ 19 18 ] loss: 0.4139350950717926 2022-07-01 09:32:16.959828
Epoch:[ 19 19 ] loss: 0.4125341475009918 2022-07-01 09:32:17.373732
Training_Epoch:[ 19 ] Training_loss: 0.4113241985440254 2022-07-01 09:32:17.374496
learning rate:  0.0008
val: 1 0.44183090329170227
val: 2 0.43295028805732727
val: 3 0.4440000057220459
val: 4 0.4309238791465759
val: 5 0.4350936710834503
val: 6 0.44457197189331055
val: 7 0.447948157787323
val: 8 0.44498714804649353
val: 9 0.43464159965515137
val: 10 0.4405527412891388
val: 11 0.44721922278404236
val: 12 0.4614717960357666
val: 13 0.4347776174545288
val: 14 0.4541141986846924
val: 15 0.44978490471839905
val: 16 0.44827529788017273
val: 17 0.4480690062046051
val: 18 0.4485088288784027
val: 19 0.4476124048233032
val: 20 0.43064630031585693
val_Epoch:[ 19 ] val_loss: 0.44339899718761444 2022-07-01 09:32:21.188074
start training 2022-07-01 09:32:21.289717
Epoch:[ 20 0 ] loss: 0.40760254859924316 2022-07-01 09:32:35.996083
Epoch:[ 20 1 ] loss: 0.41031187772750854 2022-07-01 09:32:36.489195
Epoch:[ 20 2 ] loss: 0.4117801785469055 2022-07-01 09:32:36.902793
Epoch:[ 20 3 ] loss: 0.41067028045654297 2022-07-01 09:32:37.317878
Epoch:[ 20 4 ] loss: 0.4132346212863922 2022-07-01 09:32:37.733015
Epoch:[ 20 5 ] loss: 0.41078516840934753 2022-07-01 09:32:38.151721
Epoch:[ 20 6 ] loss: 0.41234076023101807 2022-07-01 09:32:38.568910
Epoch:[ 20 7 ] loss: 0.40954869985580444 2022-07-01 09:32:38.984513
Epoch:[ 20 8 ] loss: 0.41213345527648926 2022-07-01 09:32:39.399248
Epoch:[ 20 9 ] loss: 0.4127492308616638 2022-07-01 09:32:39.814140
Epoch:[ 20 10 ] loss: 0.4102526009082794 2022-07-01 09:32:40.235263
Epoch:[ 20 11 ] loss: 0.4084378778934479 2022-07-01 09:32:40.657989
Epoch:[ 20 12 ] loss: 0.4112619161605835 2022-07-01 09:32:41.074144
Epoch:[ 20 13 ] loss: 0.41172364354133606 2022-07-01 09:32:41.489181
Epoch:[ 20 14 ] loss: 0.413338303565979 2022-07-01 09:32:41.903970
Epoch:[ 20 15 ] loss: 0.4090915322303772 2022-07-01 09:32:42.316760
Epoch:[ 20 16 ] loss: 0.4107556641101837 2022-07-01 09:32:47.925292
Epoch:[ 20 17 ] loss: 0.41297104954719543 2022-07-01 09:32:48.344834
Epoch:[ 20 18 ] loss: 0.41510137915611267 2022-07-01 09:32:48.766478
Epoch:[ 20 19 ] loss: 0.4118002951145172 2022-07-01 09:32:49.180420
Training_Epoch:[ 20 ] Training_loss: 0.4112945541739464 2022-07-01 09:32:49.181170
learning rate:  0.0008
netparams have been saved once 20
val: 1 0.452786922454834
val: 2 0.4264848530292511
val: 3 0.44483181834220886
val: 4 0.44786781072616577
val: 5 0.44198524951934814
val: 6 0.43455544114112854
val: 7 0.44797834753990173
val: 8 0.4546242356300354
val: 9 0.4468742907047272
val: 10 0.4426537752151489
val: 11 0.43956002593040466
val: 12 0.44847264885902405
val: 13 0.4436914026737213
val: 14 0.43726465106010437
val: 15 0.4359263777732849
val: 16 0.45412677526474
val: 17 0.4518018960952759
val: 18 0.4463294744491577
val: 19 0.4336797595024109
val: 20 0.4557994604110718
val_Epoch:[ 20 ] val_loss: 0.44436476081609727 2022-07-01 09:32:53.051874
start training 2022-07-01 09:32:53.152965
Epoch:[ 21 0 ] loss: 0.4088093042373657 2022-07-01 09:33:08.166537
Epoch:[ 21 1 ] loss: 0.4126339256763458 2022-07-01 09:33:08.580754
Epoch:[ 21 2 ] loss: 0.4104403257369995 2022-07-01 09:33:08.993859
Epoch:[ 21 3 ] loss: 0.40827804803848267 2022-07-01 09:33:09.406741
Epoch:[ 21 4 ] loss: 0.41073882579803467 2022-07-01 09:33:09.819823
Epoch:[ 21 5 ] loss: 0.4124707281589508 2022-07-01 09:33:10.236618
Epoch:[ 21 6 ] loss: 0.40872201323509216 2022-07-01 09:33:10.646533
Epoch:[ 21 7 ] loss: 0.4090668559074402 2022-07-01 09:33:11.061320
Epoch:[ 21 8 ] loss: 0.4085334837436676 2022-07-01 09:33:11.469071
Epoch:[ 21 9 ] loss: 0.4109162390232086 2022-07-01 09:33:11.883106
Epoch:[ 21 10 ] loss: 0.41188058257102966 2022-07-01 09:33:12.291378
Epoch:[ 21 11 ] loss: 0.41083255410194397 2022-07-01 09:33:12.707359
Epoch:[ 21 12 ] loss: 0.41035133600234985 2022-07-01 09:33:13.124763
Epoch:[ 21 13 ] loss: 0.41052523255348206 2022-07-01 09:33:13.542382
Epoch:[ 21 14 ] loss: 0.41174057126045227 2022-07-01 09:33:13.957848
Epoch:[ 21 15 ] loss: 0.4136851131916046 2022-07-01 09:33:14.374246
Epoch:[ 21 16 ] loss: 0.40970325469970703 2022-07-01 09:33:19.686028
Epoch:[ 21 17 ] loss: 0.4089880883693695 2022-07-01 09:33:20.092357
Epoch:[ 21 18 ] loss: 0.41040024161338806 2022-07-01 09:33:20.502546
Epoch:[ 21 19 ] loss: 0.40926650166511536 2022-07-01 09:33:20.919915
Training_Epoch:[ 21 ] Training_loss: 0.4103991612792015 2022-07-01 09:33:20.920566
learning rate:  0.00064
val: 1 0.4467868506908417
val: 2 0.43135276436805725
val: 3 0.4425666630268097
val: 4 0.4477599263191223
val: 5 0.44938352704048157
val: 6 0.43423140048980713
val: 7 0.4451723098754883
val: 8 0.44193577766418457
val: 9 0.46085572242736816
val: 10 0.4493354558944702
val: 11 0.44530898332595825
val: 12 0.43794092535972595
val: 13 0.4590894877910614
val: 14 0.43729662895202637
val: 15 0.42736226320266724
val: 16 0.43390128016471863
val: 17 0.44079774618148804
val: 18 0.4412127137184143
val: 19 0.434798002243042
val: 20 0.4411817193031311
val_Epoch:[ 21 ] val_loss: 0.4424135074019432 2022-07-01 09:33:24.711954
start training 2022-07-01 09:33:24.816191
Epoch:[ 22 0 ] loss: 0.41122967004776 2022-07-01 09:33:39.356144
Epoch:[ 22 1 ] loss: 0.41135433316230774 2022-07-01 09:33:39.806892
Epoch:[ 22 2 ] loss: 0.40815120935440063 2022-07-01 09:33:40.445305
Epoch:[ 22 3 ] loss: 0.4121543765068054 2022-07-01 09:33:40.860933
Epoch:[ 22 4 ] loss: 0.40816742181777954 2022-07-01 09:33:41.277610
Epoch:[ 22 5 ] loss: 0.41261401772499084 2022-07-01 09:33:41.692962
Epoch:[ 22 6 ] loss: 0.4113423526287079 2022-07-01 09:33:42.108895
Epoch:[ 22 7 ] loss: 0.40835270285606384 2022-07-01 09:33:42.525782
Epoch:[ 22 8 ] loss: 0.4100651144981384 2022-07-01 09:33:42.936913
Epoch:[ 22 9 ] loss: 0.4061821699142456 2022-07-01 09:33:43.343903
Epoch:[ 22 10 ] loss: 0.4084284007549286 2022-07-01 09:33:43.759008
Epoch:[ 22 11 ] loss: 0.41028717160224915 2022-07-01 09:33:44.174573
Epoch:[ 22 12 ] loss: 0.4110071063041687 2022-07-01 09:33:44.591294
Epoch:[ 22 13 ] loss: 0.40967243909835815 2022-07-01 09:33:45.005041
Epoch:[ 22 14 ] loss: 0.4089973568916321 2022-07-01 09:33:45.417406
Epoch:[ 22 15 ] loss: 0.41067805886268616 2022-07-01 09:33:45.833674
Epoch:[ 22 16 ] loss: 0.4099145531654358 2022-07-01 09:33:51.438679
Epoch:[ 22 17 ] loss: 0.411022424697876 2022-07-01 09:33:51.851880
Epoch:[ 22 18 ] loss: 0.40739455819129944 2022-07-01 09:33:52.265140
Epoch:[ 22 19 ] loss: 0.4079807996749878 2022-07-01 09:33:52.673125
Training_Epoch:[ 22 ] Training_loss: 0.40974981188774107 2022-07-01 09:33:52.674143
learning rate:  0.00064
netparams have been saved once 22
val: 1 0.44771087169647217
val: 2 0.45564407110214233
val: 3 0.4489698112010956
val: 4 0.4385603964328766
val: 5 0.44153594970703125
val: 6 0.44115662574768066
val: 7 0.44627562165260315
val: 8 0.4440915286540985
val: 9 0.44506776332855225
val: 10 0.44258543848991394
val: 11 0.44116678833961487
val: 12 0.443284809589386
val: 13 0.4342237114906311
val: 14 0.43343836069107056
val: 15 0.4488581120967865
val: 16 0.4272483289241791
val: 17 0.45613595843315125
val: 18 0.4473991394042969
val: 19 0.43833139538764954
val: 20 0.4466753602027893
val_Epoch:[ 22 ] val_loss: 0.44341800212860105 2022-07-01 09:33:56.581229
start training 2022-07-01 09:33:56.682632
Epoch:[ 23 0 ] loss: 0.4082368016242981 2022-07-01 09:34:11.939486
Epoch:[ 23 1 ] loss: 0.4079230725765228 2022-07-01 09:34:12.349953
Epoch:[ 23 2 ] loss: 0.4098757207393646 2022-07-01 09:34:12.760411
Epoch:[ 23 3 ] loss: 0.411981463432312 2022-07-01 09:34:13.175078
Epoch:[ 23 4 ] loss: 0.4095543622970581 2022-07-01 09:34:13.590099
Epoch:[ 23 5 ] loss: 0.4084433913230896 2022-07-01 09:34:13.997279
Epoch:[ 23 6 ] loss: 0.4054093360900879 2022-07-01 09:34:14.414499
Epoch:[ 23 7 ] loss: 0.40843749046325684 2022-07-01 09:34:14.835292
Epoch:[ 23 8 ] loss: 0.4087550640106201 2022-07-01 09:34:15.250140
Epoch:[ 23 9 ] loss: 0.41110458970069885 2022-07-01 09:34:15.664494
Epoch:[ 23 10 ] loss: 0.40987396240234375 2022-07-01 09:34:16.081229
Epoch:[ 23 11 ] loss: 0.40729302167892456 2022-07-01 09:34:16.498419
Epoch:[ 23 12 ] loss: 0.41308847069740295 2022-07-01 09:34:16.914506
Epoch:[ 23 13 ] loss: 0.4083152711391449 2022-07-01 09:34:17.330027
Epoch:[ 23 14 ] loss: 0.4088490903377533 2022-07-01 09:34:17.746226
Epoch:[ 23 15 ] loss: 0.40986159443855286 2022-07-01 09:34:18.158642
Epoch:[ 23 16 ] loss: 0.4081535339355469 2022-07-01 09:34:23.468714
Epoch:[ 23 17 ] loss: 0.4097343683242798 2022-07-01 09:34:23.879156
Epoch:[ 23 18 ] loss: 0.4075610637664795 2022-07-01 09:34:24.294976
Epoch:[ 23 19 ] loss: 0.4100366532802582 2022-07-01 09:34:24.704194
Training_Epoch:[ 23 ] Training_loss: 0.4091244161128998 2022-07-01 09:34:24.704855
learning rate:  0.00064
val: 1 0.437180757522583
val: 2 0.4420747458934784
val: 3 0.4503093361854553
val: 4 0.43900609016418457
val: 5 0.43956053256988525
val: 6 0.43715977668762207
val: 7 0.4311789274215698
val: 8 0.4493078887462616
val: 9 0.44763463735580444
val: 10 0.451749712228775
val: 11 0.4416453540325165
val: 12 0.4441341459751129
val: 13 0.44239532947540283
val: 14 0.4387719929218292
val: 15 0.43581321835517883
val: 16 0.4319240152835846
val: 17 0.4437809884548187
val: 18 0.43844836950302124
val: 19 0.43709975481033325
val: 20 0.44298887252807617
val_Epoch:[ 23 ] val_loss: 0.4411082223057747 2022-07-01 09:34:28.672966
start training 2022-07-01 09:34:28.773264
