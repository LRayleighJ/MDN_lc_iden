GPU: True
80
start training 2022-07-01 16:58:10.699597
Epoch:[ 1 0 ] loss: 0.3983617126941681 2022-07-01 16:58:34.038938
Epoch:[ 1 1 ] loss: 0.39824235439300537 2022-07-01 16:58:34.540369
Epoch:[ 1 2 ] loss: 0.3954218327999115 2022-07-01 16:58:34.972956
Epoch:[ 1 3 ] loss: 0.39521047472953796 2022-07-01 16:58:35.406775
Epoch:[ 1 4 ] loss: 0.3953092694282532 2022-07-01 16:58:35.841459
Epoch:[ 1 5 ] loss: 0.39614489674568176 2022-07-01 16:58:36.275873
Epoch:[ 1 6 ] loss: 0.39524510502815247 2022-07-01 16:58:36.708690
Epoch:[ 1 7 ] loss: 0.3946070373058319 2022-07-01 16:58:37.159519
Epoch:[ 1 8 ] loss: 0.3933883607387543 2022-07-01 16:58:37.587138
Epoch:[ 1 9 ] loss: 0.394387423992157 2022-07-01 16:58:38.017342
Epoch:[ 1 10 ] loss: 0.3897261321544647 2022-07-01 16:58:38.444871
Epoch:[ 1 11 ] loss: 0.3918927013874054 2022-07-01 16:58:38.876060
Epoch:[ 1 12 ] loss: 0.3924289345741272 2022-07-01 16:58:39.304642
Epoch:[ 1 13 ] loss: 0.39230668544769287 2022-07-01 16:58:39.732778
Epoch:[ 1 14 ] loss: 0.39155614376068115 2022-07-01 16:58:40.163515
Epoch:[ 1 15 ] loss: 0.3905823826789856 2022-07-01 16:58:40.588967
Epoch:[ 1 16 ] loss: 0.39108696579933167 2022-07-01 16:58:41.017119
Epoch:[ 1 17 ] loss: 0.390732079744339 2022-07-01 16:58:41.450613
Epoch:[ 1 18 ] loss: 0.3902585804462433 2022-07-01 16:58:41.897660
Epoch:[ 1 19 ] loss: 0.3896746337413788 2022-07-01 16:58:42.325964
Training_Epoch:[ 1 ] Training_loss: 0.39332818537950515 2022-07-01 16:58:42.326551
learning rate:  0.001
val: 1 0.3901112377643585
val: 2 0.392135888338089
val: 3 0.3941189646720886
val: 4 0.39079537987709045
val: 5 0.39426180720329285
val: 6 0.3856639266014099
val: 7 0.3945319354534149
val: 8 0.39208853244781494
val: 9 0.3934061527252197
val: 10 0.39025911688804626
val: 11 0.3891602158546448
val: 12 0.391467809677124
val: 13 0.38988351821899414
val: 14 0.3930394649505615
val: 15 0.3905310332775116
val: 16 0.3889952301979065
val: 17 0.39662477374076843
val: 18 0.3984000086784363
val: 19 0.3939996659755707
val: 20 0.3887106776237488
val_Epoch:[ 1 ] val_loss: 0.3919092670083046 2022-07-01 16:58:46.168219
start training 2022-07-01 16:58:46.280788
Epoch:[ 2 0 ] loss: 0.38869574666023254 2022-07-01 16:59:00.940952
Epoch:[ 2 1 ] loss: 0.3888564705848694 2022-07-01 16:59:01.473154
Epoch:[ 2 2 ] loss: 0.390192449092865 2022-07-01 16:59:01.903354
Epoch:[ 2 3 ] loss: 0.38902267813682556 2022-07-01 16:59:02.333106
Epoch:[ 2 4 ] loss: 0.38955727219581604 2022-07-01 16:59:02.763286
Epoch:[ 2 5 ] loss: 0.3891826570034027 2022-07-01 16:59:03.192432
Epoch:[ 2 6 ] loss: 0.3899630904197693 2022-07-01 16:59:03.625102
Epoch:[ 2 7 ] loss: 0.3883562684059143 2022-07-01 16:59:04.057552
Epoch:[ 2 8 ] loss: 0.3875002861022949 2022-07-01 16:59:04.488497
Epoch:[ 2 9 ] loss: 0.3869851529598236 2022-07-01 16:59:04.918270
Epoch:[ 2 10 ] loss: 0.389585942029953 2022-07-01 16:59:05.348606
Epoch:[ 2 11 ] loss: 0.3880109190940857 2022-07-01 16:59:05.783013
Epoch:[ 2 12 ] loss: 0.3875623941421509 2022-07-01 16:59:06.212980
Epoch:[ 2 13 ] loss: 0.3872781991958618 2022-07-01 16:59:06.644296
Epoch:[ 2 14 ] loss: 0.3884083032608032 2022-07-01 16:59:07.082171
Epoch:[ 2 15 ] loss: 0.3876918852329254 2022-07-01 16:59:07.518813
Epoch:[ 2 16 ] loss: 0.38771918416023254 2022-07-01 16:59:12.666864
Epoch:[ 2 17 ] loss: 0.3889915347099304 2022-07-01 16:59:13.096617
Epoch:[ 2 18 ] loss: 0.38735371828079224 2022-07-01 16:59:13.536178
Epoch:[ 2 19 ] loss: 0.3879711925983429 2022-07-01 16:59:13.949051
Training_Epoch:[ 2 ] Training_loss: 0.3884442672133446 2022-07-01 16:59:13.949738
learning rate:  0.001
netparams have been saved once 2
val: 1 0.3979171812534332
val: 2 0.38905084133148193
val: 3 0.3868250846862793
val: 4 0.3941134810447693
val: 5 0.3947203755378723
val: 6 0.38887882232666016
val: 7 0.3857272267341614
val: 8 0.3910503089427948
val: 9 0.3950507640838623
val: 10 0.39036744832992554
val: 11 0.39394640922546387
val: 12 0.39172986149787903
val: 13 0.3884241580963135
val: 14 0.387501984834671
val: 15 0.3852752149105072
val: 16 0.38898366689682007
val: 17 0.38518226146698
val: 18 0.38645437359809875
val: 19 0.391238808631897
val: 20 0.3863622546195984
val_Epoch:[ 2 ] val_loss: 0.38994002640247344 2022-07-01 16:59:17.962537
start training 2022-07-01 16:59:18.056980
Epoch:[ 3 0 ] loss: 0.38812294602394104 2022-07-01 16:59:32.853254
Epoch:[ 3 1 ] loss: 0.38661837577819824 2022-07-01 16:59:33.268968
Epoch:[ 3 2 ] loss: 0.38543587923049927 2022-07-01 16:59:33.683966
Epoch:[ 3 3 ] loss: 0.3858802616596222 2022-07-01 16:59:34.098214
Epoch:[ 3 4 ] loss: 0.38489291071891785 2022-07-01 16:59:34.512212
Epoch:[ 3 5 ] loss: 0.3870622515678406 2022-07-01 16:59:34.925410
Epoch:[ 3 6 ] loss: 0.38617730140686035 2022-07-01 16:59:35.340227
Epoch:[ 3 7 ] loss: 0.3890043795108795 2022-07-01 16:59:35.755319
Epoch:[ 3 8 ] loss: 0.38676002621650696 2022-07-01 16:59:36.177793
Epoch:[ 3 9 ] loss: 0.3873014450073242 2022-07-01 16:59:36.596827
Epoch:[ 3 10 ] loss: 0.38666343688964844 2022-07-01 16:59:37.011158
Epoch:[ 3 11 ] loss: 0.38755226135253906 2022-07-01 16:59:37.430916
Epoch:[ 3 12 ] loss: 0.3874950408935547 2022-07-01 16:59:37.844466
Epoch:[ 3 13 ] loss: 0.3878646194934845 2022-07-01 16:59:38.256521
Epoch:[ 3 14 ] loss: 0.3864293098449707 2022-07-01 16:59:38.670968
Epoch:[ 3 15 ] loss: 0.387625515460968 2022-07-01 16:59:39.092886
Epoch:[ 3 16 ] loss: 0.38724198937416077 2022-07-01 16:59:44.684611
Epoch:[ 3 17 ] loss: 0.38608044385910034 2022-07-01 16:59:45.096107
Epoch:[ 3 18 ] loss: 0.3874450922012329 2022-07-01 16:59:45.516599
Epoch:[ 3 19 ] loss: 0.38559287786483765 2022-07-01 16:59:45.930402
Training_Epoch:[ 3 ] Training_loss: 0.38686231821775435 2022-07-01 16:59:45.931049
learning rate:  0.001
val: 1 0.38932937383651733
val: 2 0.3882761597633362
val: 3 0.3852648437023163
val: 4 0.38897505402565
val: 5 0.39168405532836914
val: 6 0.39478492736816406
val: 7 0.38774916529655457
val: 8 0.38734859228134155
val: 9 0.39149242639541626
val: 10 0.3884986639022827
val: 11 0.3869752883911133
val: 12 0.3922242820262909
val: 13 0.3895702362060547
val: 14 0.3869601786136627
val: 15 0.388882577419281
val: 16 0.3928786814212799
val: 17 0.3886047303676605
val: 18 0.38960546255111694
val: 19 0.3950670063495636
val: 20 0.38803380727767944
val_Epoch:[ 3 ] val_loss: 0.38961027562618256 2022-07-01 16:59:49.728605
start training 2022-07-01 16:59:49.832837
Epoch:[ 4 0 ] loss: 0.3854292631149292 2022-07-01 17:00:03.871616
Epoch:[ 4 1 ] loss: 0.38386070728302 2022-07-01 17:00:04.317318
Epoch:[ 4 2 ] loss: 0.3861648142337799 2022-07-01 17:00:04.767449
Epoch:[ 4 3 ] loss: 0.3846190273761749 2022-07-01 17:00:05.180547
Epoch:[ 4 4 ] loss: 0.3842228055000305 2022-07-01 17:00:05.594672
Epoch:[ 4 5 ] loss: 0.3846935033798218 2022-07-01 17:00:06.012273
Epoch:[ 4 6 ] loss: 0.38642609119415283 2022-07-01 17:00:06.425700
Epoch:[ 4 7 ] loss: 0.386973112821579 2022-07-01 17:00:06.839782
Epoch:[ 4 8 ] loss: 0.384629487991333 2022-07-01 17:00:07.256051
Epoch:[ 4 9 ] loss: 0.38618624210357666 2022-07-01 17:00:07.676513
Epoch:[ 4 10 ] loss: 0.3850972652435303 2022-07-01 17:00:08.096208
Epoch:[ 4 11 ] loss: 0.3847019076347351 2022-07-01 17:00:08.511654
Epoch:[ 4 12 ] loss: 0.3865579664707184 2022-07-01 17:00:08.926463
Epoch:[ 4 13 ] loss: 0.38505125045776367 2022-07-01 17:00:09.341820
Epoch:[ 4 14 ] loss: 0.3850557506084442 2022-07-01 17:00:09.756166
Epoch:[ 4 15 ] loss: 0.38745221495628357 2022-07-01 17:00:10.172079
Epoch:[ 4 16 ] loss: 0.38450002670288086 2022-07-01 17:00:15.638059
Epoch:[ 4 17 ] loss: 0.38585951924324036 2022-07-01 17:00:16.316923
Epoch:[ 4 18 ] loss: 0.3855269253253937 2022-07-01 17:00:16.737211
Epoch:[ 4 19 ] loss: 0.3848012685775757 2022-07-01 17:00:17.150886
Training_Epoch:[ 4 ] Training_loss: 0.3853904575109482 2022-07-01 17:00:17.151608
learning rate:  0.001
netparams have been saved once 4
val: 1 0.3873530924320221
val: 2 0.3873673975467682
val: 3 0.3950589597225189
val: 4 0.395148903131485
val: 5 0.3881289064884186
val: 6 0.38900986313819885
val: 7 0.39312079548835754
val: 8 0.39321649074554443
val: 9 0.3885025680065155
val: 10 0.3843587636947632
val: 11 0.39096733927726746
val: 12 0.3891720175743103
val: 13 0.3846021592617035
val: 14 0.38944298028945923
val: 15 0.391574889421463
val: 16 0.3909341096878052
val: 17 0.3862619698047638
val: 18 0.3913191258907318
val: 19 0.38867056369781494
val: 20 0.3835247755050659
val_Epoch:[ 4 ] val_loss: 0.38938678354024886 2022-07-01 17:00:21.102468
start training 2022-07-01 17:00:21.203524
Epoch:[ 5 0 ] loss: 0.3830130696296692 2022-07-01 17:00:35.562852
Epoch:[ 5 1 ] loss: 0.38239967823028564 2022-07-01 17:00:36.002640
Epoch:[ 5 2 ] loss: 0.3843178153038025 2022-07-01 17:00:36.418456
Epoch:[ 5 3 ] loss: 0.38370755314826965 2022-07-01 17:00:36.833189
Epoch:[ 5 4 ] loss: 0.385170578956604 2022-07-01 17:00:37.246999
Epoch:[ 5 5 ] loss: 0.3846525549888611 2022-07-01 17:00:37.660661
Epoch:[ 5 6 ] loss: 0.3838556110858917 2022-07-01 17:00:38.075144
Epoch:[ 5 7 ] loss: 0.3856546878814697 2022-07-01 17:00:38.488477
Epoch:[ 5 8 ] loss: 0.386499285697937 2022-07-01 17:00:38.900371
Epoch:[ 5 9 ] loss: 0.3841966986656189 2022-07-01 17:00:39.320574
Epoch:[ 5 10 ] loss: 0.3840929865837097 2022-07-01 17:00:39.734771
Epoch:[ 5 11 ] loss: 0.3847324550151825 2022-07-01 17:00:40.149305
Epoch:[ 5 12 ] loss: 0.38412657380104065 2022-07-01 17:00:40.561880
Epoch:[ 5 13 ] loss: 0.3832678496837616 2022-07-01 17:00:40.976146
Epoch:[ 5 14 ] loss: 0.38513579964637756 2022-07-01 17:00:41.388218
Epoch:[ 5 15 ] loss: 0.38442742824554443 2022-07-01 17:00:41.805562
Epoch:[ 5 16 ] loss: 0.3840830326080322 2022-07-01 17:00:47.225005
Epoch:[ 5 17 ] loss: 0.3837379515171051 2022-07-01 17:00:47.646557
Epoch:[ 5 18 ] loss: 0.3814176619052887 2022-07-01 17:00:48.067111
Epoch:[ 5 19 ] loss: 0.3840858042240143 2022-07-01 17:00:48.480855
Training_Epoch:[ 5 ] Training_loss: 0.3841287538409233 2022-07-01 17:00:48.481474
learning rate:  0.001
val: 1 0.3805137574672699
val: 2 0.3877636790275574
val: 3 0.3890655040740967
val: 4 0.38893643021583557
val: 5 0.38304761052131653
val: 6 0.3931683301925659
val: 7 0.39052614569664
val: 8 0.3861793577671051
val: 9 0.3822025954723358
val: 10 0.3927933871746063
val: 11 0.3848644495010376
val: 12 0.3900456726551056
val: 13 0.38608258962631226
val: 14 0.3863179683685303
val: 15 0.3900536298751831
val: 16 0.38290470838546753
val: 17 0.38673266768455505
val: 18 0.3846634030342102
val: 19 0.38652732968330383
val: 20 0.38755548000335693
val_Epoch:[ 5 ] val_loss: 0.3869972348213196 2022-07-01 17:00:52.404279
start training 2022-07-01 17:00:52.505340
Epoch:[ 6 0 ] loss: 0.3837231397628784 2022-07-01 17:01:06.704034
Epoch:[ 6 1 ] loss: 0.3818409740924835 2022-07-01 17:01:07.148196
Epoch:[ 6 2 ] loss: 0.3836151957511902 2022-07-01 17:01:07.583016
Epoch:[ 6 3 ] loss: 0.38370752334594727 2022-07-01 17:01:07.997450
Epoch:[ 6 4 ] loss: 0.38232460618019104 2022-07-01 17:01:08.413021
Epoch:[ 6 5 ] loss: 0.381401002407074 2022-07-01 17:01:08.830451
Epoch:[ 6 6 ] loss: 0.38180360198020935 2022-07-01 17:01:09.244554
Epoch:[ 6 7 ] loss: 0.3848194181919098 2022-07-01 17:01:09.663648
Epoch:[ 6 8 ] loss: 0.38367483019828796 2022-07-01 17:01:10.077843
Epoch:[ 6 9 ] loss: 0.3813755214214325 2022-07-01 17:01:10.490882
Epoch:[ 6 10 ] loss: 0.3836027681827545 2022-07-01 17:01:10.905231
Epoch:[ 6 11 ] loss: 0.3822104036808014 2022-07-01 17:01:11.321394
Epoch:[ 6 12 ] loss: 0.3841647505760193 2022-07-01 17:01:11.736166
Epoch:[ 6 13 ] loss: 0.38462623953819275 2022-07-01 17:01:12.150610
Epoch:[ 6 14 ] loss: 0.3826234042644501 2022-07-01 17:01:12.565107
Epoch:[ 6 15 ] loss: 0.38422566652297974 2022-07-01 17:01:12.985696
Epoch:[ 6 16 ] loss: 0.3829086124897003 2022-07-01 17:01:18.834768
Epoch:[ 6 17 ] loss: 0.3823193609714508 2022-07-01 17:01:19.250810
Epoch:[ 6 18 ] loss: 0.3823711574077606 2022-07-01 17:01:19.673882
Epoch:[ 6 19 ] loss: 0.3851199746131897 2022-07-01 17:01:20.094475
Training_Epoch:[ 6 ] Training_loss: 0.3831229075789452 2022-07-01 17:01:20.095110
learning rate:  0.001
netparams have been saved once 6
val: 1 0.3960842788219452
val: 2 0.38674959540367126
val: 3 0.39098986983299255
val: 4 0.3866935670375824
val: 5 0.39753806591033936
val: 6 0.39607301354408264
val: 7 0.39350399374961853
val: 8 0.3894229531288147
val: 9 0.38390177488327026
val: 10 0.39222192764282227
val: 11 0.39014726877212524
val: 12 0.3888046145439148
val: 13 0.38662511110305786
val: 14 0.3901079595088959
val: 15 0.39112597703933716
val: 16 0.3889051675796509
val: 17 0.3892996311187744
val: 18 0.3884234130382538
val: 19 0.38346004486083984
val: 20 0.3921956419944763
val_Epoch:[ 6 ] val_loss: 0.3901136934757233 2022-07-01 17:01:24.008112
start training 2022-07-01 17:01:24.105985
Epoch:[ 7 0 ] loss: 0.3837767541408539 2022-07-01 17:01:38.587057
Epoch:[ 7 1 ] loss: 0.38235822319984436 2022-07-01 17:01:39.035458
Epoch:[ 7 2 ] loss: 0.3841586112976074 2022-07-01 17:01:39.449806
Epoch:[ 7 3 ] loss: 0.3831128776073456 2022-07-01 17:01:39.863000
Epoch:[ 7 4 ] loss: 0.38321906328201294 2022-07-01 17:01:40.278374
Epoch:[ 7 5 ] loss: 0.3811415731906891 2022-07-01 17:01:40.693198
Epoch:[ 7 6 ] loss: 0.38317546248435974 2022-07-01 17:01:41.108128
Epoch:[ 7 7 ] loss: 0.38248419761657715 2022-07-01 17:01:41.522096
Epoch:[ 7 8 ] loss: 0.3825828731060028 2022-07-01 17:01:41.937944
Epoch:[ 7 9 ] loss: 0.38130250573158264 2022-07-01 17:01:42.351600
Epoch:[ 7 10 ] loss: 0.38141486048698425 2022-07-01 17:01:42.767199
Epoch:[ 7 11 ] loss: 0.3823398947715759 2022-07-01 17:01:43.190865
Epoch:[ 7 12 ] loss: 0.38083285093307495 2022-07-01 17:01:43.613422
Epoch:[ 7 13 ] loss: 0.382773220539093 2022-07-01 17:01:44.029845
Epoch:[ 7 14 ] loss: 0.3819192051887512 2022-07-01 17:01:44.446349
Epoch:[ 7 15 ] loss: 0.3813781440258026 2022-07-01 17:01:44.860586
Epoch:[ 7 16 ] loss: 0.38327229022979736 2022-07-01 17:01:50.656828
Epoch:[ 7 17 ] loss: 0.3822973072528839 2022-07-01 17:01:51.076566
Epoch:[ 7 18 ] loss: 0.3835945129394531 2022-07-01 17:01:51.506097
Epoch:[ 7 19 ] loss: 0.38414743542671204 2022-07-01 17:01:51.921935
Training_Epoch:[ 7 ] Training_loss: 0.3825640931725502 2022-07-01 17:01:51.922683
learning rate:  0.001
val: 1 0.39339905977249146
val: 2 0.38685157895088196
val: 3 0.3879539370536804
val: 4 0.3942892849445343
val: 5 0.3889445960521698
val: 6 0.38848406076431274
val: 7 0.3858002722263336
val: 8 0.39051520824432373
val: 9 0.388783723115921
val: 10 0.3912692666053772
val: 11 0.3882136642932892
val: 12 0.3903981149196625
val: 13 0.39047542214393616
val: 14 0.3838113248348236
val: 15 0.3874377906322479
val: 16 0.3829408586025238
val: 17 0.3858334422111511
val: 18 0.3892138600349426
val: 19 0.3906557261943817
val: 20 0.3888208568096161
val_Epoch:[ 7 ] val_loss: 0.38870460242033006 2022-07-01 17:01:56.023412
start training 2022-07-01 17:01:56.127019
Epoch:[ 8 0 ] loss: 0.38178038597106934 2022-07-01 17:02:10.534705
Epoch:[ 8 1 ] loss: 0.3824053406715393 2022-07-01 17:02:11.270015
Epoch:[ 8 2 ] loss: 0.38150832056999207 2022-07-01 17:02:11.685882
Epoch:[ 8 3 ] loss: 0.3808799684047699 2022-07-01 17:02:12.106795
Epoch:[ 8 4 ] loss: 0.38458871841430664 2022-07-01 17:02:12.523111
Epoch:[ 8 5 ] loss: 0.38164111971855164 2022-07-01 17:02:12.939421
Epoch:[ 8 6 ] loss: 0.3809392750263214 2022-07-01 17:02:13.355276
Epoch:[ 8 7 ] loss: 0.381230890750885 2022-07-01 17:02:13.773518
Epoch:[ 8 8 ] loss: 0.3809196949005127 2022-07-01 17:02:14.183089
Epoch:[ 8 9 ] loss: 0.38129907846450806 2022-07-01 17:02:14.597882
Epoch:[ 8 10 ] loss: 0.3818833827972412 2022-07-01 17:02:15.021015
Epoch:[ 8 11 ] loss: 0.3831249475479126 2022-07-01 17:02:15.436266
Epoch:[ 8 12 ] loss: 0.3812306225299835 2022-07-01 17:02:15.856589
Epoch:[ 8 13 ] loss: 0.38091257214546204 2022-07-01 17:02:16.276027
Epoch:[ 8 14 ] loss: 0.3823535442352295 2022-07-01 17:02:16.692311
Epoch:[ 8 15 ] loss: 0.3826161324977875 2022-07-01 17:02:17.108863
Epoch:[ 8 16 ] loss: 0.3824344575405121 2022-07-01 17:02:22.426813
Epoch:[ 8 17 ] loss: 0.38264673948287964 2022-07-01 17:02:22.841849
Epoch:[ 8 18 ] loss: 0.3817841708660126 2022-07-01 17:02:23.263296
Epoch:[ 8 19 ] loss: 0.38288232684135437 2022-07-01 17:02:23.685271
Training_Epoch:[ 8 ] Training_loss: 0.3819530844688416 2022-07-01 17:02:23.686011
learning rate:  0.001
netparams have been saved once 8
val: 1 0.39543506503105164
val: 2 0.3858138918876648
val: 3 0.3888344168663025
val: 4 0.3931525647640228
val: 5 0.3857501149177551
val: 6 0.38935086131095886
val: 7 0.3852628767490387
val: 8 0.3847358524799347
val: 9 0.39479684829711914
val: 10 0.3856194019317627
val: 11 0.383719801902771
val: 12 0.38529184460639954
val: 13 0.38278070092201233
val: 14 0.39213401079177856
val: 15 0.3883477449417114
val: 16 0.39235353469848633
val: 17 0.38458481431007385
val: 18 0.38923147320747375
val: 19 0.38228920102119446
val: 20 0.3873548209667206
val_Epoch:[ 8 ] val_loss: 0.38784199208021164 2022-07-01 17:02:27.741666
start training 2022-07-01 17:02:27.841773
Epoch:[ 9 0 ] loss: 0.3811124861240387 2022-07-01 17:02:42.639597
Epoch:[ 9 1 ] loss: 0.3803977370262146 2022-07-01 17:02:43.053893
Epoch:[ 9 2 ] loss: 0.3808667063713074 2022-07-01 17:02:43.467395
Epoch:[ 9 3 ] loss: 0.3807653784751892 2022-07-01 17:02:43.881457
Epoch:[ 9 4 ] loss: 0.3801232874393463 2022-07-01 17:02:44.295524
Epoch:[ 9 5 ] loss: 0.38159507513046265 2022-07-01 17:02:44.709625
Epoch:[ 9 6 ] loss: 0.37907105684280396 2022-07-01 17:02:45.131345
Epoch:[ 9 7 ] loss: 0.38240402936935425 2022-07-01 17:02:45.549205
Epoch:[ 9 8 ] loss: 0.3822479248046875 2022-07-01 17:02:45.965580
Epoch:[ 9 9 ] loss: 0.38068121671676636 2022-07-01 17:02:46.386371
Epoch:[ 9 10 ] loss: 0.38028839230537415 2022-07-01 17:02:46.801403
Epoch:[ 9 11 ] loss: 0.3816772699356079 2022-07-01 17:02:47.215896
Epoch:[ 9 12 ] loss: 0.38174405694007874 2022-07-01 17:02:47.628529
Epoch:[ 9 13 ] loss: 0.3810102343559265 2022-07-01 17:02:48.044760
Epoch:[ 9 14 ] loss: 0.38124606013298035 2022-07-01 17:02:48.461003
Epoch:[ 9 15 ] loss: 0.3798515498638153 2022-07-01 17:02:48.877930
Epoch:[ 9 16 ] loss: 0.3831276297569275 2022-07-01 17:02:54.389070
Epoch:[ 9 17 ] loss: 0.38092607259750366 2022-07-01 17:02:54.808340
Epoch:[ 9 18 ] loss: 0.37943828105926514 2022-07-01 17:02:55.223393
Epoch:[ 9 19 ] loss: 0.3800109028816223 2022-07-01 17:02:55.638199
Training_Epoch:[ 9 ] Training_loss: 0.3809292674064636 2022-07-01 17:02:55.638910
learning rate:  0.001
val: 1 0.3932360112667084
val: 2 0.395285964012146
val: 3 0.388998806476593
val: 4 0.3956633508205414
val: 5 0.3889629542827606
val: 6 0.3832191228866577
val: 7 0.3846435248851776
val: 8 0.3887818455696106
val: 9 0.38508883118629456
val: 10 0.3901413381099701
val: 11 0.38663050532341003
val: 12 0.3867766857147217
val: 13 0.3866655230522156
val: 14 0.3901086151599884
val: 15 0.38787299394607544
val: 16 0.39146047830581665
val: 17 0.38862937688827515
val: 18 0.3807711899280548
val: 19 0.3902145326137543
val: 20 0.3910052478313446
val_Epoch:[ 9 ] val_loss: 0.3887078449130058 2022-07-01 17:02:59.586856
start training 2022-07-01 17:02:59.690714
Epoch:[ 10 0 ] loss: 0.38024964928627014 2022-07-01 17:03:13.987217
Epoch:[ 10 1 ] loss: 0.38039177656173706 2022-07-01 17:03:14.410688
Epoch:[ 10 2 ] loss: 0.3811725974082947 2022-07-01 17:03:14.825686
Epoch:[ 10 3 ] loss: 0.3810099959373474 2022-07-01 17:03:15.239900
Epoch:[ 10 4 ] loss: 0.3817978501319885 2022-07-01 17:03:15.653674
Epoch:[ 10 5 ] loss: 0.37972214818000793 2022-07-01 17:03:16.071383
Epoch:[ 10 6 ] loss: 0.38165611028671265 2022-07-01 17:03:16.489728
Epoch:[ 10 7 ] loss: 0.38109830021858215 2022-07-01 17:03:16.906014
Epoch:[ 10 8 ] loss: 0.38013553619384766 2022-07-01 17:03:17.327438
Epoch:[ 10 9 ] loss: 0.3812745213508606 2022-07-01 17:03:17.742656
Epoch:[ 10 10 ] loss: 0.37891435623168945 2022-07-01 17:03:18.151538
Epoch:[ 10 11 ] loss: 0.3803301751613617 2022-07-01 17:03:18.562187
Epoch:[ 10 12 ] loss: 0.37976276874542236 2022-07-01 17:03:18.978015
Epoch:[ 10 13 ] loss: 0.38133877515792847 2022-07-01 17:03:19.392755
Epoch:[ 10 14 ] loss: 0.37962377071380615 2022-07-01 17:03:19.810088
Epoch:[ 10 15 ] loss: 0.379250168800354 2022-07-01 17:03:20.229194
Epoch:[ 10 16 ] loss: 0.38145408034324646 2022-07-01 17:03:25.664165
Epoch:[ 10 17 ] loss: 0.381153404712677 2022-07-01 17:03:26.073140
Epoch:[ 10 18 ] loss: 0.37753045558929443 2022-07-01 17:03:26.492757
Epoch:[ 10 19 ] loss: 0.37994584441185 2022-07-01 17:03:26.907517
Training_Epoch:[ 10 ] Training_loss: 0.38039061427116394 2022-07-01 17:03:26.908503
learning rate:  0.001
netparams have been saved once 10
val: 1 0.3875665068626404
val: 2 0.3830460011959076
val: 3 0.3950791656970978
val: 4 0.3873169720172882
val: 5 0.38570502400398254
val: 6 0.3855718672275543
val: 7 0.3840433657169342
val: 8 0.3918488919734955
val: 9 0.38890916109085083
val: 10 0.3853974938392639
val: 11 0.3816646933555603
val: 12 0.3890588581562042
val: 13 0.38445615768432617
val: 14 0.39253145456314087
val: 15 0.38313788175582886
val: 16 0.3828597962856293
val: 17 0.38796505331993103
val: 18 0.3841496407985687
val: 19 0.3895282745361328
val: 20 0.3833903968334198
val_Epoch:[ 10 ] val_loss: 0.3866613328456879 2022-07-01 17:03:30.907154
start training 2022-07-01 17:03:31.003476
Epoch:[ 11 0 ] loss: 0.379382848739624 2022-07-01 17:03:45.147430
Epoch:[ 11 1 ] loss: 0.3789463937282562 2022-07-01 17:03:45.568643
Epoch:[ 11 2 ] loss: 0.3796236515045166 2022-07-01 17:03:46.008920
Epoch:[ 11 3 ] loss: 0.378655344247818 2022-07-01 17:03:46.425239
Epoch:[ 11 4 ] loss: 0.38016197085380554 2022-07-01 17:03:46.841106
Epoch:[ 11 5 ] loss: 0.3806245028972626 2022-07-01 17:03:47.257236
Epoch:[ 11 6 ] loss: 0.38055768609046936 2022-07-01 17:03:47.673258
Epoch:[ 11 7 ] loss: 0.379319429397583 2022-07-01 17:03:48.081548
Epoch:[ 11 8 ] loss: 0.38007885217666626 2022-07-01 17:03:48.501223
Epoch:[ 11 9 ] loss: 0.3780428171157837 2022-07-01 17:03:48.917750
Epoch:[ 11 10 ] loss: 0.37942686676979065 2022-07-01 17:03:49.332955
Epoch:[ 11 11 ] loss: 0.3795728385448456 2022-07-01 17:03:49.752633
Epoch:[ 11 12 ] loss: 0.37997201085090637 2022-07-01 17:03:50.175407
Epoch:[ 11 13 ] loss: 0.37891608476638794 2022-07-01 17:03:50.589291
Epoch:[ 11 14 ] loss: 0.3794780373573303 2022-07-01 17:03:51.001942
Epoch:[ 11 15 ] loss: 0.38054004311561584 2022-07-01 17:03:51.420811
Epoch:[ 11 16 ] loss: 0.37848204374313354 2022-07-01 17:03:56.924266
Epoch:[ 11 17 ] loss: 0.3776145279407501 2022-07-01 17:03:57.333002
Epoch:[ 11 18 ] loss: 0.3787951171398163 2022-07-01 17:03:57.754748
Epoch:[ 11 19 ] loss: 0.37915435433387756 2022-07-01 17:03:58.169442
Training_Epoch:[ 11 ] Training_loss: 0.379367271065712 2022-07-01 17:03:58.170349
learning rate:  0.0008
val: 1 0.3825298249721527
val: 2 0.37742674350738525
val: 3 0.38722553849220276
val: 4 0.38743624091148376
val: 5 0.3863769769668579
val: 6 0.38140085339546204
val: 7 0.3870644271373749
val: 8 0.3917999565601349
val: 9 0.3918541371822357
val: 10 0.3859834372997284
val: 11 0.38033077120780945
val: 12 0.3898300230503082
val: 13 0.3871931731700897
val: 14 0.3902253806591034
val: 15 0.3846797049045563
val: 16 0.38826432824134827
val: 17 0.38317644596099854
val: 18 0.38603055477142334
val: 19 0.380500465631485
val: 20 0.3814134895801544
val_Epoch:[ 11 ] val_loss: 0.3855371236801147 2022-07-01 17:04:02.139965
start training 2022-07-01 17:04:02.239993
Epoch:[ 12 0 ] loss: 0.3775414526462555 2022-07-01 17:04:17.532523
Epoch:[ 12 1 ] loss: 0.37823382019996643 2022-07-01 17:04:17.947267
Epoch:[ 12 2 ] loss: 0.3777942657470703 2022-07-01 17:04:18.363275
Epoch:[ 12 3 ] loss: 0.3793020248413086 2022-07-01 17:04:18.778692
Epoch:[ 12 4 ] loss: 0.37848982214927673 2022-07-01 17:04:19.194757
Epoch:[ 12 5 ] loss: 0.3776855766773224 2022-07-01 17:04:19.608968
Epoch:[ 12 6 ] loss: 0.37856823205947876 2022-07-01 17:04:20.030194
Epoch:[ 12 7 ] loss: 0.38055649399757385 2022-07-01 17:04:20.451249
Epoch:[ 12 8 ] loss: 0.3786875903606415 2022-07-01 17:04:20.866234
Epoch:[ 12 9 ] loss: 0.37811291217803955 2022-07-01 17:04:21.282182
Epoch:[ 12 10 ] loss: 0.3775467872619629 2022-07-01 17:04:21.698104
Epoch:[ 12 11 ] loss: 0.3790493309497833 2022-07-01 17:04:22.113106
Epoch:[ 12 12 ] loss: 0.37848252058029175 2022-07-01 17:04:22.530284
Epoch:[ 12 13 ] loss: 0.3797925114631653 2022-07-01 17:04:22.944207
Epoch:[ 12 14 ] loss: 0.3784899115562439 2022-07-01 17:04:23.358478
Epoch:[ 12 15 ] loss: 0.37970229983329773 2022-07-01 17:04:23.772068
Epoch:[ 12 16 ] loss: 0.378073513507843 2022-07-01 17:04:29.103930
Epoch:[ 12 17 ] loss: 0.380287230014801 2022-07-01 17:04:29.525477
Epoch:[ 12 18 ] loss: 0.3791920244693756 2022-07-01 17:04:29.942697
Epoch:[ 12 19 ] loss: 0.37735894322395325 2022-07-01 17:04:30.356783
Training_Epoch:[ 12 ] Training_loss: 0.37864736318588255 2022-07-01 17:04:30.357443
learning rate:  0.0008
netparams have been saved once 12
val: 1 0.38213035464286804
val: 2 0.3861875832080841
val: 3 0.3815328776836395
val: 4 0.38904672861099243
val: 5 0.38428059220314026
val: 6 0.38931551575660706
val: 7 0.38214218616485596
val: 8 0.38159942626953125
val: 9 0.383054256439209
val: 10 0.38724273443222046
val: 11 0.3879840075969696
val: 12 0.37909555435180664
val: 13 0.3837672472000122
val: 14 0.39637491106987
val: 15 0.386580228805542
val: 16 0.3899456858634949
val: 17 0.37954196333885193
val: 18 0.3872672915458679
val: 19 0.39163482189178467
val: 20 0.38911429047584534
val_Epoch:[ 12 ] val_loss: 0.38589191287755964 2022-07-01 17:04:34.312466
start training 2022-07-01 17:04:34.414955
Epoch:[ 13 0 ] loss: 0.3790217339992523 2022-07-01 17:04:48.886396
Epoch:[ 13 1 ] loss: 0.3788518011569977 2022-07-01 17:04:49.301879
Epoch:[ 13 2 ] loss: 0.3788243234157562 2022-07-01 17:04:49.718113
Epoch:[ 13 3 ] loss: 0.37849125266075134 2022-07-01 17:04:50.128844
Epoch:[ 13 4 ] loss: 0.37859001755714417 2022-07-01 17:04:50.545603
Epoch:[ 13 5 ] loss: 0.37849971652030945 2022-07-01 17:04:50.960235
Epoch:[ 13 6 ] loss: 0.37798213958740234 2022-07-01 17:04:51.377033
Epoch:[ 13 7 ] loss: 0.3780394196510315 2022-07-01 17:04:51.793224
Epoch:[ 13 8 ] loss: 0.3763597309589386 2022-07-01 17:04:52.212207
Epoch:[ 13 9 ] loss: 0.37630021572113037 2022-07-01 17:04:52.628444
Epoch:[ 13 10 ] loss: 0.3797339200973511 2022-07-01 17:04:53.049057
Epoch:[ 13 11 ] loss: 0.37872329354286194 2022-07-01 17:04:53.461175
Epoch:[ 13 12 ] loss: 0.3798066973686218 2022-07-01 17:04:53.876781
Epoch:[ 13 13 ] loss: 0.37770578265190125 2022-07-01 17:04:54.293071
Epoch:[ 13 14 ] loss: 0.37760552763938904 2022-07-01 17:04:54.708292
Epoch:[ 13 15 ] loss: 0.3791683614253998 2022-07-01 17:04:55.122909
Epoch:[ 13 16 ] loss: 0.37777793407440186 2022-07-01 17:05:00.473977
Epoch:[ 13 17 ] loss: 0.3779478967189789 2022-07-01 17:05:00.888863
Epoch:[ 13 18 ] loss: 0.3784336745738983 2022-07-01 17:05:01.442524
Epoch:[ 13 19 ] loss: 0.37828725576400757 2022-07-01 17:05:01.856772
Training_Epoch:[ 13 ] Training_loss: 0.37830753475427625 2022-07-01 17:05:01.857523
learning rate:  0.0008
val: 1 0.3884730339050293
val: 2 0.38181072473526
val: 3 0.39133134484291077
val: 4 0.38677075505256653
val: 5 0.3890523314476013
val: 6 0.39018988609313965
val: 7 0.38123077154159546
val: 8 0.38310763239860535
val: 9 0.3812192380428314
val: 10 0.3856138288974762
val: 11 0.38498178124427795
val: 12 0.38557663559913635
val: 13 0.3824535310268402
val: 14 0.3835538625717163
val: 15 0.386287659406662
val: 16 0.38715291023254395
val: 17 0.38962575793266296
val: 18 0.39326590299606323
val: 19 0.39628082513809204
val: 20 0.37992632389068604
val_Epoch:[ 13 ] val_loss: 0.38639523684978483 2022-07-01 17:05:05.803965
start training 2022-07-01 17:05:05.905164
Epoch:[ 14 0 ] loss: 0.3771810531616211 2022-07-01 17:05:20.965687
Epoch:[ 14 1 ] loss: 0.37785637378692627 2022-07-01 17:05:21.379517
Epoch:[ 14 2 ] loss: 0.37575188279151917 2022-07-01 17:05:21.795581
Epoch:[ 14 3 ] loss: 0.3792497515678406 2022-07-01 17:05:22.210529
Epoch:[ 14 4 ] loss: 0.3789979815483093 2022-07-01 17:05:22.627567
Epoch:[ 14 5 ] loss: 0.3782643675804138 2022-07-01 17:05:23.044380
Epoch:[ 14 6 ] loss: 0.37669995427131653 2022-07-01 17:05:23.459479
Epoch:[ 14 7 ] loss: 0.37742212414741516 2022-07-01 17:05:23.880006
Epoch:[ 14 8 ] loss: 0.3779579997062683 2022-07-01 17:05:24.295657
Epoch:[ 14 9 ] loss: 0.37773579359054565 2022-07-01 17:05:24.713143
Epoch:[ 14 10 ] loss: 0.37601780891418457 2022-07-01 17:05:25.129720
Epoch:[ 14 11 ] loss: 0.37680956721305847 2022-07-01 17:05:25.545863
Epoch:[ 14 12 ] loss: 0.3779745399951935 2022-07-01 17:05:25.970925
Epoch:[ 14 13 ] loss: 0.37798017263412476 2022-07-01 17:05:26.380377
Epoch:[ 14 14 ] loss: 0.37832480669021606 2022-07-01 17:05:26.794957
Epoch:[ 14 15 ] loss: 0.3768688142299652 2022-07-01 17:05:27.203628
Epoch:[ 14 16 ] loss: 0.37819966673851013 2022-07-01 17:05:32.494574
Epoch:[ 14 17 ] loss: 0.37680989503860474 2022-07-01 17:05:32.909474
Epoch:[ 14 18 ] loss: 0.37694650888442993 2022-07-01 17:05:33.334831
Epoch:[ 14 19 ] loss: 0.37759676575660706 2022-07-01 17:05:33.744472
Training_Epoch:[ 14 ] Training_loss: 0.3775322914123535 2022-07-01 17:05:33.745461
learning rate:  0.0008
netparams have been saved once 14
val: 1 0.37887731194496155
val: 2 0.38659602403640747
val: 3 0.39166030287742615
val: 4 0.3808276951313019
val: 5 0.3826729357242584
val: 6 0.3839995265007019
val: 7 0.3895244896411896
val: 8 0.38117489218711853
val: 9 0.3832729160785675
val: 10 0.3961400091648102
val: 11 0.38390272855758667
val: 12 0.38708919286727905
val: 13 0.38611549139022827
val: 14 0.3868010640144348
val: 15 0.3845455050468445
val: 16 0.3862568438053131
val: 17 0.38326796889305115
val: 18 0.39404764771461487
val: 19 0.3796653747558594
val: 20 0.3907604515552521
val_Epoch:[ 14 ] val_loss: 0.38585991859436036 2022-07-01 17:05:38.193491
start training 2022-07-01 17:05:38.307954
Epoch:[ 15 0 ] loss: 0.3773554563522339 2022-07-01 17:05:53.343381
Epoch:[ 15 1 ] loss: 0.3765416443347931 2022-07-01 17:05:53.775939
Epoch:[ 15 2 ] loss: 0.37723368406295776 2022-07-01 17:05:54.190276
Epoch:[ 15 3 ] loss: 0.37736397981643677 2022-07-01 17:05:54.613980
Epoch:[ 15 4 ] loss: 0.37735703587532043 2022-07-01 17:05:55.027079
Epoch:[ 15 5 ] loss: 0.37680304050445557 2022-07-01 17:05:55.442202
Epoch:[ 15 6 ] loss: 0.37651780247688293 2022-07-01 17:05:55.857287
Epoch:[ 15 7 ] loss: 0.3770449161529541 2022-07-01 17:05:56.271528
Epoch:[ 15 8 ] loss: 0.37708500027656555 2022-07-01 17:05:56.686928
Epoch:[ 15 9 ] loss: 0.37712931632995605 2022-07-01 17:05:57.101138
Epoch:[ 15 10 ] loss: 0.376753568649292 2022-07-01 17:05:57.515288
Epoch:[ 15 11 ] loss: 0.37669336795806885 2022-07-01 17:05:57.929004
Epoch:[ 15 12 ] loss: 0.3784656226634979 2022-07-01 17:05:58.345588
Epoch:[ 15 13 ] loss: 0.37613603472709656 2022-07-01 17:05:58.761518
Epoch:[ 15 14 ] loss: 0.37631741166114807 2022-07-01 17:05:59.176292
Epoch:[ 15 15 ] loss: 0.3767104744911194 2022-07-01 17:05:59.595307
Epoch:[ 15 16 ] loss: 0.3775177299976349 2022-07-01 17:06:05.153543
Epoch:[ 15 17 ] loss: 0.3763120472431183 2022-07-01 17:06:05.565609
Epoch:[ 15 18 ] loss: 0.37775447964668274 2022-07-01 17:06:05.992105
Epoch:[ 15 19 ] loss: 0.37953105568885803 2022-07-01 17:06:06.407426
Training_Epoch:[ 15 ] Training_loss: 0.37713118344545365 2022-07-01 17:06:06.408183
learning rate:  0.0008
val: 1 0.38446858525276184
val: 2 0.3848412036895752
val: 3 0.3864719569683075
val: 4 0.3850299119949341
val: 5 0.3817025125026703
val: 6 0.38931795954704285
val: 7 0.3859447240829468
val: 8 0.3794303238391876
val: 9 0.38479384779930115
val: 10 0.38894784450531006
val: 11 0.3858601152896881
val: 12 0.38917076587677
val: 13 0.3819369375705719
val: 14 0.3946698009967804
val: 15 0.38825371861457825
val: 16 0.38957032561302185
val: 17 0.3927212059497833
val: 18 0.387827068567276
val: 19 0.3824973404407501
val: 20 0.3967162072658539
val_Epoch:[ 15 ] val_loss: 0.38700861781835555 2022-07-01 17:06:10.370640
start training 2022-07-01 17:06:10.475821
Epoch:[ 16 0 ] loss: 0.3761429488658905 2022-07-01 17:06:25.122186
Epoch:[ 16 1 ] loss: 0.3756415545940399 2022-07-01 17:06:25.549859
Epoch:[ 16 2 ] loss: 0.3763812482357025 2022-07-01 17:06:25.959963
Epoch:[ 16 3 ] loss: 0.3759113550186157 2022-07-01 17:06:26.375560
Epoch:[ 16 4 ] loss: 0.37681853771209717 2022-07-01 17:06:26.790426
Epoch:[ 16 5 ] loss: 0.3775835335254669 2022-07-01 17:06:27.208721
Epoch:[ 16 6 ] loss: 0.3767458498477936 2022-07-01 17:06:27.625081
Epoch:[ 16 7 ] loss: 0.37702420353889465 2022-07-01 17:06:28.042102
Epoch:[ 16 8 ] loss: 0.377055287361145 2022-07-01 17:06:28.464192
Epoch:[ 16 9 ] loss: 0.3772904872894287 2022-07-01 17:06:28.877441
Epoch:[ 16 10 ] loss: 0.37827256321907043 2022-07-01 17:06:29.293252
Epoch:[ 16 11 ] loss: 0.37687256932258606 2022-07-01 17:06:29.707443
Epoch:[ 16 12 ] loss: 0.3761771619319916 2022-07-01 17:06:30.123001
Epoch:[ 16 13 ] loss: 0.37755241990089417 2022-07-01 17:06:30.538586
Epoch:[ 16 14 ] loss: 0.37802979350090027 2022-07-01 17:06:30.955328
Epoch:[ 16 15 ] loss: 0.37666115164756775 2022-07-01 17:06:31.373125
Epoch:[ 16 16 ] loss: 0.37709805369377136 2022-07-01 17:06:37.074827
Epoch:[ 16 17 ] loss: 0.37886419892311096 2022-07-01 17:06:37.494976
Epoch:[ 16 18 ] loss: 0.3793691098690033 2022-07-01 17:06:37.919012
Epoch:[ 16 19 ] loss: 0.3756035566329956 2022-07-01 17:06:38.332837
Training_Epoch:[ 16 ] Training_loss: 0.3770547792315483 2022-07-01 17:06:38.333527
learning rate:  0.0008
netparams have been saved once 16
val: 1 0.39551663398742676
val: 2 0.3885640799999237
val: 3 0.3830290734767914
val: 4 0.3914993703365326
val: 5 0.3846166431903839
val: 6 0.3872922956943512
val: 7 0.3814108073711395
val: 8 0.38740649819374084
val: 9 0.389466255903244
val: 10 0.38298189640045166
val: 11 0.3800259232521057
val: 12 0.39244404435157776
val: 13 0.38749536871910095
val: 14 0.38657811284065247
val: 15 0.39414533972740173
val: 16 0.39058297872543335
val: 17 0.38606613874435425
val: 18 0.3848055601119995
val: 19 0.3843352496623993
val: 20 0.39100462198257446
val_Epoch:[ 16 ] val_loss: 0.38746334463357923 2022-07-01 17:06:42.259002
start training 2022-07-01 17:06:42.364621
Epoch:[ 17 0 ] loss: 0.37688010931015015 2022-07-01 17:06:57.411883
Epoch:[ 17 1 ] loss: 0.37543195486068726 2022-07-01 17:06:57.827977
Epoch:[ 17 2 ] loss: 0.37636277079582214 2022-07-01 17:06:58.242147
Epoch:[ 17 3 ] loss: 0.3772207498550415 2022-07-01 17:06:58.657504
Epoch:[ 17 4 ] loss: 0.37851259112358093 2022-07-01 17:06:59.070869
Epoch:[ 17 5 ] loss: 0.3769756555557251 2022-07-01 17:06:59.484289
Epoch:[ 17 6 ] loss: 0.3756548762321472 2022-07-01 17:06:59.898372
Epoch:[ 17 7 ] loss: 0.3782900869846344 2022-07-01 17:07:00.313821
Epoch:[ 17 8 ] loss: 0.37954211235046387 2022-07-01 17:07:00.729221
Epoch:[ 17 9 ] loss: 0.3761095404624939 2022-07-01 17:07:01.150200
Epoch:[ 17 10 ] loss: 0.3772149384021759 2022-07-01 17:07:01.563243
Epoch:[ 17 11 ] loss: 0.3785553276538849 2022-07-01 17:07:01.985567
Epoch:[ 17 12 ] loss: 0.3767205774784088 2022-07-01 17:07:02.399352
Epoch:[ 17 13 ] loss: 0.3769013285636902 2022-07-01 17:07:02.812105
Epoch:[ 17 14 ] loss: 0.37738871574401855 2022-07-01 17:07:03.227851
Epoch:[ 17 15 ] loss: 0.3750397562980652 2022-07-01 17:07:03.643933
Epoch:[ 17 16 ] loss: 0.3766181766986847 2022-07-01 17:07:08.763925
Epoch:[ 17 17 ] loss: 0.3780190050601959 2022-07-01 17:07:09.180836
Epoch:[ 17 18 ] loss: 0.37486210465431213 2022-07-01 17:07:09.603150
Epoch:[ 17 19 ] loss: 0.37591052055358887 2022-07-01 17:07:10.018312
Training_Epoch:[ 17 ] Training_loss: 0.3769105449318886 2022-07-01 17:07:10.019074
learning rate:  0.0008
val: 1 0.3803834915161133
val: 2 0.38654202222824097
val: 3 0.3937992453575134
val: 4 0.3833840787410736
val: 5 0.38699179887771606
val: 6 0.3915689289569855
val: 7 0.3799649775028229
val: 8 0.38526833057403564
val: 9 0.3876069188117981
val: 10 0.3837016820907593
val: 11 0.38295015692710876
val: 12 0.38129010796546936
val: 13 0.3847721815109253
val: 14 0.3822407126426697
val: 15 0.3801097571849823
val: 16 0.3942404091358185
val: 17 0.3904372751712799
val: 18 0.3822437822818756
val: 19 0.3856338858604431
val: 20 0.38786864280700684
val_Epoch:[ 17 ] val_loss: 0.3855499193072319 2022-07-01 17:07:13.880143
start training 2022-07-01 17:07:13.983179
Epoch:[ 18 0 ] loss: 0.37578529119491577 2022-07-01 17:07:28.628367
Epoch:[ 18 1 ] loss: 0.3760172724723816 2022-07-01 17:07:29.064725
Epoch:[ 18 2 ] loss: 0.3757668137550354 2022-07-01 17:07:29.480809
Epoch:[ 18 3 ] loss: 0.37717267870903015 2022-07-01 17:07:29.895926
Epoch:[ 18 4 ] loss: 0.3752236068248749 2022-07-01 17:07:30.311613
Epoch:[ 18 5 ] loss: 0.3757598400115967 2022-07-01 17:07:30.721834
Epoch:[ 18 6 ] loss: 0.37599772214889526 2022-07-01 17:07:31.137319
Epoch:[ 18 7 ] loss: 0.37446093559265137 2022-07-01 17:07:31.551999
Epoch:[ 18 8 ] loss: 0.37403807044029236 2022-07-01 17:07:31.969397
Epoch:[ 18 9 ] loss: 0.3747154474258423 2022-07-01 17:07:32.386427
Epoch:[ 18 10 ] loss: 0.37647852301597595 2022-07-01 17:07:32.805453
Epoch:[ 18 11 ] loss: 0.37757062911987305 2022-07-01 17:07:33.227276
Epoch:[ 18 12 ] loss: 0.3775727450847626 2022-07-01 17:07:33.645110
Epoch:[ 18 13 ] loss: 0.3748510479927063 2022-07-01 17:07:34.054623
Epoch:[ 18 14 ] loss: 0.375184565782547 2022-07-01 17:07:34.468850
Epoch:[ 18 15 ] loss: 0.37653642892837524 2022-07-01 17:07:34.886170
Epoch:[ 18 16 ] loss: 0.3763313591480255 2022-07-01 17:07:40.293749
Epoch:[ 18 17 ] loss: 0.3751509487628937 2022-07-01 17:07:40.705211
Epoch:[ 18 18 ] loss: 0.37618184089660645 2022-07-01 17:07:41.121738
Epoch:[ 18 19 ] loss: 0.37635719776153564 2022-07-01 17:07:41.538505
Training_Epoch:[ 18 ] Training_loss: 0.37585764825344087 2022-07-01 17:07:41.539426
learning rate:  0.0008
netparams have been saved once 18
val: 1 0.381523460149765
val: 2 0.3859761655330658
val: 3 0.38386476039886475
val: 4 0.380750447511673
val: 5 0.3859347999095917
val: 6 0.3899874687194824
val: 7 0.3861016035079956
val: 8 0.3868127763271332
val: 9 0.3892357349395752
val: 10 0.38564586639404297
val: 11 0.3864646553993225
val: 12 0.38869747519493103
val: 13 0.3811301290988922
val: 14 0.388294517993927
val: 15 0.38853585720062256
val: 16 0.3864983916282654
val: 17 0.3846469819545746
val: 18 0.38187935948371887
val: 19 0.3842717707157135
val: 20 0.38350778818130493
val_Epoch:[ 18 ] val_loss: 0.3854880005121231 2022-07-01 17:07:45.617321
start training 2022-07-01 17:07:45.744010
Epoch:[ 19 0 ] loss: 0.374406099319458 2022-07-01 17:08:00.603045
Epoch:[ 19 1 ] loss: 0.3766403794288635 2022-07-01 17:08:01.017323
Epoch:[ 19 2 ] loss: 0.3752802014350891 2022-07-01 17:08:01.439886
Epoch:[ 19 3 ] loss: 0.37579235434532166 2022-07-01 17:08:01.856257
Epoch:[ 19 4 ] loss: 0.3741837739944458 2022-07-01 17:08:02.278268
Epoch:[ 19 5 ] loss: 0.37540844082832336 2022-07-01 17:08:02.694896
Epoch:[ 19 6 ] loss: 0.3750033974647522 2022-07-01 17:08:03.111887
Epoch:[ 19 7 ] loss: 0.3753077983856201 2022-07-01 17:08:03.525402
Epoch:[ 19 8 ] loss: 0.3746928572654724 2022-07-01 17:08:03.942117
Epoch:[ 19 9 ] loss: 0.3779933750629425 2022-07-01 17:08:04.358015
Epoch:[ 19 10 ] loss: 0.37458378076553345 2022-07-01 17:08:04.773960
Epoch:[ 19 11 ] loss: 0.37441009283065796 2022-07-01 17:08:05.190808
Epoch:[ 19 12 ] loss: 0.3768596351146698 2022-07-01 17:08:05.606388
Epoch:[ 19 13 ] loss: 0.37676355242729187 2022-07-01 17:08:06.024028
Epoch:[ 19 14 ] loss: 0.37386301159858704 2022-07-01 17:08:06.445594
Epoch:[ 19 15 ] loss: 0.37439200282096863 2022-07-01 17:08:06.859297
Epoch:[ 19 16 ] loss: 0.3752506375312805 2022-07-01 17:08:12.611818
Epoch:[ 19 17 ] loss: 0.37542861700057983 2022-07-01 17:08:13.032837
Epoch:[ 19 18 ] loss: 0.3756118416786194 2022-07-01 17:08:13.449379
Epoch:[ 19 19 ] loss: 0.3748584985733032 2022-07-01 17:08:13.869118
Training_Epoch:[ 19 ] Training_loss: 0.37533651739358903 2022-07-01 17:08:13.870195
learning rate:  0.0008
val: 1 0.37802204489707947
val: 2 0.38220515847206116
val: 3 0.38549330830574036
val: 4 0.3844321072101593
val: 5 0.3801670968532562
val: 6 0.3828142285346985
val: 7 0.38576751947402954
val: 8 0.3864521086215973
val: 9 0.3860575258731842
val: 10 0.3837176561355591
val: 11 0.3861013650894165
val: 12 0.38755112886428833
val: 13 0.3880222737789154
val: 14 0.38033974170684814
val: 15 0.39031484723091125
val: 16 0.38436180353164673
val: 17 0.3898751437664032
val: 18 0.39413872361183167
val: 19 0.3867790699005127
val: 20 0.38477379083633423
val_Epoch:[ 19 ] val_loss: 0.3853693321347237 2022-07-01 17:08:18.148180
start training 2022-07-01 17:08:18.279521
Epoch:[ 20 0 ] loss: 0.37531089782714844 2022-07-01 17:08:32.908397
Epoch:[ 20 1 ] loss: 0.3751814365386963 2022-07-01 17:08:33.346793
Epoch:[ 20 2 ] loss: 0.37432658672332764 2022-07-01 17:08:33.767628
Epoch:[ 20 3 ] loss: 0.3747953772544861 2022-07-01 17:08:34.184084
Epoch:[ 20 4 ] loss: 0.37556132674217224 2022-07-01 17:08:34.600844
Epoch:[ 20 5 ] loss: 0.37499669194221497 2022-07-01 17:08:35.023611
Epoch:[ 20 6 ] loss: 0.37487444281578064 2022-07-01 17:08:35.439782
Epoch:[ 20 7 ] loss: 0.3759579658508301 2022-07-01 17:08:35.854830
Epoch:[ 20 8 ] loss: 0.37411990761756897 2022-07-01 17:08:36.268861
Epoch:[ 20 9 ] loss: 0.37450844049453735 2022-07-01 17:08:36.682128
Epoch:[ 20 10 ] loss: 0.3757442533969879 2022-07-01 17:08:37.100961
Epoch:[ 20 11 ] loss: 0.3752965033054352 2022-07-01 17:08:37.519426
Epoch:[ 20 12 ] loss: 0.3755533695220947 2022-07-01 17:08:37.938579
Epoch:[ 20 13 ] loss: 0.3753996193408966 2022-07-01 17:08:38.352524
Epoch:[ 20 14 ] loss: 0.3755287528038025 2022-07-01 17:08:38.766833
Epoch:[ 20 15 ] loss: 0.3760528862476349 2022-07-01 17:08:39.184224
Epoch:[ 20 16 ] loss: 0.37749263644218445 2022-07-01 17:08:44.570265
Epoch:[ 20 17 ] loss: 0.37537533044815063 2022-07-01 17:08:45.290474
Epoch:[ 20 18 ] loss: 0.376640647649765 2022-07-01 17:08:45.713694
Epoch:[ 20 19 ] loss: 0.3754080533981323 2022-07-01 17:08:46.129587
Training_Epoch:[ 20 ] Training_loss: 0.3754062563180923 2022-07-01 17:08:46.130230
learning rate:  0.0008
netparams have been saved once 20
val: 1 0.38405823707580566
val: 2 0.3855619430541992
val: 3 0.3895267844200134
val: 4 0.38775163888931274
val: 5 0.3823993504047394
val: 6 0.38302114605903625
val: 7 0.38811376690864563
val: 8 0.3807252049446106
val: 9 0.3884633779525757
val: 10 0.3868587911128998
val: 11 0.38853588700294495
val: 12 0.3809588551521301
val: 13 0.39245355129241943
val: 14 0.3872687518596649
val: 15 0.3858336806297302
val: 16 0.38553112745285034
val: 17 0.390437513589859
val: 18 0.3866174817085266
val: 19 0.38982969522476196
val: 20 0.38631048798561096
val_Epoch:[ 20 ] val_loss: 0.38651286363601683 2022-07-01 17:08:50.039960
start training 2022-07-01 17:08:50.147763
Epoch:[ 21 0 ] loss: 0.3755212724208832 2022-07-01 17:09:05.264469
Epoch:[ 21 1 ] loss: 0.3748043477535248 2022-07-01 17:09:05.678096
Epoch:[ 21 2 ] loss: 0.37382254004478455 2022-07-01 17:09:06.094883
Epoch:[ 21 3 ] loss: 0.37452709674835205 2022-07-01 17:09:06.515573
Epoch:[ 21 4 ] loss: 0.37426021695137024 2022-07-01 17:09:06.932343
Epoch:[ 21 5 ] loss: 0.3741351068019867 2022-07-01 17:09:07.347856
Epoch:[ 21 6 ] loss: 0.37455639243125916 2022-07-01 17:09:07.763024
Epoch:[ 21 7 ] loss: 0.37392905354499817 2022-07-01 17:09:08.187713
Epoch:[ 21 8 ] loss: 0.3736295998096466 2022-07-01 17:09:08.605930
Epoch:[ 21 9 ] loss: 0.3753138780593872 2022-07-01 17:09:09.018994
Epoch:[ 21 10 ] loss: 0.37529483437538147 2022-07-01 17:09:09.433613
Epoch:[ 21 11 ] loss: 0.37398847937583923 2022-07-01 17:09:09.852337
Epoch:[ 21 12 ] loss: 0.3737695515155792 2022-07-01 17:09:10.269200
Epoch:[ 21 13 ] loss: 0.37337905168533325 2022-07-01 17:09:10.683121
Epoch:[ 21 14 ] loss: 0.3751031160354614 2022-07-01 17:09:11.096090
Epoch:[ 21 15 ] loss: 0.3751099407672882 2022-07-01 17:09:11.512144
Epoch:[ 21 16 ] loss: 0.37548762559890747 2022-07-01 17:09:17.152395
Epoch:[ 21 17 ] loss: 0.3741980791091919 2022-07-01 17:09:17.659552
Epoch:[ 21 18 ] loss: 0.3750324249267578 2022-07-01 17:09:18.165637
Epoch:[ 21 19 ] loss: 0.3752615451812744 2022-07-01 17:09:18.669504
Training_Epoch:[ 21 ] Training_loss: 0.3745562076568604 2022-07-01 17:09:18.670201
learning rate:  0.00064
val: 1 0.3858141005039215
val: 2 0.38341811299324036
val: 3 0.38660579919815063
val: 4 0.3820493817329407
val: 5 0.38793113827705383
val: 6 0.38965800404548645
val: 7 0.38378390669822693
val: 8 0.380842387676239
val: 9 0.3857249915599823
val: 10 0.38604190945625305
val: 11 0.39513254165649414
val: 12 0.3896826505661011
val: 13 0.3836747705936432
val: 14 0.3860885202884674
val: 15 0.38403359055519104
val: 16 0.39012178778648376
val: 17 0.38791367411613464
val: 18 0.38958683609962463
val: 19 0.3838476240634918
val: 20 0.3862404525279999
val_Epoch:[ 21 ] val_loss: 0.3864096090197563 2022-07-01 17:09:22.643565
start training 2022-07-01 17:09:22.757366
Epoch:[ 22 0 ] loss: 0.3743884861469269 2022-07-01 17:09:38.375543
Epoch:[ 22 1 ] loss: 0.3738057315349579 2022-07-01 17:09:38.886687
Epoch:[ 22 2 ] loss: 0.3749347925186157 2022-07-01 17:09:39.391716
Epoch:[ 22 3 ] loss: 0.37427276372909546 2022-07-01 17:09:39.897948
Epoch:[ 22 4 ] loss: 0.3749324083328247 2022-07-01 17:09:40.398238
Epoch:[ 22 5 ] loss: 0.37493884563446045 2022-07-01 17:09:40.900589
Epoch:[ 22 6 ] loss: 0.37499919533729553 2022-07-01 17:09:41.404838
Epoch:[ 22 7 ] loss: 0.37363991141319275 2022-07-01 17:09:41.909697
Epoch:[ 22 8 ] loss: 0.37318506836891174 2022-07-01 17:09:42.409905
Epoch:[ 22 9 ] loss: 0.3751642405986786 2022-07-01 17:09:42.912996
Epoch:[ 22 10 ] loss: 0.3719378113746643 2022-07-01 17:09:43.422695
Epoch:[ 22 11 ] loss: 0.37435293197631836 2022-07-01 17:09:43.924795
Epoch:[ 22 12 ] loss: 0.3739500045776367 2022-07-01 17:09:44.431764
Epoch:[ 22 13 ] loss: 0.37412330508232117 2022-07-01 17:09:44.939096
Epoch:[ 22 14 ] loss: 0.3734078109264374 2022-07-01 17:09:45.445973
Epoch:[ 22 15 ] loss: 0.3736707866191864 2022-07-01 17:09:45.952118
Epoch:[ 22 16 ] loss: 0.3743324279785156 2022-07-01 17:09:50.712228
Epoch:[ 22 17 ] loss: 0.3743979036808014 2022-07-01 17:09:51.218010
Epoch:[ 22 18 ] loss: 0.37235206365585327 2022-07-01 17:09:51.725693
Epoch:[ 22 19 ] loss: 0.3749365210533142 2022-07-01 17:09:52.231343
Training_Epoch:[ 22 ] Training_loss: 0.37408615052700045 2022-07-01 17:09:52.232001
learning rate:  0.00064
netparams have been saved once 22
val: 1 0.3792248070240021
val: 2 0.38004958629608154
val: 3 0.3894531726837158
val: 4 0.3806999623775482
val: 5 0.3817833364009857
val: 6 0.38099944591522217
val: 7 0.3816263973712921
val: 8 0.3842886984348297
val: 9 0.387617290019989
val: 10 0.3891696631908417
val: 11 0.3827594220638275
val: 12 0.3815028667449951
val: 13 0.3864234685897827
val: 14 0.38230621814727783
val: 15 0.3860766887664795
val: 16 0.38638314604759216
val: 17 0.3903869092464447
val: 18 0.38625645637512207
val: 19 0.38881412148475647
val: 20 0.3903593420982361
val_Epoch:[ 22 ] val_loss: 0.3848090499639511 2022-07-01 17:09:56.194033
start training 2022-07-01 17:09:56.298425
Epoch:[ 23 0 ] loss: 0.37531590461730957 2022-07-01 17:10:11.450834
Epoch:[ 23 1 ] loss: 0.37487220764160156 2022-07-01 17:10:11.955869
Epoch:[ 23 2 ] loss: 0.3742821514606476 2022-07-01 17:10:12.457226
Epoch:[ 23 3 ] loss: 0.37458735704421997 2022-07-01 17:10:12.960737
Epoch:[ 23 4 ] loss: 0.37455812096595764 2022-07-01 17:10:13.458379
Epoch:[ 23 5 ] loss: 0.37371695041656494 2022-07-01 17:10:13.955849
Epoch:[ 23 6 ] loss: 0.3754129409790039 2022-07-01 17:10:14.456243
Epoch:[ 23 7 ] loss: 0.37347355484962463 2022-07-01 17:10:14.956778
Epoch:[ 23 8 ] loss: 0.37476783990859985 2022-07-01 17:10:15.457483
Epoch:[ 23 9 ] loss: 0.37158796191215515 2022-07-01 17:10:15.964216
Epoch:[ 23 10 ] loss: 0.37263062596321106 2022-07-01 17:10:16.461667
Epoch:[ 23 11 ] loss: 0.3728751242160797 2022-07-01 17:10:16.959890
Epoch:[ 23 12 ] loss: 0.3740154802799225 2022-07-01 17:10:17.457303
Epoch:[ 23 13 ] loss: 0.37286749482154846 2022-07-01 17:10:17.959906
Epoch:[ 23 14 ] loss: 0.3739863932132721 2022-07-01 17:10:18.462857
Epoch:[ 23 15 ] loss: 0.37296006083488464 2022-07-01 17:10:18.964647
Epoch:[ 23 16 ] loss: 0.3729742765426636 2022-07-01 17:10:23.134811
Epoch:[ 23 17 ] loss: 0.37272167205810547 2022-07-01 17:10:23.633451
Epoch:[ 23 18 ] loss: 0.37349045276641846 2022-07-01 17:10:24.144420
Epoch:[ 23 19 ] loss: 0.3744533956050873 2022-07-01 17:10:24.646910
Training_Epoch:[ 23 ] Training_loss: 0.3737774983048439 2022-07-01 17:10:24.647662
learning rate:  0.00064
val: 1 0.38405442237854004
val: 2 0.38618549704551697
val: 3 0.3824182152748108
val: 4 0.3882809281349182
val: 5 0.3901761472225189
val: 6 0.3792361915111542
val: 7 0.38781386613845825
val: 8 0.384029358625412
val: 9 0.3944641351699829
val: 10 0.3820578455924988
val: 11 0.3862527906894684
val: 12 0.3825555145740509
val: 13 0.38204458355903625
val: 14 0.39230018854141235
val: 15 0.38917335867881775
val: 16 0.38396593928337097
val: 17 0.3890589475631714
val: 18 0.38345804810523987
val: 19 0.3933427035808563
val: 20 0.38023415207862854
val_Epoch:[ 23 ] val_loss: 0.3860551416873932 2022-07-01 17:10:28.645293
start training 2022-07-01 17:10:28.747038
Epoch:[ 24 0 ] loss: 0.37325555086135864 2022-07-01 17:10:43.522289
Epoch:[ 24 1 ] loss: 0.3728086054325104 2022-07-01 17:10:44.033758
Epoch:[ 24 2 ] loss: 0.3739028573036194 2022-07-01 17:10:44.535738
Epoch:[ 24 3 ] loss: 0.37327682971954346 2022-07-01 17:10:45.037695
Epoch:[ 24 4 ] loss: 0.37391069531440735 2022-07-01 17:10:45.540210
Epoch:[ 24 5 ] loss: 0.3745119869709015 2022-07-01 17:10:46.041791
Epoch:[ 24 6 ] loss: 0.37305036187171936 2022-07-01 17:10:46.542217
Epoch:[ 24 7 ] loss: 0.373498797416687 2022-07-01 17:10:47.047063
Epoch:[ 24 8 ] loss: 0.3755849599838257 2022-07-01 17:10:47.551062
Epoch:[ 24 9 ] loss: 0.37285086512565613 2022-07-01 17:10:48.055548
Epoch:[ 24 10 ] loss: 0.3737682104110718 2022-07-01 17:10:48.560822
Epoch:[ 24 11 ] loss: 0.37406840920448303 2022-07-01 17:10:49.064321
Epoch:[ 24 12 ] loss: 0.37208592891693115 2022-07-01 17:10:49.566655
Epoch:[ 24 13 ] loss: 0.37375423312187195 2022-07-01 17:10:50.073386
Epoch:[ 24 14 ] loss: 0.37128397822380066 2022-07-01 17:10:50.577176
Epoch:[ 24 15 ] loss: 0.37284982204437256 2022-07-01 17:10:51.079960
Epoch:[ 24 16 ] loss: 0.3740881383419037 2022-07-01 17:10:55.234654
Epoch:[ 24 17 ] loss: 0.37405914068222046 2022-07-01 17:10:55.732658
Epoch:[ 24 18 ] loss: 0.3731122612953186 2022-07-01 17:10:56.235688
Epoch:[ 24 19 ] loss: 0.3734050989151001 2022-07-01 17:10:56.744868
Training_Epoch:[ 24 ] Training_loss: 0.37345633655786514 2022-07-01 17:10:56.745607
learning rate:  0.00064
netparams have been saved once 24
val: 1 0.38938677310943604
val: 2 0.3840008080005646
val: 3 0.38037109375
val: 4 0.3862336575984955
val: 5 0.37861448526382446
val: 6 0.38424980640411377
val: 7 0.38401955366134644
val: 8 0.3921569585800171
val: 9 0.3869607150554657
val: 10 0.38369399309158325
val: 11 0.3868725001811981
val: 12 0.3870461583137512
val: 13 0.38335496187210083
val: 14 0.3957307040691376
val: 15 0.3861290216445923
val: 16 0.38601312041282654
val: 17 0.3837982714176178
val: 18 0.3937317132949829
val: 19 0.3873141407966614
val: 20 0.38246792554855347
val_Epoch:[ 24 ] val_loss: 0.38610731810331345 2022-07-01 17:11:00.697616
start training 2022-07-01 17:11:00.800475
Epoch:[ 25 0 ] loss: 0.3710581064224243 2022-07-01 17:11:15.556172
Epoch:[ 25 1 ] loss: 0.3727495074272156 2022-07-01 17:11:15.971668
Epoch:[ 25 2 ] loss: 0.3734953999519348 2022-07-01 17:11:16.387287
Epoch:[ 25 3 ] loss: 0.37240365147590637 2022-07-01 17:11:16.802048
Epoch:[ 25 4 ] loss: 0.3729398846626282 2022-07-01 17:11:17.217031
Epoch:[ 25 5 ] loss: 0.3730701804161072 2022-07-01 17:11:17.632147
Epoch:[ 25 6 ] loss: 0.37250205874443054 2022-07-01 17:11:18.049267
Epoch:[ 25 7 ] loss: 0.37422633171081543 2022-07-01 17:11:18.462550
Epoch:[ 25 8 ] loss: 0.374948114156723 2022-07-01 17:11:18.878707
Epoch:[ 25 9 ] loss: 0.37358859181404114 2022-07-01 17:11:19.293524
Epoch:[ 25 10 ] loss: 0.374380499124527 2022-07-01 17:11:19.714474
Epoch:[ 25 11 ] loss: 0.3720785975456238 2022-07-01 17:11:20.127626
Epoch:[ 25 12 ] loss: 0.3735724091529846 2022-07-01 17:11:20.542048
Epoch:[ 25 13 ] loss: 0.37276893854141235 2022-07-01 17:11:20.955139
Epoch:[ 25 14 ] loss: 0.37287238240242004 2022-07-01 17:11:21.369196
Epoch:[ 25 15 ] loss: 0.37293100357055664 2022-07-01 17:11:21.791043
Epoch:[ 25 16 ] loss: 0.3746161460876465 2022-07-01 17:11:27.424170
Epoch:[ 25 17 ] loss: 0.3725720942020416 2022-07-01 17:11:28.318314
Epoch:[ 25 18 ] loss: 0.3736671805381775 2022-07-01 17:11:28.821878
Epoch:[ 25 19 ] loss: 0.3735555112361908 2022-07-01 17:11:29.315214
Training_Epoch:[ 25 ] Training_loss: 0.3731998294591904 2022-07-01 17:11:29.315883
learning rate:  0.00064
val: 1 0.38475272059440613
val: 2 0.3806661367416382
val: 3 0.39262905716896057
val: 4 0.38807937502861023
val: 5 0.38467252254486084
val: 6 0.38566574454307556
val: 7 0.39252907037734985
val: 8 0.39162954688072205
val: 9 0.38164976239204407
val: 10 0.388640820980072
val: 11 0.3860446810722351
val: 12 0.3796369135379791
val: 13 0.3812519609928131
val: 14 0.38826921582221985
val: 15 0.38587871193885803
val: 16 0.38425543904304504
val: 17 0.390083909034729
val: 18 0.39406806230545044
val: 19 0.3914947509765625
val: 20 0.37874284386634827
val_Epoch:[ 25 ] val_loss: 0.386532062292099 2022-07-01 17:11:33.350471
start training 2022-07-01 17:11:33.454885
Epoch:[ 26 0 ] loss: 0.3736875057220459 2022-07-01 17:11:49.333535
Epoch:[ 26 1 ] loss: 0.37164297699928284 2022-07-01 17:11:49.824831
Epoch:[ 26 2 ] loss: 0.3711085021495819 2022-07-01 17:11:50.324559
Epoch:[ 26 3 ] loss: 0.3725256025791168 2022-07-01 17:11:50.818385
Epoch:[ 26 4 ] loss: 0.37480518221855164 2022-07-01 17:11:51.283735
Epoch:[ 26 5 ] loss: 0.3724624812602997 2022-07-01 17:11:51.781425
Epoch:[ 26 6 ] loss: 0.37305694818496704 2022-07-01 17:11:52.274437
Epoch:[ 26 7 ] loss: 0.3725224435329437 2022-07-01 17:11:52.768589
Epoch:[ 26 8 ] loss: 0.3715832829475403 2022-07-01 17:11:53.263137
Epoch:[ 26 9 ] loss: 0.37262091040611267 2022-07-01 17:11:53.760638
Epoch:[ 26 10 ] loss: 0.3739365041255951 2022-07-01 17:11:54.258723
Epoch:[ 26 11 ] loss: 0.37423762679100037 2022-07-01 17:11:54.756729
Epoch:[ 26 12 ] loss: 0.3725261092185974 2022-07-01 17:11:55.250180
Epoch:[ 26 13 ] loss: 0.3735085427761078 2022-07-01 17:11:55.744847
Epoch:[ 26 14 ] loss: 0.3726685345172882 2022-07-01 17:11:56.239052
Epoch:[ 26 15 ] loss: 0.3727385997772217 2022-07-01 17:11:56.734404
Epoch:[ 26 16 ] loss: 0.3732685446739197 2022-07-01 17:12:01.679644
Epoch:[ 26 17 ] loss: 0.37391018867492676 2022-07-01 17:12:02.179705
Epoch:[ 26 18 ] loss: 0.3727700114250183 2022-07-01 17:12:02.682157
Epoch:[ 26 19 ] loss: 0.374239981174469 2022-07-01 17:12:03.175280
Training_Epoch:[ 26 ] Training_loss: 0.3729910239577293 2022-07-01 17:12:03.175959
learning rate:  0.00064
netparams have been saved once 26
val: 1 0.38605326414108276
val: 2 0.38468801975250244
val: 3 0.38598376512527466
val: 4 0.39105039834976196
val: 5 0.3807484805583954
val: 6 0.37786319851875305
val: 7 0.3803648054599762
val: 8 0.384776771068573
val: 9 0.3842926323413849
val: 10 0.38528528809547424
val: 11 0.38269713521003723
val: 12 0.3820313811302185
val: 13 0.39136773347854614
val: 14 0.3863198757171631
val: 15 0.3928554952144623
val: 16 0.3852088153362274
val: 17 0.38821855187416077
val: 18 0.38468310236930847
val: 19 0.38668009638786316
val: 20 0.3903505206108093
val_Epoch:[ 26 ] val_loss: 0.38557596653699877 2022-07-01 17:12:07.169070
start training 2022-07-01 17:12:07.273882
Epoch:[ 27 0 ] loss: 0.37263014912605286 2022-07-01 17:12:21.881716
Epoch:[ 27 1 ] loss: 0.37347567081451416 2022-07-01 17:12:22.469162
Epoch:[ 27 2 ] loss: 0.371776282787323 2022-07-01 17:12:22.961968
Epoch:[ 27 3 ] loss: 0.37198853492736816 2022-07-01 17:12:23.460811
Epoch:[ 27 4 ] loss: 0.37120941281318665 2022-07-01 17:12:23.958322
Epoch:[ 27 5 ] loss: 0.3731524348258972 2022-07-01 17:12:24.453285
Epoch:[ 27 6 ] loss: 0.3709415793418884 2022-07-01 17:12:24.947470
Epoch:[ 27 7 ] loss: 0.3728540539741516 2022-07-01 17:12:25.439350
Epoch:[ 27 8 ] loss: 0.3732893764972687 2022-07-01 17:12:25.932392
Epoch:[ 27 9 ] loss: 0.3719249367713928 2022-07-01 17:12:26.432800
Epoch:[ 27 10 ] loss: 0.37399914860725403 2022-07-01 17:12:26.929740
Epoch:[ 27 11 ] loss: 0.37310531735420227 2022-07-01 17:12:27.427042
Epoch:[ 27 12 ] loss: 0.3729651868343353 2022-07-01 17:12:27.924388
Epoch:[ 27 13 ] loss: 0.3730597198009491 2022-07-01 17:12:28.417988
Epoch:[ 27 14 ] loss: 0.37342190742492676 2022-07-01 17:12:28.910806
Epoch:[ 27 15 ] loss: 0.3733028769493103 2022-07-01 17:12:29.403351
Epoch:[ 27 16 ] loss: 0.37210941314697266 2022-07-01 17:12:33.894158
Epoch:[ 27 17 ] loss: 0.37326696515083313 2022-07-01 17:12:34.393442
Epoch:[ 27 18 ] loss: 0.37313106656074524 2022-07-01 17:12:34.890517
Epoch:[ 27 19 ] loss: 0.3727324903011322 2022-07-01 17:12:35.391690
Training_Epoch:[ 27 ] Training_loss: 0.37271682620048524 2022-07-01 17:12:35.392407
learning rate:  0.00064
val: 1 0.38994279503822327
val: 2 0.38805052638053894
val: 3 0.39146602153778076
val: 4 0.3894243836402893
val: 5 0.3874046802520752
val: 6 0.3886260390281677
val: 7 0.38360291719436646
val: 8 0.37782976031303406
val: 9 0.38122695684432983
val: 10 0.3816530108451843
val: 11 0.39081043004989624
val: 12 0.3821897804737091
val: 13 0.39667198061943054
val: 14 0.38374263048171997
val: 15 0.39257559180259705
val: 16 0.39269885420799255
val: 17 0.38816526532173157
val: 18 0.38191190361976624
val: 19 0.3885778486728668
val: 20 0.38834840059280396
val_Epoch:[ 27 ] val_loss: 0.3872459888458252 2022-07-01 17:12:39.345156
start training 2022-07-01 17:12:39.441918
Epoch:[ 28 0 ] loss: 0.37215903401374817 2022-07-01 17:12:54.203320
Epoch:[ 28 1 ] loss: 0.3712053596973419 2022-07-01 17:12:54.695688
Epoch:[ 28 2 ] loss: 0.371748685836792 2022-07-01 17:12:55.188871
Epoch:[ 28 3 ] loss: 0.372549444437027 2022-07-01 17:12:55.682668
Epoch:[ 28 4 ] loss: 0.37224242091178894 2022-07-01 17:12:56.179296
Epoch:[ 28 5 ] loss: 0.3722694516181946 2022-07-01 17:12:56.674551
Epoch:[ 28 6 ] loss: 0.37266841530799866 2022-07-01 17:12:57.168927
Epoch:[ 28 7 ] loss: 0.37289994955062866 2022-07-01 17:12:57.661640
Epoch:[ 28 8 ] loss: 0.3707629144191742 2022-07-01 17:12:58.158089
Epoch:[ 28 9 ] loss: 0.3728879392147064 2022-07-01 17:12:58.650338
Epoch:[ 28 10 ] loss: 0.37185174226760864 2022-07-01 17:12:59.143488
Epoch:[ 28 11 ] loss: 0.3713439106941223 2022-07-01 17:12:59.592316
Epoch:[ 28 12 ] loss: 0.37302106618881226 2022-07-01 17:13:00.089065
Epoch:[ 28 13 ] loss: 0.37231963872909546 2022-07-01 17:13:00.587082
Epoch:[ 28 14 ] loss: 0.3729299008846283 2022-07-01 17:13:01.081435
Epoch:[ 28 15 ] loss: 0.3724566102027893 2022-07-01 17:13:01.575039
Epoch:[ 28 16 ] loss: 0.37246015667915344 2022-07-01 17:13:06.282879
Epoch:[ 28 17 ] loss: 0.374330073595047 2022-07-01 17:13:06.773513
Epoch:[ 28 18 ] loss: 0.37254437804222107 2022-07-01 17:13:07.282678
Epoch:[ 28 19 ] loss: 0.3729216754436493 2022-07-01 17:13:07.777554
Training_Epoch:[ 28 ] Training_loss: 0.37237863838672636 2022-07-01 17:13:07.778235
learning rate:  0.00064
netparams have been saved once 28
val: 1 0.3892030417919159
val: 2 0.38931500911712646
val: 3 0.38344573974609375
val: 4 0.3884690999984741
val: 5 0.3836994767189026
val: 6 0.3919088840484619
val: 7 0.38278529047966003
val: 8 0.3818935751914978
val: 9 0.38913336396217346
val: 10 0.3847227692604065
val: 11 0.38943755626678467
val: 12 0.3863058388233185
val: 13 0.37977978587150574
val: 14 0.38303303718566895
val: 15 0.38729485869407654
val: 16 0.3917367160320282
val: 17 0.386991947889328
val: 18 0.385951966047287
val: 19 0.3865587115287781
val: 20 0.38774746656417847
val_Epoch:[ 28 ] val_loss: 0.38647070676088335 2022-07-01 17:13:11.781800
start training 2022-07-01 17:13:11.879521
Epoch:[ 29 0 ] loss: 0.37136000394821167 2022-07-01 17:13:26.456992
Epoch:[ 29 1 ] loss: 0.37322837114334106 2022-07-01 17:13:26.975125
Epoch:[ 29 2 ] loss: 0.37265709042549133 2022-07-01 17:13:27.467425
Epoch:[ 29 3 ] loss: 0.3709918260574341 2022-07-01 17:13:27.903456
Epoch:[ 29 4 ] loss: 0.3710915744304657 2022-07-01 17:13:28.317929
Epoch:[ 29 5 ] loss: 0.37191617488861084 2022-07-01 17:13:28.732979
Epoch:[ 29 6 ] loss: 0.37182003259658813 2022-07-01 17:13:29.149370
Epoch:[ 29 7 ] loss: 0.37132975459098816 2022-07-01 17:13:29.570039
Epoch:[ 29 8 ] loss: 0.3720757067203522 2022-07-01 17:13:29.984909
Epoch:[ 29 9 ] loss: 0.3705196678638458 2022-07-01 17:13:30.403000
Epoch:[ 29 10 ] loss: 0.37333226203918457 2022-07-01 17:13:30.820077
Epoch:[ 29 11 ] loss: 0.37142622470855713 2022-07-01 17:13:31.234647
Epoch:[ 29 12 ] loss: 0.37173956632614136 2022-07-01 17:13:31.651335
Epoch:[ 29 13 ] loss: 0.37056633830070496 2022-07-01 17:13:32.068930
Epoch:[ 29 14 ] loss: 0.3718021810054779 2022-07-01 17:13:32.485452
Epoch:[ 29 15 ] loss: 0.37287580966949463 2022-07-01 17:13:32.893672
Epoch:[ 29 16 ] loss: 0.37168267369270325 2022-07-01 17:13:38.489297
Epoch:[ 29 17 ] loss: 0.37317362427711487 2022-07-01 17:13:38.905934
Epoch:[ 29 18 ] loss: 0.3714093267917633 2022-07-01 17:13:39.321633
Epoch:[ 29 19 ] loss: 0.37159380316734314 2022-07-01 17:13:39.746913
Training_Epoch:[ 29 ] Training_loss: 0.3718296006321907 2022-07-01 17:13:39.747656
learning rate:  0.00064
val: 1 0.3830808103084564
val: 2 0.38089892268180847
val: 3 0.37977275252342224
val: 4 0.39618682861328125
val: 5 0.38673165440559387
val: 6 0.38170620799064636
val: 7 0.38490548729896545
val: 8 0.3847666084766388
val: 9 0.3773094117641449
val: 10 0.38861939311027527
val: 11 0.3877311050891876
val: 12 0.38134995102882385
val: 13 0.39146435260772705
val: 14 0.39211538434028625
val: 15 0.38405314087867737
val: 16 0.379495233297348
val: 17 0.3898574411869049
val: 18 0.38750630617141724
val: 19 0.3870522379875183
val: 20 0.38864684104919434
val_Epoch:[ 29 ] val_loss: 0.3856625035405159 2022-07-01 17:13:43.595621
start training 2022-07-01 17:13:43.691917
Epoch:[ 30 0 ] loss: 0.3714287281036377 2022-07-01 17:13:58.275830
Epoch:[ 30 1 ] loss: 0.3719785511493683 2022-07-01 17:13:58.751073
Epoch:[ 30 2 ] loss: 0.37273573875427246 2022-07-01 17:13:59.166919
Epoch:[ 30 3 ] loss: 0.3708263039588928 2022-07-01 17:13:59.580724
Epoch:[ 30 4 ] loss: 0.3714160621166229 2022-07-01 17:13:59.995137
Epoch:[ 30 5 ] loss: 0.3706033229827881 2022-07-01 17:14:00.414459
Epoch:[ 30 6 ] loss: 0.37071898579597473 2022-07-01 17:14:00.830731
Epoch:[ 30 7 ] loss: 0.3722533583641052 2022-07-01 17:14:01.246873
Epoch:[ 30 8 ] loss: 0.3721258044242859 2022-07-01 17:14:01.661554
Epoch:[ 30 9 ] loss: 0.3729931712150574 2022-07-01 17:14:02.074327
Epoch:[ 30 10 ] loss: 0.3717822730541229 2022-07-01 17:14:02.488750
Epoch:[ 30 11 ] loss: 0.3704052269458771 2022-07-01 17:14:02.902402
Epoch:[ 30 12 ] loss: 0.3707663416862488 2022-07-01 17:14:03.315706
Epoch:[ 30 13 ] loss: 0.3715146780014038 2022-07-01 17:14:03.732007
Epoch:[ 30 14 ] loss: 0.37210115790367126 2022-07-01 17:14:04.154220
Epoch:[ 30 15 ] loss: 0.3717721402645111 2022-07-01 17:14:04.568412
Epoch:[ 30 16 ] loss: 0.37214338779449463 2022-07-01 17:14:09.959977
Epoch:[ 30 17 ] loss: 0.3722827136516571 2022-07-01 17:14:10.580972
Epoch:[ 30 18 ] loss: 0.37127965688705444 2022-07-01 17:14:10.997896
Epoch:[ 30 19 ] loss: 0.37417635321617126 2022-07-01 17:14:11.414428
Training_Epoch:[ 30 ] Training_loss: 0.3717651978135109 2022-07-01 17:14:11.415076
learning rate:  0.00064
netparams have been saved once 30
val: 1 0.3892481029033661
val: 2 0.38367709517478943
val: 3 0.38693833351135254
val: 4 0.38292351365089417
val: 5 0.38218072056770325
val: 6 0.3882859945297241
val: 7 0.38802942633628845
val: 8 0.38669106364250183
val: 9 0.3818771243095398
val: 10 0.39368656277656555
val: 11 0.3852038085460663
val: 12 0.3886854350566864
val: 13 0.3872852623462677
val: 14 0.37964585423469543
val: 15 0.3808082044124603
val: 16 0.3825843334197998
val: 17 0.38544535636901855
val: 18 0.38365474343299866
val: 19 0.3901095390319824
val: 20 0.385059118270874
val_Epoch:[ 30 ] val_loss: 0.38560097962617873 2022-07-01 17:14:15.356802
start training 2022-07-01 17:14:15.453006
Epoch:[ 31 0 ] loss: 0.37077632546424866 2022-07-01 17:14:29.673191
Epoch:[ 31 1 ] loss: 0.37203603982925415 2022-07-01 17:14:30.111056
Epoch:[ 31 2 ] loss: 0.3705894947052002 2022-07-01 17:14:30.527700
Epoch:[ 31 3 ] loss: 0.37121981382369995 2022-07-01 17:14:30.941791
Epoch:[ 31 4 ] loss: 0.370818555355072 2022-07-01 17:14:31.354605
Epoch:[ 31 5 ] loss: 0.37114545702934265 2022-07-01 17:14:31.768408
Epoch:[ 31 6 ] loss: 0.37165898084640503 2022-07-01 17:14:32.180965
Epoch:[ 31 7 ] loss: 0.37076324224472046 2022-07-01 17:14:32.596655
Epoch:[ 31 8 ] loss: 0.37015843391418457 2022-07-01 17:14:33.013049
Epoch:[ 31 9 ] loss: 0.37010490894317627 2022-07-01 17:14:33.426709
Epoch:[ 31 10 ] loss: 0.37188521027565 2022-07-01 17:14:33.846773
Epoch:[ 31 11 ] loss: 0.3706376552581787 2022-07-01 17:14:34.266709
Epoch:[ 31 12 ] loss: 0.37107062339782715 2022-07-01 17:14:34.679966
Epoch:[ 31 13 ] loss: 0.36967340111732483 2022-07-01 17:14:35.093324
Epoch:[ 31 14 ] loss: 0.37084126472473145 2022-07-01 17:14:35.509516
Epoch:[ 31 15 ] loss: 0.37064486742019653 2022-07-01 17:14:35.924850
Epoch:[ 31 16 ] loss: 0.3724606931209564 2022-07-01 17:14:41.296515
Epoch:[ 31 17 ] loss: 0.3717859387397766 2022-07-01 17:14:41.731766
Epoch:[ 31 18 ] loss: 0.37237435579299927 2022-07-01 17:14:42.147014
Epoch:[ 31 19 ] loss: 0.37116286158561707 2022-07-01 17:14:42.567763
Training_Epoch:[ 31 ] Training_loss: 0.3710904061794281 2022-07-01 17:14:42.568413
learning rate:  0.0005120000000000001
val: 1 0.3891856372356415
val: 2 0.3938838243484497
val: 3 0.3875797390937805
val: 4 0.38151270151138306
val: 5 0.38833943009376526
val: 6 0.39700835943222046
val: 7 0.38382986187934875
val: 8 0.3845894932746887
val: 9 0.3925471901893616
val: 10 0.3850598633289337
val: 11 0.38357990980148315
val: 12 0.38810306787490845
val: 13 0.3802633285522461
val: 14 0.38219374418258667
val: 15 0.38461214303970337
val: 16 0.38663768768310547
val: 17 0.38879111409187317
val: 18 0.3881062865257263
val: 19 0.38668644428253174
val: 20 0.385886013507843
val_Epoch:[ 31 ] val_loss: 0.386919791996479 2022-07-01 17:14:46.418401
start training 2022-07-01 17:14:46.513467
Epoch:[ 32 0 ] loss: 0.3704749047756195 2022-07-01 17:15:01.244755
Epoch:[ 32 1 ] loss: 0.37003183364868164 2022-07-01 17:15:01.667400
Epoch:[ 32 2 ] loss: 0.3707793354988098 2022-07-01 17:15:02.083080
Epoch:[ 32 3 ] loss: 0.3704262673854828 2022-07-01 17:15:02.497660
Epoch:[ 32 4 ] loss: 0.37071290612220764 2022-07-01 17:15:02.912466
Epoch:[ 32 5 ] loss: 0.37111610174179077 2022-07-01 17:15:03.328697
Epoch:[ 32 6 ] loss: 0.37121573090553284 2022-07-01 17:15:03.743730
Epoch:[ 32 7 ] loss: 0.3698402941226959 2022-07-01 17:15:04.157030
Epoch:[ 32 8 ] loss: 0.37041500210762024 2022-07-01 17:15:04.577189
Epoch:[ 32 9 ] loss: 0.3710489273071289 2022-07-01 17:15:04.992904
Epoch:[ 32 10 ] loss: 0.370454877614975 2022-07-01 17:15:05.416377
Epoch:[ 32 11 ] loss: 0.3725857436656952 2022-07-01 17:15:05.832248
Epoch:[ 32 12 ] loss: 0.37016940116882324 2022-07-01 17:15:06.247590
Epoch:[ 32 13 ] loss: 0.37081554532051086 2022-07-01 17:15:06.661622
Epoch:[ 32 14 ] loss: 0.37060341238975525 2022-07-01 17:15:07.074984
Epoch:[ 32 15 ] loss: 0.37114840745925903 2022-07-01 17:15:07.491063
Epoch:[ 32 16 ] loss: 0.37101298570632935 2022-07-01 17:15:12.677028
Epoch:[ 32 17 ] loss: 0.37050145864486694 2022-07-01 17:15:13.096744
Epoch:[ 32 18 ] loss: 0.3699302673339844 2022-07-01 17:15:13.513768
Epoch:[ 32 19 ] loss: 0.37223827838897705 2022-07-01 17:15:13.934121
Training_Epoch:[ 32 ] Training_loss: 0.37077608406543733 2022-07-01 17:15:13.934766
learning rate:  0.0005120000000000001
netparams have been saved once 32
val: 1 0.3886473476886749
val: 2 0.3868928849697113
val: 3 0.3816526532173157
val: 4 0.3834003210067749
val: 5 0.387946754693985
val: 6 0.3927170932292938
val: 7 0.38664528727531433
val: 8 0.38361528515815735
val: 9 0.3800230622291565
val: 10 0.38739314675331116
val: 11 0.3778932988643646
val: 12 0.3888521194458008
val: 13 0.3863053619861603
val: 14 0.38910818099975586
val: 15 0.38657137751579285
val: 16 0.3821297585964203
val: 17 0.3881066143512726
val: 18 0.3883249759674072
val: 19 0.3782678246498108
val: 20 0.3859693109989166
val_Epoch:[ 32 ] val_loss: 0.38552313297986984 2022-07-01 17:15:17.917234
start training 2022-07-01 17:15:18.016091
Epoch:[ 33 0 ] loss: 0.3716031312942505 2022-07-01 17:15:32.421879
Epoch:[ 33 1 ] loss: 0.37026724219322205 2022-07-01 17:15:32.845813
Epoch:[ 33 2 ] loss: 0.3684830665588379 2022-07-01 17:15:33.261569
Epoch:[ 33 3 ] loss: 0.3714179992675781 2022-07-01 17:15:33.676968
Epoch:[ 33 4 ] loss: 0.3705182671546936 2022-07-01 17:15:34.091645
Epoch:[ 33 5 ] loss: 0.37223246693611145 2022-07-01 17:15:34.505947
Epoch:[ 33 6 ] loss: 0.37169772386550903 2022-07-01 17:15:34.922232
Epoch:[ 33 7 ] loss: 0.3706776201725006 2022-07-01 17:15:35.337598
Epoch:[ 33 8 ] loss: 0.3695705235004425 2022-07-01 17:15:35.752988
Epoch:[ 33 9 ] loss: 0.3707726299762726 2022-07-01 17:15:36.172600
Epoch:[ 33 10 ] loss: 0.3703130781650543 2022-07-01 17:15:36.589663
Epoch:[ 33 11 ] loss: 0.3686850666999817 2022-07-01 17:15:37.004952
Epoch:[ 33 12 ] loss: 0.3705548048019409 2022-07-01 17:15:37.422125
Epoch:[ 33 13 ] loss: 0.3721759021282196 2022-07-01 17:15:37.840108
Epoch:[ 33 14 ] loss: 0.3710753619670868 2022-07-01 17:15:38.258556
Epoch:[ 33 15 ] loss: 0.372091680765152 2022-07-01 17:15:38.674019
Epoch:[ 33 16 ] loss: 0.37081488966941833 2022-07-01 17:15:44.175359
Epoch:[ 33 17 ] loss: 0.3698042631149292 2022-07-01 17:15:44.595792
Epoch:[ 33 18 ] loss: 0.37085261940956116 2022-07-01 17:15:45.017105
Epoch:[ 33 19 ] loss: 0.3707706332206726 2022-07-01 17:15:45.430354
Training_Epoch:[ 33 ] Training_loss: 0.37071894854307175 2022-07-01 17:15:45.431094
learning rate:  0.0005120000000000001
val: 1 0.3821733593940735
val: 2 0.37913504242897034
val: 3 0.3834753632545471
val: 4 0.38739916682243347
val: 5 0.3869803547859192
val: 6 0.38799387216567993
val: 7 0.38922300934791565
val: 8 0.38661596179008484
val: 9 0.38447242975234985
val: 10 0.3840349614620209
val: 11 0.38302817940711975
val: 12 0.3907563090324402
val: 13 0.3824143707752228
val: 14 0.38321632146835327
val: 15 0.3932551145553589
val: 16 0.3912926912307739
val: 17 0.3876991271972656
val: 18 0.38107556104660034
val: 19 0.39281004667282104
val: 20 0.3834620416164398
val_Epoch:[ 33 ] val_loss: 0.38602566421031953 2022-07-01 17:15:49.377772
start training 2022-07-01 17:15:49.477207
Epoch:[ 34 0 ] loss: 0.3706912100315094 2022-07-01 17:16:04.271660
Epoch:[ 34 1 ] loss: 0.3705677092075348 2022-07-01 17:16:04.774134
Epoch:[ 34 2 ] loss: 0.3692285120487213 2022-07-01 17:16:05.274705
Epoch:[ 34 3 ] loss: 0.3700004816055298 2022-07-01 17:16:05.779817
Epoch:[ 34 4 ] loss: 0.37112104892730713 2022-07-01 17:16:06.282953
Epoch:[ 34 5 ] loss: 0.37001827359199524 2022-07-01 17:16:06.791425
Epoch:[ 34 6 ] loss: 0.37085726857185364 2022-07-01 17:16:07.293101
Epoch:[ 34 7 ] loss: 0.370157927274704 2022-07-01 17:16:07.796344
Epoch:[ 34 8 ] loss: 0.369115948677063 2022-07-01 17:16:08.298263
Epoch:[ 34 9 ] loss: 0.37145429849624634 2022-07-01 17:16:08.797715
Epoch:[ 34 10 ] loss: 0.37152066826820374 2022-07-01 17:16:09.282428
Epoch:[ 34 11 ] loss: 0.37040653824806213 2022-07-01 17:16:09.783720
Epoch:[ 34 12 ] loss: 0.3713488280773163 2022-07-01 17:16:10.287793
Epoch:[ 34 13 ] loss: 0.36827975511550903 2022-07-01 17:16:10.790224
Epoch:[ 34 14 ] loss: 0.3724266588687897 2022-07-01 17:16:11.290233
Epoch:[ 34 15 ] loss: 0.37256813049316406 2022-07-01 17:16:11.789825
Epoch:[ 34 16 ] loss: 0.3703685700893402 2022-07-01 17:16:16.201745
Epoch:[ 34 17 ] loss: 0.3700109124183655 2022-07-01 17:16:16.705963
Epoch:[ 34 18 ] loss: 0.3709317445755005 2022-07-01 17:16:17.209455
Epoch:[ 34 19 ] loss: 0.37069547176361084 2022-07-01 17:16:17.715631
Training_Epoch:[ 34 ] Training_loss: 0.37058849781751635 2022-07-01 17:16:17.716301
learning rate:  0.0005120000000000001
netparams have been saved once 34
val: 1 0.38387852907180786
val: 2 0.3728941082954407
val: 3 0.3907562494277954
val: 4 0.38517439365386963
val: 5 0.38849806785583496
val: 6 0.3913707435131073
val: 7 0.38668787479400635
val: 8 0.3897126615047455
val: 9 0.3865111768245697
val: 10 0.39172887802124023
val: 11 0.38684529066085815
val: 12 0.3900584876537323
val: 13 0.3874894678592682
val: 14 0.3878205418586731
val: 15 0.37544146180152893
val: 16 0.38917097449302673
val: 17 0.3824410140514374
val: 18 0.38359183073043823
val: 19 0.38014233112335205
val: 20 0.3864935040473938
val_Epoch:[ 34 ] val_loss: 0.3858353793621063 2022-07-01 17:16:21.746478
start training 2022-07-01 17:16:21.846825
Epoch:[ 35 0 ] loss: 0.37013277411460876 2022-07-01 17:16:36.546782
Epoch:[ 35 1 ] loss: 0.37104031443595886 2022-07-01 17:16:37.061413
Epoch:[ 35 2 ] loss: 0.3706595003604889 2022-07-01 17:16:37.564747
Epoch:[ 35 3 ] loss: 0.37021926045417786 2022-07-01 17:16:38.068459
Epoch:[ 35 4 ] loss: 0.3703591227531433 2022-07-01 17:16:38.573354
Epoch:[ 35 5 ] loss: 0.37017250061035156 2022-07-01 17:16:39.078908
Epoch:[ 35 6 ] loss: 0.3717116713523865 2022-07-01 17:16:39.580066
Epoch:[ 35 7 ] loss: 0.3722093999385834 2022-07-01 17:16:40.076538
Epoch:[ 35 8 ] loss: 0.36965566873550415 2022-07-01 17:16:40.574277
Epoch:[ 35 9 ] loss: 0.371701717376709 2022-07-01 17:16:41.073726
Epoch:[ 35 10 ] loss: 0.36920812726020813 2022-07-01 17:16:41.573009
Epoch:[ 35 11 ] loss: 0.36973488330841064 2022-07-01 17:16:42.074674
Epoch:[ 35 12 ] loss: 0.36979514360427856 2022-07-01 17:16:42.573460
Epoch:[ 35 13 ] loss: 0.3703005313873291 2022-07-01 17:16:43.073960
Epoch:[ 35 14 ] loss: 0.36887356638908386 2022-07-01 17:16:43.571022
Epoch:[ 35 15 ] loss: 0.37048324942588806 2022-07-01 17:16:44.069791
Epoch:[ 35 16 ] loss: 0.3713919222354889 2022-07-01 17:16:48.481852
Epoch:[ 35 17 ] loss: 0.3699330687522888 2022-07-01 17:16:48.990102
Epoch:[ 35 18 ] loss: 0.37079617381095886 2022-07-01 17:16:49.495679
Epoch:[ 35 19 ] loss: 0.3693753778934479 2022-07-01 17:16:49.998626
Training_Epoch:[ 35 ] Training_loss: 0.37038769870996474 2022-07-01 17:16:49.999296
learning rate:  0.0005120000000000001
val: 1 0.38910558819770813
val: 2 0.380203515291214
val: 3 0.3838460445404053
val: 4 0.38554030656814575
val: 5 0.3833446800708771
val: 6 0.3856780230998993
val: 7 0.3914299011230469
val: 8 0.3833473324775696
val: 9 0.39572522044181824
val: 10 0.3884159028530121
val: 11 0.3899887204170227
val: 12 0.39067956805229187
val: 13 0.39021286368370056
val: 14 0.38094183802604675
val: 15 0.38558050990104675
val: 16 0.38357511162757874
val: 17 0.39052528142929077
val: 18 0.3885537385940552
val: 19 0.38467681407928467
val: 20 0.3821430504322052
val_Epoch:[ 35 ] val_loss: 0.386675700545311 2022-07-01 17:16:54.053968
start training 2022-07-01 17:16:54.150972
Epoch:[ 36 0 ] loss: 0.37075483798980713 2022-07-01 17:17:08.622645
Epoch:[ 36 1 ] loss: 0.3701816499233246 2022-07-01 17:17:09.075244
Epoch:[ 36 2 ] loss: 0.36888518929481506 2022-07-01 17:17:09.490260
Epoch:[ 36 3 ] loss: 0.36965906620025635 2022-07-01 17:17:09.912036
Epoch:[ 36 4 ] loss: 0.3703172206878662 2022-07-01 17:17:10.326044
Epoch:[ 36 5 ] loss: 0.36995312571525574 2022-07-01 17:17:10.741638
Epoch:[ 36 6 ] loss: 0.3697224259376526 2022-07-01 17:17:11.157956
Epoch:[ 36 7 ] loss: 0.36821943521499634 2022-07-01 17:17:11.572834
Epoch:[ 36 8 ] loss: 0.3718304932117462 2022-07-01 17:17:11.987742
Epoch:[ 36 9 ] loss: 0.37028634548187256 2022-07-01 17:17:12.401929
Epoch:[ 36 10 ] loss: 0.36895546317100525 2022-07-01 17:17:12.822293
Epoch:[ 36 11 ] loss: 0.3692395091056824 2022-07-01 17:17:13.238498
Epoch:[ 36 12 ] loss: 0.3706003725528717 2022-07-01 17:17:13.654930
Epoch:[ 36 13 ] loss: 0.37122321128845215 2022-07-01 17:17:14.076048
Epoch:[ 36 14 ] loss: 0.37071916460990906 2022-07-01 17:17:14.490325
Epoch:[ 36 15 ] loss: 0.3700146973133087 2022-07-01 17:17:14.904841
Epoch:[ 36 16 ] loss: 0.3710688352584839 2022-07-01 17:17:20.460540
Epoch:[ 36 17 ] loss: 0.3688794672489166 2022-07-01 17:17:21.138137
Epoch:[ 36 18 ] loss: 0.3709069490432739 2022-07-01 17:17:21.565688
Epoch:[ 36 19 ] loss: 0.3707852065563202 2022-07-01 17:17:21.981925
Training_Epoch:[ 36 ] Training_loss: 0.37011013329029085 2022-07-01 17:17:21.982574
learning rate:  0.0005120000000000001
netparams have been saved once 36
val: 1 0.3787524402141571
val: 2 0.3858293294906616
val: 3 0.38915374875068665
val: 4 0.3819694221019745
val: 5 0.38576948642730713
val: 6 0.388847678899765
val: 7 0.38830819725990295
val: 8 0.38549211621284485
val: 9 0.37934884428977966
val: 10 0.37801021337509155
val: 11 0.38634878396987915
val: 12 0.38978075981140137
val: 13 0.39140793681144714
val: 14 0.3901008367538452
val: 15 0.390049546957016
val: 16 0.3793468475341797
val: 17 0.3845355212688446
val: 18 0.38239946961402893
val: 19 0.3800692558288574
val: 20 0.3861348628997803
val_Epoch:[ 36 ] val_loss: 0.3850827649235725 2022-07-01 17:17:25.861289
start training 2022-07-01 17:17:25.962649
Epoch:[ 37 0 ] loss: 0.3706677556037903 2022-07-01 17:17:40.736971
Epoch:[ 37 1 ] loss: 0.369687020778656 2022-07-01 17:17:41.212965
Epoch:[ 37 2 ] loss: 0.3693234622478485 2022-07-01 17:17:41.689127
Epoch:[ 37 3 ] loss: 0.369686096906662 2022-07-01 17:17:42.163527
Epoch:[ 37 4 ] loss: 0.36936429142951965 2022-07-01 17:17:42.638373
Epoch:[ 37 5 ] loss: 0.37023189663887024 2022-07-01 17:17:43.119178
Epoch:[ 37 6 ] loss: 0.36999425292015076 2022-07-01 17:17:43.597073
Epoch:[ 37 7 ] loss: 0.37088102102279663 2022-07-01 17:17:44.078130
Epoch:[ 37 8 ] loss: 0.36803096532821655 2022-07-01 17:17:44.556988
Epoch:[ 37 9 ] loss: 0.369449645280838 2022-07-01 17:17:45.031363
Epoch:[ 37 10 ] loss: 0.370226114988327 2022-07-01 17:17:45.506056
Epoch:[ 37 11 ] loss: 0.3701162040233612 2022-07-01 17:17:45.979015
Epoch:[ 37 12 ] loss: 0.3696345090866089 2022-07-01 17:17:46.459822
Epoch:[ 37 13 ] loss: 0.3708823621273041 2022-07-01 17:17:46.937737
Epoch:[ 37 14 ] loss: 0.3693157732486725 2022-07-01 17:17:47.414864
Epoch:[ 37 15 ] loss: 0.3709610104560852 2022-07-01 17:17:47.889396
Epoch:[ 37 16 ] loss: 0.36929190158843994 2022-07-01 17:17:52.505142
Epoch:[ 37 17 ] loss: 0.3699316382408142 2022-07-01 17:17:52.985084
Epoch:[ 37 18 ] loss: 0.3713328242301941 2022-07-01 17:17:53.460147
Epoch:[ 37 19 ] loss: 0.3694935441017151 2022-07-01 17:17:53.933079
Training_Epoch:[ 37 ] Training_loss: 0.36992511451244353 2022-07-01 17:17:53.933801
learning rate:  0.0005120000000000001
val: 1 0.3911025822162628
val: 2 0.38385146856307983
val: 3 0.39071160554885864
val: 4 0.3843601644039154
val: 5 0.38632410764694214
val: 6 0.3915942907333374
val: 7 0.3864322304725647
val: 8 0.38335275650024414
val: 9 0.3854684829711914
val: 10 0.3828343451023102
val: 11 0.38533151149749756
val: 12 0.38018888235092163
val: 13 0.38333383202552795
val: 14 0.3866901993751526
val: 15 0.383923202753067
val: 16 0.38196611404418945
val: 17 0.3917420208454132
val: 18 0.383722186088562
val: 19 0.38369220495224
val: 20 0.3886057734489441
val_Epoch:[ 37 ] val_loss: 0.3857613980770111 2022-07-01 17:17:57.999236
start training 2022-07-01 17:17:58.098276
Epoch:[ 38 0 ] loss: 0.3685275614261627 2022-07-01 17:18:13.206498
Epoch:[ 38 1 ] loss: 0.3698146641254425 2022-07-01 17:18:13.621788
Epoch:[ 38 2 ] loss: 0.36971515417099 2022-07-01 17:18:14.037800
Epoch:[ 38 3 ] loss: 0.3694719672203064 2022-07-01 17:18:14.452176
Epoch:[ 38 4 ] loss: 0.3697444796562195 2022-07-01 17:18:14.867239
Epoch:[ 38 5 ] loss: 0.3724614381790161 2022-07-01 17:18:15.289006
Epoch:[ 38 6 ] loss: 0.37056419253349304 2022-07-01 17:18:15.702506
Epoch:[ 38 7 ] loss: 0.3695700168609619 2022-07-01 17:18:16.124495
Epoch:[ 38 8 ] loss: 0.3695526719093323 2022-07-01 17:18:16.540104
Epoch:[ 38 9 ] loss: 0.3679291009902954 2022-07-01 17:18:16.954660
Epoch:[ 38 10 ] loss: 0.3697971999645233 2022-07-01 17:18:17.368815
Epoch:[ 38 11 ] loss: 0.37090060114860535 2022-07-01 17:18:17.783724
Epoch:[ 38 12 ] loss: 0.3698987364768982 2022-07-01 17:18:18.197993
Epoch:[ 38 13 ] loss: 0.36848244071006775 2022-07-01 17:18:18.611202
Epoch:[ 38 14 ] loss: 0.36780691146850586 2022-07-01 17:18:19.027607
Epoch:[ 38 15 ] loss: 0.37004074454307556 2022-07-01 17:18:19.443957
Epoch:[ 38 16 ] loss: 0.37055647373199463 2022-07-01 17:18:25.233546
Epoch:[ 38 17 ] loss: 0.3687147796154022 2022-07-01 17:18:25.645893
Epoch:[ 38 18 ] loss: 0.3707239031791687 2022-07-01 17:18:26.073839
Epoch:[ 38 19 ] loss: 0.36896681785583496 2022-07-01 17:18:26.487268
Training_Epoch:[ 38 ] Training_loss: 0.3696619927883148 2022-07-01 17:18:26.487944
learning rate:  0.0005120000000000001
netparams have been saved once 38
val: 1 0.38570621609687805
val: 2 0.3944070339202881
val: 3 0.3915165960788727
val: 4 0.38292399048805237
val: 5 0.3853529691696167
val: 6 0.3847575783729553
val: 7 0.3872867226600647
val: 8 0.37839940190315247
val: 9 0.37819308042526245
val: 10 0.39219918847084045
val: 11 0.3899646997451782
val: 12 0.38551437854766846
val: 13 0.38042017817497253
val: 14 0.3832230567932129
val: 15 0.3842085003852844
val: 16 0.39120712876319885
val: 17 0.3876180350780487
val: 18 0.3862527906894684
val: 19 0.3820919394493103
val: 20 0.3885299563407898
val_Epoch:[ 38 ] val_loss: 0.3859886720776558 2022-07-01 17:18:30.419830
start training 2022-07-01 17:18:30.518962
Epoch:[ 39 0 ] loss: 0.3684220612049103 2022-07-01 17:18:45.291646
Epoch:[ 39 1 ] loss: 0.3685130774974823 2022-07-01 17:18:45.768708
Epoch:[ 39 2 ] loss: 0.36907339096069336 2022-07-01 17:18:46.246595
Epoch:[ 39 3 ] loss: 0.36936452984809875 2022-07-01 17:18:46.723183
Epoch:[ 39 4 ] loss: 0.3698557913303375 2022-07-01 17:18:47.199567
Epoch:[ 39 5 ] loss: 0.3701064884662628 2022-07-01 17:18:47.674889
Epoch:[ 39 6 ] loss: 0.3696390688419342 2022-07-01 17:18:48.156528
Epoch:[ 39 7 ] loss: 0.3693297207355499 2022-07-01 17:18:48.631628
Epoch:[ 39 8 ] loss: 0.3702048361301422 2022-07-01 17:18:49.108446
Epoch:[ 39 9 ] loss: 0.369310587644577 2022-07-01 17:18:49.585076
Epoch:[ 39 10 ] loss: 0.36938726902008057 2022-07-01 17:18:50.062539
Epoch:[ 39 11 ] loss: 0.3689957559108734 2022-07-01 17:18:50.538456
Epoch:[ 39 12 ] loss: 0.3692896068096161 2022-07-01 17:18:51.013467
Epoch:[ 39 13 ] loss: 0.37054723501205444 2022-07-01 17:18:51.488213
Epoch:[ 39 14 ] loss: 0.37008094787597656 2022-07-01 17:18:51.968007
Epoch:[ 39 15 ] loss: 0.3694979250431061 2022-07-01 17:18:52.444744
Epoch:[ 39 16 ] loss: 0.3691854476928711 2022-07-01 17:18:56.814129
Epoch:[ 39 17 ] loss: 0.3703829050064087 2022-07-01 17:18:57.290526
Epoch:[ 39 18 ] loss: 0.3680233061313629 2022-07-01 17:18:57.770692
Epoch:[ 39 19 ] loss: 0.36961373686790466 2022-07-01 17:18:58.252212
Training_Epoch:[ 39 ] Training_loss: 0.36944118440151213 2022-07-01 17:18:58.252929
learning rate:  0.0005120000000000001
val: 1 0.38757702708244324
val: 2 0.3823346495628357
val: 3 0.38340288400650024
val: 4 0.38437214493751526
val: 5 0.3885330855846405
val: 6 0.38258835673332214
val: 7 0.38908204436302185
val: 8 0.3886330723762512
val: 9 0.3821207880973816
val: 10 0.380639910697937
val: 11 0.3848033547401428
val: 12 0.38721203804016113
val: 13 0.3821493983268738
val: 14 0.3883533477783203
val: 15 0.3794526755809784
val: 16 0.38529422879219055
val: 17 0.3815796971321106
val: 18 0.3840993642807007
val: 19 0.39058780670166016
val: 20 0.38842305541038513
val_Epoch:[ 39 ] val_loss: 0.3850619465112686 2022-07-01 17:19:02.256227
start training 2022-07-01 17:19:02.355746
Epoch:[ 40 0 ] loss: 0.36859646439552307 2022-07-01 17:19:16.632303
Epoch:[ 40 1 ] loss: 0.3690057694911957 2022-07-01 17:19:17.077189
Epoch:[ 40 2 ] loss: 0.36831802129745483 2022-07-01 17:19:17.517227
Epoch:[ 40 3 ] loss: 0.3694259822368622 2022-07-01 17:19:17.940167
Epoch:[ 40 4 ] loss: 0.37001240253448486 2022-07-01 17:19:18.356185
Epoch:[ 40 5 ] loss: 0.36932218074798584 2022-07-01 17:19:18.771803
Epoch:[ 40 6 ] loss: 0.370402455329895 2022-07-01 17:19:19.186833
Epoch:[ 40 7 ] loss: 0.3666686713695526 2022-07-01 17:19:19.594496
Epoch:[ 40 8 ] loss: 0.37093907594680786 2022-07-01 17:19:20.010864
Epoch:[ 40 9 ] loss: 0.3690096139907837 2022-07-01 17:19:20.426712
Epoch:[ 40 10 ] loss: 0.3691568970680237 2022-07-01 17:19:20.843029
Epoch:[ 40 11 ] loss: 0.36907413601875305 2022-07-01 17:19:21.262264
Epoch:[ 40 12 ] loss: 0.36991021037101746 2022-07-01 17:19:21.676482
Epoch:[ 40 13 ] loss: 0.36952587962150574 2022-07-01 17:19:22.092508
Epoch:[ 40 14 ] loss: 0.37004876136779785 2022-07-01 17:19:22.508479
Epoch:[ 40 15 ] loss: 0.36907580494880676 2022-07-01 17:19:22.924535
Epoch:[ 40 16 ] loss: 0.3695352077484131 2022-07-01 17:19:28.504033
Epoch:[ 40 17 ] loss: 0.36892879009246826 2022-07-01 17:19:28.922906
Epoch:[ 40 18 ] loss: 0.3696387708187103 2022-07-01 17:19:29.343993
Epoch:[ 40 19 ] loss: 0.3702271580696106 2022-07-01 17:19:29.762878
Training_Epoch:[ 40 ] Training_loss: 0.3693411126732826 2022-07-01 17:19:29.763659
learning rate:  0.0005120000000000001
netparams have been saved once 40
val: 1 0.3848728835582733
val: 2 0.3825722932815552
val: 3 0.3879915475845337
val: 4 0.3895362317562103
val: 5 0.3840984106063843
val: 6 0.3898717761039734
val: 7 0.3817847669124603
val: 8 0.3819337487220764
val: 9 0.3838619291782379
val: 10 0.38276541233062744
val: 11 0.3883049488067627
val: 12 0.3875996470451355
val: 13 0.380015105009079
val: 14 0.3826592266559601
val: 15 0.3883140981197357
val: 16 0.38775280117988586
val: 17 0.3886432349681854
val: 18 0.3904842734336853
val: 19 0.38679182529449463
val: 20 0.3908049166202545
val_Epoch:[ 40 ] val_loss: 0.38603295385837555 2022-07-01 17:19:33.758653
start training 2022-07-01 17:19:33.863925
Epoch:[ 41 0 ] loss: 0.369002103805542 2022-07-01 17:19:49.169830
Epoch:[ 41 1 ] loss: 0.3699300289154053 2022-07-01 17:19:49.587035
Epoch:[ 41 2 ] loss: 0.36981961131095886 2022-07-01 17:19:50.004280
Epoch:[ 41 3 ] loss: 0.3689546585083008 2022-07-01 17:19:50.426636
Epoch:[ 41 4 ] loss: 0.3693290054798126 2022-07-01 17:19:50.843094
Epoch:[ 41 5 ] loss: 0.36811739206314087 2022-07-01 17:19:51.260891
Epoch:[ 41 6 ] loss: 0.3689230680465698 2022-07-01 17:19:51.675707
Epoch:[ 41 7 ] loss: 0.36733391880989075 2022-07-01 17:19:52.090547
Epoch:[ 41 8 ] loss: 0.3684338927268982 2022-07-01 17:19:52.551165
Epoch:[ 41 9 ] loss: 0.3687657415866852 2022-07-01 17:19:52.996776
Epoch:[ 41 10 ] loss: 0.36977723240852356 2022-07-01 17:19:53.417906
Epoch:[ 41 11 ] loss: 0.3686199486255646 2022-07-01 17:19:53.842568
Epoch:[ 41 12 ] loss: 0.36874809861183167 2022-07-01 17:19:54.263201
Epoch:[ 41 13 ] loss: 0.36846810579299927 2022-07-01 17:19:54.678981
Epoch:[ 41 14 ] loss: 0.3677161633968353 2022-07-01 17:19:55.096996
Epoch:[ 41 15 ] loss: 0.3675062656402588 2022-07-01 17:19:55.517926
Epoch:[ 41 16 ] loss: 0.36893177032470703 2022-07-01 17:20:00.915964
Epoch:[ 41 17 ] loss: 0.3677560091018677 2022-07-01 17:20:01.399525
Epoch:[ 41 18 ] loss: 0.36901989579200745 2022-07-01 17:20:01.883417
Epoch:[ 41 19 ] loss: 0.36937448382377625 2022-07-01 17:20:02.358662
Training_Epoch:[ 41 ] Training_loss: 0.3687263697385788 2022-07-01 17:20:02.359343
learning rate:  0.0004096000000000001
val: 1 0.39507603645324707
val: 2 0.3907962739467621
val: 3 0.3944456875324249
val: 4 0.3909260928630829
val: 5 0.39428046345710754
val: 6 0.3864906132221222
val: 7 0.3863343596458435
val: 8 0.38252100348472595
val: 9 0.38957977294921875
val: 10 0.3824853301048279
val: 11 0.38771888613700867
val: 12 0.3909003734588623
val: 13 0.38646170496940613
val: 14 0.3885984718799591
val: 15 0.38978311419487
val: 16 0.3889102339744568
val: 17 0.38646507263183594
val: 18 0.3835185170173645
val: 19 0.3817422091960907
val: 20 0.3754707872867584
val_Epoch:[ 41 ] val_loss: 0.38762525022029876 2022-07-01 17:20:06.321949
start training 2022-07-01 17:20:06.428591
Epoch:[ 42 0 ] loss: 0.36749643087387085 2022-07-01 17:20:21.946009
Epoch:[ 42 1 ] loss: 0.3684930205345154 2022-07-01 17:20:22.418936
Epoch:[ 42 2 ] loss: 0.3704783618450165 2022-07-01 17:20:22.894122
Epoch:[ 42 3 ] loss: 0.36854228377342224 2022-07-01 17:20:23.367572
Epoch:[ 42 4 ] loss: 0.36783260107040405 2022-07-01 17:20:23.844941
Epoch:[ 42 5 ] loss: 0.36980175971984863 2022-07-01 17:20:24.328088
Epoch:[ 42 6 ] loss: 0.36895281076431274 2022-07-01 17:20:24.805864
Epoch:[ 42 7 ] loss: 0.36784449219703674 2022-07-01 17:20:25.283364
Epoch:[ 42 8 ] loss: 0.3675619661808014 2022-07-01 17:20:25.766097
Epoch:[ 42 9 ] loss: 0.36935752630233765 2022-07-01 17:20:26.240269
Epoch:[ 42 10 ] loss: 0.3680662512779236 2022-07-01 17:20:26.713767
Epoch:[ 42 11 ] loss: 0.36728474497795105 2022-07-01 17:20:27.132263
Epoch:[ 42 12 ] loss: 0.3684450685977936 2022-07-01 17:20:27.550410
Epoch:[ 42 13 ] loss: 0.3683844208717346 2022-07-01 17:20:27.966382
Epoch:[ 42 14 ] loss: 0.367716521024704 2022-07-01 17:20:28.384042
Epoch:[ 42 15 ] loss: 0.3672889173030853 2022-07-01 17:20:28.799729
Epoch:[ 42 16 ] loss: 0.3680708110332489 2022-07-01 17:20:34.328047
Epoch:[ 42 17 ] loss: 0.36798223853111267 2022-07-01 17:20:34.754958
Epoch:[ 42 18 ] loss: 0.3687841296195984 2022-07-01 17:20:35.174909
Epoch:[ 42 19 ] loss: 0.36892014741897583 2022-07-01 17:20:35.593309
Training_Epoch:[ 42 ] Training_loss: 0.3683652251958847 2022-07-01 17:20:35.594007
learning rate:  0.0004096000000000001
netparams have been saved once 42
val: 1 0.3843976855278015
val: 2 0.38189470767974854
val: 3 0.3898029923439026
val: 4 0.38756775856018066
val: 5 0.39119893312454224
val: 6 0.3853074312210083
val: 7 0.3808289170265198
val: 8 0.3862718343734741
val: 9 0.39152786135673523
val: 10 0.3861508071422577
val: 11 0.3867394030094147
val: 12 0.3832249939441681
val: 13 0.38844871520996094
val: 14 0.3907407522201538
val: 15 0.3889751434326172
val: 16 0.38924556970596313
val: 17 0.3890775740146637
val: 18 0.387622207403183
val: 19 0.3856291174888611
val: 20 0.3843609392642975
val_Epoch:[ 42 ] val_loss: 0.3869506672024727 2022-07-01 17:20:39.459268
start training 2022-07-01 17:20:39.555568
Epoch:[ 43 0 ] loss: 0.3684864640235901 2022-07-01 17:20:54.812505
Epoch:[ 43 1 ] loss: 0.36804619431495667 2022-07-01 17:20:55.228020
Epoch:[ 43 2 ] loss: 0.3684644103050232 2022-07-01 17:20:55.650071
Epoch:[ 43 3 ] loss: 0.36741119623184204 2022-07-01 17:20:56.067908
Epoch:[ 43 4 ] loss: 0.3679015636444092 2022-07-01 17:20:56.485289
Epoch:[ 43 5 ] loss: 0.3678972125053406 2022-07-01 17:20:56.902836
Epoch:[ 43 6 ] loss: 0.36745816469192505 2022-07-01 17:20:57.318674
Epoch:[ 43 7 ] loss: 0.36754539608955383 2022-07-01 17:20:57.734115
Epoch:[ 43 8 ] loss: 0.3685055077075958 2022-07-01 17:20:58.152367
Epoch:[ 43 9 ] loss: 0.36823156476020813 2022-07-01 17:20:58.569777
Epoch:[ 43 10 ] loss: 0.36934638023376465 2022-07-01 17:20:58.986316
Epoch:[ 43 11 ] loss: 0.36863139271736145 2022-07-01 17:20:59.401571
Epoch:[ 43 12 ] loss: 0.36865946650505066 2022-07-01 17:20:59.815936
Epoch:[ 43 13 ] loss: 0.3678261935710907 2022-07-01 17:21:00.234164
Epoch:[ 43 14 ] loss: 0.3679220378398895 2022-07-01 17:21:00.650546
Epoch:[ 43 15 ] loss: 0.3687095046043396 2022-07-01 17:21:01.068718
Epoch:[ 43 16 ] loss: 0.3688141107559204 2022-07-01 17:21:06.918903
Epoch:[ 43 17 ] loss: 0.36908066272735596 2022-07-01 17:21:07.338925
Epoch:[ 43 18 ] loss: 0.3702709376811981 2022-07-01 17:21:07.761245
Epoch:[ 43 19 ] loss: 0.36767035722732544 2022-07-01 17:21:08.177359
Training_Epoch:[ 43 ] Training_loss: 0.3683439359068871 2022-07-01 17:21:08.178070
learning rate:  0.0004096000000000001
val: 1 0.38693884015083313
val: 2 0.3886014223098755
val: 3 0.38238218426704407
val: 4 0.3892548978328705
val: 5 0.3852790594100952
val: 6 0.3829297423362732
val: 7 0.38015833497047424
val: 8 0.3838927149772644
val: 9 0.38208964467048645
val: 10 0.380507230758667
val: 11 0.38378846645355225
val: 12 0.38328424096107483
val: 13 0.38587814569473267
val: 14 0.38769662380218506
val: 15 0.388342946767807
val: 16 0.39205509424209595
val: 17 0.38956210017204285
val: 18 0.38943299651145935
val: 19 0.38380497694015503
val: 20 0.38639307022094727
val_Epoch:[ 43 ] val_loss: 0.3856136366724968 2022-07-01 17:21:12.006845
start training 2022-07-01 17:21:12.100563
Epoch:[ 44 0 ] loss: 0.36879491806030273 2022-07-01 17:21:27.226236
Epoch:[ 44 1 ] loss: 0.3672262728214264 2022-07-01 17:21:27.643370
Epoch:[ 44 2 ] loss: 0.36726880073547363 2022-07-01 17:21:28.057307
Epoch:[ 44 3 ] loss: 0.36784154176712036 2022-07-01 17:21:28.471694
Epoch:[ 44 4 ] loss: 0.3673195242881775 2022-07-01 17:21:28.886377
Epoch:[ 44 5 ] loss: 0.3689613342285156 2022-07-01 17:21:29.299295
Epoch:[ 44 6 ] loss: 0.36834806203842163 2022-07-01 17:21:29.714228
Epoch:[ 44 7 ] loss: 0.3680357038974762 2022-07-01 17:21:30.129835
Epoch:[ 44 8 ] loss: 0.3681918978691101 2022-07-01 17:21:30.550372
Epoch:[ 44 9 ] loss: 0.3678240478038788 2022-07-01 17:21:30.964913
Epoch:[ 44 10 ] loss: 0.3676066994667053 2022-07-01 17:21:31.378997
Epoch:[ 44 11 ] loss: 0.36748024821281433 2022-07-01 17:21:31.792871
Epoch:[ 44 12 ] loss: 0.3689781427383423 2022-07-01 17:21:32.207111
Epoch:[ 44 13 ] loss: 0.36913833022117615 2022-07-01 17:21:32.629436
Epoch:[ 44 14 ] loss: 0.3679415285587311 2022-07-01 17:21:33.051823
Epoch:[ 44 15 ] loss: 0.3684045374393463 2022-07-01 17:21:33.465788
Epoch:[ 44 16 ] loss: 0.3680373430252075 2022-07-01 17:21:38.816507
Epoch:[ 44 17 ] loss: 0.3669499456882477 2022-07-01 17:21:39.229400
Epoch:[ 44 18 ] loss: 0.3690968453884125 2022-07-01 17:21:39.650720
Epoch:[ 44 19 ] loss: 0.3691774904727936 2022-07-01 17:21:40.070027
Training_Epoch:[ 44 ] Training_loss: 0.368131160736084 2022-07-01 17:21:40.070743
learning rate:  0.0004096000000000001
netparams have been saved once 44
val: 1 0.37873539328575134
val: 2 0.3839118480682373
val: 3 0.3883134126663208
val: 4 0.38716065883636475
val: 5 0.3947370648384094
val: 6 0.389748752117157
val: 7 0.3896498382091522
val: 8 0.39605239033699036
val: 9 0.38407108187675476
val: 10 0.38297757506370544
val: 11 0.3874559998512268
val: 12 0.3880891799926758
val: 13 0.3846176564693451
val: 14 0.38551098108291626
val: 15 0.3880559802055359
val: 16 0.3857553005218506
val: 17 0.38121679425239563
val: 18 0.3814186751842499
val: 19 0.38695067167282104
val: 20 0.3852020502090454
val_Epoch:[ 44 ] val_loss: 0.3864815652370453 2022-07-01 17:21:43.912885
start training 2022-07-01 17:21:44.006047
Epoch:[ 45 0 ] loss: 0.3688024878501892 2022-07-01 17:21:58.552354
Epoch:[ 45 1 ] loss: 0.3669499158859253 2022-07-01 17:21:58.991781
Epoch:[ 45 2 ] loss: 0.3656424283981323 2022-07-01 17:21:59.407171
Epoch:[ 45 3 ] loss: 0.3671891391277313 2022-07-01 17:21:59.828111
Epoch:[ 45 4 ] loss: 0.3678511083126068 2022-07-01 17:22:00.242244
Epoch:[ 45 5 ] loss: 0.3679301142692566 2022-07-01 17:22:00.664790
Epoch:[ 45 6 ] loss: 0.36922648549079895 2022-07-01 17:22:01.078629
Epoch:[ 45 7 ] loss: 0.36773285269737244 2022-07-01 17:22:01.500747
Epoch:[ 45 8 ] loss: 0.36901235580444336 2022-07-01 17:22:01.917441
Epoch:[ 45 9 ] loss: 0.3689374029636383 2022-07-01 17:22:02.332096
Epoch:[ 45 10 ] loss: 0.368717223405838 2022-07-01 17:22:02.749568
Epoch:[ 45 11 ] loss: 0.36767780780792236 2022-07-01 17:22:03.163862
Epoch:[ 45 12 ] loss: 0.36864522099494934 2022-07-01 17:22:03.580944
Epoch:[ 45 13 ] loss: 0.3696557283401489 2022-07-01 17:22:03.994352
Epoch:[ 45 14 ] loss: 0.3677448034286499 2022-07-01 17:22:04.409484
Epoch:[ 45 15 ] loss: 0.36782947182655334 2022-07-01 17:22:04.824603
Epoch:[ 45 16 ] loss: 0.3714180588722229 2022-07-01 17:22:10.490325
Epoch:[ 45 17 ] loss: 0.3685368299484253 2022-07-01 17:22:10.903456
Epoch:[ 45 18 ] loss: 0.3671148121356964 2022-07-01 17:22:11.323855
Epoch:[ 45 19 ] loss: 0.3685912489891052 2022-07-01 17:22:11.736719
Training_Epoch:[ 45 ] Training_loss: 0.3682602748274803 2022-07-01 17:22:11.737403
learning rate:  0.0004096000000000001
val: 1 0.3808631896972656
val: 2 0.38725146651268005
val: 3 0.3874575197696686
val: 4 0.38438913226127625
val: 5 0.3892664909362793
val: 6 0.3843390941619873
val: 7 0.3878014385700226
val: 8 0.3905739486217499
val: 9 0.3911128342151642
val: 10 0.39239010214805603
val: 11 0.38608747720718384
val: 12 0.39749324321746826
val: 13 0.38500159978866577
val: 14 0.37972986698150635
val: 15 0.3940121531486511
val: 16 0.38888344168663025
val: 17 0.39179572463035583
val: 18 0.3838416635990143
val: 19 0.38613781332969666
val: 20 0.3886975646018982
val_Epoch:[ 45 ] val_loss: 0.387856288254261 2022-07-01 17:22:15.631507
start training 2022-07-01 17:22:15.723851
Epoch:[ 46 0 ] loss: 0.3706147074699402 2022-07-01 17:22:30.387008
Epoch:[ 46 1 ] loss: 0.3698464334011078 2022-07-01 17:22:30.802768
Epoch:[ 46 2 ] loss: 0.36744141578674316 2022-07-01 17:22:31.219133
Epoch:[ 46 3 ] loss: 0.3670751452445984 2022-07-01 17:22:31.632981
Epoch:[ 46 4 ] loss: 0.3668622076511383 2022-07-01 17:22:32.047940
Epoch:[ 46 5 ] loss: 0.36905771493911743 2022-07-01 17:22:32.469581
Epoch:[ 46 6 ] loss: 0.3670610785484314 2022-07-01 17:22:32.891092
Epoch:[ 46 7 ] loss: 0.36853286623954773 2022-07-01 17:22:33.304581
Epoch:[ 46 8 ] loss: 0.3688127398490906 2022-07-01 17:22:33.721035
Epoch:[ 46 9 ] loss: 0.3674238622188568 2022-07-01 17:22:34.141992
Epoch:[ 46 10 ] loss: 0.36899393796920776 2022-07-01 17:22:34.556714
Epoch:[ 46 11 ] loss: 0.3693648874759674 2022-07-01 17:22:34.970108
Epoch:[ 46 12 ] loss: 0.36908939480781555 2022-07-01 17:22:35.384246
Epoch:[ 46 13 ] loss: 0.3674542307853699 2022-07-01 17:22:35.798074
Epoch:[ 46 14 ] loss: 0.3671242594718933 2022-07-01 17:22:36.211090
Epoch:[ 46 15 ] loss: 0.3691043555736542 2022-07-01 17:22:36.626003
Epoch:[ 46 16 ] loss: 0.3697393238544464 2022-07-01 17:22:41.628195
Epoch:[ 46 17 ] loss: 0.3675970435142517 2022-07-01 17:22:42.065298
Epoch:[ 46 18 ] loss: 0.36755362153053284 2022-07-01 17:22:42.493701
Epoch:[ 46 19 ] loss: 0.36836549639701843 2022-07-01 17:22:42.907109
Training_Epoch:[ 46 ] Training_loss: 0.36835573613643646 2022-07-01 17:22:42.907783
learning rate:  0.0004096000000000001
netparams have been saved once 46
val: 1 0.38471442461013794
val: 2 0.3904491364955902
val: 3 0.37917280197143555
val: 4 0.3854573965072632
val: 5 0.38502082228660583
val: 6 0.3900226056575775
val: 7 0.3951418995857239
val: 8 0.3830326497554779
val: 9 0.3878985643386841
val: 10 0.38661471009254456
val: 11 0.39048492908477783
val: 12 0.38445091247558594
val: 13 0.38301271200180054
val: 14 0.39452871680259705
val: 15 0.38917431235313416
val: 16 0.3894291818141937
val: 17 0.3927227854728699
val: 18 0.3879319429397583
val: 19 0.3904329538345337
val: 20 0.3835515081882477
val_Epoch:[ 46 ] val_loss: 0.387662248313427 2022-07-01 17:22:46.805487
start training 2022-07-01 17:22:46.899977
Epoch:[ 47 0 ] loss: 0.36811426281929016 2022-07-01 17:23:01.609752
Epoch:[ 47 1 ] loss: 0.36713820695877075 2022-07-01 17:23:02.024180
Epoch:[ 47 2 ] loss: 0.3678647577762604 2022-07-01 17:23:02.440637
Epoch:[ 47 3 ] loss: 0.36933422088623047 2022-07-01 17:23:02.857091
Epoch:[ 47 4 ] loss: 0.36692264676094055 2022-07-01 17:23:03.278098
Epoch:[ 47 5 ] loss: 0.36807695031166077 2022-07-01 17:23:03.696154
Epoch:[ 47 6 ] loss: 0.3676396906375885 2022-07-01 17:23:04.116661
Epoch:[ 47 7 ] loss: 0.3673325479030609 2022-07-01 17:23:04.530917
Epoch:[ 47 8 ] loss: 0.3675594925880432 2022-07-01 17:23:04.947938
Epoch:[ 47 9 ] loss: 0.3678134083747864 2022-07-01 17:23:05.363449
Epoch:[ 47 10 ] loss: 0.367718905210495 2022-07-01 17:23:05.786531
Epoch:[ 47 11 ] loss: 0.36822083592414856 2022-07-01 17:23:06.202083
Epoch:[ 47 12 ] loss: 0.3675196170806885 2022-07-01 17:23:06.617810
Epoch:[ 47 13 ] loss: 0.368348628282547 2022-07-01 17:23:07.032547
Epoch:[ 47 14 ] loss: 0.366701602935791 2022-07-01 17:23:07.447318
Epoch:[ 47 15 ] loss: 0.368104487657547 2022-07-01 17:23:07.861470
Epoch:[ 47 16 ] loss: 0.3687267601490021 2022-07-01 17:23:13.353222
Epoch:[ 47 17 ] loss: 0.36817649006843567 2022-07-01 17:23:13.767810
Epoch:[ 47 18 ] loss: 0.3690349757671356 2022-07-01 17:23:14.184400
Epoch:[ 47 19 ] loss: 0.36849841475486755 2022-07-01 17:23:14.606271
Training_Epoch:[ 47 ] Training_loss: 0.3679423451423645 2022-07-01 17:23:14.606908
learning rate:  0.0004096000000000001
val: 1 0.39092400670051575
val: 2 0.38471367955207825
val: 3 0.38511383533477783
val: 4 0.38660576939582825
val: 5 0.3862251043319702
val: 6 0.38516348600387573
val: 7 0.3924967050552368
val: 8 0.38358646631240845
val: 9 0.38626566529273987
val: 10 0.3873709440231323
val: 11 0.3827921748161316
val: 12 0.3943716287612915
val: 13 0.3848414123058319
val: 14 0.383893221616745
val: 15 0.38634225726127625
val: 16 0.381109356880188
val: 17 0.3890205919742584
val: 18 0.3891475796699524
val: 19 0.38654324412345886
val: 20 0.388566792011261
val_Epoch:[ 47 ] val_loss: 0.38675469607114793 2022-07-01 17:23:18.495312
start training 2022-07-01 17:23:18.592431
Epoch:[ 48 0 ] loss: 0.3673989772796631 2022-07-01 17:23:33.390106
Epoch:[ 48 1 ] loss: 0.36807218194007874 2022-07-01 17:23:33.809632
Epoch:[ 48 2 ] loss: 0.3674415051937103 2022-07-01 17:23:34.223529
Epoch:[ 48 3 ] loss: 0.36787623167037964 2022-07-01 17:23:34.638313
Epoch:[ 48 4 ] loss: 0.3692401647567749 2022-07-01 17:23:35.054017
Epoch:[ 48 5 ] loss: 0.3667561709880829 2022-07-01 17:23:35.468476
Epoch:[ 48 6 ] loss: 0.36754730343818665 2022-07-01 17:23:35.882244
Epoch:[ 48 7 ] loss: 0.3672715127468109 2022-07-01 17:23:36.296266
Epoch:[ 48 8 ] loss: 0.3677412271499634 2022-07-01 17:23:36.711836
Epoch:[ 48 9 ] loss: 0.367483913898468 2022-07-01 17:23:37.131354
Epoch:[ 48 10 ] loss: 0.3671763241291046 2022-07-01 17:23:37.553423
Epoch:[ 48 11 ] loss: 0.3671054244041443 2022-07-01 17:23:37.968600
Epoch:[ 48 12 ] loss: 0.3683544993400574 2022-07-01 17:23:38.386127
Epoch:[ 48 13 ] loss: 0.3679650127887726 2022-07-01 17:23:38.800219
Epoch:[ 48 14 ] loss: 0.36851590871810913 2022-07-01 17:23:39.214653
Epoch:[ 48 15 ] loss: 0.367247611284256 2022-07-01 17:23:39.628141
Epoch:[ 48 16 ] loss: 0.36703482270240784 2022-07-01 17:23:45.286873
Epoch:[ 48 17 ] loss: 0.36889874935150146 2022-07-01 17:23:45.704460
Epoch:[ 48 18 ] loss: 0.3680678904056549 2022-07-01 17:23:46.127617
Epoch:[ 48 19 ] loss: 0.3674125075340271 2022-07-01 17:23:46.543882
Training_Epoch:[ 48 ] Training_loss: 0.3677303969860077 2022-07-01 17:23:46.544550
learning rate:  0.0004096000000000001
netparams have been saved once 48
val: 1 0.38571274280548096
val: 2 0.3809942305088043
val: 3 0.3889329731464386
val: 4 0.39249134063720703
val: 5 0.38509318232536316
val: 6 0.3834480345249176
val: 7 0.3868119418621063
val: 8 0.3925201892852783
val: 9 0.3892687261104584
val: 10 0.38707488775253296
val: 11 0.3908521831035614
val: 12 0.38570132851600647
val: 13 0.3893018960952759
val: 14 0.386017382144928
val: 15 0.3875187933444977
val: 16 0.38535383343696594
val: 17 0.39599406719207764
val: 18 0.3843323886394501
val: 19 0.3846680223941803
val: 20 0.38390597701072693
val_Epoch:[ 48 ] val_loss: 0.3872997060418129 2022-07-01 17:23:50.960452
start training 2022-07-01 17:23:51.059076
Epoch:[ 49 0 ] loss: 0.3671611249446869 2022-07-01 17:24:05.912015
Epoch:[ 49 1 ] loss: 0.3661724030971527 2022-07-01 17:24:06.332398
Epoch:[ 49 2 ] loss: 0.36674919724464417 2022-07-01 17:24:06.746591
Epoch:[ 49 3 ] loss: 0.3681434094905853 2022-07-01 17:24:07.166566
Epoch:[ 49 4 ] loss: 0.36737364530563354 2022-07-01 17:24:07.582396
Epoch:[ 49 5 ] loss: 0.36786267161369324 2022-07-01 17:24:07.997032
Epoch:[ 49 6 ] loss: 0.3680851459503174 2022-07-01 17:24:08.415807
Epoch:[ 49 7 ] loss: 0.36764684319496155 2022-07-01 17:24:08.830545
Epoch:[ 49 8 ] loss: 0.36843976378440857 2022-07-01 17:24:09.246781
Epoch:[ 49 9 ] loss: 0.3664076328277588 2022-07-01 17:24:09.663972
Epoch:[ 49 10 ] loss: 0.3672769069671631 2022-07-01 17:24:10.080188
Epoch:[ 49 11 ] loss: 0.3689975142478943 2022-07-01 17:24:10.501710
Epoch:[ 49 12 ] loss: 0.3677550256252289 2022-07-01 17:24:10.920415
Epoch:[ 49 13 ] loss: 0.3657488226890564 2022-07-01 17:24:11.335794
Epoch:[ 49 14 ] loss: 0.3673616051673889 2022-07-01 17:24:11.748938
Epoch:[ 49 15 ] loss: 0.3686882555484772 2022-07-01 17:24:12.163974
Epoch:[ 49 16 ] loss: 0.36796101927757263 2022-07-01 17:24:17.074373
Epoch:[ 49 17 ] loss: 0.3679855763912201 2022-07-01 17:24:17.493468
Epoch:[ 49 18 ] loss: 0.36679714918136597 2022-07-01 17:24:17.921302
Epoch:[ 49 19 ] loss: 0.3671610653400421 2022-07-01 17:24:18.336447
Training_Epoch:[ 49 ] Training_loss: 0.3674887388944626 2022-07-01 17:24:18.337361
learning rate:  0.0004096000000000001
val: 1 0.3856755495071411
val: 2 0.3915949761867523
val: 3 0.39178234338760376
val: 4 0.3909090757369995
val: 5 0.39030948281288147
val: 6 0.3884982466697693
val: 7 0.3815566301345825
val: 8 0.38943809270858765
val: 9 0.3905662000179291
val: 10 0.3821845054626465
val: 11 0.386272668838501
val: 12 0.39142802357673645
val: 13 0.38156694173812866
val: 14 0.38485589623451233
val: 15 0.38603875041007996
val: 16 0.38183996081352234
val: 17 0.3883780241012573
val: 18 0.3876272737979889
val: 19 0.3837898373603821
val: 20 0.38979750871658325
val_Epoch:[ 49 ] val_loss: 0.38720549941062926 2022-07-01 17:24:22.204177
start training 2022-07-01 17:24:22.298053
Epoch:[ 50 0 ] loss: 0.36763641238212585 2022-07-01 17:24:36.872342
Epoch:[ 50 1 ] loss: 0.36748725175857544 2022-07-01 17:24:37.436611
Epoch:[ 50 2 ] loss: 0.36667683720588684 2022-07-01 17:24:37.855957
Epoch:[ 50 3 ] loss: 0.3674241304397583 2022-07-01 17:24:38.269881
Epoch:[ 50 4 ] loss: 0.3674847185611725 2022-07-01 17:24:38.684683
Epoch:[ 50 5 ] loss: 0.3664926588535309 2022-07-01 17:24:39.099655
Epoch:[ 50 6 ] loss: 0.3678014576435089 2022-07-01 17:24:39.522320
Epoch:[ 50 7 ] loss: 0.36745497584342957 2022-07-01 17:24:39.938947
Epoch:[ 50 8 ] loss: 0.3672168254852295 2022-07-01 17:24:40.353375
Epoch:[ 50 9 ] loss: 0.3684313893318176 2022-07-01 17:24:40.767503
Epoch:[ 50 10 ] loss: 0.3685991168022156 2022-07-01 17:24:41.181203
Epoch:[ 50 11 ] loss: 0.3679160475730896 2022-07-01 17:24:41.600862
Epoch:[ 50 12 ] loss: 0.36705148220062256 2022-07-01 17:24:42.017384
Epoch:[ 50 13 ] loss: 0.3672420382499695 2022-07-01 17:24:42.432617
Epoch:[ 50 14 ] loss: 0.3661945164203644 2022-07-01 17:24:42.846487
Epoch:[ 50 15 ] loss: 0.3684496283531189 2022-07-01 17:24:43.261292
Epoch:[ 50 16 ] loss: 0.36823534965515137 2022-07-01 17:24:48.277788
Epoch:[ 50 17 ] loss: 0.3666822910308838 2022-07-01 17:24:48.818382
Epoch:[ 50 18 ] loss: 0.3679148554801941 2022-07-01 17:24:49.237985
Epoch:[ 50 19 ] loss: 0.36903369426727295 2022-07-01 17:24:49.654027
Training_Epoch:[ 50 ] Training_loss: 0.3675712838768959 2022-07-01 17:24:49.654772
learning rate:  0.0004096000000000001
netparams have been saved once 50
val: 1 0.38339540362358093
val: 2 0.393534392118454
val: 3 0.3826659917831421
val: 4 0.38855671882629395
val: 5 0.38276681303977966
val: 6 0.38546764850616455
val: 7 0.3846212327480316
val: 8 0.3854624032974243
val: 9 0.3849209249019623
val: 10 0.3873315155506134
val: 11 0.388130247592926
val: 12 0.3860208988189697
val: 13 0.3830905556678772
val: 14 0.3839605748653412
val: 15 0.3941388726234436
val: 16 0.3920152187347412
val: 17 0.39137643575668335
val: 18 0.3937951922416687
val: 19 0.38583904504776
val: 20 0.3889888525009155
val_Epoch:[ 50 ] val_loss: 0.38730394691228864 2022-07-01 17:24:53.651348
start training 2022-07-01 17:24:53.746089
Epoch:[ 51 0 ] loss: 0.36685311794281006 2022-07-01 17:25:08.013339
Epoch:[ 51 1 ] loss: 0.366609126329422 2022-07-01 17:25:08.670589
Epoch:[ 51 2 ] loss: 0.3673125207424164 2022-07-01 17:25:09.083801
Epoch:[ 51 3 ] loss: 0.3663922846317291 2022-07-01 17:25:09.498149
Epoch:[ 51 4 ] loss: 0.36750784516334534 2022-07-01 17:25:09.921392
Epoch:[ 51 5 ] loss: 0.36844584345817566 2022-07-01 17:25:10.335618
Epoch:[ 51 6 ] loss: 0.3665566146373749 2022-07-01 17:25:10.752683
Epoch:[ 51 7 ] loss: 0.36682793498039246 2022-07-01 17:25:11.169270
Epoch:[ 51 8 ] loss: 0.36507242918014526 2022-07-01 17:25:11.585428
Epoch:[ 51 9 ] loss: 0.36646825075149536 2022-07-01 17:25:11.997532
Epoch:[ 51 10 ] loss: 0.3678937256336212 2022-07-01 17:25:12.412777
Epoch:[ 51 11 ] loss: 0.36637941002845764 2022-07-01 17:25:12.828301
Epoch:[ 51 12 ] loss: 0.366350919008255 2022-07-01 17:25:13.243130
Epoch:[ 51 13 ] loss: 0.3661375343799591 2022-07-01 17:25:13.659755
Epoch:[ 51 14 ] loss: 0.3670003414154053 2022-07-01 17:25:14.071311
Epoch:[ 51 15 ] loss: 0.36649060249328613 2022-07-01 17:25:14.487210
Epoch:[ 51 16 ] loss: 0.3686799108982086 2022-07-01 17:25:19.696188
Epoch:[ 51 17 ] loss: 0.3678727447986603 2022-07-01 17:25:20.104520
Epoch:[ 51 18 ] loss: 0.3674701452255249 2022-07-01 17:25:20.524369
Epoch:[ 51 19 ] loss: 0.3677082657814026 2022-07-01 17:25:20.932402
Training_Epoch:[ 51 ] Training_loss: 0.3670014783740044 2022-07-01 17:25:20.933196
learning rate:  0.0003276800000000001
val: 1 0.3875470459461212
val: 2 0.38195860385894775
val: 3 0.3876170516014099
val: 4 0.3886650502681732
val: 5 0.3901042938232422
val: 6 0.3866117596626282
val: 7 0.38874509930610657
val: 8 0.38822218775749207
val: 9 0.3825114965438843
val: 10 0.38481053709983826
val: 11 0.3872969150543213
val: 12 0.39174309372901917
val: 13 0.3822876811027527
val: 14 0.378138929605484
val: 15 0.38774794340133667
val: 16 0.3926457464694977
val: 17 0.3823833763599396
val: 18 0.39227157831192017
val: 19 0.388908714056015
val: 20 0.3790009319782257
val_Epoch:[ 51 ] val_loss: 0.3864609017968178 2022-07-01 17:25:24.895488
start training 2022-07-01 17:25:24.992066
Epoch:[ 52 0 ] loss: 0.3655613660812378 2022-07-01 17:25:39.752172
Epoch:[ 52 1 ] loss: 0.36634236574172974 2022-07-01 17:25:40.168224
Epoch:[ 52 2 ] loss: 0.3660013675689697 2022-07-01 17:25:40.583503
Epoch:[ 52 3 ] loss: 0.3661908209323883 2022-07-01 17:25:41.002882
Epoch:[ 52 4 ] loss: 0.3663446009159088 2022-07-01 17:25:41.418499
Epoch:[ 52 5 ] loss: 0.36638692021369934 2022-07-01 17:25:41.835759
Epoch:[ 52 6 ] loss: 0.36668696999549866 2022-07-01 17:25:42.251755
Epoch:[ 52 7 ] loss: 0.3681371510028839 2022-07-01 17:25:42.662591
Epoch:[ 52 8 ] loss: 0.3660673201084137 2022-07-01 17:25:43.073598
Epoch:[ 52 9 ] loss: 0.367887407541275 2022-07-01 17:25:43.488641
Epoch:[ 52 10 ] loss: 0.36781957745552063 2022-07-01 17:25:43.904449
Epoch:[ 52 11 ] loss: 0.36648860573768616 2022-07-01 17:25:44.320241
Epoch:[ 52 12 ] loss: 0.36586442589759827 2022-07-01 17:25:44.730612
Epoch:[ 52 13 ] loss: 0.36812448501586914 2022-07-01 17:25:45.147264
Epoch:[ 52 14 ] loss: 0.3661879003047943 2022-07-01 17:25:45.563306
Epoch:[ 52 15 ] loss: 0.36691713333129883 2022-07-01 17:25:45.980217
Epoch:[ 52 16 ] loss: 0.36638081073760986 2022-07-01 17:25:51.267477
Epoch:[ 52 17 ] loss: 0.3663772940635681 2022-07-01 17:25:51.687013
Epoch:[ 52 18 ] loss: 0.36686649918556213 2022-07-01 17:25:52.111562
Epoch:[ 52 19 ] loss: 0.36717280745506287 2022-07-01 17:25:52.525295
Training_Epoch:[ 52 ] Training_loss: 0.36669029146432874 2022-07-01 17:25:52.526267
learning rate:  0.0003276800000000001
netparams have been saved once 52
val: 1 0.3858600854873657
val: 2 0.3862802982330322
val: 3 0.38270875811576843
val: 4 0.3851605951786041
val: 5 0.3849617540836334
val: 6 0.3829224705696106
val: 7 0.3839741051197052
val: 8 0.38518026471138
val: 9 0.39368483424186707
val: 10 0.3876735270023346
val: 11 0.3822937607765198
val: 12 0.38167905807495117
val: 13 0.3831006586551666
val: 14 0.38825249671936035
val: 15 0.38953617215156555
val: 16 0.38769930601119995
val: 17 0.3925703465938568
val: 18 0.38716840744018555
val: 19 0.38524356484413147
val: 20 0.39152172207832336
val_Epoch:[ 52 ] val_loss: 0.3863736093044281 2022-07-01 17:25:56.496013
start training 2022-07-01 17:25:56.593181
Epoch:[ 53 0 ] loss: 0.36723530292510986 2022-07-01 17:26:11.419789
Epoch:[ 53 1 ] loss: 0.36683034896850586 2022-07-01 17:26:11.836223
Epoch:[ 53 2 ] loss: 0.36520472168922424 2022-07-01 17:26:12.252359
Epoch:[ 53 3 ] loss: 0.3671417236328125 2022-07-01 17:26:12.667550
Epoch:[ 53 4 ] loss: 0.3656853437423706 2022-07-01 17:26:13.080753
Epoch:[ 53 5 ] loss: 0.3664442002773285 2022-07-01 17:26:13.495147
Epoch:[ 53 6 ] loss: 0.3668496310710907 2022-07-01 17:26:13.910016
Epoch:[ 53 7 ] loss: 0.3663662075996399 2022-07-01 17:26:14.329595
Epoch:[ 53 8 ] loss: 0.3666214346885681 2022-07-01 17:26:14.745104
Epoch:[ 53 9 ] loss: 0.3663904070854187 2022-07-01 17:26:15.161249
Epoch:[ 53 10 ] loss: 0.3660459816455841 2022-07-01 17:26:15.582952
Epoch:[ 53 11 ] loss: 0.36598438024520874 2022-07-01 17:26:15.999989
Epoch:[ 53 12 ] loss: 0.3675490915775299 2022-07-01 17:26:16.414689
Epoch:[ 53 13 ] loss: 0.36767899990081787 2022-07-01 17:26:16.834510
Epoch:[ 53 14 ] loss: 0.3676813244819641 2022-07-01 17:26:17.251431
Epoch:[ 53 15 ] loss: 0.3665415644645691 2022-07-01 17:26:17.667843
Epoch:[ 53 16 ] loss: 0.3671169877052307 2022-07-01 17:26:23.278300
Epoch:[ 53 17 ] loss: 0.36682578921318054 2022-07-01 17:26:23.698519
Epoch:[ 53 18 ] loss: 0.36650019884109497 2022-07-01 17:26:24.119586
Epoch:[ 53 19 ] loss: 0.3652341961860657 2022-07-01 17:26:24.534037
Training_Epoch:[ 53 ] Training_loss: 0.3665963917970657 2022-07-01 17:26:24.534738
learning rate:  0.0003276800000000001
val: 1 0.3857539892196655
val: 2 0.3918123245239258
val: 3 0.38604438304901123
val: 4 0.3891630172729492
val: 5 0.3829200267791748
val: 6 0.3887113630771637
val: 7 0.38645756244659424
val: 8 0.3872455358505249
val: 9 0.3790103495121002
val: 10 0.38787057995796204
val: 11 0.3850991129875183
val: 12 0.3885396718978882
val: 13 0.38514333963394165
val: 14 0.39254170656204224
val: 15 0.3916383981704712
val: 16 0.39244186878204346
val: 17 0.38425883650779724
val: 18 0.37932050228118896
val: 19 0.3914141058921814
val: 20 0.387848824262619
val_Epoch:[ 53 ] val_loss: 0.38716177493333814 2022-07-01 17:26:28.433569
start training 2022-07-01 17:26:28.530926
Epoch:[ 54 0 ] loss: 0.3656209409236908 2022-07-01 17:26:43.533611
Epoch:[ 54 1 ] loss: 0.36720871925354004 2022-07-01 17:26:43.946588
Epoch:[ 54 2 ] loss: 0.36690494418144226 2022-07-01 17:26:44.362178
Epoch:[ 54 3 ] loss: 0.36605870723724365 2022-07-01 17:26:44.778574
Epoch:[ 54 4 ] loss: 0.3663843870162964 2022-07-01 17:26:45.194697
Epoch:[ 54 5 ] loss: 0.3659074306488037 2022-07-01 17:26:45.615596
Epoch:[ 54 6 ] loss: 0.36644890904426575 2022-07-01 17:26:46.029359
Epoch:[ 54 7 ] loss: 0.36740055680274963 2022-07-01 17:26:46.449314
Epoch:[ 54 8 ] loss: 0.3667813241481781 2022-07-01 17:26:46.863594
Epoch:[ 54 9 ] loss: 0.3650740385055542 2022-07-01 17:26:47.278023
Epoch:[ 54 10 ] loss: 0.3663293123245239 2022-07-01 17:26:47.692943
Epoch:[ 54 11 ] loss: 0.3671712577342987 2022-07-01 17:26:48.107881
Epoch:[ 54 12 ] loss: 0.36623847484588623 2022-07-01 17:26:48.521618
Epoch:[ 54 13 ] loss: 0.3654661774635315 2022-07-01 17:26:48.935672
Epoch:[ 54 14 ] loss: 0.36748749017715454 2022-07-01 17:26:49.355535
Epoch:[ 54 15 ] loss: 0.36632564663887024 2022-07-01 17:26:49.771605
Epoch:[ 54 16 ] loss: 0.3665885329246521 2022-07-01 17:26:55.244794
Epoch:[ 54 17 ] loss: 0.3665373623371124 2022-07-01 17:26:55.659823
Epoch:[ 54 18 ] loss: 0.36739516258239746 2022-07-01 17:26:56.075634
Epoch:[ 54 19 ] loss: 0.36511826515197754 2022-07-01 17:26:56.496105
Training_Epoch:[ 54 ] Training_loss: 0.36642238199710847 2022-07-01 17:26:56.496802
learning rate:  0.0003276800000000001
netparams have been saved once 54
val: 1 0.3906265199184418
val: 2 0.3910493850708008
val: 3 0.3825836479663849
val: 4 0.3921480178833008
val: 5 0.38674354553222656
val: 6 0.39022600650787354
val: 7 0.38856008648872375
val: 8 0.38635891675949097
val: 9 0.3885277509689331
val: 10 0.388788640499115
val: 11 0.3934704661369324
val: 12 0.3903743326663971
val: 13 0.3845711648464203
val: 14 0.3857971131801605
val: 15 0.3914477825164795
val: 16 0.3828139007091522
val: 17 0.3876843750476837
val: 18 0.39421290159225464
val: 19 0.38614150881767273
val: 20 0.3819410800933838
val_Epoch:[ 54 ] val_loss: 0.3882033571600914 2022-07-01 17:27:00.524790
start training 2022-07-01 17:27:00.622631
Epoch:[ 55 0 ] loss: 0.36543065309524536 2022-07-01 17:27:15.309682
Epoch:[ 55 1 ] loss: 0.36580315232276917 2022-07-01 17:27:15.732447
Epoch:[ 55 2 ] loss: 0.3652505576610565 2022-07-01 17:27:16.146836
Epoch:[ 55 3 ] loss: 0.3669908046722412 2022-07-01 17:27:16.561856
Epoch:[ 55 4 ] loss: 0.3657006621360779 2022-07-01 17:27:16.978028
Epoch:[ 55 5 ] loss: 0.364865243434906 2022-07-01 17:27:17.393514
Epoch:[ 55 6 ] loss: 0.36588457226753235 2022-07-01 17:27:17.807258
Epoch:[ 55 7 ] loss: 0.3661048114299774 2022-07-01 17:27:18.218082
Epoch:[ 55 8 ] loss: 0.36563995480537415 2022-07-01 17:27:18.634106
Epoch:[ 55 9 ] loss: 0.3673844337463379 2022-07-01 17:27:19.058001
Epoch:[ 55 10 ] loss: 0.3668993413448334 2022-07-01 17:27:19.474502
Epoch:[ 55 11 ] loss: 0.3660540282726288 2022-07-01 17:27:19.893313
Epoch:[ 55 12 ] loss: 0.36601439118385315 2022-07-01 17:27:20.302478
Epoch:[ 55 13 ] loss: 0.36663031578063965 2022-07-01 17:27:20.718994
Epoch:[ 55 14 ] loss: 0.36790451407432556 2022-07-01 17:27:21.132956
Epoch:[ 55 15 ] loss: 0.36683720350265503 2022-07-01 17:27:21.547769
Epoch:[ 55 16 ] loss: 0.3662467300891876 2022-07-01 17:27:27.226404
Epoch:[ 55 17 ] loss: 0.36771100759506226 2022-07-01 17:27:27.636359
Epoch:[ 55 18 ] loss: 0.36726996302604675 2022-07-01 17:27:28.066115
Epoch:[ 55 19 ] loss: 0.36673790216445923 2022-07-01 17:27:28.481307
Training_Epoch:[ 55 ] Training_loss: 0.3663680121302605 2022-07-01 17:27:28.482356
learning rate:  0.0003276800000000001
val: 1 0.39468851685523987
val: 2 0.3913100063800812
val: 3 0.39095374941825867
val: 4 0.3910064101219177
val: 5 0.3811042308807373
val: 6 0.38453489542007446
val: 7 0.3896631896495819
val: 8 0.38691169023513794
val: 9 0.39236438274383545
val: 10 0.38864436745643616
val: 11 0.38535162806510925
val: 12 0.382937490940094
val: 13 0.384086012840271
val: 14 0.39197397232055664
val: 15 0.3972831964492798
val: 16 0.38916072249412537
val: 17 0.3889254927635193
val: 18 0.3870866894721985
val: 19 0.39038634300231934
val: 20 0.39640486240386963
val_Epoch:[ 55 ] val_loss: 0.38923889249563215 2022-07-01 17:27:32.433155
start training 2022-07-01 17:27:32.529116
Epoch:[ 56 0 ] loss: 0.3657952547073364 2022-07-01 17:27:47.402993
Epoch:[ 56 1 ] loss: 0.3669152855873108 2022-07-01 17:27:47.816629
Epoch:[ 56 2 ] loss: 0.3645937442779541 2022-07-01 17:27:48.236752
Epoch:[ 56 3 ] loss: 0.3660443425178528 2022-07-01 17:27:48.652836
Epoch:[ 56 4 ] loss: 0.36499813199043274 2022-07-01 17:27:49.068691
Epoch:[ 56 5 ] loss: 0.3660568296909332 2022-07-01 17:27:49.491556
Epoch:[ 56 6 ] loss: 0.36611247062683105 2022-07-01 17:27:49.910006
Epoch:[ 56 7 ] loss: 0.3657013773918152 2022-07-01 17:27:50.323933
Epoch:[ 56 8 ] loss: 0.3672136664390564 2022-07-01 17:27:50.738585
Epoch:[ 56 9 ] loss: 0.36671683192253113 2022-07-01 17:27:51.152543
Epoch:[ 56 10 ] loss: 0.36703479290008545 2022-07-01 17:27:51.572182
Epoch:[ 56 11 ] loss: 0.36671876907348633 2022-07-01 17:27:51.987226
Epoch:[ 56 12 ] loss: 0.36516764760017395 2022-07-01 17:27:52.403227
Epoch:[ 56 13 ] loss: 0.36616331338882446 2022-07-01 17:27:52.817403
Epoch:[ 56 14 ] loss: 0.3667663633823395 2022-07-01 17:27:53.231597
Epoch:[ 56 15 ] loss: 0.36646389961242676 2022-07-01 17:27:53.645419
Epoch:[ 56 16 ] loss: 0.3655906021595001 2022-07-01 17:27:58.916916
Epoch:[ 56 17 ] loss: 0.36574026942253113 2022-07-01 17:27:59.334846
Epoch:[ 56 18 ] loss: 0.36587268114089966 2022-07-01 17:27:59.752010
Epoch:[ 56 19 ] loss: 0.3666629493236542 2022-07-01 17:28:00.165967
Training_Epoch:[ 56 ] Training_loss: 0.3661164611577988 2022-07-01 17:28:00.166649
learning rate:  0.0003276800000000001
netparams have been saved once 56
val: 1 0.38107043504714966
val: 2 0.3863905668258667
val: 3 0.39014843106269836
val: 4 0.3922302722930908
val: 5 0.3810662627220154
val: 6 0.38689592480659485
val: 7 0.38144451379776
val: 8 0.39067336916923523
val: 9 0.38512706756591797
val: 10 0.3870164453983307
val: 11 0.38711458444595337
val: 12 0.390298455953598
val: 13 0.38635021448135376
val: 14 0.3856505751609802
val: 15 0.39451393485069275
val: 16 0.39741650223731995
val: 17 0.38773828744888306
val: 18 0.38894230127334595
val: 19 0.38354018330574036
val: 20 0.37629434466362
val_Epoch:[ 56 ] val_loss: 0.38699613362550733 2022-07-01 17:28:04.048133
start training 2022-07-01 17:28:04.145025
Epoch:[ 57 0 ] loss: 0.36494362354278564 2022-07-01 17:28:18.755859
Epoch:[ 57 1 ] loss: 0.3659229576587677 2022-07-01 17:28:19.170137
Epoch:[ 57 2 ] loss: 0.36582720279693604 2022-07-01 17:28:19.584586
Epoch:[ 57 3 ] loss: 0.36420130729675293 2022-07-01 17:28:20.005171
Epoch:[ 57 4 ] loss: 0.3672555983066559 2022-07-01 17:28:20.419126
Epoch:[ 57 5 ] loss: 0.3661554455757141 2022-07-01 17:28:20.835074
Epoch:[ 57 6 ] loss: 0.36603420972824097 2022-07-01 17:28:21.251121
Epoch:[ 57 7 ] loss: 0.3669755160808563 2022-07-01 17:28:21.666289
Epoch:[ 57 8 ] loss: 0.36707180738449097 2022-07-01 17:28:22.086953
Epoch:[ 57 9 ] loss: 0.3667230010032654 2022-07-01 17:28:22.501037
Epoch:[ 57 10 ] loss: 0.36640021204948425 2022-07-01 17:28:22.915875
Epoch:[ 57 11 ] loss: 0.3652448356151581 2022-07-01 17:28:23.336081
Epoch:[ 57 12 ] loss: 0.36670711636543274 2022-07-01 17:28:23.753155
Epoch:[ 57 13 ] loss: 0.36646750569343567 2022-07-01 17:28:24.169124
Epoch:[ 57 14 ] loss: 0.36612245440483093 2022-07-01 17:28:24.583859
Epoch:[ 57 15 ] loss: 0.36746451258659363 2022-07-01 17:28:24.998209
Epoch:[ 57 16 ] loss: 0.36618587374687195 2022-07-01 17:28:30.309098
Epoch:[ 57 17 ] loss: 0.3655828535556793 2022-07-01 17:28:30.743967
Epoch:[ 57 18 ] loss: 0.364572137594223 2022-07-01 17:28:31.158491
Epoch:[ 57 19 ] loss: 0.36571750044822693 2022-07-01 17:28:31.581077
Training_Epoch:[ 57 ] Training_loss: 0.36607878357172013 2022-07-01 17:28:31.581797
learning rate:  0.0003276800000000001
val: 1 0.38783225417137146
val: 2 0.389638751745224
val: 3 0.39482325315475464
val: 4 0.39013513922691345
val: 5 0.38738691806793213
val: 6 0.3876020014286041
val: 7 0.37996846437454224
val: 8 0.3840338885784149
val: 9 0.38126882910728455
val: 10 0.3937438428401947
val: 11 0.3868388831615448
val: 12 0.3884613513946533
val: 13 0.38996484875679016
val: 14 0.3919481337070465
val: 15 0.3911163806915283
val: 16 0.38509106636047363
val: 17 0.38492661714553833
val: 18 0.3875080347061157
val: 19 0.38798046112060547
val: 20 0.391191691160202
val_Epoch:[ 57 ] val_loss: 0.3880730405449867 2022-07-01 17:28:35.479818
start training 2022-07-01 17:28:35.576046
Epoch:[ 58 0 ] loss: 0.366300106048584 2022-07-01 17:28:49.922351
Epoch:[ 58 1 ] loss: 0.36552155017852783 2022-07-01 17:28:50.578566
Epoch:[ 58 2 ] loss: 0.3661864399909973 2022-07-01 17:28:50.993981
Epoch:[ 58 3 ] loss: 0.3651587963104248 2022-07-01 17:28:51.413963
Epoch:[ 58 4 ] loss: 0.3668532073497772 2022-07-01 17:28:51.829413
Epoch:[ 58 5 ] loss: 0.3659622073173523 2022-07-01 17:28:52.241545
Epoch:[ 58 6 ] loss: 0.36631062626838684 2022-07-01 17:28:52.656756
Epoch:[ 58 7 ] loss: 0.36627328395843506 2022-07-01 17:28:53.072960
Epoch:[ 58 8 ] loss: 0.3662898540496826 2022-07-01 17:28:53.487479
Epoch:[ 58 9 ] loss: 0.36550164222717285 2022-07-01 17:28:53.899149
Epoch:[ 58 10 ] loss: 0.3655549883842468 2022-07-01 17:28:54.312533
Epoch:[ 58 11 ] loss: 0.3667633533477783 2022-07-01 17:28:54.725646
Epoch:[ 58 12 ] loss: 0.36504900455474854 2022-07-01 17:28:55.144200
Epoch:[ 58 13 ] loss: 0.36614271998405457 2022-07-01 17:28:55.559429
Epoch:[ 58 14 ] loss: 0.3662188649177551 2022-07-01 17:28:55.975233
Epoch:[ 58 15 ] loss: 0.3653809428215027 2022-07-01 17:28:56.397527
Epoch:[ 58 16 ] loss: 0.3654868006706238 2022-07-01 17:29:01.456565
Epoch:[ 58 17 ] loss: 0.364883154630661 2022-07-01 17:29:01.997460
Epoch:[ 58 18 ] loss: 0.3669109344482422 2022-07-01 17:29:02.417761
Epoch:[ 58 19 ] loss: 0.36528757214546204 2022-07-01 17:29:02.830630
Training_Epoch:[ 58 ] Training_loss: 0.3659018024802208 2022-07-01 17:29:02.831256
learning rate:  0.0003276800000000001
netparams have been saved once 58
val: 1 0.3865334689617157
val: 2 0.3909713625907898
val: 3 0.3847915232181549
val: 4 0.3874523639678955
val: 5 0.38539329171180725
val: 6 0.37891432642936707
val: 7 0.3885657787322998
val: 8 0.3830106556415558
val: 9 0.3867877125740051
val: 10 0.3888705372810364
val: 11 0.3852810859680176
val: 12 0.38860979676246643
val: 13 0.3857496976852417
val: 14 0.38630712032318115
val: 15 0.3851322829723358
val: 16 0.3827483355998993
val: 17 0.3911083936691284
val: 18 0.3812828063964844
val: 19 0.3871866762638092
val: 20 0.39599063992500305
val_Epoch:[ 58 ] val_loss: 0.3865343928337097 2022-07-01 17:29:06.857918
start training 2022-07-01 17:29:06.956307
Epoch:[ 59 0 ] loss: 0.3665165305137634 2022-07-01 17:29:21.656334
Epoch:[ 59 1 ] loss: 0.3645569384098053 2022-07-01 17:29:22.072693
Epoch:[ 59 2 ] loss: 0.36606013774871826 2022-07-01 17:29:22.487562
Epoch:[ 59 3 ] loss: 0.36635252833366394 2022-07-01 17:29:22.900703
Epoch:[ 59 4 ] loss: 0.3654778301715851 2022-07-01 17:29:23.315090
Epoch:[ 59 5 ] loss: 0.36624258756637573 2022-07-01 17:29:23.728634
Epoch:[ 59 6 ] loss: 0.3654012978076935 2022-07-01 17:29:24.142811
Epoch:[ 59 7 ] loss: 0.3670293092727661 2022-07-01 17:29:24.561081
Epoch:[ 59 8 ] loss: 0.36694657802581787 2022-07-01 17:29:24.977520
Epoch:[ 59 9 ] loss: 0.3649207651615143 2022-07-01 17:29:25.391458
Epoch:[ 59 10 ] loss: 0.366849422454834 2022-07-01 17:29:25.808543
Epoch:[ 59 11 ] loss: 0.36567622423171997 2022-07-01 17:29:26.228873
Epoch:[ 59 12 ] loss: 0.36417415738105774 2022-07-01 17:29:26.649247
Epoch:[ 59 13 ] loss: 0.36611875891685486 2022-07-01 17:29:27.062140
Epoch:[ 59 14 ] loss: 0.3650909960269928 2022-07-01 17:29:27.478326
Epoch:[ 59 15 ] loss: 0.3651513457298279 2022-07-01 17:29:27.899767
Epoch:[ 59 16 ] loss: 0.3653637766838074 2022-07-01 17:29:33.439561
Epoch:[ 59 17 ] loss: 0.366293340921402 2022-07-01 17:29:33.858671
Epoch:[ 59 18 ] loss: 0.3660259246826172 2022-07-01 17:29:34.279981
Epoch:[ 59 19 ] loss: 0.3662510812282562 2022-07-01 17:29:34.693548
Training_Epoch:[ 59 ] Training_loss: 0.3658249765634537 2022-07-01 17:29:34.694250
learning rate:  0.0003276800000000001
val: 1 0.39262863993644714
val: 2 0.38794419169425964
val: 3 0.3919335603713989
val: 4 0.38733261823654175
val: 5 0.3858587145805359
val: 6 0.38893911242485046
val: 7 0.3923812210559845
val: 8 0.38849663734436035
val: 9 0.38154610991477966
val: 10 0.38565513491630554
val: 11 0.37935981154441833
val: 12 0.39414748549461365
val: 13 0.3874991238117218
val: 14 0.3874082565307617
val: 15 0.39300844073295593
val: 16 0.39072883129119873
val: 17 0.3862378001213074
val: 18 0.3938020169734955
val: 19 0.38433048129081726
val: 20 0.3830307126045227
val_Epoch:[ 59 ] val_loss: 0.3881134450435638 2022-07-01 17:29:38.556889
start training 2022-07-01 17:29:38.654533
Epoch:[ 60 0 ] loss: 0.3647863268852234 2022-07-01 17:29:53.924222
Epoch:[ 60 1 ] loss: 0.36592429876327515 2022-07-01 17:29:54.339715
Epoch:[ 60 2 ] loss: 0.3667084872722626 2022-07-01 17:29:54.755823
Epoch:[ 60 3 ] loss: 0.36541125178337097 2022-07-01 17:29:55.177043
Epoch:[ 60 4 ] loss: 0.36540424823760986 2022-07-01 17:29:55.592078
Epoch:[ 60 5 ] loss: 0.3672662079334259 2022-07-01 17:29:56.006798
Epoch:[ 60 6 ] loss: 0.3662710189819336 2022-07-01 17:29:56.427711
Epoch:[ 60 7 ] loss: 0.3653324246406555 2022-07-01 17:29:56.841383
Epoch:[ 60 8 ] loss: 0.364857017993927 2022-07-01 17:29:57.258178
Epoch:[ 60 9 ] loss: 0.3658277988433838 2022-07-01 17:29:57.673419
Epoch:[ 60 10 ] loss: 0.365757554769516 2022-07-01 17:29:58.089659
Epoch:[ 60 11 ] loss: 0.36550962924957275 2022-07-01 17:29:58.505591
Epoch:[ 60 12 ] loss: 0.36739057302474976 2022-07-01 17:29:58.919985
Epoch:[ 60 13 ] loss: 0.36531862616539 2022-07-01 17:29:59.340268
Epoch:[ 60 14 ] loss: 0.366234689950943 2022-07-01 17:29:59.755708
Epoch:[ 60 15 ] loss: 0.36567503213882446 2022-07-01 17:30:00.172324
Epoch:[ 60 16 ] loss: 0.36432507634162903 2022-07-01 17:30:05.321562
Epoch:[ 60 17 ] loss: 0.3663461208343506 2022-07-01 17:30:05.735876
Epoch:[ 60 18 ] loss: 0.36567336320877075 2022-07-01 17:30:06.151673
Epoch:[ 60 19 ] loss: 0.36512550711631775 2022-07-01 17:30:06.574463
Training_Epoch:[ 60 ] Training_loss: 0.36575726270675657 2022-07-01 17:30:06.575113
learning rate:  0.0003276800000000001
netparams have been saved once 60
val: 1 0.3920832872390747
val: 2 0.3939305543899536
val: 3 0.3842077851295471
val: 4 0.38823264837265015
val: 5 0.39442309737205505
val: 6 0.3793623447418213
val: 7 0.3910524547100067
val: 8 0.3877403438091278
val: 9 0.3800807297229767
val: 10 0.39131760597229004
val: 11 0.3916056752204895
val: 12 0.39064496755599976
val: 13 0.3796522915363312
val: 14 0.38422074913978577
val: 15 0.38665178418159485
val: 16 0.39154598116874695
val: 17 0.38888034224510193
val: 18 0.3868015706539154
val: 19 0.3900860846042633
val: 20 0.3873876929283142
val_Epoch:[ 60 ] val_loss: 0.3879953995347023 2022-07-01 17:30:10.515707
start training 2022-07-01 17:30:10.614316
Epoch:[ 61 0 ] loss: 0.3676198124885559 2022-07-01 17:30:24.787354
Epoch:[ 61 1 ] loss: 0.3640892803668976 2022-07-01 17:30:25.201692
Epoch:[ 61 2 ] loss: 0.36559247970581055 2022-07-01 17:30:25.617097
Epoch:[ 61 3 ] loss: 0.36498233675956726 2022-07-01 17:30:26.042883
Epoch:[ 61 4 ] loss: 0.3651556670665741 2022-07-01 17:30:26.464096
Epoch:[ 61 5 ] loss: 0.36512836813926697 2022-07-01 17:30:26.877780
Epoch:[ 61 6 ] loss: 0.36503565311431885 2022-07-01 17:30:27.291498
Epoch:[ 61 7 ] loss: 0.3656165897846222 2022-07-01 17:30:27.704552
Epoch:[ 61 8 ] loss: 0.36726242303848267 2022-07-01 17:30:28.117925
Epoch:[ 61 9 ] loss: 0.36525431275367737 2022-07-01 17:30:28.539719
Epoch:[ 61 10 ] loss: 0.36526957154273987 2022-07-01 17:30:28.954600
Epoch:[ 61 11 ] loss: 0.3673049509525299 2022-07-01 17:30:29.369175
Epoch:[ 61 12 ] loss: 0.3647834062576294 2022-07-01 17:30:29.783094
Epoch:[ 61 13 ] loss: 0.36531150341033936 2022-07-01 17:30:30.197401
Epoch:[ 61 14 ] loss: 0.3653855323791504 2022-07-01 17:30:30.611289
Epoch:[ 61 15 ] loss: 0.3653121292591095 2022-07-01 17:30:31.026204
Epoch:[ 61 16 ] loss: 0.36619627475738525 2022-07-01 17:30:36.261037
Epoch:[ 61 17 ] loss: 0.3648148477077484 2022-07-01 17:30:36.810701
Epoch:[ 61 18 ] loss: 0.36523643136024475 2022-07-01 17:30:37.225130
Epoch:[ 61 19 ] loss: 0.3661443293094635 2022-07-01 17:30:37.644774
Training_Epoch:[ 61 ] Training_loss: 0.3655747950077057 2022-07-01 17:30:37.645401
learning rate:  0.0002621440000000001
val: 1 0.3885214626789093
val: 2 0.38313809037208557
val: 3 0.38554757833480835
val: 4 0.38341227173805237
val: 5 0.39023277163505554
val: 6 0.3914819657802582
val: 7 0.386588454246521
val: 8 0.388993501663208
val: 9 0.38970306515693665
val: 10 0.39109236001968384
val: 11 0.38426026701927185
val: 12 0.39176619052886963
val: 13 0.3852797746658325
val: 14 0.3836786150932312
val: 15 0.3819887042045593
val: 16 0.3899495601654053
val: 17 0.3824417293071747
val: 18 0.38985228538513184
val: 19 0.3839488923549652
val: 20 0.3909573554992676
val_Epoch:[ 61 ] val_loss: 0.3871417447924614 2022-07-01 17:30:41.466790
start training 2022-07-01 17:30:41.566078
Epoch:[ 62 0 ] loss: 0.36425894498825073 2022-07-01 17:30:56.192732
Epoch:[ 62 1 ] loss: 0.3659069836139679 2022-07-01 17:30:56.606011
Epoch:[ 62 2 ] loss: 0.3666301965713501 2022-07-01 17:30:57.019867
Epoch:[ 62 3 ] loss: 0.3653475046157837 2022-07-01 17:30:57.435593
Epoch:[ 62 4 ] loss: 0.3657265603542328 2022-07-01 17:30:57.859953
Epoch:[ 62 5 ] loss: 0.36499086022377014 2022-07-01 17:30:58.277176
Epoch:[ 62 6 ] loss: 0.3656548261642456 2022-07-01 17:30:58.692474
Epoch:[ 62 7 ] loss: 0.3658830225467682 2022-07-01 17:30:59.108446
Epoch:[ 62 8 ] loss: 0.36589178442955017 2022-07-01 17:30:59.526119
Epoch:[ 62 9 ] loss: 0.36527037620544434 2022-07-01 17:30:59.942487
Epoch:[ 62 10 ] loss: 0.3640497624874115 2022-07-01 17:31:00.362036
Epoch:[ 62 11 ] loss: 0.36590591073036194 2022-07-01 17:31:00.775480
Epoch:[ 62 12 ] loss: 0.3659578263759613 2022-07-01 17:31:01.189322
Epoch:[ 62 13 ] loss: 0.3652295768260956 2022-07-01 17:31:01.609105
Epoch:[ 62 14 ] loss: 0.3645866811275482 2022-07-01 17:31:02.024706
Epoch:[ 62 15 ] loss: 0.36512649059295654 2022-07-01 17:31:02.443534
Epoch:[ 62 16 ] loss: 0.3659299612045288 2022-07-01 17:31:07.761688
Epoch:[ 62 17 ] loss: 0.3651461601257324 2022-07-01 17:31:08.178992
Epoch:[ 62 18 ] loss: 0.3656807839870453 2022-07-01 17:31:08.608709
Epoch:[ 62 19 ] loss: 0.36552923917770386 2022-07-01 17:31:09.029603
Training_Epoch:[ 62 ] Training_loss: 0.36543517261743547 2022-07-01 17:31:09.030360
learning rate:  0.0002621440000000001
netparams have been saved once 62
val: 1 0.38692858815193176
val: 2 0.38764864206314087
val: 3 0.38978224992752075
val: 4 0.3905477821826935
val: 5 0.37970224022865295
val: 6 0.38629886507987976
val: 7 0.387494295835495
val: 8 0.3913441300392151
val: 9 0.3778044283390045
val: 10 0.394052118062973
val: 11 0.3848014175891876
val: 12 0.3848591446876526
val: 13 0.3880559504032135
val: 14 0.3899015486240387
val: 15 0.38622426986694336
val: 16 0.3864767849445343
val: 17 0.3924960792064667
val: 18 0.3930465579032898
val: 19 0.3905027210712433
val: 20 0.38635334372520447
val_Epoch:[ 62 ] val_loss: 0.38771605789661406 2022-07-01 17:31:13.122252
start training 2022-07-01 17:31:13.221649
Epoch:[ 63 0 ] loss: 0.364004522562027 2022-07-01 17:31:28.167907
Epoch:[ 63 1 ] loss: 0.3659611940383911 2022-07-01 17:31:28.582062
Epoch:[ 63 2 ] loss: 0.364836722612381 2022-07-01 17:31:28.997065
Epoch:[ 63 3 ] loss: 0.3649979531764984 2022-07-01 17:31:29.417032
Epoch:[ 63 4 ] loss: 0.3653992712497711 2022-07-01 17:31:29.835280
Epoch:[ 63 5 ] loss: 0.36645156145095825 2022-07-01 17:31:30.258188
Epoch:[ 63 6 ] loss: 0.36493048071861267 2022-07-01 17:31:30.674002
Epoch:[ 63 7 ] loss: 0.3659284710884094 2022-07-01 17:31:31.090563
Epoch:[ 63 8 ] loss: 0.36532968282699585 2022-07-01 17:31:31.513235
Epoch:[ 63 9 ] loss: 0.36619946360588074 2022-07-01 17:31:31.929002
Epoch:[ 63 10 ] loss: 0.36525776982307434 2022-07-01 17:31:32.347013
Epoch:[ 63 11 ] loss: 0.3655115067958832 2022-07-01 17:31:32.762750
Epoch:[ 63 12 ] loss: 0.3651396930217743 2022-07-01 17:31:33.180210
Epoch:[ 63 13 ] loss: 0.36610132455825806 2022-07-01 17:31:33.599280
Epoch:[ 63 14 ] loss: 0.364411860704422 2022-07-01 17:31:34.017558
Epoch:[ 63 15 ] loss: 0.3655075132846832 2022-07-01 17:31:34.431773
Epoch:[ 63 16 ] loss: 0.36587759852409363 2022-07-01 17:31:39.815752
Epoch:[ 63 17 ] loss: 0.3643113374710083 2022-07-01 17:31:40.236048
Epoch:[ 63 18 ] loss: 0.365727961063385 2022-07-01 17:31:40.658529
Epoch:[ 63 19 ] loss: 0.3649290204048157 2022-07-01 17:31:41.075587
Training_Epoch:[ 63 ] Training_loss: 0.36534074544906614 2022-07-01 17:31:41.076398
learning rate:  0.0002621440000000001
val: 1 0.38455691933631897
val: 2 0.3817588686943054
val: 3 0.3867019712924957
val: 4 0.3867482841014862
val: 5 0.39146822690963745
val: 6 0.3855970501899719
val: 7 0.3857439160346985
val: 8 0.3926134705543518
val: 9 0.3853073716163635
val: 10 0.3925742506980896
val: 11 0.3782969117164612
val: 12 0.38905277848243713
val: 13 0.3856608271598816
val: 14 0.3917233943939209
val: 15 0.38753005862236023
val: 16 0.389591246843338
val: 17 0.3834347426891327
val: 18 0.3792548179626465
val: 19 0.3823002874851227
val: 20 0.38604724407196045
val_Epoch:[ 63 ] val_loss: 0.38629813194274903 2022-07-01 17:31:44.991425
start training 2022-07-01 17:31:45.092078
Epoch:[ 64 0 ] loss: 0.36590978503227234 2022-07-01 17:31:59.756981
Epoch:[ 64 1 ] loss: 0.3648630380630493 2022-07-01 17:32:00.180116
Epoch:[ 64 2 ] loss: 0.3656980097293854 2022-07-01 17:32:00.595110
Epoch:[ 64 3 ] loss: 0.3648754954338074 2022-07-01 17:32:01.009800
Epoch:[ 64 4 ] loss: 0.36569860577583313 2022-07-01 17:32:01.432719
Epoch:[ 64 5 ] loss: 0.3663712441921234 2022-07-01 17:32:01.854405
Epoch:[ 64 6 ] loss: 0.3630335330963135 2022-07-01 17:32:02.271419
Epoch:[ 64 7 ] loss: 0.3651401996612549 2022-07-01 17:32:02.689522
Epoch:[ 64 8 ] loss: 0.36426547169685364 2022-07-01 17:32:03.106756
Epoch:[ 64 9 ] loss: 0.36637061834335327 2022-07-01 17:32:03.523852
Epoch:[ 64 10 ] loss: 0.3650053143501282 2022-07-01 17:32:03.940957
Epoch:[ 64 11 ] loss: 0.364542156457901 2022-07-01 17:32:04.359493
Epoch:[ 64 12 ] loss: 0.36532288789749146 2022-07-01 17:32:04.777044
Epoch:[ 64 13 ] loss: 0.3657938539981842 2022-07-01 17:32:05.192351
Epoch:[ 64 14 ] loss: 0.36422601342201233 2022-07-01 17:32:05.610114
Epoch:[ 64 15 ] loss: 0.3645130395889282 2022-07-01 17:32:06.030320
Epoch:[ 64 16 ] loss: 0.3644411861896515 2022-07-01 17:32:11.421227
Epoch:[ 64 17 ] loss: 0.365570604801178 2022-07-01 17:32:11.840667
Epoch:[ 64 18 ] loss: 0.3655068576335907 2022-07-01 17:32:12.264570
Epoch:[ 64 19 ] loss: 0.36582815647125244 2022-07-01 17:32:12.680949
Training_Epoch:[ 64 ] Training_loss: 0.3651488035917282 2022-07-01 17:32:12.681654
learning rate:  0.0002621440000000001
netparams have been saved once 64
val: 1 0.3876538872718811
val: 2 0.38433030247688293
val: 3 0.3811693787574768
val: 4 0.3884614109992981
val: 5 0.3866567015647888
val: 6 0.3821488618850708
val: 7 0.3958423137664795
val: 8 0.38924896717071533
val: 9 0.38355085253715515
val: 10 0.39025193452835083
val: 11 0.39202478528022766
val: 12 0.386912077665329
val: 13 0.3890669643878937
val: 14 0.38791322708129883
val: 15 0.391391783952713
val: 16 0.3929208517074585
val: 17 0.3922663629055023
val: 18 0.3934377133846283
val: 19 0.3867444694042206
val: 20 0.38889279961586
val_Epoch:[ 64 ] val_loss: 0.38854428231716154 2022-07-01 17:32:16.675681
start training 2022-07-01 17:32:16.783795
Epoch:[ 65 0 ] loss: 0.36448904871940613 2022-07-01 17:32:31.817113
Epoch:[ 65 1 ] loss: 0.36409884691238403 2022-07-01 17:32:32.232353
Epoch:[ 65 2 ] loss: 0.36527177691459656 2022-07-01 17:32:32.646945
Epoch:[ 65 3 ] loss: 0.36409541964530945 2022-07-01 17:32:33.069892
Epoch:[ 65 4 ] loss: 0.36558711528778076 2022-07-01 17:32:33.486717
Epoch:[ 65 5 ] loss: 0.3654311001300812 2022-07-01 17:32:33.900798
Epoch:[ 65 6 ] loss: 0.3650900721549988 2022-07-01 17:32:34.317270
Epoch:[ 65 7 ] loss: 0.3646884858608246 2022-07-01 17:32:34.738785
Epoch:[ 65 8 ] loss: 0.36667925119400024 2022-07-01 17:32:35.155097
Epoch:[ 65 9 ] loss: 0.36509108543395996 2022-07-01 17:32:35.571463
Epoch:[ 65 10 ] loss: 0.3659103810787201 2022-07-01 17:32:35.990420
Epoch:[ 65 11 ] loss: 0.3650550842285156 2022-07-01 17:32:36.411589
Epoch:[ 65 12 ] loss: 0.3649909198284149 2022-07-01 17:32:36.826102
Epoch:[ 65 13 ] loss: 0.3664984703063965 2022-07-01 17:32:37.242400
Epoch:[ 65 14 ] loss: 0.366045206785202 2022-07-01 17:32:37.658282
Epoch:[ 65 15 ] loss: 0.3645380735397339 2022-07-01 17:32:38.076821
Epoch:[ 65 16 ] loss: 0.36712199449539185 2022-07-01 17:32:43.377284
Epoch:[ 65 17 ] loss: 0.3649824857711792 2022-07-01 17:32:43.796834
Epoch:[ 65 18 ] loss: 0.3647487461566925 2022-07-01 17:32:44.212242
Epoch:[ 65 19 ] loss: 0.3653293251991272 2022-07-01 17:32:44.625056
Training_Epoch:[ 65 ] Training_loss: 0.3652871444821358 2022-07-01 17:32:44.625707
learning rate:  0.0002621440000000001
val: 1 0.3906387984752655
val: 2 0.378060907125473
val: 3 0.39039719104766846
val: 4 0.3832566440105438
val: 5 0.3947296440601349
val: 6 0.3927035629749298
val: 7 0.3854319155216217
val: 8 0.3845682740211487
val: 9 0.39043718576431274
val: 10 0.3884560465812683
val: 11 0.3872157335281372
val: 12 0.38698098063468933
val: 13 0.38668474555015564
val: 14 0.38605228066444397
val: 15 0.39162132143974304
val: 16 0.39088112115859985
val: 17 0.3904338479042053
val: 18 0.3941177427768707
val: 19 0.38643115758895874
val: 20 0.3849988579750061
val_Epoch:[ 65 ] val_loss: 0.38820489794015883 2022-07-01 17:32:48.529003
start training 2022-07-01 17:32:48.628211
Epoch:[ 66 0 ] loss: 0.36495283246040344 2022-07-01 17:33:03.570520
Epoch:[ 66 1 ] loss: 0.3661849796772003 2022-07-01 17:33:03.986966
Epoch:[ 66 2 ] loss: 0.36589857935905457 2022-07-01 17:33:04.401997
Epoch:[ 66 3 ] loss: 0.3647221624851227 2022-07-01 17:33:04.816471
Epoch:[ 66 4 ] loss: 0.36418357491493225 2022-07-01 17:33:05.231461
Epoch:[ 66 5 ] loss: 0.3628193736076355 2022-07-01 17:33:05.645718
Epoch:[ 66 6 ] loss: 0.36556512117385864 2022-07-01 17:33:06.059173
Epoch:[ 66 7 ] loss: 0.3666954040527344 2022-07-01 17:33:06.475706
Epoch:[ 66 8 ] loss: 0.36548370122909546 2022-07-01 17:33:06.892235
Epoch:[ 66 9 ] loss: 0.3647262156009674 2022-07-01 17:33:07.309252
Epoch:[ 66 10 ] loss: 0.36495134234428406 2022-07-01 17:33:07.726721
Epoch:[ 66 11 ] loss: 0.3664878010749817 2022-07-01 17:33:08.145046
Epoch:[ 66 12 ] loss: 0.365006685256958 2022-07-01 17:33:08.560341
Epoch:[ 66 13 ] loss: 0.363373726606369 2022-07-01 17:33:08.979983
Epoch:[ 66 14 ] loss: 0.36600807309150696 2022-07-01 17:33:09.390119
Epoch:[ 66 15 ] loss: 0.36425358057022095 2022-07-01 17:33:09.799830
Epoch:[ 66 16 ] loss: 0.36513611674308777 2022-07-01 17:33:15.032659
Epoch:[ 66 17 ] loss: 0.3646809458732605 2022-07-01 17:33:15.445337
Epoch:[ 66 18 ] loss: 0.3641972839832306 2022-07-01 17:33:15.855609
Epoch:[ 66 19 ] loss: 0.36571574211120605 2022-07-01 17:33:16.269099
Training_Epoch:[ 66 ] Training_loss: 0.3650521621108055 2022-07-01 17:33:16.269922
learning rate:  0.0002621440000000001
netparams have been saved once 66
val: 1 0.3946792781352997
val: 2 0.3897916376590729
val: 3 0.3837474584579468
val: 4 0.3849925696849823
val: 5 0.3859291076660156
val: 6 0.38363903760910034
val: 7 0.3851411044597626
val: 8 0.3854997754096985
val: 9 0.387997567653656
val: 10 0.3892049491405487
val: 11 0.3883855640888214
val: 12 0.3856155574321747
val: 13 0.38234955072402954
val: 14 0.3891000747680664
val: 15 0.382308691740036
val: 16 0.3873650133609772
val: 17 0.39277657866477966
val: 18 0.39112037420272827
val: 19 0.39029985666275024
val: 20 0.387273371219635
val_Epoch:[ 66 ] val_loss: 0.3873608559370041 2022-07-01 17:33:20.282685
start training 2022-07-01 17:33:20.381061
Epoch:[ 67 0 ] loss: 0.366004079580307 2022-07-01 17:33:34.771519
Epoch:[ 67 1 ] loss: 0.36548903584480286 2022-07-01 17:33:35.201258
Epoch:[ 67 2 ] loss: 0.36472225189208984 2022-07-01 17:33:35.623925
Epoch:[ 67 3 ] loss: 0.3638824224472046 2022-07-01 17:33:36.038225
Epoch:[ 67 4 ] loss: 0.3647922873497009 2022-07-01 17:33:36.458670
Epoch:[ 67 5 ] loss: 0.36484354734420776 2022-07-01 17:33:36.874577
Epoch:[ 67 6 ] loss: 0.36404961347579956 2022-07-01 17:33:37.289409
Epoch:[ 67 7 ] loss: 0.36405307054519653 2022-07-01 17:33:37.703206
Epoch:[ 67 8 ] loss: 0.3645852506160736 2022-07-01 17:33:38.120675
Epoch:[ 67 9 ] loss: 0.3635731339454651 2022-07-01 17:33:38.536267
Epoch:[ 67 10 ] loss: 0.36614856123924255 2022-07-01 17:33:38.951680
Epoch:[ 67 11 ] loss: 0.36460837721824646 2022-07-01 17:33:39.366011
Epoch:[ 67 12 ] loss: 0.3654038608074188 2022-07-01 17:33:39.780414
Epoch:[ 67 13 ] loss: 0.36566615104675293 2022-07-01 17:33:40.194580
Epoch:[ 67 14 ] loss: 0.36377549171447754 2022-07-01 17:33:40.608277
Epoch:[ 67 15 ] loss: 0.3646702468395233 2022-07-01 17:33:41.024522
Epoch:[ 67 16 ] loss: 0.363823264837265 2022-07-01 17:33:46.565294
Epoch:[ 67 17 ] loss: 0.3646544814109802 2022-07-01 17:33:46.982039
Epoch:[ 67 18 ] loss: 0.3668835759162903 2022-07-01 17:33:47.402070
Epoch:[ 67 19 ] loss: 0.3651527464389801 2022-07-01 17:33:47.816955
Training_Epoch:[ 67 ] Training_loss: 0.36483907252550124 2022-07-01 17:33:47.817817
learning rate:  0.0002621440000000001
val: 1 0.38264283537864685
val: 2 0.3831337094306946
val: 3 0.39108961820602417
val: 4 0.3915087878704071
val: 5 0.3993636667728424
val: 6 0.39139604568481445
val: 7 0.3908654749393463
val: 8 0.39063918590545654
val: 9 0.38789239525794983
val: 10 0.3828151524066925
val: 11 0.38947567343711853
val: 12 0.38254597783088684
val: 13 0.3896029591560364
val: 14 0.3891986608505249
val: 15 0.3877177834510803
val: 16 0.382554829120636
val: 17 0.3961372375488281
val: 18 0.3924066424369812
val: 19 0.3878942131996155
val: 20 0.38106101751327515
val_Epoch:[ 67 ] val_loss: 0.3884970933198929 2022-07-01 17:33:51.790231
start training 2022-07-01 17:33:51.890631
Epoch:[ 68 0 ] loss: 0.3655175566673279 2022-07-01 17:34:06.627058
Epoch:[ 68 1 ] loss: 0.36474746465682983 2022-07-01 17:34:07.041493
Epoch:[ 68 2 ] loss: 0.36388856172561646 2022-07-01 17:34:07.457533
Epoch:[ 68 3 ] loss: 0.3627837002277374 2022-07-01 17:34:07.875121
Epoch:[ 68 4 ] loss: 0.3636787533760071 2022-07-01 17:34:08.290844
Epoch:[ 68 5 ] loss: 0.36466705799102783 2022-07-01 17:34:08.713905
Epoch:[ 68 6 ] loss: 0.3640371263027191 2022-07-01 17:34:09.135767
Epoch:[ 68 7 ] loss: 0.3648660480976105 2022-07-01 17:34:09.550232
Epoch:[ 68 8 ] loss: 0.36457332968711853 2022-07-01 17:34:09.963833
Epoch:[ 68 9 ] loss: 0.3652404248714447 2022-07-01 17:34:10.380007
Epoch:[ 68 10 ] loss: 0.3649679720401764 2022-07-01 17:34:10.801644
Epoch:[ 68 11 ] loss: 0.36439424753189087 2022-07-01 17:34:11.223061
Epoch:[ 68 12 ] loss: 0.3657797574996948 2022-07-01 17:34:11.637885
Epoch:[ 68 13 ] loss: 0.3653070628643036 2022-07-01 17:34:12.055313
Epoch:[ 68 14 ] loss: 0.36495766043663025 2022-07-01 17:34:12.470678
Epoch:[ 68 15 ] loss: 0.36592167615890503 2022-07-01 17:34:12.884851
Epoch:[ 68 16 ] loss: 0.36487752199172974 2022-07-01 17:34:18.718973
Epoch:[ 68 17 ] loss: 0.36600521206855774 2022-07-01 17:34:19.134674
Epoch:[ 68 18 ] loss: 0.36555925011634827 2022-07-01 17:34:19.555825
Epoch:[ 68 19 ] loss: 0.36459702253341675 2022-07-01 17:34:19.979871
Training_Epoch:[ 68 ] Training_loss: 0.3648183703422546 2022-07-01 17:34:19.980639
learning rate:  0.0002621440000000001
netparams have been saved once 68
val: 1 0.38225439190864563
val: 2 0.38885432481765747
val: 3 0.38939040899276733
val: 4 0.38280513882637024
val: 5 0.39820238947868347
val: 6 0.38495340943336487
val: 7 0.38697004318237305
val: 8 0.3935740292072296
val: 9 0.3939637243747711
val: 10 0.3897417485713959
val: 11 0.38472530245780945
val: 12 0.38673046231269836
val: 13 0.3819723427295685
val: 14 0.3935073912143707
val: 15 0.3937297463417053
val: 16 0.3989616334438324
val: 17 0.3869788944721222
val: 18 0.38807567954063416
val: 19 0.39721783995628357
val: 20 0.3868752717971802
val_Epoch:[ 68 ] val_loss: 0.38947420865297316 2022-07-01 17:34:23.935743
start training 2022-07-01 17:34:24.035799
Epoch:[ 69 0 ] loss: 0.36539825797080994 2022-07-01 17:34:38.100114
Epoch:[ 69 1 ] loss: 0.36421653628349304 2022-07-01 17:34:38.518403
Epoch:[ 69 2 ] loss: 0.36562052369117737 2022-07-01 17:34:38.944639
Epoch:[ 69 3 ] loss: 0.3652507960796356 2022-07-01 17:34:39.361037
Epoch:[ 69 4 ] loss: 0.3651842474937439 2022-07-01 17:34:39.771971
Epoch:[ 69 5 ] loss: 0.3645590543746948 2022-07-01 17:34:40.194393
Epoch:[ 69 6 ] loss: 0.36538276076316833 2022-07-01 17:34:40.610624
Epoch:[ 69 7 ] loss: 0.36455193161964417 2022-07-01 17:34:41.025220
Epoch:[ 69 8 ] loss: 0.3657045364379883 2022-07-01 17:34:41.448100
Epoch:[ 69 9 ] loss: 0.36462464928627014 2022-07-01 17:34:41.857514
Epoch:[ 69 10 ] loss: 0.3638942539691925 2022-07-01 17:34:42.274168
Epoch:[ 69 11 ] loss: 0.36390429735183716 2022-07-01 17:34:42.689708
Epoch:[ 69 12 ] loss: 0.3647923171520233 2022-07-01 17:34:43.106362
Epoch:[ 69 13 ] loss: 0.3647938668727875 2022-07-01 17:34:43.530546
Epoch:[ 69 14 ] loss: 0.3644700050354004 2022-07-01 17:34:43.939283
Epoch:[ 69 15 ] loss: 0.36509689688682556 2022-07-01 17:34:44.353791
Epoch:[ 69 16 ] loss: 0.36413708329200745 2022-07-01 17:34:50.078384
Epoch:[ 69 17 ] loss: 0.3651774525642395 2022-07-01 17:34:50.498303
Epoch:[ 69 18 ] loss: 0.3653557002544403 2022-07-01 17:34:50.916002
Epoch:[ 69 19 ] loss: 0.3655615448951721 2022-07-01 17:34:51.339445
Training_Epoch:[ 69 ] Training_loss: 0.36488383561372756 2022-07-01 17:34:51.340242
learning rate:  0.0002621440000000001
val: 1 0.3868875205516815
val: 2 0.3888726532459259
val: 3 0.39235174655914307
val: 4 0.38860437273979187
val: 5 0.3883938491344452
val: 6 0.38558337092399597
val: 7 0.38966119289398193
val: 8 0.3862287402153015
val: 9 0.3892858922481537
val: 10 0.3784823715686798
val: 11 0.38700246810913086
val: 12 0.38926389813423157
val: 13 0.38928428292274475
val: 14 0.3851974606513977
val: 15 0.3899534344673157
val: 16 0.3829837739467621
val: 17 0.3881773054599762
val: 18 0.3920888602733612
val: 19 0.3839305639266968
val: 20 0.38807040452957153
val_Epoch:[ 69 ] val_loss: 0.3875152081251144 2022-07-01 17:34:55.284371
start training 2022-07-01 17:34:55.383771
Epoch:[ 70 0 ] loss: 0.3642065227031708 2022-07-01 17:35:09.647373
Epoch:[ 70 1 ] loss: 0.36506932973861694 2022-07-01 17:35:10.236168
Epoch:[ 70 2 ] loss: 0.3640501797199249 2022-07-01 17:35:10.650270
Epoch:[ 70 3 ] loss: 0.36479121446609497 2022-07-01 17:35:11.064878
Epoch:[ 70 4 ] loss: 0.36490997672080994 2022-07-01 17:35:11.481361
Epoch:[ 70 5 ] loss: 0.3655116558074951 2022-07-01 17:35:11.897862
Epoch:[ 70 6 ] loss: 0.3646228611469269 2022-07-01 17:35:12.312622
Epoch:[ 70 7 ] loss: 0.36492323875427246 2022-07-01 17:35:12.727446
Epoch:[ 70 8 ] loss: 0.3664438724517822 2022-07-01 17:35:13.143086
Epoch:[ 70 9 ] loss: 0.36562275886535645 2022-07-01 17:35:13.556768
Epoch:[ 70 10 ] loss: 0.3645628094673157 2022-07-01 17:35:13.970398
Epoch:[ 70 11 ] loss: 0.36477911472320557 2022-07-01 17:35:14.392627
Epoch:[ 70 12 ] loss: 0.36475133895874023 2022-07-01 17:35:14.810166
Epoch:[ 70 13 ] loss: 0.36500629782676697 2022-07-01 17:35:15.231575
Epoch:[ 70 14 ] loss: 0.3639947175979614 2022-07-01 17:35:15.649930
Epoch:[ 70 15 ] loss: 0.36571213603019714 2022-07-01 17:35:16.070468
Epoch:[ 70 16 ] loss: 0.364249050617218 2022-07-01 17:35:21.304127
Epoch:[ 70 17 ] loss: 0.3646981716156006 2022-07-01 17:35:21.723574
Epoch:[ 70 18 ] loss: 0.36469268798828125 2022-07-01 17:35:22.147172
Epoch:[ 70 19 ] loss: 0.36506640911102295 2022-07-01 17:35:22.562727
Training_Epoch:[ 70 ] Training_loss: 0.364883217215538 2022-07-01 17:35:22.563432
learning rate:  0.0002621440000000001
netparams have been saved once 70
val: 1 0.38978737592697144
val: 2 0.38934338092803955
val: 3 0.38614794611930847
val: 4 0.38504666090011597
val: 5 0.3917364478111267
val: 6 0.392152339220047
val: 7 0.3920891284942627
val: 8 0.3835313320159912
val: 9 0.39005133509635925
val: 10 0.38554152846336365
val: 11 0.39378127455711365
val: 12 0.38319265842437744
val: 13 0.39151716232299805
val: 14 0.3917902112007141
val: 15 0.38830167055130005
val: 16 0.38289186358451843
val: 17 0.38633671402931213
val: 18 0.3827039897441864
val: 19 0.38601163029670715
val: 20 0.38298994302749634
val_Epoch:[ 70 ] val_loss: 0.3877472296357155 2022-07-01 17:35:26.465782
start training 2022-07-01 17:35:26.568336
Epoch:[ 71 0 ] loss: 0.36477193236351013 2022-07-01 17:35:40.896939
Epoch:[ 71 1 ] loss: 0.36408552527427673 2022-07-01 17:35:41.445366
Epoch:[ 71 2 ] loss: 0.36545270681381226 2022-07-01 17:35:41.860182
Epoch:[ 71 3 ] loss: 0.3642894923686981 2022-07-01 17:35:42.273680
Epoch:[ 71 4 ] loss: 0.36511659622192383 2022-07-01 17:35:42.686532
Epoch:[ 71 5 ] loss: 0.3646180331707001 2022-07-01 17:35:43.101702
Epoch:[ 71 6 ] loss: 0.3648795485496521 2022-07-01 17:35:43.522656
Epoch:[ 71 7 ] loss: 0.3639373779296875 2022-07-01 17:35:43.936623
Epoch:[ 71 8 ] loss: 0.36475294828414917 2022-07-01 17:35:44.351226
Epoch:[ 71 9 ] loss: 0.3646865785121918 2022-07-01 17:35:44.772141
Epoch:[ 71 10 ] loss: 0.3643471598625183 2022-07-01 17:35:45.186122
Epoch:[ 71 11 ] loss: 0.364871084690094 2022-07-01 17:35:45.606136
Epoch:[ 71 12 ] loss: 0.3642248809337616 2022-07-01 17:35:46.022552
Epoch:[ 71 13 ] loss: 0.364202618598938 2022-07-01 17:35:46.438793
Epoch:[ 71 14 ] loss: 0.36406469345092773 2022-07-01 17:35:46.853351
Epoch:[ 71 15 ] loss: 0.3644566237926483 2022-07-01 17:35:47.267887
Epoch:[ 71 16 ] loss: 0.3648506999015808 2022-07-01 17:35:52.315933
Epoch:[ 71 17 ] loss: 0.36319947242736816 2022-07-01 17:35:53.338971
Epoch:[ 71 18 ] loss: 0.3646201193332672 2022-07-01 17:35:53.753338
Epoch:[ 71 19 ] loss: 0.36469441652297974 2022-07-01 17:35:54.174269
Training_Epoch:[ 71 ] Training_loss: 0.3645061254501343 2022-07-01 17:35:54.174962
learning rate:  0.00020971520000000012
val: 1 0.38340964913368225
val: 2 0.3902377486228943
val: 3 0.3824576735496521
val: 4 0.3904244005680084
val: 5 0.3799948990345001
val: 6 0.3887886106967926
val: 7 0.3832448124885559
val: 8 0.3924258053302765
val: 9 0.3810851275920868
val: 10 0.3881157636642456
val: 11 0.39131537079811096
val: 12 0.3855222463607788
val: 13 0.38342463970184326
val: 14 0.38411226868629456
val: 15 0.3842855393886566
val: 16 0.40137138962745667
val: 17 0.38051119446754456
val: 18 0.38990041613578796
val: 19 0.39445483684539795
val: 20 0.3890978693962097
val_Epoch:[ 71 ] val_loss: 0.3872090131044388 2022-07-01 17:35:58.007659
start training 2022-07-01 17:35:58.108818
Epoch:[ 72 0 ] loss: 0.3636264204978943 2022-07-01 17:36:12.883139
Epoch:[ 72 1 ] loss: 0.36255699396133423 2022-07-01 17:36:13.300059
Epoch:[ 72 2 ] loss: 0.3640049993991852 2022-07-01 17:36:13.721417
Epoch:[ 72 3 ] loss: 0.3666343688964844 2022-07-01 17:36:14.135288
Epoch:[ 72 4 ] loss: 0.3647118806838989 2022-07-01 17:36:14.552460
Epoch:[ 72 5 ] loss: 0.36356937885284424 2022-07-01 17:36:14.965674
Epoch:[ 72 6 ] loss: 0.3647350072860718 2022-07-01 17:36:15.381814
Epoch:[ 72 7 ] loss: 0.36381176114082336 2022-07-01 17:36:15.798127
Epoch:[ 72 8 ] loss: 0.3635295629501343 2022-07-01 17:36:16.212800
Epoch:[ 72 9 ] loss: 0.3642081916332245 2022-07-01 17:36:16.625916
Epoch:[ 72 10 ] loss: 0.362998366355896 2022-07-01 17:36:17.046915
Epoch:[ 72 11 ] loss: 0.3643771708011627 2022-07-01 17:36:17.460881
Epoch:[ 72 12 ] loss: 0.3633812367916107 2022-07-01 17:36:17.875211
Epoch:[ 72 13 ] loss: 0.3653603792190552 2022-07-01 17:36:18.296316
Epoch:[ 72 14 ] loss: 0.36456212401390076 2022-07-01 17:36:18.712297
Epoch:[ 72 15 ] loss: 0.36392679810523987 2022-07-01 17:36:19.126080
Epoch:[ 72 16 ] loss: 0.3629412055015564 2022-07-01 17:36:24.291951
Epoch:[ 72 17 ] loss: 0.3652430474758148 2022-07-01 17:36:24.711923
Epoch:[ 72 18 ] loss: 0.3639829456806183 2022-07-01 17:36:25.138613
Epoch:[ 72 19 ] loss: 0.36515918374061584 2022-07-01 17:36:25.552078
Training_Epoch:[ 72 ] Training_loss: 0.3641660511493683 2022-07-01 17:36:25.552727
learning rate:  0.00020971520000000012
netparams have been saved once 72
val: 1 0.3966740667819977
val: 2 0.3863658607006073
val: 3 0.3941650986671448
val: 4 0.3875293433666229
val: 5 0.3895849287509918
val: 6 0.3801361322402954
val: 7 0.38708576560020447
val: 8 0.39718008041381836
val: 9 0.3892066776752472
val: 10 0.39689695835113525
val: 11 0.395842581987381
val: 12 0.38426288962364197
val: 13 0.38019025325775146
val: 14 0.3928447961807251
val: 15 0.3870698809623718
val: 16 0.3849721848964691
val: 17 0.38446298241615295
val: 18 0.38997095823287964
val: 19 0.38667911291122437
val: 20 0.3930898606777191
val_Epoch:[ 72 ] val_loss: 0.38921052068471906 2022-07-01 17:36:29.421176
start training 2022-07-01 17:36:29.521300
Epoch:[ 73 0 ] loss: 0.3647640347480774 2022-07-01 17:36:43.718574
Epoch:[ 73 1 ] loss: 0.3621912896633148 2022-07-01 17:36:44.266377
Epoch:[ 73 2 ] loss: 0.3633090853691101 2022-07-01 17:36:44.687189
Epoch:[ 73 3 ] loss: 0.36457517743110657 2022-07-01 17:36:45.102300
Epoch:[ 73 4 ] loss: 0.3634762167930603 2022-07-01 17:36:45.516848
Epoch:[ 73 5 ] loss: 0.36473286151885986 2022-07-01 17:36:45.930821
Epoch:[ 73 6 ] loss: 0.3644352853298187 2022-07-01 17:36:46.350286
Epoch:[ 73 7 ] loss: 0.36358416080474854 2022-07-01 17:36:46.765391
Epoch:[ 73 8 ] loss: 0.36549538373947144 2022-07-01 17:36:47.181360
Epoch:[ 73 9 ] loss: 0.36406299471855164 2022-07-01 17:36:47.602028
Epoch:[ 73 10 ] loss: 0.3641248047351837 2022-07-01 17:36:48.017533
Epoch:[ 73 11 ] loss: 0.3633357286453247 2022-07-01 17:36:48.430337
Epoch:[ 73 12 ] loss: 0.3645377457141876 2022-07-01 17:36:48.844517
Epoch:[ 73 13 ] loss: 0.3642353415489197 2022-07-01 17:36:49.258200
Epoch:[ 73 14 ] loss: 0.36483293771743774 2022-07-01 17:36:49.674698
Epoch:[ 73 15 ] loss: 0.36549192667007446 2022-07-01 17:36:50.090723
Epoch:[ 73 16 ] loss: 0.36466076970100403 2022-07-01 17:36:55.603818
Epoch:[ 73 17 ] loss: 0.36446094512939453 2022-07-01 17:36:56.024805
Epoch:[ 73 18 ] loss: 0.36428871750831604 2022-07-01 17:36:56.442202
Epoch:[ 73 19 ] loss: 0.36466485261917114 2022-07-01 17:36:56.856524
Training_Epoch:[ 73 ] Training_loss: 0.36426301300525665 2022-07-01 17:36:56.857282
learning rate:  0.00020971520000000012
val: 1 0.3880068063735962
val: 2 0.3952827453613281
val: 3 0.38750600814819336
val: 4 0.38792821764945984
val: 5 0.4046127200126648
val: 6 0.38594695925712585
val: 7 0.39136040210723877
val: 8 0.38325148820877075
val: 9 0.3892863392829895
val: 10 0.391707181930542
val: 11 0.38411760330200195
val: 12 0.3848537802696228
val: 13 0.3904595971107483
val: 14 0.3877411186695099
val: 15 0.3921416401863098
val: 16 0.3819981515407562
val: 17 0.39273834228515625
val: 18 0.38723909854888916
val: 19 0.382379949092865
val: 20 0.3842040002346039
val_Epoch:[ 73 ] val_loss: 0.3886381074786186 2022-07-01 17:37:00.794971
start training 2022-07-01 17:37:00.894248
Epoch:[ 74 0 ] loss: 0.3637082576751709 2022-07-01 17:37:14.990726
Epoch:[ 74 1 ] loss: 0.3642505407333374 2022-07-01 17:37:15.407040
Epoch:[ 74 2 ] loss: 0.3635380268096924 2022-07-01 17:37:15.840238
Epoch:[ 74 3 ] loss: 0.363930881023407 2022-07-01 17:37:16.255790
Epoch:[ 74 4 ] loss: 0.36401084065437317 2022-07-01 17:37:16.671676
Epoch:[ 74 5 ] loss: 0.363332062959671 2022-07-01 17:37:17.087511
Epoch:[ 74 6 ] loss: 0.3636626601219177 2022-07-01 17:37:17.502853
Epoch:[ 74 7 ] loss: 0.36468714475631714 2022-07-01 17:37:17.917080
Epoch:[ 74 8 ] loss: 0.3652796149253845 2022-07-01 17:37:18.333384
Epoch:[ 74 9 ] loss: 0.36468297243118286 2022-07-01 17:37:18.750934
Epoch:[ 74 10 ] loss: 0.36353597044944763 2022-07-01 17:37:19.161568
Epoch:[ 74 11 ] loss: 0.3643089830875397 2022-07-01 17:37:19.576385
Epoch:[ 74 12 ] loss: 0.36370033025741577 2022-07-01 17:37:19.987860
Epoch:[ 74 13 ] loss: 0.36472994089126587 2022-07-01 17:37:20.403446
Epoch:[ 74 14 ] loss: 0.3647497594356537 2022-07-01 17:37:20.817673
Epoch:[ 74 15 ] loss: 0.36318424344062805 2022-07-01 17:37:21.227871
Epoch:[ 74 16 ] loss: 0.3639124631881714 2022-07-01 17:37:26.757892
Epoch:[ 74 17 ] loss: 0.3653949499130249 2022-07-01 17:37:27.175249
Epoch:[ 74 18 ] loss: 0.36369913816452026 2022-07-01 17:37:27.589692
Epoch:[ 74 19 ] loss: 0.36569979786872864 2022-07-01 17:37:27.998813
Training_Epoch:[ 74 ] Training_loss: 0.3641999289393425 2022-07-01 17:37:27.999873
learning rate:  0.00020971520000000012
netparams have been saved once 74
val: 1 0.3875328004360199
val: 2 0.3868335485458374
val: 3 0.39460065960884094
val: 4 0.386457622051239
val: 5 0.3883614242076874
val: 6 0.3933945596218109
val: 7 0.38541877269744873
val: 8 0.3899029493331909
val: 9 0.3866472542285919
val: 10 0.38939177989959717
val: 11 0.3900029957294464
val: 12 0.39313942193984985
val: 13 0.39811185002326965
val: 14 0.38243597745895386
val: 15 0.38963258266448975
val: 16 0.38365277647972107
val: 17 0.3829360008239746
val: 18 0.3861519396305084
val: 19 0.39011305570602417
val: 20 0.3960660398006439
val_Epoch:[ 74 ] val_loss: 0.3890392005443573 2022-07-01 17:37:31.951754
start training 2022-07-01 17:37:32.052729
Epoch:[ 75 0 ] loss: 0.36330437660217285 2022-07-01 17:37:46.279530
Epoch:[ 75 1 ] loss: 0.3637442886829376 2022-07-01 17:37:47.063620
Epoch:[ 75 2 ] loss: 0.3643938899040222 2022-07-01 17:37:47.479277
Epoch:[ 75 3 ] loss: 0.3635868430137634 2022-07-01 17:37:47.895214
Epoch:[ 75 4 ] loss: 0.3651731312274933 2022-07-01 17:37:48.312460
Epoch:[ 75 5 ] loss: 0.3641897737979889 2022-07-01 17:37:48.725344
Epoch:[ 75 6 ] loss: 0.36476123332977295 2022-07-01 17:37:49.139209
Epoch:[ 75 7 ] loss: 0.36369094252586365 2022-07-01 17:37:49.552914
Epoch:[ 75 8 ] loss: 0.36357298493385315 2022-07-01 17:37:49.967056
Epoch:[ 75 9 ] loss: 0.36338239908218384 2022-07-01 17:37:50.381372
Epoch:[ 75 10 ] loss: 0.36468833684921265 2022-07-01 17:37:50.804223
Epoch:[ 75 11 ] loss: 0.3636753559112549 2022-07-01 17:37:51.219168
Epoch:[ 75 12 ] loss: 0.3626781702041626 2022-07-01 17:37:51.640018
Epoch:[ 75 13 ] loss: 0.36372315883636475 2022-07-01 17:37:52.054995
Epoch:[ 75 14 ] loss: 0.3645460903644562 2022-07-01 17:37:52.469423
Epoch:[ 75 15 ] loss: 0.3656604290008545 2022-07-01 17:37:52.893905
Epoch:[ 75 16 ] loss: 0.3642956614494324 2022-07-01 17:37:57.779182
Epoch:[ 75 17 ] loss: 0.36507025361061096 2022-07-01 17:37:59.199658
Epoch:[ 75 18 ] loss: 0.3634159564971924 2022-07-01 17:37:59.628011
Epoch:[ 75 19 ] loss: 0.3641802966594696 2022-07-01 17:38:00.043606
Training_Epoch:[ 75 ] Training_loss: 0.3640866786241531 2022-07-01 17:38:00.044301
learning rate:  0.00020971520000000012
val: 1 0.3888241648674011
val: 2 0.3923183083534241
val: 3 0.39275187253952026
val: 4 0.3951245844364166
val: 5 0.38649892807006836
val: 6 0.38799649477005005
val: 7 0.39081448316574097
val: 8 0.390753835439682
val: 9 0.39412859082221985
val: 10 0.39529675245285034
val: 11 0.38515031337738037
val: 12 0.38234904408454895
val: 13 0.38942238688468933
val: 14 0.3862250745296478
val: 15 0.39398691058158875
val: 16 0.39079439640045166
val: 17 0.3925135135650635
val: 18 0.39574509859085083
val: 19 0.3836565613746643
val: 20 0.3825497329235077
val_Epoch:[ 75 ] val_loss: 0.38984505236148836 2022-07-01 17:38:03.893572
start training 2022-07-01 17:38:03.993591
Epoch:[ 76 0 ] loss: 0.3635663688182831 2022-07-01 17:38:18.575400
Epoch:[ 76 1 ] loss: 0.3636999726295471 2022-07-01 17:38:18.990322
Epoch:[ 76 2 ] loss: 0.36382684111595154 2022-07-01 17:38:19.410252
Epoch:[ 76 3 ] loss: 0.364626407623291 2022-07-01 17:38:19.832487
Epoch:[ 76 4 ] loss: 0.3620729148387909 2022-07-01 17:38:20.247855
Epoch:[ 76 5 ] loss: 0.3651048541069031 2022-07-01 17:38:20.662759
Epoch:[ 76 6 ] loss: 0.3633852005004883 2022-07-01 17:38:21.076962
Epoch:[ 76 7 ] loss: 0.3642004728317261 2022-07-01 17:38:21.492861
Epoch:[ 76 8 ] loss: 0.3635118901729584 2022-07-01 17:38:21.908156
Epoch:[ 76 9 ] loss: 0.3635541498661041 2022-07-01 17:38:22.322239
Epoch:[ 76 10 ] loss: 0.3629010021686554 2022-07-01 17:38:22.736458
Epoch:[ 76 11 ] loss: 0.3647919297218323 2022-07-01 17:38:23.155076
Epoch:[ 76 12 ] loss: 0.36413124203681946 2022-07-01 17:38:23.573096
Epoch:[ 76 13 ] loss: 0.3654853105545044 2022-07-01 17:38:23.989152
Epoch:[ 76 14 ] loss: 0.36556246876716614 2022-07-01 17:38:24.405253
Epoch:[ 76 15 ] loss: 0.36378225684165955 2022-07-01 17:38:24.825640
Epoch:[ 76 16 ] loss: 0.3649154603481293 2022-07-01 17:38:29.996940
Epoch:[ 76 17 ] loss: 0.3640759587287903 2022-07-01 17:38:30.418805
Epoch:[ 76 18 ] loss: 0.3638902008533478 2022-07-01 17:38:30.836029
Epoch:[ 76 19 ] loss: 0.3647352457046509 2022-07-01 17:38:31.259156
Training_Epoch:[ 76 ] Training_loss: 0.3640910074114799 2022-07-01 17:38:31.260129
learning rate:  0.00020971520000000012
netparams have been saved once 76
val: 1 0.39382731914520264
val: 2 0.3799697756767273
val: 3 0.39368754625320435
val: 4 0.3862115740776062
val: 5 0.3867329955101013
val: 6 0.3882964253425598
val: 7 0.3823704123497009
val: 8 0.3852079212665558
val: 9 0.390902042388916
val: 10 0.3915747106075287
val: 11 0.387446790933609
val: 12 0.38719114661216736
val: 13 0.38852813839912415
val: 14 0.3874721825122833
val: 15 0.3896504044532776
val: 16 0.38065311312675476
val: 17 0.3932528495788574
val: 18 0.3886452317237854
val: 19 0.39039283990859985
val: 20 0.3829873502254486
val_Epoch:[ 76 ] val_loss: 0.38775003850460055 2022-07-01 17:38:35.262786
start training 2022-07-01 17:38:35.363749
Epoch:[ 77 0 ] loss: 0.36400383710861206 2022-07-01 17:38:49.383890
Epoch:[ 77 1 ] loss: 0.36363962292671204 2022-07-01 17:38:50.117699
Epoch:[ 77 2 ] loss: 0.3658680021762848 2022-07-01 17:38:50.531070
Epoch:[ 77 3 ] loss: 0.36363956332206726 2022-07-01 17:38:50.945410
Epoch:[ 77 4 ] loss: 0.3617601692676544 2022-07-01 17:38:51.360456
Epoch:[ 77 5 ] loss: 0.36384329199790955 2022-07-01 17:38:51.776373
Epoch:[ 77 6 ] loss: 0.36430874466896057 2022-07-01 17:38:52.191925
Epoch:[ 77 7 ] loss: 0.3640925884246826 2022-07-01 17:38:52.605896
Epoch:[ 77 8 ] loss: 0.3643987476825714 2022-07-01 17:38:53.022896
Epoch:[ 77 9 ] loss: 0.3646925091743469 2022-07-01 17:38:53.441820
Epoch:[ 77 10 ] loss: 0.3632025122642517 2022-07-01 17:38:53.860877
Epoch:[ 77 11 ] loss: 0.36401793360710144 2022-07-01 17:38:54.282437
Epoch:[ 77 12 ] loss: 0.36358487606048584 2022-07-01 17:38:54.698626
Epoch:[ 77 13 ] loss: 0.3632794916629791 2022-07-01 17:38:55.114699
Epoch:[ 77 14 ] loss: 0.36368048191070557 2022-07-01 17:38:55.528593
Epoch:[ 77 15 ] loss: 0.3646448850631714 2022-07-01 17:38:55.942295
Epoch:[ 77 16 ] loss: 0.36424440145492554 2022-07-01 17:39:00.961842
Epoch:[ 77 17 ] loss: 0.3644702434539795 2022-07-01 17:39:01.992601
Epoch:[ 77 18 ] loss: 0.36503326892852783 2022-07-01 17:39:02.414685
Epoch:[ 77 19 ] loss: 0.36307451128959656 2022-07-01 17:39:02.831040
Training_Epoch:[ 77 ] Training_loss: 0.36397398412227633 2022-07-01 17:39:02.831674
learning rate:  0.00020971520000000012
val: 1 0.39431241154670715
val: 2 0.3877054750919342
val: 3 0.3916386365890503
val: 4 0.3822951912879944
val: 5 0.3911067843437195
val: 6 0.3854084610939026
val: 7 0.387775719165802
val: 8 0.3844848573207855
val: 9 0.39284005761146545
val: 10 0.3916524648666382
val: 11 0.39713630080223083
val: 12 0.39384734630584717
val: 13 0.3898144066333771
val: 14 0.3869132101535797
val: 15 0.38485661149024963
val: 16 0.3870190382003784
val: 17 0.3885887563228607
val: 18 0.3872950077056885
val: 19 0.38228851556777954
val: 20 0.39343640208244324
val_Epoch:[ 77 ] val_loss: 0.3890207827091217 2022-07-01 17:39:06.647636
start training 2022-07-01 17:39:06.750313
Epoch:[ 78 0 ] loss: 0.36413800716400146 2022-07-01 17:39:21.320343
Epoch:[ 78 1 ] loss: 0.3641810715198517 2022-07-01 17:39:21.734041
Epoch:[ 78 2 ] loss: 0.3634696304798126 2022-07-01 17:39:22.148767
Epoch:[ 78 3 ] loss: 0.3643287718296051 2022-07-01 17:39:22.569498
Epoch:[ 78 4 ] loss: 0.3629515767097473 2022-07-01 17:39:22.983406
Epoch:[ 78 5 ] loss: 0.363599568605423 2022-07-01 17:39:23.399166
Epoch:[ 78 6 ] loss: 0.3628360629081726 2022-07-01 17:39:23.821480
Epoch:[ 78 7 ] loss: 0.3645798861980438 2022-07-01 17:39:24.236463
Epoch:[ 78 8 ] loss: 0.36459991335868835 2022-07-01 17:39:24.657098
Epoch:[ 78 9 ] loss: 0.3636724054813385 2022-07-01 17:39:25.069933
Epoch:[ 78 10 ] loss: 0.36411726474761963 2022-07-01 17:39:25.483927
Epoch:[ 78 11 ] loss: 0.363790899515152 2022-07-01 17:39:25.898061
Epoch:[ 78 12 ] loss: 0.364641398191452 2022-07-01 17:39:26.314511
Epoch:[ 78 13 ] loss: 0.36451247334480286 2022-07-01 17:39:26.730796
Epoch:[ 78 14 ] loss: 0.3634084165096283 2022-07-01 17:39:27.145774
Epoch:[ 78 15 ] loss: 0.36324891448020935 2022-07-01 17:39:27.559503
Epoch:[ 78 16 ] loss: 0.3636379539966583 2022-07-01 17:39:32.969084
Epoch:[ 78 17 ] loss: 0.36356931924819946 2022-07-01 17:39:33.381526
Epoch:[ 78 18 ] loss: 0.3633485734462738 2022-07-01 17:39:33.795928
Epoch:[ 78 19 ] loss: 0.36456671357154846 2022-07-01 17:39:34.217370
Training_Epoch:[ 78 ] Training_loss: 0.36385994106531144 2022-07-01 17:39:34.218005
learning rate:  0.00020971520000000012
netparams have been saved once 78
val: 1 0.38156020641326904
val: 2 0.38870927691459656
val: 3 0.3859887421131134
val: 4 0.38968321681022644
val: 5 0.39474186301231384
val: 6 0.3795796036720276
val: 7 0.3841968774795532
val: 8 0.38233211636543274
val: 9 0.3878888487815857
val: 10 0.38936203718185425
val: 11 0.3932303786277771
val: 12 0.3885168731212616
val: 13 0.3892824649810791
val: 14 0.3869725465774536
val: 15 0.39554518461227417
val: 16 0.38592296838760376
val: 17 0.39062774181365967
val: 18 0.39107874035835266
val: 19 0.3863013982772827
val: 20 0.3897530138492584
val_Epoch:[ 78 ] val_loss: 0.38806370496749876 2022-07-01 17:39:38.064048
start training 2022-07-01 17:39:38.165236
Epoch:[ 79 0 ] loss: 0.3640038073062897 2022-07-01 17:39:52.841968
Epoch:[ 79 1 ] loss: 0.36430248618125916 2022-07-01 17:39:53.259321
Epoch:[ 79 2 ] loss: 0.36398205161094666 2022-07-01 17:39:53.681154
Epoch:[ 79 3 ] loss: 0.36456993222236633 2022-07-01 17:39:54.096649
Epoch:[ 79 4 ] loss: 0.3619242012500763 2022-07-01 17:39:54.511069
Epoch:[ 79 5 ] loss: 0.3650404214859009 2022-07-01 17:39:54.925190
Epoch:[ 79 6 ] loss: 0.3641340434551239 2022-07-01 17:39:55.341016
Epoch:[ 79 7 ] loss: 0.363434374332428 2022-07-01 17:39:55.763716
Epoch:[ 79 8 ] loss: 0.36385002732276917 2022-07-01 17:39:56.177782
Epoch:[ 79 9 ] loss: 0.3631141781806946 2022-07-01 17:39:56.591233
Epoch:[ 79 10 ] loss: 0.3629872798919678 2022-07-01 17:39:57.004693
Epoch:[ 79 11 ] loss: 0.3643825054168701 2022-07-01 17:39:57.418893
Epoch:[ 79 12 ] loss: 0.36317068338394165 2022-07-01 17:39:57.834547
Epoch:[ 79 13 ] loss: 0.36422693729400635 2022-07-01 17:39:58.250504
Epoch:[ 79 14 ] loss: 0.36310020089149475 2022-07-01 17:39:58.675252
Epoch:[ 79 15 ] loss: 0.363416850566864 2022-07-01 17:39:59.089641
Epoch:[ 79 16 ] loss: 0.36323049664497375 2022-07-01 17:40:04.453008
Epoch:[ 79 17 ] loss: 0.3631574809551239 2022-07-01 17:40:04.865603
Epoch:[ 79 18 ] loss: 0.36393997073173523 2022-07-01 17:40:05.287044
Epoch:[ 79 19 ] loss: 0.3642761707305908 2022-07-01 17:40:05.706374
Training_Epoch:[ 79 ] Training_loss: 0.3637122049927711 2022-07-01 17:40:05.707060
learning rate:  0.00020971520000000012
val: 1 0.39208897948265076
val: 2 0.3912038505077362
val: 3 0.38628795742988586
val: 4 0.39099153876304626
val: 5 0.38869428634643555
val: 6 0.38903942704200745
val: 7 0.3880125880241394
val: 8 0.38661816716194153
val: 9 0.38121241331100464
val: 10 0.3873383402824402
val: 11 0.39331740140914917
val: 12 0.38980886340141296
val: 13 0.3837366998195648
val: 14 0.3886154294013977
val: 15 0.38675248622894287
val: 16 0.3969229459762573
val: 17 0.3863067030906677
val: 18 0.3869476616382599
val: 19 0.3931128978729248
val: 20 0.38508713245391846
val_Epoch:[ 79 ] val_loss: 0.38860478848218916 2022-07-01 17:40:09.628152
start training 2022-07-01 17:40:09.730007
Epoch:[ 80 0 ] loss: 0.3647184371948242 2022-07-01 17:40:24.668578
Epoch:[ 80 1 ] loss: 0.36415281891822815 2022-07-01 17:40:25.084393
Epoch:[ 80 2 ] loss: 0.36466479301452637 2022-07-01 17:40:25.499525
Epoch:[ 80 3 ] loss: 0.36375850439071655 2022-07-01 17:40:25.913850
Epoch:[ 80 4 ] loss: 0.3629116117954254 2022-07-01 17:40:26.329276
Epoch:[ 80 5 ] loss: 0.36408981680870056 2022-07-01 17:40:26.742871
Epoch:[ 80 6 ] loss: 0.3645806610584259 2022-07-01 17:40:27.156092
Epoch:[ 80 7 ] loss: 0.3636874258518219 2022-07-01 17:40:27.576412
Epoch:[ 80 8 ] loss: 0.3633614480495453 2022-07-01 17:40:27.992681
Epoch:[ 80 9 ] loss: 0.36276447772979736 2022-07-01 17:40:28.413148
Epoch:[ 80 10 ] loss: 0.36481037735939026 2022-07-01 17:40:28.825870
Epoch:[ 80 11 ] loss: 0.3631247878074646 2022-07-01 17:40:29.241083
Epoch:[ 80 12 ] loss: 0.36265817284584045 2022-07-01 17:40:29.654705
Epoch:[ 80 13 ] loss: 0.36420324444770813 2022-07-01 17:40:30.067764
Epoch:[ 80 14 ] loss: 0.3635932505130768 2022-07-01 17:40:30.483939
Epoch:[ 80 15 ] loss: 0.36434292793273926 2022-07-01 17:40:30.906057
Epoch:[ 80 16 ] loss: 0.36283913254737854 2022-07-01 17:40:36.626639
Epoch:[ 80 17 ] loss: 0.36252477765083313 2022-07-01 17:40:37.045461
Epoch:[ 80 18 ] loss: 0.36449524760246277 2022-07-01 17:40:37.470588
Epoch:[ 80 19 ] loss: 0.3636437654495239 2022-07-01 17:40:37.883296
Training_Epoch:[ 80 ] Training_loss: 0.36374628394842146 2022-07-01 17:40:37.883973
learning rate:  0.00020971520000000012
netparams have been saved once 80
val: 1 0.38474100828170776
val: 2 0.3901476562023163
val: 3 0.3852689564228058
val: 4 0.38963037729263306
val: 5 0.39197975397109985
val: 6 0.3958970010280609
val: 7 0.3833327293395996
val: 8 0.39182305335998535
val: 9 0.39175406098365784
val: 10 0.3887244462966919
val: 11 0.3810346722602844
val: 12 0.3903239965438843
val: 13 0.3885074555873871
val: 14 0.3879739046096802
val: 15 0.3885323107242584
val: 16 0.385635107755661
val: 17 0.38653337955474854
val: 18 0.394562304019928
val: 19 0.38380226492881775
val: 20 0.3893384039402008
val_Epoch:[ 80 ] val_loss: 0.38847714215517043 2022-07-01 17:40:41.885095
start training 2022-07-01 17:40:41.988114
Epoch:[ 81 0 ] loss: 0.3631816506385803 2022-07-01 17:40:56.059403
Epoch:[ 81 1 ] loss: 0.3638831675052643 2022-07-01 17:40:56.496157
Epoch:[ 81 2 ] loss: 0.36321571469306946 2022-07-01 17:40:56.938942
Epoch:[ 81 3 ] loss: 0.3633522093296051 2022-07-01 17:40:57.355259
Epoch:[ 81 4 ] loss: 0.3617595136165619 2022-07-01 17:40:57.768504
Epoch:[ 81 5 ] loss: 0.3632030785083771 2022-07-01 17:40:58.183583
Epoch:[ 81 6 ] loss: 0.3641324043273926 2022-07-01 17:40:58.598236
Epoch:[ 81 7 ] loss: 0.3633068799972534 2022-07-01 17:40:59.012689
Epoch:[ 81 8 ] loss: 0.3627796769142151 2022-07-01 17:40:59.429047
Epoch:[ 81 9 ] loss: 0.3638915419578552 2022-07-01 17:40:59.845660
Epoch:[ 81 10 ] loss: 0.363528847694397 2022-07-01 17:41:00.266031
Epoch:[ 81 11 ] loss: 0.36357569694519043 2022-07-01 17:41:00.686562
Epoch:[ 81 12 ] loss: 0.3635847866535187 2022-07-01 17:41:01.102286
Epoch:[ 81 13 ] loss: 0.36262455582618713 2022-07-01 17:41:01.516706
Epoch:[ 81 14 ] loss: 0.3637731373310089 2022-07-01 17:41:01.935300
Epoch:[ 81 15 ] loss: 0.36490803956985474 2022-07-01 17:41:02.351118
Epoch:[ 81 16 ] loss: 0.36382731795310974 2022-07-01 17:41:07.915632
Epoch:[ 81 17 ] loss: 0.3637771010398865 2022-07-01 17:41:08.335758
Epoch:[ 81 18 ] loss: 0.36336255073547363 2022-07-01 17:41:08.750346
Epoch:[ 81 19 ] loss: 0.36407533288002014 2022-07-01 17:41:09.164742
Training_Epoch:[ 81 ] Training_loss: 0.36348716020584104 2022-07-01 17:41:09.165413
learning rate:  0.0001677721600000001
val: 1 0.388220876455307
val: 2 0.3872109651565552
val: 3 0.39830517768859863
val: 4 0.37894633412361145
val: 5 0.3891443610191345
val: 6 0.3830130398273468
val: 7 0.3859085142612457
val: 8 0.393338143825531
val: 9 0.38484784960746765
val: 10 0.3927766978740692
val: 11 0.38384974002838135
val: 12 0.38035330176353455
val: 13 0.38826891779899597
val: 14 0.3942245543003082
val: 15 0.3833851218223572
val: 16 0.38943976163864136
val: 17 0.38751235604286194
val: 18 0.3970226049423218
val: 19 0.3895150125026703
val: 20 0.3871401250362396
val_Epoch:[ 81 ] val_loss: 0.38812117278575897 2022-07-01 17:41:13.073485
start training 2022-07-01 17:41:13.175136
Epoch:[ 82 0 ] loss: 0.36267778277397156 2022-07-01 17:41:28.124424
Epoch:[ 82 1 ] loss: 0.363709032535553 2022-07-01 17:41:28.539130
Epoch:[ 82 2 ] loss: 0.3640632629394531 2022-07-01 17:41:28.961547
Epoch:[ 82 3 ] loss: 0.3639950156211853 2022-07-01 17:41:29.379740
Epoch:[ 82 4 ] loss: 0.36224767565727234 2022-07-01 17:41:29.795606
Epoch:[ 82 5 ] loss: 0.36295461654663086 2022-07-01 17:41:30.212103
Epoch:[ 82 6 ] loss: 0.36317601799964905 2022-07-01 17:41:30.628100
Epoch:[ 82 7 ] loss: 0.3637452721595764 2022-07-01 17:41:31.042888
Epoch:[ 82 8 ] loss: 0.36268532276153564 2022-07-01 17:41:31.453233
Epoch:[ 82 9 ] loss: 0.36449140310287476 2022-07-01 17:41:31.870026
Epoch:[ 82 10 ] loss: 0.36301854252815247 2022-07-01 17:41:32.286726
Epoch:[ 82 11 ] loss: 0.36386895179748535 2022-07-01 17:41:32.706754
Epoch:[ 82 12 ] loss: 0.363603800535202 2022-07-01 17:41:33.122835
Epoch:[ 82 13 ] loss: 0.36421331763267517 2022-07-01 17:41:33.542279
Epoch:[ 82 14 ] loss: 0.3625396490097046 2022-07-01 17:41:33.961012
Epoch:[ 82 15 ] loss: 0.36372047662734985 2022-07-01 17:41:34.369728
Epoch:[ 82 16 ] loss: 0.3635646104812622 2022-07-01 17:41:39.377958
Epoch:[ 82 17 ] loss: 0.36315658688545227 2022-07-01 17:41:39.793249
Epoch:[ 82 18 ] loss: 0.36325860023498535 2022-07-01 17:41:40.210136
Epoch:[ 82 19 ] loss: 0.36332038044929504 2022-07-01 17:41:40.631835
Training_Epoch:[ 82 ] Training_loss: 0.36340051591396333 2022-07-01 17:41:40.632573
learning rate:  0.0001677721600000001
netparams have been saved once 82
val: 1 0.38987845182418823
val: 2 0.3879182040691376
val: 3 0.3835529386997223
val: 4 0.39115628600120544
val: 5 0.38491398096084595
val: 6 0.39296969771385193
val: 7 0.38816919922828674
val: 8 0.39379289746284485
val: 9 0.38189736008644104
val: 10 0.3923504054546356
val: 11 0.3904050588607788
val: 12 0.3936581611633301
val: 13 0.39286771416664124
val: 14 0.38338959217071533
val: 15 0.3846314549446106
val: 16 0.3853600323200226
val: 17 0.3787214457988739
val: 18 0.39053672552108765
val: 19 0.38628333806991577
val: 20 0.3969392776489258
val_Epoch:[ 82 ] val_loss: 0.3884696111083031 2022-07-01 17:41:44.621476
start training 2022-07-01 17:41:44.725043
Epoch:[ 83 0 ] loss: 0.3625432848930359 2022-07-01 17:41:59.406132
Epoch:[ 83 1 ] loss: 0.3634708821773529 2022-07-01 17:41:59.883996
Epoch:[ 83 2 ] loss: 0.36344701051712036 2022-07-01 17:42:00.357297
Epoch:[ 83 3 ] loss: 0.3636869788169861 2022-07-01 17:42:00.834653
Epoch:[ 83 4 ] loss: 0.3640350103378296 2022-07-01 17:42:01.315455
Epoch:[ 83 5 ] loss: 0.3630404472351074 2022-07-01 17:42:01.796767
Epoch:[ 83 6 ] loss: 0.36244550347328186 2022-07-01 17:42:02.273046
Epoch:[ 83 7 ] loss: 0.36321765184402466 2022-07-01 17:42:02.754213
Epoch:[ 83 8 ] loss: 0.3630886673927307 2022-07-01 17:42:03.229620
Epoch:[ 83 9 ] loss: 0.3631385564804077 2022-07-01 17:42:03.704122
Epoch:[ 83 10 ] loss: 0.3618542551994324 2022-07-01 17:42:04.181710
Epoch:[ 83 11 ] loss: 0.3625961244106293 2022-07-01 17:42:04.656997
Epoch:[ 83 12 ] loss: 0.3643879294395447 2022-07-01 17:42:05.137062
Epoch:[ 83 13 ] loss: 0.36345377564430237 2022-07-01 17:42:05.611192
Epoch:[ 83 14 ] loss: 0.36497169733047485 2022-07-01 17:42:06.085729
Epoch:[ 83 15 ] loss: 0.36431288719177246 2022-07-01 17:42:06.560939
Epoch:[ 83 16 ] loss: 0.3628917336463928 2022-07-01 17:42:11.082600
Epoch:[ 83 17 ] loss: 0.36254221200942993 2022-07-01 17:42:11.503440
Epoch:[ 83 18 ] loss: 0.3632046580314636 2022-07-01 17:42:11.920369
Epoch:[ 83 19 ] loss: 0.3625434935092926 2022-07-01 17:42:12.342087
Training_Epoch:[ 83 ] Training_loss: 0.3632436379790306 2022-07-01 17:42:12.342944
learning rate:  0.0001677721600000001
val: 1 0.39125069975852966
val: 2 0.39288070797920227
val: 3 0.38537734746932983
val: 4 0.39039725065231323
val: 5 0.39410361647605896
val: 6 0.38726741075515747
val: 7 0.38466623425483704
val: 8 0.3859597444534302
val: 9 0.3887050151824951
val: 10 0.3903203010559082
val: 11 0.39327508211135864
val: 12 0.39259466528892517
val: 13 0.3907741606235504
val: 14 0.3900867700576782
val: 15 0.3916358947753906
val: 16 0.3783496618270874
val: 17 0.38898178935050964
val: 18 0.38590067625045776
val: 19 0.3938167095184326
val: 20 0.38969674706459045
val_Epoch:[ 83 ] val_loss: 0.38930202424526217 2022-07-01 17:42:16.193320
start training 2022-07-01 17:42:16.290018
Epoch:[ 84 0 ] loss: 0.3630475699901581 2022-07-01 17:42:31.590231
Epoch:[ 84 1 ] loss: 0.36335620284080505 2022-07-01 17:42:32.009268
Epoch:[ 84 2 ] loss: 0.36281436681747437 2022-07-01 17:42:32.426834
Epoch:[ 84 3 ] loss: 0.36294159293174744 2022-07-01 17:42:32.841365
Epoch:[ 84 4 ] loss: 0.3629172146320343 2022-07-01 17:42:33.302515
Epoch:[ 84 5 ] loss: 0.36112672090530396 2022-07-01 17:42:33.781393
Epoch:[ 84 6 ] loss: 0.36489155888557434 2022-07-01 17:42:34.272531
Epoch:[ 84 7 ] loss: 0.3644281327724457 2022-07-01 17:42:34.749533
Epoch:[ 84 8 ] loss: 0.36341142654418945 2022-07-01 17:42:35.214593
Epoch:[ 84 9 ] loss: 0.3619571924209595 2022-07-01 17:42:35.694554
Epoch:[ 84 10 ] loss: 0.3631034195423126 2022-07-01 17:42:36.176238
Epoch:[ 84 11 ] loss: 0.362707257270813 2022-07-01 17:42:36.594485
Epoch:[ 84 12 ] loss: 0.3636234998703003 2022-07-01 17:42:37.012472
Epoch:[ 84 13 ] loss: 0.362738698720932 2022-07-01 17:42:37.466135
Epoch:[ 84 14 ] loss: 0.36433538794517517 2022-07-01 17:42:37.947119
Epoch:[ 84 15 ] loss: 0.3644893169403076 2022-07-01 17:42:38.422774
Epoch:[ 84 16 ] loss: 0.36415189504623413 2022-07-01 17:42:43.611341
Epoch:[ 84 17 ] loss: 0.3621097207069397 2022-07-01 17:42:44.090868
Epoch:[ 84 18 ] loss: 0.36463096737861633 2022-07-01 17:42:44.570009
Epoch:[ 84 19 ] loss: 0.3635164797306061 2022-07-01 17:42:45.045890
Training_Epoch:[ 84 ] Training_loss: 0.36331493109464646 2022-07-01 17:42:45.046643
learning rate:  0.0001677721600000001
netparams have been saved once 84
val: 1 0.38574814796447754
val: 2 0.3912064731121063
val: 3 0.3951609432697296
val: 4 0.3889838755130768
val: 5 0.386687308549881
val: 6 0.39125189185142517
val: 7 0.38365569710731506
val: 8 0.3925275206565857
val: 9 0.40146660804748535
val: 10 0.38420116901397705
val: 11 0.3788425624370575
val: 12 0.3881166875362396
val: 13 0.3839467167854309
val: 14 0.38718265295028687
val: 15 0.3911903202533722
val: 16 0.3894560635089874
val: 17 0.3882063329219818
val: 18 0.3929314911365509
val: 19 0.3853139877319336
val: 20 0.38276320695877075
val_Epoch:[ 84 ] val_loss: 0.38844198286533355 2022-07-01 17:42:49.006734
start training 2022-07-01 17:42:49.107300
Epoch:[ 85 0 ] loss: 0.36448031663894653 2022-07-01 17:43:03.675055
Epoch:[ 85 1 ] loss: 0.3635905981063843 2022-07-01 17:43:04.408467
Epoch:[ 85 2 ] loss: 0.3623366355895996 2022-07-01 17:43:04.825611
Epoch:[ 85 3 ] loss: 0.3639153838157654 2022-07-01 17:43:05.243718
Epoch:[ 85 4 ] loss: 0.36349549889564514 2022-07-01 17:43:05.658518
Epoch:[ 85 5 ] loss: 0.3630695343017578 2022-07-01 17:43:06.079816
Epoch:[ 85 6 ] loss: 0.36220481991767883 2022-07-01 17:43:06.499306
Epoch:[ 85 7 ] loss: 0.36311423778533936 2022-07-01 17:43:06.917457
Epoch:[ 85 8 ] loss: 0.36434274911880493 2022-07-01 17:43:07.332960
Epoch:[ 85 9 ] loss: 0.36524245142936707 2022-07-01 17:43:07.748811
Epoch:[ 85 10 ] loss: 0.36317119002342224 2022-07-01 17:43:08.166775
Epoch:[ 85 11 ] loss: 0.36355462670326233 2022-07-01 17:43:08.582343
Epoch:[ 85 12 ] loss: 0.3637213408946991 2022-07-01 17:43:08.999777
Epoch:[ 85 13 ] loss: 0.36329469084739685 2022-07-01 17:43:09.421046
Epoch:[ 85 14 ] loss: 0.3623330295085907 2022-07-01 17:43:09.843074
Epoch:[ 85 15 ] loss: 0.3632011115550995 2022-07-01 17:43:10.257844
Epoch:[ 85 16 ] loss: 0.3612954020500183 2022-07-01 17:43:15.469086
Epoch:[ 85 17 ] loss: 0.3633551001548767 2022-07-01 17:43:16.224183
Epoch:[ 85 18 ] loss: 0.36221763491630554 2022-07-01 17:43:16.645983
Epoch:[ 85 19 ] loss: 0.36301934719085693 2022-07-01 17:43:17.063061
Training_Epoch:[ 85 ] Training_loss: 0.36324778497219085 2022-07-01 17:43:17.063715
learning rate:  0.0001677721600000001
val: 1 0.3777736723423004
val: 2 0.39251822233200073
val: 3 0.3862244486808777
val: 4 0.3909962475299835
val: 5 0.3862680494785309
val: 6 0.3945486545562744
val: 7 0.39147230982780457
val: 8 0.38962438702583313
val: 9 0.39310336112976074
val: 10 0.38546523451805115
val: 11 0.38375282287597656
val: 12 0.3896099627017975
val: 13 0.38543087244033813
val: 14 0.3886268436908722
val: 15 0.3904803991317749
val: 16 0.39073944091796875
val: 17 0.3977487087249756
val: 18 0.3905041813850403
val: 19 0.38998234272003174
val: 20 0.3942830562591553
val_Epoch:[ 85 ] val_loss: 0.3894576609134674 2022-07-01 17:43:20.978619
start training 2022-07-01 17:43:21.084906
Epoch:[ 86 0 ] loss: 0.36319616436958313 2022-07-01 17:43:35.182761
Epoch:[ 86 1 ] loss: 0.3630242347717285 2022-07-01 17:43:36.202095
Epoch:[ 86 2 ] loss: 0.3631572127342224 2022-07-01 17:43:36.616628
Epoch:[ 86 3 ] loss: 0.3624614179134369 2022-07-01 17:43:37.030442
Epoch:[ 86 4 ] loss: 0.3616803288459778 2022-07-01 17:43:37.452819
Epoch:[ 86 5 ] loss: 0.3624143600463867 2022-07-01 17:43:37.865960
Epoch:[ 86 6 ] loss: 0.36310532689094543 2022-07-01 17:43:38.281745
Epoch:[ 86 7 ] loss: 0.364637166261673 2022-07-01 17:43:38.697158
Epoch:[ 86 8 ] loss: 0.36365988850593567 2022-07-01 17:43:39.120034
Epoch:[ 86 9 ] loss: 0.3644392788410187 2022-07-01 17:43:39.535923
Epoch:[ 86 10 ] loss: 0.36233317852020264 2022-07-01 17:43:39.951451
Epoch:[ 86 11 ] loss: 0.3634517192840576 2022-07-01 17:43:40.371006
Epoch:[ 86 12 ] loss: 0.36318346858024597 2022-07-01 17:43:40.785081
Epoch:[ 86 13 ] loss: 0.3637705147266388 2022-07-01 17:43:41.203930
Epoch:[ 86 14 ] loss: 0.36376428604125977 2022-07-01 17:43:41.623092
Epoch:[ 86 15 ] loss: 0.3638432025909424 2022-07-01 17:43:42.041922
Epoch:[ 86 16 ] loss: 0.36284470558166504 2022-07-01 17:43:46.964809
Epoch:[ 86 17 ] loss: 0.3631361722946167 2022-07-01 17:43:47.815383
Epoch:[ 86 18 ] loss: 0.36345478892326355 2022-07-01 17:43:48.240999
Epoch:[ 86 19 ] loss: 0.3637664318084717 2022-07-01 17:43:48.659264
Training_Epoch:[ 86 ] Training_loss: 0.3632661923766136 2022-07-01 17:43:48.659894
learning rate:  0.0001677721600000001
netparams have been saved once 86
val: 1 0.38937804102897644
val: 2 0.38258427381515503
val: 3 0.3903671205043793
val: 4 0.3924982249736786
val: 5 0.3923896253108978
val: 6 0.39843717217445374
val: 7 0.38677144050598145
val: 8 0.3899364173412323
val: 9 0.38872674107551575
val: 10 0.39192822575569153
val: 11 0.39860963821411133
val: 12 0.3835190236568451
val: 13 0.39014849066734314
val: 14 0.38471847772598267
val: 15 0.380653440952301
val: 16 0.38869065046310425
val: 17 0.38250523805618286
val: 18 0.3907899856567383
val: 19 0.39256149530410767
val: 20 0.3857947289943695
val_Epoch:[ 86 ] val_loss: 0.38905042260885236 2022-07-01 17:43:52.624793
start training 2022-07-01 17:43:52.722200
Epoch:[ 87 0 ] loss: 0.3621354401111603 2022-07-01 17:44:07.256514
Epoch:[ 87 1 ] loss: 0.3631514310836792 2022-07-01 17:44:07.725556
Epoch:[ 87 2 ] loss: 0.36251455545425415 2022-07-01 17:44:08.140422
Epoch:[ 87 3 ] loss: 0.3623461425304413 2022-07-01 17:44:08.560909
Epoch:[ 87 4 ] loss: 0.36314913630485535 2022-07-01 17:44:08.975194
Epoch:[ 87 5 ] loss: 0.3631308674812317 2022-07-01 17:44:09.389212
Epoch:[ 87 6 ] loss: 0.36258652806282043 2022-07-01 17:44:09.799641
Epoch:[ 87 7 ] loss: 0.363793283700943 2022-07-01 17:44:10.216471
Epoch:[ 87 8 ] loss: 0.36435016989707947 2022-07-01 17:44:10.633562
Epoch:[ 87 9 ] loss: 0.363524466753006 2022-07-01 17:44:11.052443
Epoch:[ 87 10 ] loss: 0.362697958946228 2022-07-01 17:44:11.469217
Epoch:[ 87 11 ] loss: 0.36262306571006775 2022-07-01 17:44:11.883609
Epoch:[ 87 12 ] loss: 0.3630340099334717 2022-07-01 17:44:12.299679
Epoch:[ 87 13 ] loss: 0.364467054605484 2022-07-01 17:44:12.708305
Epoch:[ 87 14 ] loss: 0.3627814054489136 2022-07-01 17:44:13.125569
Epoch:[ 87 15 ] loss: 0.363768607378006 2022-07-01 17:44:13.543771
Epoch:[ 87 16 ] loss: 0.36422985792160034 2022-07-01 17:44:18.844521
Epoch:[ 87 17 ] loss: 0.36326056718826294 2022-07-01 17:44:19.284921
Epoch:[ 87 18 ] loss: 0.36267468333244324 2022-07-01 17:44:19.706319
Epoch:[ 87 19 ] loss: 0.36232662200927734 2022-07-01 17:44:20.120312
Training_Epoch:[ 87 ] Training_loss: 0.3631272926926613 2022-07-01 17:44:20.121047
learning rate:  0.0001677721600000001
val: 1 0.3895775079727173
val: 2 0.3845721185207367
val: 3 0.382828027009964
val: 4 0.38543087244033813
val: 5 0.39468780159950256
val: 6 0.386474072933197
val: 7 0.3838164806365967
val: 8 0.3881247043609619
val: 9 0.3904457986354828
val: 10 0.38478314876556396
val: 11 0.38799962401390076
val: 12 0.3886367380619049
val: 13 0.3999917805194855
val: 14 0.40179887413978577
val: 15 0.3839733600616455
val: 16 0.39088329672813416
val: 17 0.3842011094093323
val: 18 0.38551685214042664
val: 19 0.3930756747722626
val: 20 0.3809400796890259
val_Epoch:[ 87 ] val_loss: 0.38838789612054825 2022-07-01 17:44:24.017924
start training 2022-07-01 17:44:24.115206
Epoch:[ 88 0 ] loss: 0.36340847611427307 2022-07-01 17:44:38.374258
Epoch:[ 88 1 ] loss: 0.3628937005996704 2022-07-01 17:44:38.809999
Epoch:[ 88 2 ] loss: 0.3623318076133728 2022-07-01 17:44:39.224928
Epoch:[ 88 3 ] loss: 0.3629571199417114 2022-07-01 17:44:39.641827
Epoch:[ 88 4 ] loss: 0.3629200756549835 2022-07-01 17:44:40.056287
Epoch:[ 88 5 ] loss: 0.3632584810256958 2022-07-01 17:44:40.475010
Epoch:[ 88 6 ] loss: 0.3626338243484497 2022-07-01 17:44:40.889317
Epoch:[ 88 7 ] loss: 0.36416763067245483 2022-07-01 17:44:41.304570
Epoch:[ 88 8 ] loss: 0.3630998730659485 2022-07-01 17:44:41.721633
Epoch:[ 88 9 ] loss: 0.3645310401916504 2022-07-01 17:44:42.137161
Epoch:[ 88 10 ] loss: 0.3617260754108429 2022-07-01 17:44:42.554550
Epoch:[ 88 11 ] loss: 0.3631335496902466 2022-07-01 17:44:42.967668
Epoch:[ 88 12 ] loss: 0.3633492588996887 2022-07-01 17:44:43.382246
Epoch:[ 88 13 ] loss: 0.3631243407726288 2022-07-01 17:44:43.795504
Epoch:[ 88 14 ] loss: 0.3619919717311859 2022-07-01 17:44:44.209308
Epoch:[ 88 15 ] loss: 0.36188605427742004 2022-07-01 17:44:44.630885
Epoch:[ 88 16 ] loss: 0.36359313130378723 2022-07-01 17:44:50.551779
Epoch:[ 88 17 ] loss: 0.3626396059989929 2022-07-01 17:44:50.964539
Epoch:[ 88 18 ] loss: 0.36291828751564026 2022-07-01 17:44:51.394114
Epoch:[ 88 19 ] loss: 0.3627205193042755 2022-07-01 17:44:51.813836
Training_Epoch:[ 88 ] Training_loss: 0.36296424120664594 2022-07-01 17:44:51.814521
learning rate:  0.0001677721600000001
netparams have been saved once 88
val: 1 0.3851124346256256
val: 2 0.3905893564224243
val: 3 0.39375877380371094
val: 4 0.3936198651790619
val: 5 0.38946306705474854
val: 6 0.39488446712493896
val: 7 0.38942334055900574
val: 8 0.4015031158924103
val: 9 0.3861117362976074
val: 10 0.3873697817325592
val: 11 0.39496463537216187
val: 12 0.3911026418209076
val: 13 0.38524776697158813
val: 14 0.388260155916214
val: 15 0.3797309100627899
val: 16 0.38829636573791504
val: 17 0.3912074863910675
val: 18 0.3869708776473999
val: 19 0.3904092013835907
val: 20 0.382778137922287
val_Epoch:[ 88 ] val_loss: 0.3895402058959007 2022-07-01 17:44:55.672642
start training 2022-07-01 17:44:55.768352
Epoch:[ 89 0 ] loss: 0.36277392506599426 2022-07-01 17:45:10.415373
Epoch:[ 89 1 ] loss: 0.36206862330436707 2022-07-01 17:45:10.833022
Epoch:[ 89 2 ] loss: 0.36222440004348755 2022-07-01 17:45:11.249769
Epoch:[ 89 3 ] loss: 0.36207693815231323 2022-07-01 17:45:11.665261
Epoch:[ 89 4 ] loss: 0.36243969202041626 2022-07-01 17:45:12.083048
Epoch:[ 89 5 ] loss: 0.3622426688671112 2022-07-01 17:45:12.498191
Epoch:[ 89 6 ] loss: 0.3624834716320038 2022-07-01 17:45:12.921210
Epoch:[ 89 7 ] loss: 0.3625454902648926 2022-07-01 17:45:13.336136
Epoch:[ 89 8 ] loss: 0.3636225163936615 2022-07-01 17:45:13.756826
Epoch:[ 89 9 ] loss: 0.362229585647583 2022-07-01 17:45:14.172603
Epoch:[ 89 10 ] loss: 0.36274245381355286 2022-07-01 17:45:14.589854
Epoch:[ 89 11 ] loss: 0.3637864887714386 2022-07-01 17:45:15.005668
Epoch:[ 89 12 ] loss: 0.3641245663166046 2022-07-01 17:45:15.421153
Epoch:[ 89 13 ] loss: 0.363212525844574 2022-07-01 17:45:15.843114
Epoch:[ 89 14 ] loss: 0.3639228343963623 2022-07-01 17:45:16.257963
Epoch:[ 89 15 ] loss: 0.36280688643455505 2022-07-01 17:45:16.674132
Epoch:[ 89 16 ] loss: 0.36287984251976013 2022-07-01 17:45:22.141535
Epoch:[ 89 17 ] loss: 0.36255013942718506 2022-07-01 17:45:22.567134
Epoch:[ 89 18 ] loss: 0.36381280422210693 2022-07-01 17:45:22.992607
Epoch:[ 89 19 ] loss: 0.3643495440483093 2022-07-01 17:45:23.409716
Training_Epoch:[ 89 ] Training_loss: 0.36294476985931395 2022-07-01 17:45:23.410388
learning rate:  0.0001677721600000001
val: 1 0.3861752450466156
val: 2 0.38455891609191895
val: 3 0.3890703618526459
val: 4 0.3860984444618225
val: 5 0.3936893045902252
val: 6 0.392417311668396
val: 7 0.3913946747779846
val: 8 0.38086962699890137
val: 9 0.395571768283844
val: 10 0.39103609323501587
val: 11 0.38964805006980896
val: 12 0.38823550939559937
val: 13 0.3873033821582794
val: 14 0.38197213411331177
val: 15 0.38756006956100464
val: 16 0.3814346492290497
val: 17 0.38927140831947327
val: 18 0.3912087082862854
val: 19 0.38353365659713745
val: 20 0.38927656412124634
val_Epoch:[ 89 ] val_loss: 0.3880162939429283 2022-07-01 17:45:27.256582
start training 2022-07-01 17:45:27.351195
Epoch:[ 90 0 ] loss: 0.36421599984169006 2022-07-01 17:45:41.731032
Epoch:[ 90 1 ] loss: 0.3627105951309204 2022-07-01 17:45:42.183683
Epoch:[ 90 2 ] loss: 0.3635886311531067 2022-07-01 17:45:42.610534
Epoch:[ 90 3 ] loss: 0.3624230623245239 2022-07-01 17:45:43.038033
Epoch:[ 90 4 ] loss: 0.36421364545822144 2022-07-01 17:45:43.465937
Epoch:[ 90 5 ] loss: 0.3638781011104584 2022-07-01 17:45:43.897766
Epoch:[ 90 6 ] loss: 0.3624384105205536 2022-07-01 17:45:44.322517
Epoch:[ 90 7 ] loss: 0.3623766303062439 2022-07-01 17:45:44.750765
Epoch:[ 90 8 ] loss: 0.3637810945510864 2022-07-01 17:45:45.176785
Epoch:[ 90 9 ] loss: 0.36286383867263794 2022-07-01 17:45:45.600883
Epoch:[ 90 10 ] loss: 0.36280566453933716 2022-07-01 17:45:46.029159
Epoch:[ 90 11 ] loss: 0.3621063828468323 2022-07-01 17:45:46.456572
Epoch:[ 90 12 ] loss: 0.3631066083908081 2022-07-01 17:45:46.884539
Epoch:[ 90 13 ] loss: 0.36285287141799927 2022-07-01 17:45:47.317650
Epoch:[ 90 14 ] loss: 0.362885445356369 2022-07-01 17:45:47.743271
Epoch:[ 90 15 ] loss: 0.36283284425735474 2022-07-01 17:45:48.191328
Epoch:[ 90 16 ] loss: 0.36490392684936523 2022-07-01 17:45:53.574311
Epoch:[ 90 17 ] loss: 0.3636554777622223 2022-07-01 17:45:54.002863
Epoch:[ 90 18 ] loss: 0.36280059814453125 2022-07-01 17:45:54.501848
Epoch:[ 90 19 ] loss: 0.3630962073802948 2022-07-01 17:45:54.990023
Training_Epoch:[ 90 ] Training_loss: 0.36317680180072787 2022-07-01 17:45:54.990760
learning rate:  0.0001677721600000001
netparams have been saved once 90
val: 1 0.39572271704673767
val: 2 0.38753730058670044
val: 3 0.3855951428413391
val: 4 0.3891203999519348
val: 5 0.3914499580860138
val: 6 0.3904723525047302
val: 7 0.3910536766052246
val: 8 0.3885625898838043
val: 9 0.3860628604888916
val: 10 0.384977251291275
val: 11 0.38555988669395447
val: 12 0.38148587942123413
val: 13 0.39712634682655334
val: 14 0.3903826177120209
val: 15 0.39066168665885925
val: 16 0.39243531227111816
val: 17 0.39087578654289246
val: 18 0.3851231336593628
val: 19 0.38769909739494324
val: 20 0.3855583071708679
val_Epoch:[ 90 ] val_loss: 0.3888731151819229 2022-07-01 17:45:58.924235
start training 2022-07-01 17:45:59.021118
Epoch:[ 91 0 ] loss: 0.362902969121933 2022-07-01 17:46:13.607786
Epoch:[ 91 1 ] loss: 0.3622134029865265 2022-07-01 17:46:14.098326
Epoch:[ 91 2 ] loss: 0.36320143938064575 2022-07-01 17:46:14.591419
Epoch:[ 91 3 ] loss: 0.36350008845329285 2022-07-01 17:46:15.080435
Epoch:[ 91 4 ] loss: 0.3626489043235779 2022-07-01 17:46:15.573191
Epoch:[ 91 5 ] loss: 0.3636561334133148 2022-07-01 17:46:16.070257
Epoch:[ 91 6 ] loss: 0.3634984791278839 2022-07-01 17:46:16.562927
Epoch:[ 91 7 ] loss: 0.3635937571525574 2022-07-01 17:46:17.054065
Epoch:[ 91 8 ] loss: 0.3634014427661896 2022-07-01 17:46:17.545732
Epoch:[ 91 9 ] loss: 0.3630618751049042 2022-07-01 17:46:18.042609
Epoch:[ 91 10 ] loss: 0.36194825172424316 2022-07-01 17:46:18.530218
Epoch:[ 91 11 ] loss: 0.36211341619491577 2022-07-01 17:46:19.024020
Epoch:[ 91 12 ] loss: 0.36200541257858276 2022-07-01 17:46:19.516208
Epoch:[ 91 13 ] loss: 0.3622016906738281 2022-07-01 17:46:19.945570
Epoch:[ 91 14 ] loss: 0.3635397255420685 2022-07-01 17:46:20.379285
Epoch:[ 91 15 ] loss: 0.3640574514865875 2022-07-01 17:46:20.811549
Epoch:[ 91 16 ] loss: 0.3623524308204651 2022-07-01 17:46:24.890839
Epoch:[ 91 17 ] loss: 0.3630047142505646 2022-07-01 17:46:25.507236
Epoch:[ 91 18 ] loss: 0.36316683888435364 2022-07-01 17:46:25.959074
Epoch:[ 91 19 ] loss: 0.3626464009284973 2022-07-01 17:46:26.378274
Training_Epoch:[ 91 ] Training_loss: 0.3629357412457466 2022-07-01 17:46:26.379122
learning rate:  0.00013421772800000008
val: 1 0.3935295045375824
val: 2 0.3845289945602417
val: 3 0.38791748881340027
val: 4 0.38785773515701294
val: 5 0.38500869274139404
val: 6 0.3844180107116699
val: 7 0.3936551511287689
val: 8 0.39763879776000977
val: 9 0.3941629230976105
val: 10 0.38714274764060974
val: 11 0.38664525747299194
val: 12 0.39327117800712585
val: 13 0.3854169249534607
val: 14 0.3854166567325592
val: 15 0.3853538930416107
val: 16 0.3906283974647522
val: 17 0.3974565863609314
val: 18 0.3882026672363281
val: 19 0.382744163274765
val: 20 0.3879683315753937
val_Epoch:[ 91 ] val_loss: 0.38894820511341094 2022-07-01 17:46:30.191202
start training 2022-07-01 17:46:30.286633
Epoch:[ 92 0 ] loss: 0.36210277676582336 2022-07-01 17:46:45.487360
Epoch:[ 92 1 ] loss: 0.36286643147468567 2022-07-01 17:46:45.901856
Epoch:[ 92 2 ] loss: 0.363237202167511 2022-07-01 17:46:46.316648
Epoch:[ 92 3 ] loss: 0.3624449372291565 2022-07-01 17:46:46.731704
Epoch:[ 92 4 ] loss: 0.3613958954811096 2022-07-01 17:46:47.146802
Epoch:[ 92 5 ] loss: 0.3619709610939026 2022-07-01 17:46:47.569421
Epoch:[ 92 6 ] loss: 0.3625527620315552 2022-07-01 17:46:47.992290
Epoch:[ 92 7 ] loss: 0.3630756139755249 2022-07-01 17:46:48.407832
Epoch:[ 92 8 ] loss: 0.3621065020561218 2022-07-01 17:46:48.822865
Epoch:[ 92 9 ] loss: 0.3636128902435303 2022-07-01 17:46:49.237958
Epoch:[ 92 10 ] loss: 0.36253008246421814 2022-07-01 17:46:49.654179
Epoch:[ 92 11 ] loss: 0.3615224063396454 2022-07-01 17:46:50.067745
Epoch:[ 92 12 ] loss: 0.3620440661907196 2022-07-01 17:46:50.484416
Epoch:[ 92 13 ] loss: 0.3629912734031677 2022-07-01 17:46:50.901097
Epoch:[ 92 14 ] loss: 0.36255475878715515 2022-07-01 17:46:51.323265
Epoch:[ 92 15 ] loss: 0.36317163705825806 2022-07-01 17:46:51.738387
Epoch:[ 92 16 ] loss: 0.3644959628582001 2022-07-01 17:46:57.281190
Epoch:[ 92 17 ] loss: 0.36245620250701904 2022-07-01 17:46:57.694272
Epoch:[ 92 18 ] loss: 0.3626157343387604 2022-07-01 17:46:58.109131
Epoch:[ 92 19 ] loss: 0.36328551173210144 2022-07-01 17:46:58.530868
Training_Epoch:[ 92 ] Training_loss: 0.3626516804099083 2022-07-01 17:46:58.531938
learning rate:  0.00013421772800000008
netparams have been saved once 92
val: 1 0.39253613352775574
val: 2 0.3901645243167877
val: 3 0.3898143768310547
val: 4 0.3887621760368347
val: 5 0.38428038358688354
val: 6 0.38802069425582886
val: 7 0.3903142511844635
val: 8 0.391343891620636
val: 9 0.39414432644844055
val: 10 0.3872269093990326
val: 11 0.39427849650382996
val: 12 0.3847700357437134
val: 13 0.40034791827201843
val: 14 0.387675940990448
val: 15 0.3916577696800232
val: 16 0.3837788701057434
val: 17 0.391783744096756
val: 18 0.3893052637577057
val: 19 0.3936997652053833
val: 20 0.38563111424446106
val_Epoch:[ 92 ] val_loss: 0.38997682929039 2022-07-01 17:47:02.543277
start training 2022-07-01 17:47:02.639744
Epoch:[ 93 0 ] loss: 0.36216336488723755 2022-07-01 17:47:17.093173
Epoch:[ 93 1 ] loss: 0.36409977078437805 2022-07-01 17:47:17.528112
Epoch:[ 93 2 ] loss: 0.363776296377182 2022-07-01 17:47:17.941657
Epoch:[ 93 3 ] loss: 0.36215370893478394 2022-07-01 17:47:18.356280
Epoch:[ 93 4 ] loss: 0.3621082603931427 2022-07-01 17:47:18.763859
Epoch:[ 93 5 ] loss: 0.3631499111652374 2022-07-01 17:47:19.177615
Epoch:[ 93 6 ] loss: 0.36269545555114746 2022-07-01 17:47:19.587629
Epoch:[ 93 7 ] loss: 0.3621505796909332 2022-07-01 17:47:20.005532
Epoch:[ 93 8 ] loss: 0.3628624677658081 2022-07-01 17:47:20.421129
Epoch:[ 93 9 ] loss: 0.36150622367858887 2022-07-01 17:47:20.834770
Epoch:[ 93 10 ] loss: 0.36227086186408997 2022-07-01 17:47:21.249429
Epoch:[ 93 11 ] loss: 0.36474716663360596 2022-07-01 17:47:21.671794
Epoch:[ 93 12 ] loss: 0.3625839650630951 2022-07-01 17:47:22.086659
Epoch:[ 93 13 ] loss: 0.3622238337993622 2022-07-01 17:47:22.503167
Epoch:[ 93 14 ] loss: 0.3624049127101898 2022-07-01 17:47:22.918708
Epoch:[ 93 15 ] loss: 0.3640311360359192 2022-07-01 17:47:23.334288
Epoch:[ 93 16 ] loss: 0.36207687854766846 2022-07-01 17:47:28.690794
Epoch:[ 93 17 ] loss: 0.3620031476020813 2022-07-01 17:47:29.110352
Epoch:[ 93 18 ] loss: 0.3628096878528595 2022-07-01 17:47:29.531646
Epoch:[ 93 19 ] loss: 0.36246246099472046 2022-07-01 17:47:29.945126
Training_Epoch:[ 93 ] Training_loss: 0.3627140045166016 2022-07-01 17:47:29.945879
learning rate:  0.00013421772800000008
val: 1 0.3953901529312134
val: 2 0.38851240277290344
val: 3 0.38742050528526306
val: 4 0.39067429304122925
val: 5 0.39477744698524475
val: 6 0.3859665095806122
val: 7 0.3914147615432739
val: 8 0.39125967025756836
val: 9 0.3822961449623108
val: 10 0.390543133020401
val: 11 0.3909665048122406
val: 12 0.39089447259902954
val: 13 0.3851107358932495
val: 14 0.3945838212966919
val: 15 0.3890990912914276
val: 16 0.38685375452041626
val: 17 0.39134252071380615
val: 18 0.38983625173568726
val: 19 0.3934881091117859
val: 20 0.39080798625946045
val_Epoch:[ 93 ] val_loss: 0.39006191343069074 2022-07-01 17:47:33.757744
start training 2022-07-01 17:47:33.856991
Epoch:[ 94 0 ] loss: 0.36254608631134033 2022-07-01 17:47:48.235891
Epoch:[ 94 1 ] loss: 0.36328816413879395 2022-07-01 17:47:48.671878
Epoch:[ 94 2 ] loss: 0.36140045523643494 2022-07-01 17:47:49.086848
Epoch:[ 94 3 ] loss: 0.36385592818260193 2022-07-01 17:47:49.503622
Epoch:[ 94 4 ] loss: 0.36266398429870605 2022-07-01 17:47:49.918375
Epoch:[ 94 5 ] loss: 0.3628063201904297 2022-07-01 17:47:50.332390
Epoch:[ 94 6 ] loss: 0.3635317087173462 2022-07-01 17:47:50.746212
Epoch:[ 94 7 ] loss: 0.3622710704803467 2022-07-01 17:47:51.168249
Epoch:[ 94 8 ] loss: 0.36211246252059937 2022-07-01 17:47:51.585519
Epoch:[ 94 9 ] loss: 0.36235547065734863 2022-07-01 17:47:52.008555
Epoch:[ 94 10 ] loss: 0.3627377450466156 2022-07-01 17:47:52.424599
Epoch:[ 94 11 ] loss: 0.36373671889305115 2022-07-01 17:47:52.839235
Epoch:[ 94 12 ] loss: 0.3620435297489166 2022-07-01 17:47:53.254081
Epoch:[ 94 13 ] loss: 0.36244434118270874 2022-07-01 17:47:53.667640
Epoch:[ 94 14 ] loss: 0.36297938227653503 2022-07-01 17:47:54.089442
Epoch:[ 94 15 ] loss: 0.3629492223262787 2022-07-01 17:47:54.503936
Epoch:[ 94 16 ] loss: 0.3623026907444 2022-07-01 17:47:59.776875
Epoch:[ 94 17 ] loss: 0.36255985498428345 2022-07-01 17:48:00.202045
Epoch:[ 94 18 ] loss: 0.3628511130809784 2022-07-01 17:48:00.618593
Epoch:[ 94 19 ] loss: 0.3620084524154663 2022-07-01 17:48:01.038027
Training_Epoch:[ 94 ] Training_loss: 0.3626722350716591 2022-07-01 17:48:01.038699
learning rate:  0.00013421772800000008
netparams have been saved once 94
val: 1 0.3972023129463196
val: 2 0.38822272419929504
val: 3 0.3920307159423828
val: 4 0.3882134258747101
val: 5 0.39451539516448975
val: 6 0.39335691928863525
val: 7 0.3838851749897003
val: 8 0.3882458508014679
val: 9 0.39564722776412964
val: 10 0.3851110637187958
val: 11 0.3882835805416107
val: 12 0.38393962383270264
val: 13 0.3786700367927551
val: 14 0.38457030057907104
val: 15 0.3980405628681183
val: 16 0.39304736256599426
val: 17 0.38830339908599854
val: 18 0.38767799735069275
val: 19 0.39129582047462463
val: 20 0.38818514347076416
val_Epoch:[ 94 ] val_loss: 0.38942223191261294 2022-07-01 17:48:04.956854
start training 2022-07-01 17:48:05.054508
Epoch:[ 95 0 ] loss: 0.36282503604888916 2022-07-01 17:48:19.646584
Epoch:[ 95 1 ] loss: 0.3635886311531067 2022-07-01 17:48:20.064043
Epoch:[ 95 2 ] loss: 0.36193183064460754 2022-07-01 17:48:20.481318
Epoch:[ 95 3 ] loss: 0.36185505986213684 2022-07-01 17:48:20.896990
Epoch:[ 95 4 ] loss: 0.3624362051486969 2022-07-01 17:48:21.312336
Epoch:[ 95 5 ] loss: 0.361031711101532 2022-07-01 17:48:21.727929
Epoch:[ 95 6 ] loss: 0.362129807472229 2022-07-01 17:48:22.142186
Epoch:[ 95 7 ] loss: 0.3638330101966858 2022-07-01 17:48:22.557227
Epoch:[ 95 8 ] loss: 0.36281919479370117 2022-07-01 17:48:22.973612
Epoch:[ 95 9 ] loss: 0.36273887753486633 2022-07-01 17:48:23.389790
Epoch:[ 95 10 ] loss: 0.3619369566440582 2022-07-01 17:48:23.798603
Epoch:[ 95 11 ] loss: 0.36334800720214844 2022-07-01 17:48:24.214982
Epoch:[ 95 12 ] loss: 0.36217355728149414 2022-07-01 17:48:24.624615
Epoch:[ 95 13 ] loss: 0.363159716129303 2022-07-01 17:48:25.037996
Epoch:[ 95 14 ] loss: 0.36343538761138916 2022-07-01 17:48:25.450665
Epoch:[ 95 15 ] loss: 0.3634807765483856 2022-07-01 17:48:25.866342
Epoch:[ 95 16 ] loss: 0.36236894130706787 2022-07-01 17:48:31.171818
Epoch:[ 95 17 ] loss: 0.3628294765949249 2022-07-01 17:48:31.580107
Epoch:[ 95 18 ] loss: 0.36229193210601807 2022-07-01 17:48:31.997329
Epoch:[ 95 19 ] loss: 0.36221179366111755 2022-07-01 17:48:32.407254
Training_Epoch:[ 95 ] Training_loss: 0.3626212954521179 2022-07-01 17:48:32.408063
learning rate:  0.00013421772800000008
val: 1 0.3855063319206238
val: 2 0.38755983114242554
val: 3 0.3913346230983734
val: 4 0.39510229229927063
val: 5 0.39652350544929504
val: 6 0.38630834221839905
val: 7 0.39211684465408325
val: 8 0.388725608587265
val: 9 0.38773664832115173
val: 10 0.3998417258262634
val: 11 0.39231574535369873
val: 12 0.38222742080688477
val: 13 0.39094778895378113
val: 14 0.3929317891597748
val: 15 0.3846868574619293
val: 16 0.389004111289978
val: 17 0.3909103572368622
val: 18 0.38255393505096436
val: 19 0.3900107443332672
val: 20 0.38632455468177795
val_Epoch:[ 95 ] val_loss: 0.38963345289230344 2022-07-01 17:48:36.264175
start training 2022-07-01 17:48:36.360283
Epoch:[ 96 0 ] loss: 0.364120215177536 2022-07-01 17:48:50.346847
Epoch:[ 96 1 ] loss: 0.36145880818367004 2022-07-01 17:48:50.769312
Epoch:[ 96 2 ] loss: 0.3626422882080078 2022-07-01 17:48:51.209538
Epoch:[ 96 3 ] loss: 0.36301618814468384 2022-07-01 17:48:51.625610
Epoch:[ 96 4 ] loss: 0.3621577024459839 2022-07-01 17:48:52.042098
Epoch:[ 96 5 ] loss: 0.36279577016830444 2022-07-01 17:48:52.451036
Epoch:[ 96 6 ] loss: 0.36292776465415955 2022-07-01 17:48:52.867810
Epoch:[ 96 7 ] loss: 0.3614559471607208 2022-07-01 17:48:53.283011
Epoch:[ 96 8 ] loss: 0.3632664084434509 2022-07-01 17:48:53.696803
Epoch:[ 96 9 ] loss: 0.3620195686817169 2022-07-01 17:48:54.113020
Epoch:[ 96 10 ] loss: 0.36256927251815796 2022-07-01 17:48:54.529256
Epoch:[ 96 11 ] loss: 0.3630077838897705 2022-07-01 17:48:54.945848
Epoch:[ 96 12 ] loss: 0.36219918727874756 2022-07-01 17:48:55.360832
Epoch:[ 96 13 ] loss: 0.3619631826877594 2022-07-01 17:48:55.769719
Epoch:[ 96 14 ] loss: 0.36230164766311646 2022-07-01 17:48:56.186836
Epoch:[ 96 15 ] loss: 0.3623257875442505 2022-07-01 17:48:56.603130
Epoch:[ 96 16 ] loss: 0.36235862970352173 2022-07-01 17:49:02.314487
Epoch:[ 96 17 ] loss: 0.361709862947464 2022-07-01 17:49:02.730086
Epoch:[ 96 18 ] loss: 0.362575501203537 2022-07-01 17:49:03.149047
Epoch:[ 96 19 ] loss: 0.36306828260421753 2022-07-01 17:49:03.558322
Training_Epoch:[ 96 ] Training_loss: 0.36249698996543883 2022-07-01 17:49:03.559620
learning rate:  0.00013421772800000008
netparams have been saved once 96
val: 1 0.39469727873802185
val: 2 0.38461801409721375
val: 3 0.3890397548675537
val: 4 0.39086517691612244
val: 5 0.38625556230545044
val: 6 0.3819747865200043
val: 7 0.3847607970237732
val: 8 0.39453381299972534
val: 9 0.388802707195282
val: 10 0.3885125517845154
val: 11 0.4034932851791382
val: 12 0.3918896019458771
val: 13 0.3820899724960327
val: 14 0.383265882730484
val: 15 0.39157623052597046
val: 16 0.3874081075191498
val: 17 0.3869728744029999
val: 18 0.38890740275382996
val: 19 0.39092788100242615
val: 20 0.39427313208580017
val_Epoch:[ 96 ] val_loss: 0.3892432406544685 2022-07-01 17:49:07.573973
start training 2022-07-01 17:49:07.670778
Epoch:[ 97 0 ] loss: 0.3627283573150635 2022-07-01 17:49:22.379150
Epoch:[ 97 1 ] loss: 0.36171430349349976 2022-07-01 17:49:22.792825
Epoch:[ 97 2 ] loss: 0.3621504008769989 2022-07-01 17:49:23.208014
Epoch:[ 97 3 ] loss: 0.3627496063709259 2022-07-01 17:49:23.629862
Epoch:[ 97 4 ] loss: 0.3619464337825775 2022-07-01 17:49:24.046330
Epoch:[ 97 5 ] loss: 0.3625929653644562 2022-07-01 17:49:24.461017
Epoch:[ 97 6 ] loss: 0.3626523017883301 2022-07-01 17:49:24.875468
Epoch:[ 97 7 ] loss: 0.36359986662864685 2022-07-01 17:49:25.291042
Epoch:[ 97 8 ] loss: 0.36362800002098083 2022-07-01 17:49:25.705005
Epoch:[ 97 9 ] loss: 0.36259523034095764 2022-07-01 17:49:26.117904
Epoch:[ 97 10 ] loss: 0.3628925681114197 2022-07-01 17:49:26.533146
Epoch:[ 97 11 ] loss: 0.3641577363014221 2022-07-01 17:49:26.948960
Epoch:[ 97 12 ] loss: 0.3626405596733093 2022-07-01 17:49:27.365385
Epoch:[ 97 13 ] loss: 0.3632928431034088 2022-07-01 17:49:27.785695
Epoch:[ 97 14 ] loss: 0.36281776428222656 2022-07-01 17:49:28.199828
Epoch:[ 97 15 ] loss: 0.3629278242588043 2022-07-01 17:49:28.620836
Epoch:[ 97 16 ] loss: 0.36318472027778625 2022-07-01 17:49:33.923505
Epoch:[ 97 17 ] loss: 0.36253446340560913 2022-07-01 17:49:34.337577
Epoch:[ 97 18 ] loss: 0.36098650097846985 2022-07-01 17:49:34.760391
Epoch:[ 97 19 ] loss: 0.3618308901786804 2022-07-01 17:49:35.184759
Training_Epoch:[ 97 ] Training_loss: 0.3626811668276787 2022-07-01 17:49:35.185400
learning rate:  0.00013421772800000008
val: 1 0.38930147886276245
val: 2 0.39089009165763855
val: 3 0.3849576413631439
val: 4 0.3949664235115051
val: 5 0.38162681460380554
val: 6 0.3918027877807617
val: 7 0.3889957666397095
val: 8 0.391245573759079
val: 9 0.39199793338775635
val: 10 0.3867931663990021
val: 11 0.38612639904022217
val: 12 0.38841375708580017
val: 13 0.3835795819759369
val: 14 0.38596218824386597
val: 15 0.38778916001319885
val: 16 0.39381143450737
val: 17 0.3959938585758209
val: 18 0.3910059928894043
val: 19 0.38387060165405273
val: 20 0.3899848461151123
val_Epoch:[ 97 ] val_loss: 0.3889557749032974 2022-07-01 17:49:39.063760
start training 2022-07-01 17:49:39.162856
Epoch:[ 98 0 ] loss: 0.36289894580841064 2022-07-01 17:49:53.621257
Epoch:[ 98 1 ] loss: 0.36267128586769104 2022-07-01 17:49:54.047136
Epoch:[ 98 2 ] loss: 0.3621711730957031 2022-07-01 17:49:54.468971
Epoch:[ 98 3 ] loss: 0.36178267002105713 2022-07-01 17:49:54.882376
Epoch:[ 98 4 ] loss: 0.36274659633636475 2022-07-01 17:49:55.299300
Epoch:[ 98 5 ] loss: 0.3616127073764801 2022-07-01 17:49:55.715824
Epoch:[ 98 6 ] loss: 0.36148157715797424 2022-07-01 17:49:56.133769
Epoch:[ 98 7 ] loss: 0.3630126118659973 2022-07-01 17:49:56.548034
Epoch:[ 98 8 ] loss: 0.36365199089050293 2022-07-01 17:49:56.962975
Epoch:[ 98 9 ] loss: 0.3614725172519684 2022-07-01 17:49:57.382905
Epoch:[ 98 10 ] loss: 0.36215662956237793 2022-07-01 17:49:57.802863
Epoch:[ 98 11 ] loss: 0.36293941736221313 2022-07-01 17:49:58.218720
Epoch:[ 98 12 ] loss: 0.36148694157600403 2022-07-01 17:49:58.635668
Epoch:[ 98 13 ] loss: 0.3635038733482361 2022-07-01 17:49:59.050520
Epoch:[ 98 14 ] loss: 0.3624725341796875 2022-07-01 17:49:59.464087
Epoch:[ 98 15 ] loss: 0.36278414726257324 2022-07-01 17:49:59.878368
Epoch:[ 98 16 ] loss: 0.3623292148113251 2022-07-01 17:50:05.021111
Epoch:[ 98 17 ] loss: 0.3622343838214874 2022-07-01 17:50:05.598302
Epoch:[ 98 18 ] loss: 0.36232495307922363 2022-07-01 17:50:06.021660
Epoch:[ 98 19 ] loss: 0.36328718066215515 2022-07-01 17:50:06.437861
Training_Epoch:[ 98 ] Training_loss: 0.3624510675668716 2022-07-01 17:50:06.438581
learning rate:  0.00013421772800000008
netparams have been saved once 98
val: 1 0.3908352255821228
val: 2 0.3806861340999603
val: 3 0.39378538727760315
val: 4 0.3894957900047302
val: 5 0.3862588107585907
val: 6 0.3893834948539734
val: 7 0.39057356119155884
val: 8 0.3907230496406555
val: 9 0.3879247307777405
val: 10 0.39035001397132874
val: 11 0.3889642655849457
val: 12 0.3986942768096924
val: 13 0.39049458503723145
val: 14 0.389020711183548
val: 15 0.3860935568809509
val: 16 0.390115886926651
val: 17 0.39374420046806335
val: 18 0.383965402841568
val: 19 0.38990432024002075
val: 20 0.3865572214126587
val_Epoch:[ 98 ] val_loss: 0.3893785312771797 2022-07-01 17:50:10.302510
start training 2022-07-01 17:50:10.401597
Epoch:[ 99 0 ] loss: 0.36331847310066223 2022-07-01 17:50:24.946869
Epoch:[ 99 1 ] loss: 0.3617190718650818 2022-07-01 17:50:25.372238
Epoch:[ 99 2 ] loss: 0.36294272541999817 2022-07-01 17:50:25.793827
Epoch:[ 99 3 ] loss: 0.36165738105773926 2022-07-01 17:50:26.214073
Epoch:[ 99 4 ] loss: 0.3634081780910492 2022-07-01 17:50:26.627061
Epoch:[ 99 5 ] loss: 0.36223116517066956 2022-07-01 17:50:27.043890
Epoch:[ 99 6 ] loss: 0.3625549077987671 2022-07-01 17:50:27.459776
Epoch:[ 99 7 ] loss: 0.3627089262008667 2022-07-01 17:50:27.874499
Epoch:[ 99 8 ] loss: 0.36191344261169434 2022-07-01 17:50:28.292065
Epoch:[ 99 9 ] loss: 0.3626420795917511 2022-07-01 17:50:28.711984
Epoch:[ 99 10 ] loss: 0.36121323704719543 2022-07-01 17:50:29.126033
Epoch:[ 99 11 ] loss: 0.3623885214328766 2022-07-01 17:50:29.543727
Epoch:[ 99 12 ] loss: 0.3613807260990143 2022-07-01 17:50:29.960162
Epoch:[ 99 13 ] loss: 0.36238008737564087 2022-07-01 17:50:30.376479
Epoch:[ 99 14 ] loss: 0.36354711651802063 2022-07-01 17:50:30.791256
Epoch:[ 99 15 ] loss: 0.3625785708427429 2022-07-01 17:50:31.205129
Epoch:[ 99 16 ] loss: 0.36163023114204407 2022-07-01 17:50:36.417879
Epoch:[ 99 17 ] loss: 0.3625706434249878 2022-07-01 17:50:37.206052
Epoch:[ 99 18 ] loss: 0.3621968924999237 2022-07-01 17:50:37.619904
Epoch:[ 99 19 ] loss: 0.3636570870876312 2022-07-01 17:50:38.041019
Training_Epoch:[ 99 ] Training_loss: 0.36243197321891785 2022-07-01 17:50:38.041726
learning rate:  0.00013421772800000008
val: 1 0.39134177565574646
val: 2 0.3959367573261261
val: 3 0.39121145009994507
val: 4 0.3847906291484833
val: 5 0.38745132088661194
val: 6 0.38439005613327026
val: 7 0.3932519555091858
val: 8 0.38255661725997925
val: 9 0.38446417450904846
val: 10 0.3856073021888733
val: 11 0.3782055675983429
val: 12 0.39338281750679016
val: 13 0.4002062976360321
val: 14 0.3851016163825989
val: 15 0.38790008425712585
val: 16 0.39512792229652405
val: 17 0.3806861937046051
val: 18 0.3941552937030792
val: 19 0.391275018453598
val: 20 0.3982381224632263
val_Epoch:[ 99 ] val_loss: 0.38926404863595965 2022-07-01 17:50:41.886893
start training 2022-07-01 17:50:41.984990
Epoch:[ 100 0 ] loss: 0.3615109920501709 2022-07-01 17:50:57.017340
Epoch:[ 100 1 ] loss: 0.36266499757766724 2022-07-01 17:50:57.432118
Epoch:[ 100 2 ] loss: 0.3638051748275757 2022-07-01 17:50:57.846016
Epoch:[ 100 3 ] loss: 0.3618444800376892 2022-07-01 17:50:58.266062
Epoch:[ 100 4 ] loss: 0.3620952069759369 2022-07-01 17:50:58.679804
Epoch:[ 100 5 ] loss: 0.3624951243400574 2022-07-01 17:50:59.094074
Epoch:[ 100 6 ] loss: 0.36175447702407837 2022-07-01 17:50:59.509982
Epoch:[ 100 7 ] loss: 0.36446723341941833 2022-07-01 17:50:59.925794
Epoch:[ 100 8 ] loss: 0.36082035303115845 2022-07-01 17:51:00.340207
Epoch:[ 100 9 ] loss: 0.36233994364738464 2022-07-01 17:51:00.753873
Epoch:[ 100 10 ] loss: 0.3621823489665985 2022-07-01 17:51:01.175850
Epoch:[ 100 11 ] loss: 0.3628137707710266 2022-07-01 17:51:01.589738
Epoch:[ 100 12 ] loss: 0.36215728521347046 2022-07-01 17:51:02.003568
Epoch:[ 100 13 ] loss: 0.36377596855163574 2022-07-01 17:51:02.419225
Epoch:[ 100 14 ] loss: 0.36346983909606934 2022-07-01 17:51:02.841171
Epoch:[ 100 15 ] loss: 0.3625609874725342 2022-07-01 17:51:03.255648
Epoch:[ 100 16 ] loss: 0.36249250173568726 2022-07-01 17:51:08.752622
Epoch:[ 100 17 ] loss: 0.3627549707889557 2022-07-01 17:51:09.165632
Epoch:[ 100 18 ] loss: 0.3619152903556824 2022-07-01 17:51:09.582732
Epoch:[ 100 19 ] loss: 0.3621777594089508 2022-07-01 17:51:10.002460
Training_Epoch:[ 100 ] Training_loss: 0.3625049352645874 2022-07-01 17:51:10.003082
learning rate:  0.00013421772800000008
netparams have been saved once 100
val: 1 0.3893946409225464
val: 2 0.38664889335632324
val: 3 0.3828926086425781
val: 4 0.38701412081718445
val: 5 0.3874576687812805
val: 6 0.3954451382160187
val: 7 0.39079025387763977
val: 8 0.3866303265094757
val: 9 0.3892589509487152
val: 10 0.38972100615501404
val: 11 0.386027067899704
val: 12 0.38469457626342773
val: 13 0.3840651214122772
val: 14 0.3990887701511383
val: 15 0.3922516703605652
val: 16 0.3848206698894501
val: 17 0.39183032512664795
val: 18 0.3888269066810608
val: 19 0.3907560408115387
val: 20 0.3922329246997833
val_Epoch:[ 100 ] val_loss: 0.38899238407611847 2022-07-01 17:51:13.906980
start training 2022-07-01 17:51:14.006637
Epoch:[ 101 0 ] loss: 0.3621758222579956 2022-07-01 17:51:28.886918
Epoch:[ 101 1 ] loss: 0.3614957630634308 2022-07-01 17:51:29.303238
Epoch:[ 101 2 ] loss: 0.36247098445892334 2022-07-01 17:51:29.718188
Epoch:[ 101 3 ] loss: 0.36179280281066895 2022-07-01 17:51:30.132759
Epoch:[ 101 4 ] loss: 0.36322399973869324 2022-07-01 17:51:30.549564
Epoch:[ 101 5 ] loss: 0.3628908097743988 2022-07-01 17:51:30.966245
Epoch:[ 101 6 ] loss: 0.3620189130306244 2022-07-01 17:51:31.386504
Epoch:[ 101 7 ] loss: 0.3625420033931732 2022-07-01 17:51:31.801734
Epoch:[ 101 8 ] loss: 0.36325567960739136 2022-07-01 17:51:32.217953
Epoch:[ 101 9 ] loss: 0.36220911145210266 2022-07-01 17:51:32.633026
Epoch:[ 101 10 ] loss: 0.3609025478363037 2022-07-01 17:51:33.047420
Epoch:[ 101 11 ] loss: 0.362732857465744 2022-07-01 17:51:33.468950
Epoch:[ 101 12 ] loss: 0.3625619113445282 2022-07-01 17:51:33.883443
Epoch:[ 101 13 ] loss: 0.3629729151725769 2022-07-01 17:51:34.299233
Epoch:[ 101 14 ] loss: 0.36271101236343384 2022-07-01 17:51:34.715242
Epoch:[ 101 15 ] loss: 0.3627426028251648 2022-07-01 17:51:35.138033
Epoch:[ 101 16 ] loss: 0.3620609641075134 2022-07-01 17:51:40.890584
Epoch:[ 101 17 ] loss: 0.3619157075881958 2022-07-01 17:51:41.308814
Epoch:[ 101 18 ] loss: 0.36140692234039307 2022-07-01 17:51:41.723603
Epoch:[ 101 19 ] loss: 0.36143773794174194 2022-07-01 17:51:42.140121
Training_Epoch:[ 101 ] Training_loss: 0.3622760534286499 2022-07-01 17:51:42.140795
learning rate:  0.00010737418240000007
val: 1 0.3848673403263092
val: 2 0.383129745721817
val: 3 0.38460731506347656
val: 4 0.3890220522880554
val: 5 0.39672544598579407
val: 6 0.40164056420326233
val: 7 0.3885101079940796
val: 8 0.3917385935783386
val: 9 0.38943180441856384
val: 10 0.38676247000694275
val: 11 0.39233601093292236
val: 12 0.3892034888267517
val: 13 0.3920240104198456
val: 14 0.3884064257144928
val: 15 0.38607773184776306
val: 16 0.39116814732551575
val: 17 0.3977203071117401
val: 18 0.38667914271354675
val: 19 0.38143759965896606
val: 20 0.38645806908607483
val_Epoch:[ 101 ] val_loss: 0.3893973186612129 2022-07-01 17:51:45.976875
start training 2022-07-01 17:51:46.074223
Epoch:[ 102 0 ] loss: 0.36140987277030945 2022-07-01 17:52:00.686630
Epoch:[ 102 1 ] loss: 0.36218398809432983 2022-07-01 17:52:01.100917
Epoch:[ 102 2 ] loss: 0.3614346385002136 2022-07-01 17:52:01.517251
Epoch:[ 102 3 ] loss: 0.36216264963150024 2022-07-01 17:52:01.933372
Epoch:[ 102 4 ] loss: 0.36332079768180847 2022-07-01 17:52:02.349060
Epoch:[ 102 5 ] loss: 0.36244356632232666 2022-07-01 17:52:02.761129
Epoch:[ 102 6 ] loss: 0.3621794283390045 2022-07-01 17:52:03.181141
Epoch:[ 102 7 ] loss: 0.36147773265838623 2022-07-01 17:52:03.599157
Epoch:[ 102 8 ] loss: 0.36207860708236694 2022-07-01 17:52:04.013311
Epoch:[ 102 9 ] loss: 0.36240655183792114 2022-07-01 17:52:04.429668
Epoch:[ 102 10 ] loss: 0.36283645033836365 2022-07-01 17:52:04.843077
Epoch:[ 102 11 ] loss: 0.36279749870300293 2022-07-01 17:52:05.255139
Epoch:[ 102 12 ] loss: 0.3615628182888031 2022-07-01 17:52:05.677074
Epoch:[ 102 13 ] loss: 0.3625039756298065 2022-07-01 17:52:06.096829
Epoch:[ 102 14 ] loss: 0.36203432083129883 2022-07-01 17:52:06.511604
Epoch:[ 102 15 ] loss: 0.3617398142814636 2022-07-01 17:52:06.926269
Epoch:[ 102 16 ] loss: 0.3624897003173828 2022-07-01 17:52:11.817526
Epoch:[ 102 17 ] loss: 0.3613722324371338 2022-07-01 17:52:12.231652
Epoch:[ 102 18 ] loss: 0.36086323857307434 2022-07-01 17:52:12.656789
Epoch:[ 102 19 ] loss: 0.3627856373786926 2022-07-01 17:52:13.076818
Training_Epoch:[ 102 ] Training_loss: 0.36210417598485944 2022-07-01 17:52:13.077517
learning rate:  0.00010737418240000007
netparams have been saved once 102
val: 1 0.39442139863967896
val: 2 0.3906918466091156
val: 3 0.38501960039138794
val: 4 0.3872482180595398
val: 5 0.39550191164016724
val: 6 0.3969117999076843
val: 7 0.3866257965564728
val: 8 0.38534271717071533
val: 9 0.39154061675071716
val: 10 0.39212775230407715
val: 11 0.3939399719238281
val: 12 0.3915489614009857
val: 13 0.39559081196784973
val: 14 0.3873012065887451
val: 15 0.39020639657974243
val: 16 0.3871868848800659
val: 17 0.38902032375335693
val: 18 0.3828793168067932
val: 19 0.39267799258232117
val: 20 0.40167972445487976
val_Epoch:[ 102 ] val_loss: 0.3908731624484062 2022-07-01 17:52:16.988191
start training 2022-07-01 17:52:17.089509
Epoch:[ 103 0 ] loss: 0.3622661232948303 2022-07-01 17:52:31.650996
Epoch:[ 103 1 ] loss: 0.36070606112480164 2022-07-01 17:52:32.063771
Epoch:[ 103 2 ] loss: 0.3624856173992157 2022-07-01 17:52:32.478805
Epoch:[ 103 3 ] loss: 0.3611113131046295 2022-07-01 17:52:32.896957
Epoch:[ 103 4 ] loss: 0.3617233335971832 2022-07-01 17:52:33.318260
Epoch:[ 103 5 ] loss: 0.3619037866592407 2022-07-01 17:52:33.730259
Epoch:[ 103 6 ] loss: 0.36223936080932617 2022-07-01 17:52:34.152143
Epoch:[ 103 7 ] loss: 0.3617091178894043 2022-07-01 17:52:34.564161
Epoch:[ 103 8 ] loss: 0.3620625138282776 2022-07-01 17:52:34.977292
Epoch:[ 103 9 ] loss: 0.36305126547813416 2022-07-01 17:52:35.392304
Epoch:[ 103 10 ] loss: 0.36211997270584106 2022-07-01 17:52:35.807582
Epoch:[ 103 11 ] loss: 0.36200791597366333 2022-07-01 17:52:36.221796
Epoch:[ 103 12 ] loss: 0.36128777265548706 2022-07-01 17:52:36.635619
Epoch:[ 103 13 ] loss: 0.36191096901893616 2022-07-01 17:52:37.048993
Epoch:[ 103 14 ] loss: 0.3615902364253998 2022-07-01 17:52:37.468989
Epoch:[ 103 15 ] loss: 0.362150102853775 2022-07-01 17:52:37.880681
Epoch:[ 103 16 ] loss: 0.3623892664909363 2022-07-01 17:52:43.365601
Epoch:[ 103 17 ] loss: 0.3627236783504486 2022-07-01 17:52:43.784666
Epoch:[ 103 18 ] loss: 0.3626973032951355 2022-07-01 17:52:44.199436
Epoch:[ 103 19 ] loss: 0.36161187291145325 2022-07-01 17:52:44.620662
Training_Epoch:[ 103 ] Training_loss: 0.361987379193306 2022-07-01 17:52:44.621317
learning rate:  0.00010737418240000007
val: 1 0.38765648007392883
val: 2 0.38600096106529236
val: 3 0.3866874575614929
val: 4 0.3899848759174347
val: 5 0.3969813585281372
val: 6 0.3937930762767792
val: 7 0.39230355620384216
val: 8 0.37977156043052673
val: 9 0.3957943022251129
val: 10 0.38310185074806213
val: 11 0.3893342614173889
val: 12 0.38302457332611084
val: 13 0.3997301161289215
val: 14 0.3852103352546692
val: 15 0.3927714228630066
val: 16 0.3841537833213806
val: 17 0.38868841528892517
val: 18 0.3890781104564667
val: 19 0.39280247688293457
val: 20 0.38736629486083984
val_Epoch:[ 103 ] val_loss: 0.38921176344156266 2022-07-01 17:52:48.519763
start training 2022-07-01 17:52:48.618158
Epoch:[ 104 0 ] loss: 0.3630823493003845 2022-07-01 17:53:03.440431
Epoch:[ 104 1 ] loss: 0.36194318532943726 2022-07-01 17:53:03.854710
Epoch:[ 104 2 ] loss: 0.3606831431388855 2022-07-01 17:53:04.274821
Epoch:[ 104 3 ] loss: 0.3607672452926636 2022-07-01 17:53:04.690253
Epoch:[ 104 4 ] loss: 0.36268964409828186 2022-07-01 17:53:05.113577
Epoch:[ 104 5 ] loss: 0.3613104224205017 2022-07-01 17:53:05.529691
Epoch:[ 104 6 ] loss: 0.36163634061813354 2022-07-01 17:53:05.944052
Epoch:[ 104 7 ] loss: 0.3630672097206116 2022-07-01 17:53:06.359167
Epoch:[ 104 8 ] loss: 0.36335042119026184 2022-07-01 17:53:06.773878
Epoch:[ 104 9 ] loss: 0.3613741993904114 2022-07-01 17:53:07.187823
Epoch:[ 104 10 ] loss: 0.36225834488868713 2022-07-01 17:53:07.601907
Epoch:[ 104 11 ] loss: 0.3620370924472809 2022-07-01 17:53:08.018016
Epoch:[ 104 12 ] loss: 0.3617449998855591 2022-07-01 17:53:08.439933
Epoch:[ 104 13 ] loss: 0.36259564757347107 2022-07-01 17:53:08.854445
Epoch:[ 104 14 ] loss: 0.3631669580936432 2022-07-01 17:53:09.269559
Epoch:[ 104 15 ] loss: 0.363167405128479 2022-07-01 17:53:09.683831
Epoch:[ 104 16 ] loss: 0.36205825209617615 2022-07-01 17:53:15.195542
Epoch:[ 104 17 ] loss: 0.36199143528938293 2022-07-01 17:53:15.619610
Epoch:[ 104 18 ] loss: 0.3613007664680481 2022-07-01 17:53:16.041450
Epoch:[ 104 19 ] loss: 0.36111214756965637 2022-07-01 17:53:16.454847
Training_Epoch:[ 104 ] Training_loss: 0.3620668604969978 2022-07-01 17:53:16.455527
learning rate:  0.00010737418240000007
netparams have been saved once 104
val: 1 0.3871016204357147
val: 2 0.3890591859817505
val: 3 0.3978606164455414
val: 4 0.3911025822162628
val: 5 0.38739731907844543
val: 6 0.3920136094093323
val: 7 0.39010024070739746
val: 8 0.388123482465744
val: 9 0.3854159414768219
val: 10 0.39088860154151917
val: 11 0.3883160650730133
val: 12 0.3893555700778961
val: 13 0.38458123803138733
val: 14 0.392723947763443
val: 15 0.3945516049861908
val: 16 0.38947874307632446
val: 17 0.3916863799095154
val: 18 0.3885568380355835
val: 19 0.38349995017051697
val: 20 0.3940194845199585
val_Epoch:[ 104 ] val_loss: 0.38979165107011793 2022-07-01 17:53:20.374797
start training 2022-07-01 17:53:20.471584
Epoch:[ 105 0 ] loss: 0.36142808198928833 2022-07-01 17:53:35.135414
Epoch:[ 105 1 ] loss: 0.36231499910354614 2022-07-01 17:53:35.549940
Epoch:[ 105 2 ] loss: 0.3611298203468323 2022-07-01 17:53:35.964283
Epoch:[ 105 3 ] loss: 0.36284783482551575 2022-07-01 17:53:36.381299
Epoch:[ 105 4 ] loss: 0.36283230781555176 2022-07-01 17:53:36.800141
Epoch:[ 105 5 ] loss: 0.36247512698173523 2022-07-01 17:53:37.217622
Epoch:[ 105 6 ] loss: 0.3619435727596283 2022-07-01 17:53:37.639107
Epoch:[ 105 7 ] loss: 0.36255037784576416 2022-07-01 17:53:38.060763
Epoch:[ 105 8 ] loss: 0.362398236989975 2022-07-01 17:53:38.478702
Epoch:[ 105 9 ] loss: 0.36209216713905334 2022-07-01 17:53:38.898420
Epoch:[ 105 10 ] loss: 0.36058568954467773 2022-07-01 17:53:39.313748
Epoch:[ 105 11 ] loss: 0.3618479371070862 2022-07-01 17:53:39.730438
Epoch:[ 105 12 ] loss: 0.3617825210094452 2022-07-01 17:53:40.153566
Epoch:[ 105 13 ] loss: 0.36118510365486145 2022-07-01 17:53:40.571107
Epoch:[ 105 14 ] loss: 0.36139753460884094 2022-07-01 17:53:40.989893
Epoch:[ 105 15 ] loss: 0.3637104630470276 2022-07-01 17:53:41.405837
Epoch:[ 105 16 ] loss: 0.36285626888275146 2022-07-01 17:53:47.323982
Epoch:[ 105 17 ] loss: 0.3619856536388397 2022-07-01 17:53:47.810106
Epoch:[ 105 18 ] loss: 0.36155998706817627 2022-07-01 17:53:48.228005
Epoch:[ 105 19 ] loss: 0.3616093099117279 2022-07-01 17:53:48.642228
Training_Epoch:[ 105 ] Training_loss: 0.3620266497135162 2022-07-01 17:53:48.642878
learning rate:  0.00010737418240000007
val: 1 0.38886797428131104
val: 2 0.3842073380947113
val: 3 0.39141353964805603
val: 4 0.3879714608192444
val: 5 0.38287553191185
val: 6 0.3919108211994171
val: 7 0.3951725363731384
val: 8 0.3906020522117615
val: 9 0.3956319987773895
val: 10 0.3911082446575165
val: 11 0.39176255464553833
val: 12 0.38941890001296997
val: 13 0.38612207770347595
val: 14 0.38908931612968445
val: 15 0.3887437582015991
val: 16 0.3919724225997925
val: 17 0.39162778854370117
val: 18 0.39809954166412354
val: 19 0.3972795009613037
val: 20 0.379285603761673
val_Epoch:[ 105 ] val_loss: 0.3901581481099129 2022-07-01 17:53:52.530950
start training 2022-07-01 17:53:52.631867
Epoch:[ 106 0 ] loss: 0.3613780438899994 2022-07-01 17:54:07.104421
Epoch:[ 106 1 ] loss: 0.3604999780654907 2022-07-01 17:54:07.522530
Epoch:[ 106 2 ] loss: 0.36159664392471313 2022-07-01 17:54:07.939944
Epoch:[ 106 3 ] loss: 0.36127257347106934 2022-07-01 17:54:08.351646
Epoch:[ 106 4 ] loss: 0.3620496392250061 2022-07-01 17:54:08.761825
Epoch:[ 106 5 ] loss: 0.36191144585609436 2022-07-01 17:54:09.180521
Epoch:[ 106 6 ] loss: 0.362411230802536 2022-07-01 17:54:09.599025
Epoch:[ 106 7 ] loss: 0.3620244264602661 2022-07-01 17:54:10.017267
Epoch:[ 106 8 ] loss: 0.3622274398803711 2022-07-01 17:54:10.427503
Epoch:[ 106 9 ] loss: 0.3614681363105774 2022-07-01 17:54:10.843480
Epoch:[ 106 10 ] loss: 0.3640454411506653 2022-07-01 17:54:11.264716
Epoch:[ 106 11 ] loss: 0.36270296573638916 2022-07-01 17:54:11.686867
Epoch:[ 106 12 ] loss: 0.3623008131980896 2022-07-01 17:54:12.106057
Epoch:[ 106 13 ] loss: 0.36283019185066223 2022-07-01 17:54:12.526076
Epoch:[ 106 14 ] loss: 0.36199504137039185 2022-07-01 17:54:12.943094
Epoch:[ 106 15 ] loss: 0.3622148633003235 2022-07-01 17:54:13.359312
Epoch:[ 106 16 ] loss: 0.3621768355369568 2022-07-01 17:54:18.755068
Epoch:[ 106 17 ] loss: 0.36125245690345764 2022-07-01 17:54:19.174137
Epoch:[ 106 18 ] loss: 0.3614490330219269 2022-07-01 17:54:19.585129
Epoch:[ 106 19 ] loss: 0.3626292645931244 2022-07-01 17:54:20.002642
Training_Epoch:[ 106 ] Training_loss: 0.36202182322740556 2022-07-01 17:54:20.003799
learning rate:  0.00010737418240000007
netparams have been saved once 106
val: 1 0.3898049294948578
val: 2 0.38983872532844543
val: 3 0.3895862102508545
val: 4 0.39681383967399597
val: 5 0.38858529925346375
val: 6 0.4075050950050354
val: 7 0.39587682485580444
val: 8 0.3892803490161896
val: 9 0.38705798983573914
val: 10 0.3906232416629791
val: 11 0.38432905077934265
val: 12 0.39151549339294434
val: 13 0.385438472032547
val: 14 0.3951656222343445
val: 15 0.3892252445220947
val: 16 0.37920746207237244
val: 17 0.3825795650482178
val: 18 0.39314764738082886
val: 19 0.3859042227268219
val: 20 0.3851642608642578
val_Epoch:[ 106 ] val_loss: 0.38983247727155684 2022-07-01 17:54:23.993988
start training 2022-07-01 17:54:24.089536
Epoch:[ 107 0 ] loss: 0.3616558015346527 2022-07-01 17:54:38.713022
Epoch:[ 107 1 ] loss: 0.36165475845336914 2022-07-01 17:54:39.150680
Epoch:[ 107 2 ] loss: 0.36080941557884216 2022-07-01 17:54:39.563655
Epoch:[ 107 3 ] loss: 0.3626459538936615 2022-07-01 17:54:39.979514
Epoch:[ 107 4 ] loss: 0.36331242322921753 2022-07-01 17:54:40.396701
Epoch:[ 107 5 ] loss: 0.36175301671028137 2022-07-01 17:54:40.813508
Epoch:[ 107 6 ] loss: 0.36172932386398315 2022-07-01 17:54:41.228821
Epoch:[ 107 7 ] loss: 0.36267831921577454 2022-07-01 17:54:41.645500
Epoch:[ 107 8 ] loss: 0.3618025779724121 2022-07-01 17:54:42.063008
Epoch:[ 107 9 ] loss: 0.36231860518455505 2022-07-01 17:54:42.477566
Epoch:[ 107 10 ] loss: 0.36239683628082275 2022-07-01 17:54:42.893345
Epoch:[ 107 11 ] loss: 0.36177048087120056 2022-07-01 17:54:43.308970
Epoch:[ 107 12 ] loss: 0.36175018548965454 2022-07-01 17:54:43.731540
Epoch:[ 107 13 ] loss: 0.3617890179157257 2022-07-01 17:54:44.147162
Epoch:[ 107 14 ] loss: 0.36113226413726807 2022-07-01 17:54:44.569067
Epoch:[ 107 15 ] loss: 0.362886905670166 2022-07-01 17:54:44.986162
Epoch:[ 107 16 ] loss: 0.36208152770996094 2022-07-01 17:54:50.110614
Epoch:[ 107 17 ] loss: 0.3607446849346161 2022-07-01 17:54:50.528045
Epoch:[ 107 18 ] loss: 0.36316582560539246 2022-07-01 17:54:50.950047
Epoch:[ 107 19 ] loss: 0.3631388545036316 2022-07-01 17:54:51.369487
Training_Epoch:[ 107 ] Training_loss: 0.3620608389377594 2022-07-01 17:54:51.370385
learning rate:  0.00010737418240000007
val: 1 0.3847886919975281
val: 2 0.3926854133605957
val: 3 0.3961467444896698
val: 4 0.383154034614563
val: 5 0.39175236225128174
val: 6 0.379696786403656
val: 7 0.39005714654922485
val: 8 0.3943029046058655
val: 9 0.3900562524795532
val: 10 0.39426904916763306
val: 11 0.39018750190734863
val: 12 0.39028337597846985
val: 13 0.39209797978401184
val: 14 0.38103097677230835
val: 15 0.39185065031051636
val: 16 0.3918822705745697
val: 17 0.3881719708442688
val: 18 0.38788482546806335
val: 19 0.3928529620170593
val: 20 0.3892847001552582
val_Epoch:[ 107 ] val_loss: 0.38962182998657224 2022-07-01 17:54:55.499592
start training 2022-07-01 17:54:55.596882
Epoch:[ 108 0 ] loss: 0.3618675470352173 2022-07-01 17:55:09.905782
Epoch:[ 108 1 ] loss: 0.36081981658935547 2022-07-01 17:55:10.328385
Epoch:[ 108 2 ] loss: 0.36115169525146484 2022-07-01 17:55:10.744302
Epoch:[ 108 3 ] loss: 0.36141785979270935 2022-07-01 17:55:11.159547
Epoch:[ 108 4 ] loss: 0.3618103861808777 2022-07-01 17:55:11.576799
Epoch:[ 108 5 ] loss: 0.36188942193984985 2022-07-01 17:55:11.992574
Epoch:[ 108 6 ] loss: 0.36195918917655945 2022-07-01 17:55:12.407958
Epoch:[ 108 7 ] loss: 0.36245399713516235 2022-07-01 17:55:12.830532
Epoch:[ 108 8 ] loss: 0.3620260953903198 2022-07-01 17:55:13.246986
Epoch:[ 108 9 ] loss: 0.3623836934566498 2022-07-01 17:55:13.664266
Epoch:[ 108 10 ] loss: 0.3618523180484772 2022-07-01 17:55:14.078519
Epoch:[ 108 11 ] loss: 0.3615703880786896 2022-07-01 17:55:14.494213
Epoch:[ 108 12 ] loss: 0.3632449805736542 2022-07-01 17:55:14.912386
Epoch:[ 108 13 ] loss: 0.3621704876422882 2022-07-01 17:55:15.332184
Epoch:[ 108 14 ] loss: 0.3626408874988556 2022-07-01 17:55:15.757084
Epoch:[ 108 15 ] loss: 0.36282315850257874 2022-07-01 17:55:16.174124
Epoch:[ 108 16 ] loss: 0.36234086751937866 2022-07-01 17:55:21.472706
Epoch:[ 108 17 ] loss: 0.3626902997493744 2022-07-01 17:55:21.890441
Epoch:[ 108 18 ] loss: 0.36069971323013306 2022-07-01 17:55:22.549598
Epoch:[ 108 19 ] loss: 0.36222922801971436 2022-07-01 17:55:22.971530
Training_Epoch:[ 108 ] Training_loss: 0.3620021015405655 2022-07-01 17:55:22.972196
learning rate:  0.00010737418240000007
netparams have been saved once 108
val: 1 0.3856784701347351
val: 2 0.3944154977798462
val: 3 0.3889172077178955
val: 4 0.38341882824897766
val: 5 0.3903889060020447
val: 6 0.3864632844924927
val: 7 0.3894362449645996
val: 8 0.388679176568985
val: 9 0.39126425981521606
val: 10 0.39480945467948914
val: 11 0.3824577331542969
val: 12 0.3939213454723358
val: 13 0.39130744338035583
val: 14 0.3891505002975464
val: 15 0.3908081352710724
val: 16 0.3892726004123688
val: 17 0.40200889110565186
val: 18 0.38887983560562134
val: 19 0.3954659402370453
val: 20 0.3817923963069916
val_Epoch:[ 108 ] val_loss: 0.3899268075823784 2022-07-01 17:55:26.969393
start training 2022-07-01 17:55:27.070140
Epoch:[ 109 0 ] loss: 0.36209917068481445 2022-07-01 17:55:41.310525
Epoch:[ 109 1 ] loss: 0.36128300428390503 2022-07-01 17:55:42.058929
Epoch:[ 109 2 ] loss: 0.36140725016593933 2022-07-01 17:55:42.474714
Epoch:[ 109 3 ] loss: 0.36007651686668396 2022-07-01 17:55:42.889363
Epoch:[ 109 4 ] loss: 0.36162835359573364 2022-07-01 17:55:43.305633
Epoch:[ 109 5 ] loss: 0.36253294348716736 2022-07-01 17:55:43.719226
Epoch:[ 109 6 ] loss: 0.36169710755348206 2022-07-01 17:55:44.134039
Epoch:[ 109 7 ] loss: 0.36233577132225037 2022-07-01 17:55:44.547816
Epoch:[ 109 8 ] loss: 0.362346351146698 2022-07-01 17:55:44.963937
Epoch:[ 109 9 ] loss: 0.36222609877586365 2022-07-01 17:55:45.379352
Epoch:[ 109 10 ] loss: 0.36192506551742554 2022-07-01 17:55:45.794565
Epoch:[ 109 11 ] loss: 0.3620017170906067 2022-07-01 17:55:46.214883
Epoch:[ 109 12 ] loss: 0.3615906834602356 2022-07-01 17:55:46.635215
Epoch:[ 109 13 ] loss: 0.36204788088798523 2022-07-01 17:55:47.056205
Epoch:[ 109 14 ] loss: 0.362396240234375 2022-07-01 17:55:47.469982
Epoch:[ 109 15 ] loss: 0.3621671199798584 2022-07-01 17:55:47.885446
Epoch:[ 109 16 ] loss: 0.3630465865135193 2022-07-01 17:55:53.286893
Epoch:[ 109 17 ] loss: 0.3616606593132019 2022-07-01 17:55:53.708221
Epoch:[ 109 18 ] loss: 0.3625570833683014 2022-07-01 17:55:54.122841
Epoch:[ 109 19 ] loss: 0.36141911149024963 2022-07-01 17:55:54.537623
Training_Epoch:[ 109 ] Training_loss: 0.36192223578691485 2022-07-01 17:55:54.538326
learning rate:  0.00010737418240000007
val: 1 0.39112961292266846
val: 2 0.38924846053123474
val: 3 0.3855053186416626
val: 4 0.38653066754341125
val: 5 0.3926449120044708
val: 6 0.3849638104438782
val: 7 0.388197124004364
val: 8 0.3935451805591583
val: 9 0.39478906989097595
val: 10 0.3850088119506836
val: 11 0.39451491832733154
val: 12 0.37952306866645813
val: 13 0.38890329003334045
val: 14 0.39368733763694763
val: 15 0.3934279978275299
val: 16 0.39359357953071594
val: 17 0.39654678106307983
val: 18 0.3930008113384247
val: 19 0.39212989807128906
val: 20 0.3880569636821747
val_Epoch:[ 109 ] val_loss: 0.39024738073348997 2022-07-01 17:55:58.380147
start training 2022-07-01 17:55:58.478156
Epoch:[ 110 0 ] loss: 0.36155039072036743 2022-07-01 17:56:12.607602
Epoch:[ 110 1 ] loss: 0.36124709248542786 2022-07-01 17:56:13.040575
Epoch:[ 110 2 ] loss: 0.3608984649181366 2022-07-01 17:56:13.456442
Epoch:[ 110 3 ] loss: 0.36172741651535034 2022-07-01 17:56:13.872583
Epoch:[ 110 4 ] loss: 0.3627742528915405 2022-07-01 17:56:14.287936
Epoch:[ 110 5 ] loss: 0.36177751421928406 2022-07-01 17:56:14.705481
Epoch:[ 110 6 ] loss: 0.3619992733001709 2022-07-01 17:56:15.119634
Epoch:[ 110 7 ] loss: 0.36252301931381226 2022-07-01 17:56:15.532841
Epoch:[ 110 8 ] loss: 0.3614882826805115 2022-07-01 17:56:15.945872
Epoch:[ 110 9 ] loss: 0.36253678798675537 2022-07-01 17:56:16.360407
Epoch:[ 110 10 ] loss: 0.36255306005477905 2022-07-01 17:56:16.781282
Epoch:[ 110 11 ] loss: 0.36136001348495483 2022-07-01 17:56:17.195611
Epoch:[ 110 12 ] loss: 0.3631937801837921 2022-07-01 17:56:17.617382
Epoch:[ 110 13 ] loss: 0.362995445728302 2022-07-01 17:56:18.035853
Epoch:[ 110 14 ] loss: 0.3613041937351227 2022-07-01 17:56:18.450300
Epoch:[ 110 15 ] loss: 0.3616781532764435 2022-07-01 17:56:18.863123
Epoch:[ 110 16 ] loss: 0.36098527908325195 2022-07-01 17:56:24.352140
Epoch:[ 110 17 ] loss: 0.3603714108467102 2022-07-01 17:56:24.769880
Epoch:[ 110 18 ] loss: 0.3626849353313446 2022-07-01 17:56:25.180453
Epoch:[ 110 19 ] loss: 0.3618400990962982 2022-07-01 17:56:25.586594
Training_Epoch:[ 110 ] Training_loss: 0.3618744432926178 2022-07-01 17:56:25.587460
learning rate:  0.00010737418240000007
netparams have been saved once 110
val: 1 0.3899211883544922
val: 2 0.38274508714675903
val: 3 0.3976292312145233
val: 4 0.3854804039001465
val: 5 0.398558646440506
val: 6 0.38993674516677856
val: 7 0.38665810227394104
val: 8 0.38525938987731934
val: 9 0.39120227098464966
val: 10 0.38378092646598816
val: 11 0.38861218094825745
val: 12 0.38913193345069885
val: 13 0.3873392343521118
val: 14 0.3929023742675781
val: 15 0.39326992630958557
val: 16 0.40117165446281433
val: 17 0.3840143382549286
val: 18 0.38573336601257324
val: 19 0.3889835774898529
val: 20 0.3857298791408539
val_Epoch:[ 110 ] val_loss: 0.3894030228257179 2022-07-01 17:56:29.576258
start training 2022-07-01 17:56:29.679130
Epoch:[ 111 0 ] loss: 0.3620658218860626 2022-07-01 17:56:44.287164
Epoch:[ 111 1 ] loss: 0.36188215017318726 2022-07-01 17:56:44.706918
Epoch:[ 111 2 ] loss: 0.36159560084342957 2022-07-01 17:56:45.120378
Epoch:[ 111 3 ] loss: 0.3619422912597656 2022-07-01 17:56:45.536177
Epoch:[ 111 4 ] loss: 0.36218157410621643 2022-07-01 17:56:45.952630
Epoch:[ 111 5 ] loss: 0.36259981989860535 2022-07-01 17:56:46.368478
Epoch:[ 111 6 ] loss: 0.3625617027282715 2022-07-01 17:56:46.781746
Epoch:[ 111 7 ] loss: 0.36132994294166565 2022-07-01 17:56:47.196379
Epoch:[ 111 8 ] loss: 0.36183661222457886 2022-07-01 17:56:47.611105
Epoch:[ 111 9 ] loss: 0.362326443195343 2022-07-01 17:56:48.024042
Epoch:[ 111 10 ] loss: 0.36158210039138794 2022-07-01 17:56:48.439517
Epoch:[ 111 11 ] loss: 0.3608347177505493 2022-07-01 17:56:48.860866
Epoch:[ 111 12 ] loss: 0.3612692356109619 2022-07-01 17:56:49.281941
Epoch:[ 111 13 ] loss: 0.36285048723220825 2022-07-01 17:56:49.697664
Epoch:[ 111 14 ] loss: 0.3615778684616089 2022-07-01 17:56:50.111496
Epoch:[ 111 15 ] loss: 0.3614225387573242 2022-07-01 17:56:50.526328
Epoch:[ 111 16 ] loss: 0.3619201183319092 2022-07-01 17:56:55.612912
Epoch:[ 111 17 ] loss: 0.3617798388004303 2022-07-01 17:56:56.027684
Epoch:[ 111 18 ] loss: 0.3612436056137085 2022-07-01 17:56:56.451828
Epoch:[ 111 19 ] loss: 0.3623322546482086 2022-07-01 17:56:56.866670
Training_Epoch:[ 111 ] Training_loss: 0.36185673624277115 2022-07-01 17:56:56.867428
learning rate:  8.589934592000007e-05
val: 1 0.38831764459609985
val: 2 0.38451147079467773
val: 3 0.39297395944595337
val: 4 0.39444437623023987
val: 5 0.39449673891067505
val: 6 0.38332894444465637
val: 7 0.3849430978298187
val: 8 0.3852582573890686
val: 9 0.38573628664016724
val: 10 0.39660516381263733
val: 11 0.3948863744735718
val: 12 0.3916758596897125
val: 13 0.39344000816345215
val: 14 0.39159056544303894
val: 15 0.3931260406970978
val: 16 0.39112165570259094
val: 17 0.3875819444656372
val: 18 0.38703829050064087
val: 19 0.3843717873096466
val: 20 0.4000679552555084
val_Epoch:[ 111 ] val_loss: 0.39027582108974457 2022-07-01 17:57:00.761515
start training 2022-07-01 17:57:00.860662
Epoch:[ 112 0 ] loss: 0.3609490692615509 2022-07-01 17:57:15.737937
Epoch:[ 112 1 ] loss: 0.36097025871276855 2022-07-01 17:57:16.152161
Epoch:[ 112 2 ] loss: 0.3629514276981354 2022-07-01 17:57:16.566372
Epoch:[ 112 3 ] loss: 0.36064761877059937 2022-07-01 17:57:16.980193
Epoch:[ 112 4 ] loss: 0.3630430996417999 2022-07-01 17:57:17.401749
Epoch:[ 112 5 ] loss: 0.36216482520103455 2022-07-01 17:57:17.824361
Epoch:[ 112 6 ] loss: 0.3614877760410309 2022-07-01 17:57:18.239916
Epoch:[ 112 7 ] loss: 0.36245474219322205 2022-07-01 17:57:18.653083
Epoch:[ 112 8 ] loss: 0.3627963066101074 2022-07-01 17:57:19.068278
Epoch:[ 112 9 ] loss: 0.36262261867523193 2022-07-01 17:57:19.483361
Epoch:[ 112 10 ] loss: 0.361560583114624 2022-07-01 17:57:19.897421
Epoch:[ 112 11 ] loss: 0.36100804805755615 2022-07-01 17:57:20.319498
Epoch:[ 112 12 ] loss: 0.36109763383865356 2022-07-01 17:57:20.734855
Epoch:[ 112 13 ] loss: 0.3604670464992523 2022-07-01 17:57:21.149438
Epoch:[ 112 14 ] loss: 0.361113578081131 2022-07-01 17:57:21.563693
Epoch:[ 112 15 ] loss: 0.3639286458492279 2022-07-01 17:57:21.977666
Epoch:[ 112 16 ] loss: 0.3624153435230255 2022-07-01 17:57:27.339888
Epoch:[ 112 17 ] loss: 0.3629913628101349 2022-07-01 17:57:27.759267
Epoch:[ 112 18 ] loss: 0.3622276186943054 2022-07-01 17:57:28.177381
Epoch:[ 112 19 ] loss: 0.36126989126205444 2022-07-01 17:57:28.593460
Training_Epoch:[ 112 ] Training_loss: 0.3619083747267723 2022-07-01 17:57:28.594146
learning rate:  8.589934592000007e-05
netparams have been saved once 112
val: 1 0.38492196798324585
val: 2 0.3839878737926483
val: 3 0.38634181022644043
val: 4 0.3882598578929901
val: 5 0.3916019797325134
val: 6 0.38826653361320496
val: 7 0.3839108347892761
val: 8 0.3937194049358368
val: 9 0.39301225543022156
val: 10 0.3889654278755188
val: 11 0.38008832931518555
val: 12 0.3963572382926941
val: 13 0.39858853816986084
val: 14 0.39125490188598633
val: 15 0.38974902033805847
val: 16 0.3895795941352844
val: 17 0.39245426654815674
val: 18 0.39568963646888733
val: 19 0.3901103436946869
val: 20 0.38823622465133667
val_Epoch:[ 112 ] val_loss: 0.3897548019886017 2022-07-01 17:57:32.546654
start training 2022-07-01 17:57:32.645370
Epoch:[ 113 0 ] loss: 0.3625721037387848 2022-07-01 17:57:47.154053
Epoch:[ 113 1 ] loss: 0.36236435174942017 2022-07-01 17:57:47.591643
Epoch:[ 113 2 ] loss: 0.3625079095363617 2022-07-01 17:57:48.012567
Epoch:[ 113 3 ] loss: 0.3619655966758728 2022-07-01 17:57:48.428687
Epoch:[ 113 4 ] loss: 0.360927015542984 2022-07-01 17:57:48.848439
Epoch:[ 113 5 ] loss: 0.36289963126182556 2022-07-01 17:57:49.263345
Epoch:[ 113 6 ] loss: 0.36231353878974915 2022-07-01 17:57:49.678205
Epoch:[ 113 7 ] loss: 0.36150941252708435 2022-07-01 17:57:50.094625
Epoch:[ 113 8 ] loss: 0.3609471619129181 2022-07-01 17:57:50.509250
Epoch:[ 113 9 ] loss: 0.36247527599334717 2022-07-01 17:57:50.915980
Epoch:[ 113 10 ] loss: 0.3610682487487793 2022-07-01 17:57:51.330573
Epoch:[ 113 11 ] loss: 0.3620772659778595 2022-07-01 17:57:51.743964
Epoch:[ 113 12 ] loss: 0.36216485500335693 2022-07-01 17:57:52.160553
Epoch:[ 113 13 ] loss: 0.3608633577823639 2022-07-01 17:57:52.576405
Epoch:[ 113 14 ] loss: 0.3629957437515259 2022-07-01 17:57:52.991621
Epoch:[ 113 15 ] loss: 0.36227503418922424 2022-07-01 17:57:53.412075
Epoch:[ 113 16 ] loss: 0.36191973090171814 2022-07-01 17:57:58.872932
Epoch:[ 113 17 ] loss: 0.36082690954208374 2022-07-01 17:57:59.286778
Epoch:[ 113 18 ] loss: 0.36165204644203186 2022-07-01 17:57:59.707881
Epoch:[ 113 19 ] loss: 0.36156895756721497 2022-07-01 17:58:00.129772
Training_Epoch:[ 113 ] Training_loss: 0.3618947073817253 2022-07-01 17:58:00.130826
learning rate:  8.589934592000007e-05
val: 1 0.38874951004981995
val: 2 0.38677045702934265
val: 3 0.38631439208984375
val: 4 0.3856841027736664
val: 5 0.3885577321052551
val: 6 0.38825029134750366
val: 7 0.3964899480342865
val: 8 0.3890994191169739
val: 9 0.3887290358543396
val: 10 0.395643025636673
val: 11 0.3928573429584503
val: 12 0.3912893831729889
val: 13 0.3966101109981537
val: 14 0.39103344082832336
val: 15 0.38705095648765564
val: 16 0.3896879255771637
val: 17 0.3894275724887848
val: 18 0.38259246945381165
val: 19 0.38725826144218445
val: 20 0.38796550035476685
val_Epoch:[ 113 ] val_loss: 0.3895030438899994 2022-07-01 17:58:04.063437
start training 2022-07-01 17:58:04.159595
Epoch:[ 114 0 ] loss: 0.3613874316215515 2022-07-01 17:58:18.954092
Epoch:[ 114 1 ] loss: 0.36155062913894653 2022-07-01 17:58:19.369172
Epoch:[ 114 2 ] loss: 0.36031293869018555 2022-07-01 17:58:19.783077
Epoch:[ 114 3 ] loss: 0.36218470335006714 2022-07-01 17:58:20.200973
Epoch:[ 114 4 ] loss: 0.3627840578556061 2022-07-01 17:58:20.621070
Epoch:[ 114 5 ] loss: 0.3602486848831177 2022-07-01 17:58:21.034069
Epoch:[ 114 6 ] loss: 0.36124780774116516 2022-07-01 17:58:21.449858
Epoch:[ 114 7 ] loss: 0.3623698353767395 2022-07-01 17:58:21.866213
Epoch:[ 114 8 ] loss: 0.36258792877197266 2022-07-01 17:58:22.289482
Epoch:[ 114 9 ] loss: 0.36269688606262207 2022-07-01 17:58:22.713036
Epoch:[ 114 10 ] loss: 0.3617706000804901 2022-07-01 17:58:23.126029
Epoch:[ 114 11 ] loss: 0.36184871196746826 2022-07-01 17:58:23.539761
Epoch:[ 114 12 ] loss: 0.36119943857192993 2022-07-01 17:58:23.954120
Epoch:[ 114 13 ] loss: 0.3609308898448944 2022-07-01 17:58:24.369445
Epoch:[ 114 14 ] loss: 0.3616016209125519 2022-07-01 17:58:24.784760
Epoch:[ 114 15 ] loss: 0.36191537976264954 2022-07-01 17:58:25.199487
Epoch:[ 114 16 ] loss: 0.36182570457458496 2022-07-01 17:58:30.246244
Epoch:[ 114 17 ] loss: 0.36267855763435364 2022-07-01 17:58:30.665806
Epoch:[ 114 18 ] loss: 0.36217063665390015 2022-07-01 17:58:31.080794
Epoch:[ 114 19 ] loss: 0.36203551292419434 2022-07-01 17:58:31.497688
Training_Epoch:[ 114 ] Training_loss: 0.3617673978209496 2022-07-01 17:58:31.498521
learning rate:  8.589934592000007e-05
netparams have been saved once 114
val: 1 0.39180323481559753
val: 2 0.38858795166015625
val: 3 0.3860265016555786
val: 4 0.39092302322387695
val: 5 0.3829575479030609
val: 6 0.38846027851104736
val: 7 0.39055460691452026
val: 8 0.39666032791137695
val: 9 0.3881983160972595
val: 10 0.39515385031700134
val: 11 0.3881460428237915
val: 12 0.3914181590080261
val: 13 0.3980454206466675
val: 14 0.39086630940437317
val: 15 0.38466504216194153
val: 16 0.38005101680755615
val: 17 0.3884977698326111
val: 18 0.3882918059825897
val: 19 0.39121273159980774
val: 20 0.3903774619102478
val_Epoch:[ 114 ] val_loss: 0.3895448699593544 2022-07-01 17:58:35.471896
start training 2022-07-01 17:58:35.573394
Epoch:[ 115 0 ] loss: 0.3615535795688629 2022-07-01 17:58:49.949179
Epoch:[ 115 1 ] loss: 0.3629322946071625 2022-07-01 17:58:50.371399
Epoch:[ 115 2 ] loss: 0.36094313859939575 2022-07-01 17:58:50.784803
Epoch:[ 115 3 ] loss: 0.36277320981025696 2022-07-01 17:58:51.193775
Epoch:[ 115 4 ] loss: 0.36295264959335327 2022-07-01 17:58:51.608857
Epoch:[ 115 5 ] loss: 0.36132165789604187 2022-07-01 17:58:52.024673
Epoch:[ 115 6 ] loss: 0.36229032278060913 2022-07-01 17:58:52.445599
Epoch:[ 115 7 ] loss: 0.3619186580181122 2022-07-01 17:58:52.862119
Epoch:[ 115 8 ] loss: 0.361935555934906 2022-07-01 17:58:53.280662
Epoch:[ 115 9 ] loss: 0.36253055930137634 2022-07-01 17:58:53.689654
Epoch:[ 115 10 ] loss: 0.36107778549194336 2022-07-01 17:58:54.108790
Epoch:[ 115 11 ] loss: 0.36265233159065247 2022-07-01 17:58:54.525144
Epoch:[ 115 12 ] loss: 0.36178916692733765 2022-07-01 17:58:54.939683
Epoch:[ 115 13 ] loss: 0.36124834418296814 2022-07-01 17:58:55.355330
Epoch:[ 115 14 ] loss: 0.3618026673793793 2022-07-01 17:58:55.772266
Epoch:[ 115 15 ] loss: 0.3620436489582062 2022-07-01 17:58:56.189264
Epoch:[ 115 16 ] loss: 0.36221569776535034 2022-07-01 17:59:01.642044
Epoch:[ 115 17 ] loss: 0.36050933599472046 2022-07-01 17:59:02.049963
Epoch:[ 115 18 ] loss: 0.3609010577201843 2022-07-01 17:59:02.465845
Epoch:[ 115 19 ] loss: 0.3622576892375946 2022-07-01 17:59:02.880435
Training_Epoch:[ 115 ] Training_loss: 0.3618824675679207 2022-07-01 17:59:02.881354
learning rate:  8.589934592000007e-05
val: 1 0.3804970681667328
val: 2 0.38798511028289795
val: 3 0.38501566648483276
val: 4 0.40321820974349976
val: 5 0.38796401023864746
val: 6 0.38346368074417114
val: 7 0.39493805170059204
val: 8 0.3810523748397827
val: 9 0.38039612770080566
val: 10 0.3932330310344696
val: 11 0.38778194785118103
val: 12 0.3968586325645447
val: 13 0.3935546875
val: 14 0.39485833048820496
val: 15 0.3895534574985504
val: 16 0.38852620124816895
val: 17 0.3972569406032562
val: 18 0.394795298576355
val: 19 0.38327762484550476
val: 20 0.3922891914844513
val_Epoch:[ 115 ] val_loss: 0.38982578217983244 2022-07-01 17:59:06.873392
start training 2022-07-01 17:59:06.975346
Epoch:[ 116 0 ] loss: 0.3612917363643646 2022-07-01 17:59:21.773448
Epoch:[ 116 1 ] loss: 0.36204010248184204 2022-07-01 17:59:22.189398
Epoch:[ 116 2 ] loss: 0.362546443939209 2022-07-01 17:59:22.604756
Epoch:[ 116 3 ] loss: 0.36256638169288635 2022-07-01 17:59:23.019116
Epoch:[ 116 4 ] loss: 0.36144423484802246 2022-07-01 17:59:23.433599
Epoch:[ 116 5 ] loss: 0.36055463552474976 2022-07-01 17:59:23.848554
Epoch:[ 116 6 ] loss: 0.36067861318588257 2022-07-01 17:59:24.262394
Epoch:[ 116 7 ] loss: 0.36068207025527954 2022-07-01 17:59:24.675659
Epoch:[ 116 8 ] loss: 0.3606402277946472 2022-07-01 17:59:25.092397
Epoch:[ 116 9 ] loss: 0.3620823919773102 2022-07-01 17:59:25.505944
Epoch:[ 116 10 ] loss: 0.36116233468055725 2022-07-01 17:59:25.927150
Epoch:[ 116 11 ] loss: 0.3607823848724365 2022-07-01 17:59:26.341178
Epoch:[ 116 12 ] loss: 0.3618814945220947 2022-07-01 17:59:26.757547
Epoch:[ 116 13 ] loss: 0.36247116327285767 2022-07-01 17:59:27.170802
Epoch:[ 116 14 ] loss: 0.3614533543586731 2022-07-01 17:59:27.591529
Epoch:[ 116 15 ] loss: 0.36226266622543335 2022-07-01 17:59:28.013724
Epoch:[ 116 16 ] loss: 0.3618449568748474 2022-07-01 17:59:33.518484
Epoch:[ 116 17 ] loss: 0.3631274998188019 2022-07-01 17:59:33.931765
Epoch:[ 116 18 ] loss: 0.3631567656993866 2022-07-01 17:59:34.345214
Epoch:[ 116 19 ] loss: 0.362192839384079 2022-07-01 17:59:34.768871
Training_Epoch:[ 116 ] Training_loss: 0.36174311488866806 2022-07-01 17:59:34.769608
learning rate:  8.589934592000007e-05
netparams have been saved once 116
val: 1 0.3891260623931885
val: 2 0.386574387550354
val: 3 0.38739514350891113
val: 4 0.4039417803287506
val: 5 0.3894007205963135
val: 6 0.3936985433101654
val: 7 0.38046178221702576
val: 8 0.3868148624897003
val: 9 0.3838491439819336
val: 10 0.3888588547706604
val: 11 0.391386479139328
val: 12 0.3842402994632721
val: 13 0.3940654993057251
val: 14 0.38458624482154846
val: 15 0.38673654198646545
val: 16 0.39290404319763184
val: 17 0.3938293159008026
val: 18 0.3811575472354889
val: 19 0.3900783956050873
val: 20 0.3939895033836365
val_Epoch:[ 116 ] val_loss: 0.38915475755929946 2022-07-01 17:59:38.725134
start training 2022-07-01 17:59:38.823718
Epoch:[ 117 0 ] loss: 0.3618867099285126 2022-07-01 17:59:53.048279
Epoch:[ 117 1 ] loss: 0.3611193001270294 2022-07-01 17:59:53.476493
Epoch:[ 117 2 ] loss: 0.36124029755592346 2022-07-01 17:59:53.893014
Epoch:[ 117 3 ] loss: 0.3612823486328125 2022-07-01 17:59:54.309272
Epoch:[ 117 4 ] loss: 0.36214858293533325 2022-07-01 17:59:54.724339
Epoch:[ 117 5 ] loss: 0.362613320350647 2022-07-01 17:59:55.140743
Epoch:[ 117 6 ] loss: 0.36244118213653564 2022-07-01 17:59:55.558751
Epoch:[ 117 7 ] loss: 0.3620941936969757 2022-07-01 17:59:55.971921
Epoch:[ 117 8 ] loss: 0.36154723167419434 2022-07-01 17:59:56.394434
Epoch:[ 117 9 ] loss: 0.3612675070762634 2022-07-01 17:59:56.809689
Epoch:[ 117 10 ] loss: 0.36077049374580383 2022-07-01 17:59:57.225953
Epoch:[ 117 11 ] loss: 0.36271485686302185 2022-07-01 17:59:57.644159
Epoch:[ 117 12 ] loss: 0.36125144362449646 2022-07-01 17:59:58.058440
Epoch:[ 117 13 ] loss: 0.3630055785179138 2022-07-01 17:59:58.466427
Epoch:[ 117 14 ] loss: 0.3606785535812378 2022-07-01 17:59:58.881572
Epoch:[ 117 15 ] loss: 0.36053964495658875 2022-07-01 17:59:59.295586
Epoch:[ 117 16 ] loss: 0.3625158667564392 2022-07-01 18:00:04.862161
Epoch:[ 117 17 ] loss: 0.3620702922344208 2022-07-01 18:00:05.272136
Epoch:[ 117 18 ] loss: 0.3611425459384918 2022-07-01 18:00:05.853510
Epoch:[ 117 19 ] loss: 0.36076369881629944 2022-07-01 18:00:06.267398
Training_Epoch:[ 117 ] Training_loss: 0.36165468245744703 2022-07-01 18:00:06.268250
learning rate:  8.589934592000007e-05
val: 1 0.3878783583641052
val: 2 0.39255818724632263
val: 3 0.3934590518474579
val: 4 0.3863590359687805
val: 5 0.38840943574905396
val: 6 0.38820013403892517
val: 7 0.3934279680252075
val: 8 0.3958379924297333
val: 9 0.3911142945289612
val: 10 0.38611382246017456
val: 11 0.3903430998325348
val: 12 0.39845919609069824
val: 13 0.38339707255363464
val: 14 0.3882334232330322
val: 15 0.390625923871994
val: 16 0.3971070647239685
val: 17 0.3874734044075012
val: 18 0.3930210471153259
val: 19 0.39282241463661194
val: 20 0.39172062277793884
val_Epoch:[ 117 ] val_loss: 0.3908280774950981 2022-07-01 18:00:10.184458
start training 2022-07-01 18:00:10.284118
Epoch:[ 118 0 ] loss: 0.36209970712661743 2022-07-01 18:00:25.027333
Epoch:[ 118 1 ] loss: 0.3609935939311981 2022-07-01 18:00:25.440003
Epoch:[ 118 2 ] loss: 0.3618735671043396 2022-07-01 18:00:25.852149
Epoch:[ 118 3 ] loss: 0.35986849665641785 2022-07-01 18:00:26.267268
Epoch:[ 118 4 ] loss: 0.3605439364910126 2022-07-01 18:00:26.682732
Epoch:[ 118 5 ] loss: 0.36254119873046875 2022-07-01 18:00:27.097716
Epoch:[ 118 6 ] loss: 0.36308565735816956 2022-07-01 18:00:27.511701
Epoch:[ 118 7 ] loss: 0.36117008328437805 2022-07-01 18:00:27.926442
Epoch:[ 118 8 ] loss: 0.36263981461524963 2022-07-01 18:00:28.345858
Epoch:[ 118 9 ] loss: 0.36144885420799255 2022-07-01 18:00:28.758751
Epoch:[ 118 10 ] loss: 0.36060649156570435 2022-07-01 18:00:29.176806
Epoch:[ 118 11 ] loss: 0.3620661497116089 2022-07-01 18:00:29.593098
Epoch:[ 118 12 ] loss: 0.3612493574619293 2022-07-01 18:00:30.014744
Epoch:[ 118 13 ] loss: 0.3616078495979309 2022-07-01 18:00:30.428968
Epoch:[ 118 14 ] loss: 0.3633446991443634 2022-07-01 18:00:30.849629
Epoch:[ 118 15 ] loss: 0.3616875112056732 2022-07-01 18:00:31.265436
Epoch:[ 118 16 ] loss: 0.3623741865158081 2022-07-01 18:00:36.657992
Epoch:[ 118 17 ] loss: 0.36153069138526917 2022-07-01 18:00:37.082066
Epoch:[ 118 18 ] loss: 0.36133626103401184 2022-07-01 18:00:37.498973
Epoch:[ 118 19 ] loss: 0.3612033426761627 2022-07-01 18:00:37.921728
Training_Epoch:[ 118 ] Training_loss: 0.3616635724902153 2022-07-01 18:00:37.922422
learning rate:  8.589934592000007e-05
netparams have been saved once 118
val: 1 0.38718727231025696
val: 2 0.3941974639892578
val: 3 0.3828461170196533
val: 4 0.39292439818382263
val: 5 0.3921678960323334
val: 6 0.38452911376953125
val: 7 0.3946470022201538
val: 8 0.39175036549568176
val: 9 0.38188642263412476
val: 10 0.40382665395736694
val: 11 0.3853052854537964
val: 12 0.38535118103027344
val: 13 0.3890906870365143
val: 14 0.3945273756980896
val: 15 0.38634470105171204
val: 16 0.39189478754997253
val: 17 0.3874182403087616
val: 18 0.39247414469718933
val: 19 0.3904438316822052
val: 20 0.38724884390830994
val_Epoch:[ 118 ] val_loss: 0.38980308920145035 2022-07-01 18:00:41.940454
start training 2022-07-01 18:00:42.038378
Epoch:[ 119 0 ] loss: 0.36119574308395386 2022-07-01 18:00:56.823342
Epoch:[ 119 1 ] loss: 0.36200976371765137 2022-07-01 18:00:57.236924
Epoch:[ 119 2 ] loss: 0.3626631796360016 2022-07-01 18:00:57.652325
Epoch:[ 119 3 ] loss: 0.3628520667552948 2022-07-01 18:00:58.060797
Epoch:[ 119 4 ] loss: 0.361675500869751 2022-07-01 18:00:58.477933
Epoch:[ 119 5 ] loss: 0.3623489439487457 2022-07-01 18:00:58.895245
Epoch:[ 119 6 ] loss: 0.3619365394115448 2022-07-01 18:00:59.311262
Epoch:[ 119 7 ] loss: 0.3607265055179596 2022-07-01 18:00:59.725159
Epoch:[ 119 8 ] loss: 0.36014631390571594 2022-07-01 18:01:00.141895
Epoch:[ 119 9 ] loss: 0.36173075437545776 2022-07-01 18:01:00.557746
Epoch:[ 119 10 ] loss: 0.3622058629989624 2022-07-01 18:01:00.975277
Epoch:[ 119 11 ] loss: 0.3610990643501282 2022-07-01 18:01:01.391327
Epoch:[ 119 12 ] loss: 0.3611398935317993 2022-07-01 18:01:01.802102
Epoch:[ 119 13 ] loss: 0.3611905872821808 2022-07-01 18:01:02.218261
Epoch:[ 119 14 ] loss: 0.3607271611690521 2022-07-01 18:01:02.632383
Epoch:[ 119 15 ] loss: 0.3621332347393036 2022-07-01 18:01:03.040384
Epoch:[ 119 16 ] loss: 0.36343687772750854 2022-07-01 18:01:08.195574
Epoch:[ 119 17 ] loss: 0.3609730005264282 2022-07-01 18:01:08.604507
Epoch:[ 119 18 ] loss: 0.36227554082870483 2022-07-01 18:01:09.022146
Epoch:[ 119 19 ] loss: 0.36111965775489807 2022-07-01 18:01:09.437303
Training_Epoch:[ 119 ] Training_loss: 0.36167930960655215 2022-07-01 18:01:09.438049
learning rate:  8.589934592000007e-05
val: 1 0.3823891282081604
val: 2 0.38614171743392944
val: 3 0.40096214413642883
val: 4 0.38921797275543213
val: 5 0.3884655237197876
val: 6 0.38695093989372253
val: 7 0.3834172487258911
val: 8 0.3901560306549072
val: 9 0.38643649220466614
val: 10 0.38902679085731506
val: 11 0.38968366384506226
val: 12 0.3834507465362549
val: 13 0.38716113567352295
val: 14 0.3943036198616028
val: 15 0.39159467816352844
val: 16 0.39140769839286804
val: 17 0.39496222138404846
val: 18 0.39212948083877563
val: 19 0.39625832438468933
val: 20 0.3924137353897095
val_Epoch:[ 119 ] val_loss: 0.3898264646530151 2022-07-01 18:01:13.264857
start training 2022-07-01 18:01:13.366758
Epoch:[ 120 0 ] loss: 0.3613819181919098 2022-07-01 18:01:27.796290
Epoch:[ 120 1 ] loss: 0.3610951602458954 2022-07-01 18:01:28.237425
Epoch:[ 120 2 ] loss: 0.3630489706993103 2022-07-01 18:01:28.652191
Epoch:[ 120 3 ] loss: 0.36144495010375977 2022-07-01 18:01:29.067169
Epoch:[ 120 4 ] loss: 0.3610552251338959 2022-07-01 18:01:29.482252
Epoch:[ 120 5 ] loss: 0.3617080748081207 2022-07-01 18:01:29.897958
Epoch:[ 120 6 ] loss: 0.35984593629837036 2022-07-01 18:01:30.315119
Epoch:[ 120 7 ] loss: 0.36270079016685486 2022-07-01 18:01:30.735580
Epoch:[ 120 8 ] loss: 0.36243823170661926 2022-07-01 18:01:31.150085
Epoch:[ 120 9 ] loss: 0.3616182208061218 2022-07-01 18:01:31.564025
Epoch:[ 120 10 ] loss: 0.36120179295539856 2022-07-01 18:01:31.978281
Epoch:[ 120 11 ] loss: 0.3608453571796417 2022-07-01 18:01:32.392080
Epoch:[ 120 12 ] loss: 0.361656129360199 2022-07-01 18:01:32.814366
Epoch:[ 120 13 ] loss: 0.36135196685791016 2022-07-01 18:01:33.230516
Epoch:[ 120 14 ] loss: 0.36034640669822693 2022-07-01 18:01:33.645153
Epoch:[ 120 15 ] loss: 0.3627517521381378 2022-07-01 18:01:34.063862
Epoch:[ 120 16 ] loss: 0.36145907640457153 2022-07-01 18:01:39.370192
Epoch:[ 120 17 ] loss: 0.36262786388397217 2022-07-01 18:01:39.783761
Epoch:[ 120 18 ] loss: 0.36190733313560486 2022-07-01 18:01:40.204390
Epoch:[ 120 19 ] loss: 0.3604946434497833 2022-07-01 18:01:40.620181
Training_Epoch:[ 120 ] Training_loss: 0.3615489900112152 2022-07-01 18:01:40.620874
learning rate:  8.589934592000007e-05
netparams have been saved once 120
val: 1 0.3907988965511322
val: 2 0.389686644077301
val: 3 0.38443219661712646
val: 4 0.39705097675323486
val: 5 0.38852459192276
val: 6 0.38490232825279236
val: 7 0.39015114307403564
val: 8 0.3793937563896179
val: 9 0.3892253041267395
val: 10 0.3935198187828064
val: 11 0.38373756408691406
val: 12 0.39358630776405334
val: 13 0.39548763632774353
val: 14 0.3888533115386963
val: 15 0.3871990144252777
val: 16 0.3878842890262604
val: 17 0.39008596539497375
val: 18 0.39073318243026733
val: 19 0.40231260657310486
val: 20 0.38747841119766235
val_Epoch:[ 120 ] val_loss: 0.389752197265625 2022-07-01 18:01:44.605460
start training 2022-07-01 18:01:44.706677
Epoch:[ 121 0 ] loss: 0.3603823184967041 2022-07-01 18:01:59.149969
Epoch:[ 121 1 ] loss: 0.36091843247413635 2022-07-01 18:01:59.572093
Epoch:[ 121 2 ] loss: 0.36197173595428467 2022-07-01 18:01:59.985909
Epoch:[ 121 3 ] loss: 0.36088454723358154 2022-07-01 18:02:00.406301
Epoch:[ 121 4 ] loss: 0.36153823137283325 2022-07-01 18:02:00.823667
Epoch:[ 121 5 ] loss: 0.36052969098091125 2022-07-01 18:02:01.237142
Epoch:[ 121 6 ] loss: 0.362010657787323 2022-07-01 18:02:01.652557
Epoch:[ 121 7 ] loss: 0.36204099655151367 2022-07-01 18:02:02.075462
Epoch:[ 121 8 ] loss: 0.36185577511787415 2022-07-01 18:02:02.491096
Epoch:[ 121 9 ] loss: 0.3631349503993988 2022-07-01 18:02:02.904381
Epoch:[ 121 10 ] loss: 0.3608742356300354 2022-07-01 18:02:03.325884
Epoch:[ 121 11 ] loss: 0.3612357974052429 2022-07-01 18:02:03.739113
Epoch:[ 121 12 ] loss: 0.3611849844455719 2022-07-01 18:02:04.153403
Epoch:[ 121 13 ] loss: 0.3613733649253845 2022-07-01 18:02:04.569157
Epoch:[ 121 14 ] loss: 0.36101406812667847 2022-07-01 18:02:04.987467
Epoch:[ 121 15 ] loss: 0.36168572306632996 2022-07-01 18:02:05.402365
Epoch:[ 121 16 ] loss: 0.36142289638519287 2022-07-01 18:02:10.967181
Epoch:[ 121 17 ] loss: 0.36134201288223267 2022-07-01 18:02:11.381106
Epoch:[ 121 18 ] loss: 0.36211270093917847 2022-07-01 18:02:11.802991
Epoch:[ 121 19 ] loss: 0.36086922883987427 2022-07-01 18:02:12.216120
Training_Epoch:[ 121 ] Training_loss: 0.3614191174507141 2022-07-01 18:02:12.216861
learning rate:  6.871947673600006e-05
val: 1 0.3890852928161621
val: 2 0.40477195382118225
val: 3 0.38920241594314575
val: 4 0.39535969495773315
val: 5 0.3883296549320221
val: 6 0.38772764801979065
val: 7 0.39392444491386414
val: 8 0.38747233152389526
val: 9 0.39489927887916565
val: 10 0.39411041140556335
val: 11 0.39440032839775085
val: 12 0.3936010003089905
val: 13 0.3898029327392578
val: 14 0.38714927434921265
val: 15 0.3842400908470154
val: 16 0.3849038779735565
val: 17 0.39507046341896057
val: 18 0.38498038053512573
val: 19 0.4026768207550049
val: 20 0.38529324531555176
val_Epoch:[ 121 ] val_loss: 0.3913500770926476 2022-07-01 18:02:16.063113
start training 2022-07-01 18:02:16.164367
Epoch:[ 122 0 ] loss: 0.3610045909881592 2022-07-01 18:02:30.812255
Epoch:[ 122 1 ] loss: 0.36088573932647705 2022-07-01 18:02:31.235188
Epoch:[ 122 2 ] loss: 0.3621411621570587 2022-07-01 18:02:31.650635
Epoch:[ 122 3 ] loss: 0.3603917360305786 2022-07-01 18:02:32.072543
Epoch:[ 122 4 ] loss: 0.3600996136665344 2022-07-01 18:02:32.487344
Epoch:[ 122 5 ] loss: 0.3617299497127533 2022-07-01 18:02:32.907888
Epoch:[ 122 6 ] loss: 0.36137858033180237 2022-07-01 18:02:33.324400
Epoch:[ 122 7 ] loss: 0.3611598312854767 2022-07-01 18:02:33.740829
Epoch:[ 122 8 ] loss: 0.3602219521999359 2022-07-01 18:02:34.157037
Epoch:[ 122 9 ] loss: 0.36232438683509827 2022-07-01 18:02:34.571697
Epoch:[ 122 10 ] loss: 0.3622710704803467 2022-07-01 18:02:34.986054
Epoch:[ 122 11 ] loss: 0.36109834909439087 2022-07-01 18:02:35.399661
Epoch:[ 122 12 ] loss: 0.3630063533782959 2022-07-01 18:02:35.814231
Epoch:[ 122 13 ] loss: 0.36113569140434265 2022-07-01 18:02:36.228828
Epoch:[ 122 14 ] loss: 0.36268648505210876 2022-07-01 18:02:36.644698
Epoch:[ 122 15 ] loss: 0.36243370175361633 2022-07-01 18:02:37.060638
Epoch:[ 122 16 ] loss: 0.3612102270126343 2022-07-01 18:02:42.619223
Epoch:[ 122 17 ] loss: 0.36055442690849304 2022-07-01 18:02:43.032043
Epoch:[ 122 18 ] loss: 0.3602359890937805 2022-07-01 18:02:43.452866
Epoch:[ 122 19 ] loss: 0.3621738851070404 2022-07-01 18:02:43.866655
Training_Epoch:[ 122 ] Training_loss: 0.3614071860909462 2022-07-01 18:02:43.867356
learning rate:  6.871947673600006e-05
netparams have been saved once 122
val: 1 0.38598185777664185
val: 2 0.3853560984134674
val: 3 0.3944188952445984
val: 4 0.3927443325519562
val: 5 0.37985461950302124
val: 6 0.3988227844238281
val: 7 0.38494759798049927
val: 8 0.3908361792564392
val: 9 0.39570173621177673
val: 10 0.3894403576850891
val: 11 0.39271578192710876
val: 12 0.399620920419693
val: 13 0.3962426483631134
val: 14 0.38883405923843384
val: 15 0.38387227058410645
val: 16 0.3788665533065796
val: 17 0.40007761120796204
val: 18 0.39161238074302673
val: 19 0.3829793334007263
val: 20 0.38943588733673096
val_Epoch:[ 122 ] val_loss: 0.3901180952787399 2022-07-01 18:02:47.788259
start training 2022-07-01 18:02:47.889127
Epoch:[ 123 0 ] loss: 0.3612090051174164 2022-07-01 18:03:02.328516
Epoch:[ 123 1 ] loss: 0.36162447929382324 2022-07-01 18:03:02.744801
Epoch:[ 123 2 ] loss: 0.36210888624191284 2022-07-01 18:03:03.166654
Epoch:[ 123 3 ] loss: 0.3616675138473511 2022-07-01 18:03:03.580871
Epoch:[ 123 4 ] loss: 0.3608424663543701 2022-07-01 18:03:03.997708
Epoch:[ 123 5 ] loss: 0.3608459234237671 2022-07-01 18:03:04.411833
Epoch:[ 123 6 ] loss: 0.36062881350517273 2022-07-01 18:03:04.825690
Epoch:[ 123 7 ] loss: 0.36025601625442505 2022-07-01 18:03:05.250596
Epoch:[ 123 8 ] loss: 0.360087126493454 2022-07-01 18:03:05.667380
Epoch:[ 123 9 ] loss: 0.36138880252838135 2022-07-01 18:03:06.083660
Epoch:[ 123 10 ] loss: 0.3618387281894684 2022-07-01 18:03:06.498245
Epoch:[ 123 11 ] loss: 0.3618614077568054 2022-07-01 18:03:06.912535
Epoch:[ 123 12 ] loss: 0.3610752522945404 2022-07-01 18:03:07.327153
Epoch:[ 123 13 ] loss: 0.3619900941848755 2022-07-01 18:03:07.746409
Epoch:[ 123 14 ] loss: 0.3616017699241638 2022-07-01 18:03:08.160488
Epoch:[ 123 15 ] loss: 0.3612534999847412 2022-07-01 18:03:08.576157
Epoch:[ 123 16 ] loss: 0.3609614968299866 2022-07-01 18:03:13.926693
Epoch:[ 123 17 ] loss: 0.36243802309036255 2022-07-01 18:03:14.347597
Epoch:[ 123 18 ] loss: 0.36178916692733765 2022-07-01 18:03:14.764481
Epoch:[ 123 19 ] loss: 0.36209040880203247 2022-07-01 18:03:15.187079
Training_Epoch:[ 123 ] Training_loss: 0.3613779440522194 2022-07-01 18:03:15.187740
learning rate:  6.871947673600006e-05
val: 1 0.3916984498500824
val: 2 0.38978323340415955
val: 3 0.3867337703704834
val: 4 0.39172202348709106
val: 5 0.3890456557273865
val: 6 0.3878187835216522
val: 7 0.39457306265830994
val: 8 0.39091747999191284
val: 9 0.3904297947883606
val: 10 0.3832121789455414
val: 11 0.399106502532959
val: 12 0.39378756284713745
val: 13 0.3921346366405487
val: 14 0.3918472230434418
val: 15 0.384408175945282
val: 16 0.3937612771987915
val: 17 0.39178821444511414
val: 18 0.3921140730381012
val: 19 0.3903810679912567
val: 20 0.3843413293361664
val_Epoch:[ 123 ] val_loss: 0.39048022478818895 2022-07-01 18:03:19.077800
start training 2022-07-01 18:03:19.178336
Epoch:[ 124 0 ] loss: 0.3619236350059509 2022-07-01 18:03:33.811418
Epoch:[ 124 1 ] loss: 0.3601774573326111 2022-07-01 18:03:34.231129
Epoch:[ 124 2 ] loss: 0.3612269163131714 2022-07-01 18:03:34.653143
Epoch:[ 124 3 ] loss: 0.36116883158683777 2022-07-01 18:03:35.068797
Epoch:[ 124 4 ] loss: 0.36157914996147156 2022-07-01 18:03:35.485117
Epoch:[ 124 5 ] loss: 0.3614375591278076 2022-07-01 18:03:35.900715
Epoch:[ 124 6 ] loss: 0.3605121374130249 2022-07-01 18:03:36.314824
Epoch:[ 124 7 ] loss: 0.36176246404647827 2022-07-01 18:03:36.728552
Epoch:[ 124 8 ] loss: 0.3604274094104767 2022-07-01 18:03:37.142077
Epoch:[ 124 9 ] loss: 0.3625623285770416 2022-07-01 18:03:37.556569
Epoch:[ 124 10 ] loss: 0.36144402623176575 2022-07-01 18:03:37.971994
Epoch:[ 124 11 ] loss: 0.36035770177841187 2022-07-01 18:03:38.388949
Epoch:[ 124 12 ] loss: 0.36199742555618286 2022-07-01 18:03:38.803259
Epoch:[ 124 13 ] loss: 0.3607165515422821 2022-07-01 18:03:39.216452
Epoch:[ 124 14 ] loss: 0.3616762161254883 2022-07-01 18:03:39.630275
Epoch:[ 124 15 ] loss: 0.36128902435302734 2022-07-01 18:03:40.052964
Epoch:[ 124 16 ] loss: 0.3598088324069977 2022-07-01 18:03:45.590131
Epoch:[ 124 17 ] loss: 0.3622383773326874 2022-07-01 18:03:46.005566
Epoch:[ 124 18 ] loss: 0.36250925064086914 2022-07-01 18:03:46.420320
Epoch:[ 124 19 ] loss: 0.362133264541626 2022-07-01 18:03:46.842049
Training_Epoch:[ 124 ] Training_loss: 0.3613474279642105 2022-07-01 18:03:46.842764
learning rate:  6.871947673600006e-05
netparams have been saved once 124
val: 1 0.3913446068763733
val: 2 0.3879760205745697
val: 3 0.38485807180404663
val: 4 0.39055970311164856
val: 5 0.39822104573249817
val: 6 0.3890079855918884
val: 7 0.3876330554485321
val: 8 0.4020436704158783
val: 9 0.3870273232460022
val: 10 0.38773012161254883
val: 11 0.3876665532588959
val: 12 0.39056751132011414
val: 13 0.39572787284851074
val: 14 0.3938322067260742
val: 15 0.3925480842590332
val: 16 0.38884010910987854
val: 17 0.39076024293899536
val: 18 0.3880220353603363
val: 19 0.38701382279396057
val: 20 0.3838207423686981
val_Epoch:[ 124 ] val_loss: 0.39026003926992414 2022-07-01 18:03:50.749951
start training 2022-07-01 18:03:50.849468
Epoch:[ 125 0 ] loss: 0.3603525161743164 2022-07-01 18:04:05.501546
Epoch:[ 125 1 ] loss: 0.3621836006641388 2022-07-01 18:04:05.917533
Epoch:[ 125 2 ] loss: 0.3616752028465271 2022-07-01 18:04:06.331728
Epoch:[ 125 3 ] loss: 0.36147043108940125 2022-07-01 18:04:06.747532
Epoch:[ 125 4 ] loss: 0.3607138395309448 2022-07-01 18:04:07.164587
Epoch:[ 125 5 ] loss: 0.36147281527519226 2022-07-01 18:04:07.580339
Epoch:[ 125 6 ] loss: 0.36055660247802734 2022-07-01 18:04:07.994724
Epoch:[ 125 7 ] loss: 0.361349493265152 2022-07-01 18:04:08.408407
Epoch:[ 125 8 ] loss: 0.36029037833213806 2022-07-01 18:04:08.818052
Epoch:[ 125 9 ] loss: 0.3624967336654663 2022-07-01 18:04:09.225826
Epoch:[ 125 10 ] loss: 0.36114880442619324 2022-07-01 18:04:09.641727
Epoch:[ 125 11 ] loss: 0.3607625663280487 2022-07-01 18:04:10.058001
Epoch:[ 125 12 ] loss: 0.36188313364982605 2022-07-01 18:04:10.473728
Epoch:[ 125 13 ] loss: 0.3620000183582306 2022-07-01 18:04:10.882999
Epoch:[ 125 14 ] loss: 0.361784428358078 2022-07-01 18:04:11.297116
Epoch:[ 125 15 ] loss: 0.36169329285621643 2022-07-01 18:04:11.711478
Epoch:[ 125 16 ] loss: 0.35984551906585693 2022-07-01 18:04:16.914945
Epoch:[ 125 17 ] loss: 0.3613818287849426 2022-07-01 18:04:17.330266
Epoch:[ 125 18 ] loss: 0.3626406788825989 2022-07-01 18:04:17.755935
Epoch:[ 125 19 ] loss: 0.3611809313297272 2022-07-01 18:04:18.176640
Training_Epoch:[ 125 ] Training_loss: 0.36134414076805116 2022-07-01 18:04:18.177396
learning rate:  6.871947673600006e-05
val: 1 0.3909357488155365
val: 2 0.393433153629303
val: 3 0.39608335494995117
val: 4 0.3884829878807068
val: 5 0.39238259196281433
val: 6 0.39285531640052795
val: 7 0.38401293754577637
val: 8 0.3925963044166565
val: 9 0.39017051458358765
val: 10 0.3903173804283142
val: 11 0.38951829075813293
val: 12 0.3909638226032257
val: 13 0.393710196018219
val: 14 0.39262092113494873
val: 15 0.38981959223747253
val: 16 0.39527344703674316
val: 17 0.38938096165657043
val: 18 0.3889620006084442
val: 19 0.3846015930175781
val: 20 0.38444530963897705
val_Epoch:[ 125 ] val_loss: 0.3905283212661743 2022-07-01 18:04:22.067655
start training 2022-07-01 18:04:22.174753
Epoch:[ 126 0 ] loss: 0.361614853143692 2022-07-01 18:04:36.262398
Epoch:[ 126 1 ] loss: 0.3613847494125366 2022-07-01 18:04:36.901760
Epoch:[ 126 2 ] loss: 0.36213213205337524 2022-07-01 18:04:37.322900
Epoch:[ 126 3 ] loss: 0.35980910062789917 2022-07-01 18:04:37.743288
Epoch:[ 126 4 ] loss: 0.3613812029361725 2022-07-01 18:04:38.159446
Epoch:[ 126 5 ] loss: 0.36134564876556396 2022-07-01 18:04:38.581637
Epoch:[ 126 6 ] loss: 0.36122891306877136 2022-07-01 18:04:38.996360
Epoch:[ 126 7 ] loss: 0.36080309748649597 2022-07-01 18:04:39.410357
Epoch:[ 126 8 ] loss: 0.3607361912727356 2022-07-01 18:04:39.824108
Epoch:[ 126 9 ] loss: 0.3627907335758209 2022-07-01 18:04:40.241241
Epoch:[ 126 10 ] loss: 0.36183708906173706 2022-07-01 18:04:40.655126
Epoch:[ 126 11 ] loss: 0.36191031336784363 2022-07-01 18:04:41.071056
Epoch:[ 126 12 ] loss: 0.36036086082458496 2022-07-01 18:04:41.486933
Epoch:[ 126 13 ] loss: 0.3609737753868103 2022-07-01 18:04:41.903526
Epoch:[ 126 14 ] loss: 0.36141759157180786 2022-07-01 18:04:42.318040
Epoch:[ 126 15 ] loss: 0.3602074980735779 2022-07-01 18:04:42.733360
Epoch:[ 126 16 ] loss: 0.36139780282974243 2022-07-01 18:04:48.498563
Epoch:[ 126 17 ] loss: 0.3608579933643341 2022-07-01 18:04:48.916146
Epoch:[ 126 18 ] loss: 0.36226314306259155 2022-07-01 18:04:49.339128
Epoch:[ 126 19 ] loss: 0.3617841899394989 2022-07-01 18:04:49.754574
Training_Epoch:[ 126 ] Training_loss: 0.3613118439912796 2022-07-01 18:04:49.755372
learning rate:  6.871947673600006e-05
netparams have been saved once 126
val: 1 0.39967241883277893
val: 2 0.3906211853027344
val: 3 0.38931891322135925
val: 4 0.39505890011787415
val: 5 0.3839198350906372
val: 6 0.3889000415802002
val: 7 0.4010196924209595
val: 8 0.39297428727149963
val: 9 0.38961830735206604
val: 10 0.389744371175766
val: 11 0.385815292596817
val: 12 0.38376086950302124
val: 13 0.3880269229412079
val: 14 0.39171311259269714
val: 15 0.38800740242004395
val: 16 0.38988491892814636
val: 17 0.39021679759025574
val: 18 0.3906187117099762
val: 19 0.39104169607162476
val: 20 0.38451632857322693
val_Epoch:[ 126 ] val_loss: 0.3902225002646446 2022-07-01 18:04:53.906400
start training 2022-07-01 18:04:54.009096
Epoch:[ 127 0 ] loss: 0.36103224754333496 2022-07-01 18:05:08.755638
Epoch:[ 127 1 ] loss: 0.3596617579460144 2022-07-01 18:05:09.170354
Epoch:[ 127 2 ] loss: 0.3603174090385437 2022-07-01 18:05:09.587679
Epoch:[ 127 3 ] loss: 0.360146701335907 2022-07-01 18:05:10.001770
Epoch:[ 127 4 ] loss: 0.36148810386657715 2022-07-01 18:05:10.422350
Epoch:[ 127 5 ] loss: 0.3624646067619324 2022-07-01 18:05:10.837370
Epoch:[ 127 6 ] loss: 0.36051836609840393 2022-07-01 18:05:11.254563
Epoch:[ 127 7 ] loss: 0.3619179129600525 2022-07-01 18:05:11.671726
Epoch:[ 127 8 ] loss: 0.36170318722724915 2022-07-01 18:05:12.087234
Epoch:[ 127 9 ] loss: 0.3629808723926544 2022-07-01 18:05:12.500994
Epoch:[ 127 10 ] loss: 0.36194249987602234 2022-07-01 18:05:12.924077
Epoch:[ 127 11 ] loss: 0.3608340620994568 2022-07-01 18:05:13.338087
Epoch:[ 127 12 ] loss: 0.36105090379714966 2022-07-01 18:05:13.760615
Epoch:[ 127 13 ] loss: 0.36111053824424744 2022-07-01 18:05:14.176787
Epoch:[ 127 14 ] loss: 0.3626771569252014 2022-07-01 18:05:14.593499
Epoch:[ 127 15 ] loss: 0.3619336783885956 2022-07-01 18:05:15.010462
Epoch:[ 127 16 ] loss: 0.36095279455184937 2022-07-01 18:05:20.966261
Epoch:[ 127 17 ] loss: 0.3612232208251953 2022-07-01 18:05:21.388111
Epoch:[ 127 18 ] loss: 0.3612063527107239 2022-07-01 18:05:21.813084
Epoch:[ 127 19 ] loss: 0.36107057332992554 2022-07-01 18:05:22.226906
Training_Epoch:[ 127 ] Training_loss: 0.36131164729595183 2022-07-01 18:05:22.227601
learning rate:  6.871947673600006e-05
val: 1 0.39088737964630127
val: 2 0.3908981680870056
val: 3 0.3931557536125183
val: 4 0.3875258266925812
val: 5 0.38479381799697876
val: 6 0.382304310798645
val: 7 0.3987846076488495
val: 8 0.3832595944404602
val: 9 0.38518407940864563
val: 10 0.3878113031387329
val: 11 0.393096387386322
val: 12 0.39173170924186707
val: 13 0.39050397276878357
val: 14 0.3928169906139374
val: 15 0.3912551999092102
val: 16 0.39494460821151733
val: 17 0.38835659623146057
val: 18 0.3920172452926636
val: 19 0.3843626081943512
val: 20 0.39601752161979675
val_Epoch:[ 127 ] val_loss: 0.3899853840470314 2022-07-01 18:05:26.087533
start training 2022-07-01 18:05:26.190774
Epoch:[ 128 0 ] loss: 0.3620651662349701 2022-07-01 18:05:41.005640
Epoch:[ 128 1 ] loss: 0.36079803109169006 2022-07-01 18:05:41.450083
Epoch:[ 128 2 ] loss: 0.36085963249206543 2022-07-01 18:05:41.864697
Epoch:[ 128 3 ] loss: 0.36117613315582275 2022-07-01 18:05:42.285070
Epoch:[ 128 4 ] loss: 0.36188361048698425 2022-07-01 18:05:42.699109
Epoch:[ 128 5 ] loss: 0.3623330593109131 2022-07-01 18:05:43.115109
Epoch:[ 128 6 ] loss: 0.3605266809463501 2022-07-01 18:05:43.537530
Epoch:[ 128 7 ] loss: 0.36113980412483215 2022-07-01 18:05:43.954534
Epoch:[ 128 8 ] loss: 0.3616200387477875 2022-07-01 18:05:44.371264
Epoch:[ 128 9 ] loss: 0.3622162938117981 2022-07-01 18:05:44.785906
Epoch:[ 128 10 ] loss: 0.36172810196876526 2022-07-01 18:05:45.203379
Epoch:[ 128 11 ] loss: 0.36059266328811646 2022-07-01 18:05:45.619435
Epoch:[ 128 12 ] loss: 0.3616885542869568 2022-07-01 18:05:46.033609
Epoch:[ 128 13 ] loss: 0.3605833947658539 2022-07-01 18:05:46.449664
Epoch:[ 128 14 ] loss: 0.36078187823295593 2022-07-01 18:05:46.868527
Epoch:[ 128 15 ] loss: 0.36050522327423096 2022-07-01 18:05:47.293277
Epoch:[ 128 16 ] loss: 0.360898494720459 2022-07-01 18:05:53.208770
Epoch:[ 128 17 ] loss: 0.36103713512420654 2022-07-01 18:05:53.627397
Epoch:[ 128 18 ] loss: 0.36210882663726807 2022-07-01 18:05:54.046627
Epoch:[ 128 19 ] loss: 0.36162933707237244 2022-07-01 18:05:54.463448
Training_Epoch:[ 128 ] Training_loss: 0.3613086029887199 2022-07-01 18:05:54.464103
learning rate:  6.871947673600006e-05
netparams have been saved once 128
val: 1 0.38400089740753174
val: 2 0.38282257318496704
val: 3 0.39374205470085144
val: 4 0.4017190933227539
val: 5 0.39305487275123596
val: 6 0.3972133696079254
val: 7 0.3864486813545227
val: 8 0.3926853537559509
val: 9 0.38492682576179504
val: 10 0.3892965316772461
val: 11 0.3859419822692871
val: 12 0.3962199091911316
val: 13 0.3878946900367737
val: 14 0.3878336548805237
val: 15 0.39389362931251526
val: 16 0.3870495855808258
val: 17 0.3919755816459656
val: 18 0.39191678166389465
val: 19 0.3855864703655243
val: 20 0.3887452483177185
val_Epoch:[ 128 ] val_loss: 0.390148389339447 2022-07-01 18:05:58.427035
start training 2022-07-01 18:05:58.528645
Epoch:[ 129 0 ] loss: 0.3617497980594635 2022-07-01 18:06:12.689341
Epoch:[ 129 1 ] loss: 0.3613317906856537 2022-07-01 18:06:13.137110
Epoch:[ 129 2 ] loss: 0.36157482862472534 2022-07-01 18:06:13.584465
Epoch:[ 129 3 ] loss: 0.36114275455474854 2022-07-01 18:06:14.003573
Epoch:[ 129 4 ] loss: 0.36190852522850037 2022-07-01 18:06:14.420282
Epoch:[ 129 5 ] loss: 0.3606751263141632 2022-07-01 18:06:14.833772
Epoch:[ 129 6 ] loss: 0.3607468903064728 2022-07-01 18:06:15.249735
Epoch:[ 129 7 ] loss: 0.3618139326572418 2022-07-01 18:06:15.675228
Epoch:[ 129 8 ] loss: 0.3606056571006775 2022-07-01 18:06:16.092074
Epoch:[ 129 9 ] loss: 0.36172008514404297 2022-07-01 18:06:16.509299
Epoch:[ 129 10 ] loss: 0.36128756403923035 2022-07-01 18:06:16.929934
Epoch:[ 129 11 ] loss: 0.3609064221382141 2022-07-01 18:06:17.344182
Epoch:[ 129 12 ] loss: 0.3597421646118164 2022-07-01 18:06:17.759188
Epoch:[ 129 13 ] loss: 0.3614957928657532 2022-07-01 18:06:18.176555
Epoch:[ 129 14 ] loss: 0.3613469898700714 2022-07-01 18:06:18.593635
Epoch:[ 129 15 ] loss: 0.36180147528648376 2022-07-01 18:06:19.010973
Epoch:[ 129 16 ] loss: 0.36123690009117126 2022-07-01 18:06:24.497525
Epoch:[ 129 17 ] loss: 0.3621041178703308 2022-07-01 18:06:24.915936
Epoch:[ 129 18 ] loss: 0.3616899847984314 2022-07-01 18:06:25.333110
Epoch:[ 129 19 ] loss: 0.3606325089931488 2022-07-01 18:06:25.749529
Training_Epoch:[ 129 ] Training_loss: 0.36127566546201706 2022-07-01 18:06:25.750258
learning rate:  6.871947673600006e-05
val: 1 0.39098066091537476
val: 2 0.39100325107574463
val: 3 0.3950781524181366
val: 4 0.38928017020225525
val: 5 0.38717007637023926
val: 6 0.3897923529148102
val: 7 0.3893488347530365
val: 8 0.3970792889595032
val: 9 0.38708221912384033
val: 10 0.38952744007110596
val: 11 0.3885083794593811
val: 12 0.3891139328479767
val: 13 0.3848726749420166
val: 14 0.3942098915576935
val: 15 0.3809753954410553
val: 16 0.3851909339427948
val: 17 0.39262279868125916
val: 18 0.39727070927619934
val: 19 0.3893073499202728
val: 20 0.39377066493034363
val_Epoch:[ 129 ] val_loss: 0.39010925889015197 2022-07-01 18:06:29.659779
start training 2022-07-01 18:06:29.766591
Epoch:[ 130 0 ] loss: 0.3614380955696106 2022-07-01 18:06:44.339823
Epoch:[ 130 1 ] loss: 0.3622150123119354 2022-07-01 18:06:44.779907
Epoch:[ 130 2 ] loss: 0.3611716628074646 2022-07-01 18:06:45.195076
Epoch:[ 130 3 ] loss: 0.36074307560920715 2022-07-01 18:06:45.610949
Epoch:[ 130 4 ] loss: 0.36192604899406433 2022-07-01 18:06:46.025724
Epoch:[ 130 5 ] loss: 0.361390620470047 2022-07-01 18:06:46.438575
Epoch:[ 130 6 ] loss: 0.36119702458381653 2022-07-01 18:06:46.852027
Epoch:[ 130 7 ] loss: 0.3614784777164459 2022-07-01 18:06:47.264948
Epoch:[ 130 8 ] loss: 0.36140117049217224 2022-07-01 18:06:47.686885
Epoch:[ 130 9 ] loss: 0.36119285225868225 2022-07-01 18:06:48.108203
Epoch:[ 130 10 ] loss: 0.3601241707801819 2022-07-01 18:06:48.521900
Epoch:[ 130 11 ] loss: 0.3605896830558777 2022-07-01 18:06:48.935337
Epoch:[ 130 12 ] loss: 0.3607132136821747 2022-07-01 18:06:49.348691
Epoch:[ 130 13 ] loss: 0.36135026812553406 2022-07-01 18:06:49.769267
Epoch:[ 130 14 ] loss: 0.36118635535240173 2022-07-01 18:06:50.181094
Epoch:[ 130 15 ] loss: 0.36114880442619324 2022-07-01 18:06:50.596096
Epoch:[ 130 16 ] loss: 0.36154255270957947 2022-07-01 18:06:56.179869
Epoch:[ 130 17 ] loss: 0.3618867099285126 2022-07-01 18:06:56.598681
Epoch:[ 130 18 ] loss: 0.3612670302391052 2022-07-01 18:06:57.014040
Epoch:[ 130 19 ] loss: 0.3617568910121918 2022-07-01 18:06:57.433936
Training_Epoch:[ 130 ] Training_loss: 0.36128598600625994 2022-07-01 18:06:57.434655
learning rate:  6.871947673600006e-05
netparams have been saved once 130
val: 1 0.3827354609966278
val: 2 0.3938610553741455
val: 3 0.393640398979187
val: 4 0.38882532715797424
val: 5 0.3840795159339905
val: 6 0.37841176986694336
val: 7 0.38766875863075256
val: 8 0.39090850949287415
val: 9 0.39530202746391296
val: 10 0.3920036256313324
val: 11 0.3884604871273041
val: 12 0.393161803483963
val: 13 0.39858198165893555
val: 14 0.3994747996330261
val: 15 0.396597683429718
val: 16 0.39061596989631653
val: 17 0.3945729732513428
val: 18 0.3818175792694092
val: 19 0.3915543854236603
val: 20 0.3861180245876312
val_Epoch:[ 130 ] val_loss: 0.3904196068644524 2022-07-01 18:07:01.359025
start training 2022-07-01 18:07:01.460329
Epoch:[ 131 0 ] loss: 0.36075326800346375 2022-07-01 18:07:16.222897
Epoch:[ 131 1 ] loss: 0.3599676489830017 2022-07-01 18:07:16.635874
Epoch:[ 131 2 ] loss: 0.3614087402820587 2022-07-01 18:07:17.051157
Epoch:[ 131 3 ] loss: 0.3609035313129425 2022-07-01 18:07:17.471875
Epoch:[ 131 4 ] loss: 0.3608034551143646 2022-07-01 18:07:17.895345
Epoch:[ 131 5 ] loss: 0.36059272289276123 2022-07-01 18:07:18.309996
Epoch:[ 131 6 ] loss: 0.3623848855495453 2022-07-01 18:07:18.723604
Epoch:[ 131 7 ] loss: 0.3607373535633087 2022-07-01 18:07:19.137156
Epoch:[ 131 8 ] loss: 0.36162933707237244 2022-07-01 18:07:19.554352
Epoch:[ 131 9 ] loss: 0.3624690771102905 2022-07-01 18:07:19.969903
Epoch:[ 131 10 ] loss: 0.3614908456802368 2022-07-01 18:07:20.386168
Epoch:[ 131 11 ] loss: 0.3621390759944916 2022-07-01 18:07:20.801155
Epoch:[ 131 12 ] loss: 0.36120790243148804 2022-07-01 18:07:21.215297
Epoch:[ 131 13 ] loss: 0.3603470027446747 2022-07-01 18:07:21.629368
Epoch:[ 131 14 ] loss: 0.36046847701072693 2022-07-01 18:07:22.049571
Epoch:[ 131 15 ] loss: 0.3608616292476654 2022-07-01 18:07:22.463436
Epoch:[ 131 16 ] loss: 0.36077189445495605 2022-07-01 18:07:28.136454
Epoch:[ 131 17 ] loss: 0.3612011671066284 2022-07-01 18:07:28.557803
Epoch:[ 131 18 ] loss: 0.36220353841781616 2022-07-01 18:07:28.974013
Epoch:[ 131 19 ] loss: 0.36202746629714966 2022-07-01 18:07:29.387715
Training_Epoch:[ 131 ] Training_loss: 0.36121845096349714 2022-07-01 18:07:29.388432
learning rate:  5.497558138880005e-05
val: 1 0.3878137171268463
val: 2 0.38478583097457886
val: 3 0.3980970084667206
val: 4 0.38836783170700073
val: 5 0.39334315061569214
val: 6 0.3917861878871918
val: 7 0.39377376437187195
val: 8 0.3910371661186218
val: 9 0.3913314640522003
val: 10 0.38842660188674927
val: 11 0.3913150429725647
val: 12 0.39780184626579285
val: 13 0.3851134479045868
val: 14 0.38429132103919983
val: 15 0.38865232467651367
val: 16 0.39480090141296387
val: 17 0.38806259632110596
val: 18 0.3938193917274475
val: 19 0.3956896960735321
val: 20 0.3873416781425476
val_Epoch:[ 131 ] val_loss: 0.3907825484871864 2022-07-01 18:07:33.223162
start training 2022-07-01 18:07:33.324148
Epoch:[ 132 0 ] loss: 0.3611319959163666 2022-07-01 18:07:47.990852
Epoch:[ 132 1 ] loss: 0.3611968457698822 2022-07-01 18:07:48.407154
Epoch:[ 132 2 ] loss: 0.36269867420196533 2022-07-01 18:07:48.822057
Epoch:[ 132 3 ] loss: 0.36048242449760437 2022-07-01 18:07:49.239618
Epoch:[ 132 4 ] loss: 0.36113303899765015 2022-07-01 18:07:49.657109
Epoch:[ 132 5 ] loss: 0.3620436191558838 2022-07-01 18:07:50.071671
Epoch:[ 132 6 ] loss: 0.3607860505580902 2022-07-01 18:07:50.491701
Epoch:[ 132 7 ] loss: 0.36072733998298645 2022-07-01 18:07:50.906011
Epoch:[ 132 8 ] loss: 0.36058464646339417 2022-07-01 18:07:51.320607
Epoch:[ 132 9 ] loss: 0.3608611524105072 2022-07-01 18:07:51.740762
Epoch:[ 132 10 ] loss: 0.3612709641456604 2022-07-01 18:07:52.157529
Epoch:[ 132 11 ] loss: 0.36150214076042175 2022-07-01 18:07:52.573813
Epoch:[ 132 12 ] loss: 0.36144721508026123 2022-07-01 18:07:52.995899
Epoch:[ 132 13 ] loss: 0.36100059747695923 2022-07-01 18:07:53.417184
Epoch:[ 132 14 ] loss: 0.3612670600414276 2022-07-01 18:07:53.833159
Epoch:[ 132 15 ] loss: 0.3604305386543274 2022-07-01 18:07:54.247334
Epoch:[ 132 16 ] loss: 0.36180225014686584 2022-07-01 18:07:59.874245
Epoch:[ 132 17 ] loss: 0.3614693284034729 2022-07-01 18:08:00.293563
Epoch:[ 132 18 ] loss: 0.3617803752422333 2022-07-01 18:08:00.711016
Epoch:[ 132 19 ] loss: 0.3606880307197571 2022-07-01 18:08:01.131856
Training_Epoch:[ 132 ] Training_loss: 0.36121521443128585 2022-07-01 18:08:01.132592
learning rate:  5.497558138880005e-05
netparams have been saved once 132
val: 1 0.39830851554870605
val: 2 0.3957758843898773
val: 3 0.38817542791366577
val: 4 0.3896621763706207
val: 5 0.3892335593700409
val: 6 0.38551273941993713
val: 7 0.38137727975845337
val: 8 0.3912980556488037
val: 9 0.38907650113105774
val: 10 0.39043280482292175
val: 11 0.3925425410270691
val: 12 0.3928820788860321
val: 13 0.3968099057674408
val: 14 0.3846929669380188
val: 15 0.38934776186943054
val: 16 0.39022958278656006
val: 17 0.3889514207839966
val: 18 0.38439443707466125
val: 19 0.3847082555294037
val: 20 0.40273210406303406
val_Epoch:[ 132 ] val_loss: 0.3903071999549866 2022-07-01 18:08:05.143963
start training 2022-07-01 18:08:05.244571
Epoch:[ 133 0 ] loss: 0.36077144742012024 2022-07-01 18:08:19.248336
Epoch:[ 133 1 ] loss: 0.3611091673374176 2022-07-01 18:08:19.960604
Epoch:[ 133 2 ] loss: 0.36149269342422485 2022-07-01 18:08:20.384101
Epoch:[ 133 3 ] loss: 0.36200836300849915 2022-07-01 18:08:20.797446
Epoch:[ 133 4 ] loss: 0.36209380626678467 2022-07-01 18:08:21.214335
Epoch:[ 133 5 ] loss: 0.3614656925201416 2022-07-01 18:08:21.630989
Epoch:[ 133 6 ] loss: 0.36228466033935547 2022-07-01 18:08:22.045764
Epoch:[ 133 7 ] loss: 0.36111488938331604 2022-07-01 18:08:22.460294
Epoch:[ 133 8 ] loss: 0.3621666729450226 2022-07-01 18:08:22.882706
Epoch:[ 133 9 ] loss: 0.3609858453273773 2022-07-01 18:08:23.305491
Epoch:[ 133 10 ] loss: 0.36003604531288147 2022-07-01 18:08:23.719018
Epoch:[ 133 11 ] loss: 0.3605831563472748 2022-07-01 18:08:24.136251
Epoch:[ 133 12 ] loss: 0.3611830174922943 2022-07-01 18:08:24.553238
Epoch:[ 133 13 ] loss: 0.3604469299316406 2022-07-01 18:08:24.968246
Epoch:[ 133 14 ] loss: 0.3613705337047577 2022-07-01 18:08:25.383544
Epoch:[ 133 15 ] loss: 0.3604966998100281 2022-07-01 18:08:25.797650
Epoch:[ 133 16 ] loss: 0.3603600561618805 2022-07-01 18:08:31.091626
Epoch:[ 133 17 ] loss: 0.3607405722141266 2022-07-01 18:08:31.510760
Epoch:[ 133 18 ] loss: 0.36088818311691284 2022-07-01 18:08:31.934932
Epoch:[ 133 19 ] loss: 0.3618168532848358 2022-07-01 18:08:32.351340
Training_Epoch:[ 133 ] Training_loss: 0.3611707642674446 2022-07-01 18:08:32.352056
learning rate:  5.497558138880005e-05
val: 1 0.397804319858551
val: 2 0.3900403082370758
val: 3 0.3909398019313812
val: 4 0.39316558837890625
val: 5 0.393450528383255
val: 6 0.3884422183036804
val: 7 0.38805338740348816
val: 8 0.3945866525173187
val: 9 0.38084545731544495
val: 10 0.39150291681289673
val: 11 0.3919263184070587
val: 12 0.38607338070869446
val: 13 0.3808249831199646
val: 14 0.3976706266403198
val: 15 0.3875204026699066
val: 16 0.3875359892845154
val: 17 0.3974440097808838
val: 18 0.393029123544693
val: 19 0.3960767984390259
val: 20 0.38703110814094543
val_Epoch:[ 133 ] val_loss: 0.3906981959939003 2022-07-01 18:08:36.267531
start training 2022-07-01 18:08:36.371640
Epoch:[ 134 0 ] loss: 0.36204349994659424 2022-07-01 18:08:51.296687
Epoch:[ 134 1 ] loss: 0.3613079786300659 2022-07-01 18:08:51.711475
Epoch:[ 134 2 ] loss: 0.36033394932746887 2022-07-01 18:08:52.126144
Epoch:[ 134 3 ] loss: 0.360574871301651 2022-07-01 18:08:52.540043
Epoch:[ 134 4 ] loss: 0.36098748445510864 2022-07-01 18:08:52.960229
Epoch:[ 134 5 ] loss: 0.36069199442863464 2022-07-01 18:08:53.375344
Epoch:[ 134 6 ] loss: 0.36245930194854736 2022-07-01 18:08:53.790748
Epoch:[ 134 7 ] loss: 0.36069154739379883 2022-07-01 18:08:54.213344
Epoch:[ 134 8 ] loss: 0.3609391450881958 2022-07-01 18:08:54.626606
Epoch:[ 134 9 ] loss: 0.3611982762813568 2022-07-01 18:08:55.041009
Epoch:[ 134 10 ] loss: 0.36058467626571655 2022-07-01 18:08:55.455804
Epoch:[ 134 11 ] loss: 0.36276066303253174 2022-07-01 18:08:55.869128
Epoch:[ 134 12 ] loss: 0.36063018441200256 2022-07-01 18:08:56.292197
Epoch:[ 134 13 ] loss: 0.36005541682243347 2022-07-01 18:08:56.707996
Epoch:[ 134 14 ] loss: 0.36148032546043396 2022-07-01 18:08:57.123272
Epoch:[ 134 15 ] loss: 0.36160334944725037 2022-07-01 18:08:57.536621
Epoch:[ 134 16 ] loss: 0.36028915643692017 2022-07-01 18:09:03.351535
Epoch:[ 134 17 ] loss: 0.3615799844264984 2022-07-01 18:09:03.764988
Epoch:[ 134 18 ] loss: 0.3610575795173645 2022-07-01 18:09:04.184999
Epoch:[ 134 19 ] loss: 0.36078307032585144 2022-07-01 18:09:04.603064
Training_Epoch:[ 134 ] Training_loss: 0.3611026227474213 2022-07-01 18:09:04.603764
learning rate:  5.497558138880005e-05
netparams have been saved once 134
val: 1 0.3915116488933563
val: 2 0.38485661149024963
val: 3 0.39862269163131714
val: 4 0.3888939917087555
val: 5 0.38804566860198975
val: 6 0.3918924927711487
val: 7 0.3897026777267456
val: 8 0.39337605237960815
val: 9 0.38461562991142273
val: 10 0.39560672640800476
val: 11 0.38959047198295593
val: 12 0.3887861967086792
val: 13 0.3929755389690399
val: 14 0.39711621403694153
val: 15 0.39150187373161316
val: 16 0.38604530692100525
val: 17 0.39341941475868225
val: 18 0.3921685516834259
val: 19 0.39113834500312805
val: 20 0.3858419358730316
val_Epoch:[ 134 ] val_loss: 0.39078540205955503 2022-07-01 18:09:08.483341
start training 2022-07-01 18:09:08.586801
Epoch:[ 135 0 ] loss: 0.3612511157989502 2022-07-01 18:09:22.935458
Epoch:[ 135 1 ] loss: 0.36012697219848633 2022-07-01 18:09:23.355637
Epoch:[ 135 2 ] loss: 0.360953152179718 2022-07-01 18:09:23.775872
Epoch:[ 135 3 ] loss: 0.35970360040664673 2022-07-01 18:09:24.189007
Epoch:[ 135 4 ] loss: 0.3612385392189026 2022-07-01 18:09:24.601898
Epoch:[ 135 5 ] loss: 0.3609044551849365 2022-07-01 18:09:25.013836
Epoch:[ 135 6 ] loss: 0.36139366030693054 2022-07-01 18:09:25.429600
Epoch:[ 135 7 ] loss: 0.36084839701652527 2022-07-01 18:09:25.851172
Epoch:[ 135 8 ] loss: 0.36102694272994995 2022-07-01 18:09:26.267725
Epoch:[ 135 9 ] loss: 0.36048781871795654 2022-07-01 18:09:26.681850
Epoch:[ 135 10 ] loss: 0.36147403717041016 2022-07-01 18:09:27.097162
Epoch:[ 135 11 ] loss: 0.36169034242630005 2022-07-01 18:09:27.515207
Epoch:[ 135 12 ] loss: 0.3624475300312042 2022-07-01 18:09:27.929167
Epoch:[ 135 13 ] loss: 0.3619471788406372 2022-07-01 18:09:28.348309
Epoch:[ 135 14 ] loss: 0.3607487380504608 2022-07-01 18:09:28.765737
Epoch:[ 135 15 ] loss: 0.3626616597175598 2022-07-01 18:09:29.181136
Epoch:[ 135 16 ] loss: 0.3609442412853241 2022-07-01 18:09:34.574960
Epoch:[ 135 17 ] loss: 0.3616986572742462 2022-07-01 18:09:34.992380
Epoch:[ 135 18 ] loss: 0.3611796200275421 2022-07-01 18:09:35.413690
Epoch:[ 135 19 ] loss: 0.361483633518219 2022-07-01 18:09:35.828179
Training_Epoch:[ 135 ] Training_loss: 0.36121051460504533 2022-07-01 18:09:35.829144
learning rate:  5.497558138880005e-05
val: 1 0.3922787308692932
val: 2 0.39085260033607483
val: 3 0.3949551284313202
val: 4 0.3888845443725586
val: 5 0.38809382915496826
val: 6 0.39273601770401
val: 7 0.39102527499198914
val: 8 0.38985344767570496
val: 9 0.39295393228530884
val: 10 0.39003807306289673
val: 11 0.3887929320335388
val: 12 0.38595494627952576
val: 13 0.38847067952156067
val: 14 0.3918286859989166
val: 15 0.3911929130554199
val: 16 0.3923446834087372
val: 17 0.3930528163909912
val: 18 0.3820432722568512
val: 19 0.38475367426872253
val: 20 0.3955353796482086
val_Epoch:[ 135 ] val_loss: 0.39028207808732984 2022-07-01 18:09:39.748554
start training 2022-07-01 18:09:39.853932
Epoch:[ 136 0 ] loss: 0.3602508306503296 2022-07-01 18:09:54.151252
Epoch:[ 136 1 ] loss: 0.3600436747074127 2022-07-01 18:09:54.596512
Epoch:[ 136 2 ] loss: 0.36196476221084595 2022-07-01 18:09:55.011890
Epoch:[ 136 3 ] loss: 0.36169496178627014 2022-07-01 18:09:55.426080
Epoch:[ 136 4 ] loss: 0.35969415307044983 2022-07-01 18:09:55.841692
Epoch:[ 136 5 ] loss: 0.36101552844047546 2022-07-01 18:09:56.264879
Epoch:[ 136 6 ] loss: 0.36140790581703186 2022-07-01 18:09:56.676514
Epoch:[ 136 7 ] loss: 0.3611937165260315 2022-07-01 18:09:57.093235
Epoch:[ 136 8 ] loss: 0.3601677715778351 2022-07-01 18:09:57.502834
Epoch:[ 136 9 ] loss: 0.3601909279823303 2022-07-01 18:09:57.918968
Epoch:[ 136 10 ] loss: 0.3621646761894226 2022-07-01 18:09:58.333755
Epoch:[ 136 11 ] loss: 0.3617669343948364 2022-07-01 18:09:58.743804
Epoch:[ 136 12 ] loss: 0.36159390211105347 2022-07-01 18:09:59.159492
Epoch:[ 136 13 ] loss: 0.36251986026763916 2022-07-01 18:09:59.573574
Epoch:[ 136 14 ] loss: 0.36145174503326416 2022-07-01 18:09:59.989184
Epoch:[ 136 15 ] loss: 0.3599131107330322 2022-07-01 18:10:00.409450
Epoch:[ 136 16 ] loss: 0.36186283826828003 2022-07-01 18:10:05.891015
Epoch:[ 136 17 ] loss: 0.36138924956321716 2022-07-01 18:10:06.310821
Epoch:[ 136 18 ] loss: 0.3617384433746338 2022-07-01 18:10:06.726494
Epoch:[ 136 19 ] loss: 0.36014804244041443 2022-07-01 18:10:07.141385
Training_Epoch:[ 136 ] Training_loss: 0.3611086517572403 2022-07-01 18:10:07.142206
learning rate:  5.497558138880005e-05
netparams have been saved once 136
val: 1 0.3856237828731537
val: 2 0.38346731662750244
val: 3 0.4036617577075958
val: 4 0.3956699073314667
val: 5 0.38950014114379883
val: 6 0.3880417048931122
val: 7 0.3893868923187256
val: 8 0.3916110098361969
val: 9 0.3898889422416687
val: 10 0.3948758542537689
val: 11 0.3909780979156494
val: 12 0.39425137639045715
val: 13 0.39063557982444763
val: 14 0.3916901648044586
val: 15 0.3834282457828522
val: 16 0.3855005204677582
val: 17 0.3847557008266449
val: 18 0.3852609694004059
val: 19 0.38756263256073
val: 20 0.3864859938621521
val_Epoch:[ 136 ] val_loss: 0.3896138295531273 2022-07-01 18:10:11.184194
start training 2022-07-01 18:10:11.289402
Epoch:[ 137 0 ] loss: 0.36123231053352356 2022-07-01 18:10:26.345747
Epoch:[ 137 1 ] loss: 0.3604404032230377 2022-07-01 18:10:26.760658
Epoch:[ 137 2 ] loss: 0.36128148436546326 2022-07-01 18:10:27.176119
Epoch:[ 137 3 ] loss: 0.36112889647483826 2022-07-01 18:10:27.589772
Epoch:[ 137 4 ] loss: 0.3601808547973633 2022-07-01 18:10:28.012917
Epoch:[ 137 5 ] loss: 0.3623046576976776 2022-07-01 18:10:28.426419
Epoch:[ 137 6 ] loss: 0.3622315526008606 2022-07-01 18:10:28.840257
Epoch:[ 137 7 ] loss: 0.36117228865623474 2022-07-01 18:10:29.256572
Epoch:[ 137 8 ] loss: 0.36090025305747986 2022-07-01 18:10:29.671770
Epoch:[ 137 9 ] loss: 0.3609830141067505 2022-07-01 18:10:30.092507
Epoch:[ 137 10 ] loss: 0.36025470495224 2022-07-01 18:10:30.506634
Epoch:[ 137 11 ] loss: 0.36185675859451294 2022-07-01 18:10:30.920021
Epoch:[ 137 12 ] loss: 0.3610532581806183 2022-07-01 18:10:31.334654
Epoch:[ 137 13 ] loss: 0.36152663826942444 2022-07-01 18:10:31.747802
Epoch:[ 137 14 ] loss: 0.36056867241859436 2022-07-01 18:10:32.160856
Epoch:[ 137 15 ] loss: 0.35955920815467834 2022-07-01 18:10:32.582987
Epoch:[ 137 16 ] loss: 0.36058440804481506 2022-07-01 18:10:37.865905
Epoch:[ 137 17 ] loss: 0.3606325387954712 2022-07-01 18:10:38.278773
Epoch:[ 137 18 ] loss: 0.3617812693119049 2022-07-01 18:10:38.705786
Epoch:[ 137 19 ] loss: 0.36121442914009094 2022-07-01 18:10:39.125956
Training_Epoch:[ 137 ] Training_loss: 0.361044380068779 2022-07-01 18:10:39.126614
learning rate:  5.497558138880005e-05
val: 1 0.39279696345329285
val: 2 0.3887300491333008
val: 3 0.3903212547302246
val: 4 0.38205960392951965
val: 5 0.39848825335502625
val: 6 0.3926314115524292
val: 7 0.3944297432899475
val: 8 0.3841014802455902
val: 9 0.393511027097702
val: 10 0.39805442094802856
val: 11 0.38511142134666443
val: 12 0.3917903006076813
val: 13 0.3857273459434509
val: 14 0.39475658535957336
val: 15 0.3900945782661438
val: 16 0.3916352391242981
val: 17 0.3946068584918976
val: 18 0.3876025974750519
val: 19 0.38580822944641113
val: 20 0.3909606337547302
val_Epoch:[ 137 ] val_loss: 0.3906608998775482 2022-07-01 18:10:42.982711
start training 2022-07-01 18:10:43.085074
Epoch:[ 138 0 ] loss: 0.3602168560028076 2022-07-01 18:10:57.370659
Epoch:[ 138 1 ] loss: 0.36135491728782654 2022-07-01 18:10:57.844198
Epoch:[ 138 2 ] loss: 0.36177632212638855 2022-07-01 18:10:58.260059
Epoch:[ 138 3 ] loss: 0.36065974831581116 2022-07-01 18:10:58.674368
Epoch:[ 138 4 ] loss: 0.3610481023788452 2022-07-01 18:10:59.088843
Epoch:[ 138 5 ] loss: 0.36104750633239746 2022-07-01 18:10:59.502071
Epoch:[ 138 6 ] loss: 0.3612852096557617 2022-07-01 18:10:59.922420
Epoch:[ 138 7 ] loss: 0.3612043559551239 2022-07-01 18:11:00.334266
Epoch:[ 138 8 ] loss: 0.36088061332702637 2022-07-01 18:11:00.748055
Epoch:[ 138 9 ] loss: 0.3612099587917328 2022-07-01 18:11:01.162122
Epoch:[ 138 10 ] loss: 0.361433207988739 2022-07-01 18:11:01.583050
Epoch:[ 138 11 ] loss: 0.3602413237094879 2022-07-01 18:11:01.999883
Epoch:[ 138 12 ] loss: 0.36076799035072327 2022-07-01 18:11:02.414404
Epoch:[ 138 13 ] loss: 0.36122700572013855 2022-07-01 18:11:02.826268
Epoch:[ 138 14 ] loss: 0.36197420954704285 2022-07-01 18:11:03.246753
Epoch:[ 138 15 ] loss: 0.3614499568939209 2022-07-01 18:11:03.659209
Epoch:[ 138 16 ] loss: 0.360208123922348 2022-07-01 18:11:09.002626
Epoch:[ 138 17 ] loss: 0.3620263338088989 2022-07-01 18:11:09.441336
Epoch:[ 138 18 ] loss: 0.3614290654659271 2022-07-01 18:11:09.868955
Epoch:[ 138 19 ] loss: 0.3607780635356903 2022-07-01 18:11:10.292021
Training_Epoch:[ 138 ] Training_loss: 0.3611109435558319 2022-07-01 18:11:10.292685
learning rate:  5.497558138880005e-05
netparams have been saved once 138
val: 1 0.39511099457740784
val: 2 0.39818575978279114
val: 3 0.3884447515010834
val: 4 0.38613659143447876
val: 5 0.3899935483932495
val: 6 0.38770005106925964
val: 7 0.3874934911727905
val: 8 0.3902035355567932
val: 9 0.3911278545856476
val: 10 0.38888800144195557
val: 11 0.3937843441963196
val: 12 0.39377108216285706
val: 13 0.38859832286834717
val: 14 0.3901360034942627
val: 15 0.39051032066345215
val: 16 0.39193716645240784
val: 17 0.3947867751121521
val: 18 0.3873617351055145
val: 19 0.3867051303386688
val: 20 0.3848235309123993
val_Epoch:[ 138 ] val_loss: 0.39028494954109194 2022-07-01 18:11:14.344980
start training 2022-07-01 18:11:14.446641
Epoch:[ 139 0 ] loss: 0.36062031984329224 2022-07-01 18:11:28.823254
Epoch:[ 139 1 ] loss: 0.36062413454055786 2022-07-01 18:11:29.261955
Epoch:[ 139 2 ] loss: 0.36092236638069153 2022-07-01 18:11:29.677356
Epoch:[ 139 3 ] loss: 0.36163896322250366 2022-07-01 18:11:30.087130
Epoch:[ 139 4 ] loss: 0.3605903089046478 2022-07-01 18:11:30.503553
Epoch:[ 139 5 ] loss: 0.36048999428749084 2022-07-01 18:11:30.912938
Epoch:[ 139 6 ] loss: 0.3603653311729431 2022-07-01 18:11:31.327794
Epoch:[ 139 7 ] loss: 0.3603280782699585 2022-07-01 18:11:31.742184
Epoch:[ 139 8 ] loss: 0.36017906665802 2022-07-01 18:11:32.156021
Epoch:[ 139 9 ] loss: 0.3606036305427551 2022-07-01 18:11:32.568187
Epoch:[ 139 10 ] loss: 0.3626254200935364 2022-07-01 18:11:32.990777
Epoch:[ 139 11 ] loss: 0.3621584475040436 2022-07-01 18:11:33.408086
Epoch:[ 139 12 ] loss: 0.36023473739624023 2022-07-01 18:11:33.822179
Epoch:[ 139 13 ] loss: 0.36229151487350464 2022-07-01 18:11:34.235786
Epoch:[ 139 14 ] loss: 0.3620817959308624 2022-07-01 18:11:34.651294
Epoch:[ 139 15 ] loss: 0.3616769313812256 2022-07-01 18:11:35.069260
Epoch:[ 139 16 ] loss: 0.36035823822021484 2022-07-01 18:11:40.936652
Epoch:[ 139 17 ] loss: 0.3606617748737335 2022-07-01 18:11:41.359103
Epoch:[ 139 18 ] loss: 0.3618409335613251 2022-07-01 18:11:41.776433
Epoch:[ 139 19 ] loss: 0.3609966039657593 2022-07-01 18:11:42.190083
Training_Epoch:[ 139 ] Training_loss: 0.3610644295811653 2022-07-01 18:11:42.191035
learning rate:  5.497558138880005e-05
val: 1 0.38988545536994934
val: 2 0.39460524916648865
val: 3 0.3934328258037567
val: 4 0.39014706015586853
val: 5 0.4013604521751404
val: 6 0.3928547203540802
val: 7 0.39753735065460205
val: 8 0.39053231477737427
val: 9 0.3861624598503113
val: 10 0.38696229457855225
val: 11 0.38958391547203064
val: 12 0.39143767952919006
val: 13 0.38869136571884155
val: 14 0.39103901386260986
val: 15 0.3922732472419739
val: 16 0.38509246706962585
val: 17 0.38894036412239075
val: 18 0.3930917978286743
val: 19 0.39545533061027527
val: 20 0.3858909606933594
val_Epoch:[ 139 ] val_loss: 0.3912488162517548 2022-07-01 18:11:46.122637
start training 2022-07-01 18:11:46.228213
Epoch:[ 140 0 ] loss: 0.3610120117664337 2022-07-01 18:12:01.074753
Epoch:[ 140 1 ] loss: 0.36074432730674744 2022-07-01 18:12:01.487746
Epoch:[ 140 2 ] loss: 0.36099305748939514 2022-07-01 18:12:01.901879
Epoch:[ 140 3 ] loss: 0.36116454005241394 2022-07-01 18:12:02.317402
Epoch:[ 140 4 ] loss: 0.3604392409324646 2022-07-01 18:12:02.733219
Epoch:[ 140 5 ] loss: 0.3617390990257263 2022-07-01 18:12:03.147290
Epoch:[ 140 6 ] loss: 0.3615072965621948 2022-07-01 18:12:03.568043
Epoch:[ 140 7 ] loss: 0.36204537749290466 2022-07-01 18:12:03.981413
Epoch:[ 140 8 ] loss: 0.3614725172519684 2022-07-01 18:12:04.395567
Epoch:[ 140 9 ] loss: 0.36035311222076416 2022-07-01 18:12:04.808817
Epoch:[ 140 10 ] loss: 0.3606127202510834 2022-07-01 18:12:05.222320
Epoch:[ 140 11 ] loss: 0.36133283376693726 2022-07-01 18:12:05.643573
Epoch:[ 140 12 ] loss: 0.36066752672195435 2022-07-01 18:12:06.059584
Epoch:[ 140 13 ] loss: 0.3613319396972656 2022-07-01 18:12:06.480838
Epoch:[ 140 14 ] loss: 0.3600035011768341 2022-07-01 18:12:06.894893
Epoch:[ 140 15 ] loss: 0.36086878180503845 2022-07-01 18:12:07.308001
Epoch:[ 140 16 ] loss: 0.36124467849731445 2022-07-01 18:12:12.863851
Epoch:[ 140 17 ] loss: 0.36150020360946655 2022-07-01 18:12:13.282110
Epoch:[ 140 18 ] loss: 0.36066359281539917 2022-07-01 18:12:13.698973
Epoch:[ 140 19 ] loss: 0.36138349771499634 2022-07-01 18:12:14.118866
Training_Epoch:[ 140 ] Training_loss: 0.36105399280786515 2022-07-01 18:12:14.119521
learning rate:  5.497558138880005e-05
netparams have been saved once 140
val: 1 0.38682466745376587
val: 2 0.3850884735584259
val: 3 0.3946407735347748
val: 4 0.3926889896392822
val: 5 0.38325035572052
val: 6 0.3879580795764923
val: 7 0.40537798404693604
val: 8 0.3933051526546478
val: 9 0.38598063588142395
val: 10 0.38871830701828003
val: 11 0.3836763799190521
val: 12 0.39272573590278625
val: 13 0.3928987979888916
val: 14 0.39012017846107483
val: 15 0.38746654987335205
val: 16 0.3999730348587036
val: 17 0.4048286974430084
val: 18 0.38435739278793335
val: 19 0.39116379618644714
val: 20 0.388625830411911
val_Epoch:[ 140 ] val_loss: 0.39098349064588545 2022-07-01 18:12:18.105766
start training 2022-07-01 18:12:18.211176
Epoch:[ 141 0 ] loss: 0.3606792986392975 2022-07-01 18:12:32.673168
Epoch:[ 141 1 ] loss: 0.3612489402294159 2022-07-01 18:12:33.117031
Epoch:[ 141 2 ] loss: 0.3612917363643646 2022-07-01 18:12:33.533125
Epoch:[ 141 3 ] loss: 0.36018261313438416 2022-07-01 18:12:33.946066
Epoch:[ 141 4 ] loss: 0.36045601963996887 2022-07-01 18:12:34.366737
Epoch:[ 141 5 ] loss: 0.3597771227359772 2022-07-01 18:12:34.788520
Epoch:[ 141 6 ] loss: 0.36115220189094543 2022-07-01 18:12:35.205068
Epoch:[ 141 7 ] loss: 0.36155936121940613 2022-07-01 18:12:35.618862
Epoch:[ 141 8 ] loss: 0.360404908657074 2022-07-01 18:12:36.033105
Epoch:[ 141 9 ] loss: 0.36089763045310974 2022-07-01 18:12:36.461990
Epoch:[ 141 10 ] loss: 0.36238721013069153 2022-07-01 18:12:36.876301
Epoch:[ 141 11 ] loss: 0.3594253957271576 2022-07-01 18:12:37.290593
Epoch:[ 141 12 ] loss: 0.3592298626899719 2022-07-01 18:12:37.706270
Epoch:[ 141 13 ] loss: 0.36130475997924805 2022-07-01 18:12:38.121669
Epoch:[ 141 14 ] loss: 0.3610808551311493 2022-07-01 18:12:38.535939
Epoch:[ 141 15 ] loss: 0.3615882992744446 2022-07-01 18:12:38.949420
Epoch:[ 141 16 ] loss: 0.3612063229084015 2022-07-01 18:12:44.752190
Epoch:[ 141 17 ] loss: 0.36387595534324646 2022-07-01 18:12:45.169405
Epoch:[ 141 18 ] loss: 0.3614223003387451 2022-07-01 18:12:45.591120
Epoch:[ 141 19 ] loss: 0.3612663745880127 2022-07-01 18:12:46.007172
Training_Epoch:[ 141 ] Training_loss: 0.3610218584537506 2022-07-01 18:12:46.007881
learning rate:  4.3980465111040044e-05
val: 1 0.3894979953765869
val: 2 0.38922417163848877
val: 3 0.3936885595321655
val: 4 0.38755854964256287
val: 5 0.38778114318847656
val: 6 0.39040157198905945
val: 7 0.40596550703048706
val: 8 0.3950183391571045
val: 9 0.3907538056373596
val: 10 0.3834361433982849
val: 11 0.3804011344909668
val: 12 0.3874644935131073
val: 13 0.38824233412742615
val: 14 0.3922826945781708
val: 15 0.4031212031841278
val: 16 0.3896058201789856
val: 17 0.39536306262016296
val: 18 0.3936716914176941
val: 19 0.3887137174606323
val: 20 0.38636359572410583
val_Epoch:[ 141 ] val_loss: 0.3909277766942978 2022-07-01 18:12:49.855650
start training 2022-07-01 18:12:49.957391
Epoch:[ 142 0 ] loss: 0.3600721061229706 2022-07-01 18:13:05.097036
Epoch:[ 142 1 ] loss: 0.3612118661403656 2022-07-01 18:13:05.514697
Epoch:[ 142 2 ] loss: 0.36201930046081543 2022-07-01 18:13:05.925851
Epoch:[ 142 3 ] loss: 0.3621219992637634 2022-07-01 18:13:06.340738
Epoch:[ 142 4 ] loss: 0.36159297823905945 2022-07-01 18:13:06.757122
Epoch:[ 142 5 ] loss: 0.3614005148410797 2022-07-01 18:13:07.171058
Epoch:[ 142 6 ] loss: 0.3604866564273834 2022-07-01 18:13:07.587310
Epoch:[ 142 7 ] loss: 0.3608062267303467 2022-07-01 18:13:08.005077
Epoch:[ 142 8 ] loss: 0.3602180778980255 2022-07-01 18:13:08.421133
Epoch:[ 142 9 ] loss: 0.3619327247142792 2022-07-01 18:13:08.834035
Epoch:[ 142 10 ] loss: 0.36093342304229736 2022-07-01 18:13:09.251569
Epoch:[ 142 11 ] loss: 0.36158686876296997 2022-07-01 18:13:09.660250
Epoch:[ 142 12 ] loss: 0.3609488904476166 2022-07-01 18:13:10.074925
Epoch:[ 142 13 ] loss: 0.3603082299232483 2022-07-01 18:13:10.486132
Epoch:[ 142 14 ] loss: 0.3609512448310852 2022-07-01 18:13:10.902067
Epoch:[ 142 15 ] loss: 0.3608129024505615 2022-07-01 18:13:11.322442
Epoch:[ 142 16 ] loss: 0.36192798614501953 2022-07-01 18:13:16.383221
Epoch:[ 142 17 ] loss: 0.3601005971431732 2022-07-01 18:13:16.797896
Epoch:[ 142 18 ] loss: 0.3606822192668915 2022-07-01 18:13:17.228160
Epoch:[ 142 19 ] loss: 0.3604170083999634 2022-07-01 18:13:17.656589
Training_Epoch:[ 142 ] Training_loss: 0.36102659106254575 2022-07-01 18:13:17.657349
learning rate:  4.3980465111040044e-05
netparams have been saved once 142
val: 1 0.39873483777046204
val: 2 0.39123958349227905
val: 3 0.3885563611984253
val: 4 0.39463797211647034
val: 5 0.3883410394191742
val: 6 0.3883989751338959
val: 7 0.39541566371917725
val: 8 0.3826740086078644
val: 9 0.39316195249557495
val: 10 0.3907569646835327
val: 11 0.3917957544326782
val: 12 0.3867080807685852
val: 13 0.3895016312599182
val: 14 0.38935357332229614
val: 15 0.3945672810077667
val: 16 0.40194785594940186
val: 17 0.3899557888507843
val: 18 0.39223068952560425
val: 19 0.38226041197776794
val: 20 0.3781093955039978
val_Epoch:[ 142 ] val_loss: 0.39041739106178286 2022-07-01 18:13:21.625448
start training 2022-07-01 18:13:21.730201
Epoch:[ 143 0 ] loss: 0.36231303215026855 2022-07-01 18:13:36.735090
Epoch:[ 143 1 ] loss: 0.36015424132347107 2022-07-01 18:13:37.151730
Epoch:[ 143 2 ] loss: 0.3617710471153259 2022-07-01 18:13:37.567422
Epoch:[ 143 3 ] loss: 0.3606717884540558 2022-07-01 18:13:37.982102
Epoch:[ 143 4 ] loss: 0.36071711778640747 2022-07-01 18:13:38.397191
Epoch:[ 143 5 ] loss: 0.3613424003124237 2022-07-01 18:13:38.811776
Epoch:[ 143 6 ] loss: 0.36132967472076416 2022-07-01 18:13:39.224685
Epoch:[ 143 7 ] loss: 0.3612079322338104 2022-07-01 18:13:39.636048
Epoch:[ 143 8 ] loss: 0.3608158528804779 2022-07-01 18:13:40.053480
Epoch:[ 143 9 ] loss: 0.3614371418952942 2022-07-01 18:13:40.468838
Epoch:[ 143 10 ] loss: 0.36090365052223206 2022-07-01 18:13:40.878653
Epoch:[ 143 11 ] loss: 0.36124399304389954 2022-07-01 18:13:41.294301
Epoch:[ 143 12 ] loss: 0.36021995544433594 2022-07-01 18:13:41.710836
Epoch:[ 143 13 ] loss: 0.3612068295478821 2022-07-01 18:13:42.125354
Epoch:[ 143 14 ] loss: 0.3598720133304596 2022-07-01 18:13:42.540681
Epoch:[ 143 15 ] loss: 0.36066699028015137 2022-07-01 18:13:42.962170
Epoch:[ 143 16 ] loss: 0.36088207364082336 2022-07-01 18:13:48.017202
Epoch:[ 143 17 ] loss: 0.36101865768432617 2022-07-01 18:13:48.424601
Epoch:[ 143 18 ] loss: 0.36064764857292175 2022-07-01 18:13:48.841085
Epoch:[ 143 19 ] loss: 0.3605063557624817 2022-07-01 18:13:49.255013
Training_Epoch:[ 143 ] Training_loss: 0.3609464198350906 2022-07-01 18:13:49.256018
learning rate:  4.3980465111040044e-05
val: 1 0.39440274238586426
val: 2 0.38761699199676514
val: 3 0.3962427079677582
val: 4 0.39071059226989746
val: 5 0.3875711262226105
val: 6 0.39967185258865356
val: 7 0.3905888497829437
val: 8 0.39918965101242065
val: 9 0.38989534974098206
val: 10 0.38493940234184265
val: 11 0.38747429847717285
val: 12 0.391922265291214
val: 13 0.3983270227909088
val: 14 0.3851071894168854
val: 15 0.3940439224243164
val: 16 0.3905119299888611
val: 17 0.38799309730529785
val: 18 0.38798099756240845
val: 19 0.39087679982185364
val: 20 0.381475031375885
val_Epoch:[ 143 ] val_loss: 0.3908270910382271 2022-07-01 18:13:53.667503
start training 2022-07-01 18:13:53.773026
Epoch:[ 144 0 ] loss: 0.361684113740921 2022-07-01 18:14:08.849415
Epoch:[ 144 1 ] loss: 0.36091846227645874 2022-07-01 18:14:09.286754
Epoch:[ 144 2 ] loss: 0.3590763807296753 2022-07-01 18:14:09.704786
Epoch:[ 144 3 ] loss: 0.3613412082195282 2022-07-01 18:14:10.119719
Epoch:[ 144 4 ] loss: 0.36152011156082153 2022-07-01 18:14:10.533775
Epoch:[ 144 5 ] loss: 0.3595751225948334 2022-07-01 18:14:10.944202
Epoch:[ 144 6 ] loss: 0.3600376546382904 2022-07-01 18:14:11.359713
Epoch:[ 144 7 ] loss: 0.360816091299057 2022-07-01 18:14:11.778400
Epoch:[ 144 8 ] loss: 0.3602439761161804 2022-07-01 18:14:12.209381
Epoch:[ 144 9 ] loss: 0.3604527711868286 2022-07-01 18:14:12.645324
Epoch:[ 144 10 ] loss: 0.3612370491027832 2022-07-01 18:14:13.074951
Epoch:[ 144 11 ] loss: 0.3606472313404083 2022-07-01 18:14:13.508838
Epoch:[ 144 12 ] loss: 0.36178624629974365 2022-07-01 18:14:13.938468
Epoch:[ 144 13 ] loss: 0.3612847626209259 2022-07-01 18:14:14.366791
Epoch:[ 144 14 ] loss: 0.36052051186561584 2022-07-01 18:14:14.795128
Epoch:[ 144 15 ] loss: 0.36028388142585754 2022-07-01 18:14:15.225405
Epoch:[ 144 16 ] loss: 0.3617514371871948 2022-07-01 18:14:20.303603
Epoch:[ 144 17 ] loss: 0.36219143867492676 2022-07-01 18:14:20.737543
Epoch:[ 144 18 ] loss: 0.3620857000350952 2022-07-01 18:14:21.176591
Epoch:[ 144 19 ] loss: 0.3602178394794464 2022-07-01 18:14:21.605256
Training_Epoch:[ 144 ] Training_loss: 0.3608835995197296 2022-07-01 18:14:21.606147
learning rate:  4.3980465111040044e-05
netparams have been saved once 144
val: 1 0.40095067024230957
val: 2 0.38684016466140747
val: 3 0.3876468241214752
val: 4 0.3949201703071594
val: 5 0.39597970247268677
val: 6 0.38730573654174805
val: 7 0.3842562437057495
val: 8 0.3872534930706024
val: 9 0.38768044114112854
val: 10 0.38511914014816284
val: 11 0.386699378490448
val: 12 0.386709064245224
val: 13 0.3942411243915558
val: 14 0.39736202359199524
val: 15 0.39502084255218506
val: 16 0.38982123136520386
val: 17 0.39490440487861633
val: 18 0.39289408922195435
val: 19 0.3920097351074219
val: 20 0.38762837648391724
val_Epoch:[ 144 ] val_loss: 0.3907621428370476 2022-07-01 18:14:25.629427
start training 2022-07-01 18:14:25.739117
Epoch:[ 145 0 ] loss: 0.36129412055015564 2022-07-01 18:14:39.917423
Epoch:[ 145 1 ] loss: 0.36027097702026367 2022-07-01 18:14:40.358001
Epoch:[ 145 2 ] loss: 0.36105233430862427 2022-07-01 18:14:40.789835
Epoch:[ 145 3 ] loss: 0.36102908849716187 2022-07-01 18:14:41.219894
Epoch:[ 145 4 ] loss: 0.3611522912979126 2022-07-01 18:14:41.655676
Epoch:[ 145 5 ] loss: 0.3611035645008087 2022-07-01 18:14:42.086188
Epoch:[ 145 6 ] loss: 0.3600550889968872 2022-07-01 18:14:42.516145
Epoch:[ 145 7 ] loss: 0.36090245842933655 2022-07-01 18:14:42.944335
Epoch:[ 145 8 ] loss: 0.36068660020828247 2022-07-01 18:14:43.373762
Epoch:[ 145 9 ] loss: 0.36049267649650574 2022-07-01 18:14:43.790039
Epoch:[ 145 10 ] loss: 0.3606123924255371 2022-07-01 18:14:44.207296
Epoch:[ 145 11 ] loss: 0.3610627353191376 2022-07-01 18:14:44.614515
Epoch:[ 145 12 ] loss: 0.3617478609085083 2022-07-01 18:14:45.030380
Epoch:[ 145 13 ] loss: 0.3612775206565857 2022-07-01 18:14:45.448826
Epoch:[ 145 14 ] loss: 0.36063480377197266 2022-07-01 18:14:45.856932
Epoch:[ 145 15 ] loss: 0.3595964312553406 2022-07-01 18:14:46.272535
Epoch:[ 145 16 ] loss: 0.3612850606441498 2022-07-01 18:14:51.835758
Epoch:[ 145 17 ] loss: 0.3612854778766632 2022-07-01 18:14:52.246779
Epoch:[ 145 18 ] loss: 0.36093106865882874 2022-07-01 18:14:52.683478
Epoch:[ 145 19 ] loss: 0.36058107018470764 2022-07-01 18:14:53.112304
Training_Epoch:[ 145 ] Training_loss: 0.3608526811003685 2022-07-01 18:14:53.113090
learning rate:  4.3980465111040044e-05
val: 1 0.3865417242050171
val: 2 0.38356813788414
val: 3 0.3898126184940338
val: 4 0.3880402743816376
val: 5 0.3917761743068695
val: 6 0.3869248330593109
val: 7 0.39719483256340027
val: 8 0.396759033203125
val: 9 0.3884154260158539
val: 10 0.39263299107551575
val: 11 0.3882007598876953
val: 12 0.3865310549736023
val: 13 0.3910735547542572
val: 14 0.39802005887031555
val: 15 0.3914911448955536
val: 16 0.3989904224872589
val: 17 0.3867059648036957
val: 18 0.38518619537353516
val: 19 0.3941335380077362
val: 20 0.3905685544013977
val_Epoch:[ 145 ] val_loss: 0.3906283646821976 2022-07-01 18:14:57.070815
start training 2022-07-01 18:14:57.172708
Epoch:[ 146 0 ] loss: 0.36089128255844116 2022-07-01 18:15:11.704049
Epoch:[ 146 1 ] loss: 0.3604567348957062 2022-07-01 18:15:12.139633
Epoch:[ 146 2 ] loss: 0.36141422390937805 2022-07-01 18:15:12.569000
Epoch:[ 146 3 ] loss: 0.35985541343688965 2022-07-01 18:15:13.000321
Epoch:[ 146 4 ] loss: 0.36094745993614197 2022-07-01 18:15:13.432038
Epoch:[ 146 5 ] loss: 0.3612934648990631 2022-07-01 18:15:13.865013
Epoch:[ 146 6 ] loss: 0.36003831028938293 2022-07-01 18:15:14.296990
Epoch:[ 146 7 ] loss: 0.36082717776298523 2022-07-01 18:15:14.727027
Epoch:[ 146 8 ] loss: 0.3620252311229706 2022-07-01 18:15:15.157105
Epoch:[ 146 9 ] loss: 0.3600102663040161 2022-07-01 18:15:15.591262
Epoch:[ 146 10 ] loss: 0.36195167899131775 2022-07-01 18:15:16.023846
Epoch:[ 146 11 ] loss: 0.36191892623901367 2022-07-01 18:15:16.455224
Epoch:[ 146 12 ] loss: 0.36092716455459595 2022-07-01 18:15:16.887253
Epoch:[ 146 13 ] loss: 0.36075299978256226 2022-07-01 18:15:17.317498
Epoch:[ 146 14 ] loss: 0.3604333996772766 2022-07-01 18:15:17.752343
Epoch:[ 146 15 ] loss: 0.36067265272140503 2022-07-01 18:15:18.181354
Epoch:[ 146 16 ] loss: 0.36159810423851013 2022-07-01 18:15:23.422027
Epoch:[ 146 17 ] loss: 0.3616206645965576 2022-07-01 18:15:23.851790
Epoch:[ 146 18 ] loss: 0.3602956235408783 2022-07-01 18:15:24.306765
Epoch:[ 146 19 ] loss: 0.3613624572753906 2022-07-01 18:15:24.735375
Training_Epoch:[ 146 ] Training_loss: 0.3609646618366241 2022-07-01 18:15:24.736161
learning rate:  4.3980465111040044e-05
netparams have been saved once 146
val: 1 0.3926238715648651
val: 2 0.3812960386276245
val: 3 0.39325419068336487
val: 4 0.39325448870658875
val: 5 0.38055601716041565
val: 6 0.38583266735076904
val: 7 0.39001569151878357
val: 8 0.38916972279548645
val: 9 0.3786754310131073
val: 10 0.39101284742355347
val: 11 0.40531158447265625
val: 12 0.39697861671447754
val: 13 0.3968254029750824
val: 14 0.38629335165023804
val: 15 0.3912805914878845
val: 16 0.39158618450164795
val: 17 0.3944717347621918
val: 18 0.3908049166202545
val: 19 0.38848578929901123
val: 20 0.39047688245773315
val_Epoch:[ 146 ] val_loss: 0.3904103010892868 2022-07-01 18:15:28.635527
start training 2022-07-01 18:15:28.737845
Epoch:[ 147 0 ] loss: 0.3609224557876587 2022-07-01 18:15:43.479154
Epoch:[ 147 1 ] loss: 0.360641211271286 2022-07-01 18:15:43.908811
Epoch:[ 147 2 ] loss: 0.36142441630363464 2022-07-01 18:15:44.339870
Epoch:[ 147 3 ] loss: 0.3607073724269867 2022-07-01 18:15:44.773365
Epoch:[ 147 4 ] loss: 0.3626728653907776 2022-07-01 18:15:45.204404
Epoch:[ 147 5 ] loss: 0.36179274320602417 2022-07-01 18:15:45.634845
Epoch:[ 147 6 ] loss: 0.3612879514694214 2022-07-01 18:15:46.068021
Epoch:[ 147 7 ] loss: 0.3603038489818573 2022-07-01 18:15:46.497204
Epoch:[ 147 8 ] loss: 0.36086976528167725 2022-07-01 18:15:46.927275
Epoch:[ 147 9 ] loss: 0.36092525720596313 2022-07-01 18:15:47.355542
Epoch:[ 147 10 ] loss: 0.35938653349876404 2022-07-01 18:15:47.784774
Epoch:[ 147 11 ] loss: 0.3612639605998993 2022-07-01 18:15:48.223106
Epoch:[ 147 12 ] loss: 0.36109158396720886 2022-07-01 18:15:48.659671
Epoch:[ 147 13 ] loss: 0.36109670996665955 2022-07-01 18:15:49.088522
Epoch:[ 147 14 ] loss: 0.36081087589263916 2022-07-01 18:15:49.516539
Epoch:[ 147 15 ] loss: 0.3608625531196594 2022-07-01 18:15:49.947574
Epoch:[ 147 16 ] loss: 0.36117517948150635 2022-07-01 18:15:54.969557
Epoch:[ 147 17 ] loss: 0.3605474531650543 2022-07-01 18:15:55.440491
Epoch:[ 147 18 ] loss: 0.36045026779174805 2022-07-01 18:15:55.884551
Epoch:[ 147 19 ] loss: 0.36074918508529663 2022-07-01 18:15:56.313963
Training_Epoch:[ 147 ] Training_loss: 0.3609491094946861 2022-07-01 18:15:56.314588
learning rate:  4.3980465111040044e-05
val: 1 0.39184653759002686
val: 2 0.38801077008247375
val: 3 0.3878403306007385
val: 4 0.3878931701183319
val: 5 0.39640191197395325
val: 6 0.393598347902298
val: 7 0.39081835746765137
val: 8 0.3857196271419525
val: 9 0.3877589702606201
val: 10 0.3921150267124176
val: 11 0.3839981257915497
val: 12 0.38953444361686707
val: 13 0.39597636461257935
val: 14 0.3983052372932434
val: 15 0.38280561566352844
val: 16 0.3961106836795807
val: 17 0.39160871505737305
val: 18 0.39073747396469116
val: 19 0.3945326805114746
val: 20 0.3959707021713257
val_Epoch:[ 147 ] val_loss: 0.39107915461063386 2022-07-01 18:16:00.251149
start training 2022-07-01 18:16:00.354140
Epoch:[ 148 0 ] loss: 0.36141249537467957 2022-07-01 18:16:15.021883
Epoch:[ 148 1 ] loss: 0.36074602603912354 2022-07-01 18:16:15.452674
Epoch:[ 148 2 ] loss: 0.3608481287956238 2022-07-01 18:16:15.884283
Epoch:[ 148 3 ] loss: 0.36136868596076965 2022-07-01 18:16:16.316723
Epoch:[ 148 4 ] loss: 0.3603335916996002 2022-07-01 18:16:16.746981
Epoch:[ 148 5 ] loss: 0.36171677708625793 2022-07-01 18:16:17.179161
Epoch:[ 148 6 ] loss: 0.3601255714893341 2022-07-01 18:16:17.609540
Epoch:[ 148 7 ] loss: 0.3617578446865082 2022-07-01 18:16:18.046575
Epoch:[ 148 8 ] loss: 0.36048394441604614 2022-07-01 18:16:18.476774
Epoch:[ 148 9 ] loss: 0.36196956038475037 2022-07-01 18:16:18.909802
Epoch:[ 148 10 ] loss: 0.36118432879447937 2022-07-01 18:16:19.347208
Epoch:[ 148 11 ] loss: 0.3605765104293823 2022-07-01 18:16:19.776840
Epoch:[ 148 12 ] loss: 0.3607727885246277 2022-07-01 18:16:20.209227
Epoch:[ 148 13 ] loss: 0.3608020544052124 2022-07-01 18:16:20.643851
Epoch:[ 148 14 ] loss: 0.36211690306663513 2022-07-01 18:16:21.074315
Epoch:[ 148 15 ] loss: 0.36126357316970825 2022-07-01 18:16:21.507873
Epoch:[ 148 16 ] loss: 0.3605875074863434 2022-07-01 18:16:27.107121
Epoch:[ 148 17 ] loss: 0.36151644587516785 2022-07-01 18:16:27.534195
Epoch:[ 148 18 ] loss: 0.3600010275840759 2022-07-01 18:16:27.990382
Epoch:[ 148 19 ] loss: 0.36004361510276794 2022-07-01 18:16:28.427968
Training_Epoch:[ 148 ] Training_loss: 0.3609813690185547 2022-07-01 18:16:28.428829
learning rate:  4.3980465111040044e-05
netparams have been saved once 148
val: 1 0.39290371537208557
val: 2 0.39177384972572327
val: 3 0.4002380967140198
val: 4 0.38895905017852783
val: 5 0.37870606780052185
val: 6 0.3889274299144745
val: 7 0.39433544874191284
val: 8 0.3926693797111511
val: 9 0.39228522777557373
val: 10 0.39468997716903687
val: 11 0.398595929145813
val: 12 0.38709065318107605
val: 13 0.3914806842803955
val: 14 0.39367344975471497
val: 15 0.38762956857681274
val: 16 0.39033910632133484
val: 17 0.38571226596832275
val: 18 0.39411455392837524
val: 19 0.39164993166923523
val: 20 0.3861173391342163
val_Epoch:[ 148 ] val_loss: 0.3910945862531662 2022-07-01 18:16:32.406427
start training 2022-07-01 18:16:32.514052
Epoch:[ 149 0 ] loss: 0.3601642847061157 2022-07-01 18:16:47.749652
Epoch:[ 149 1 ] loss: 0.36000970005989075 2022-07-01 18:16:48.182146
Epoch:[ 149 2 ] loss: 0.36096489429473877 2022-07-01 18:16:48.611372
Epoch:[ 149 3 ] loss: 0.3619145452976227 2022-07-01 18:16:49.045038
Epoch:[ 149 4 ] loss: 0.36115384101867676 2022-07-01 18:16:49.475478
Epoch:[ 149 5 ] loss: 0.3601683974266052 2022-07-01 18:16:49.910514
Epoch:[ 149 6 ] loss: 0.361083984375 2022-07-01 18:16:50.342521
Epoch:[ 149 7 ] loss: 0.3611207902431488 2022-07-01 18:16:50.781867
Epoch:[ 149 8 ] loss: 0.3607708513736725 2022-07-01 18:16:51.215716
Epoch:[ 149 9 ] loss: 0.36226239800453186 2022-07-01 18:16:51.648059
Epoch:[ 149 10 ] loss: 0.3613932132720947 2022-07-01 18:16:52.078011
Epoch:[ 149 11 ] loss: 0.3624694347381592 2022-07-01 18:16:52.509417
Epoch:[ 149 12 ] loss: 0.35942867398262024 2022-07-01 18:16:52.939317
Epoch:[ 149 13 ] loss: 0.3599446713924408 2022-07-01 18:16:53.376052
Epoch:[ 149 14 ] loss: 0.3619183599948883 2022-07-01 18:16:53.807815
Epoch:[ 149 15 ] loss: 0.36154165863990784 2022-07-01 18:16:54.238768
Epoch:[ 149 16 ] loss: 0.3606785535812378 2022-07-01 18:16:59.662469
Epoch:[ 149 17 ] loss: 0.359904408454895 2022-07-01 18:17:00.094137
Epoch:[ 149 18 ] loss: 0.35995274782180786 2022-07-01 18:17:00.544379
Epoch:[ 149 19 ] loss: 0.3605654537677765 2022-07-01 18:17:00.979983
Training_Epoch:[ 149 ] Training_loss: 0.36087054312229155 2022-07-01 18:17:00.980721
learning rate:  4.3980465111040044e-05
val: 1 0.39183005690574646
val: 2 0.3905373215675354
val: 3 0.3874667286872864
val: 4 0.38391610980033875
val: 5 0.38795602321624756
val: 6 0.3844347596168518
val: 7 0.38662630319595337
val: 8 0.3860015869140625
val: 9 0.38740846514701843
val: 10 0.39345279335975647
val: 11 0.39811497926712036
val: 12 0.39160799980163574
val: 13 0.39152801036834717
val: 14 0.39208871126174927
val: 15 0.3902438282966614
val: 16 0.3863363564014435
val: 17 0.3973442316055298
val: 18 0.3949405252933502
val: 19 0.3994652330875397
val: 20 0.3861866295337677
val_Epoch:[ 149 ] val_loss: 0.3903743326663971 2022-07-01 18:17:04.891632
start training 2022-07-01 18:17:04.997052
Epoch:[ 150 0 ] loss: 0.3618890047073364 2022-07-01 18:17:20.246128
Epoch:[ 150 1 ] loss: 0.3614293932914734 2022-07-01 18:17:20.683546
Epoch:[ 150 2 ] loss: 0.3597443103790283 2022-07-01 18:17:21.113858
Epoch:[ 150 3 ] loss: 0.3610275387763977 2022-07-01 18:17:21.547185
Epoch:[ 150 4 ] loss: 0.3617595136165619 2022-07-01 18:17:21.998221
Epoch:[ 150 5 ] loss: 0.36024540662765503 2022-07-01 18:17:22.433149
Epoch:[ 150 6 ] loss: 0.36052176356315613 2022-07-01 18:17:22.869130
Epoch:[ 150 7 ] loss: 0.3609301447868347 2022-07-01 18:17:23.302311
Epoch:[ 150 8 ] loss: 0.3604636490345001 2022-07-01 18:17:23.733813
Epoch:[ 150 9 ] loss: 0.3609122931957245 2022-07-01 18:17:24.167459
Epoch:[ 150 10 ] loss: 0.3602462410926819 2022-07-01 18:17:24.597405
Epoch:[ 150 11 ] loss: 0.3621135652065277 2022-07-01 18:17:25.032193
Epoch:[ 150 12 ] loss: 0.3610319495201111 2022-07-01 18:17:25.465392
Epoch:[ 150 13 ] loss: 0.3611541986465454 2022-07-01 18:17:25.895108
Epoch:[ 150 14 ] loss: 0.36032575368881226 2022-07-01 18:17:26.327735
Epoch:[ 150 15 ] loss: 0.3608619272708893 2022-07-01 18:17:26.758412
Epoch:[ 150 16 ] loss: 0.35977378487586975 2022-07-01 18:17:32.101897
Epoch:[ 150 17 ] loss: 0.3615497350692749 2022-07-01 18:17:32.535874
Epoch:[ 150 18 ] loss: 0.36069950461387634 2022-07-01 18:17:32.985104
Epoch:[ 150 19 ] loss: 0.3611837923526764 2022-07-01 18:17:33.417873
Training_Epoch:[ 150 ] Training_loss: 0.36089317351579664 2022-07-01 18:17:33.418569
learning rate:  4.3980465111040044e-05
netparams have been saved once 150
val: 1 0.3973454535007477
val: 2 0.3880034387111664
val: 3 0.38307827711105347
val: 4 0.385955274105072
val: 5 0.38505032658576965
val: 6 0.3880762457847595
val: 7 0.3840335011482239
val: 8 0.38869503140449524
val: 9 0.38878464698791504
val: 10 0.3940456509590149
val: 11 0.39609119296073914
val: 12 0.3904150128364563
val: 13 0.40405067801475525
val: 14 0.3905377984046936
val: 15 0.3891351819038391
val: 16 0.3957865834236145
val: 17 0.39207741618156433
val: 18 0.3939494788646698
val: 19 0.3948584794998169
val: 20 0.39449214935302734
val_Epoch:[ 150 ] val_loss: 0.3912230908870697 2022-07-01 18:17:37.331705
start training 2022-07-01 18:17:37.440657
Epoch:[ 151 0 ] loss: 0.3608364462852478 2022-07-01 18:17:51.833218
Epoch:[ 151 1 ] loss: 0.3604421019554138 2022-07-01 18:17:52.293840
Epoch:[ 151 2 ] loss: 0.3598809540271759 2022-07-01 18:17:52.727753
Epoch:[ 151 3 ] loss: 0.36023232340812683 2022-07-01 18:17:53.163096
Epoch:[ 151 4 ] loss: 0.36197584867477417 2022-07-01 18:17:53.593012
Epoch:[ 151 5 ] loss: 0.36199015378952026 2022-07-01 18:17:54.023587
Epoch:[ 151 6 ] loss: 0.36155617237091064 2022-07-01 18:17:54.453390
Epoch:[ 151 7 ] loss: 0.3613615036010742 2022-07-01 18:17:54.884151
Epoch:[ 151 8 ] loss: 0.35988542437553406 2022-07-01 18:17:55.317323
Epoch:[ 151 9 ] loss: 0.35985368490219116 2022-07-01 18:17:55.752485
Epoch:[ 151 10 ] loss: 0.35979771614074707 2022-07-01 18:17:56.192527
Epoch:[ 151 11 ] loss: 0.35990139842033386 2022-07-01 18:17:56.625281
Epoch:[ 151 12 ] loss: 0.3605281114578247 2022-07-01 18:17:57.060369
Epoch:[ 151 13 ] loss: 0.36102020740509033 2022-07-01 18:17:57.499164
Epoch:[ 151 14 ] loss: 0.36169904470443726 2022-07-01 18:17:57.929767
Epoch:[ 151 15 ] loss: 0.36244192719459534 2022-07-01 18:17:58.364733
Epoch:[ 151 16 ] loss: 0.36121034622192383 2022-07-01 18:18:03.597946
Epoch:[ 151 17 ] loss: 0.36008232831954956 2022-07-01 18:18:04.033791
Epoch:[ 151 18 ] loss: 0.36242756247520447 2022-07-01 18:18:04.472924
Epoch:[ 151 19 ] loss: 0.3611888885498047 2022-07-01 18:18:04.910944
Training_Epoch:[ 151 ] Training_loss: 0.360915607213974 2022-07-01 18:18:04.911675
learning rate:  3.5184372088832036e-05
val: 1 0.38211673498153687
val: 2 0.38731321692466736
val: 3 0.38218140602111816
val: 4 0.38431721925735474
val: 5 0.3930758535861969
val: 6 0.39312106370925903
val: 7 0.3952275216579437
val: 8 0.39235958456993103
val: 9 0.39390960335731506
val: 10 0.380984902381897
val: 11 0.38751769065856934
val: 12 0.3951447606086731
val: 13 0.3922866880893707
val: 14 0.39550265669822693
val: 15 0.39478394389152527
val: 16 0.38897860050201416
val: 17 0.39193394780158997
val: 18 0.3993905782699585
val: 19 0.3921665847301483
val: 20 0.3883921504020691
val_Epoch:[ 151 ] val_loss: 0.39053523540496826 2022-07-01 18:18:08.779484
start training 2022-07-01 18:18:08.883631
Epoch:[ 152 0 ] loss: 0.36189505457878113 2022-07-01 18:18:23.178044
Epoch:[ 152 1 ] loss: 0.36205217242240906 2022-07-01 18:18:23.627511
Epoch:[ 152 2 ] loss: 0.36145490407943726 2022-07-01 18:18:24.057963
Epoch:[ 152 3 ] loss: 0.3610002100467682 2022-07-01 18:18:24.488783
Epoch:[ 152 4 ] loss: 0.36096513271331787 2022-07-01 18:18:24.921686
Epoch:[ 152 5 ] loss: 0.36050933599472046 2022-07-01 18:18:25.380632
Epoch:[ 152 6 ] loss: 0.3596089482307434 2022-07-01 18:18:25.817176
Epoch:[ 152 7 ] loss: 0.36030569672584534 2022-07-01 18:18:26.245181
Epoch:[ 152 8 ] loss: 0.36126816272735596 2022-07-01 18:18:26.660399
Epoch:[ 152 9 ] loss: 0.36141079664230347 2022-07-01 18:18:27.075849
Epoch:[ 152 10 ] loss: 0.35907670855522156 2022-07-01 18:18:27.492935
Epoch:[ 152 11 ] loss: 0.36140918731689453 2022-07-01 18:18:27.902907
Epoch:[ 152 12 ] loss: 0.3598048985004425 2022-07-01 18:18:28.318091
Epoch:[ 152 13 ] loss: 0.36054131388664246 2022-07-01 18:18:28.732921
Epoch:[ 152 14 ] loss: 0.36069655418395996 2022-07-01 18:18:29.148268
Epoch:[ 152 15 ] loss: 0.3607650101184845 2022-07-01 18:18:29.562475
Epoch:[ 152 16 ] loss: 0.36153316497802734 2022-07-01 18:18:34.801408
Epoch:[ 152 17 ] loss: 0.3613857924938202 2022-07-01 18:18:35.309096
Epoch:[ 152 18 ] loss: 0.36054527759552 2022-07-01 18:18:35.747003
Epoch:[ 152 19 ] loss: 0.3606339693069458 2022-07-01 18:18:36.179347
Training_Epoch:[ 152 ] Training_loss: 0.36084311455488205 2022-07-01 18:18:36.180095
learning rate:  3.5184372088832036e-05
netparams have been saved once 152
val: 1 0.38634952902793884
val: 2 0.3834788501262665
val: 3 0.392997145652771
val: 4 0.3907490372657776
val: 5 0.39013588428497314
val: 6 0.39193883538246155
val: 7 0.3863075375556946
val: 8 0.39119768142700195
val: 9 0.39134228229522705
val: 10 0.3907277286052704
val: 11 0.3848736584186554
val: 12 0.3854627013206482
val: 13 0.388240784406662
val: 14 0.3988693654537201
val: 15 0.3937976360321045
val: 16 0.3955099880695343
val: 17 0.39233261346817017
val: 18 0.39406734704971313
val: 19 0.3891478180885315
val: 20 0.3969598114490509
val_Epoch:[ 152 ] val_loss: 0.3907243117690086 2022-07-01 18:18:40.085621
start training 2022-07-01 18:18:40.193879
Epoch:[ 153 0 ] loss: 0.3613090515136719 2022-07-01 18:18:54.430436
Epoch:[ 153 1 ] loss: 0.3611032962799072 2022-07-01 18:18:54.858024
Epoch:[ 153 2 ] loss: 0.3611660301685333 2022-07-01 18:18:55.287953
Epoch:[ 153 3 ] loss: 0.36060044169425964 2022-07-01 18:18:55.711646
Epoch:[ 153 4 ] loss: 0.3609466850757599 2022-07-01 18:18:56.128751
Epoch:[ 153 5 ] loss: 0.36041706800460815 2022-07-01 18:18:56.543949
Epoch:[ 153 6 ] loss: 0.3606831133365631 2022-07-01 18:18:56.953481
Epoch:[ 153 7 ] loss: 0.3606822192668915 2022-07-01 18:18:57.369089
Epoch:[ 153 8 ] loss: 0.3602689206600189 2022-07-01 18:18:57.783978
Epoch:[ 153 9 ] loss: 0.36036190390586853 2022-07-01 18:18:58.192866
Epoch:[ 153 10 ] loss: 0.36111128330230713 2022-07-01 18:18:58.604546
Epoch:[ 153 11 ] loss: 0.3607267439365387 2022-07-01 18:18:59.020853
Epoch:[ 153 12 ] loss: 0.36192864179611206 2022-07-01 18:18:59.440140
Epoch:[ 153 13 ] loss: 0.3602714240550995 2022-07-01 18:18:59.855197
Epoch:[ 153 14 ] loss: 0.36113888025283813 2022-07-01 18:19:00.269621
Epoch:[ 153 15 ] loss: 0.3605712652206421 2022-07-01 18:19:00.685660
Epoch:[ 153 16 ] loss: 0.3608812391757965 2022-07-01 18:19:06.553418
Epoch:[ 153 17 ] loss: 0.3606331944465637 2022-07-01 18:19:06.963067
Epoch:[ 153 18 ] loss: 0.3597569167613983 2022-07-01 18:19:07.406851
Epoch:[ 153 19 ] loss: 0.36031240224838257 2022-07-01 18:19:07.821682
Training_Epoch:[ 153 ] Training_loss: 0.360743536055088 2022-07-01 18:19:07.822733
learning rate:  3.5184372088832036e-05
val: 1 0.3896138072013855
val: 2 0.39378872513771057
val: 3 0.38553187251091003
val: 4 0.38920122385025024
val: 5 0.3939187824726105
val: 6 0.39337900280952454
val: 7 0.38767316937446594
val: 8 0.3912877142429352
val: 9 0.3912978172302246
val: 10 0.38646697998046875
val: 11 0.3968416154384613
val: 12 0.394378125667572
val: 13 0.3881343603134155
val: 14 0.3997355103492737
val: 15 0.39398816227912903
val: 16 0.3812806308269501
val: 17 0.3964192271232605
val: 18 0.39460134506225586
val: 19 0.384893000125885
val: 20 0.3903132975101471
val_Epoch:[ 153 ] val_loss: 0.3911372184753418 2022-07-01 18:19:11.854834
start training 2022-07-01 18:19:11.963699
Epoch:[ 154 0 ] loss: 0.35999050736427307 2022-07-01 18:19:26.773012
Epoch:[ 154 1 ] loss: 0.36069610714912415 2022-07-01 18:19:27.202999
Epoch:[ 154 2 ] loss: 0.36131972074508667 2022-07-01 18:19:27.632743
Epoch:[ 154 3 ] loss: 0.3612748384475708 2022-07-01 18:19:28.061736
Epoch:[ 154 4 ] loss: 0.36002302169799805 2022-07-01 18:19:28.499163
Epoch:[ 154 5 ] loss: 0.3613918125629425 2022-07-01 18:19:28.929260
Epoch:[ 154 6 ] loss: 0.3612554371356964 2022-07-01 18:19:29.359713
Epoch:[ 154 7 ] loss: 0.3599960207939148 2022-07-01 18:19:29.788977
Epoch:[ 154 8 ] loss: 0.3605314791202545 2022-07-01 18:19:30.220468
Epoch:[ 154 9 ] loss: 0.36047351360321045 2022-07-01 18:19:30.649232
Epoch:[ 154 10 ] loss: 0.3596258759498596 2022-07-01 18:19:31.076839
Epoch:[ 154 11 ] loss: 0.36285731196403503 2022-07-01 18:19:31.509065
Epoch:[ 154 12 ] loss: 0.36138203740119934 2022-07-01 18:19:31.946500
Epoch:[ 154 13 ] loss: 0.3618320822715759 2022-07-01 18:19:32.376044
Epoch:[ 154 14 ] loss: 0.36181584000587463 2022-07-01 18:19:32.804688
Epoch:[ 154 15 ] loss: 0.36049142479896545 2022-07-01 18:19:33.240276
Epoch:[ 154 16 ] loss: 0.359948992729187 2022-07-01 18:19:38.350641
Epoch:[ 154 17 ] loss: 0.36029207706451416 2022-07-01 18:19:38.780652
Epoch:[ 154 18 ] loss: 0.3598351776599884 2022-07-01 18:19:39.219831
Epoch:[ 154 19 ] loss: 0.3614090383052826 2022-07-01 18:19:39.655912
Training_Epoch:[ 154 ] Training_loss: 0.3608221158385277 2022-07-01 18:19:39.656618
learning rate:  3.5184372088832036e-05
netparams have been saved once 154
val: 1 0.3976515233516693
val: 2 0.38910871744155884
val: 3 0.38588160276412964
val: 4 0.39325013756752014
val: 5 0.38772550225257874
val: 6 0.3846541941165924
val: 7 0.39449670910835266
val: 8 0.39890074729919434
val: 9 0.3829127550125122
val: 10 0.386412650346756
val: 11 0.3864567279815674
val: 12 0.3919248580932617
val: 13 0.38925257325172424
val: 14 0.3932619094848633
val: 15 0.396901398897171
val: 16 0.3937693238258362
val: 17 0.3962160348892212
val: 18 0.385784775018692
val: 19 0.390555202960968
val: 20 0.3915800154209137
val_Epoch:[ 154 ] val_loss: 0.39083486795425415 2022-07-01 18:19:43.547711
start training 2022-07-01 18:19:43.652193
Epoch:[ 155 0 ] loss: 0.36050698161125183 2022-07-01 18:19:58.774803
Epoch:[ 155 1 ] loss: 0.36103397607803345 2022-07-01 18:19:59.203731
Epoch:[ 155 2 ] loss: 0.3611128330230713 2022-07-01 18:19:59.633800
Epoch:[ 155 3 ] loss: 0.3608245849609375 2022-07-01 18:20:00.061807
Epoch:[ 155 4 ] loss: 0.3602624833583832 2022-07-01 18:20:00.493172
Epoch:[ 155 5 ] loss: 0.35990962386131287 2022-07-01 18:20:00.923431
Epoch:[ 155 6 ] loss: 0.3600235879421234 2022-07-01 18:20:01.354401
Epoch:[ 155 7 ] loss: 0.36054688692092896 2022-07-01 18:20:01.783965
Epoch:[ 155 8 ] loss: 0.3599952161312103 2022-07-01 18:20:02.218713
Epoch:[ 155 9 ] loss: 0.3601895272731781 2022-07-01 18:20:02.650009
Epoch:[ 155 10 ] loss: 0.3630395829677582 2022-07-01 18:20:03.079945
Epoch:[ 155 11 ] loss: 0.36048299074172974 2022-07-01 18:20:03.508842
Epoch:[ 155 12 ] loss: 0.3617875277996063 2022-07-01 18:20:03.939911
Epoch:[ 155 13 ] loss: 0.36009687185287476 2022-07-01 18:20:04.375304
Epoch:[ 155 14 ] loss: 0.3612263798713684 2022-07-01 18:20:04.810378
Epoch:[ 155 15 ] loss: 0.36045923829078674 2022-07-01 18:20:05.239912
Epoch:[ 155 16 ] loss: 0.3613039255142212 2022-07-01 18:20:10.158361
Epoch:[ 155 17 ] loss: 0.36094003915786743 2022-07-01 18:20:10.586818
Epoch:[ 155 18 ] loss: 0.3617159128189087 2022-07-01 18:20:11.026988
Epoch:[ 155 19 ] loss: 0.36170417070388794 2022-07-01 18:20:11.459964
Training_Epoch:[ 155 ] Training_loss: 0.360858117043972 2022-07-01 18:20:11.460667
learning rate:  3.5184372088832036e-05
val: 1 0.39268386363983154
val: 2 0.3906310200691223
val: 3 0.394214928150177
val: 4 0.3931290805339813
val: 5 0.4016473889350891
val: 6 0.38752105832099915
val: 7 0.39559999108314514
val: 8 0.39303383231163025
val: 9 0.3785974979400635
val: 10 0.3895748257637024
val: 11 0.3927719295024872
val: 12 0.39276501536369324
val: 13 0.39386042952537537
val: 14 0.3869175612926483
val: 15 0.38664403557777405
val: 16 0.3905424177646637
val: 17 0.3854158818721771
val: 18 0.3807372748851776
val: 19 0.4065234065055847
val: 20 0.38455721735954285
val_Epoch:[ 155 ] val_loss: 0.3908684328198433 2022-07-01 18:20:15.326387
start training 2022-07-01 18:20:15.433508
Epoch:[ 156 0 ] loss: 0.35970568656921387 2022-07-01 18:20:30.159210
Epoch:[ 156 1 ] loss: 0.36136236786842346 2022-07-01 18:20:30.588929
Epoch:[ 156 2 ] loss: 0.3617228865623474 2022-07-01 18:20:31.018486
Epoch:[ 156 3 ] loss: 0.3598083257675171 2022-07-01 18:20:31.449218
Epoch:[ 156 4 ] loss: 0.36114636063575745 2022-07-01 18:20:31.878430
Epoch:[ 156 5 ] loss: 0.35967007279396057 2022-07-01 18:20:32.308187
Epoch:[ 156 6 ] loss: 0.3606081008911133 2022-07-01 18:20:32.739744
Epoch:[ 156 7 ] loss: 0.36100515723228455 2022-07-01 18:20:33.170531
Epoch:[ 156 8 ] loss: 0.36095598340034485 2022-07-01 18:20:33.601006
Epoch:[ 156 9 ] loss: 0.36092251539230347 2022-07-01 18:20:34.029890
Epoch:[ 156 10 ] loss: 0.3608490228652954 2022-07-01 18:20:34.464223
Epoch:[ 156 11 ] loss: 0.3601120710372925 2022-07-01 18:20:34.898756
Epoch:[ 156 12 ] loss: 0.3612450361251831 2022-07-01 18:20:35.332292
Epoch:[ 156 13 ] loss: 0.35940033197402954 2022-07-01 18:20:35.768166
Epoch:[ 156 14 ] loss: 0.3613138496875763 2022-07-01 18:20:36.200171
Epoch:[ 156 15 ] loss: 0.36159443855285645 2022-07-01 18:20:36.630022
Epoch:[ 156 16 ] loss: 0.3606897294521332 2022-07-01 18:20:41.909755
Epoch:[ 156 17 ] loss: 0.36129698157310486 2022-07-01 18:20:42.341930
Epoch:[ 156 18 ] loss: 0.36189863085746765 2022-07-01 18:20:42.781986
Epoch:[ 156 19 ] loss: 0.36096251010894775 2022-07-01 18:20:43.211312
Training_Epoch:[ 156 ] Training_loss: 0.36081350296735765 2022-07-01 18:20:43.211955
learning rate:  3.5184372088832036e-05
netparams have been saved once 156
val: 1 0.3896992802619934
val: 2 0.3818168342113495
val: 3 0.3963440954685211
val: 4 0.3933766484260559
val: 5 0.38875067234039307
val: 6 0.39282485842704773
val: 7 0.3969610929489136
val: 8 0.3908219337463379
val: 9 0.3951866924762726
val: 10 0.3910222053527832
val: 11 0.3808937072753906
val: 12 0.39642515778541565
val: 13 0.3889765441417694
val: 14 0.3852209150791168
val: 15 0.390890896320343
val: 16 0.38765761256217957
val: 17 0.4006129205226898
val: 18 0.3847677409648895
val: 19 0.39147812128067017
val: 20 0.3905984163284302
val_Epoch:[ 156 ] val_loss: 0.3907163172960281 2022-07-01 18:20:47.087954
start training 2022-07-01 18:20:47.191480
Epoch:[ 157 0 ] loss: 0.36116859316825867 2022-07-01 18:21:01.840336
Epoch:[ 157 1 ] loss: 0.3606521487236023 2022-07-01 18:21:02.269947
Epoch:[ 157 2 ] loss: 0.3622191548347473 2022-07-01 18:21:02.703921
Epoch:[ 157 3 ] loss: 0.36103206872940063 2022-07-01 18:21:03.132932
Epoch:[ 157 4 ] loss: 0.3618306815624237 2022-07-01 18:21:03.569364
Epoch:[ 157 5 ] loss: 0.3610086441040039 2022-07-01 18:21:03.998614
Epoch:[ 157 6 ] loss: 0.3605749309062958 2022-07-01 18:21:04.428359
Epoch:[ 157 7 ] loss: 0.36110255122184753 2022-07-01 18:21:04.858998
Epoch:[ 157 8 ] loss: 0.3608086407184601 2022-07-01 18:21:05.290848
Epoch:[ 157 9 ] loss: 0.35988685488700867 2022-07-01 18:21:05.720481
Epoch:[ 157 10 ] loss: 0.36142998933792114 2022-07-01 18:21:06.148802
Epoch:[ 157 11 ] loss: 0.36106187105178833 2022-07-01 18:21:06.584668
Epoch:[ 157 12 ] loss: 0.3607265055179596 2022-07-01 18:21:07.016177
Epoch:[ 157 13 ] loss: 0.36078134179115295 2022-07-01 18:21:07.445290
Epoch:[ 157 14 ] loss: 0.36063680052757263 2022-07-01 18:21:07.875336
Epoch:[ 157 15 ] loss: 0.36128973960876465 2022-07-01 18:21:08.305356
Epoch:[ 157 16 ] loss: 0.36060184240341187 2022-07-01 18:21:13.454225
Epoch:[ 157 17 ] loss: 0.359960675239563 2022-07-01 18:21:13.883707
Epoch:[ 157 18 ] loss: 0.3601688742637634 2022-07-01 18:21:14.319415
Epoch:[ 157 19 ] loss: 0.3608092963695526 2022-07-01 18:21:14.751538
Training_Epoch:[ 157 ] Training_loss: 0.36088756024837493 2022-07-01 18:21:14.752186
learning rate:  3.5184372088832036e-05
val: 1 0.3870249092578888
val: 2 0.3999671936035156
val: 3 0.3864240348339081
val: 4 0.3831605911254883
val: 5 0.39078351855278015
val: 6 0.3948003053665161
val: 7 0.387098491191864
val: 8 0.39132827520370483
val: 9 0.3903527557849884
val: 10 0.39461779594421387
val: 11 0.3923642337322235
val: 12 0.39699822664260864
val: 13 0.3905242681503296
val: 14 0.39346012473106384
val: 15 0.3863634765148163
val: 16 0.39443108439445496
val: 17 0.3833411931991577
val: 18 0.38672176003456116
val: 19 0.3908565938472748
val: 20 0.39500805735588074
val_Epoch:[ 157 ] val_loss: 0.390781344473362 2022-07-01 18:21:18.602975
start training 2022-07-01 18:21:18.708269
Epoch:[ 158 0 ] loss: 0.36034947633743286 2022-07-01 18:21:33.117529
Epoch:[ 158 1 ] loss: 0.36176374554634094 2022-07-01 18:21:33.566366
Epoch:[ 158 2 ] loss: 0.3611997961997986 2022-07-01 18:21:33.996760
Epoch:[ 158 3 ] loss: 0.36066004633903503 2022-07-01 18:21:34.427211
Epoch:[ 158 4 ] loss: 0.36217111349105835 2022-07-01 18:21:34.861406
Epoch:[ 158 5 ] loss: 0.36148861050605774 2022-07-01 18:21:35.276350
Epoch:[ 158 6 ] loss: 0.3602145314216614 2022-07-01 18:21:35.693569
Epoch:[ 158 7 ] loss: 0.36007627844810486 2022-07-01 18:21:36.108042
Epoch:[ 158 8 ] loss: 0.3626348376274109 2022-07-01 18:21:36.517186
Epoch:[ 158 9 ] loss: 0.3602552115917206 2022-07-01 18:21:36.933934
Epoch:[ 158 10 ] loss: 0.3613537549972534 2022-07-01 18:21:37.349903
Epoch:[ 158 11 ] loss: 0.3599560558795929 2022-07-01 18:21:37.765842
Epoch:[ 158 12 ] loss: 0.36016958951950073 2022-07-01 18:21:38.182210
Epoch:[ 158 13 ] loss: 0.3598923981189728 2022-07-01 18:21:38.591698
Epoch:[ 158 14 ] loss: 0.3603381812572479 2022-07-01 18:21:39.007548
Epoch:[ 158 15 ] loss: 0.3599459230899811 2022-07-01 18:21:39.425091
Epoch:[ 158 16 ] loss: 0.3608335256576538 2022-07-01 18:21:44.755045
Epoch:[ 158 17 ] loss: 0.3604201376438141 2022-07-01 18:21:45.185385
Epoch:[ 158 18 ] loss: 0.361527681350708 2022-07-01 18:21:45.593952
Epoch:[ 158 19 ] loss: 0.360141396522522 2022-07-01 18:21:46.002242
Training_Epoch:[ 158 ] Training_loss: 0.3607696145772934 2022-07-01 18:21:46.002984
learning rate:  3.5184372088832036e-05
netparams have been saved once 158
val: 1 0.39517372846603394
val: 2 0.3833354711532593
val: 3 0.3910938799381256
val: 4 0.3932279944419861
val: 5 0.3870205283164978
val: 6 0.3956284821033478
val: 7 0.39083701372146606
val: 8 0.39054909348487854
val: 9 0.3940907418727875
val: 10 0.3882640600204468
val: 11 0.38869205117225647
val: 12 0.38873615860939026
val: 13 0.39348188042640686
val: 14 0.385095477104187
val: 15 0.38566944003105164
val: 16 0.39062610268592834
val: 17 0.4019589424133301
val: 18 0.3899926543235779
val: 19 0.39253389835357666
val: 20 0.3969622254371643
val_Epoch:[ 158 ] val_loss: 0.3911484912037849 2022-07-01 18:21:49.932509
start training 2022-07-01 18:21:50.038358
Epoch:[ 159 0 ] loss: 0.35947921872138977 2022-07-01 18:22:04.327109
Epoch:[ 159 1 ] loss: 0.359431654214859 2022-07-01 18:22:04.766115
Epoch:[ 159 2 ] loss: 0.36119332909584045 2022-07-01 18:22:05.204426
Epoch:[ 159 3 ] loss: 0.3610198199748993 2022-07-01 18:22:05.623052
Epoch:[ 159 4 ] loss: 0.3599404990673065 2022-07-01 18:22:06.039138
Epoch:[ 159 5 ] loss: 0.36049363017082214 2022-07-01 18:22:06.464577
Epoch:[ 159 6 ] loss: 0.3611110746860504 2022-07-01 18:22:06.882236
Epoch:[ 159 7 ] loss: 0.36232447624206543 2022-07-01 18:22:07.298612
Epoch:[ 159 8 ] loss: 0.3602094352245331 2022-07-01 18:22:07.712654
Epoch:[ 159 9 ] loss: 0.36145228147506714 2022-07-01 18:22:08.128176
Epoch:[ 159 10 ] loss: 0.3604716360569 2022-07-01 18:22:08.545051
Epoch:[ 159 11 ] loss: 0.36103886365890503 2022-07-01 18:22:08.961363
Epoch:[ 159 12 ] loss: 0.3611508011817932 2022-07-01 18:22:09.376992
Epoch:[ 159 13 ] loss: 0.35999414324760437 2022-07-01 18:22:09.792448
Epoch:[ 159 14 ] loss: 0.36167266964912415 2022-07-01 18:22:10.207801
Epoch:[ 159 15 ] loss: 0.3614019453525543 2022-07-01 18:22:10.622972
Epoch:[ 159 16 ] loss: 0.3603467643260956 2022-07-01 18:22:16.200773
Epoch:[ 159 17 ] loss: 0.3600349426269531 2022-07-01 18:22:16.610697
Epoch:[ 159 18 ] loss: 0.36090031266212463 2022-07-01 18:22:17.027438
Epoch:[ 159 19 ] loss: 0.3608994483947754 2022-07-01 18:22:17.436513
Training_Epoch:[ 159 ] Training_loss: 0.3607283473014832 2022-07-01 18:22:17.437289
learning rate:  3.5184372088832036e-05
val: 1 0.39231857657432556
val: 2 0.38967180252075195
val: 3 0.39239591360092163
val: 4 0.38516882061958313
val: 5 0.39283105731010437
val: 6 0.3900224268436432
val: 7 0.38880154490470886
val: 8 0.38893309235572815
val: 9 0.3921656012535095
val: 10 0.3859981596469879
val: 11 0.38911542296409607
val: 12 0.39372843503952026
val: 13 0.3875945508480072
val: 14 0.39445486664772034
val: 15 0.39006879925727844
val: 16 0.38980183005332947
val: 17 0.3920336365699768
val: 18 0.3920728266239166
val: 19 0.3859117329120636
val: 20 0.3980870842933655
val_Epoch:[ 159 ] val_loss: 0.39055880904197693 2022-07-01 18:22:21.431246
start training 2022-07-01 18:22:21.535192
Epoch:[ 160 0 ] loss: 0.36075738072395325 2022-07-01 18:22:36.518465
Epoch:[ 160 1 ] loss: 0.3600974977016449 2022-07-01 18:22:36.948649
Epoch:[ 160 2 ] loss: 0.3612416684627533 2022-07-01 18:22:37.384296
Epoch:[ 160 3 ] loss: 0.3595207929611206 2022-07-01 18:22:37.815471
Epoch:[ 160 4 ] loss: 0.36058157682418823 2022-07-01 18:22:38.247005
Epoch:[ 160 5 ] loss: 0.3610832095146179 2022-07-01 18:22:38.662392
Epoch:[ 160 6 ] loss: 0.3621709644794464 2022-07-01 18:22:39.078671
Epoch:[ 160 7 ] loss: 0.3597780466079712 2022-07-01 18:22:39.494209
Epoch:[ 160 8 ] loss: 0.3597533106803894 2022-07-01 18:22:39.901286
Epoch:[ 160 9 ] loss: 0.3598332405090332 2022-07-01 18:22:40.315999
Epoch:[ 160 10 ] loss: 0.3607862889766693 2022-07-01 18:22:40.732505
Epoch:[ 160 11 ] loss: 0.3617653250694275 2022-07-01 18:22:41.149706
Epoch:[ 160 12 ] loss: 0.36011576652526855 2022-07-01 18:22:41.565668
Epoch:[ 160 13 ] loss: 0.3613530993461609 2022-07-01 18:22:41.979563
Epoch:[ 160 14 ] loss: 0.3612516224384308 2022-07-01 18:22:42.395653
Epoch:[ 160 15 ] loss: 0.36060142517089844 2022-07-01 18:22:42.804445
Epoch:[ 160 16 ] loss: 0.36156904697418213 2022-07-01 18:22:47.608250
Epoch:[ 160 17 ] loss: 0.36123040318489075 2022-07-01 18:22:48.037664
Epoch:[ 160 18 ] loss: 0.35966333746910095 2022-07-01 18:22:48.477437
Epoch:[ 160 19 ] loss: 0.36015450954437256 2022-07-01 18:22:48.911612
Training_Epoch:[ 160 ] Training_loss: 0.360665425658226 2022-07-01 18:22:48.912350
learning rate:  3.5184372088832036e-05
netparams have been saved once 160
val: 1 0.3975293040275574
val: 2 0.39612406492233276
val: 3 0.3916280269622803
val: 4 0.4011656641960144
val: 5 0.40175241231918335
val: 6 0.39226579666137695
val: 7 0.3882710635662079
val: 8 0.38733407855033875
val: 9 0.3926089107990265
val: 10 0.3930792808532715
val: 11 0.38873496651649475
val: 12 0.38768884539604187
val: 13 0.39148131012916565
val: 14 0.3883007764816284
val: 15 0.38027647137641907
val: 16 0.3867315351963043
val: 17 0.39050760865211487
val: 18 0.3855423331260681
val: 19 0.38798078894615173
val: 20 0.3872033357620239
val_Epoch:[ 160 ] val_loss: 0.3908103287220001 2022-07-01 18:22:52.867835
start training 2022-07-01 18:22:52.971391
Epoch:[ 161 0 ] loss: 0.3606606125831604 2022-07-01 18:23:07.606376
Epoch:[ 161 1 ] loss: 0.36073753237724304 2022-07-01 18:23:08.034939
Epoch:[ 161 2 ] loss: 0.36180177330970764 2022-07-01 18:23:08.444476
Epoch:[ 161 3 ] loss: 0.3616383969783783 2022-07-01 18:23:08.851921
Epoch:[ 161 4 ] loss: 0.3621496558189392 2022-07-01 18:23:09.267241
Epoch:[ 161 5 ] loss: 0.36152389645576477 2022-07-01 18:23:09.684328
Epoch:[ 161 6 ] loss: 0.3600277006626129 2022-07-01 18:23:10.101734
Epoch:[ 161 7 ] loss: 0.35993948578834534 2022-07-01 18:23:10.518928
Epoch:[ 161 8 ] loss: 0.36015138030052185 2022-07-01 18:23:10.934634
Epoch:[ 161 9 ] loss: 0.3603222966194153 2022-07-01 18:23:11.349952
Epoch:[ 161 10 ] loss: 0.3607133626937866 2022-07-01 18:23:11.765272
Epoch:[ 161 11 ] loss: 0.36066263914108276 2022-07-01 18:23:12.181932
Epoch:[ 161 12 ] loss: 0.35916823148727417 2022-07-01 18:23:12.597670
Epoch:[ 161 13 ] loss: 0.360343873500824 2022-07-01 18:23:13.013817
Epoch:[ 161 14 ] loss: 0.35991379618644714 2022-07-01 18:23:13.429839
Epoch:[ 161 15 ] loss: 0.36070412397384644 2022-07-01 18:23:13.857063
Epoch:[ 161 16 ] loss: 0.3603082597255707 2022-07-01 18:23:19.236698
Epoch:[ 161 17 ] loss: 0.36053168773651123 2022-07-01 18:23:19.670199
Epoch:[ 161 18 ] loss: 0.3604465425014496 2022-07-01 18:23:20.108202
Epoch:[ 161 19 ] loss: 0.3619925379753113 2022-07-01 18:23:20.543218
Training_Epoch:[ 161 ] Training_loss: 0.3606868892908096 2022-07-01 18:23:20.544231
learning rate:  2.814749767106563e-05
val: 1 0.3877367675304413
val: 2 0.38838067650794983
val: 3 0.39834848046302795
val: 4 0.3867884576320648
val: 5 0.39749693870544434
val: 6 0.3989083766937256
val: 7 0.3897625505924225
val: 8 0.38948968052864075
val: 9 0.3968825042247772
val: 10 0.3861411213874817
val: 11 0.38542458415031433
val: 12 0.3871719539165497
val: 13 0.3950662910938263
val: 14 0.3995230197906494
val: 15 0.3843250870704651
val: 16 0.3954048752784729
val: 17 0.38743478059768677
val: 18 0.38819894194602966
val: 19 0.383131206035614
val: 20 0.39168137311935425
val_Epoch:[ 161 ] val_loss: 0.39086488336324693 2022-07-01 18:23:24.531900
start training 2022-07-01 18:23:24.636481
Epoch:[ 162 0 ] loss: 0.35969048738479614 2022-07-01 18:23:38.795581
Epoch:[ 162 1 ] loss: 0.3606560528278351 2022-07-01 18:23:39.695572
Epoch:[ 162 2 ] loss: 0.36011168360710144 2022-07-01 18:23:40.126271
Epoch:[ 162 3 ] loss: 0.3600775897502899 2022-07-01 18:23:40.555385
Epoch:[ 162 4 ] loss: 0.36118558049201965 2022-07-01 18:23:40.987809
Epoch:[ 162 5 ] loss: 0.3609468936920166 2022-07-01 18:23:41.417755
Epoch:[ 162 6 ] loss: 0.3601892292499542 2022-07-01 18:23:41.849568
Epoch:[ 162 7 ] loss: 0.36019739508628845 2022-07-01 18:23:42.286718
Epoch:[ 162 8 ] loss: 0.3617881238460541 2022-07-01 18:23:42.716121
Epoch:[ 162 9 ] loss: 0.3611670434474945 2022-07-01 18:23:43.146504
Epoch:[ 162 10 ] loss: 0.36051425337791443 2022-07-01 18:23:43.576748
Epoch:[ 162 11 ] loss: 0.3597206771373749 2022-07-01 18:23:44.006168
Epoch:[ 162 12 ] loss: 0.36088937520980835 2022-07-01 18:23:44.442408
Epoch:[ 162 13 ] loss: 0.35992372035980225 2022-07-01 18:23:44.872918
Epoch:[ 162 14 ] loss: 0.36124587059020996 2022-07-01 18:23:45.302541
Epoch:[ 162 15 ] loss: 0.3602902591228485 2022-07-01 18:23:45.731059
Epoch:[ 162 16 ] loss: 0.361155241727829 2022-07-01 18:23:50.571988
Epoch:[ 162 17 ] loss: 0.3611181676387787 2022-07-01 18:23:51.002824
Epoch:[ 162 18 ] loss: 0.36011070013046265 2022-07-01 18:23:51.443259
Epoch:[ 162 19 ] loss: 0.3619749844074249 2022-07-01 18:23:51.870932
Training_Epoch:[ 162 ] Training_loss: 0.3606476664543152 2022-07-01 18:23:51.871614
learning rate:  2.814749767106563e-05
netparams have been saved once 162
val: 1 0.38404613733291626
val: 2 0.39776360988616943
val: 3 0.3871997892856598
val: 4 0.3805190920829773
val: 5 0.3947504460811615
val: 6 0.3921055197715759
val: 7 0.39196670055389404
val: 8 0.39353233575820923
val: 9 0.3998304605484009
val: 10 0.3927292823791504
val: 11 0.3876587152481079
val: 12 0.3894991874694824
val: 13 0.3857457637786865
val: 14 0.3855721056461334
val: 15 0.39164862036705017
val: 16 0.3914165198802948
val: 17 0.3936876952648163
val: 18 0.39402517676353455
val: 19 0.3918193578720093
val: 20 0.39063912630081177
val_Epoch:[ 162 ] val_loss: 0.3908077821135521 2022-07-01 18:23:55.823943
start training 2022-07-01 18:23:55.928983
Epoch:[ 163 0 ] loss: 0.35971927642822266 2022-07-01 18:24:10.476951
Epoch:[ 163 1 ] loss: 0.3597019612789154 2022-07-01 18:24:10.905605
Epoch:[ 163 2 ] loss: 0.35988375544548035 2022-07-01 18:24:11.335652
Epoch:[ 163 3 ] loss: 0.36208999156951904 2022-07-01 18:24:11.765081
Epoch:[ 163 4 ] loss: 0.3622826933860779 2022-07-01 18:24:12.198012
Epoch:[ 163 5 ] loss: 0.3586682379245758 2022-07-01 18:24:12.624200
Epoch:[ 163 6 ] loss: 0.359987735748291 2022-07-01 18:24:13.055057
Epoch:[ 163 7 ] loss: 0.3607909381389618 2022-07-01 18:24:13.490043
Epoch:[ 163 8 ] loss: 0.3597978949546814 2022-07-01 18:24:13.920900
Epoch:[ 163 9 ] loss: 0.3598870038986206 2022-07-01 18:24:14.349396
Epoch:[ 163 10 ] loss: 0.360193133354187 2022-07-01 18:24:14.783259
Epoch:[ 163 11 ] loss: 0.3604888916015625 2022-07-01 18:24:15.212592
Epoch:[ 163 12 ] loss: 0.36168649792671204 2022-07-01 18:24:15.640751
Epoch:[ 163 13 ] loss: 0.3605450391769409 2022-07-01 18:24:16.071028
Epoch:[ 163 14 ] loss: 0.36127564311027527 2022-07-01 18:24:16.501763
Epoch:[ 163 15 ] loss: 0.36077189445495605 2022-07-01 18:24:16.932538
Epoch:[ 163 16 ] loss: 0.3617576062679291 2022-07-01 18:24:22.331216
Epoch:[ 163 17 ] loss: 0.3595753610134125 2022-07-01 18:24:22.757267
Epoch:[ 163 18 ] loss: 0.36243507266044617 2022-07-01 18:24:23.195124
Epoch:[ 163 19 ] loss: 0.36092260479927063 2022-07-01 18:24:23.626860
Training_Epoch:[ 163 ] Training_loss: 0.3606230616569519 2022-07-01 18:24:23.627475
learning rate:  2.814749767106563e-05
val: 1 0.39095160365104675
val: 2 0.39259597659111023
val: 3 0.39571666717529297
val: 4 0.38560253381729126
val: 5 0.3834173381328583
val: 6 0.39275142550468445
val: 7 0.39186468720436096
val: 8 0.4020317792892456
val: 9 0.3886818289756775
val: 10 0.3956255316734314
val: 11 0.3892388939857483
val: 12 0.39663612842559814
val: 13 0.38865724205970764
val: 14 0.3828914165496826
val: 15 0.38239380717277527
val: 16 0.39504316449165344
val: 17 0.3876752555370331
val: 18 0.3935883045196533
val: 19 0.39138272404670715
val: 20 0.3931812345981598
val_Epoch:[ 163 ] val_loss: 0.3909963771700859 2022-07-01 18:24:27.506361
start training 2022-07-01 18:24:27.611746
Epoch:[ 164 0 ] loss: 0.36008110642433167 2022-07-01 18:24:41.860769
Epoch:[ 164 1 ] loss: 0.3604888319969177 2022-07-01 18:24:42.532143
Epoch:[ 164 2 ] loss: 0.36177363991737366 2022-07-01 18:24:42.961978
Epoch:[ 164 3 ] loss: 0.3614526093006134 2022-07-01 18:24:43.391851
Epoch:[ 164 4 ] loss: 0.360257625579834 2022-07-01 18:24:43.821618
Epoch:[ 164 5 ] loss: 0.36105117201805115 2022-07-01 18:24:44.250354
Epoch:[ 164 6 ] loss: 0.3609240651130676 2022-07-01 18:24:44.679724
Epoch:[ 164 7 ] loss: 0.3607665002346039 2022-07-01 18:24:45.115912
Epoch:[ 164 8 ] loss: 0.36076128482818604 2022-07-01 18:24:45.547910
Epoch:[ 164 9 ] loss: 0.3594788610935211 2022-07-01 18:24:45.979769
Epoch:[ 164 10 ] loss: 0.3608405292034149 2022-07-01 18:24:46.415318
Epoch:[ 164 11 ] loss: 0.36137959361076355 2022-07-01 18:24:46.845406
Epoch:[ 164 12 ] loss: 0.36083507537841797 2022-07-01 18:24:47.275441
Epoch:[ 164 13 ] loss: 0.3611886203289032 2022-07-01 18:24:47.707395
Epoch:[ 164 14 ] loss: 0.36015376448631287 2022-07-01 18:24:48.138162
Epoch:[ 164 15 ] loss: 0.35955551266670227 2022-07-01 18:24:48.573639
Epoch:[ 164 16 ] loss: 0.36119377613067627 2022-07-01 18:24:53.359340
Epoch:[ 164 17 ] loss: 0.36019518971443176 2022-07-01 18:24:53.806987
Epoch:[ 164 18 ] loss: 0.3612666726112366 2022-07-01 18:24:54.244664
Epoch:[ 164 19 ] loss: 0.3590899705886841 2022-07-01 18:24:54.672893
Training_Epoch:[ 164 ] Training_loss: 0.3606367200613022 2022-07-01 18:24:54.673593
learning rate:  2.814749767106563e-05
netparams have been saved once 164
val: 1 0.3949322998523712
val: 2 0.3968949317932129
val: 3 0.3909144401550293
val: 4 0.3884935975074768
val: 5 0.3947330117225647
val: 6 0.39204809069633484
val: 7 0.3968098759651184
val: 8 0.3905433118343353
val: 9 0.39220067858695984
val: 10 0.38993212580680847
val: 11 0.3796822130680084
val: 12 0.39873820543289185
val: 13 0.39684921503067017
val: 14 0.38691750168800354
val: 15 0.3903215527534485
val: 16 0.39085662364959717
val: 17 0.3885034918785095
val: 18 0.38075339794158936
val: 19 0.3924117386341095
val: 20 0.3926168382167816
val_Epoch:[ 164 ] val_loss: 0.39125765711069105 2022-07-01 18:24:58.577660
start training 2022-07-01 18:24:58.686654
Epoch:[ 165 0 ] loss: 0.3618966042995453 2022-07-01 18:25:13.751947
Epoch:[ 165 1 ] loss: 0.36200621724128723 2022-07-01 18:25:14.162280
Epoch:[ 165 2 ] loss: 0.36093321442604065 2022-07-01 18:25:14.576525
Epoch:[ 165 3 ] loss: 0.36151590943336487 2022-07-01 18:25:14.992490
Epoch:[ 165 4 ] loss: 0.36172839999198914 2022-07-01 18:25:15.407243
Epoch:[ 165 5 ] loss: 0.35866019129753113 2022-07-01 18:25:15.821233
Epoch:[ 165 6 ] loss: 0.36130595207214355 2022-07-01 18:25:16.235944
Epoch:[ 165 7 ] loss: 0.3612079322338104 2022-07-01 18:25:16.649759
Epoch:[ 165 8 ] loss: 0.3607320189476013 2022-07-01 18:25:17.066441
Epoch:[ 165 9 ] loss: 0.36029526591300964 2022-07-01 18:25:17.482661
Epoch:[ 165 10 ] loss: 0.36005207896232605 2022-07-01 18:25:17.901935
Epoch:[ 165 11 ] loss: 0.36033016443252563 2022-07-01 18:25:18.312864
Epoch:[ 165 12 ] loss: 0.3600451946258545 2022-07-01 18:25:18.735342
Epoch:[ 165 13 ] loss: 0.3608095347881317 2022-07-01 18:25:19.150231
Epoch:[ 165 14 ] loss: 0.3605972230434418 2022-07-01 18:25:19.559119
Epoch:[ 165 15 ] loss: 0.3603707551956177 2022-07-01 18:25:19.975411
Epoch:[ 165 16 ] loss: 0.359086275100708 2022-07-01 18:25:25.486369
Epoch:[ 165 17 ] loss: 0.3618710935115814 2022-07-01 18:25:25.902272
Epoch:[ 165 18 ] loss: 0.3615964651107788 2022-07-01 18:25:26.339310
Epoch:[ 165 19 ] loss: 0.3603060245513916 2022-07-01 18:25:26.773015
Training_Epoch:[ 165 ] Training_loss: 0.360767325758934 2022-07-01 18:25:26.773808
learning rate:  2.814749767106563e-05
val: 1 0.38578489422798157
val: 2 0.3899676501750946
val: 3 0.39282482862472534
val: 4 0.3968096375465393
val: 5 0.3918885290622711
val: 6 0.38933080434799194
val: 7 0.3935461938381195
val: 8 0.39549586176872253
val: 9 0.3923760950565338
val: 10 0.389801949262619
val: 11 0.39421284198760986
val: 12 0.37877753376960754
val: 13 0.39388254284858704
val: 14 0.39358675479888916
val: 15 0.3892558515071869
val: 16 0.3902621269226074
val: 17 0.3884454667568207
val: 18 0.39753457903862
val: 19 0.38878586888313293
val: 20 0.386287122964859
val_Epoch:[ 165 ] val_loss: 0.39094285666942596 2022-07-01 18:25:30.679906
start training 2022-07-01 18:25:30.783710
Epoch:[ 166 0 ] loss: 0.3591812252998352 2022-07-01 18:25:45.530640
Epoch:[ 166 1 ] loss: 0.3603985011577606 2022-07-01 18:25:45.959232
Epoch:[ 166 2 ] loss: 0.3601439297199249 2022-07-01 18:25:46.390409
Epoch:[ 166 3 ] loss: 0.36254531145095825 2022-07-01 18:25:46.821124
Epoch:[ 166 4 ] loss: 0.3593914210796356 2022-07-01 18:25:47.252297
Epoch:[ 166 5 ] loss: 0.36153560876846313 2022-07-01 18:25:47.682855
Epoch:[ 166 6 ] loss: 0.36124491691589355 2022-07-01 18:25:48.112937
Epoch:[ 166 7 ] loss: 0.3610232472419739 2022-07-01 18:25:48.541719
Epoch:[ 166 8 ] loss: 0.35987231135368347 2022-07-01 18:25:48.976062
Epoch:[ 166 9 ] loss: 0.36098024249076843 2022-07-01 18:25:49.411508
Epoch:[ 166 10 ] loss: 0.3599446415901184 2022-07-01 18:25:49.843789
Epoch:[ 166 11 ] loss: 0.3590249717235565 2022-07-01 18:25:50.274114
Epoch:[ 166 12 ] loss: 0.36027106642723083 2022-07-01 18:25:50.702863
Epoch:[ 166 13 ] loss: 0.36187657713890076 2022-07-01 18:25:51.132904
Epoch:[ 166 14 ] loss: 0.3597531020641327 2022-07-01 18:25:51.567355
Epoch:[ 166 15 ] loss: 0.3614030182361603 2022-07-01 18:25:51.997142
Epoch:[ 166 16 ] loss: 0.36163127422332764 2022-07-01 18:25:56.895574
Epoch:[ 166 17 ] loss: 0.3607651889324188 2022-07-01 18:25:57.323691
Epoch:[ 166 18 ] loss: 0.36076122522354126 2022-07-01 18:25:57.765492
Epoch:[ 166 19 ] loss: 0.3615468740463257 2022-07-01 18:25:58.193537
Training_Epoch:[ 166 ] Training_loss: 0.3606647327542305 2022-07-01 18:25:58.194156
learning rate:  2.814749767106563e-05
netparams have been saved once 166
val: 1 0.38873064517974854
val: 2 0.39188188314437866
val: 3 0.38881006836891174
val: 4 0.3909272849559784
val: 5 0.39777350425720215
val: 6 0.38912567496299744
val: 7 0.3938705623149872
val: 8 0.3870696425437927
val: 9 0.38687172532081604
val: 10 0.390701025724411
val: 11 0.38576772809028625
val: 12 0.39258238673210144
val: 13 0.39581239223480225
val: 14 0.38927340507507324
val: 15 0.39223819971084595
val: 16 0.39490169286727905
val: 17 0.38710817694664
val: 18 0.38659101724624634
val: 19 0.4041871726512909
val: 20 0.3846514821052551
val_Epoch:[ 166 ] val_loss: 0.3909437835216522 2022-07-01 18:26:02.115740
start training 2022-07-01 18:26:02.219514
Epoch:[ 167 0 ] loss: 0.36110827326774597 2022-07-01 18:26:16.552889
Epoch:[ 167 1 ] loss: 0.3601778447628021 2022-07-01 18:26:16.996816
Epoch:[ 167 2 ] loss: 0.36106476187705994 2022-07-01 18:26:17.425314
Epoch:[ 167 3 ] loss: 0.3612893223762512 2022-07-01 18:26:17.857226
Epoch:[ 167 4 ] loss: 0.35991525650024414 2022-07-01 18:26:18.288853
Epoch:[ 167 5 ] loss: 0.36110469698905945 2022-07-01 18:26:18.717983
Epoch:[ 167 6 ] loss: 0.35990041494369507 2022-07-01 18:26:19.152209
Epoch:[ 167 7 ] loss: 0.3604487180709839 2022-07-01 18:26:19.581555
Epoch:[ 167 8 ] loss: 0.36081501841545105 2022-07-01 18:26:20.013236
Epoch:[ 167 9 ] loss: 0.36149561405181885 2022-07-01 18:26:20.442025
Epoch:[ 167 10 ] loss: 0.3597250282764435 2022-07-01 18:26:20.873153
Epoch:[ 167 11 ] loss: 0.3606152832508087 2022-07-01 18:26:21.304382
Epoch:[ 167 12 ] loss: 0.36098286509513855 2022-07-01 18:26:21.740171
Epoch:[ 167 13 ] loss: 0.3596031367778778 2022-07-01 18:26:22.169470
Epoch:[ 167 14 ] loss: 0.3610841929912567 2022-07-01 18:26:22.598754
Epoch:[ 167 15 ] loss: 0.3606487810611725 2022-07-01 18:26:23.033131
Epoch:[ 167 16 ] loss: 0.36190930008888245 2022-07-01 18:26:28.360140
Epoch:[ 167 17 ] loss: 0.36067044734954834 2022-07-01 18:26:28.796301
Epoch:[ 167 18 ] loss: 0.36005446314811707 2022-07-01 18:26:29.250941
Epoch:[ 167 19 ] loss: 0.3611130714416504 2022-07-01 18:26:29.682882
Training_Epoch:[ 167 ] Training_loss: 0.3606863245368004 2022-07-01 18:26:29.683562
learning rate:  2.814749767106563e-05
val: 1 0.38474443554878235
val: 2 0.39054247736930847
val: 3 0.39167550206184387
val: 4 0.3939483165740967
val: 5 0.39047402143478394
val: 6 0.39022111892700195
val: 7 0.3918396532535553
val: 8 0.40136000514030457
val: 9 0.38098350167274475
val: 10 0.4024522602558136
val: 11 0.3954024314880371
val: 12 0.389852374792099
val: 13 0.38962897658348083
val: 14 0.39111629128456116
val: 15 0.3917420506477356
val: 16 0.3876010775566101
val: 17 0.3846762776374817
val: 18 0.38411423563957214
val: 19 0.38563820719718933
val: 20 0.3985573351383209
val_Epoch:[ 167 ] val_loss: 0.39082852751016617 2022-07-01 18:26:33.616230
start training 2022-07-01 18:26:33.720042
Epoch:[ 168 0 ] loss: 0.3604395389556885 2022-07-01 18:26:48.650087
Epoch:[ 168 1 ] loss: 0.3601933419704437 2022-07-01 18:26:49.079507
Epoch:[ 168 2 ] loss: 0.36029690504074097 2022-07-01 18:26:49.513233
Epoch:[ 168 3 ] loss: 0.3599757254123688 2022-07-01 18:26:49.942607
Epoch:[ 168 4 ] loss: 0.3607722222805023 2022-07-01 18:26:50.373682
Epoch:[ 168 5 ] loss: 0.3608419895172119 2022-07-01 18:26:50.804717
Epoch:[ 168 6 ] loss: 0.3615610599517822 2022-07-01 18:26:51.236202
Epoch:[ 168 7 ] loss: 0.361500084400177 2022-07-01 18:26:51.668338
Epoch:[ 168 8 ] loss: 0.3593939244747162 2022-07-01 18:26:52.103836
Epoch:[ 168 9 ] loss: 0.3611688017845154 2022-07-01 18:26:52.517718
Epoch:[ 168 10 ] loss: 0.36014872789382935 2022-07-01 18:26:52.929053
Epoch:[ 168 11 ] loss: 0.3599792420864105 2022-07-01 18:26:53.347196
Epoch:[ 168 12 ] loss: 0.361150324344635 2022-07-01 18:26:53.762374
Epoch:[ 168 13 ] loss: 0.3609989583492279 2022-07-01 18:26:54.179505
Epoch:[ 168 14 ] loss: 0.3607011139392853 2022-07-01 18:26:54.594228
Epoch:[ 168 15 ] loss: 0.3602766692638397 2022-07-01 18:26:55.011297
Epoch:[ 168 16 ] loss: 0.3614751696586609 2022-07-01 18:27:00.161997
Epoch:[ 168 17 ] loss: 0.36123722791671753 2022-07-01 18:27:00.576065
Epoch:[ 168 18 ] loss: 0.3601146936416626 2022-07-01 18:27:01.017031
Epoch:[ 168 19 ] loss: 0.3611442744731903 2022-07-01 18:27:01.462422
Training_Epoch:[ 168 ] Training_loss: 0.3606684997677803 2022-07-01 18:27:01.463505
learning rate:  2.814749767106563e-05
netparams have been saved once 168
val: 1 0.39630791544914246
val: 2 0.39263203740119934
val: 3 0.3915393054485321
val: 4 0.38628795742988586
val: 5 0.3917221426963806
val: 6 0.396065354347229
val: 7 0.3907032012939453
val: 8 0.39633679389953613
val: 9 0.38238587975502014
val: 10 0.3973761796951294
val: 11 0.39345744252204895
val: 12 0.3811616897583008
val: 13 0.38697385787963867
val: 14 0.3930699825286865
val: 15 0.3997759521007538
val: 16 0.38981950283050537
val: 17 0.387744277715683
val: 18 0.3876763880252838
val: 19 0.3958567678928375
val: 20 0.39238035678863525
val_Epoch:[ 168 ] val_loss: 0.3914636492729187 2022-07-01 18:27:05.941601
start training 2022-07-01 18:27:06.049775
Epoch:[ 169 0 ] loss: 0.36011457443237305 2022-07-01 18:27:20.364237
Epoch:[ 169 1 ] loss: 0.3602554500102997 2022-07-01 18:27:21.038011
Epoch:[ 169 2 ] loss: 0.3615807294845581 2022-07-01 18:27:21.464576
Epoch:[ 169 3 ] loss: 0.36027735471725464 2022-07-01 18:27:21.894729
Epoch:[ 169 4 ] loss: 0.3600004017353058 2022-07-01 18:27:22.314564
Epoch:[ 169 5 ] loss: 0.3599206507205963 2022-07-01 18:27:22.731717
Epoch:[ 169 6 ] loss: 0.36119797825813293 2022-07-01 18:27:23.147679
Epoch:[ 169 7 ] loss: 0.3596022427082062 2022-07-01 18:27:23.563074
Epoch:[ 169 8 ] loss: 0.3612041473388672 2022-07-01 18:27:23.972772
Epoch:[ 169 9 ] loss: 0.3607737720012665 2022-07-01 18:27:24.386055
Epoch:[ 169 10 ] loss: 0.36072757840156555 2022-07-01 18:27:24.800946
Epoch:[ 169 11 ] loss: 0.36133578419685364 2022-07-01 18:27:25.208062
Epoch:[ 169 12 ] loss: 0.360312283039093 2022-07-01 18:27:25.624396
Epoch:[ 169 13 ] loss: 0.3604845702648163 2022-07-01 18:27:26.033444
Epoch:[ 169 14 ] loss: 0.3612918257713318 2022-07-01 18:27:26.449256
Epoch:[ 169 15 ] loss: 0.36100339889526367 2022-07-01 18:27:26.864533
Epoch:[ 169 16 ] loss: 0.3606669008731842 2022-07-01 18:27:32.041803
Epoch:[ 169 17 ] loss: 0.3597089648246765 2022-07-01 18:27:32.451094
Epoch:[ 169 18 ] loss: 0.36194732785224915 2022-07-01 18:27:32.864827
Epoch:[ 169 19 ] loss: 0.3602045774459839 2022-07-01 18:27:33.273399
Training_Epoch:[ 169 ] Training_loss: 0.3606305256485939 2022-07-01 18:27:33.274448
learning rate:  2.814749767106563e-05
val: 1 0.38814470171928406
val: 2 0.3857240080833435
val: 3 0.4014626145362854
val: 4 0.39061275124549866
val: 5 0.38802197575569153
val: 6 0.3877456784248352
val: 7 0.38856878876686096
val: 8 0.38903114199638367
val: 9 0.3890450596809387
val: 10 0.3933277726173401
val: 11 0.3917626738548279
val: 12 0.39941322803497314
val: 13 0.3953244686126709
val: 14 0.39016464352607727
val: 15 0.38070324063301086
val: 16 0.3971673548221588
val: 17 0.3927688002586365
val: 18 0.3928884267807007
val: 19 0.3875740170478821
val: 20 0.392148494720459
val_Epoch:[ 169 ] val_loss: 0.39107999205589294 2022-07-01 18:27:37.229130
start training 2022-07-01 18:27:37.334328
Epoch:[ 170 0 ] loss: 0.3597254753112793 2022-07-01 18:27:52.101013
Epoch:[ 170 1 ] loss: 0.3606889545917511 2022-07-01 18:27:52.536974
Epoch:[ 170 2 ] loss: 0.36078354716300964 2022-07-01 18:27:52.953030
Epoch:[ 170 3 ] loss: 0.36059311032295227 2022-07-01 18:27:53.371940
Epoch:[ 170 4 ] loss: 0.3611835241317749 2022-07-01 18:27:53.784721
Epoch:[ 170 5 ] loss: 0.361674427986145 2022-07-01 18:27:54.200113
Epoch:[ 170 6 ] loss: 0.3598853051662445 2022-07-01 18:27:54.617426
Epoch:[ 170 7 ] loss: 0.3606607913970947 2022-07-01 18:27:55.031610
Epoch:[ 170 8 ] loss: 0.36063194274902344 2022-07-01 18:27:55.449623
Epoch:[ 170 9 ] loss: 0.36209627985954285 2022-07-01 18:27:55.859602
Epoch:[ 170 10 ] loss: 0.3603854179382324 2022-07-01 18:27:56.277502
Epoch:[ 170 11 ] loss: 0.36119818687438965 2022-07-01 18:27:56.695314
Epoch:[ 170 12 ] loss: 0.359674334526062 2022-07-01 18:27:57.113606
Epoch:[ 170 13 ] loss: 0.3609181344509125 2022-07-01 18:27:57.531133
Epoch:[ 170 14 ] loss: 0.359672874212265 2022-07-01 18:27:57.948264
Epoch:[ 170 15 ] loss: 0.36019065976142883 2022-07-01 18:27:58.366074
Epoch:[ 170 16 ] loss: 0.3613952100276947 2022-07-01 18:28:04.196637
Epoch:[ 170 17 ] loss: 0.3610115945339203 2022-07-01 18:28:04.616111
Epoch:[ 170 18 ] loss: 0.36047056317329407 2022-07-01 18:28:05.035299
Epoch:[ 170 19 ] loss: 0.360098659992218 2022-07-01 18:28:05.447706
Training_Epoch:[ 170 ] Training_loss: 0.3606469497084618 2022-07-01 18:28:05.449019
learning rate:  2.814749767106563e-05
netparams have been saved once 170
val: 1 0.3909018039703369
val: 2 0.38340094685554504
val: 3 0.3889225721359253
val: 4 0.3991145193576813
val: 5 0.39489465951919556
val: 6 0.39282169938087463
val: 7 0.3996911644935608
val: 8 0.3864056169986725
val: 9 0.3978065252304077
val: 10 0.3884968161582947
val: 11 0.3970189690589905
val: 12 0.39210429787635803
val: 13 0.3886125385761261
val: 14 0.3878134787082672
val: 15 0.3854723870754242
val: 16 0.38481539487838745
val: 17 0.38487759232521057
val: 18 0.3910827934741974
val: 19 0.38896307349205017
val: 20 0.3925454616546631
val_Epoch:[ 170 ] val_loss: 0.39078811556100845 2022-07-01 18:28:09.519378
start training 2022-07-01 18:28:09.624997
Epoch:[ 171 0 ] loss: 0.35931217670440674 2022-07-01 18:28:23.863839
Epoch:[ 171 1 ] loss: 0.36007827520370483 2022-07-01 18:28:24.557390
Epoch:[ 171 2 ] loss: 0.360220342874527 2022-07-01 18:28:24.991549
Epoch:[ 171 3 ] loss: 0.35973939299583435 2022-07-01 18:28:25.427366
Epoch:[ 171 4 ] loss: 0.36063653230667114 2022-07-01 18:28:25.856463
Epoch:[ 171 5 ] loss: 0.3606273829936981 2022-07-01 18:28:26.288679
Epoch:[ 171 6 ] loss: 0.36049744486808777 2022-07-01 18:28:26.720970
Epoch:[ 171 7 ] loss: 0.3606089651584625 2022-07-01 18:28:27.151893
Epoch:[ 171 8 ] loss: 0.36118003726005554 2022-07-01 18:28:27.583101
Epoch:[ 171 9 ] loss: 0.36024314165115356 2022-07-01 18:28:28.019947
Epoch:[ 171 10 ] loss: 0.3596687912940979 2022-07-01 18:28:28.449547
Epoch:[ 171 11 ] loss: 0.36162155866622925 2022-07-01 18:28:28.882571
Epoch:[ 171 12 ] loss: 0.3598913848400116 2022-07-01 18:28:29.314633
Epoch:[ 171 13 ] loss: 0.36127620935440063 2022-07-01 18:28:29.745576
Epoch:[ 171 14 ] loss: 0.3616417646408081 2022-07-01 18:28:30.179771
Epoch:[ 171 15 ] loss: 0.36085349321365356 2022-07-01 18:28:30.611262
Epoch:[ 171 16 ] loss: 0.3613407611846924 2022-07-01 18:28:35.747713
Epoch:[ 171 17 ] loss: 0.3600935637950897 2022-07-01 18:28:36.184041
Epoch:[ 171 18 ] loss: 0.36103975772857666 2022-07-01 18:28:36.627250
Epoch:[ 171 19 ] loss: 0.3614194095134735 2022-07-01 18:28:37.054530
Training_Epoch:[ 171 ] Training_loss: 0.36059951931238177 2022-07-01 18:28:37.055165
learning rate:  2.2517998136852506e-05
val: 1 0.3866961896419525
val: 2 0.38834643363952637
val: 3 0.3977351784706116
val: 4 0.39136001467704773
val: 5 0.382461816072464
val: 6 0.3870159685611725
val: 7 0.39015406370162964
val: 8 0.3889198303222656
val: 9 0.3976095914840698
val: 10 0.38914966583251953
val: 11 0.3898361623287201
val: 12 0.39228856563568115
val: 13 0.3899666965007782
val: 14 0.4010303318500519
val: 15 0.39873477816581726
val: 16 0.3868582248687744
val: 17 0.39736658334732056
val: 18 0.38686975836753845
val: 19 0.3893543481826782
val: 20 0.39281487464904785
val_Epoch:[ 171 ] val_loss: 0.3912284538149834 2022-07-01 18:28:40.916117
start training 2022-07-01 18:28:41.018743
Epoch:[ 172 0 ] loss: 0.3612038493156433 2022-07-01 18:28:55.448257
Epoch:[ 172 1 ] loss: 0.3605882525444031 2022-07-01 18:28:55.885206
Epoch:[ 172 2 ] loss: 0.3598858416080475 2022-07-01 18:28:56.319129
Epoch:[ 172 3 ] loss: 0.36091774702072144 2022-07-01 18:28:56.750670
Epoch:[ 172 4 ] loss: 0.36065810918807983 2022-07-01 18:28:57.181185
Epoch:[ 172 5 ] loss: 0.36021023988723755 2022-07-01 18:28:57.610223
Epoch:[ 172 6 ] loss: 0.36261680722236633 2022-07-01 18:28:58.042465
Epoch:[ 172 7 ] loss: 0.3600403368473053 2022-07-01 18:28:58.471168
Epoch:[ 172 8 ] loss: 0.36120080947875977 2022-07-01 18:28:58.907710
Epoch:[ 172 9 ] loss: 0.36119070649147034 2022-07-01 18:28:59.338442
Epoch:[ 172 10 ] loss: 0.3609682023525238 2022-07-01 18:28:59.774058
Epoch:[ 172 11 ] loss: 0.36021849513053894 2022-07-01 18:29:00.206417
Epoch:[ 172 12 ] loss: 0.36043742299079895 2022-07-01 18:29:00.639373
Epoch:[ 172 13 ] loss: 0.3603074252605438 2022-07-01 18:29:01.067223
Epoch:[ 172 14 ] loss: 0.3600108325481415 2022-07-01 18:29:01.499658
Epoch:[ 172 15 ] loss: 0.3598298132419586 2022-07-01 18:29:01.937023
Epoch:[ 172 16 ] loss: 0.3596796989440918 2022-07-01 18:29:07.250631
Epoch:[ 172 17 ] loss: 0.360738605260849 2022-07-01 18:29:07.686034
Epoch:[ 172 18 ] loss: 0.3588561415672302 2022-07-01 18:29:08.127747
Epoch:[ 172 19 ] loss: 0.36129605770111084 2022-07-01 18:29:08.560339
Training_Epoch:[ 172 ] Training_loss: 0.3605427697300911 2022-07-01 18:29:08.560971
learning rate:  2.2517998136852506e-05
netparams have been saved once 172
val: 1 0.3924121856689453
val: 2 0.38407987356185913
val: 3 0.39282113313674927
val: 4 0.39223361015319824
val: 5 0.38287121057510376
val: 6 0.3869421184062958
val: 7 0.3951699733734131
val: 8 0.3843199610710144
val: 9 0.39633217453956604
val: 10 0.38844946026802063
val: 11 0.3934887647628784
val: 12 0.4023200571537018
val: 13 0.39191463589668274
val: 14 0.3919219970703125
val: 15 0.38718366622924805
val: 16 0.3940991759300232
val: 17 0.3962540626525879
val: 18 0.3888566493988037
val: 19 0.39179664850234985
val: 20 0.38708046078681946
val_Epoch:[ 172 ] val_loss: 0.39102739095687866 2022-07-01 18:29:12.521662
start training 2022-07-01 18:29:12.623699
Epoch:[ 173 0 ] loss: 0.358903169631958 2022-07-01 18:29:27.005879
Epoch:[ 173 1 ] loss: 0.3603808581829071 2022-07-01 18:29:27.463616
Epoch:[ 173 2 ] loss: 0.36018991470336914 2022-07-01 18:29:27.901492
Epoch:[ 173 3 ] loss: 0.360399067401886 2022-07-01 18:29:28.332964
Epoch:[ 173 4 ] loss: 0.360801637172699 2022-07-01 18:29:28.765272
Epoch:[ 173 5 ] loss: 0.3613203465938568 2022-07-01 18:29:29.193955
Epoch:[ 173 6 ] loss: 0.3616635203361511 2022-07-01 18:29:29.625569
Epoch:[ 173 7 ] loss: 0.35962173342704773 2022-07-01 18:29:30.055764
Epoch:[ 173 8 ] loss: 0.36035144329071045 2022-07-01 18:29:30.491197
Epoch:[ 173 9 ] loss: 0.36069026589393616 2022-07-01 18:29:30.922827
Epoch:[ 173 10 ] loss: 0.36051008105278015 2022-07-01 18:29:31.360569
Epoch:[ 173 11 ] loss: 0.36071160435676575 2022-07-01 18:29:31.776475
Epoch:[ 173 12 ] loss: 0.360688179731369 2022-07-01 18:29:32.189835
Epoch:[ 173 13 ] loss: 0.36084842681884766 2022-07-01 18:29:32.598341
Epoch:[ 173 14 ] loss: 0.3605523407459259 2022-07-01 18:29:33.012486
Epoch:[ 173 15 ] loss: 0.36041685938835144 2022-07-01 18:29:33.427165
Epoch:[ 173 16 ] loss: 0.3611539304256439 2022-07-01 18:29:38.801354
Epoch:[ 173 17 ] loss: 0.3598206043243408 2022-07-01 18:29:39.213288
Epoch:[ 173 18 ] loss: 0.36084121465682983 2022-07-01 18:29:39.625654
Epoch:[ 173 19 ] loss: 0.3607838451862335 2022-07-01 18:29:40.041236
Training_Epoch:[ 173 ] Training_loss: 0.3605324521660805 2022-07-01 18:29:40.042419
learning rate:  2.2517998136852506e-05
val: 1 0.39367344975471497
val: 2 0.3869781792163849
val: 3 0.38694801926612854
val: 4 0.3898185193538666
val: 5 0.39631348848342896
val: 6 0.3954111337661743
val: 7 0.39079633355140686
val: 8 0.3915618062019348
val: 9 0.38741829991340637
val: 10 0.39723923802375793
val: 11 0.386475145816803
val: 12 0.3927752673625946
val: 13 0.3844517469406128
val: 14 0.38589945435523987
val: 15 0.3942997455596924
val: 16 0.3919534385204315
val: 17 0.4021783769130707
val: 18 0.3941381871700287
val: 19 0.3901512622833252
val: 20 0.3857133984565735
val_Epoch:[ 173 ] val_loss: 0.3912097245454788 2022-07-01 18:29:44.490372
start training 2022-07-01 18:29:44.601672
Epoch:[ 174 0 ] loss: 0.35960453748703003 2022-07-01 18:29:59.415527
Epoch:[ 174 1 ] loss: 0.36214911937713623 2022-07-01 18:29:59.845322
Epoch:[ 174 2 ] loss: 0.3613186478614807 2022-07-01 18:30:00.262427
Epoch:[ 174 3 ] loss: 0.3593394458293915 2022-07-01 18:30:00.679808
Epoch:[ 174 4 ] loss: 0.36053481698036194 2022-07-01 18:30:01.091036
Epoch:[ 174 5 ] loss: 0.3608551025390625 2022-07-01 18:30:01.499710
Epoch:[ 174 6 ] loss: 0.3599522113800049 2022-07-01 18:30:01.915783
Epoch:[ 174 7 ] loss: 0.35968485474586487 2022-07-01 18:30:02.331618
Epoch:[ 174 8 ] loss: 0.3600391745567322 2022-07-01 18:30:02.745908
Epoch:[ 174 9 ] loss: 0.3613528907299042 2022-07-01 18:30:03.159832
Epoch:[ 174 10 ] loss: 0.36041706800460815 2022-07-01 18:30:03.576772
Epoch:[ 174 11 ] loss: 0.36108046770095825 2022-07-01 18:30:03.995532
Epoch:[ 174 12 ] loss: 0.3596143424510956 2022-07-01 18:30:04.412986
Epoch:[ 174 13 ] loss: 0.3605048954486847 2022-07-01 18:30:04.827392
Epoch:[ 174 14 ] loss: 0.36005666851997375 2022-07-01 18:30:05.244122
Epoch:[ 174 15 ] loss: 0.3604251742362976 2022-07-01 18:30:05.652859
Epoch:[ 174 16 ] loss: 0.3612591326236725 2022-07-01 18:30:10.994050
Epoch:[ 174 17 ] loss: 0.3613121211528778 2022-07-01 18:30:11.405693
Epoch:[ 174 18 ] loss: 0.3609393835067749 2022-07-01 18:30:11.853278
Epoch:[ 174 19 ] loss: 0.3611910939216614 2022-07-01 18:30:12.282867
Training_Epoch:[ 174 ] Training_loss: 0.36058155745267867 2022-07-01 18:30:12.283666
learning rate:  2.2517998136852506e-05
netparams have been saved once 174
val: 1 0.3830817937850952
val: 2 0.3896639049053192
val: 3 0.3930082619190216
val: 4 0.4010111689567566
val: 5 0.38935714960098267
val: 6 0.3897021412849426
val: 7 0.38578343391418457
val: 8 0.3896072208881378
val: 9 0.3974226713180542
val: 10 0.3934488892555237
val: 11 0.3899374306201935
val: 12 0.38572460412979126
val: 13 0.3876844644546509
val: 14 0.3978220522403717
val: 15 0.38932928442955017
val: 16 0.39437156915664673
val: 17 0.38593801856040955
val: 18 0.39701607823371887
val: 19 0.3888251781463623
val: 20 0.39160585403442383
val_Epoch:[ 174 ] val_loss: 0.39101705849170687 2022-07-01 18:30:16.307761
start training 2022-07-01 18:30:16.413178
Epoch:[ 175 0 ] loss: 0.36215606331825256 2022-07-01 18:30:30.590462
Epoch:[ 175 1 ] loss: 0.35978177189826965 2022-07-01 18:30:31.151375
Epoch:[ 175 2 ] loss: 0.36042520403862 2022-07-01 18:30:31.580722
Epoch:[ 175 3 ] loss: 0.36044010519981384 2022-07-01 18:30:31.994319
Epoch:[ 175 4 ] loss: 0.36008310317993164 2022-07-01 18:30:32.411514
Epoch:[ 175 5 ] loss: 0.361019492149353 2022-07-01 18:30:32.829447
Epoch:[ 175 6 ] loss: 0.3605451285839081 2022-07-01 18:30:33.265042
Epoch:[ 175 7 ] loss: 0.36115723848342896 2022-07-01 18:30:33.694676
Epoch:[ 175 8 ] loss: 0.3610372543334961 2022-07-01 18:30:34.124497
Epoch:[ 175 9 ] loss: 0.36179807782173157 2022-07-01 18:30:34.553322
Epoch:[ 175 10 ] loss: 0.36077427864074707 2022-07-01 18:30:34.982611
Epoch:[ 175 11 ] loss: 0.3601187765598297 2022-07-01 18:30:35.413094
Epoch:[ 175 12 ] loss: 0.35987427830696106 2022-07-01 18:30:35.844839
Epoch:[ 175 13 ] loss: 0.36044323444366455 2022-07-01 18:30:36.273917
Epoch:[ 175 14 ] loss: 0.36141639947891235 2022-07-01 18:30:36.711019
Epoch:[ 175 15 ] loss: 0.3606935441493988 2022-07-01 18:30:37.145402
Epoch:[ 175 16 ] loss: 0.35957375168800354 2022-07-01 18:30:42.359967
Epoch:[ 175 17 ] loss: 0.36024031043052673 2022-07-01 18:30:42.967169
Epoch:[ 175 18 ] loss: 0.3606441915035248 2022-07-01 18:30:43.424073
Epoch:[ 175 19 ] loss: 0.3613494038581848 2022-07-01 18:30:43.855774
Training_Epoch:[ 175 ] Training_loss: 0.36067858040332795 2022-07-01 18:30:43.856483
learning rate:  2.2517998136852506e-05
val: 1 0.3851485848426819
val: 2 0.3934853672981262
val: 3 0.3852458894252777
val: 4 0.3906300961971283
val: 5 0.38122060894966125
val: 6 0.39560359716415405
val: 7 0.3895943760871887
val: 8 0.3888310492038727
val: 9 0.40141209959983826
val: 10 0.3839370906352997
val: 11 0.3990516662597656
val: 12 0.388222873210907
val: 13 0.3928282856941223
val: 14 0.3841845691204071
val: 15 0.3894447982311249
val: 16 0.4035227298736572
val: 17 0.38902056217193604
val: 18 0.39219745993614197
val: 19 0.3883923590183258
val: 20 0.39857542514801025
val_Epoch:[ 175 ] val_loss: 0.39102747440338137 2022-07-01 18:30:47.633871
start training 2022-07-01 18:30:47.743929
Epoch:[ 176 0 ] loss: 0.35918116569519043 2022-07-01 18:31:02.283554
Epoch:[ 176 1 ] loss: 0.36043694615364075 2022-07-01 18:31:02.729023
Epoch:[ 176 2 ] loss: 0.3616970181465149 2022-07-01 18:31:03.144207
Epoch:[ 176 3 ] loss: 0.3598500192165375 2022-07-01 18:31:03.574701
Epoch:[ 176 4 ] loss: 0.3602181673049927 2022-07-01 18:31:04.005976
Epoch:[ 176 5 ] loss: 0.3611656129360199 2022-07-01 18:31:04.436538
Epoch:[ 176 6 ] loss: 0.3609149158000946 2022-07-01 18:31:04.870624
Epoch:[ 176 7 ] loss: 0.36017534136772156 2022-07-01 18:31:05.308669
Epoch:[ 176 8 ] loss: 0.3600478768348694 2022-07-01 18:31:05.737712
Epoch:[ 176 9 ] loss: 0.36096248030662537 2022-07-01 18:31:06.166356
Epoch:[ 176 10 ] loss: 0.3601469397544861 2022-07-01 18:31:06.597525
Epoch:[ 176 11 ] loss: 0.36058175563812256 2022-07-01 18:31:07.032086
Epoch:[ 176 12 ] loss: 0.360952228307724 2022-07-01 18:31:07.464678
Epoch:[ 176 13 ] loss: 0.36118361353874207 2022-07-01 18:31:07.895857
Epoch:[ 176 14 ] loss: 0.3598361909389496 2022-07-01 18:31:08.338872
Epoch:[ 176 15 ] loss: 0.3611783981323242 2022-07-01 18:31:08.768432
Epoch:[ 176 16 ] loss: 0.3604414463043213 2022-07-01 18:31:13.843496
Epoch:[ 176 17 ] loss: 0.3617624044418335 2022-07-01 18:31:14.277494
Epoch:[ 176 18 ] loss: 0.36101505160331726 2022-07-01 18:31:14.714064
Epoch:[ 176 19 ] loss: 0.3605342209339142 2022-07-01 18:31:15.148567
Training_Epoch:[ 176 ] Training_loss: 0.36061408966779707 2022-07-01 18:31:15.149308
learning rate:  2.2517998136852506e-05
netparams have been saved once 176
val: 1 0.38970470428466797
val: 2 0.3889698386192322
val: 3 0.39319080114364624
val: 4 0.3897019028663635
val: 5 0.3938685357570648
val: 6 0.39366772770881653
val: 7 0.3897073566913605
val: 8 0.3933911621570587
val: 9 0.3920084536075592
val: 10 0.38804274797439575
val: 11 0.38368895649909973
val: 12 0.3940622806549072
val: 13 0.3902202248573303
val: 14 0.38752567768096924
val: 15 0.38714277744293213
val: 16 0.3895892798900604
val: 17 0.4005066454410553
val: 18 0.39030975103378296
val: 19 0.3910611569881439
val: 20 0.3927757740020752
val_Epoch:[ 176 ] val_loss: 0.39095678776502607 2022-07-01 18:31:19.102596
start training 2022-07-01 18:31:19.207195
Epoch:[ 177 0 ] loss: 0.35964685678482056 2022-07-01 18:31:33.921760
Epoch:[ 177 1 ] loss: 0.3609466552734375 2022-07-01 18:31:34.349876
Epoch:[ 177 2 ] loss: 0.3604993522167206 2022-07-01 18:31:34.780846
Epoch:[ 177 3 ] loss: 0.3605433404445648 2022-07-01 18:31:35.211430
Epoch:[ 177 4 ] loss: 0.3614963889122009 2022-07-01 18:31:35.640517
Epoch:[ 177 5 ] loss: 0.36137130856513977 2022-07-01 18:31:36.073907
Epoch:[ 177 6 ] loss: 0.3604673743247986 2022-07-01 18:31:36.505149
Epoch:[ 177 7 ] loss: 0.3605943024158478 2022-07-01 18:31:36.941108
Epoch:[ 177 8 ] loss: 0.3601449429988861 2022-07-01 18:31:37.370857
Epoch:[ 177 9 ] loss: 0.36079052090644836 2022-07-01 18:31:37.799402
Epoch:[ 177 10 ] loss: 0.3603649139404297 2022-07-01 18:31:38.233654
Epoch:[ 177 11 ] loss: 0.360620379447937 2022-07-01 18:31:38.664726
Epoch:[ 177 12 ] loss: 0.36092543601989746 2022-07-01 18:31:39.093282
Epoch:[ 177 13 ] loss: 0.35962095856666565 2022-07-01 18:31:39.522681
Epoch:[ 177 14 ] loss: 0.3608473241329193 2022-07-01 18:31:39.953558
Epoch:[ 177 15 ] loss: 0.36073750257492065 2022-07-01 18:31:40.383413
Epoch:[ 177 16 ] loss: 0.3597562313079834 2022-07-01 18:31:45.525125
Epoch:[ 177 17 ] loss: 0.3601509928703308 2022-07-01 18:31:45.952187
Epoch:[ 177 18 ] loss: 0.3605220317840576 2022-07-01 18:31:46.389944
Epoch:[ 177 19 ] loss: 0.3605406582355499 2022-07-01 18:31:46.825781
Training_Epoch:[ 177 ] Training_loss: 0.3605293735861778 2022-07-01 18:31:46.826433
learning rate:  2.2517998136852506e-05
val: 1 0.3860108554363251
val: 2 0.3834184408187866
val: 3 0.3930165469646454
val: 4 0.39038705825805664
val: 5 0.3859376013278961
val: 6 0.39446720480918884
val: 7 0.40015238523483276
val: 8 0.3908882141113281
val: 9 0.3903851807117462
val: 10 0.39426711201667786
val: 11 0.3904634118080139
val: 12 0.39141321182250977
val: 13 0.3949225842952728
val: 14 0.3827677369117737
val: 15 0.3823246359825134
val: 16 0.3969341814517975
val: 17 0.39601653814315796
val: 18 0.3916182219982147
val: 19 0.3892631232738495
val: 20 0.3923742473125458
val_Epoch:[ 177 ] val_loss: 0.39085142463445666 2022-07-01 18:31:50.693451
start training 2022-07-01 18:31:50.795706
Epoch:[ 178 0 ] loss: 0.3609446883201599 2022-07-01 18:32:05.572461
Epoch:[ 178 1 ] loss: 0.36034199595451355 2022-07-01 18:32:06.008410
Epoch:[ 178 2 ] loss: 0.36122459173202515 2022-07-01 18:32:06.441100
Epoch:[ 178 3 ] loss: 0.3599662780761719 2022-07-01 18:32:06.870176
Epoch:[ 178 4 ] loss: 0.36090385913848877 2022-07-01 18:32:07.300952
Epoch:[ 178 5 ] loss: 0.36076289415359497 2022-07-01 18:32:07.729789
Epoch:[ 178 6 ] loss: 0.3608129620552063 2022-07-01 18:32:08.160259
Epoch:[ 178 7 ] loss: 0.36085230112075806 2022-07-01 18:32:08.592310
Epoch:[ 178 8 ] loss: 0.35909730195999146 2022-07-01 18:32:09.023743
Epoch:[ 178 9 ] loss: 0.3593839406967163 2022-07-01 18:32:09.453413
Epoch:[ 178 10 ] loss: 0.36026570200920105 2022-07-01 18:32:09.883611
Epoch:[ 178 11 ] loss: 0.3590760827064514 2022-07-01 18:32:10.315634
Epoch:[ 178 12 ] loss: 0.36171674728393555 2022-07-01 18:32:10.745532
Epoch:[ 178 13 ] loss: 0.3613397479057312 2022-07-01 18:32:11.179564
Epoch:[ 178 14 ] loss: 0.35938555002212524 2022-07-01 18:32:11.610874
Epoch:[ 178 15 ] loss: 0.3616066873073578 2022-07-01 18:32:12.047355
Epoch:[ 178 16 ] loss: 0.361004114151001 2022-07-01 18:32:17.187040
Epoch:[ 178 17 ] loss: 0.3597203195095062 2022-07-01 18:32:17.619823
Epoch:[ 178 18 ] loss: 0.3606404662132263 2022-07-01 18:32:18.055176
Epoch:[ 178 19 ] loss: 0.3616257607936859 2022-07-01 18:32:18.485351
Training_Epoch:[ 178 ] Training_loss: 0.3605335995554924 2022-07-01 18:32:18.485999
learning rate:  2.2517998136852506e-05
netparams have been saved once 178
val: 1 0.3954150378704071
val: 2 0.39093029499053955
val: 3 0.3860301673412323
val: 4 0.3967660665512085
val: 5 0.3896527588367462
val: 6 0.3963964879512787
val: 7 0.38988521695137024
val: 8 0.3901681900024414
val: 9 0.3887859880924225
val: 10 0.3861519694328308
val: 11 0.38960880041122437
val: 12 0.39435410499572754
val: 13 0.39376991987228394
val: 14 0.3883805572986603
val: 15 0.3977872133255005
val: 16 0.39370059967041016
val: 17 0.386679083108902
val: 18 0.38363370299339294
val: 19 0.389896422624588
val: 20 0.3930821120738983
val_Epoch:[ 178 ] val_loss: 0.39105373471975324 2022-07-01 18:32:22.391887
start training 2022-07-01 18:32:22.495858
Epoch:[ 179 0 ] loss: 0.3599785566329956 2022-07-01 18:32:37.134390
Epoch:[ 179 1 ] loss: 0.36149564385414124 2022-07-01 18:32:37.569323
Epoch:[ 179 2 ] loss: 0.36096933484077454 2022-07-01 18:32:38.001799
Epoch:[ 179 3 ] loss: 0.3608841300010681 2022-07-01 18:32:38.431858
Epoch:[ 179 4 ] loss: 0.36122605204582214 2022-07-01 18:32:38.862102
Epoch:[ 179 5 ] loss: 0.3600679337978363 2022-07-01 18:32:39.296282
Epoch:[ 179 6 ] loss: 0.36120304465293884 2022-07-01 18:32:39.727753
Epoch:[ 179 7 ] loss: 0.3606032729148865 2022-07-01 18:32:40.157034
Epoch:[ 179 8 ] loss: 0.36060190200805664 2022-07-01 18:32:40.588073
Epoch:[ 179 9 ] loss: 0.36087968945503235 2022-07-01 18:32:41.018635
Epoch:[ 179 10 ] loss: 0.3598479926586151 2022-07-01 18:32:41.450561
Epoch:[ 179 11 ] loss: 0.3614621162414551 2022-07-01 18:32:41.880113
Epoch:[ 179 12 ] loss: 0.3601055145263672 2022-07-01 18:32:42.309362
Epoch:[ 179 13 ] loss: 0.36252066493034363 2022-07-01 18:32:42.738820
Epoch:[ 179 14 ] loss: 0.3610270321369171 2022-07-01 18:32:43.172251
Epoch:[ 179 15 ] loss: 0.3600033223628998 2022-07-01 18:32:43.609116
Epoch:[ 179 16 ] loss: 0.3601514995098114 2022-07-01 18:32:48.748183
Epoch:[ 179 17 ] loss: 0.35943907499313354 2022-07-01 18:32:49.181260
Epoch:[ 179 18 ] loss: 0.3602769672870636 2022-07-01 18:32:49.618522
Epoch:[ 179 19 ] loss: 0.35971659421920776 2022-07-01 18:32:50.046968
Training_Epoch:[ 179 ] Training_loss: 0.3606230169534683 2022-07-01 18:32:50.047676
learning rate:  2.2517998136852506e-05
val: 1 0.38795921206474304
val: 2 0.393829882144928
val: 3 0.3926944136619568
val: 4 0.39007696509361267
val: 5 0.3953106701374054
val: 6 0.3862949013710022
val: 7 0.39102858304977417
val: 8 0.3946039378643036
val: 9 0.39188122749328613
val: 10 0.39726555347442627
val: 11 0.39284875988960266
val: 12 0.3889710605144501
val: 13 0.3837793171405792
val: 14 0.3863351047039032
val: 15 0.39403167366981506
val: 16 0.3940895199775696
val: 17 0.3893336355686188
val: 18 0.3954283595085144
val: 19 0.38847482204437256
val: 20 0.39048829674720764
val_Epoch:[ 179 ] val_loss: 0.3912362948060036 2022-07-01 18:32:53.906953
start training 2022-07-01 18:32:54.011573
Epoch:[ 180 0 ] loss: 0.36010509729385376 2022-07-01 18:33:07.940356
Epoch:[ 180 1 ] loss: 0.35963231325149536 2022-07-01 18:33:08.685443
Epoch:[ 180 2 ] loss: 0.36046072840690613 2022-07-01 18:33:09.122420
Epoch:[ 180 3 ] loss: 0.36100471019744873 2022-07-01 18:33:09.554362
Epoch:[ 180 4 ] loss: 0.3616010546684265 2022-07-01 18:33:09.984947
Epoch:[ 180 5 ] loss: 0.3596685528755188 2022-07-01 18:33:10.419694
Epoch:[ 180 6 ] loss: 0.36038196086883545 2022-07-01 18:33:10.848263
Epoch:[ 180 7 ] loss: 0.36005058884620667 2022-07-01 18:33:11.277759
Epoch:[ 180 8 ] loss: 0.36056485772132874 2022-07-01 18:33:11.706800
Epoch:[ 180 9 ] loss: 0.36041873693466187 2022-07-01 18:33:12.137670
Epoch:[ 180 10 ] loss: 0.3601144254207611 2022-07-01 18:33:12.569240
Epoch:[ 180 11 ] loss: 0.3605016767978668 2022-07-01 18:33:13.000965
Epoch:[ 180 12 ] loss: 0.36038079857826233 2022-07-01 18:33:13.431296
Epoch:[ 180 13 ] loss: 0.3615932762622833 2022-07-01 18:33:13.866265
Epoch:[ 180 14 ] loss: 0.3607136309146881 2022-07-01 18:33:14.296610
Epoch:[ 180 15 ] loss: 0.3600270748138428 2022-07-01 18:33:14.725699
Epoch:[ 180 16 ] loss: 0.36166852712631226 2022-07-01 18:33:19.598839
Epoch:[ 180 17 ] loss: 0.3602195084095001 2022-07-01 18:33:20.461318
Epoch:[ 180 18 ] loss: 0.36172786355018616 2022-07-01 18:33:20.902889
Epoch:[ 180 19 ] loss: 0.3598093092441559 2022-07-01 18:33:21.330672
Training_Epoch:[ 180 ] Training_loss: 0.36053223460912703 2022-07-01 18:33:21.331306
learning rate:  2.2517998136852506e-05
netparams have been saved once 180
val: 1 0.38698455691337585
val: 2 0.39417755603790283
val: 3 0.3916670083999634
val: 4 0.3961019515991211
val: 5 0.3903355002403259
val: 6 0.39569056034088135
val: 7 0.3924439251422882
val: 8 0.39028674364089966
val: 9 0.38648298382759094
val: 10 0.38481149077415466
val: 11 0.3935440480709076
val: 12 0.3784979581832886
val: 13 0.3904803693294525
val: 14 0.39222872257232666
val: 15 0.3914521634578705
val: 16 0.3955934941768646
val: 17 0.3935836851596832
val: 18 0.39437705278396606
val: 19 0.3937007784843445
val: 20 0.3898773491382599
val_Epoch:[ 180 ] val_loss: 0.3911158949136734 2022-07-01 18:33:25.299926
start training 2022-07-01 18:33:25.403437
Epoch:[ 181 0 ] loss: 0.3590259850025177 2022-07-01 18:33:40.096251
Epoch:[ 181 1 ] loss: 0.36137089133262634 2022-07-01 18:33:40.524897
Epoch:[ 181 2 ] loss: 0.3598223328590393 2022-07-01 18:33:40.953171
Epoch:[ 181 3 ] loss: 0.3608384132385254 2022-07-01 18:33:41.384427
Epoch:[ 181 4 ] loss: 0.35899534821510315 2022-07-01 18:33:41.815431
Epoch:[ 181 5 ] loss: 0.3605807423591614 2022-07-01 18:33:42.244475
Epoch:[ 181 6 ] loss: 0.3607865869998932 2022-07-01 18:33:42.679025
Epoch:[ 181 7 ] loss: 0.36034277081489563 2022-07-01 18:33:43.108495
Epoch:[ 181 8 ] loss: 0.3607819378376007 2022-07-01 18:33:43.540710
Epoch:[ 181 9 ] loss: 0.3613125681877136 2022-07-01 18:33:43.974303
Epoch:[ 181 10 ] loss: 0.3607533574104309 2022-07-01 18:33:44.406274
Epoch:[ 181 11 ] loss: 0.3599914312362671 2022-07-01 18:33:44.842710
Epoch:[ 181 12 ] loss: 0.36051076650619507 2022-07-01 18:33:45.274243
Epoch:[ 181 13 ] loss: 0.3596492111682892 2022-07-01 18:33:45.704219
Epoch:[ 181 14 ] loss: 0.3603787422180176 2022-07-01 18:33:46.134909
Epoch:[ 181 15 ] loss: 0.3602026104927063 2022-07-01 18:33:46.563869
Epoch:[ 181 16 ] loss: 0.36067458987236023 2022-07-01 18:33:52.046070
Epoch:[ 181 17 ] loss: 0.3602312505245209 2022-07-01 18:33:52.479075
Epoch:[ 181 18 ] loss: 0.36109358072280884 2022-07-01 18:33:52.920760
Epoch:[ 181 19 ] loss: 0.36286675930023193 2022-07-01 18:33:53.349728
Training_Epoch:[ 181 ] Training_loss: 0.3605104938149452 2022-07-01 18:33:53.350380
learning rate:  1.8014398509482006e-05
val: 1 0.3922187089920044
val: 2 0.38885247707366943
val: 3 0.3995096683502197
val: 4 0.394166499376297
val: 5 0.38980770111083984
val: 6 0.3981662094593048
val: 7 0.38729962706565857
val: 8 0.3985922634601593
val: 9 0.3954411447048187
val: 10 0.3924754858016968
val: 11 0.38408613204956055
val: 12 0.3882141709327698
val: 13 0.39024198055267334
val: 14 0.39031490683555603
val: 15 0.387896329164505
val: 16 0.39305296540260315
val: 17 0.38493624329566956
val: 18 0.3824506103992462
val: 19 0.3897492587566376
val: 20 0.3918244242668152
val_Epoch:[ 181 ] val_loss: 0.39096484035253526 2022-07-01 18:33:57.317629
start training 2022-07-01 18:33:57.420927
Epoch:[ 182 0 ] loss: 0.35974857211112976 2022-07-01 18:34:12.434813
Epoch:[ 182 1 ] loss: 0.36069566011428833 2022-07-01 18:34:12.863710
Epoch:[ 182 2 ] loss: 0.3596227467060089 2022-07-01 18:34:13.292254
Epoch:[ 182 3 ] loss: 0.36030301451683044 2022-07-01 18:34:13.706972
Epoch:[ 182 4 ] loss: 0.3603973686695099 2022-07-01 18:34:14.144688
Epoch:[ 182 5 ] loss: 0.3618638217449188 2022-07-01 18:34:14.576533
Epoch:[ 182 6 ] loss: 0.36116310954093933 2022-07-01 18:34:15.007726
Epoch:[ 182 7 ] loss: 0.3612440824508667 2022-07-01 18:34:15.437573
Epoch:[ 182 8 ] loss: 0.3613482713699341 2022-07-01 18:34:15.867160
Epoch:[ 182 9 ] loss: 0.36178719997406006 2022-07-01 18:34:16.296969
Epoch:[ 182 10 ] loss: 0.36076778173446655 2022-07-01 18:34:16.726359
Epoch:[ 182 11 ] loss: 0.35988420248031616 2022-07-01 18:34:17.164070
Epoch:[ 182 12 ] loss: 0.35956189036369324 2022-07-01 18:34:17.601428
Epoch:[ 182 13 ] loss: 0.3606191873550415 2022-07-01 18:34:18.033003
Epoch:[ 182 14 ] loss: 0.3604907989501953 2022-07-01 18:34:18.463104
Epoch:[ 182 15 ] loss: 0.3616239130496979 2022-07-01 18:34:18.892538
Epoch:[ 182 16 ] loss: 0.35948291420936584 2022-07-01 18:34:23.897395
Epoch:[ 182 17 ] loss: 0.3596213161945343 2022-07-01 18:34:24.331689
Epoch:[ 182 18 ] loss: 0.35975053906440735 2022-07-01 18:34:24.777067
Epoch:[ 182 19 ] loss: 0.36125656962394714 2022-07-01 18:34:25.205921
Training_Epoch:[ 182 ] Training_loss: 0.3605616480112076 2022-07-01 18:34:25.206893
learning rate:  1.8014398509482006e-05
netparams have been saved once 182
val: 1 0.3926437497138977
val: 2 0.38819488883018494
val: 3 0.3915264904499054
val: 4 0.37782448530197144
val: 5 0.3948209881782532
val: 6 0.393116295337677
val: 7 0.388854056596756
val: 8 0.3917730450630188
val: 9 0.3860737979412079
val: 10 0.3946191966533661
val: 11 0.3861718773841858
val: 12 0.39225295186042786
val: 13 0.38956913352012634
val: 14 0.38556334376335144
val: 15 0.39798614382743835
val: 16 0.3928717374801636
val: 17 0.38733094930648804
val: 18 0.39451828598976135
val: 19 0.39683961868286133
val: 20 0.3973149359226227
val_Epoch:[ 182 ] val_loss: 0.3909932985901833 2022-07-01 18:34:29.244116
start training 2022-07-01 18:34:29.347221
Epoch:[ 183 0 ] loss: 0.36005479097366333 2022-07-01 18:34:43.443616
Epoch:[ 183 1 ] loss: 0.36058303713798523 2022-07-01 18:34:43.891577
Epoch:[ 183 2 ] loss: 0.36010438203811646 2022-07-01 18:34:44.322854
Epoch:[ 183 3 ] loss: 0.3607197701931 2022-07-01 18:34:44.757652
Epoch:[ 183 4 ] loss: 0.3601662814617157 2022-07-01 18:34:45.189255
Epoch:[ 183 5 ] loss: 0.36089983582496643 2022-07-01 18:34:45.619857
Epoch:[ 183 6 ] loss: 0.3604173958301544 2022-07-01 18:34:46.053436
Epoch:[ 183 7 ] loss: 0.3600301444530487 2022-07-01 18:34:46.488518
Epoch:[ 183 8 ] loss: 0.36048218607902527 2022-07-01 18:34:46.919647
Epoch:[ 183 9 ] loss: 0.3599838614463806 2022-07-01 18:34:47.356793
Epoch:[ 183 10 ] loss: 0.3611350357532501 2022-07-01 18:34:47.786893
Epoch:[ 183 11 ] loss: 0.3609331250190735 2022-07-01 18:34:48.215939
Epoch:[ 183 12 ] loss: 0.36130672693252563 2022-07-01 18:34:48.647536
Epoch:[ 183 13 ] loss: 0.36153122782707214 2022-07-01 18:34:49.078370
Epoch:[ 183 14 ] loss: 0.3604657053947449 2022-07-01 18:34:49.508506
Epoch:[ 183 15 ] loss: 0.3599183261394501 2022-07-01 18:34:49.937209
Epoch:[ 183 16 ] loss: 0.36015573143959045 2022-07-01 18:34:55.322307
Epoch:[ 183 17 ] loss: 0.36110150814056396 2022-07-01 18:34:55.754711
Epoch:[ 183 18 ] loss: 0.3614253103733063 2022-07-01 18:34:56.200774
Epoch:[ 183 19 ] loss: 0.35998615622520447 2022-07-01 18:34:56.635764
Training_Epoch:[ 183 ] Training_loss: 0.36057002693414686 2022-07-01 18:34:56.636449
learning rate:  1.8014398509482006e-05
val: 1 0.3965919613838196
val: 2 0.3906009793281555
val: 3 0.39144477248191833
val: 4 0.39432674646377563
val: 5 0.3925042748451233
val: 6 0.38827717304229736
val: 7 0.3896823525428772
val: 8 0.390186071395874
val: 9 0.3968135118484497
val: 10 0.3802698254585266
val: 11 0.38470011949539185
val: 12 0.38940751552581787
val: 13 0.40301087498664856
val: 14 0.3921158015727997
val: 15 0.3906727135181427
val: 16 0.3822772800922394
val: 17 0.3989377021789551
val: 18 0.3848681151866913
val: 19 0.391926109790802
val: 20 0.3890048861503601
val_Epoch:[ 183 ] val_loss: 0.3908809393644333 2022-07-01 18:35:00.542100
start training 2022-07-01 18:35:00.644495
Epoch:[ 184 0 ] loss: 0.35934263467788696 2022-07-01 18:35:15.341700
Epoch:[ 184 1 ] loss: 0.36105549335479736 2022-07-01 18:35:15.769342
Epoch:[ 184 2 ] loss: 0.3592425286769867 2022-07-01 18:35:16.202298
Epoch:[ 184 3 ] loss: 0.35959142446517944 2022-07-01 18:35:16.632604
Epoch:[ 184 4 ] loss: 0.36003896594047546 2022-07-01 18:35:17.066785
Epoch:[ 184 5 ] loss: 0.3596125841140747 2022-07-01 18:35:17.497175
Epoch:[ 184 6 ] loss: 0.3611887991428375 2022-07-01 18:35:17.928239
Epoch:[ 184 7 ] loss: 0.36084768176078796 2022-07-01 18:35:18.366370
Epoch:[ 184 8 ] loss: 0.36125174164772034 2022-07-01 18:35:18.801837
Epoch:[ 184 9 ] loss: 0.36125630140304565 2022-07-01 18:35:19.230726
Epoch:[ 184 10 ] loss: 0.3609149158000946 2022-07-01 18:35:19.659481
Epoch:[ 184 11 ] loss: 0.36046382784843445 2022-07-01 18:35:20.088282
Epoch:[ 184 12 ] loss: 0.36024707555770874 2022-07-01 18:35:20.518294
Epoch:[ 184 13 ] loss: 0.36064860224723816 2022-07-01 18:35:20.949241
Epoch:[ 184 14 ] loss: 0.3603143095970154 2022-07-01 18:35:21.379677
Epoch:[ 184 15 ] loss: 0.3607997000217438 2022-07-01 18:35:21.809618
Epoch:[ 184 16 ] loss: 0.3609395921230316 2022-07-01 18:35:26.881313
Epoch:[ 184 17 ] loss: 0.3604376018047333 2022-07-01 18:35:27.311291
Epoch:[ 184 18 ] loss: 0.3604458272457123 2022-07-01 18:35:27.748888
Epoch:[ 184 19 ] loss: 0.36115044355392456 2022-07-01 18:35:28.184234
Training_Epoch:[ 184 ] Training_loss: 0.36048950254917145 2022-07-01 18:35:28.184908
learning rate:  1.8014398509482006e-05
netparams have been saved once 184
val: 1 0.3868720233440399
val: 2 0.3904704451560974
val: 3 0.39350420236587524
val: 4 0.4007236659526825
val: 5 0.39252933859825134
val: 6 0.38262346386909485
val: 7 0.38988667726516724
val: 8 0.3972420394420624
val: 9 0.3880120813846588
val: 10 0.39521917700767517
val: 11 0.38554850220680237
val: 12 0.39690548181533813
val: 13 0.3960636556148529
val: 14 0.3893568813800812
val: 15 0.3880552351474762
val: 16 0.39062264561653137
val: 17 0.3875226676464081
val: 18 0.38571828603744507
val: 19 0.4011344015598297
val: 20 0.3876500725746155
val_Epoch:[ 184 ] val_loss: 0.3912830471992493 2022-07-01 18:35:32.135116
start training 2022-07-01 18:35:32.241225
Epoch:[ 185 0 ] loss: 0.3599592447280884 2022-07-01 18:35:46.712974
Epoch:[ 185 1 ] loss: 0.36067864298820496 2022-07-01 18:35:47.143638
Epoch:[ 185 2 ] loss: 0.3603123724460602 2022-07-01 18:35:47.579979
Epoch:[ 185 3 ] loss: 0.35977667570114136 2022-07-01 18:35:48.010512
Epoch:[ 185 4 ] loss: 0.35953623056411743 2022-07-01 18:35:48.440504
Epoch:[ 185 5 ] loss: 0.36095184087753296 2022-07-01 18:35:48.874299
Epoch:[ 185 6 ] loss: 0.3603755235671997 2022-07-01 18:35:49.302281
Epoch:[ 185 7 ] loss: 0.36024731397628784 2022-07-01 18:35:49.733420
Epoch:[ 185 8 ] loss: 0.3616187870502472 2022-07-01 18:35:50.166528
Epoch:[ 185 9 ] loss: 0.361218124628067 2022-07-01 18:35:50.600275
Epoch:[ 185 10 ] loss: 0.3601599633693695 2022-07-01 18:35:51.028634
Epoch:[ 185 11 ] loss: 0.35943305492401123 2022-07-01 18:35:51.458641
Epoch:[ 185 12 ] loss: 0.3599010705947876 2022-07-01 18:35:51.887730
Epoch:[ 185 13 ] loss: 0.36076417565345764 2022-07-01 18:35:52.316335
Epoch:[ 185 14 ] loss: 0.35999125242233276 2022-07-01 18:35:52.746803
Epoch:[ 185 15 ] loss: 0.3617842197418213 2022-07-01 18:35:53.178231
Epoch:[ 185 16 ] loss: 0.36178329586982727 2022-07-01 18:35:58.332319
Epoch:[ 185 17 ] loss: 0.36057713627815247 2022-07-01 18:35:58.764122
Epoch:[ 185 18 ] loss: 0.35935112833976746 2022-07-01 18:35:59.199656
Epoch:[ 185 19 ] loss: 0.3606996536254883 2022-07-01 18:35:59.627459
Training_Epoch:[ 185 ] Training_loss: 0.3604559853672981 2022-07-01 18:35:59.628091
learning rate:  1.8014398509482006e-05
val: 1 0.3866053521633148
val: 2 0.3952254354953766
val: 3 0.38854968547821045
val: 4 0.39576128125190735
val: 5 0.38753390312194824
val: 6 0.39008408784866333
val: 7 0.3830997347831726
val: 8 0.3967198431491852
val: 9 0.3937363922595978
val: 10 0.3891870677471161
val: 11 0.3928677439689636
val: 12 0.401103675365448
val: 13 0.39227375388145447
val: 14 0.38264399766921997
val: 15 0.3915804326534271
val: 16 0.3968098759651184
val: 17 0.3900996744632721
val: 18 0.380709707736969
val: 19 0.3916386663913727
val: 20 0.3903554379940033
val_Epoch:[ 185 ] val_loss: 0.39082928746938705 2022-07-01 18:36:03.502825
start training 2022-07-01 18:36:03.607755
Epoch:[ 186 0 ] loss: 0.36039993166923523 2022-07-01 18:36:17.754478
Epoch:[ 186 1 ] loss: 0.35955628752708435 2022-07-01 18:36:18.197451
Epoch:[ 186 2 ] loss: 0.3597368597984314 2022-07-01 18:36:18.640579
Epoch:[ 186 3 ] loss: 0.36040276288986206 2022-07-01 18:36:19.073955
Epoch:[ 186 4 ] loss: 0.3602675199508667 2022-07-01 18:36:19.489902
Epoch:[ 186 5 ] loss: 0.35941842198371887 2022-07-01 18:36:19.905086
Epoch:[ 186 6 ] loss: 0.36010876297950745 2022-07-01 18:36:20.319672
Epoch:[ 186 7 ] loss: 0.3606625199317932 2022-07-01 18:36:20.733891
Epoch:[ 186 8 ] loss: 0.36096689105033875 2022-07-01 18:36:21.151464
Epoch:[ 186 9 ] loss: 0.361308753490448 2022-07-01 18:36:21.565949
Epoch:[ 186 10 ] loss: 0.3611750900745392 2022-07-01 18:36:21.975476
Epoch:[ 186 11 ] loss: 0.3605460226535797 2022-07-01 18:36:22.391302
Epoch:[ 186 12 ] loss: 0.36167699098587036 2022-07-01 18:36:22.802417
Epoch:[ 186 13 ] loss: 0.3589056134223938 2022-07-01 18:36:23.218744
Epoch:[ 186 14 ] loss: 0.3608238697052002 2022-07-01 18:36:23.631998
Epoch:[ 186 15 ] loss: 0.3598610758781433 2022-07-01 18:36:24.063748
Epoch:[ 186 16 ] loss: 0.36024099588394165 2022-07-01 18:36:29.612718
Epoch:[ 186 17 ] loss: 0.36161312460899353 2022-07-01 18:36:30.041420
Epoch:[ 186 18 ] loss: 0.3610598146915436 2022-07-01 18:36:30.473275
Epoch:[ 186 19 ] loss: 0.36117762327194214 2022-07-01 18:36:30.907915
Training_Epoch:[ 186 ] Training_loss: 0.36049544662237165 2022-07-01 18:36:30.908649
learning rate:  1.8014398509482006e-05
netparams have been saved once 186
val: 1 0.38184213638305664
val: 2 0.3944135010242462
val: 3 0.39742162823677063
val: 4 0.39842742681503296
val: 5 0.38641220331192017
val: 6 0.3945562243461609
val: 7 0.3860051929950714
val: 8 0.39647215604782104
val: 9 0.3903803527355194
val: 10 0.3912849724292755
val: 11 0.387554794549942
val: 12 0.38515517115592957
val: 13 0.3920039236545563
val: 14 0.39016401767730713
val: 15 0.3814355731010437
val: 16 0.38704171776771545
val: 17 0.3847963213920593
val: 18 0.40217843651771545
val: 19 0.3901750445365906
val: 20 0.39796262979507446
val_Epoch:[ 186 ] val_loss: 0.39078417122364045 2022-07-01 18:36:34.870163
start training 2022-07-01 18:36:34.975402
Epoch:[ 187 0 ] loss: 0.3617425262928009 2022-07-01 18:36:49.340353
Epoch:[ 187 1 ] loss: 0.3603041172027588 2022-07-01 18:36:50.003238
Epoch:[ 187 2 ] loss: 0.3609035909175873 2022-07-01 18:36:50.440357
Epoch:[ 187 3 ] loss: 0.35976994037628174 2022-07-01 18:36:50.856323
Epoch:[ 187 4 ] loss: 0.3618181049823761 2022-07-01 18:36:51.299071
Epoch:[ 187 5 ] loss: 0.36130863428115845 2022-07-01 18:36:51.713633
Epoch:[ 187 6 ] loss: 0.35931628942489624 2022-07-01 18:36:52.134195
Epoch:[ 187 7 ] loss: 0.3612968921661377 2022-07-01 18:36:52.549729
Epoch:[ 187 8 ] loss: 0.3601236045360565 2022-07-01 18:36:52.964110
Epoch:[ 187 9 ] loss: 0.360017329454422 2022-07-01 18:36:53.380177
Epoch:[ 187 10 ] loss: 0.3611345589160919 2022-07-01 18:36:53.797076
Epoch:[ 187 11 ] loss: 0.359711229801178 2022-07-01 18:36:54.238951
Epoch:[ 187 12 ] loss: 0.3609033226966858 2022-07-01 18:36:54.655077
Epoch:[ 187 13 ] loss: 0.3589487373828888 2022-07-01 18:36:55.070479
Epoch:[ 187 14 ] loss: 0.3612125515937805 2022-07-01 18:36:55.479351
Epoch:[ 187 15 ] loss: 0.359132319688797 2022-07-01 18:36:55.887736
Epoch:[ 187 16 ] loss: 0.36165744066238403 2022-07-01 18:37:00.790630
Epoch:[ 187 17 ] loss: 0.3597762882709503 2022-07-01 18:37:01.251597
Epoch:[ 187 18 ] loss: 0.3604607582092285 2022-07-01 18:37:01.691756
Epoch:[ 187 19 ] loss: 0.36038562655448914 2022-07-01 18:37:02.120437
Training_Epoch:[ 187 ] Training_loss: 0.3604961931705475 2022-07-01 18:37:02.121170
learning rate:  1.8014398509482006e-05
val: 1 0.3981737196445465
val: 2 0.38763099908828735
val: 3 0.39740997552871704
val: 4 0.4008181095123291
val: 5 0.38540202379226685
val: 6 0.40018942952156067
val: 7 0.3904779553413391
val: 8 0.3943120539188385
val: 9 0.3916742503643036
val: 10 0.3962800204753876
val: 11 0.3860785961151123
val: 12 0.38415980339050293
val: 13 0.3962057828903198
val: 14 0.3889160454273224
val: 15 0.38972631096839905
val: 16 0.39456573128700256
val: 17 0.38727638125419617
val: 18 0.3869033753871918
val: 19 0.3880387246608734
val: 20 0.3802255690097809
val_Epoch:[ 187 ] val_loss: 0.39122324287891386 2022-07-01 18:37:06.050152
start training 2022-07-01 18:37:06.151162
Epoch:[ 188 0 ] loss: 0.36051422357559204 2022-07-01 18:37:20.330849
Epoch:[ 188 1 ] loss: 0.36020368337631226 2022-07-01 18:37:20.785090
Epoch:[ 188 2 ] loss: 0.3605647683143616 2022-07-01 18:37:21.215043
Epoch:[ 188 3 ] loss: 0.36100897192955017 2022-07-01 18:37:21.645555
Epoch:[ 188 4 ] loss: 0.36144164204597473 2022-07-01 18:37:22.076069
Epoch:[ 188 5 ] loss: 0.35997870564460754 2022-07-01 18:37:22.491890
Epoch:[ 188 6 ] loss: 0.36032208800315857 2022-07-01 18:37:22.907703
Epoch:[ 188 7 ] loss: 0.3603106439113617 2022-07-01 18:37:23.322270
Epoch:[ 188 8 ] loss: 0.3606140613555908 2022-07-01 18:37:23.730799
Epoch:[ 188 9 ] loss: 0.36065787076950073 2022-07-01 18:37:24.149793
Epoch:[ 188 10 ] loss: 0.3608590066432953 2022-07-01 18:37:24.560900
Epoch:[ 188 11 ] loss: 0.3606671988964081 2022-07-01 18:37:24.972700
Epoch:[ 188 12 ] loss: 0.3592607080936432 2022-07-01 18:37:25.388990
Epoch:[ 188 13 ] loss: 0.3595007061958313 2022-07-01 18:37:25.804529
Epoch:[ 188 14 ] loss: 0.36119943857192993 2022-07-01 18:37:26.220277
Epoch:[ 188 15 ] loss: 0.36010119318962097 2022-07-01 18:37:26.634925
Epoch:[ 188 16 ] loss: 0.36109116673469543 2022-07-01 18:37:32.180878
Epoch:[ 188 17 ] loss: 0.3608904182910919 2022-07-01 18:37:32.590000
Epoch:[ 188 18 ] loss: 0.3608183264732361 2022-07-01 18:37:33.029124
Epoch:[ 188 19 ] loss: 0.3608463406562805 2022-07-01 18:37:33.457792
Training_Epoch:[ 188 ] Training_loss: 0.36054255813360214 2022-07-01 18:37:33.458510
learning rate:  1.8014398509482006e-05
netparams have been saved once 188
val: 1 0.3888342082500458
val: 2 0.3825177550315857
val: 3 0.3890341818332672
val: 4 0.39679020643234253
val: 5 0.3894498646259308
val: 6 0.39397552609443665
val: 7 0.38956403732299805
val: 8 0.39611268043518066
val: 9 0.38887837529182434
val: 10 0.39320969581604004
val: 11 0.3887311518192291
val: 12 0.3845345973968506
val: 13 0.3877909481525421
val: 14 0.39954859018325806
val: 15 0.382187157869339
val: 16 0.3945915102958679
val: 17 0.3979434072971344
val: 18 0.3817834258079529
val: 19 0.39810091257095337
val: 20 0.3985605239868164
val_Epoch:[ 188 ] val_loss: 0.3911069378256798 2022-07-01 18:37:37.405568
start training 2022-07-01 18:37:37.507082
Epoch:[ 189 0 ] loss: 0.36026203632354736 2022-07-01 18:37:52.232871
Epoch:[ 189 1 ] loss: 0.3618033230304718 2022-07-01 18:37:52.662405
Epoch:[ 189 2 ] loss: 0.3610202670097351 2022-07-01 18:37:53.092870
Epoch:[ 189 3 ] loss: 0.36014288663864136 2022-07-01 18:37:53.522677
Epoch:[ 189 4 ] loss: 0.3601061701774597 2022-07-01 18:37:53.954853
Epoch:[ 189 5 ] loss: 0.36019980907440186 2022-07-01 18:37:54.386030
Epoch:[ 189 6 ] loss: 0.3611333966255188 2022-07-01 18:37:54.816027
Epoch:[ 189 7 ] loss: 0.35994189977645874 2022-07-01 18:37:55.247113
Epoch:[ 189 8 ] loss: 0.3609248697757721 2022-07-01 18:37:55.678494
Epoch:[ 189 9 ] loss: 0.3591781258583069 2022-07-01 18:37:56.107735
Epoch:[ 189 10 ] loss: 0.36052411794662476 2022-07-01 18:37:56.542479
Epoch:[ 189 11 ] loss: 0.36225903034210205 2022-07-01 18:37:56.974325
Epoch:[ 189 12 ] loss: 0.3612329363822937 2022-07-01 18:37:57.405358
Epoch:[ 189 13 ] loss: 0.36016878485679626 2022-07-01 18:37:57.835703
Epoch:[ 189 14 ] loss: 0.3596546947956085 2022-07-01 18:37:58.271496
Epoch:[ 189 15 ] loss: 0.36034974455833435 2022-07-01 18:37:58.681328
Epoch:[ 189 16 ] loss: 0.36073222756385803 2022-07-01 18:38:03.879148
Epoch:[ 189 17 ] loss: 0.3601684868335724 2022-07-01 18:38:04.292195
Epoch:[ 189 18 ] loss: 0.3600572347640991 2022-07-01 18:38:04.736172
Epoch:[ 189 19 ] loss: 0.3609417974948883 2022-07-01 18:38:05.166969
Training_Epoch:[ 189 ] Training_loss: 0.36054009199142456 2022-07-01 18:38:05.167673
learning rate:  1.8014398509482006e-05
val: 1 0.38960331678390503
val: 2 0.39192771911621094
val: 3 0.38595274090766907
val: 4 0.3905060291290283
val: 5 0.39678049087524414
val: 6 0.3934166729450226
val: 7 0.3874938189983368
val: 8 0.3903985619544983
val: 9 0.3888569176197052
val: 10 0.38735780119895935
val: 11 0.38150808215141296
val: 12 0.3909137547016144
val: 13 0.3989807069301605
val: 14 0.40223437547683716
val: 15 0.3874134123325348
val: 16 0.3982679843902588
val: 17 0.3882727026939392
val: 18 0.38428375124931335
val: 19 0.3924742341041565
val: 20 0.38642996549606323
val_Epoch:[ 189 ] val_loss: 0.39065365195274354 2022-07-01 18:38:09.114704
start training 2022-07-01 18:38:09.220984
Epoch:[ 190 0 ] loss: 0.3613300919532776 2022-07-01 18:38:23.960885
Epoch:[ 190 1 ] loss: 0.3602573871612549 2022-07-01 18:38:24.391911
Epoch:[ 190 2 ] loss: 0.35985031723976135 2022-07-01 18:38:24.821047
Epoch:[ 190 3 ] loss: 0.3608780801296234 2022-07-01 18:38:25.256169
Epoch:[ 190 4 ] loss: 0.3595924973487854 2022-07-01 18:38:25.684655
Epoch:[ 190 5 ] loss: 0.3597523272037506 2022-07-01 18:38:26.116410
Epoch:[ 190 6 ] loss: 0.3599224090576172 2022-07-01 18:38:26.546534
Epoch:[ 190 7 ] loss: 0.3602055609226227 2022-07-01 18:38:26.975702
Epoch:[ 190 8 ] loss: 0.3595729172229767 2022-07-01 18:38:27.404889
Epoch:[ 190 9 ] loss: 0.36029839515686035 2022-07-01 18:38:27.834667
Epoch:[ 190 10 ] loss: 0.36127227544784546 2022-07-01 18:38:28.267292
Epoch:[ 190 11 ] loss: 0.3615965247154236 2022-07-01 18:38:28.695341
Epoch:[ 190 12 ] loss: 0.3604951798915863 2022-07-01 18:38:29.132458
Epoch:[ 190 13 ] loss: 0.359981507062912 2022-07-01 18:38:29.568120
Epoch:[ 190 14 ] loss: 0.36078542470932007 2022-07-01 18:38:29.998982
Epoch:[ 190 15 ] loss: 0.3615555465221405 2022-07-01 18:38:30.427529
Epoch:[ 190 16 ] loss: 0.36112579703330994 2022-07-01 18:38:35.655104
Epoch:[ 190 17 ] loss: 0.3599385619163513 2022-07-01 18:38:36.081946
Epoch:[ 190 18 ] loss: 0.3602392077445984 2022-07-01 18:38:36.530001
Epoch:[ 190 19 ] loss: 0.36154624819755554 2022-07-01 18:38:36.963601
Training_Epoch:[ 190 ] Training_loss: 0.36050981283187866 2022-07-01 18:38:36.964290
learning rate:  1.8014398509482006e-05
netparams have been saved once 190
val: 1 0.38690006732940674
val: 2 0.3913413882255554
val: 3 0.39497020840644836
val: 4 0.3912009000778198
val: 5 0.3877580761909485
val: 6 0.3975600302219391
val: 7 0.38614189624786377
val: 8 0.39163705706596375
val: 9 0.39350104331970215
val: 10 0.3902660012245178
val: 11 0.38871583342552185
val: 12 0.38317376375198364
val: 13 0.397926390171051
val: 14 0.38449957966804504
val: 15 0.3876745104789734
val: 16 0.3952006995677948
val: 17 0.39731988310813904
val: 18 0.38332220911979675
val: 19 0.3922935724258423
val: 20 0.3925159275531769
val_Epoch:[ 190 ] val_loss: 0.3906959518790245 2022-07-01 18:38:40.900251
start training 2022-07-01 18:38:41.004269
Epoch:[ 191 0 ] loss: 0.36009854078292847 2022-07-01 18:38:55.619311
Epoch:[ 191 1 ] loss: 0.36032670736312866 2022-07-01 18:38:56.053153
Epoch:[ 191 2 ] loss: 0.3607777953147888 2022-07-01 18:38:56.486688
Epoch:[ 191 3 ] loss: 0.36059004068374634 2022-07-01 18:38:56.919749
Epoch:[ 191 4 ] loss: 0.360085129737854 2022-07-01 18:38:57.350632
Epoch:[ 191 5 ] loss: 0.3599459230899811 2022-07-01 18:38:57.782784
Epoch:[ 191 6 ] loss: 0.3608923852443695 2022-07-01 18:38:58.214843
Epoch:[ 191 7 ] loss: 0.3624716103076935 2022-07-01 18:38:58.646310
Epoch:[ 191 8 ] loss: 0.3592846095561981 2022-07-01 18:38:59.076996
Epoch:[ 191 9 ] loss: 0.3605387210845947 2022-07-01 18:38:59.511195
Epoch:[ 191 10 ] loss: 0.3600196838378906 2022-07-01 18:38:59.949861
Epoch:[ 191 11 ] loss: 0.3597981631755829 2022-07-01 18:39:00.386048
Epoch:[ 191 12 ] loss: 0.36118340492248535 2022-07-01 18:39:00.822532
Epoch:[ 191 13 ] loss: 0.36004874110221863 2022-07-01 18:39:01.254577
Epoch:[ 191 14 ] loss: 0.3622691333293915 2022-07-01 18:39:01.685326
Epoch:[ 191 15 ] loss: 0.3591436445713043 2022-07-01 18:39:02.121846
Epoch:[ 191 16 ] loss: 0.35998857021331787 2022-07-01 18:39:07.174264
Epoch:[ 191 17 ] loss: 0.35979583859443665 2022-07-01 18:39:07.608360
Epoch:[ 191 18 ] loss: 0.36031925678253174 2022-07-01 18:39:08.050873
Epoch:[ 191 19 ] loss: 0.361812025308609 2022-07-01 18:39:08.479220
Training_Epoch:[ 191 ] Training_loss: 0.36046949625015257 2022-07-01 18:39:08.480078
learning rate:  1.4411518807585605e-05
val: 1 0.38772571086883545
val: 2 0.391713410615921
val: 3 0.3889828622341156
val: 4 0.38900306820869446
val: 5 0.388033002614975
val: 6 0.39464691281318665
val: 7 0.39175233244895935
val: 8 0.39041730761528015
val: 9 0.3902917504310608
val: 10 0.3952412009239197
val: 11 0.3981763422489166
val: 12 0.38685935735702515
val: 13 0.4042375087738037
val: 14 0.3891770541667938
val: 15 0.39312678575515747
val: 16 0.3792940080165863
val: 17 0.3908219039440155
val: 18 0.3859279751777649
val: 19 0.38939154148101807
val: 20 0.39527323842048645
val_Epoch:[ 191 ] val_loss: 0.3910046637058258 2022-07-01 18:39:12.345417
start training 2022-07-01 18:39:12.453005
Epoch:[ 192 0 ] loss: 0.3612801432609558 2022-07-01 18:39:26.632669
Epoch:[ 192 1 ] loss: 0.3609806299209595 2022-07-01 18:39:27.073751
Epoch:[ 192 2 ] loss: 0.3600322902202606 2022-07-01 18:39:27.513929
Epoch:[ 192 3 ] loss: 0.36119550466537476 2022-07-01 18:39:27.943784
Epoch:[ 192 4 ] loss: 0.3609183430671692 2022-07-01 18:39:28.376019
Epoch:[ 192 5 ] loss: 0.35990169644355774 2022-07-01 18:39:28.809818
Epoch:[ 192 6 ] loss: 0.36100950837135315 2022-07-01 18:39:29.242804
Epoch:[ 192 7 ] loss: 0.35917234420776367 2022-07-01 18:39:29.678733
Epoch:[ 192 8 ] loss: 0.3595350682735443 2022-07-01 18:39:30.111596
Epoch:[ 192 9 ] loss: 0.36079317331314087 2022-07-01 18:39:30.542330
Epoch:[ 192 10 ] loss: 0.35955488681793213 2022-07-01 18:39:30.981129
Epoch:[ 192 11 ] loss: 0.3620744049549103 2022-07-01 18:39:31.412364
Epoch:[ 192 12 ] loss: 0.36084312200546265 2022-07-01 18:39:31.844142
Epoch:[ 192 13 ] loss: 0.3595831096172333 2022-07-01 18:39:32.276740
Epoch:[ 192 14 ] loss: 0.3596511483192444 2022-07-01 18:39:32.712551
Epoch:[ 192 15 ] loss: 0.3600829541683197 2022-07-01 18:39:33.130105
Epoch:[ 192 16 ] loss: 0.36045271158218384 2022-07-01 18:39:38.476197
Epoch:[ 192 17 ] loss: 0.3612326979637146 2022-07-01 18:39:38.903455
Epoch:[ 192 18 ] loss: 0.3598732650279999 2022-07-01 18:39:39.347797
Epoch:[ 192 19 ] loss: 0.3598650097846985 2022-07-01 18:39:39.779862
Training_Epoch:[ 192 ] Training_loss: 0.36040160059928894 2022-07-01 18:39:39.780560
learning rate:  1.4411518807585605e-05
netparams have been saved once 192
val: 1 0.3862401843070984
val: 2 0.39453214406967163
val: 3 0.3864101767539978
val: 4 0.3887109160423279
val: 5 0.3865714371204376
val: 6 0.3974916636943817
val: 7 0.39623117446899414
val: 8 0.3910215497016907
val: 9 0.39428287744522095
val: 10 0.3932589590549469
val: 11 0.38828572630882263
val: 12 0.3961722254753113
val: 13 0.3891572952270508
val: 14 0.3883035480976105
val: 15 0.3954619765281677
val: 16 0.38534045219421387
val: 17 0.3957650363445282
val: 18 0.3907901644706726
val: 19 0.38493457436561584
val: 20 0.39103418588638306
val_Epoch:[ 192 ] val_loss: 0.3909998133778572 2022-07-01 18:39:43.775085
start training 2022-07-01 18:39:43.879744
Epoch:[ 193 0 ] loss: 0.35948455333709717 2022-07-01 18:39:58.660588
Epoch:[ 193 1 ] loss: 0.36155322194099426 2022-07-01 18:39:59.096986
Epoch:[ 193 2 ] loss: 0.36032983660697937 2022-07-01 18:39:59.528182
Epoch:[ 193 3 ] loss: 0.3604179918766022 2022-07-01 18:39:59.959919
Epoch:[ 193 4 ] loss: 0.3602082133293152 2022-07-01 18:40:00.388820
Epoch:[ 193 5 ] loss: 0.36010411381721497 2022-07-01 18:40:00.818690
Epoch:[ 193 6 ] loss: 0.3603959381580353 2022-07-01 18:40:01.251213
Epoch:[ 193 7 ] loss: 0.3613705635070801 2022-07-01 18:40:01.680359
Epoch:[ 193 8 ] loss: 0.3614122271537781 2022-07-01 18:40:02.117495
Epoch:[ 193 9 ] loss: 0.3602188527584076 2022-07-01 18:40:02.549719
Epoch:[ 193 10 ] loss: 0.3596760928630829 2022-07-01 18:40:02.983254
Epoch:[ 193 11 ] loss: 0.36116722226142883 2022-07-01 18:40:03.416023
Epoch:[ 193 12 ] loss: 0.36017754673957825 2022-07-01 18:40:03.847043
Epoch:[ 193 13 ] loss: 0.3609778583049774 2022-07-01 18:40:04.282267
Epoch:[ 193 14 ] loss: 0.3608420789241791 2022-07-01 18:40:04.715583
Epoch:[ 193 15 ] loss: 0.3605736494064331 2022-07-01 18:40:05.149308
Epoch:[ 193 16 ] loss: 0.3588545024394989 2022-07-01 18:40:11.026518
Epoch:[ 193 17 ] loss: 0.36007386445999146 2022-07-01 18:40:11.456939
Epoch:[ 193 18 ] loss: 0.36004960536956787 2022-07-01 18:40:11.898111
Epoch:[ 193 19 ] loss: 0.3601667582988739 2022-07-01 18:40:12.332201
Training_Epoch:[ 193 ] Training_loss: 0.3604027345776558 2022-07-01 18:40:12.332909
learning rate:  1.4411518807585605e-05
val: 1 0.4020100235939026
val: 2 0.3923301100730896
val: 3 0.38487276434898376
val: 4 0.3863605558872223
val: 5 0.39196574687957764
val: 6 0.39542844891548157
val: 7 0.3870192766189575
val: 8 0.3809286952018738
val: 9 0.3883475065231323
val: 10 0.3975973129272461
val: 11 0.3909733295440674
val: 12 0.3906744718551636
val: 13 0.3941245377063751
val: 14 0.38561317324638367
val: 15 0.39411357045173645
val: 16 0.39321985840797424
val: 17 0.3832024037837982
val: 18 0.3880542516708374
val: 19 0.39628729224205017
val: 20 0.3992878794670105
val_Epoch:[ 193 ] val_loss: 0.3911205604672432 2022-07-01 18:40:16.196782
start training 2022-07-01 18:40:16.307489
Epoch:[ 194 0 ] loss: 0.36040884256362915 2022-07-01 18:40:31.102560
Epoch:[ 194 1 ] loss: 0.36054685711860657 2022-07-01 18:40:31.532557
Epoch:[ 194 2 ] loss: 0.3605330288410187 2022-07-01 18:40:31.964142
Epoch:[ 194 3 ] loss: 0.35987961292266846 2022-07-01 18:40:32.401375
Epoch:[ 194 4 ] loss: 0.36023369431495667 2022-07-01 18:40:32.834342
Epoch:[ 194 5 ] loss: 0.3601838946342468 2022-07-01 18:40:33.264528
Epoch:[ 194 6 ] loss: 0.3590252697467804 2022-07-01 18:40:33.698150
Epoch:[ 194 7 ] loss: 0.36094537377357483 2022-07-01 18:40:34.128617
Epoch:[ 194 8 ] loss: 0.360730916261673 2022-07-01 18:40:34.561410
Epoch:[ 194 9 ] loss: 0.3606705069541931 2022-07-01 18:40:34.992968
Epoch:[ 194 10 ] loss: 0.3603113293647766 2022-07-01 18:40:35.431487
Epoch:[ 194 11 ] loss: 0.3588986098766327 2022-07-01 18:40:35.863369
Epoch:[ 194 12 ] loss: 0.36057984828948975 2022-07-01 18:40:36.293641
Epoch:[ 194 13 ] loss: 0.36091315746307373 2022-07-01 18:40:36.724109
Epoch:[ 194 14 ] loss: 0.36039260029792786 2022-07-01 18:40:37.161537
Epoch:[ 194 15 ] loss: 0.36079347133636475 2022-07-01 18:40:37.591975
Epoch:[ 194 16 ] loss: 0.36154183745384216 2022-07-01 18:40:42.385787
Epoch:[ 194 17 ] loss: 0.36101943254470825 2022-07-01 18:40:43.487336
Epoch:[ 194 18 ] loss: 0.36075904965400696 2022-07-01 18:40:43.937582
Epoch:[ 194 19 ] loss: 0.36086374521255493 2022-07-01 18:40:44.373840
Training_Epoch:[ 194 ] Training_loss: 0.36046155393123624 2022-07-01 18:40:44.374516
learning rate:  1.4411518807585605e-05
netparams have been saved once 194
val: 1 0.39415866136550903
val: 2 0.3873440623283386
val: 3 0.39213788509368896
val: 4 0.3864632844924927
val: 5 0.38405030965805054
val: 6 0.39529871940612793
val: 7 0.3943009674549103
val: 8 0.3867882788181305
val: 9 0.38919568061828613
val: 10 0.3924965560436249
val: 11 0.3895246982574463
val: 12 0.3885359466075897
val: 13 0.39529159665107727
val: 14 0.38823893666267395
val: 15 0.39673155546188354
val: 16 0.3870445191860199
val: 17 0.4012109339237213
val: 18 0.38349947333335876
val: 19 0.39815589785575867
val: 20 0.38618582487106323
val_Epoch:[ 194 ] val_loss: 0.3908326894044876 2022-07-01 18:40:48.320400
start training 2022-07-01 18:40:48.440505
Epoch:[ 195 0 ] loss: 0.36115390062332153 2022-07-01 18:41:02.968290
Epoch:[ 195 1 ] loss: 0.3600482642650604 2022-07-01 18:41:03.423031
Epoch:[ 195 2 ] loss: 0.3612779676914215 2022-07-01 18:41:03.851628
Epoch:[ 195 3 ] loss: 0.36129793524742126 2022-07-01 18:41:04.292386
Epoch:[ 195 4 ] loss: 0.36118072271347046 2022-07-01 18:41:04.722490
Epoch:[ 195 5 ] loss: 0.36080703139305115 2022-07-01 18:41:05.152683
Epoch:[ 195 6 ] loss: 0.36069780588150024 2022-07-01 18:41:05.582528
Epoch:[ 195 7 ] loss: 0.3598460555076599 2022-07-01 18:41:06.011186
Epoch:[ 195 8 ] loss: 0.360986590385437 2022-07-01 18:41:06.448928
Epoch:[ 195 9 ] loss: 0.35928764939308167 2022-07-01 18:41:06.878118
Epoch:[ 195 10 ] loss: 0.36041033267974854 2022-07-01 18:41:07.309651
Epoch:[ 195 11 ] loss: 0.3601611852645874 2022-07-01 18:41:07.741804
Epoch:[ 195 12 ] loss: 0.3618091642856598 2022-07-01 18:41:08.171542
Epoch:[ 195 13 ] loss: 0.36059805750846863 2022-07-01 18:41:08.602149
Epoch:[ 195 14 ] loss: 0.35922467708587646 2022-07-01 18:41:09.031678
Epoch:[ 195 15 ] loss: 0.35991644859313965 2022-07-01 18:41:09.460512
Epoch:[ 195 16 ] loss: 0.35929614305496216 2022-07-01 18:41:14.576364
Epoch:[ 195 17 ] loss: 0.3605729043483734 2022-07-01 18:41:15.011104
Epoch:[ 195 18 ] loss: 0.36007753014564514 2022-07-01 18:41:15.452624
Epoch:[ 195 19 ] loss: 0.3603307008743286 2022-07-01 18:41:15.884298
Training_Epoch:[ 195 ] Training_loss: 0.36044905334711075 2022-07-01 18:41:15.885012
learning rate:  1.4411518807585605e-05
val: 1 0.3884390890598297
val: 2 0.3817136883735657
val: 3 0.40099790692329407
val: 4 0.3984454274177551
val: 5 0.38541173934936523
val: 6 0.38942772150039673
val: 7 0.3899185359477997
val: 8 0.3879844546318054
val: 9 0.39289402961730957
val: 10 0.3931146562099457
val: 11 0.3917253315448761
val: 12 0.3908036947250366
val: 13 0.39847737550735474
val: 14 0.3970831036567688
val: 15 0.3881789445877075
val: 16 0.3880600333213806
val: 17 0.39169779419898987
val: 18 0.3961283564567566
val: 19 0.3852022588253021
val: 20 0.3851112425327301
val_Epoch:[ 195 ] val_loss: 0.3910407692193985 2022-07-01 18:41:19.804737
start training 2022-07-01 18:41:19.911628
Epoch:[ 196 0 ] loss: 0.3599441647529602 2022-07-01 18:41:34.224839
Epoch:[ 196 1 ] loss: 0.36132046580314636 2022-07-01 18:41:34.759442
Epoch:[ 196 2 ] loss: 0.36062857508659363 2022-07-01 18:41:35.190365
Epoch:[ 196 3 ] loss: 0.3602640926837921 2022-07-01 18:41:35.619122
Epoch:[ 196 4 ] loss: 0.3603211045265198 2022-07-01 18:41:36.050780
Epoch:[ 196 5 ] loss: 0.3615419566631317 2022-07-01 18:41:36.481623
Epoch:[ 196 6 ] loss: 0.360322505235672 2022-07-01 18:41:36.911106
Epoch:[ 196 7 ] loss: 0.36025553941726685 2022-07-01 18:41:37.346678
Epoch:[ 196 8 ] loss: 0.360393762588501 2022-07-01 18:41:37.777014
Epoch:[ 196 9 ] loss: 0.3615683317184448 2022-07-01 18:41:38.209606
Epoch:[ 196 10 ] loss: 0.3599260747432709 2022-07-01 18:41:38.640352
Epoch:[ 196 11 ] loss: 0.36090102791786194 2022-07-01 18:41:39.071670
Epoch:[ 196 12 ] loss: 0.3613699972629547 2022-07-01 18:41:39.508898
Epoch:[ 196 13 ] loss: 0.35884562134742737 2022-07-01 18:41:39.938260
Epoch:[ 196 14 ] loss: 0.35982686281204224 2022-07-01 18:41:40.368048
Epoch:[ 196 15 ] loss: 0.35948821902275085 2022-07-01 18:41:40.799099
Epoch:[ 196 16 ] loss: 0.3600426912307739 2022-07-01 18:41:46.331477
Epoch:[ 196 17 ] loss: 0.3597789406776428 2022-07-01 18:41:46.763083
Epoch:[ 196 18 ] loss: 0.3616044223308563 2022-07-01 18:41:47.201204
Epoch:[ 196 19 ] loss: 0.36030179262161255 2022-07-01 18:41:47.631212
Training_Epoch:[ 196 ] Training_loss: 0.3604323074221611 2022-07-01 18:41:47.631835
learning rate:  1.4411518807585605e-05
netparams have been saved once 196
val: 1 0.3904547095298767
val: 2 0.3896149694919586
val: 3 0.39119401574134827
val: 4 0.3890887200832367
val: 5 0.3888138234615326
val: 6 0.39178478717803955
val: 7 0.3909676671028137
val: 8 0.39487382769584656
val: 9 0.3882489502429962
val: 10 0.39293062686920166
val: 11 0.3872215151786804
val: 12 0.38796404004096985
val: 13 0.3929661512374878
val: 14 0.3923388123512268
val: 15 0.39777329564094543
val: 16 0.3908081352710724
val: 17 0.3933553695678711
val: 18 0.3947485685348511
val: 19 0.3902178108692169
val: 20 0.3862033784389496
val_Epoch:[ 196 ] val_loss: 0.3910784587264061 2022-07-01 18:41:51.484547
start training 2022-07-01 18:41:51.592102
Epoch:[ 197 0 ] loss: 0.35986897349357605 2022-07-01 18:42:05.699389
Epoch:[ 197 1 ] loss: 0.3603661358356476 2022-07-01 18:42:06.158652
Epoch:[ 197 2 ] loss: 0.36006614565849304 2022-07-01 18:42:06.588938
Epoch:[ 197 3 ] loss: 0.3601689636707306 2022-07-01 18:42:07.023697
Epoch:[ 197 4 ] loss: 0.36085471510887146 2022-07-01 18:42:07.452762
Epoch:[ 197 5 ] loss: 0.361194372177124 2022-07-01 18:42:07.885629
Epoch:[ 197 6 ] loss: 0.3598282039165497 2022-07-01 18:42:08.316774
Epoch:[ 197 7 ] loss: 0.3605268895626068 2022-07-01 18:42:08.752808
Epoch:[ 197 8 ] loss: 0.36038342118263245 2022-07-01 18:42:09.187899
Epoch:[ 197 9 ] loss: 0.36126643419265747 2022-07-01 18:42:09.618471
Epoch:[ 197 10 ] loss: 0.36123228073120117 2022-07-01 18:42:10.048444
Epoch:[ 197 11 ] loss: 0.3602001667022705 2022-07-01 18:42:10.476975
Epoch:[ 197 12 ] loss: 0.3603668808937073 2022-07-01 18:42:10.910799
Epoch:[ 197 13 ] loss: 0.3591782748699188 2022-07-01 18:42:11.325539
Epoch:[ 197 14 ] loss: 0.36073949933052063 2022-07-01 18:42:11.742798
Epoch:[ 197 15 ] loss: 0.3608902394771576 2022-07-01 18:42:12.161384
Epoch:[ 197 16 ] loss: 0.3610977530479431 2022-07-01 18:42:17.419813
Epoch:[ 197 17 ] loss: 0.36072686314582825 2022-07-01 18:42:17.851913
Epoch:[ 197 18 ] loss: 0.36017975211143494 2022-07-01 18:42:18.288915
Epoch:[ 197 19 ] loss: 0.3603753447532654 2022-07-01 18:42:18.719437
Training_Epoch:[ 197 ] Training_loss: 0.36047556549310683 2022-07-01 18:42:18.720073
learning rate:  1.4411518807585605e-05
val: 1 0.3921656608581543
val: 2 0.38896116614341736
val: 3 0.3908463716506958
val: 4 0.38451260328292847
val: 5 0.3858485817909241
val: 6 0.38367554545402527
val: 7 0.39814504981040955
val: 8 0.4022809565067291
val: 9 0.4007994532585144
val: 10 0.3999427258968353
val: 11 0.39518114924430847
val: 12 0.39101558923721313
val: 13 0.395803302526474
val: 14 0.38287293910980225
val: 15 0.39035284519195557
val: 16 0.3915966749191284
val: 17 0.3863966166973114
val: 18 0.3832853436470032
val: 19 0.39239969849586487
val: 20 0.3909892439842224
val_Epoch:[ 197 ] val_loss: 0.39135357588529585 2022-07-01 18:42:22.574421
start training 2022-07-01 18:42:22.679271
Epoch:[ 198 0 ] loss: 0.35942381620407104 2022-07-01 18:42:37.466323
Epoch:[ 198 1 ] loss: 0.36128783226013184 2022-07-01 18:42:37.897780
Epoch:[ 198 2 ] loss: 0.3613905906677246 2022-07-01 18:42:38.331054
Epoch:[ 198 3 ] loss: 0.36032065749168396 2022-07-01 18:42:38.759454
Epoch:[ 198 4 ] loss: 0.36026665568351746 2022-07-01 18:42:39.187924
Epoch:[ 198 5 ] loss: 0.3605869710445404 2022-07-01 18:42:39.618234
Epoch:[ 198 6 ] loss: 0.3592725098133087 2022-07-01 18:42:40.048922
Epoch:[ 198 7 ] loss: 0.36057132482528687 2022-07-01 18:42:40.471190
Epoch:[ 198 8 ] loss: 0.3595755994319916 2022-07-01 18:42:40.907980
Epoch:[ 198 9 ] loss: 0.3597205877304077 2022-07-01 18:42:41.327253
Epoch:[ 198 10 ] loss: 0.3597484230995178 2022-07-01 18:42:41.743129
Epoch:[ 198 11 ] loss: 0.36151885986328125 2022-07-01 18:42:42.157991
Epoch:[ 198 12 ] loss: 0.36081650853157043 2022-07-01 18:42:42.572880
Epoch:[ 198 13 ] loss: 0.35948529839515686 2022-07-01 18:42:42.990892
Epoch:[ 198 14 ] loss: 0.36158013343811035 2022-07-01 18:42:43.407657
Epoch:[ 198 15 ] loss: 0.3600587248802185 2022-07-01 18:42:43.817586
Epoch:[ 198 16 ] loss: 0.36191773414611816 2022-07-01 18:42:49.049118
Epoch:[ 198 17 ] loss: 0.3600287139415741 2022-07-01 18:42:49.473696
Epoch:[ 198 18 ] loss: 0.36010682582855225 2022-07-01 18:42:49.909950
Epoch:[ 198 19 ] loss: 0.36131787300109863 2022-07-01 18:42:50.341147
Training_Epoch:[ 198 ] Training_loss: 0.3604497820138931 2022-07-01 18:42:50.341864
learning rate:  1.4411518807585605e-05
netparams have been saved once 198
val: 1 0.3887082636356354
val: 2 0.3905528783798218
val: 3 0.3872753381729126
val: 4 0.390622079372406
val: 5 0.38503342866897583
val: 6 0.3985021114349365
val: 7 0.38173070549964905
val: 8 0.3969791829586029
val: 9 0.39091816544532776
val: 10 0.38965529203414917
val: 11 0.395633339881897
val: 12 0.3893546462059021
val: 13 0.3938065469264984
val: 14 0.38883689045906067
val: 15 0.3861621618270874
val: 16 0.3940316140651703
val: 17 0.3954509496688843
val: 18 0.39115673303604126
val: 19 0.3980713188648224
val: 20 0.38782551884651184
val_Epoch:[ 198 ] val_loss: 0.39101535826921463 2022-07-01 18:42:54.180208
start training 2022-07-01 18:42:54.284907
Epoch:[ 199 0 ] loss: 0.3606893718242645 2022-07-01 18:43:09.191927
Epoch:[ 199 1 ] loss: 0.36111369729042053 2022-07-01 18:43:09.623161
Epoch:[ 199 2 ] loss: 0.3611811399459839 2022-07-01 18:43:10.053973
Epoch:[ 199 3 ] loss: 0.36006975173950195 2022-07-01 18:43:10.483317
Epoch:[ 199 4 ] loss: 0.36053091287612915 2022-07-01 18:43:10.919253
Epoch:[ 199 5 ] loss: 0.35983937978744507 2022-07-01 18:43:11.348021
Epoch:[ 199 6 ] loss: 0.36045345664024353 2022-07-01 18:43:11.781783
Epoch:[ 199 7 ] loss: 0.3596193790435791 2022-07-01 18:43:12.212876
Epoch:[ 199 8 ] loss: 0.36144548654556274 2022-07-01 18:43:12.644879
Epoch:[ 199 9 ] loss: 0.36141061782836914 2022-07-01 18:43:13.074643
Epoch:[ 199 10 ] loss: 0.3602672219276428 2022-07-01 18:43:13.504687
Epoch:[ 199 11 ] loss: 0.3589288592338562 2022-07-01 18:43:13.934646
Epoch:[ 199 12 ] loss: 0.36062198877334595 2022-07-01 18:43:14.362906
Epoch:[ 199 13 ] loss: 0.36048057675361633 2022-07-01 18:43:14.791231
Epoch:[ 199 14 ] loss: 0.3604457974433899 2022-07-01 18:43:15.221485
Epoch:[ 199 15 ] loss: 0.36022239923477173 2022-07-01 18:43:15.656618
Epoch:[ 199 16 ] loss: 0.3591192066669464 2022-07-01 18:43:20.863046
Epoch:[ 199 17 ] loss: 0.3611806333065033 2022-07-01 18:43:21.294923
Epoch:[ 199 18 ] loss: 0.3609510362148285 2022-07-01 18:43:21.731750
Epoch:[ 199 19 ] loss: 0.3602326214313507 2022-07-01 18:43:22.160794
Training_Epoch:[ 199 ] Training_loss: 0.3604401767253876 2022-07-01 18:43:22.161453
learning rate:  1.4411518807585605e-05
val: 1 0.3925412893295288
val: 2 0.38585734367370605
val: 3 0.3880073130130768
val: 4 0.38728970289230347
val: 5 0.39202022552490234
val: 6 0.39842069149017334
val: 7 0.38687992095947266
val: 8 0.38886937499046326
val: 9 0.40087711811065674
val: 10 0.39667677879333496
val: 11 0.38662344217300415
val: 12 0.3881758749485016
val: 13 0.3861634135246277
val: 14 0.38899776339530945
val: 15 0.403750479221344
val: 16 0.38533109426498413
val: 17 0.39260146021842957
val: 18 0.39063388109207153
val: 19 0.39450588822364807
val: 20 0.38625743985176086
val_Epoch:[ 199 ] val_loss: 0.391024024784565 2022-07-01 18:43:26.012984
start training 2022-07-01 18:43:26.117737
Epoch:[ 200 0 ] loss: 0.36077696084976196 2022-07-01 18:43:41.039249
Epoch:[ 200 1 ] loss: 0.36032500863075256 2022-07-01 18:43:41.469625
Epoch:[ 200 2 ] loss: 0.3595603406429291 2022-07-01 18:43:41.901670
Epoch:[ 200 3 ] loss: 0.36122438311576843 2022-07-01 18:43:42.330837
Epoch:[ 200 4 ] loss: 0.35999661684036255 2022-07-01 18:43:42.760692
Epoch:[ 200 5 ] loss: 0.36028343439102173 2022-07-01 18:43:43.189678
Epoch:[ 200 6 ] loss: 0.36021777987480164 2022-07-01 18:43:43.618903
Epoch:[ 200 7 ] loss: 0.36172011494636536 2022-07-01 18:43:44.048095
Epoch:[ 200 8 ] loss: 0.3601316809654236 2022-07-01 18:43:44.483294
Epoch:[ 200 9 ] loss: 0.3595159351825714 2022-07-01 18:43:44.922448
Epoch:[ 200 10 ] loss: 0.35922902822494507 2022-07-01 18:43:45.351634
Epoch:[ 200 11 ] loss: 0.3614204525947571 2022-07-01 18:43:45.787677
Epoch:[ 200 12 ] loss: 0.3598363697528839 2022-07-01 18:43:46.216187
Epoch:[ 200 13 ] loss: 0.36087241768836975 2022-07-01 18:43:46.644379
Epoch:[ 200 14 ] loss: 0.36099663376808167 2022-07-01 18:43:47.073517
Epoch:[ 200 15 ] loss: 0.361287921667099 2022-07-01 18:43:47.504166
Epoch:[ 200 16 ] loss: 0.35950174927711487 2022-07-01 18:43:52.911368
Epoch:[ 200 17 ] loss: 0.36025503277778625 2022-07-01 18:43:53.343527
Epoch:[ 200 18 ] loss: 0.3599817454814911 2022-07-01 18:43:53.786671
Epoch:[ 200 19 ] loss: 0.360061377286911 2022-07-01 18:43:54.215420
Training_Epoch:[ 200 ] Training_loss: 0.3603597491979599 2022-07-01 18:43:54.216071
learning rate:  1.4411518807585605e-05
netparams have been saved once 200
val: 1 0.388726145029068
val: 2 0.38871029019355774
val: 3 0.390262246131897
val: 4 0.3894989788532257
val: 5 0.3918527364730835
val: 6 0.3988044559955597
val: 7 0.394988477230072
val: 8 0.3974056839942932
val: 9 0.3887712061405182
val: 10 0.3843511641025543
val: 11 0.38712525367736816
val: 12 0.38939738273620605
val: 13 0.38981467485427856
val: 14 0.38887059688568115
val: 15 0.3924451470375061
val: 16 0.3853456377983093
val: 17 0.39232367277145386
val: 18 0.3905797004699707
val: 19 0.3909463882446289
val: 20 0.3989335000514984
val_Epoch:[ 200 ] val_loss: 0.3909576669335365 2022-07-01 18:43:58.136273
start training 2022-07-01 18:43:58.245538
Epoch:[ 201 0 ] loss: 0.36137986183166504 2022-07-01 18:44:12.772320
Epoch:[ 201 1 ] loss: 0.36006471514701843 2022-07-01 18:44:13.200139
Epoch:[ 201 2 ] loss: 0.3605693578720093 2022-07-01 18:44:13.631213
Epoch:[ 201 3 ] loss: 0.35952192544937134 2022-07-01 18:44:14.061186
Epoch:[ 201 4 ] loss: 0.35956230759620667 2022-07-01 18:44:14.491443
Epoch:[ 201 5 ] loss: 0.36164283752441406 2022-07-01 18:44:14.920475
Epoch:[ 201 6 ] loss: 0.3611370921134949 2022-07-01 18:44:15.350449
Epoch:[ 201 7 ] loss: 0.36097973585128784 2022-07-01 18:44:15.779410
Epoch:[ 201 8 ] loss: 0.36061665415763855 2022-07-01 18:44:16.211637
Epoch:[ 201 9 ] loss: 0.36061233282089233 2022-07-01 18:44:16.642170
Epoch:[ 201 10 ] loss: 0.36063969135284424 2022-07-01 18:44:17.077447
Epoch:[ 201 11 ] loss: 0.3586072623729706 2022-07-01 18:44:17.509218
Epoch:[ 201 12 ] loss: 0.3597806692123413 2022-07-01 18:44:17.939523
Epoch:[ 201 13 ] loss: 0.35988929867744446 2022-07-01 18:44:18.373225
Epoch:[ 201 14 ] loss: 0.36056259274482727 2022-07-01 18:44:18.800097
Epoch:[ 201 15 ] loss: 0.3602806627750397 2022-07-01 18:44:19.234655
Epoch:[ 201 16 ] loss: 0.359752893447876 2022-07-01 18:44:24.163443
Epoch:[ 201 17 ] loss: 0.35965487360954285 2022-07-01 18:44:24.597355
Epoch:[ 201 18 ] loss: 0.36190134286880493 2022-07-01 18:44:25.032849
Epoch:[ 201 19 ] loss: 0.3616596758365631 2022-07-01 18:44:25.464959
Training_Epoch:[ 201 ] Training_loss: 0.3604407891631126 2022-07-01 18:44:25.465630
learning rate:  1.1529215046068485e-05
val: 1 0.3987344205379486
val: 2 0.38809260725975037
val: 3 0.39234817028045654
val: 4 0.38413262367248535
val: 5 0.3920825123786926
val: 6 0.3944006860256195
val: 7 0.39601239562034607
val: 8 0.38757166266441345
val: 9 0.3887767493724823
val: 10 0.38412484526634216
val: 11 0.39024072885513306
val: 12 0.3869127631187439
val: 13 0.395101398229599
val: 14 0.382829487323761
val: 15 0.3936407268047333
val: 16 0.39195194840431213
val: 17 0.3915215730667114
val: 18 0.39732998609542847
val: 19 0.3909066915512085
val: 20 0.3974546194076538
val_Epoch:[ 201 ] val_loss: 0.3912083297967911 2022-07-01 18:44:29.386606
start training 2022-07-01 18:44:29.498459
Epoch:[ 202 0 ] loss: 0.3601192235946655 2022-07-01 18:44:44.249765
Epoch:[ 202 1 ] loss: 0.36105483770370483 2022-07-01 18:44:44.678640
Epoch:[ 202 2 ] loss: 0.36030831933021545 2022-07-01 18:44:45.108223
Epoch:[ 202 3 ] loss: 0.3614766597747803 2022-07-01 18:44:45.543934
Epoch:[ 202 4 ] loss: 0.36069852113723755 2022-07-01 18:44:45.977415
Epoch:[ 202 5 ] loss: 0.36049705743789673 2022-07-01 18:44:46.406919
Epoch:[ 202 6 ] loss: 0.3591407239437103 2022-07-01 18:44:46.841241
Epoch:[ 202 7 ] loss: 0.36044183373451233 2022-07-01 18:44:47.272380
Epoch:[ 202 8 ] loss: 0.3615940809249878 2022-07-01 18:44:47.702408
Epoch:[ 202 9 ] loss: 0.36098966002464294 2022-07-01 18:44:48.132797
Epoch:[ 202 10 ] loss: 0.36157816648483276 2022-07-01 18:44:48.565586
Epoch:[ 202 11 ] loss: 0.3595062494277954 2022-07-01 18:44:49.004896
Epoch:[ 202 12 ] loss: 0.36083516478538513 2022-07-01 18:44:49.436050
Epoch:[ 202 13 ] loss: 0.35979700088500977 2022-07-01 18:44:49.869321
Epoch:[ 202 14 ] loss: 0.3598611056804657 2022-07-01 18:44:50.284706
Epoch:[ 202 15 ] loss: 0.3595283031463623 2022-07-01 18:44:50.699298
Epoch:[ 202 16 ] loss: 0.3599666357040405 2022-07-01 18:44:55.702576
Epoch:[ 202 17 ] loss: 0.36055871844291687 2022-07-01 18:44:56.131715
Epoch:[ 202 18 ] loss: 0.36078113317489624 2022-07-01 18:44:56.574976
Epoch:[ 202 19 ] loss: 0.3602965772151947 2022-07-01 18:44:57.005813
Training_Epoch:[ 202 ] Training_loss: 0.3604514986276627 2022-07-01 18:44:57.006515
learning rate:  1.1529215046068485e-05
netparams have been saved once 202
val: 1 0.39036092162132263
val: 2 0.39418157935142517
val: 3 0.38980168104171753
val: 4 0.39055684208869934
val: 5 0.3873394727706909
val: 6 0.3929498493671417
val: 7 0.39623621106147766
val: 8 0.38964036107063293
val: 9 0.3880816698074341
val: 10 0.3890872299671173
val: 11 0.3885498344898224
val: 12 0.3932656943798065
val: 13 0.3977072238922119
val: 14 0.38914361596107483
val: 15 0.3861927092075348
val: 16 0.3911705017089844
val: 17 0.39192280173301697
val: 18 0.396014928817749
val: 19 0.39322593808174133
val: 20 0.384191632270813
val_Epoch:[ 202 ] val_loss: 0.39098103493452074 2022-07-01 18:45:00.945657
start training 2022-07-01 18:45:01.050273
Epoch:[ 203 0 ] loss: 0.3626119792461395 2022-07-01 18:45:16.056929
Epoch:[ 203 1 ] loss: 0.35986003279685974 2022-07-01 18:45:16.485969
Epoch:[ 203 2 ] loss: 0.360154390335083 2022-07-01 18:45:16.914845
Epoch:[ 203 3 ] loss: 0.36055612564086914 2022-07-01 18:45:17.344991
Epoch:[ 203 4 ] loss: 0.3601771295070648 2022-07-01 18:45:17.781864
Epoch:[ 203 5 ] loss: 0.36046651005744934 2022-07-01 18:45:18.212549
Epoch:[ 203 6 ] loss: 0.36037230491638184 2022-07-01 18:45:18.644812
Epoch:[ 203 7 ] loss: 0.36139610409736633 2022-07-01 18:45:19.074930
Epoch:[ 203 8 ] loss: 0.36072447896003723 2022-07-01 18:45:19.507783
Epoch:[ 203 9 ] loss: 0.35962799191474915 2022-07-01 18:45:19.942408
Epoch:[ 203 10 ] loss: 0.3594892621040344 2022-07-01 18:45:20.371052
Epoch:[ 203 11 ] loss: 0.35987043380737305 2022-07-01 18:45:20.801965
Epoch:[ 203 12 ] loss: 0.36044251918792725 2022-07-01 18:45:21.239795
Epoch:[ 203 13 ] loss: 0.36067041754722595 2022-07-01 18:45:21.669388
Epoch:[ 203 14 ] loss: 0.36007726192474365 2022-07-01 18:45:22.097222
Epoch:[ 203 15 ] loss: 0.3601796329021454 2022-07-01 18:45:22.526863
Epoch:[ 203 16 ] loss: 0.360880970954895 2022-07-01 18:45:27.647122
Epoch:[ 203 17 ] loss: 0.360757052898407 2022-07-01 18:45:28.079584
Epoch:[ 203 18 ] loss: 0.35871899127960205 2022-07-01 18:45:28.520606
Epoch:[ 203 19 ] loss: 0.36085793375968933 2022-07-01 18:45:28.949405
Training_Epoch:[ 203 ] Training_loss: 0.3603945761919022 2022-07-01 18:45:28.950083
learning rate:  1.1529215046068485e-05
val: 1 0.3915221393108368
val: 2 0.39558663964271545
val: 3 0.3930407166481018
val: 4 0.3908137083053589
val: 5 0.39323335886001587
val: 6 0.3884011507034302
val: 7 0.3925279974937439
val: 8 0.3920465111732483
val: 9 0.39457371830940247
val: 10 0.38855817914009094
val: 11 0.39042928814888
val: 12 0.38769590854644775
val: 13 0.39286768436431885
val: 14 0.3956109881401062
val: 15 0.3878774344921112
val: 16 0.3893914222717285
val: 17 0.3856322765350342
val: 18 0.3878821134567261
val: 19 0.39356228709220886
val: 20 0.3870227634906769
val_Epoch:[ 203 ] val_loss: 0.39091381430625916 2022-07-01 18:45:32.841876
start training 2022-07-01 18:45:32.946529
Epoch:[ 204 0 ] loss: 0.3604556918144226 2022-07-01 18:45:46.984296
Epoch:[ 204 1 ] loss: 0.36088183522224426 2022-07-01 18:45:47.765646
Epoch:[ 204 2 ] loss: 0.3602285385131836 2022-07-01 18:45:48.196134
Epoch:[ 204 3 ] loss: 0.3604193329811096 2022-07-01 18:45:48.624979
Epoch:[ 204 4 ] loss: 0.3600991666316986 2022-07-01 18:45:49.054661
Epoch:[ 204 5 ] loss: 0.3602091073989868 2022-07-01 18:45:49.488659
Epoch:[ 204 6 ] loss: 0.36074745655059814 2022-07-01 18:45:49.925646
Epoch:[ 204 7 ] loss: 0.3610379099845886 2022-07-01 18:45:50.355407
Epoch:[ 204 8 ] loss: 0.36118948459625244 2022-07-01 18:45:50.790512
Epoch:[ 204 9 ] loss: 0.36033061146736145 2022-07-01 18:45:51.220370
Epoch:[ 204 10 ] loss: 0.3598312735557556 2022-07-01 18:45:51.652698
Epoch:[ 204 11 ] loss: 0.3595905005931854 2022-07-01 18:45:52.082542
Epoch:[ 204 12 ] loss: 0.35976478457450867 2022-07-01 18:45:52.514963
Epoch:[ 204 13 ] loss: 0.3601635992527008 2022-07-01 18:45:52.952936
Epoch:[ 204 14 ] loss: 0.3613402247428894 2022-07-01 18:45:53.384033
Epoch:[ 204 15 ] loss: 0.3611926734447479 2022-07-01 18:45:53.813380
Epoch:[ 204 16 ] loss: 0.36014461517333984 2022-07-01 18:45:58.719177
Epoch:[ 204 17 ] loss: 0.3606002926826477 2022-07-01 18:45:59.367131
Epoch:[ 204 18 ] loss: 0.36099889874458313 2022-07-01 18:45:59.803200
Epoch:[ 204 19 ] loss: 0.35948553681373596 2022-07-01 18:46:00.238223
Training_Epoch:[ 204 ] Training_loss: 0.36043557673692705 2022-07-01 18:46:00.238888
learning rate:  1.1529215046068485e-05
netparams have been saved once 204
val: 1 0.39116016030311584
val: 2 0.3878771662712097
val: 3 0.3877553939819336
val: 4 0.3978835940361023
val: 5 0.3938016891479492
val: 6 0.3963474631309509
val: 7 0.38801369071006775
val: 8 0.38932672142982483
val: 9 0.3958514332771301
val: 10 0.39052969217300415
val: 11 0.39180877804756165
val: 12 0.3973236083984375
val: 13 0.3902765214443207
val: 14 0.39471349120140076
val: 15 0.38683050870895386
val: 16 0.3863512873649597
val: 17 0.3894575238227844
val: 18 0.39562639594078064
val: 19 0.3816131353378296
val: 20 0.38687849044799805
val_Epoch:[ 204 ] val_loss: 0.3909713372588158 2022-07-01 18:46:04.159076
start training 2022-07-01 18:46:04.264634
Epoch:[ 205 0 ] loss: 0.3601900339126587 2022-07-01 18:46:19.167400
Epoch:[ 205 1 ] loss: 0.3599734902381897 2022-07-01 18:46:19.597197
Epoch:[ 205 2 ] loss: 0.36084091663360596 2022-07-01 18:46:20.027879
Epoch:[ 205 3 ] loss: 0.36127009987831116 2022-07-01 18:46:20.456868
Epoch:[ 205 4 ] loss: 0.36060506105422974 2022-07-01 18:46:20.884547
Epoch:[ 205 5 ] loss: 0.36138829588890076 2022-07-01 18:46:21.313379
Epoch:[ 205 6 ] loss: 0.36022067070007324 2022-07-01 18:46:21.748626
Epoch:[ 205 7 ] loss: 0.3595214784145355 2022-07-01 18:46:22.178983
Epoch:[ 205 8 ] loss: 0.36025336384773254 2022-07-01 18:46:22.614165
Epoch:[ 205 9 ] loss: 0.36114805936813354 2022-07-01 18:46:23.045574
Epoch:[ 205 10 ] loss: 0.36035510897636414 2022-07-01 18:46:23.477156
Epoch:[ 205 11 ] loss: 0.3606835901737213 2022-07-01 18:46:23.906342
Epoch:[ 205 12 ] loss: 0.36077064275741577 2022-07-01 18:46:24.335636
Epoch:[ 205 13 ] loss: 0.36097100377082825 2022-07-01 18:46:24.766912
Epoch:[ 205 14 ] loss: 0.359279066324234 2022-07-01 18:46:25.198211
Epoch:[ 205 15 ] loss: 0.3601202964782715 2022-07-01 18:46:25.635762
Epoch:[ 205 16 ] loss: 0.36017653346061707 2022-07-01 18:46:30.968176
Epoch:[ 205 17 ] loss: 0.3598836362361908 2022-07-01 18:46:31.400851
Epoch:[ 205 18 ] loss: 0.36061885952949524 2022-07-01 18:46:31.842182
Epoch:[ 205 19 ] loss: 0.35989823937416077 2022-07-01 18:46:32.270342
Training_Epoch:[ 205 ] Training_loss: 0.3604084223508835 2022-07-01 18:46:32.270995
learning rate:  1.1529215046068485e-05
val: 1 0.39751312136650085
val: 2 0.40060991048812866
val: 3 0.391041100025177
val: 4 0.3849100172519684
val: 5 0.38349494338035583
val: 6 0.3875121772289276
val: 7 0.3859073519706726
val: 8 0.39225077629089355
val: 9 0.38195720314979553
val: 10 0.3902837932109833
val: 11 0.3940011262893677
val: 12 0.39137089252471924
val: 13 0.39413827657699585
val: 14 0.39743828773498535
val: 15 0.39015185832977295
val: 16 0.39384162425994873
val: 17 0.38819000124931335
val: 18 0.38621985912323
val: 19 0.39083048701286316
val: 20 0.3997704088687897
val_Epoch:[ 205 ] val_loss: 0.39107166081666944 2022-07-01 18:46:36.142060
start training 2022-07-01 18:46:36.247875
Epoch:[ 206 0 ] loss: 0.3604459762573242 2022-07-01 18:46:50.551466
Epoch:[ 206 1 ] loss: 0.35967162251472473 2022-07-01 18:46:50.984638
Epoch:[ 206 2 ] loss: 0.3598254323005676 2022-07-01 18:46:51.416850
Epoch:[ 206 3 ] loss: 0.36059391498565674 2022-07-01 18:46:51.846823
Epoch:[ 206 4 ] loss: 0.3609313368797302 2022-07-01 18:46:52.263411
Epoch:[ 206 5 ] loss: 0.36073747277259827 2022-07-01 18:46:52.678796
Epoch:[ 206 6 ] loss: 0.3600568175315857 2022-07-01 18:46:53.086607
Epoch:[ 206 7 ] loss: 0.3604113459587097 2022-07-01 18:46:53.501362
Epoch:[ 206 8 ] loss: 0.3586302101612091 2022-07-01 18:46:53.918375
Epoch:[ 206 9 ] loss: 0.36121541261672974 2022-07-01 18:46:54.333567
Epoch:[ 206 10 ] loss: 0.36074578762054443 2022-07-01 18:46:54.749334
Epoch:[ 206 11 ] loss: 0.3610849678516388 2022-07-01 18:46:55.164991
Epoch:[ 206 12 ] loss: 0.3605879247188568 2022-07-01 18:46:55.582323
Epoch:[ 206 13 ] loss: 0.36009481549263 2022-07-01 18:46:55.998056
Epoch:[ 206 14 ] loss: 0.3600178062915802 2022-07-01 18:46:56.408523
Epoch:[ 206 15 ] loss: 0.36129212379455566 2022-07-01 18:46:56.844378
Epoch:[ 206 16 ] loss: 0.35921141505241394 2022-07-01 18:47:02.326439
Epoch:[ 206 17 ] loss: 0.3613390326499939 2022-07-01 18:47:02.759052
Epoch:[ 206 18 ] loss: 0.360684335231781 2022-07-01 18:47:03.198679
Epoch:[ 206 19 ] loss: 0.3596872091293335 2022-07-01 18:47:03.627008
Training_Epoch:[ 206 ] Training_loss: 0.3603632479906082 2022-07-01 18:47:03.627705
learning rate:  1.1529215046068485e-05
netparams have been saved once 206
val: 1 0.38711413741111755
val: 2 0.395368754863739
val: 3 0.3941403329372406
val: 4 0.39447569847106934
val: 5 0.3941686153411865
val: 6 0.38886186480522156
val: 7 0.3880760073661804
val: 8 0.38682883977890015
val: 9 0.38800081610679626
val: 10 0.39310139417648315
val: 11 0.38238537311553955
val: 12 0.3878386914730072
val: 13 0.3869403600692749
val: 14 0.4050338864326477
val: 15 0.3932885527610779
val: 16 0.38085949420928955
val: 17 0.3979094624519348
val: 18 0.3909597396850586
val: 19 0.3939666152000427
val: 20 0.39327046275138855
val_Epoch:[ 206 ] val_loss: 0.3911294549703598 2022-07-01 18:47:07.556050
start training 2022-07-01 18:47:07.654993
Epoch:[ 207 0 ] loss: 0.3601383864879608 2022-07-01 18:47:22.071279
Epoch:[ 207 1 ] loss: 0.36021333932876587 2022-07-01 18:47:22.522449
Epoch:[ 207 2 ] loss: 0.359662801027298 2022-07-01 18:47:22.959939
Epoch:[ 207 3 ] loss: 0.35977211594581604 2022-07-01 18:47:23.390715
Epoch:[ 207 4 ] loss: 0.36144837737083435 2022-07-01 18:47:23.822816
Epoch:[ 207 5 ] loss: 0.35976988077163696 2022-07-01 18:47:24.253038
Epoch:[ 207 6 ] loss: 0.3589210510253906 2022-07-01 18:47:24.688039
Epoch:[ 207 7 ] loss: 0.36204731464385986 2022-07-01 18:47:25.117638
Epoch:[ 207 8 ] loss: 0.36109307408332825 2022-07-01 18:47:25.549724
Epoch:[ 207 9 ] loss: 0.3607330322265625 2022-07-01 18:47:25.980755
Epoch:[ 207 10 ] loss: 0.36006975173950195 2022-07-01 18:47:26.416057
Epoch:[ 207 11 ] loss: 0.360826700925827 2022-07-01 18:47:26.845638
Epoch:[ 207 12 ] loss: 0.3593088388442993 2022-07-01 18:47:27.275962
Epoch:[ 207 13 ] loss: 0.3605635464191437 2022-07-01 18:47:27.704770
Epoch:[ 207 14 ] loss: 0.3610508143901825 2022-07-01 18:47:28.135429
Epoch:[ 207 15 ] loss: 0.36068108677864075 2022-07-01 18:47:28.565585
Epoch:[ 207 16 ] loss: 0.360211044549942 2022-07-01 18:47:33.533608
Epoch:[ 207 17 ] loss: 0.35949626564979553 2022-07-01 18:47:33.961692
Epoch:[ 207 18 ] loss: 0.3607138693332672 2022-07-01 18:47:34.403382
Epoch:[ 207 19 ] loss: 0.3603707551956177 2022-07-01 18:47:34.837218
Training_Epoch:[ 207 ] Training_loss: 0.36035460233688354 2022-07-01 18:47:34.837825
learning rate:  1.1529215046068485e-05
val: 1 0.3920699656009674
val: 2 0.3957107663154602
val: 3 0.39431166648864746
val: 4 0.3896332383155823
val: 5 0.3811691701412201
val: 6 0.3944855034351349
val: 7 0.3956736922264099
val: 8 0.39036133885383606
val: 9 0.38772207498550415
val: 10 0.3871573209762573
val: 11 0.3908947706222534
val: 12 0.39443713426589966
val: 13 0.3799586296081543
val: 14 0.3933313190937042
val: 15 0.38198941946029663
val: 16 0.39698296785354614
val: 17 0.39355823397636414
val: 18 0.3847876787185669
val: 19 0.40241971611976624
val: 20 0.4003050625324249
val_Epoch:[ 207 ] val_loss: 0.39134798347949984 2022-07-01 18:47:38.684515
start training 2022-07-01 18:47:38.784392
Epoch:[ 208 0 ] loss: 0.3602011501789093 2022-07-01 18:47:53.506903
Epoch:[ 208 1 ] loss: 0.360255628824234 2022-07-01 18:47:53.940975
Epoch:[ 208 2 ] loss: 0.35989922285079956 2022-07-01 18:47:54.370921
Epoch:[ 208 3 ] loss: 0.3598398268222809 2022-07-01 18:47:54.807041
Epoch:[ 208 4 ] loss: 0.3611602187156677 2022-07-01 18:47:55.237383
Epoch:[ 208 5 ] loss: 0.35986781120300293 2022-07-01 18:47:55.666561
Epoch:[ 208 6 ] loss: 0.359939843416214 2022-07-01 18:47:56.096464
Epoch:[ 208 7 ] loss: 0.3598983585834503 2022-07-01 18:47:56.524803
Epoch:[ 208 8 ] loss: 0.3596867620944977 2022-07-01 18:47:56.957139
Epoch:[ 208 9 ] loss: 0.36016911268234253 2022-07-01 18:47:57.392495
Epoch:[ 208 10 ] loss: 0.36022958159446716 2022-07-01 18:47:57.824017
Epoch:[ 208 11 ] loss: 0.36202144622802734 2022-07-01 18:47:58.254197
Epoch:[ 208 12 ] loss: 0.36097976565361023 2022-07-01 18:47:58.684753
Epoch:[ 208 13 ] loss: 0.35959166288375854 2022-07-01 18:47:59.115915
Epoch:[ 208 14 ] loss: 0.36069226264953613 2022-07-01 18:47:59.545774
Epoch:[ 208 15 ] loss: 0.36019080877304077 2022-07-01 18:47:59.973778
Epoch:[ 208 16 ] loss: 0.35956135392189026 2022-07-01 18:48:04.956364
Epoch:[ 208 17 ] loss: 0.3614945113658905 2022-07-01 18:48:05.386501
Epoch:[ 208 18 ] loss: 0.36087536811828613 2022-07-01 18:48:05.921117
Epoch:[ 208 19 ] loss: 0.36021119356155396 2022-07-01 18:48:06.353962
Training_Epoch:[ 208 ] Training_loss: 0.360338294506073 2022-07-01 18:48:06.354611
learning rate:  1.1529215046068485e-05
netparams have been saved once 208
val: 1 0.39436396956443787
val: 2 0.38488027453422546
val: 3 0.39152759313583374
val: 4 0.39335060119628906
val: 5 0.3834388554096222
val: 6 0.389204740524292
val: 7 0.3912558853626251
val: 8 0.39038220047950745
val: 9 0.3889196515083313
val: 10 0.3909911811351776
val: 11 0.40104609727859497
val: 12 0.39452895522117615
val: 13 0.38795050978660583
val: 14 0.3915215730667114
val: 15 0.3886260390281677
val: 16 0.39124545454978943
val: 17 0.3934234082698822
val: 18 0.38612210750579834
val: 19 0.3885580003261566
val: 20 0.40102124214172363
val_Epoch:[ 208 ] val_loss: 0.39111791700124743 2022-07-01 18:48:10.235373
start training 2022-07-01 18:48:10.334305
Epoch:[ 209 0 ] loss: 0.36004987359046936 2022-07-01 18:48:25.307105
Epoch:[ 209 1 ] loss: 0.36063992977142334 2022-07-01 18:48:25.736134
Epoch:[ 209 2 ] loss: 0.36069077253341675 2022-07-01 18:48:26.164960
Epoch:[ 209 3 ] loss: 0.36134886741638184 2022-07-01 18:48:26.597699
Epoch:[ 209 4 ] loss: 0.3604526221752167 2022-07-01 18:48:27.028351
Epoch:[ 209 5 ] loss: 0.3597925305366516 2022-07-01 18:48:27.460837
Epoch:[ 209 6 ] loss: 0.36029666662216187 2022-07-01 18:48:27.890887
Epoch:[ 209 7 ] loss: 0.36068907380104065 2022-07-01 18:48:28.325279
Epoch:[ 209 8 ] loss: 0.3598195016384125 2022-07-01 18:48:28.757080
Epoch:[ 209 9 ] loss: 0.360978364944458 2022-07-01 18:48:29.185364
Epoch:[ 209 10 ] loss: 0.3605921268463135 2022-07-01 18:48:29.616379
Epoch:[ 209 11 ] loss: 0.36007773876190186 2022-07-01 18:48:30.049181
Epoch:[ 209 12 ] loss: 0.3608338534832001 2022-07-01 18:48:30.484276
Epoch:[ 209 13 ] loss: 0.36002010107040405 2022-07-01 18:48:30.914157
Epoch:[ 209 14 ] loss: 0.36054474115371704 2022-07-01 18:48:31.343804
Epoch:[ 209 15 ] loss: 0.3604430556297302 2022-07-01 18:48:31.774641
Epoch:[ 209 16 ] loss: 0.3608739674091339 2022-07-01 18:48:36.797655
Epoch:[ 209 17 ] loss: 0.3598540723323822 2022-07-01 18:48:37.225461
Epoch:[ 209 18 ] loss: 0.35910338163375854 2022-07-01 18:48:37.670442
Epoch:[ 209 19 ] loss: 0.36148273944854736 2022-07-01 18:48:38.104268
Training_Epoch:[ 209 ] Training_loss: 0.3604291990399361 2022-07-01 18:48:38.104918
learning rate:  1.1529215046068485e-05
val: 1 0.3959166705608368
val: 2 0.38684818148612976
val: 3 0.3913276195526123
val: 4 0.39164838194847107
val: 5 0.3934153914451599
val: 6 0.3892533481121063
val: 7 0.39191120862960815
val: 8 0.390651673078537
val: 9 0.3866331875324249
val: 10 0.39138439297676086
val: 11 0.38831642270088196
val: 12 0.38967472314834595
val: 13 0.3939550817012787
val: 14 0.3927645981311798
val: 15 0.3856985569000244
val: 16 0.3947182595729828
val: 17 0.3921831250190735
val: 18 0.38373851776123047
val: 19 0.3955497145652771
val: 20 0.3966085910797119
val_Epoch:[ 209 ] val_loss: 0.39110988229513166 2022-07-01 18:48:42.023269
start training 2022-07-01 18:48:42.120440
Epoch:[ 210 0 ] loss: 0.36048799753189087 2022-07-01 18:48:56.337066
Epoch:[ 210 1 ] loss: 0.3605267107486725 2022-07-01 18:48:56.883446
Epoch:[ 210 2 ] loss: 0.35973960161209106 2022-07-01 18:48:57.311714
Epoch:[ 210 3 ] loss: 0.3601425290107727 2022-07-01 18:48:57.739678
Epoch:[ 210 4 ] loss: 0.36014753580093384 2022-07-01 18:48:58.170729
Epoch:[ 210 5 ] loss: 0.3591746985912323 2022-07-01 18:48:58.599932
Epoch:[ 210 6 ] loss: 0.36135193705558777 2022-07-01 18:48:59.029496
Epoch:[ 210 7 ] loss: 0.3606323301792145 2022-07-01 18:48:59.458920
Epoch:[ 210 8 ] loss: 0.3614642322063446 2022-07-01 18:48:59.887121
Epoch:[ 210 9 ] loss: 0.36166688799858093 2022-07-01 18:49:00.320423
Epoch:[ 210 10 ] loss: 0.3596756160259247 2022-07-01 18:49:00.747126
Epoch:[ 210 11 ] loss: 0.3601440191268921 2022-07-01 18:49:01.178001
Epoch:[ 210 12 ] loss: 0.35963431000709534 2022-07-01 18:49:01.607557
Epoch:[ 210 13 ] loss: 0.3595390319824219 2022-07-01 18:49:02.036238
Epoch:[ 210 14 ] loss: 0.3602001965045929 2022-07-01 18:49:02.472053
Epoch:[ 210 15 ] loss: 0.3601626455783844 2022-07-01 18:49:02.906304
Epoch:[ 210 16 ] loss: 0.36027154326438904 2022-07-01 18:49:07.743486
Epoch:[ 210 17 ] loss: 0.36075708270072937 2022-07-01 18:49:08.174268
Epoch:[ 210 18 ] loss: 0.3604099154472351 2022-07-01 18:49:08.623810
Epoch:[ 210 19 ] loss: 0.3605334758758545 2022-07-01 18:49:09.054233
Training_Epoch:[ 210 ] Training_loss: 0.360333114862442 2022-07-01 18:49:09.054867
learning rate:  1.1529215046068485e-05
netparams have been saved once 210
val: 1 0.389020711183548
val: 2 0.3966209292411804
val: 3 0.39574673771858215
val: 4 0.3846561014652252
val: 5 0.3866983950138092
val: 6 0.39762166142463684
val: 7 0.3962363302707672
val: 8 0.3933742642402649
val: 9 0.3949606418609619
val: 10 0.3931099772453308
val: 11 0.39270758628845215
val: 12 0.3886473774909973
val: 13 0.38714584708213806
val: 14 0.3906555473804474
val: 15 0.38826555013656616
val: 16 0.38740381598472595
val: 17 0.3796333372592926
val: 18 0.393709272146225
val: 19 0.39101263880729675
val: 20 0.39653369784355164
val_Epoch:[ 210 ] val_loss: 0.39118802100419997 2022-07-01 18:49:13.200760
start training 2022-07-01 18:49:13.300784
Epoch:[ 211 0 ] loss: 0.36109161376953125 2022-07-01 18:49:28.276996
Epoch:[ 211 1 ] loss: 0.3600374162197113 2022-07-01 18:49:28.706208
Epoch:[ 211 2 ] loss: 0.3610646426677704 2022-07-01 18:49:29.134800
Epoch:[ 211 3 ] loss: 0.36024191975593567 2022-07-01 18:49:29.563358
Epoch:[ 211 4 ] loss: 0.36155033111572266 2022-07-01 18:49:29.992922
Epoch:[ 211 5 ] loss: 0.36021482944488525 2022-07-01 18:49:30.423436
Epoch:[ 211 6 ] loss: 0.36086320877075195 2022-07-01 18:49:30.861510
Epoch:[ 211 7 ] loss: 0.36001506447792053 2022-07-01 18:49:31.290438
Epoch:[ 211 8 ] loss: 0.36060866713523865 2022-07-01 18:49:31.719466
Epoch:[ 211 9 ] loss: 0.35908570885658264 2022-07-01 18:49:32.146725
Epoch:[ 211 10 ] loss: 0.36031168699264526 2022-07-01 18:49:32.575907
Epoch:[ 211 11 ] loss: 0.35956066846847534 2022-07-01 18:49:33.008142
Epoch:[ 211 12 ] loss: 0.36088135838508606 2022-07-01 18:49:33.440573
Epoch:[ 211 13 ] loss: 0.36037158966064453 2022-07-01 18:49:33.875241
Epoch:[ 211 14 ] loss: 0.36068543791770935 2022-07-01 18:49:34.305121
Epoch:[ 211 15 ] loss: 0.3608269989490509 2022-07-01 18:49:34.738947
Epoch:[ 211 16 ] loss: 0.3608524203300476 2022-07-01 18:49:39.613392
Epoch:[ 211 17 ] loss: 0.35928165912628174 2022-07-01 18:49:40.062887
Epoch:[ 211 18 ] loss: 0.3611067831516266 2022-07-01 18:49:40.503274
Epoch:[ 211 19 ] loss: 0.3591465353965759 2022-07-01 18:49:40.932542
Training_Epoch:[ 211 ] Training_loss: 0.3603899270296097 2022-07-01 18:49:40.933164
learning rate:  9.223372036854789e-06
val: 1 0.39259856939315796
val: 2 0.39625000953674316
val: 3 0.39049696922302246
val: 4 0.3949429988861084
val: 5 0.38077616691589355
val: 6 0.3873305022716522
val: 7 0.3971160650253296
val: 8 0.3912566304206848
val: 9 0.39383697509765625
val: 10 0.395952969789505
val: 11 0.389649361371994
val: 12 0.3941630721092224
val: 13 0.3809843063354492
val: 14 0.39253178238868713
val: 15 0.4008585214614868
val: 16 0.3902965784072876
val: 17 0.39027151465415955
val: 18 0.3865417242050171
val: 19 0.3841996192932129
val: 20 0.39004606008529663
val_Epoch:[ 211 ] val_loss: 0.3910050198435783 2022-07-01 18:49:44.867258
start training 2022-07-01 18:49:44.966984
Epoch:[ 212 0 ] loss: 0.3601365387439728 2022-07-01 18:49:59.432755
Epoch:[ 212 1 ] loss: 0.3593955636024475 2022-07-01 18:49:59.886698
Epoch:[ 212 2 ] loss: 0.359941303730011 2022-07-01 18:50:00.315976
Epoch:[ 212 3 ] loss: 0.35979288816452026 2022-07-01 18:50:00.746024
Epoch:[ 212 4 ] loss: 0.36170271039009094 2022-07-01 18:50:01.176978
Epoch:[ 212 5 ] loss: 0.36016449332237244 2022-07-01 18:50:01.607279
Epoch:[ 212 6 ] loss: 0.3592715561389923 2022-07-01 18:50:02.038381
Epoch:[ 212 7 ] loss: 0.3614093065261841 2022-07-01 18:50:02.473608
Epoch:[ 212 8 ] loss: 0.3606785833835602 2022-07-01 18:50:02.906303
Epoch:[ 212 9 ] loss: 0.35961779952049255 2022-07-01 18:50:03.333953
Epoch:[ 212 10 ] loss: 0.3615201413631439 2022-07-01 18:50:03.763963
Epoch:[ 212 11 ] loss: 0.35900864005088806 2022-07-01 18:50:04.193392
Epoch:[ 212 12 ] loss: 0.36086899042129517 2022-07-01 18:50:04.628977
Epoch:[ 212 13 ] loss: 0.35991916060447693 2022-07-01 18:50:05.039852
Epoch:[ 212 14 ] loss: 0.3601743280887604 2022-07-01 18:50:05.455867
Epoch:[ 212 15 ] loss: 0.3607006072998047 2022-07-01 18:50:05.870108
Epoch:[ 212 16 ] loss: 0.3596862256526947 2022-07-01 18:50:11.009195
Epoch:[ 212 17 ] loss: 0.3608191907405853 2022-07-01 18:50:11.437188
Epoch:[ 212 18 ] loss: 0.3610086441040039 2022-07-01 18:50:11.890952
Epoch:[ 212 19 ] loss: 0.36050358414649963 2022-07-01 18:50:12.326992
Training_Epoch:[ 212 ] Training_loss: 0.36031601279973985 2022-07-01 18:50:12.327668
learning rate:  9.223372036854789e-06
netparams have been saved once 212
val: 1 0.3924299478530884
val: 2 0.3942306935787201
val: 3 0.39209991693496704
val: 4 0.3930884003639221
val: 5 0.3933121860027313
val: 6 0.3873327076435089
val: 7 0.39647796750068665
val: 8 0.39116498827934265
val: 9 0.3863266110420227
val: 10 0.38515928387641907
val: 11 0.39309927821159363
val: 12 0.39019879698753357
val: 13 0.39436304569244385
val: 14 0.3797963857650757
val: 15 0.3978891968727112
val: 16 0.3921237289905548
val: 17 0.38906043767929077
val: 18 0.39698469638824463
val: 19 0.3789767026901245
val: 20 0.39881810545921326
val_Epoch:[ 212 ] val_loss: 0.39114665389060976 2022-07-01 18:50:16.301303
start training 2022-07-01 18:50:16.399036
Epoch:[ 213 0 ] loss: 0.3603108525276184 2022-07-01 18:50:31.503933
Epoch:[ 213 1 ] loss: 0.3601144850254059 2022-07-01 18:50:31.937028
Epoch:[ 213 2 ] loss: 0.35983696579933167 2022-07-01 18:50:32.372115
Epoch:[ 213 3 ] loss: 0.3605923056602478 2022-07-01 18:50:32.812111
Epoch:[ 213 4 ] loss: 0.359910786151886 2022-07-01 18:50:33.249657
Epoch:[ 213 5 ] loss: 0.3606783449649811 2022-07-01 18:50:33.680665
Epoch:[ 213 6 ] loss: 0.3614034056663513 2022-07-01 18:50:34.119311
Epoch:[ 213 7 ] loss: 0.360601544380188 2022-07-01 18:50:34.551733
Epoch:[ 213 8 ] loss: 0.36015284061431885 2022-07-01 18:50:34.989357
Epoch:[ 213 9 ] loss: 0.35960137844085693 2022-07-01 18:50:35.422561
Epoch:[ 213 10 ] loss: 0.3609384596347809 2022-07-01 18:50:35.852411
Epoch:[ 213 11 ] loss: 0.35968858003616333 2022-07-01 18:50:36.285066
Epoch:[ 213 12 ] loss: 0.36049404740333557 2022-07-01 18:50:36.718605
Epoch:[ 213 13 ] loss: 0.3608643114566803 2022-07-01 18:50:37.152113
Epoch:[ 213 14 ] loss: 0.3616170287132263 2022-07-01 18:50:37.583750
Epoch:[ 213 15 ] loss: 0.35973817110061646 2022-07-01 18:50:38.019591
Epoch:[ 213 16 ] loss: 0.3593072295188904 2022-07-01 18:50:43.364896
Epoch:[ 213 17 ] loss: 0.36020347476005554 2022-07-01 18:50:43.800080
Epoch:[ 213 18 ] loss: 0.3607138991355896 2022-07-01 18:50:44.238243
Epoch:[ 213 19 ] loss: 0.36033546924591064 2022-07-01 18:50:44.670445
Training_Epoch:[ 213 ] Training_loss: 0.36035517901182174 2022-07-01 18:50:44.671225
learning rate:  9.223372036854789e-06
val: 1 0.39503926038742065
val: 2 0.38812562823295593
val: 3 0.3897077441215515
val: 4 0.38683244585990906
val: 5 0.392964631319046
val: 6 0.39171168208122253
val: 7 0.3965592682361603
val: 8 0.39911577105522156
val: 9 0.3920834958553314
val: 10 0.3850403428077698
val: 11 0.387698769569397
val: 12 0.38543057441711426
val: 13 0.3939248323440552
val: 14 0.39466676115989685
val: 15 0.3940223753452301
val: 16 0.3942011594772339
val: 17 0.3912166357040405
val: 18 0.38925567269325256
val: 19 0.38597986102104187
val: 20 0.38584601879119873
val_Epoch:[ 213 ] val_loss: 0.3909711465239525 2022-07-01 18:50:48.570529
start training 2022-07-01 18:50:48.669829
Epoch:[ 214 0 ] loss: 0.35996130108833313 2022-07-01 18:51:02.972588
Epoch:[ 214 1 ] loss: 0.35982802510261536 2022-07-01 18:51:03.422048
Epoch:[ 214 2 ] loss: 0.3602413833141327 2022-07-01 18:51:03.855473
Epoch:[ 214 3 ] loss: 0.36002156138420105 2022-07-01 18:51:04.292990
Epoch:[ 214 4 ] loss: 0.3604786694049835 2022-07-01 18:51:04.729783
Epoch:[ 214 5 ] loss: 0.3603364825248718 2022-07-01 18:51:05.164001
Epoch:[ 214 6 ] loss: 0.35998407006263733 2022-07-01 18:51:05.600810
Epoch:[ 214 7 ] loss: 0.3610948324203491 2022-07-01 18:51:06.032522
Epoch:[ 214 8 ] loss: 0.36052191257476807 2022-07-01 18:51:06.465013
Epoch:[ 214 9 ] loss: 0.3609035313129425 2022-07-01 18:51:06.899829
Epoch:[ 214 10 ] loss: 0.3610629141330719 2022-07-01 18:51:07.332517
Epoch:[ 214 11 ] loss: 0.3605066239833832 2022-07-01 18:51:07.763840
Epoch:[ 214 12 ] loss: 0.3613702058792114 2022-07-01 18:51:08.194886
Epoch:[ 214 13 ] loss: 0.36034172773361206 2022-07-01 18:51:08.627787
Epoch:[ 214 14 ] loss: 0.3599225580692291 2022-07-01 18:51:09.057767
Epoch:[ 214 15 ] loss: 0.35950934886932373 2022-07-01 18:51:09.492573
Epoch:[ 214 16 ] loss: 0.3593567907810211 2022-07-01 18:51:15.355755
Epoch:[ 214 17 ] loss: 0.3601742088794708 2022-07-01 18:51:15.787566
Epoch:[ 214 18 ] loss: 0.36111050844192505 2022-07-01 18:51:16.233520
Epoch:[ 214 19 ] loss: 0.3599662780761719 2022-07-01 18:51:16.666836
Training_Epoch:[ 214 ] Training_loss: 0.36033464670181276 2022-07-01 18:51:16.667487
learning rate:  9.223372036854789e-06
netparams have been saved once 214
val: 1 0.3929486572742462
val: 2 0.39057308435440063
val: 3 0.3834100365638733
val: 4 0.39358046650886536
val: 5 0.381838858127594
val: 6 0.3932369649410248
val: 7 0.38459184765815735
val: 8 0.3931640684604645
val: 9 0.3909904360771179
val: 10 0.39076775312423706
val: 11 0.40552738308906555
val: 12 0.39045313000679016
val: 13 0.3850933909416199
val: 14 0.3942476511001587
val: 15 0.38741227984428406
val: 16 0.3892818093299866
val: 17 0.3930886685848236
val: 18 0.3839826285839081
val: 19 0.39756056666374207
val: 20 0.39612698554992676
val_Epoch:[ 214 ] val_loss: 0.39089383333921435 2022-07-01 18:51:20.665089
start training 2022-07-01 18:51:20.764707
Epoch:[ 215 0 ] loss: 0.3600389361381531 2022-07-01 18:51:35.704252
Epoch:[ 215 1 ] loss: 0.360953688621521 2022-07-01 18:51:36.137774
Epoch:[ 215 2 ] loss: 0.3592747747898102 2022-07-01 18:51:36.568527
Epoch:[ 215 3 ] loss: 0.3596585988998413 2022-07-01 18:51:37.002606
Epoch:[ 215 4 ] loss: 0.3603152334690094 2022-07-01 18:51:37.435683
Epoch:[ 215 5 ] loss: 0.360547810792923 2022-07-01 18:51:37.867355
Epoch:[ 215 6 ] loss: 0.3595964014530182 2022-07-01 18:51:38.303112
Epoch:[ 215 7 ] loss: 0.3603689968585968 2022-07-01 18:51:38.736266
Epoch:[ 215 8 ] loss: 0.3601512908935547 2022-07-01 18:51:39.169028
Epoch:[ 215 9 ] loss: 0.35883358120918274 2022-07-01 18:51:39.606642
Epoch:[ 215 10 ] loss: 0.36027437448501587 2022-07-01 18:51:40.040845
Epoch:[ 215 11 ] loss: 0.3606119155883789 2022-07-01 18:51:40.479525
Epoch:[ 215 12 ] loss: 0.3613912761211395 2022-07-01 18:51:40.911694
Epoch:[ 215 13 ] loss: 0.3617733418941498 2022-07-01 18:51:41.341671
Epoch:[ 215 14 ] loss: 0.3609679639339447 2022-07-01 18:51:41.775217
Epoch:[ 215 15 ] loss: 0.3603610396385193 2022-07-01 18:51:42.207516
Epoch:[ 215 16 ] loss: 0.3598685562610626 2022-07-01 18:51:47.788867
Epoch:[ 215 17 ] loss: 0.3605411946773529 2022-07-01 18:51:48.218127
Epoch:[ 215 18 ] loss: 0.36015602946281433 2022-07-01 18:51:48.662359
Epoch:[ 215 19 ] loss: 0.3610122799873352 2022-07-01 18:51:49.096366
Training_Epoch:[ 215 ] Training_loss: 0.36033486425876615 2022-07-01 18:51:49.097104
learning rate:  9.223372036854789e-06
val: 1 0.3870501220226288
val: 2 0.39551371335983276
val: 3 0.3904196619987488
val: 4 0.38732343912124634
val: 5 0.3891032934188843
val: 6 0.39719733595848083
val: 7 0.39191192388534546
val: 8 0.3882274627685547
val: 9 0.3916689455509186
val: 10 0.3908078670501709
val: 11 0.3951685428619385
val: 12 0.3930729329586029
val: 13 0.39093440771102905
val: 14 0.39042267203330994
val: 15 0.38767528533935547
val: 16 0.38929250836372375
val: 17 0.39076516032218933
val: 18 0.3890921175479889
val: 19 0.396605908870697
val: 20 0.38908857107162476
val_Epoch:[ 215 ] val_loss: 0.3910670936107635 2022-07-01 18:51:52.973819
start training 2022-07-01 18:51:53.074054
Epoch:[ 216 0 ] loss: 0.35911786556243896 2022-07-01 18:52:07.212403
Epoch:[ 216 1 ] loss: 0.36063629388809204 2022-07-01 18:52:07.671432
Epoch:[ 216 2 ] loss: 0.3605545461177826 2022-07-01 18:52:08.132680
Epoch:[ 216 3 ] loss: 0.3599393963813782 2022-07-01 18:52:08.564394
Epoch:[ 216 4 ] loss: 0.36099767684936523 2022-07-01 18:52:08.996394
Epoch:[ 216 5 ] loss: 0.3597657382488251 2022-07-01 18:52:09.427665
Epoch:[ 216 6 ] loss: 0.3606891632080078 2022-07-01 18:52:09.860413
Epoch:[ 216 7 ] loss: 0.36008259654045105 2022-07-01 18:52:10.291804
Epoch:[ 216 8 ] loss: 0.36095428466796875 2022-07-01 18:52:10.721958
Epoch:[ 216 9 ] loss: 0.35999560356140137 2022-07-01 18:52:11.150534
Epoch:[ 216 10 ] loss: 0.36050111055374146 2022-07-01 18:52:11.588825
Epoch:[ 216 11 ] loss: 0.3614182472229004 2022-07-01 18:52:12.022865
Epoch:[ 216 12 ] loss: 0.36202821135520935 2022-07-01 18:52:12.439008
Epoch:[ 216 13 ] loss: 0.35979771614074707 2022-07-01 18:52:12.849750
Epoch:[ 216 14 ] loss: 0.3610081076622009 2022-07-01 18:52:13.270274
Epoch:[ 216 15 ] loss: 0.3593467175960541 2022-07-01 18:52:13.700684
Epoch:[ 216 16 ] loss: 0.3607650101184845 2022-07-01 18:52:18.914192
Epoch:[ 216 17 ] loss: 0.3587947487831116 2022-07-01 18:52:19.345329
Epoch:[ 216 18 ] loss: 0.3599624037742615 2022-07-01 18:52:19.780984
Epoch:[ 216 19 ] loss: 0.35999587178230286 2022-07-01 18:52:20.232905
Training_Epoch:[ 216 ] Training_loss: 0.36031756550073624 2022-07-01 18:52:20.233510
learning rate:  9.223372036854789e-06
netparams have been saved once 216
val: 1 0.3918287754058838
val: 2 0.398309588432312
val: 3 0.3942609131336212
val: 4 0.39478883147239685
val: 5 0.3920544683933258
val: 6 0.38725996017456055
val: 7 0.39110997319221497
val: 8 0.38085368275642395
val: 9 0.3911934792995453
val: 10 0.3908134996891022
val: 11 0.39598390460014343
val: 12 0.3935665786266327
val: 13 0.38850367069244385
val: 14 0.3940567374229431
val: 15 0.3913622200489044
val: 16 0.38590583205223083
val: 17 0.3815060257911682
val: 18 0.396732360124588
val: 19 0.3908422887325287
val: 20 0.3910117745399475
val_Epoch:[ 216 ] val_loss: 0.39109722822904586 2022-07-01 18:52:24.120725
start training 2022-07-01 18:52:24.219783
Epoch:[ 217 0 ] loss: 0.3611271381378174 2022-07-01 18:52:38.501049
Epoch:[ 217 1 ] loss: 0.3602549135684967 2022-07-01 18:52:38.942911
Epoch:[ 217 2 ] loss: 0.3611362874507904 2022-07-01 18:52:39.356236
Epoch:[ 217 3 ] loss: 0.36097651720046997 2022-07-01 18:52:39.763183
Epoch:[ 217 4 ] loss: 0.3594309985637665 2022-07-01 18:52:40.172216
Epoch:[ 217 5 ] loss: 0.35997164249420166 2022-07-01 18:52:40.588179
Epoch:[ 217 6 ] loss: 0.36015698313713074 2022-07-01 18:52:41.002621
Epoch:[ 217 7 ] loss: 0.3599424958229065 2022-07-01 18:52:41.412671
Epoch:[ 217 8 ] loss: 0.3594447672367096 2022-07-01 18:52:41.829155
Epoch:[ 217 9 ] loss: 0.36087629199028015 2022-07-01 18:52:42.242788
Epoch:[ 217 10 ] loss: 0.3604431748390198 2022-07-01 18:52:42.656216
Epoch:[ 217 11 ] loss: 0.36018744111061096 2022-07-01 18:52:43.072938
Epoch:[ 217 12 ] loss: 0.35977301001548767 2022-07-01 18:52:43.489546
Epoch:[ 217 13 ] loss: 0.36058396100997925 2022-07-01 18:52:43.903652
Epoch:[ 217 14 ] loss: 0.36054491996765137 2022-07-01 18:52:44.318637
Epoch:[ 217 15 ] loss: 0.3608432114124298 2022-07-01 18:52:44.732403
Epoch:[ 217 16 ] loss: 0.36042389273643494 2022-07-01 18:52:50.216036
Epoch:[ 217 17 ] loss: 0.35909149050712585 2022-07-01 18:52:50.623069
Epoch:[ 217 18 ] loss: 0.36130380630493164 2022-07-01 18:52:51.120944
Epoch:[ 217 19 ] loss: 0.3602566123008728 2022-07-01 18:52:51.551782
Training_Epoch:[ 217 ] Training_loss: 0.36033847779035566 2022-07-01 18:52:51.552469
learning rate:  9.223372036854789e-06
val: 1 0.3975050747394562
val: 2 0.3915643095970154
val: 3 0.397291898727417
val: 4 0.38491058349609375
val: 5 0.3943837285041809
val: 6 0.39347922801971436
val: 7 0.39168667793273926
val: 8 0.3866865336894989
val: 9 0.39131277799606323
val: 10 0.39242061972618103
val: 11 0.38586169481277466
val: 12 0.39201295375823975
val: 13 0.388250470161438
val: 14 0.38894233107566833
val: 15 0.38866928219795227
val: 16 0.3956955373287201
val: 17 0.39803826808929443
val: 18 0.38973987102508545
val: 19 0.3896515965461731
val: 20 0.38399818539619446
val_Epoch:[ 217 ] val_loss: 0.391105081140995 2022-07-01 18:52:55.409369
start training 2022-07-01 18:52:55.510919
Epoch:[ 218 0 ] loss: 0.3613034784793854 2022-07-01 18:53:09.802641
Epoch:[ 218 1 ] loss: 0.360063374042511 2022-07-01 18:53:10.355669
Epoch:[ 218 2 ] loss: 0.3600994646549225 2022-07-01 18:53:10.789076
Epoch:[ 218 3 ] loss: 0.35948774218559265 2022-07-01 18:53:11.203896
Epoch:[ 218 4 ] loss: 0.3612631559371948 2022-07-01 18:53:11.617835
Epoch:[ 218 5 ] loss: 0.3600665032863617 2022-07-01 18:53:12.050227
Epoch:[ 218 6 ] loss: 0.3593713343143463 2022-07-01 18:53:12.461690
Epoch:[ 218 7 ] loss: 0.360254168510437 2022-07-01 18:53:12.877275
Epoch:[ 218 8 ] loss: 0.35937395691871643 2022-07-01 18:53:13.295393
Epoch:[ 218 9 ] loss: 0.3605290353298187 2022-07-01 18:53:13.709794
Epoch:[ 218 10 ] loss: 0.36005982756614685 2022-07-01 18:53:14.117728
Epoch:[ 218 11 ] loss: 0.36121657490730286 2022-07-01 18:53:14.531853
Epoch:[ 218 12 ] loss: 0.36250460147857666 2022-07-01 18:53:14.943006
Epoch:[ 218 13 ] loss: 0.36072614789009094 2022-07-01 18:53:15.359153
Epoch:[ 218 14 ] loss: 0.35987967252731323 2022-07-01 18:53:15.775765
Epoch:[ 218 15 ] loss: 0.3600897192955017 2022-07-01 18:53:16.190791
Epoch:[ 218 16 ] loss: 0.3597065806388855 2022-07-01 18:53:21.669598
Epoch:[ 218 17 ] loss: 0.3611455261707306 2022-07-01 18:53:22.078864
Epoch:[ 218 18 ] loss: 0.35980308055877686 2022-07-01 18:53:22.519414
Epoch:[ 218 19 ] loss: 0.35973185300827026 2022-07-01 18:53:22.949594
Training_Epoch:[ 218 ] Training_loss: 0.3603337898850441 2022-07-01 18:53:22.950382
learning rate:  9.223372036854789e-06
netparams have been saved once 218
val: 1 0.38726627826690674
val: 2 0.3920147120952606
val: 3 0.3918165862560272
val: 4 0.3878396153450012
val: 5 0.3895876109600067
val: 6 0.39772433042526245
val: 7 0.3880591094493866
val: 8 0.3901747465133667
val: 9 0.39843058586120605
val: 10 0.3922653794288635
val: 11 0.3935367465019226
val: 12 0.3961867094039917
val: 13 0.39408543705940247
val: 14 0.38988086581230164
val: 15 0.3878040611743927
val: 16 0.3870723247528076
val: 17 0.3914431035518646
val: 18 0.38855549693107605
val: 19 0.3936948776245117
val: 20 0.3845997154712677
val_Epoch:[ 218 ] val_loss: 0.3911019146442413 2022-07-01 18:53:26.911393
start training 2022-07-01 18:53:27.008384
Epoch:[ 219 0 ] loss: 0.3593558669090271 2022-07-01 18:53:41.080075
Epoch:[ 219 1 ] loss: 0.35899224877357483 2022-07-01 18:53:41.998036
Epoch:[ 219 2 ] loss: 0.35972926020622253 2022-07-01 18:53:42.428691
Epoch:[ 219 3 ] loss: 0.36082327365875244 2022-07-01 18:53:42.857938
Epoch:[ 219 4 ] loss: 0.359365850687027 2022-07-01 18:53:43.286665
Epoch:[ 219 5 ] loss: 0.3605019450187683 2022-07-01 18:53:43.717500
Epoch:[ 219 6 ] loss: 0.3618753254413605 2022-07-01 18:53:44.149031
Epoch:[ 219 7 ] loss: 0.36039987206459045 2022-07-01 18:53:44.583418
Epoch:[ 219 8 ] loss: 0.3599655330181122 2022-07-01 18:53:45.014131
Epoch:[ 219 9 ] loss: 0.36171120405197144 2022-07-01 18:53:45.443521
Epoch:[ 219 10 ] loss: 0.3598043918609619 2022-07-01 18:53:45.873333
Epoch:[ 219 11 ] loss: 0.36052075028419495 2022-07-01 18:53:46.301836
Epoch:[ 219 12 ] loss: 0.36047089099884033 2022-07-01 18:53:46.734533
Epoch:[ 219 13 ] loss: 0.3608244061470032 2022-07-01 18:53:47.165520
Epoch:[ 219 14 ] loss: 0.35955554246902466 2022-07-01 18:53:47.601185
Epoch:[ 219 15 ] loss: 0.36087343096733093 2022-07-01 18:53:48.030573
Epoch:[ 219 16 ] loss: 0.36053261160850525 2022-07-01 18:53:52.735147
Epoch:[ 219 17 ] loss: 0.3599838614463806 2022-07-01 18:53:53.313043
Epoch:[ 219 18 ] loss: 0.360745370388031 2022-07-01 18:53:53.748407
Epoch:[ 219 19 ] loss: 0.3602820634841919 2022-07-01 18:53:54.174793
Training_Epoch:[ 219 ] Training_loss: 0.3603156849741936 2022-07-01 18:53:54.175537
learning rate:  9.223372036854789e-06
val: 1 0.39099517464637756
val: 2 0.39377522468566895
val: 3 0.39024609327316284
val: 4 0.38785386085510254
val: 5 0.3862841725349426
val: 6 0.3997994363307953
val: 7 0.38806310296058655
val: 8 0.39468079805374146
val: 9 0.3832190930843353
val: 10 0.3978656530380249
val: 11 0.4004124701023102
val: 12 0.38524502515792847
val: 13 0.39221304655075073
val: 14 0.39573705196380615
val: 15 0.38323381543159485
val: 16 0.3970489203929901
val: 17 0.38990718126296997
val: 18 0.3865523636341095
val: 19 0.3926343023777008
val: 20 0.3894230127334595
val_Epoch:[ 219 ] val_loss: 0.3912594899535179 2022-07-01 18:53:58.110910
start training 2022-07-01 18:53:58.208873
Epoch:[ 220 0 ] loss: 0.358977735042572 2022-07-01 18:54:12.818223
Epoch:[ 220 1 ] loss: 0.360991895198822 2022-07-01 18:54:13.250854
Epoch:[ 220 2 ] loss: 0.3603300154209137 2022-07-01 18:54:13.681061
Epoch:[ 220 3 ] loss: 0.3593989610671997 2022-07-01 18:54:14.099001
Epoch:[ 220 4 ] loss: 0.3613854646682739 2022-07-01 18:54:14.508267
Epoch:[ 220 5 ] loss: 0.3596341609954834 2022-07-01 18:54:14.922108
Epoch:[ 220 6 ] loss: 0.36091724038124084 2022-07-01 18:54:15.329650
Epoch:[ 220 7 ] loss: 0.3616042137145996 2022-07-01 18:54:15.745257
Epoch:[ 220 8 ] loss: 0.3595041334629059 2022-07-01 18:54:16.162398
Epoch:[ 220 9 ] loss: 0.35923823714256287 2022-07-01 18:54:16.577258
Epoch:[ 220 10 ] loss: 0.3603213131427765 2022-07-01 18:54:16.992695
Epoch:[ 220 11 ] loss: 0.3596504330635071 2022-07-01 18:54:17.407179
Epoch:[ 220 12 ] loss: 0.36065974831581116 2022-07-01 18:54:17.822090
Epoch:[ 220 13 ] loss: 0.35975995659828186 2022-07-01 18:54:18.236708
Epoch:[ 220 14 ] loss: 0.3598138689994812 2022-07-01 18:54:18.647682
Epoch:[ 220 15 ] loss: 0.3610268533229828 2022-07-01 18:54:19.064335
Epoch:[ 220 16 ] loss: 0.36021503806114197 2022-07-01 18:54:24.378616
Epoch:[ 220 17 ] loss: 0.3618409335613251 2022-07-01 18:54:24.793629
Epoch:[ 220 18 ] loss: 0.3595651090145111 2022-07-01 18:54:25.202256
Epoch:[ 220 19 ] loss: 0.36117374897003174 2022-07-01 18:54:25.616197
Training_Epoch:[ 220 ] Training_loss: 0.36030045300722124 2022-07-01 18:54:25.617007
learning rate:  9.223372036854789e-06
netparams have been saved once 220
val: 1 0.3859334886074066
val: 2 0.3915342688560486
val: 3 0.40075936913490295
val: 4 0.40011197328567505
val: 5 0.3969098627567291
val: 6 0.37811553478240967
val: 7 0.38418734073638916
val: 8 0.38564884662628174
val: 9 0.3932412564754486
val: 10 0.3960955739021301
val: 11 0.3913993835449219
val: 12 0.38733673095703125
val: 13 0.38831278681755066
val: 14 0.38651126623153687
val: 15 0.3862664997577667
val: 16 0.39222925901412964
val: 17 0.39600181579589844
val: 18 0.3894694149494171
val: 19 0.39819082617759705
val: 20 0.3937024772167206
val_Epoch:[ 220 ] val_loss: 0.3910978987812996 2022-07-01 18:54:29.627797
start training 2022-07-01 18:54:29.726536
Epoch:[ 221 0 ] loss: 0.35979607701301575 2022-07-01 18:54:44.264736
Epoch:[ 221 1 ] loss: 0.36030450463294983 2022-07-01 18:54:44.698059
Epoch:[ 221 2 ] loss: 0.3603234589099884 2022-07-01 18:54:45.136134
Epoch:[ 221 3 ] loss: 0.3610650300979614 2022-07-01 18:54:45.571028
Epoch:[ 221 4 ] loss: 0.3600265085697174 2022-07-01 18:54:45.999437
Epoch:[ 221 5 ] loss: 0.3607221841812134 2022-07-01 18:54:46.429662
Epoch:[ 221 6 ] loss: 0.3604942262172699 2022-07-01 18:54:46.857044
Epoch:[ 221 7 ] loss: 0.36006367206573486 2022-07-01 18:54:47.286400
Epoch:[ 221 8 ] loss: 0.35954567790031433 2022-07-01 18:54:47.703505
Epoch:[ 221 9 ] loss: 0.3608299791812897 2022-07-01 18:54:48.118679
Epoch:[ 221 10 ] loss: 0.35992828011512756 2022-07-01 18:54:48.535562
Epoch:[ 221 11 ] loss: 0.36073723435401917 2022-07-01 18:54:48.950084
Epoch:[ 221 12 ] loss: 0.3589489161968231 2022-07-01 18:54:49.359892
Epoch:[ 221 13 ] loss: 0.3604603111743927 2022-07-01 18:54:49.774501
Epoch:[ 221 14 ] loss: 0.3610609471797943 2022-07-01 18:54:50.189407
Epoch:[ 221 15 ] loss: 0.36040404438972473 2022-07-01 18:54:50.606585
Epoch:[ 221 16 ] loss: 0.35937708616256714 2022-07-01 18:54:55.754517
Epoch:[ 221 17 ] loss: 0.36071500182151794 2022-07-01 18:54:56.168148
Epoch:[ 221 18 ] loss: 0.36154380440711975 2022-07-01 18:54:56.584254
Epoch:[ 221 19 ] loss: 0.3599707782268524 2022-07-01 18:54:56.991738
Training_Epoch:[ 221 ] Training_loss: 0.3603158861398697 2022-07-01 18:54:56.992836
learning rate:  7.378697629483831e-06
val: 1 0.3927508592605591
val: 2 0.3803158104419708
val: 3 0.40354084968566895
val: 4 0.3893839120864868
val: 5 0.3905278444290161
val: 6 0.3817559778690338
val: 7 0.39334481954574585
val: 8 0.3919285535812378
val: 9 0.39005884528160095
val: 10 0.3865399658679962
val: 11 0.3970683515071869
val: 12 0.3976268470287323
val: 13 0.3960835635662079
val: 14 0.3856726288795471
val: 15 0.392028272151947
val: 16 0.39071905612945557
val: 17 0.3871171772480011
val: 18 0.3950965404510498
val: 19 0.38926488161087036
val: 20 0.3943857252597809
val_Epoch:[ 221 ] val_loss: 0.3912605240941048 2022-07-01 18:55:00.971230
start training 2022-07-01 18:55:01.069662
Epoch:[ 222 0 ] loss: 0.36084476113319397 2022-07-01 18:55:15.378225
Epoch:[ 222 1 ] loss: 0.3600681722164154 2022-07-01 18:55:15.816899
Epoch:[ 222 2 ] loss: 0.3600585460662842 2022-07-01 18:55:16.234237
Epoch:[ 222 3 ] loss: 0.35849377512931824 2022-07-01 18:55:16.663196
Epoch:[ 222 4 ] loss: 0.35968607664108276 2022-07-01 18:55:17.096829
Epoch:[ 222 5 ] loss: 0.36115336418151855 2022-07-01 18:55:17.525979
Epoch:[ 222 6 ] loss: 0.3611762225627899 2022-07-01 18:55:17.955998
Epoch:[ 222 7 ] loss: 0.36019274592399597 2022-07-01 18:55:18.385696
Epoch:[ 222 8 ] loss: 0.3599574863910675 2022-07-01 18:55:18.814799
Epoch:[ 222 9 ] loss: 0.35932812094688416 2022-07-01 18:55:19.245064
Epoch:[ 222 10 ] loss: 0.360192209482193 2022-07-01 18:55:19.676003
Epoch:[ 222 11 ] loss: 0.36034736037254333 2022-07-01 18:55:20.105622
Epoch:[ 222 12 ] loss: 0.360478937625885 2022-07-01 18:55:20.536147
Epoch:[ 222 13 ] loss: 0.360679566860199 2022-07-01 18:55:20.966163
Epoch:[ 222 14 ] loss: 0.3607879877090454 2022-07-01 18:55:21.404015
Epoch:[ 222 15 ] loss: 0.36106306314468384 2022-07-01 18:55:21.835507
Epoch:[ 222 16 ] loss: 0.35941067337989807 2022-07-01 18:55:27.493596
Epoch:[ 222 17 ] loss: 0.3597439229488373 2022-07-01 18:55:27.910295
Epoch:[ 222 18 ] loss: 0.36055871844291687 2022-07-01 18:55:28.319421
Epoch:[ 222 19 ] loss: 0.36057335138320923 2022-07-01 18:55:28.736659
Training_Epoch:[ 222 ] Training_loss: 0.3602397531270981 2022-07-01 18:55:28.737723
learning rate:  7.378697629483831e-06
netparams have been saved once 222
val: 1 0.3864242136478424
val: 2 0.389999657869339
val: 3 0.4074372351169586
val: 4 0.3882482945919037
val: 5 0.40157729387283325
val: 6 0.3965117931365967
val: 7 0.3927752673625946
val: 8 0.38547226786613464
val: 9 0.38671740889549255
val: 10 0.39850085973739624
val: 11 0.3840719759464264
val: 12 0.40446311235427856
val: 13 0.38346415758132935
val: 14 0.3883307874202728
val: 15 0.3864137828350067
val: 16 0.38800710439682007
val: 17 0.39213985204696655
val: 18 0.38585522770881653
val: 19 0.38600781559944153
val: 20 0.3907933831214905
val_Epoch:[ 222 ] val_loss: 0.39116057455539704 2022-07-01 18:55:33.078994
start training 2022-07-01 18:55:33.184197
Epoch:[ 223 0 ] loss: 0.3611513376235962 2022-07-01 18:55:48.229815
Epoch:[ 223 1 ] loss: 0.3603426218032837 2022-07-01 18:55:48.657766
Epoch:[ 223 2 ] loss: 0.3605687916278839 2022-07-01 18:55:49.090966
Epoch:[ 223 3 ] loss: 0.36128106713294983 2022-07-01 18:55:49.527206
Epoch:[ 223 4 ] loss: 0.35924920439720154 2022-07-01 18:55:49.958311
Epoch:[ 223 5 ] loss: 0.36104723811149597 2022-07-01 18:55:50.388161
Epoch:[ 223 6 ] loss: 0.36025911569595337 2022-07-01 18:55:50.822348
Epoch:[ 223 7 ] loss: 0.3606644868850708 2022-07-01 18:55:51.250293
Epoch:[ 223 8 ] loss: 0.36041849851608276 2022-07-01 18:55:51.684835
Epoch:[ 223 9 ] loss: 0.35928162932395935 2022-07-01 18:55:52.112441
Epoch:[ 223 10 ] loss: 0.36053401231765747 2022-07-01 18:55:52.542781
Epoch:[ 223 11 ] loss: 0.35900482535362244 2022-07-01 18:55:52.974689
Epoch:[ 223 12 ] loss: 0.36048203706741333 2022-07-01 18:55:53.404160
Epoch:[ 223 13 ] loss: 0.3601013422012329 2022-07-01 18:55:53.831350
Epoch:[ 223 14 ] loss: 0.3601990342140198 2022-07-01 18:55:54.261586
Epoch:[ 223 15 ] loss: 0.36026060581207275 2022-07-01 18:55:54.692047
Epoch:[ 223 16 ] loss: 0.3610404133796692 2022-07-01 18:55:59.464259
Epoch:[ 223 17 ] loss: 0.3604646921157837 2022-07-01 18:55:59.894137
Epoch:[ 223 18 ] loss: 0.35999131202697754 2022-07-01 18:56:00.349337
Epoch:[ 223 19 ] loss: 0.3612395226955414 2022-07-01 18:56:00.778477
Training_Epoch:[ 223 ] Training_loss: 0.3603790894150734 2022-07-01 18:56:00.779226
learning rate:  7.378697629483831e-06
val: 1 0.38909661769866943
val: 2 0.39907699823379517
val: 3 0.3862915635108948
val: 4 0.39209726452827454
val: 5 0.3891977071762085
val: 6 0.40255627036094666
val: 7 0.39080244302749634
val: 8 0.3897785544395447
val: 9 0.38779428601264954
val: 10 0.3879236578941345
val: 11 0.38413524627685547
val: 12 0.391735702753067
val: 13 0.3900813162326813
val: 14 0.3892085552215576
val: 15 0.3909767270088196
val: 16 0.3874175250530243
val: 17 0.38453155755996704
val: 18 0.401972234249115
val: 19 0.38922733068466187
val: 20 0.3980140686035156
val_Epoch:[ 223 ] val_loss: 0.39109578132629397 2022-07-01 18:56:04.773403
start training 2022-07-01 18:56:04.870708
Epoch:[ 224 0 ] loss: 0.36070898175239563 2022-07-01 18:56:19.454020
Epoch:[ 224 1 ] loss: 0.3596964478492737 2022-07-01 18:56:19.882308
Epoch:[ 224 2 ] loss: 0.3605581223964691 2022-07-01 18:56:20.316605
Epoch:[ 224 3 ] loss: 0.3605262339115143 2022-07-01 18:56:20.745486
Epoch:[ 224 4 ] loss: 0.3597491979598999 2022-07-01 18:56:21.177480
Epoch:[ 224 5 ] loss: 0.36053410172462463 2022-07-01 18:56:21.609178
Epoch:[ 224 6 ] loss: 0.36065730452537537 2022-07-01 18:56:22.039881
Epoch:[ 224 7 ] loss: 0.3600490689277649 2022-07-01 18:56:22.470844
Epoch:[ 224 8 ] loss: 0.3607124388217926 2022-07-01 18:56:22.901510
Epoch:[ 224 9 ] loss: 0.3604218065738678 2022-07-01 18:56:23.337528
Epoch:[ 224 10 ] loss: 0.36044037342071533 2022-07-01 18:56:23.766273
Epoch:[ 224 11 ] loss: 0.35980871319770813 2022-07-01 18:56:24.202972
Epoch:[ 224 12 ] loss: 0.36036205291748047 2022-07-01 18:56:24.636226
Epoch:[ 224 13 ] loss: 0.3606726825237274 2022-07-01 18:56:25.066505
Epoch:[ 224 14 ] loss: 0.3595053255558014 2022-07-01 18:56:25.499302
Epoch:[ 224 15 ] loss: 0.3600124418735504 2022-07-01 18:56:25.928945
Epoch:[ 224 16 ] loss: 0.3602769076824188 2022-07-01 18:56:30.653505
Epoch:[ 224 17 ] loss: 0.36058199405670166 2022-07-01 18:56:31.086648
Epoch:[ 224 18 ] loss: 0.36029374599456787 2022-07-01 18:56:31.524950
Epoch:[ 224 19 ] loss: 0.36076584458351135 2022-07-01 18:56:31.956183
Training_Epoch:[ 224 ] Training_loss: 0.360316689312458 2022-07-01 18:56:31.956860
learning rate:  7.378697629483831e-06
netparams have been saved once 224
val: 1 0.39703330397605896
val: 2 0.3892911672592163
val: 3 0.3943065106868744
val: 4 0.38916802406311035
val: 5 0.3891570270061493
val: 6 0.3870477080345154
val: 7 0.3966727554798126
val: 8 0.38562455773353577
val: 9 0.3924350440502167
val: 10 0.3862660527229309
val: 11 0.3937320113182068
val: 12 0.3845011293888092
val: 13 0.4011777341365814
val: 14 0.392980694770813
val: 15 0.39407631754875183
val: 16 0.3865295946598053
val: 17 0.39039212465286255
val: 18 0.38605669140815735
val: 19 0.39716836810112
val: 20 0.3921353816986084
val_Epoch:[ 224 ] val_loss: 0.3912876099348068 2022-07-01 18:56:35.944876
start training 2022-07-01 18:56:36.044049
Epoch:[ 225 0 ] loss: 0.36059117317199707 2022-07-01 18:56:50.961186
Epoch:[ 225 1 ] loss: 0.3609926104545593 2022-07-01 18:56:51.391071
Epoch:[ 225 2 ] loss: 0.3604493737220764 2022-07-01 18:56:51.825616
Epoch:[ 225 3 ] loss: 0.36146247386932373 2022-07-01 18:56:52.254838
Epoch:[ 225 4 ] loss: 0.3602602481842041 2022-07-01 18:56:52.683723
Epoch:[ 225 5 ] loss: 0.3605257272720337 2022-07-01 18:56:53.119584
Epoch:[ 225 6 ] loss: 0.36073681712150574 2022-07-01 18:56:53.550429
Epoch:[ 225 7 ] loss: 0.35923418402671814 2022-07-01 18:56:53.981171
Epoch:[ 225 8 ] loss: 0.3601078391075134 2022-07-01 18:56:54.410452
Epoch:[ 225 9 ] loss: 0.35958293080329895 2022-07-01 18:56:54.843905
Epoch:[ 225 10 ] loss: 0.36114072799682617 2022-07-01 18:56:55.272967
Epoch:[ 225 11 ] loss: 0.35951247811317444 2022-07-01 18:56:55.701593
Epoch:[ 225 12 ] loss: 0.35916566848754883 2022-07-01 18:56:56.133034
Epoch:[ 225 13 ] loss: 0.3594948649406433 2022-07-01 18:56:56.563305
Epoch:[ 225 14 ] loss: 0.3607359230518341 2022-07-01 18:56:56.992879
Epoch:[ 225 15 ] loss: 0.3595651388168335 2022-07-01 18:56:57.423261
Epoch:[ 225 16 ] loss: 0.36202189326286316 2022-07-01 18:57:03.063132
Epoch:[ 225 17 ] loss: 0.3605102002620697 2022-07-01 18:57:03.490134
Epoch:[ 225 18 ] loss: 0.36018630862236023 2022-07-01 18:57:03.936334
Epoch:[ 225 19 ] loss: 0.3604816496372223 2022-07-01 18:57:04.370613
Training_Epoch:[ 225 ] Training_loss: 0.3603379115462303 2022-07-01 18:57:04.371191
learning rate:  7.378697629483831e-06
val: 1 0.3962167501449585
val: 2 0.3903060853481293
val: 3 0.3866526186466217
val: 4 0.3915596306324005
val: 5 0.3882523477077484
val: 6 0.3978271782398224
val: 7 0.395148903131485
val: 8 0.39026153087615967
val: 9 0.3999871015548706
val: 10 0.38900226354599
val: 11 0.38999783992767334
val: 12 0.3820207715034485
val: 13 0.39346766471862793
val: 14 0.4014549255371094
val: 15 0.38205230236053467
val: 16 0.3894510567188263
val: 17 0.39323532581329346
val: 18 0.3884773552417755
val: 19 0.388045072555542
val: 20 0.39555808901786804
val_Epoch:[ 225 ] val_loss: 0.39144874066114427 2022-07-01 18:57:08.185876
start training 2022-07-01 18:57:08.284112
Epoch:[ 226 0 ] loss: 0.3598977029323578 2022-07-01 18:57:23.336515
Epoch:[ 226 1 ] loss: 0.3601263165473938 2022-07-01 18:57:23.766137
Epoch:[ 226 2 ] loss: 0.3597807288169861 2022-07-01 18:57:24.200068
Epoch:[ 226 3 ] loss: 0.36034533381462097 2022-07-01 18:57:24.629325
Epoch:[ 226 4 ] loss: 0.3600342571735382 2022-07-01 18:57:25.058802
Epoch:[ 226 5 ] loss: 0.3590143322944641 2022-07-01 18:57:25.492370
Epoch:[ 226 6 ] loss: 0.3597273528575897 2022-07-01 18:57:25.923709
Epoch:[ 226 7 ] loss: 0.3607167899608612 2022-07-01 18:57:26.354605
Epoch:[ 226 8 ] loss: 0.3598826825618744 2022-07-01 18:57:26.791021
Epoch:[ 226 9 ] loss: 0.360165536403656 2022-07-01 18:57:27.218100
Epoch:[ 226 10 ] loss: 0.3595059812068939 2022-07-01 18:57:27.646141
Epoch:[ 226 11 ] loss: 0.3608905076980591 2022-07-01 18:57:28.074517
Epoch:[ 226 12 ] loss: 0.35966992378234863 2022-07-01 18:57:28.505669
Epoch:[ 226 13 ] loss: 0.36035898327827454 2022-07-01 18:57:28.936303
Epoch:[ 226 14 ] loss: 0.36132869124412537 2022-07-01 18:57:29.367283
Epoch:[ 226 15 ] loss: 0.3614095151424408 2022-07-01 18:57:29.797274
Epoch:[ 226 16 ] loss: 0.36029568314552307 2022-07-01 18:57:34.904547
Epoch:[ 226 17 ] loss: 0.35929349064826965 2022-07-01 18:57:35.332299
Epoch:[ 226 18 ] loss: 0.3605906367301941 2022-07-01 18:57:35.767961
Epoch:[ 226 19 ] loss: 0.3609352707862854 2022-07-01 18:57:36.200910
Training_Epoch:[ 226 ] Training_loss: 0.36019848585128783 2022-07-01 18:57:36.201610
learning rate:  7.378697629483831e-06
netparams have been saved once 226
val: 1 0.3926226496696472
val: 2 0.3829337954521179
val: 3 0.3932870924472809
val: 4 0.3885463774204254
val: 5 0.39063236117362976
val: 6 0.3961462676525116
val: 7 0.38929659128189087
val: 8 0.39419102668762207
val: 9 0.3862471282482147
val: 10 0.3901301622390747
val: 11 0.38555917143821716
val: 12 0.3973701000213623
val: 13 0.3982497751712799
val: 14 0.3932270407676697
val: 15 0.38801318407058716
val: 16 0.388214111328125
val: 17 0.39466235041618347
val: 18 0.40077143907546997
val: 19 0.39227548241615295
val: 20 0.3862870931625366
val_Epoch:[ 226 ] val_loss: 0.39143316000699996 2022-07-01 18:57:40.106205
start training 2022-07-01 18:57:40.202430
Epoch:[ 227 0 ] loss: 0.36029016971588135 2022-07-01 18:57:54.720757
Epoch:[ 227 1 ] loss: 0.3614793121814728 2022-07-01 18:57:55.161842
Epoch:[ 227 2 ] loss: 0.3595925569534302 2022-07-01 18:57:55.593358
Epoch:[ 227 3 ] loss: 0.36087530851364136 2022-07-01 18:57:56.024524
Epoch:[ 227 4 ] loss: 0.35951805114746094 2022-07-01 18:57:56.453785
Epoch:[ 227 5 ] loss: 0.3596097230911255 2022-07-01 18:57:56.887155
Epoch:[ 227 6 ] loss: 0.36095666885375977 2022-07-01 18:57:57.322082
Epoch:[ 227 7 ] loss: 0.3590245842933655 2022-07-01 18:57:57.753532
Epoch:[ 227 8 ] loss: 0.3592534065246582 2022-07-01 18:57:58.185809
Epoch:[ 227 9 ] loss: 0.3612971305847168 2022-07-01 18:57:58.619340
Epoch:[ 227 10 ] loss: 0.3601784408092499 2022-07-01 18:57:59.048216
Epoch:[ 227 11 ] loss: 0.3602123260498047 2022-07-01 18:57:59.477635
Epoch:[ 227 12 ] loss: 0.35973259806632996 2022-07-01 18:57:59.913662
Epoch:[ 227 13 ] loss: 0.36049044132232666 2022-07-01 18:58:00.342774
Epoch:[ 227 14 ] loss: 0.3600631356239319 2022-07-01 18:58:00.774139
Epoch:[ 227 15 ] loss: 0.36102086305618286 2022-07-01 18:58:01.205497
Epoch:[ 227 16 ] loss: 0.36080098152160645 2022-07-01 18:58:06.512118
Epoch:[ 227 17 ] loss: 0.36051270365715027 2022-07-01 18:58:06.940500
Epoch:[ 227 18 ] loss: 0.36090460419654846 2022-07-01 18:58:07.395240
Epoch:[ 227 19 ] loss: 0.3601037859916687 2022-07-01 18:58:07.829787
Training_Epoch:[ 227 ] Training_loss: 0.3602958396077156 2022-07-01 18:58:07.830406
learning rate:  7.378697629483831e-06
val: 1 0.38679563999176025
val: 2 0.38934463262557983
val: 3 0.39103320240974426
val: 4 0.39421510696411133
val: 5 0.39361536502838135
val: 6 0.38626745343208313
val: 7 0.39721909165382385
val: 8 0.38366565108299255
val: 9 0.3910538852214813
val: 10 0.39631909132003784
val: 11 0.3884442150592804
val: 12 0.3943536579608917
val: 13 0.3905102610588074
val: 14 0.38598787784576416
val: 15 0.39416950941085815
val: 16 0.39074885845184326
val: 17 0.38554275035858154
val: 18 0.3886212706565857
val: 19 0.39090925455093384
val: 20 0.40168026089668274
val_Epoch:[ 227 ] val_loss: 0.39102485179901125 2022-07-01 18:58:11.675327
start training 2022-07-01 18:58:11.781131
Epoch:[ 228 0 ] loss: 0.3608640134334564 2022-07-01 18:58:26.450486
Epoch:[ 228 1 ] loss: 0.3600407540798187 2022-07-01 18:58:26.886255
Epoch:[ 228 2 ] loss: 0.3605509102344513 2022-07-01 18:58:27.316337
Epoch:[ 228 3 ] loss: 0.36087435483932495 2022-07-01 18:58:27.747436
Epoch:[ 228 4 ] loss: 0.3592822253704071 2022-07-01 18:58:28.177809
Epoch:[ 228 5 ] loss: 0.3602200150489807 2022-07-01 18:58:28.605749
Epoch:[ 228 6 ] loss: 0.3614140748977661 2022-07-01 18:58:29.035250
Epoch:[ 228 7 ] loss: 0.3607236444950104 2022-07-01 18:58:29.463478
Epoch:[ 228 8 ] loss: 0.3593946397304535 2022-07-01 18:58:29.894403
Epoch:[ 228 9 ] loss: 0.3593713641166687 2022-07-01 18:58:30.330290
Epoch:[ 228 10 ] loss: 0.3602166771888733 2022-07-01 18:58:30.760483
Epoch:[ 228 11 ] loss: 0.360424667596817 2022-07-01 18:58:31.190092
Epoch:[ 228 12 ] loss: 0.3597881495952606 2022-07-01 18:58:31.625828
Epoch:[ 228 13 ] loss: 0.3601842522621155 2022-07-01 18:58:32.053930
Epoch:[ 228 14 ] loss: 0.36027246713638306 2022-07-01 18:58:32.482249
Epoch:[ 228 15 ] loss: 0.36055201292037964 2022-07-01 18:58:32.914028
Epoch:[ 228 16 ] loss: 0.36034783720970154 2022-07-01 18:58:37.715383
Epoch:[ 228 17 ] loss: 0.3609306812286377 2022-07-01 18:58:38.164555
Epoch:[ 228 18 ] loss: 0.3603655695915222 2022-07-01 18:58:38.617616
Epoch:[ 228 19 ] loss: 0.3600977659225464 2022-07-01 18:58:39.047017
Training_Epoch:[ 228 ] Training_loss: 0.36029580384492876 2022-07-01 18:58:39.047678
learning rate:  7.378697629483831e-06
netparams have been saved once 228
val: 1 0.39737391471862793
val: 2 0.39388564229011536
val: 3 0.3919748067855835
val: 4 0.38873693346977234
val: 5 0.39965054392814636
val: 6 0.3901849389076233
val: 7 0.3915099501609802
val: 8 0.3896336853504181
val: 9 0.38287729024887085
val: 10 0.3831084370613098
val: 11 0.3892592787742615
val: 12 0.38759955763816833
val: 13 0.3919975161552429
val: 14 0.39482244849205017
val: 15 0.3915177285671234
val: 16 0.3929615020751953
val: 17 0.38740381598472595
val: 18 0.39410924911499023
val: 19 0.3935416042804718
val: 20 0.3940024673938751
val_Epoch:[ 228 ] val_loss: 0.3913075655698776 2022-07-01 18:58:42.901982
start training 2022-07-01 18:58:43.005465
Epoch:[ 229 0 ] loss: 0.3595272898674011 2022-07-01 18:58:57.188960
Epoch:[ 229 1 ] loss: 0.36090511083602905 2022-07-01 18:58:57.633832
Epoch:[ 229 2 ] loss: 0.3601616322994232 2022-07-01 18:58:58.065998
Epoch:[ 229 3 ] loss: 0.3601538836956024 2022-07-01 18:58:58.496907
Epoch:[ 229 4 ] loss: 0.36035454273223877 2022-07-01 18:58:58.927064
Epoch:[ 229 5 ] loss: 0.36005526781082153 2022-07-01 18:58:59.362269
Epoch:[ 229 6 ] loss: 0.35903072357177734 2022-07-01 18:58:59.792438
Epoch:[ 229 7 ] loss: 0.36002251505851746 2022-07-01 18:59:00.221870
Epoch:[ 229 8 ] loss: 0.35916414856910706 2022-07-01 18:59:00.656909
Epoch:[ 229 9 ] loss: 0.3607948422431946 2022-07-01 18:59:01.086704
Epoch:[ 229 10 ] loss: 0.3614618182182312 2022-07-01 18:59:01.518329
Epoch:[ 229 11 ] loss: 0.3607742488384247 2022-07-01 18:59:01.949669
Epoch:[ 229 12 ] loss: 0.361423522233963 2022-07-01 18:59:02.385295
Epoch:[ 229 13 ] loss: 0.3615165054798126 2022-07-01 18:59:02.814310
Epoch:[ 229 14 ] loss: 0.3597567677497864 2022-07-01 18:59:03.243986
Epoch:[ 229 15 ] loss: 0.3603225648403168 2022-07-01 18:59:03.675799
Epoch:[ 229 16 ] loss: 0.360397607088089 2022-07-01 18:59:08.707843
Epoch:[ 229 17 ] loss: 0.36009204387664795 2022-07-01 18:59:09.142614
Epoch:[ 229 18 ] loss: 0.35994952917099 2022-07-01 18:59:09.650440
Epoch:[ 229 19 ] loss: 0.35991206765174866 2022-07-01 18:59:10.084403
Training_Epoch:[ 229 ] Training_loss: 0.36028883159160613 2022-07-01 18:59:10.085097
learning rate:  7.378697629483831e-06
val: 1 0.39174532890319824
val: 2 0.400619775056839
val: 3 0.38713645935058594
val: 4 0.3961559534072876
val: 5 0.38866090774536133
val: 6 0.3970036506652832
val: 7 0.38522884249687195
val: 8 0.39475393295288086
val: 9 0.3882140815258026
val: 10 0.39293912053108215
val: 11 0.3936448395252228
val: 12 0.398612380027771
val: 13 0.3876722753047943
val: 14 0.38946789503097534
val: 15 0.387848436832428
val: 16 0.3808650076389313
val: 17 0.39802417159080505
val: 18 0.3905397951602936
val: 19 0.38778144121170044
val: 20 0.3870041072368622
val_Epoch:[ 229 ] val_loss: 0.39119592010974885 2022-07-01 18:59:13.922920
start training 2022-07-01 18:59:14.023281
Epoch:[ 230 0 ] loss: 0.361112505197525 2022-07-01 18:59:27.989845
Epoch:[ 230 1 ] loss: 0.3608473539352417 2022-07-01 18:59:28.436709
Epoch:[ 230 2 ] loss: 0.3612554371356964 2022-07-01 18:59:28.866916
Epoch:[ 230 3 ] loss: 0.35971418023109436 2022-07-01 18:59:29.304249
Epoch:[ 230 4 ] loss: 0.36142733693122864 2022-07-01 18:59:29.723208
Epoch:[ 230 5 ] loss: 0.359112948179245 2022-07-01 18:59:30.132220
Epoch:[ 230 6 ] loss: 0.359526127576828 2022-07-01 18:59:30.547669
Epoch:[ 230 7 ] loss: 0.35949474573135376 2022-07-01 18:59:30.963216
Epoch:[ 230 8 ] loss: 0.36142048239707947 2022-07-01 18:59:31.371636
Epoch:[ 230 9 ] loss: 0.3595079481601715 2022-07-01 18:59:31.790290
Epoch:[ 230 10 ] loss: 0.3605792820453644 2022-07-01 18:59:32.208555
Epoch:[ 230 11 ] loss: 0.3606812357902527 2022-07-01 18:59:32.625491
Epoch:[ 230 12 ] loss: 0.3596494197845459 2022-07-01 18:59:33.042346
Epoch:[ 230 13 ] loss: 0.3612034320831299 2022-07-01 18:59:33.456722
Epoch:[ 230 14 ] loss: 0.3602643311023712 2022-07-01 18:59:33.875529
Epoch:[ 230 15 ] loss: 0.3595084547996521 2022-07-01 18:59:34.291942
Epoch:[ 230 16 ] loss: 0.3612980544567108 2022-07-01 18:59:39.821688
Epoch:[ 230 17 ] loss: 0.3604006767272949 2022-07-01 18:59:40.253008
Epoch:[ 230 18 ] loss: 0.3593824803829193 2022-07-01 18:59:40.695702
Epoch:[ 230 19 ] loss: 0.35871514678001404 2022-07-01 18:59:41.127269
Training_Epoch:[ 230 ] Training_loss: 0.360255078971386 2022-07-01 18:59:41.128007
learning rate:  7.378697629483831e-06
netparams have been saved once 230
val: 1 0.3999652862548828
val: 2 0.39451780915260315
val: 3 0.38325655460357666
val: 4 0.3926757276058197
val: 5 0.39013415575027466
val: 6 0.3916435241699219
val: 7 0.3963741064071655
val: 8 0.39130252599716187
val: 9 0.39647942781448364
val: 10 0.3921738564968109
val: 11 0.38908639550209045
val: 12 0.3863256275653839
val: 13 0.3981248438358307
val: 14 0.3837675154209137
val: 15 0.3864831030368805
val: 16 0.3879010081291199
val: 17 0.38934436440467834
val: 18 0.39381322264671326
val: 19 0.3868418335914612
val: 20 0.39252662658691406
val_Epoch:[ 230 ] val_loss: 0.3911368757486343 2022-07-01 18:59:45.153984
start training 2022-07-01 18:59:45.256392
Epoch:[ 231 0 ] loss: 0.35882970690727234 2022-07-01 19:00:00.226836
Epoch:[ 231 1 ] loss: 0.35998839139938354 2022-07-01 19:00:00.656532
Epoch:[ 231 2 ] loss: 0.3613182306289673 2022-07-01 19:00:01.088161
Epoch:[ 231 3 ] loss: 0.36036425828933716 2022-07-01 19:00:01.517146
Epoch:[ 231 4 ] loss: 0.3604714274406433 2022-07-01 19:00:01.947258
Epoch:[ 231 5 ] loss: 0.3608071208000183 2022-07-01 19:00:02.377424
Epoch:[ 231 6 ] loss: 0.35853737592697144 2022-07-01 19:00:02.812813
Epoch:[ 231 7 ] loss: 0.3596805930137634 2022-07-01 19:00:03.242155
Epoch:[ 231 8 ] loss: 0.3600972592830658 2022-07-01 19:00:03.672806
Epoch:[ 231 9 ] loss: 0.36064961552619934 2022-07-01 19:00:04.101778
Epoch:[ 231 10 ] loss: 0.36082708835601807 2022-07-01 19:00:04.532677
Epoch:[ 231 11 ] loss: 0.35970401763916016 2022-07-01 19:00:04.969200
Epoch:[ 231 12 ] loss: 0.36132577061653137 2022-07-01 19:00:05.400633
Epoch:[ 231 13 ] loss: 0.36080247163772583 2022-07-01 19:00:05.830686
Epoch:[ 231 14 ] loss: 0.3603803217411041 2022-07-01 19:00:06.265383
Epoch:[ 231 15 ] loss: 0.36086899042129517 2022-07-01 19:00:06.694084
Epoch:[ 231 16 ] loss: 0.3597268760204315 2022-07-01 19:00:11.605642
Epoch:[ 231 17 ] loss: 0.36076417565345764 2022-07-01 19:00:12.040644
Epoch:[ 231 18 ] loss: 0.36008626222610474 2022-07-01 19:00:12.479294
Epoch:[ 231 19 ] loss: 0.3611077666282654 2022-07-01 19:00:12.911192
Training_Epoch:[ 231 ] Training_loss: 0.3603168860077858 2022-07-01 19:00:12.911915
learning rate:  5.902958103587065e-06
val: 1 0.39713054895401
val: 2 0.38647931814193726
val: 3 0.3907182216644287
val: 4 0.3876296877861023
val: 5 0.3921372890472412
val: 6 0.3856155276298523
val: 7 0.397862046957016
val: 8 0.39420926570892334
val: 9 0.38885608315467834
val: 10 0.38726574182510376
val: 11 0.38705748319625854
val: 12 0.3903261423110962
val: 13 0.3855856955051422
val: 14 0.3933328092098236
val: 15 0.3835792541503906
val: 16 0.3944336175918579
val: 17 0.39295247197151184
val: 18 0.40423139929771423
val: 19 0.395860880613327
val: 20 0.3879915177822113
val_Epoch:[ 231 ] val_loss: 0.39116275012493135 2022-07-01 19:00:16.776319
start training 2022-07-01 19:00:16.883210
Epoch:[ 232 0 ] loss: 0.36128321290016174 2022-07-01 19:00:32.052362
Epoch:[ 232 1 ] loss: 0.3605335056781769 2022-07-01 19:00:32.481862
Epoch:[ 232 2 ] loss: 0.3599364757537842 2022-07-01 19:00:32.911261
Epoch:[ 232 3 ] loss: 0.35946616530418396 2022-07-01 19:00:33.346108
Epoch:[ 232 4 ] loss: 0.3597921133041382 2022-07-01 19:00:33.778062
Epoch:[ 232 5 ] loss: 0.3603680729866028 2022-07-01 19:00:34.210189
Epoch:[ 232 6 ] loss: 0.3614637553691864 2022-07-01 19:00:34.647201
Epoch:[ 232 7 ] loss: 0.3597877323627472 2022-07-01 19:00:35.077798
Epoch:[ 232 8 ] loss: 0.3609081208705902 2022-07-01 19:00:35.510477
Epoch:[ 232 9 ] loss: 0.35979270935058594 2022-07-01 19:00:35.939419
Epoch:[ 232 10 ] loss: 0.3605974316596985 2022-07-01 19:00:36.373004
Epoch:[ 232 11 ] loss: 0.3600022792816162 2022-07-01 19:00:36.803409
Epoch:[ 232 12 ] loss: 0.3598233163356781 2022-07-01 19:00:37.236008
Epoch:[ 232 13 ] loss: 0.3606766164302826 2022-07-01 19:00:37.668012
Epoch:[ 232 14 ] loss: 0.36135387420654297 2022-07-01 19:00:38.098771
Epoch:[ 232 15 ] loss: 0.360122948884964 2022-07-01 19:00:38.527433
Epoch:[ 232 16 ] loss: 0.3594731092453003 2022-07-01 19:00:43.556999
Epoch:[ 232 17 ] loss: 0.3592558801174164 2022-07-01 19:00:43.988456
Epoch:[ 232 18 ] loss: 0.3606864809989929 2022-07-01 19:00:44.425300
Epoch:[ 232 19 ] loss: 0.3603542149066925 2022-07-01 19:00:44.861638
Training_Epoch:[ 232 ] Training_loss: 0.3602839007973671 2022-07-01 19:00:44.862372
learning rate:  5.902958103587065e-06
netparams have been saved once 232
val: 1 0.3868699073791504
val: 2 0.3834429681301117
val: 3 0.38698095083236694
val: 4 0.3890775144100189
val: 5 0.38318347930908203
val: 6 0.3929184675216675
val: 7 0.38846585154533386
val: 8 0.392952561378479
val: 9 0.3976607322692871
val: 10 0.395641565322876
val: 11 0.3954307734966278
val: 12 0.39605459570884705
val: 13 0.3915344476699829
val: 14 0.39937859773635864
val: 15 0.39201489090919495
val: 16 0.3924112915992737
val: 17 0.38878127932548523
val: 18 0.38610145449638367
val: 19 0.39059606194496155
val: 20 0.3928848206996918
val_Epoch:[ 232 ] val_loss: 0.391119110584259 2022-07-01 19:00:48.739676
start training 2022-07-01 19:00:48.839010
Epoch:[ 233 0 ] loss: 0.35987263917922974 2022-07-01 19:01:03.882186
Epoch:[ 233 1 ] loss: 0.35993772745132446 2022-07-01 19:01:04.312071
Epoch:[ 233 2 ] loss: 0.3592950105667114 2022-07-01 19:01:04.740435
Epoch:[ 233 3 ] loss: 0.36043915152549744 2022-07-01 19:01:05.170334
Epoch:[ 233 4 ] loss: 0.3613773584365845 2022-07-01 19:01:05.599449
Epoch:[ 233 5 ] loss: 0.36069414019584656 2022-07-01 19:01:06.028245
Epoch:[ 233 6 ] loss: 0.36105629801750183 2022-07-01 19:01:06.459446
Epoch:[ 233 7 ] loss: 0.36047372221946716 2022-07-01 19:01:06.890364
Epoch:[ 233 8 ] loss: 0.3598308265209198 2022-07-01 19:01:07.322941
Epoch:[ 233 9 ] loss: 0.36131107807159424 2022-07-01 19:01:07.750362
Epoch:[ 233 10 ] loss: 0.3609186112880707 2022-07-01 19:01:08.179311
Epoch:[ 233 11 ] loss: 0.3587038218975067 2022-07-01 19:01:08.608143
Epoch:[ 233 12 ] loss: 0.36144423484802246 2022-07-01 19:01:09.036673
Epoch:[ 233 13 ] loss: 0.35990095138549805 2022-07-01 19:01:09.473399
Epoch:[ 233 14 ] loss: 0.36056044697761536 2022-07-01 19:01:09.908904
Epoch:[ 233 15 ] loss: 0.35860854387283325 2022-07-01 19:01:10.339102
Epoch:[ 233 16 ] loss: 0.36079803109169006 2022-07-01 19:01:15.605216
Epoch:[ 233 17 ] loss: 0.36101603507995605 2022-07-01 19:01:16.032042
Epoch:[ 233 18 ] loss: 0.35975566506385803 2022-07-01 19:01:16.467169
Epoch:[ 233 19 ] loss: 0.35907572507858276 2022-07-01 19:01:16.902183
Training_Epoch:[ 233 ] Training_loss: 0.3602535009384155 2022-07-01 19:01:16.902849
learning rate:  5.902958103587065e-06
val: 1 0.38759711384773254
val: 2 0.3862473964691162
val: 3 0.38203972578048706
val: 4 0.3853972256183624
val: 5 0.3897460103034973
val: 6 0.39215710759162903
val: 7 0.38340824842453003
val: 8 0.3931894600391388
val: 9 0.3856222927570343
val: 10 0.3813794255256653
val: 11 0.39239510893821716
val: 12 0.3967219293117523
val: 13 0.40272659063339233
val: 14 0.39458122849464417
val: 15 0.39699554443359375
val: 16 0.3947843611240387
val: 17 0.39858320355415344
val: 18 0.39753758907318115
val: 19 0.39607059955596924
val: 20 0.3876907527446747
val_Epoch:[ 233 ] val_loss: 0.3912435457110405 2022-07-01 19:01:20.731666
start training 2022-07-01 19:01:20.831238
Epoch:[ 234 0 ] loss: 0.3591957986354828 2022-07-01 19:01:35.667177
Epoch:[ 234 1 ] loss: 0.36096811294555664 2022-07-01 19:01:36.097925
Epoch:[ 234 2 ] loss: 0.360134482383728 2022-07-01 19:01:36.528412
Epoch:[ 234 3 ] loss: 0.36085742712020874 2022-07-01 19:01:36.957731
Epoch:[ 234 4 ] loss: 0.3608472943305969 2022-07-01 19:01:37.388841
Epoch:[ 234 5 ] loss: 0.3600136935710907 2022-07-01 19:01:37.818251
Epoch:[ 234 6 ] loss: 0.35935887694358826 2022-07-01 19:01:38.248038
Epoch:[ 234 7 ] loss: 0.36103323101997375 2022-07-01 19:01:38.684853
Epoch:[ 234 8 ] loss: 0.36053526401519775 2022-07-01 19:01:39.117886
Epoch:[ 234 9 ] loss: 0.36090096831321716 2022-07-01 19:01:39.551202
Epoch:[ 234 10 ] loss: 0.3597116470336914 2022-07-01 19:01:39.982864
Epoch:[ 234 11 ] loss: 0.3604333698749542 2022-07-01 19:01:40.420863
Epoch:[ 234 12 ] loss: 0.3591298460960388 2022-07-01 19:01:40.851103
Epoch:[ 234 13 ] loss: 0.36021366715431213 2022-07-01 19:01:41.284873
Epoch:[ 234 14 ] loss: 0.35937732458114624 2022-07-01 19:01:41.727139
Epoch:[ 234 15 ] loss: 0.36018338799476624 2022-07-01 19:01:42.159521
Epoch:[ 234 16 ] loss: 0.36044928431510925 2022-07-01 19:01:47.148584
Epoch:[ 234 17 ] loss: 0.3618185818195343 2022-07-01 19:01:47.583702
Epoch:[ 234 18 ] loss: 0.3602769672870636 2022-07-01 19:01:48.019896
Epoch:[ 234 19 ] loss: 0.3596225082874298 2022-07-01 19:01:48.449479
Training_Epoch:[ 234 ] Training_loss: 0.3602530866861343 2022-07-01 19:01:48.450340
learning rate:  5.902958103587065e-06
netparams have been saved once 234
val: 1 0.39183422923088074
val: 2 0.3820802867412567
val: 3 0.38326582312583923
val: 4 0.3953072726726532
val: 5 0.3866022527217865
val: 6 0.3837697207927704
val: 7 0.39501917362213135
val: 8 0.3926622271537781
val: 9 0.3936716318130493
val: 10 0.39075401425361633
val: 11 0.38580527901649475
val: 12 0.3953976333141327
val: 13 0.3880864381790161
val: 14 0.3887004852294922
val: 15 0.3989329934120178
val: 16 0.3937269449234009
val: 17 0.3927733898162842
val: 18 0.3900032043457031
val: 19 0.39757034182548523
val: 20 0.3983054757118225
val_Epoch:[ 234 ] val_loss: 0.3912134408950806 2022-07-01 19:01:52.495775
start training 2022-07-01 19:01:52.594464
Epoch:[ 235 0 ] loss: 0.3609442710876465 2022-07-01 19:02:07.067994
Epoch:[ 235 1 ] loss: 0.3599536716938019 2022-07-01 19:02:07.505919
Epoch:[ 235 2 ] loss: 0.360032856464386 2022-07-01 19:02:07.938603
Epoch:[ 235 3 ] loss: 0.3601474165916443 2022-07-01 19:02:08.378810
Epoch:[ 235 4 ] loss: 0.3607593774795532 2022-07-01 19:02:08.809470
Epoch:[ 235 5 ] loss: 0.3593388497829437 2022-07-01 19:02:09.241268
Epoch:[ 235 6 ] loss: 0.3603920340538025 2022-07-01 19:02:09.670643
Epoch:[ 235 7 ] loss: 0.36048364639282227 2022-07-01 19:02:10.102711
Epoch:[ 235 8 ] loss: 0.3593444526195526 2022-07-01 19:02:10.537878
Epoch:[ 235 9 ] loss: 0.3598632216453552 2022-07-01 19:02:10.969490
Epoch:[ 235 10 ] loss: 0.3587336540222168 2022-07-01 19:02:11.402446
Epoch:[ 235 11 ] loss: 0.36039915680885315 2022-07-01 19:02:11.833601
Epoch:[ 235 12 ] loss: 0.36067628860473633 2022-07-01 19:02:12.267213
Epoch:[ 235 13 ] loss: 0.36034250259399414 2022-07-01 19:02:12.696982
Epoch:[ 235 14 ] loss: 0.36082345247268677 2022-07-01 19:02:13.130208
Epoch:[ 235 15 ] loss: 0.3612252473831177 2022-07-01 19:02:13.568994
Epoch:[ 235 16 ] loss: 0.35921013355255127 2022-07-01 19:02:18.932341
Epoch:[ 235 17 ] loss: 0.36087313294410706 2022-07-01 19:02:19.372303
Epoch:[ 235 18 ] loss: 0.36040574312210083 2022-07-01 19:02:19.814139
Epoch:[ 235 19 ] loss: 0.3605291247367859 2022-07-01 19:02:20.245303
Training_Epoch:[ 235 ] Training_loss: 0.3602239117026329 2022-07-01 19:02:20.245974
learning rate:  5.902958103587065e-06
val: 1 0.40174320340156555
val: 2 0.38656556606292725
val: 3 0.3886757791042328
val: 4 0.38924726843833923
val: 5 0.3868761658668518
val: 6 0.385381817817688
val: 7 0.38618165254592896
val: 8 0.39499005675315857
val: 9 0.39127784967422485
val: 10 0.39062291383743286
val: 11 0.3920494019985199
val: 12 0.3933134973049164
val: 13 0.3907466232776642
val: 14 0.3942607045173645
val: 15 0.39351025223731995
val: 16 0.39504358172416687
val: 17 0.38945168256759644
val: 18 0.3968298137187958
val: 19 0.3886060416698456
val: 20 0.3875746726989746
val_Epoch:[ 235 ] val_loss: 0.3911474272608757 2022-07-01 19:02:24.139556
start training 2022-07-01 19:02:24.239070
Epoch:[ 236 0 ] loss: 0.3593149185180664 2022-07-01 19:02:39.276395
Epoch:[ 236 1 ] loss: 0.3592821955680847 2022-07-01 19:02:39.709192
Epoch:[ 236 2 ] loss: 0.362517774105072 2022-07-01 19:02:40.143977
Epoch:[ 236 3 ] loss: 0.3600919246673584 2022-07-01 19:02:40.582814
Epoch:[ 236 4 ] loss: 0.360244482755661 2022-07-01 19:02:41.016019
Epoch:[ 236 5 ] loss: 0.3600136935710907 2022-07-01 19:02:41.446225
Epoch:[ 236 6 ] loss: 0.35947394371032715 2022-07-01 19:02:41.879207
Epoch:[ 236 7 ] loss: 0.36071544885635376 2022-07-01 19:02:42.308782
Epoch:[ 236 8 ] loss: 0.35926908254623413 2022-07-01 19:02:42.742110
Epoch:[ 236 9 ] loss: 0.3605392277240753 2022-07-01 19:02:43.177568
Epoch:[ 236 10 ] loss: 0.36041387915611267 2022-07-01 19:02:43.615779
Epoch:[ 236 11 ] loss: 0.36082738637924194 2022-07-01 19:02:44.052412
Epoch:[ 236 12 ] loss: 0.3613041341304779 2022-07-01 19:02:44.484576
Epoch:[ 236 13 ] loss: 0.3600751459598541 2022-07-01 19:02:44.915196
Epoch:[ 236 14 ] loss: 0.3595871925354004 2022-07-01 19:02:45.348556
Epoch:[ 236 15 ] loss: 0.3602345287799835 2022-07-01 19:02:45.778705
Epoch:[ 236 16 ] loss: 0.3599417507648468 2022-07-01 19:02:50.925783
Epoch:[ 236 17 ] loss: 0.3592739701271057 2022-07-01 19:02:51.363559
Epoch:[ 236 18 ] loss: 0.3607027232646942 2022-07-01 19:02:51.812186
Epoch:[ 236 19 ] loss: 0.36192938685417175 2022-07-01 19:02:52.240736
Training_Epoch:[ 236 ] Training_loss: 0.3602876394987106 2022-07-01 19:02:52.241411
learning rate:  5.902958103587065e-06
netparams have been saved once 236
val: 1 0.39029985666275024
val: 2 0.39010950922966003
val: 3 0.3950919508934021
val: 4 0.39171677827835083
val: 5 0.393726646900177
val: 6 0.3886584937572479
val: 7 0.3954063653945923
val: 8 0.39638882875442505
val: 9 0.39372003078460693
val: 10 0.38669800758361816
val: 11 0.39356690645217896
val: 12 0.38981571793556213
val: 13 0.39594197273254395
val: 14 0.38922345638275146
val: 15 0.38856273889541626
val: 16 0.3859502673149109
val: 17 0.3947189748287201
val: 18 0.3888563811779022
val: 19 0.40163522958755493
val: 20 0.3807970881462097
val_Epoch:[ 236 ] val_loss: 0.39154426008462906 2022-07-01 19:02:56.101490
start training 2022-07-01 19:02:56.201814
Epoch:[ 237 0 ] loss: 0.36069586873054504 2022-07-01 19:03:10.895593
Epoch:[ 237 1 ] loss: 0.36044690012931824 2022-07-01 19:03:11.341645
Epoch:[ 237 2 ] loss: 0.3589896559715271 2022-07-01 19:03:11.777010
Epoch:[ 237 3 ] loss: 0.3590563237667084 2022-07-01 19:03:12.209704
Epoch:[ 237 4 ] loss: 0.3603619933128357 2022-07-01 19:03:12.626981
Epoch:[ 237 5 ] loss: 0.3601965606212616 2022-07-01 19:03:13.043070
Epoch:[ 237 6 ] loss: 0.360028475522995 2022-07-01 19:03:13.460515
Epoch:[ 237 7 ] loss: 0.3599991798400879 2022-07-01 19:03:13.875201
Epoch:[ 237 8 ] loss: 0.36084210872650146 2022-07-01 19:03:14.284716
Epoch:[ 237 9 ] loss: 0.3593345582485199 2022-07-01 19:03:14.703604
Epoch:[ 237 10 ] loss: 0.35985124111175537 2022-07-01 19:03:15.124419
Epoch:[ 237 11 ] loss: 0.36042043566703796 2022-07-01 19:03:15.537017
Epoch:[ 237 12 ] loss: 0.36178189516067505 2022-07-01 19:03:15.955122
Epoch:[ 237 13 ] loss: 0.36167553067207336 2022-07-01 19:03:16.372997
Epoch:[ 237 14 ] loss: 0.3613077402114868 2022-07-01 19:03:16.788642
Epoch:[ 237 15 ] loss: 0.3592541515827179 2022-07-01 19:03:17.203383
Epoch:[ 237 16 ] loss: 0.360767662525177 2022-07-01 19:03:22.487882
Epoch:[ 237 17 ] loss: 0.3596327304840088 2022-07-01 19:03:22.908363
Epoch:[ 237 18 ] loss: 0.36028340458869934 2022-07-01 19:03:23.346995
Epoch:[ 237 19 ] loss: 0.36079737544059753 2022-07-01 19:03:23.762100
Training_Epoch:[ 237 ] Training_loss: 0.36028618961572645 2022-07-01 19:03:23.762991
learning rate:  5.902958103587065e-06
val: 1 0.39310622215270996
val: 2 0.3892245888710022
val: 3 0.38654953241348267
val: 4 0.3902183175086975
val: 5 0.3958282470703125
val: 6 0.3928079307079315
val: 7 0.3901659846305847
val: 8 0.38261404633522034
val: 9 0.38787728548049927
val: 10 0.3895723819732666
val: 11 0.38457411527633667
val: 12 0.3937934339046478
val: 13 0.3838799297809601
val: 14 0.3903229832649231
val: 15 0.39124172925949097
val: 16 0.39009127020835876
val: 17 0.40131253004074097
val: 18 0.4007563591003418
val: 19 0.39100369811058044
val: 20 0.3966524302959442
val_Epoch:[ 237 ] val_loss: 0.3910796508193016 2022-07-01 19:03:27.864524
start training 2022-07-01 19:03:27.962709
Epoch:[ 238 0 ] loss: 0.3597690761089325 2022-07-01 19:03:42.298945
Epoch:[ 238 1 ] loss: 0.3598307967185974 2022-07-01 19:03:42.903334
Epoch:[ 238 2 ] loss: 0.36035066843032837 2022-07-01 19:03:43.332244
Epoch:[ 238 3 ] loss: 0.3599143624305725 2022-07-01 19:03:43.760417
Epoch:[ 238 4 ] loss: 0.3598669469356537 2022-07-01 19:03:44.191722
Epoch:[ 238 5 ] loss: 0.36058977246284485 2022-07-01 19:03:44.634050
Epoch:[ 238 6 ] loss: 0.3596852421760559 2022-07-01 19:03:45.069008
Epoch:[ 238 7 ] loss: 0.3602021634578705 2022-07-01 19:03:45.497247
Epoch:[ 238 8 ] loss: 0.35880541801452637 2022-07-01 19:03:45.928140
Epoch:[ 238 9 ] loss: 0.3601812422275543 2022-07-01 19:03:46.356190
Epoch:[ 238 10 ] loss: 0.36020129919052124 2022-07-01 19:03:46.789968
Epoch:[ 238 11 ] loss: 0.3608246445655823 2022-07-01 19:03:47.219641
Epoch:[ 238 12 ] loss: 0.3601286709308624 2022-07-01 19:03:47.656370
Epoch:[ 238 13 ] loss: 0.36067530512809753 2022-07-01 19:03:48.086338
Epoch:[ 238 14 ] loss: 0.3629709482192993 2022-07-01 19:03:48.516420
Epoch:[ 238 15 ] loss: 0.35968396067619324 2022-07-01 19:03:48.943752
Epoch:[ 238 16 ] loss: 0.3600219488143921 2022-07-01 19:03:54.510233
Epoch:[ 238 17 ] loss: 0.3605791926383972 2022-07-01 19:03:54.941403
Epoch:[ 238 18 ] loss: 0.36061277985572815 2022-07-01 19:03:55.386065
Epoch:[ 238 19 ] loss: 0.36008501052856445 2022-07-01 19:03:55.816045
Training_Epoch:[ 238 ] Training_loss: 0.36024897247552873 2022-07-01 19:03:55.816711
learning rate:  5.902958103587065e-06
netparams have been saved once 238
val: 1 0.38823366165161133
val: 2 0.3867394030094147
val: 3 0.4014172852039337
val: 4 0.38861793279647827
val: 5 0.3866274654865265
val: 6 0.3977891206741333
val: 7 0.3874751627445221
val: 8 0.3912639617919922
val: 9 0.39363107085227966
val: 10 0.38642629981040955
val: 11 0.3866589665412903
val: 12 0.4002034366130829
val: 13 0.3927944302558899
val: 14 0.38681402802467346
val: 15 0.3916628062725067
val: 16 0.38554224371910095
val: 17 0.39618468284606934
val: 18 0.39059263467788696
val: 19 0.38963744044303894
val: 20 0.39608651399612427
val_Epoch:[ 238 ] val_loss: 0.3912199273705482 2022-07-01 19:03:59.720618
start training 2022-07-01 19:03:59.820698
Epoch:[ 239 0 ] loss: 0.3618875741958618 2022-07-01 19:04:14.177512
Epoch:[ 239 1 ] loss: 0.3598529100418091 2022-07-01 19:04:14.592133
Epoch:[ 239 2 ] loss: 0.36088448762893677 2022-07-01 19:04:15.007683
Epoch:[ 239 3 ] loss: 0.3614440858364105 2022-07-01 19:04:15.421166
Epoch:[ 239 4 ] loss: 0.360919713973999 2022-07-01 19:04:15.826727
Epoch:[ 239 5 ] loss: 0.3598322868347168 2022-07-01 19:04:16.243360
Epoch:[ 239 6 ] loss: 0.35975655913352966 2022-07-01 19:04:16.658069
Epoch:[ 239 7 ] loss: 0.361248642206192 2022-07-01 19:04:17.074109
Epoch:[ 239 8 ] loss: 0.3600025177001953 2022-07-01 19:04:17.483569
Epoch:[ 239 9 ] loss: 0.3595446050167084 2022-07-01 19:04:17.898350
Epoch:[ 239 10 ] loss: 0.36062192916870117 2022-07-01 19:04:18.315113
Epoch:[ 239 11 ] loss: 0.36012619733810425 2022-07-01 19:04:18.728810
Epoch:[ 239 12 ] loss: 0.35950881242752075 2022-07-01 19:04:19.137160
Epoch:[ 239 13 ] loss: 0.35993558168411255 2022-07-01 19:04:19.554160
Epoch:[ 239 14 ] loss: 0.3605203926563263 2022-07-01 19:04:19.969312
Epoch:[ 239 15 ] loss: 0.36009931564331055 2022-07-01 19:04:20.386451
Epoch:[ 239 16 ] loss: 0.3587546944618225 2022-07-01 19:04:25.875702
Epoch:[ 239 17 ] loss: 0.3594546318054199 2022-07-01 19:04:26.294034
Epoch:[ 239 18 ] loss: 0.36121267080307007 2022-07-01 19:04:26.729516
Epoch:[ 239 19 ] loss: 0.35975345969200134 2022-07-01 19:04:27.138679
Training_Epoch:[ 239 ] Training_loss: 0.36026805341243745 2022-07-01 19:04:27.139780
learning rate:  5.902958103587065e-06
val: 1 0.38886064291000366
val: 2 0.3955010771751404
val: 3 0.3955155909061432
val: 4 0.3863891363143921
val: 5 0.39173370599746704
val: 6 0.39200055599212646
val: 7 0.38974982500076294
val: 8 0.3862729072570801
val: 9 0.39425501227378845
val: 10 0.38916370272636414
val: 11 0.3935643434524536
val: 12 0.39283350110054016
val: 13 0.3899215757846832
val: 14 0.3959183096885681
val: 15 0.3938257098197937
val: 16 0.3906639516353607
val: 17 0.3860221207141876
val: 18 0.38375890254974365
val: 19 0.39764249324798584
val: 20 0.3873496949672699
val_Epoch:[ 239 ] val_loss: 0.39104713797569274 2022-07-01 19:04:31.102136
start training 2022-07-01 19:04:31.202972
Epoch:[ 240 0 ] loss: 0.36179423332214355 2022-07-01 19:04:45.974058
Epoch:[ 240 1 ] loss: 0.36056584119796753 2022-07-01 19:04:46.403427
Epoch:[ 240 2 ] loss: 0.36187276244163513 2022-07-01 19:04:46.838617
Epoch:[ 240 3 ] loss: 0.35993725061416626 2022-07-01 19:04:47.267908
Epoch:[ 240 4 ] loss: 0.3604670763015747 2022-07-01 19:04:47.696773
Epoch:[ 240 5 ] loss: 0.3599247634410858 2022-07-01 19:04:48.126201
Epoch:[ 240 6 ] loss: 0.35969051718711853 2022-07-01 19:04:48.561955
Epoch:[ 240 7 ] loss: 0.36072665452957153 2022-07-01 19:04:48.993312
Epoch:[ 240 8 ] loss: 0.35983404517173767 2022-07-01 19:04:49.423472
Epoch:[ 240 9 ] loss: 0.36034801602363586 2022-07-01 19:04:49.852407
Epoch:[ 240 10 ] loss: 0.35927873849868774 2022-07-01 19:04:50.283297
Epoch:[ 240 11 ] loss: 0.3599962592124939 2022-07-01 19:04:50.711791
Epoch:[ 240 12 ] loss: 0.35958319902420044 2022-07-01 19:04:51.143623
Epoch:[ 240 13 ] loss: 0.3586112856864929 2022-07-01 19:04:51.579431
Epoch:[ 240 14 ] loss: 0.36003080010414124 2022-07-01 19:04:52.010011
Epoch:[ 240 15 ] loss: 0.3612583577632904 2022-07-01 19:04:52.440214
Epoch:[ 240 16 ] loss: 0.36007311940193176 2022-07-01 19:04:57.397506
Epoch:[ 240 17 ] loss: 0.3612155020236969 2022-07-01 19:04:57.900079
Epoch:[ 240 18 ] loss: 0.3615279793739319 2022-07-01 19:04:58.335597
Epoch:[ 240 19 ] loss: 0.3597993850708008 2022-07-01 19:04:58.768417
Training_Epoch:[ 240 ] Training_loss: 0.36032678931951523 2022-07-01 19:04:58.769072
learning rate:  5.902958103587065e-06
netparams have been saved once 240
val: 1 0.38916894793510437
val: 2 0.38503286242485046
val: 3 0.3947140574455261
val: 4 0.3972817361354828
val: 5 0.39085283875465393
val: 6 0.3915131092071533
val: 7 0.39204323291778564
val: 8 0.3849312663078308
val: 9 0.3846668004989624
val: 10 0.3891770839691162
val: 11 0.38674235343933105
val: 12 0.39844393730163574
val: 13 0.3886507451534271
val: 14 0.39510655403137207
val: 15 0.3936983346939087
val: 16 0.39329993724823
val: 17 0.38897815346717834
val: 18 0.3902343809604645
val: 19 0.3972993791103363
val: 20 0.39088886976242065
val_Epoch:[ 240 ] val_loss: 0.3911362290382385 2022-07-01 19:05:02.682379
start training 2022-07-01 19:05:02.788634
Epoch:[ 241 0 ] loss: 0.3594304025173187 2022-07-01 19:05:17.492117
Epoch:[ 241 1 ] loss: 0.36020171642303467 2022-07-01 19:05:17.922809
Epoch:[ 241 2 ] loss: 0.3600033223628998 2022-07-01 19:05:18.358186
Epoch:[ 241 3 ] loss: 0.3597635328769684 2022-07-01 19:05:18.787494
Epoch:[ 241 4 ] loss: 0.36050817370414734 2022-07-01 19:05:19.217512
Epoch:[ 241 5 ] loss: 0.36090895533561707 2022-07-01 19:05:19.646993
Epoch:[ 241 6 ] loss: 0.36249902844429016 2022-07-01 19:05:20.075738
Epoch:[ 241 7 ] loss: 0.3608497381210327 2022-07-01 19:05:20.505867
Epoch:[ 241 8 ] loss: 0.35907527804374695 2022-07-01 19:05:20.937408
Epoch:[ 241 9 ] loss: 0.3583696186542511 2022-07-01 19:05:21.366975
Epoch:[ 241 10 ] loss: 0.36027905344963074 2022-07-01 19:05:21.796256
Epoch:[ 241 11 ] loss: 0.36032629013061523 2022-07-01 19:05:22.225785
Epoch:[ 241 12 ] loss: 0.36012303829193115 2022-07-01 19:05:22.663212
Epoch:[ 241 13 ] loss: 0.3617892265319824 2022-07-01 19:05:23.098981
Epoch:[ 241 14 ] loss: 0.3598288297653198 2022-07-01 19:05:23.530235
Epoch:[ 241 15 ] loss: 0.35969674587249756 2022-07-01 19:05:23.962173
Epoch:[ 241 16 ] loss: 0.3611282706260681 2022-07-01 19:05:29.337403
Epoch:[ 241 17 ] loss: 0.3602136969566345 2022-07-01 19:05:29.763875
Epoch:[ 241 18 ] loss: 0.35945114493370056 2022-07-01 19:05:30.200098
Epoch:[ 241 19 ] loss: 0.3613013029098511 2022-07-01 19:05:30.633477
Training_Epoch:[ 241 ] Training_loss: 0.3602873682975769 2022-07-01 19:05:30.634161
learning rate:  4.722366482869652e-06
val: 1 0.3889000415802002
val: 2 0.39933764934539795
val: 3 0.3888564109802246
val: 4 0.39175963401794434
val: 5 0.3875529170036316
val: 6 0.38271448016166687
val: 7 0.3945756256580353
val: 8 0.393258661031723
val: 9 0.4010685980319977
val: 10 0.38811466097831726
val: 11 0.39007025957107544
val: 12 0.3906324803829193
val: 13 0.39049702882766724
val: 14 0.39210981130599976
val: 15 0.38495582342147827
val: 16 0.3879939317703247
val: 17 0.39145755767822266
val: 18 0.3912113308906555
val: 19 0.3927988111972809
val: 20 0.39463528990745544
val_Epoch:[ 241 ] val_loss: 0.3911250501871109 2022-07-01 19:05:34.611265
start training 2022-07-01 19:05:34.711207
Epoch:[ 242 0 ] loss: 0.359333336353302 2022-07-01 19:05:48.940651
Epoch:[ 242 1 ] loss: 0.360855370759964 2022-07-01 19:05:49.400553
Epoch:[ 242 2 ] loss: 0.361095666885376 2022-07-01 19:05:49.832611
Epoch:[ 242 3 ] loss: 0.35938772559165955 2022-07-01 19:05:50.248161
Epoch:[ 242 4 ] loss: 0.3606807291507721 2022-07-01 19:05:50.663824
Epoch:[ 242 5 ] loss: 0.36019065976142883 2022-07-01 19:05:51.080158
Epoch:[ 242 6 ] loss: 0.3596108555793762 2022-07-01 19:05:51.494085
Epoch:[ 242 7 ] loss: 0.35998374223709106 2022-07-01 19:05:51.919944
Epoch:[ 242 8 ] loss: 0.36013084650039673 2022-07-01 19:05:52.337403
Epoch:[ 242 9 ] loss: 0.360882043838501 2022-07-01 19:05:52.753633
Epoch:[ 242 10 ] loss: 0.36093810200691223 2022-07-01 19:05:53.161177
Epoch:[ 242 11 ] loss: 0.36169955134391785 2022-07-01 19:05:53.569774
Epoch:[ 242 12 ] loss: 0.3600432574748993 2022-07-01 19:05:53.992842
Epoch:[ 242 13 ] loss: 0.3602725565433502 2022-07-01 19:05:54.408231
Epoch:[ 242 14 ] loss: 0.35961800813674927 2022-07-01 19:05:54.837943
Epoch:[ 242 15 ] loss: 0.362714946269989 2022-07-01 19:05:55.253556
Epoch:[ 242 16 ] loss: 0.35939034819602966 2022-07-01 19:06:01.127690
Epoch:[ 242 17 ] loss: 0.359788179397583 2022-07-01 19:06:01.556533
Epoch:[ 242 18 ] loss: 0.36033543944358826 2022-07-01 19:06:01.997889
Epoch:[ 242 19 ] loss: 0.3593269884586334 2022-07-01 19:06:02.427793
Training_Epoch:[ 242 ] Training_loss: 0.36031391769647597 2022-07-01 19:06:02.428515
learning rate:  4.722366482869652e-06
netparams have been saved once 242
val: 1 0.38906311988830566
val: 2 0.39156365394592285
val: 3 0.39317116141319275
val: 4 0.39680010080337524
val: 5 0.391570121049881
val: 6 0.39113685488700867
val: 7 0.3914896845817566
val: 8 0.3895030617713928
val: 9 0.3854239881038666
val: 10 0.3863629400730133
val: 11 0.3861483335494995
val: 12 0.39569762349128723
val: 13 0.39365553855895996
val: 14 0.3872470259666443
val: 15 0.39701569080352783
val: 16 0.3911826014518738
val: 17 0.3996226191520691
val: 18 0.3916427195072174
val: 19 0.39080193638801575
val: 20 0.38214725255966187
val_Epoch:[ 242 ] val_loss: 0.3910623013973236 2022-07-01 19:06:06.418565
start training 2022-07-01 19:06:06.519526
Epoch:[ 243 0 ] loss: 0.36143386363983154 2022-07-01 19:06:21.432573
Epoch:[ 243 1 ] loss: 0.36113840341567993 2022-07-01 19:06:21.861828
Epoch:[ 243 2 ] loss: 0.36053580045700073 2022-07-01 19:06:22.292727
Epoch:[ 243 3 ] loss: 0.3593932092189789 2022-07-01 19:06:22.724074
Epoch:[ 243 4 ] loss: 0.3596777617931366 2022-07-01 19:06:23.154211
Epoch:[ 243 5 ] loss: 0.3592838943004608 2022-07-01 19:06:23.588046
Epoch:[ 243 6 ] loss: 0.3596041202545166 2022-07-01 19:06:24.017166
Epoch:[ 243 7 ] loss: 0.35979700088500977 2022-07-01 19:06:24.445456
Epoch:[ 243 8 ] loss: 0.36123356223106384 2022-07-01 19:06:24.874947
Epoch:[ 243 9 ] loss: 0.36121541261672974 2022-07-01 19:06:25.306438
Epoch:[ 243 10 ] loss: 0.3600127100944519 2022-07-01 19:06:25.737986
Epoch:[ 243 11 ] loss: 0.36012494564056396 2022-07-01 19:06:26.167539
Epoch:[ 243 12 ] loss: 0.35926687717437744 2022-07-01 19:06:26.601690
Epoch:[ 243 13 ] loss: 0.3601122498512268 2022-07-01 19:06:27.029711
Epoch:[ 243 14 ] loss: 0.36043381690979004 2022-07-01 19:06:27.459511
Epoch:[ 243 15 ] loss: 0.3600056767463684 2022-07-01 19:06:27.893354
Epoch:[ 243 16 ] loss: 0.3609473705291748 2022-07-01 19:06:33.288922
Epoch:[ 243 17 ] loss: 0.3598614037036896 2022-07-01 19:06:33.717324
Epoch:[ 243 18 ] loss: 0.3611293435096741 2022-07-01 19:06:34.153394
Epoch:[ 243 19 ] loss: 0.36065158247947693 2022-07-01 19:06:34.584810
Training_Epoch:[ 243 ] Training_loss: 0.36029295027256014 2022-07-01 19:06:34.585485
learning rate:  4.722366482869652e-06
val: 1 0.3939836323261261
val: 2 0.3964501619338989
val: 3 0.3848706781864166
val: 4 0.39912527799606323
val: 5 0.3978217840194702
val: 6 0.38497263193130493
val: 7 0.4021126329898834
val: 8 0.3903467655181885
val: 9 0.38159963488578796
val: 10 0.38531482219696045
val: 11 0.38951045274734497
val: 12 0.391876757144928
val: 13 0.3946283757686615
val: 14 0.39226123690605164
val: 15 0.3906373381614685
val: 16 0.3944284915924072
val: 17 0.3858509957790375
val: 18 0.38359320163726807
val: 19 0.3929353952407837
val: 20 0.39378613233566284
val_Epoch:[ 243 ] val_loss: 0.3913053199648857 2022-07-01 19:06:38.515128
start training 2022-07-01 19:06:38.618649
Epoch:[ 244 0 ] loss: 0.35934752225875854 2022-07-01 19:06:53.332383
Epoch:[ 244 1 ] loss: 0.35969990491867065 2022-07-01 19:06:53.763317
Epoch:[ 244 2 ] loss: 0.36020973324775696 2022-07-01 19:06:54.194641
Epoch:[ 244 3 ] loss: 0.3599642515182495 2022-07-01 19:06:54.626423
Epoch:[ 244 4 ] loss: 0.36038312315940857 2022-07-01 19:06:55.058362
Epoch:[ 244 5 ] loss: 0.3593115508556366 2022-07-01 19:06:55.490886
Epoch:[ 244 6 ] loss: 0.360661119222641 2022-07-01 19:06:55.920162
Epoch:[ 244 7 ] loss: 0.3606936037540436 2022-07-01 19:06:56.349902
Epoch:[ 244 8 ] loss: 0.36145275831222534 2022-07-01 19:06:56.779958
Epoch:[ 244 9 ] loss: 0.35978421568870544 2022-07-01 19:06:57.208317
Epoch:[ 244 10 ] loss: 0.3591877222061157 2022-07-01 19:06:57.644352
Epoch:[ 244 11 ] loss: 0.3611351549625397 2022-07-01 19:06:58.081251
Epoch:[ 244 12 ] loss: 0.3603692650794983 2022-07-01 19:06:58.517223
Epoch:[ 244 13 ] loss: 0.3617578148841858 2022-07-01 19:06:58.946679
Epoch:[ 244 14 ] loss: 0.3595179319381714 2022-07-01 19:06:59.376399
Epoch:[ 244 15 ] loss: 0.36043065786361694 2022-07-01 19:06:59.807632
Epoch:[ 244 16 ] loss: 0.36063411831855774 2022-07-01 19:07:04.829028
Epoch:[ 244 17 ] loss: 0.3610524833202362 2022-07-01 19:07:05.262710
Epoch:[ 244 18 ] loss: 0.3601774275302887 2022-07-01 19:07:05.701830
Epoch:[ 244 19 ] loss: 0.3588588237762451 2022-07-01 19:07:06.131008
Training_Epoch:[ 244 ] Training_loss: 0.3602314591407776 2022-07-01 19:07:06.131656
learning rate:  4.722366482869652e-06
netparams have been saved once 244
val: 1 0.39139336347579956
val: 2 0.38943594694137573
val: 3 0.39225319027900696
val: 4 0.3992951214313507
val: 5 0.39611196517944336
val: 6 0.3917713761329651
val: 7 0.397752583026886
val: 8 0.3863959014415741
val: 9 0.3909671902656555
val: 10 0.3867000639438629
val: 11 0.3908338248729706
val: 12 0.38884252309799194
val: 13 0.3797859251499176
val: 14 0.3890592157840729
val: 15 0.39877939224243164
val: 16 0.39350712299346924
val: 17 0.3875812292098999
val: 18 0.38365545868873596
val: 19 0.38851138949394226
val: 20 0.3952440321445465
val_Epoch:[ 244 ] val_loss: 0.39089384078979494 2022-07-01 19:07:10.072830
start training 2022-07-01 19:07:10.176410
Epoch:[ 245 0 ] loss: 0.36014801263809204 2022-07-01 19:07:24.732119
Epoch:[ 245 1 ] loss: 0.3605595529079437 2022-07-01 19:07:25.166977
Epoch:[ 245 2 ] loss: 0.36004871129989624 2022-07-01 19:07:25.599225
Epoch:[ 245 3 ] loss: 0.3611026108264923 2022-07-01 19:07:26.026317
Epoch:[ 245 4 ] loss: 0.3605443835258484 2022-07-01 19:07:26.457891
Epoch:[ 245 5 ] loss: 0.35998284816741943 2022-07-01 19:07:26.888501
Epoch:[ 245 6 ] loss: 0.3598684072494507 2022-07-01 19:07:27.319904
Epoch:[ 245 7 ] loss: 0.36056089401245117 2022-07-01 19:07:27.749294
Epoch:[ 245 8 ] loss: 0.3597167730331421 2022-07-01 19:07:28.179268
Epoch:[ 245 9 ] loss: 0.36087819933891296 2022-07-01 19:07:28.606560
Epoch:[ 245 10 ] loss: 0.3603096604347229 2022-07-01 19:07:29.034658
Epoch:[ 245 11 ] loss: 0.36125820875167847 2022-07-01 19:07:29.471194
Epoch:[ 245 12 ] loss: 0.35933515429496765 2022-07-01 19:07:29.903122
Epoch:[ 245 13 ] loss: 0.3595450520515442 2022-07-01 19:07:30.337848
Epoch:[ 245 14 ] loss: 0.3611425459384918 2022-07-01 19:07:30.768011
Epoch:[ 245 15 ] loss: 0.35991543531417847 2022-07-01 19:07:31.197141
Epoch:[ 245 16 ] loss: 0.35965704917907715 2022-07-01 19:07:36.600559
Epoch:[ 245 17 ] loss: 0.36024853587150574 2022-07-01 19:07:37.035259
Epoch:[ 245 18 ] loss: 0.36043134331703186 2022-07-01 19:07:37.473284
Epoch:[ 245 19 ] loss: 0.36071252822875977 2022-07-01 19:07:37.903244
Training_Epoch:[ 245 ] Training_loss: 0.36029829531908036 2022-07-01 19:07:37.903908
learning rate:  4.722366482869652e-06
val: 1 0.3880757689476013
val: 2 0.3950931429862976
val: 3 0.3948361873626709
val: 4 0.3826760947704315
val: 5 0.39164862036705017
val: 6 0.3859018087387085
val: 7 0.3999095559120178
val: 8 0.38691797852516174
val: 9 0.3915393054485321
val: 10 0.39309054613113403
val: 11 0.3913644254207611
val: 12 0.38681891560554504
val: 13 0.39388734102249146
val: 14 0.3940504491329193
val: 15 0.3950898051261902
val: 16 0.39103078842163086
val: 17 0.38792017102241516
val: 18 0.3977951109409332
val: 19 0.3861003816127777
val: 20 0.38845404982566833
val_Epoch:[ 245 ] val_loss: 0.3911100223660469 2022-07-01 19:07:41.847787
start training 2022-07-01 19:07:41.950688
Epoch:[ 246 0 ] loss: 0.35949474573135376 2022-07-01 19:07:56.017525
Epoch:[ 246 1 ] loss: 0.3603091835975647 2022-07-01 19:07:56.921497
Epoch:[ 246 2 ] loss: 0.3606667220592499 2022-07-01 19:07:57.352165
Epoch:[ 246 3 ] loss: 0.360230028629303 2022-07-01 19:07:57.781645
Epoch:[ 246 4 ] loss: 0.3592720031738281 2022-07-01 19:07:58.214568
Epoch:[ 246 5 ] loss: 0.36105263233184814 2022-07-01 19:07:58.644519
Epoch:[ 246 6 ] loss: 0.36094358563423157 2022-07-01 19:07:59.076462
Epoch:[ 246 7 ] loss: 0.3616608679294586 2022-07-01 19:07:59.506559
Epoch:[ 246 8 ] loss: 0.360090434551239 2022-07-01 19:07:59.921416
Epoch:[ 246 9 ] loss: 0.35954388976097107 2022-07-01 19:08:00.335213
Epoch:[ 246 10 ] loss: 0.36115145683288574 2022-07-01 19:08:00.750819
Epoch:[ 246 11 ] loss: 0.36019739508628845 2022-07-01 19:08:01.160306
Epoch:[ 246 12 ] loss: 0.3597675859928131 2022-07-01 19:08:01.577182
Epoch:[ 246 13 ] loss: 0.3608531951904297 2022-07-01 19:08:01.994096
Epoch:[ 246 14 ] loss: 0.3602433204650879 2022-07-01 19:08:02.404777
Epoch:[ 246 15 ] loss: 0.3598700165748596 2022-07-01 19:08:02.819456
Epoch:[ 246 16 ] loss: 0.36057668924331665 2022-07-01 19:08:07.789253
Epoch:[ 246 17 ] loss: 0.3595980107784271 2022-07-01 19:08:08.255803
Epoch:[ 246 18 ] loss: 0.3594268560409546 2022-07-01 19:08:08.693003
Epoch:[ 246 19 ] loss: 0.36022213101387024 2022-07-01 19:08:09.129338
Training_Epoch:[ 246 ] Training_loss: 0.36025853753089904 2022-07-01 19:08:09.130044
learning rate:  4.722366482869652e-06
netparams have been saved once 246
val: 1 0.39196932315826416
val: 2 0.3873947858810425
val: 3 0.39528727531433105
val: 4 0.38943034410476685
val: 5 0.39157551527023315
val: 6 0.39421576261520386
val: 7 0.389054536819458
val: 8 0.3868738114833832
val: 9 0.39944958686828613
val: 10 0.3916553854942322
val: 11 0.38415223360061646
val: 12 0.39324694871902466
val: 13 0.393658846616745
val: 14 0.3902978301048279
val: 15 0.39566168189048767
val: 16 0.38902804255485535
val: 17 0.38865548372268677
val: 18 0.3927516043186188
val: 19 0.38888874650001526
val: 20 0.3899424374103546
val_Epoch:[ 246 ] val_loss: 0.3911595091223717 2022-07-01 19:08:13.088424
start training 2022-07-01 19:08:13.188641
Epoch:[ 247 0 ] loss: 0.36076438426971436 2022-07-01 19:08:27.541386
Epoch:[ 247 1 ] loss: 0.3601076602935791 2022-07-01 19:08:28.141833
Epoch:[ 247 2 ] loss: 0.3593810498714447 2022-07-01 19:08:28.571671
Epoch:[ 247 3 ] loss: 0.3615502715110779 2022-07-01 19:08:29.001480
Epoch:[ 247 4 ] loss: 0.36018118262290955 2022-07-01 19:08:29.430999
Epoch:[ 247 5 ] loss: 0.36069536209106445 2022-07-01 19:08:29.860497
Epoch:[ 247 6 ] loss: 0.36012446880340576 2022-07-01 19:08:30.291201
Epoch:[ 247 7 ] loss: 0.3613511025905609 2022-07-01 19:08:30.723130
Epoch:[ 247 8 ] loss: 0.3607594966888428 2022-07-01 19:08:31.153194
Epoch:[ 247 9 ] loss: 0.3607412278652191 2022-07-01 19:08:31.587795
Epoch:[ 247 10 ] loss: 0.3608338236808777 2022-07-01 19:08:32.016744
Epoch:[ 247 11 ] loss: 0.36000075936317444 2022-07-01 19:08:32.448137
Epoch:[ 247 12 ] loss: 0.359104186296463 2022-07-01 19:08:32.877790
Epoch:[ 247 13 ] loss: 0.35969868302345276 2022-07-01 19:08:33.308577
Epoch:[ 247 14 ] loss: 0.3598922789096832 2022-07-01 19:08:33.745863
Epoch:[ 247 15 ] loss: 0.3598494529724121 2022-07-01 19:08:34.183344
Epoch:[ 247 16 ] loss: 0.35985758900642395 2022-07-01 19:08:39.197611
Epoch:[ 247 17 ] loss: 0.35982248187065125 2022-07-01 19:08:39.628433
Epoch:[ 247 18 ] loss: 0.3611117899417877 2022-07-01 19:08:40.064042
Epoch:[ 247 19 ] loss: 0.359417587518692 2022-07-01 19:08:40.495959
Training_Epoch:[ 247 ] Training_loss: 0.36026224195957185 2022-07-01 19:08:40.496645
learning rate:  4.722366482869652e-06
val: 1 0.3900281488895416
val: 2 0.3927558958530426
val: 3 0.39501237869262695
val: 4 0.39758726954460144
val: 5 0.3851810395717621
val: 6 0.39611151814460754
val: 7 0.38580790162086487
val: 8 0.3957233726978302
val: 9 0.3833450973033905
val: 10 0.39309272170066833
val: 11 0.4005643427371979
val: 12 0.3829927146434784
val: 13 0.3890719711780548
val: 14 0.3861808180809021
val: 15 0.39271295070648193
val: 16 0.3929966986179352
val: 17 0.386461079120636
val: 18 0.39640626311302185
val: 19 0.3896338641643524
val: 20 0.3926122188568115
val_Epoch:[ 247 ] val_loss: 0.3912139132618904 2022-07-01 19:08:44.326971
start training 2022-07-01 19:08:44.426811
Epoch:[ 248 0 ] loss: 0.36035099625587463 2022-07-01 19:08:58.584623
Epoch:[ 248 1 ] loss: 0.3602440655231476 2022-07-01 19:08:59.284532
Epoch:[ 248 2 ] loss: 0.3597251772880554 2022-07-01 19:08:59.714385
Epoch:[ 248 3 ] loss: 0.3595956265926361 2022-07-01 19:09:00.142392
Epoch:[ 248 4 ] loss: 0.36104893684387207 2022-07-01 19:09:00.571188
Epoch:[ 248 5 ] loss: 0.3595757484436035 2022-07-01 19:09:00.999676
Epoch:[ 248 6 ] loss: 0.36006343364715576 2022-07-01 19:09:01.429140
Epoch:[ 248 7 ] loss: 0.35936522483825684 2022-07-01 19:09:01.858674
Epoch:[ 248 8 ] loss: 0.3604365289211273 2022-07-01 19:09:02.289871
Epoch:[ 248 9 ] loss: 0.36018848419189453 2022-07-01 19:09:02.718572
Epoch:[ 248 10 ] loss: 0.3601652979850769 2022-07-01 19:09:03.155827
Epoch:[ 248 11 ] loss: 0.36075177788734436 2022-07-01 19:09:03.590604
Epoch:[ 248 12 ] loss: 0.36023274064064026 2022-07-01 19:09:04.021329
Epoch:[ 248 13 ] loss: 0.360526978969574 2022-07-01 19:09:04.454252
Epoch:[ 248 14 ] loss: 0.35998958349227905 2022-07-01 19:09:04.884516
Epoch:[ 248 15 ] loss: 0.360379159450531 2022-07-01 19:09:05.315752
Epoch:[ 248 16 ] loss: 0.3597695231437683 2022-07-01 19:09:10.150737
Epoch:[ 248 17 ] loss: 0.35948383808135986 2022-07-01 19:09:11.142334
Epoch:[ 248 18 ] loss: 0.36326056718826294 2022-07-01 19:09:11.577262
Epoch:[ 248 19 ] loss: 0.3589664399623871 2022-07-01 19:09:12.010832
Training_Epoch:[ 248 ] Training_loss: 0.36020600646734235 2022-07-01 19:09:12.011532
learning rate:  4.722366482869652e-06
netparams have been saved once 248
val: 1 0.39079684019088745
val: 2 0.3913270831108093
val: 3 0.39092135429382324
val: 4 0.3882923126220703
val: 5 0.38885554671287537
val: 6 0.38699793815612793
val: 7 0.38938021659851074
val: 8 0.3903694450855255
val: 9 0.40378326177597046
val: 10 0.3988224267959595
val: 11 0.39160794019699097
val: 12 0.39729657769203186
val: 13 0.38294661045074463
val: 14 0.3888513743877411
val: 15 0.39910992980003357
val: 16 0.3857862651348114
val: 17 0.3881593346595764
val: 18 0.39394140243530273
val: 19 0.3865198493003845
val: 20 0.3940555453300476
val_Epoch:[ 248 ] val_loss: 0.39139106273651125 2022-07-01 19:09:15.971311
start training 2022-07-01 19:09:16.072804
Epoch:[ 249 0 ] loss: 0.3601504862308502 2022-07-01 19:09:30.137654
Epoch:[ 249 1 ] loss: 0.3611293137073517 2022-07-01 19:09:30.574490
Epoch:[ 249 2 ] loss: 0.36137574911117554 2022-07-01 19:09:31.004758
Epoch:[ 249 3 ] loss: 0.35988789796829224 2022-07-01 19:09:31.435167
Epoch:[ 249 4 ] loss: 0.3594081699848175 2022-07-01 19:09:31.868943
Epoch:[ 249 5 ] loss: 0.36035609245300293 2022-07-01 19:09:32.298845
Epoch:[ 249 6 ] loss: 0.36073940992355347 2022-07-01 19:09:32.728853
Epoch:[ 249 7 ] loss: 0.3598316013813019 2022-07-01 19:09:33.157668
Epoch:[ 249 8 ] loss: 0.3589840233325958 2022-07-01 19:09:33.588988
Epoch:[ 249 9 ] loss: 0.3607539236545563 2022-07-01 19:09:34.021036
Epoch:[ 249 10 ] loss: 0.36059150099754333 2022-07-01 19:09:34.450828
Epoch:[ 249 11 ] loss: 0.360061913728714 2022-07-01 19:09:34.880375
Epoch:[ 249 12 ] loss: 0.35914260149002075 2022-07-01 19:09:35.309780
Epoch:[ 249 13 ] loss: 0.36152032017707825 2022-07-01 19:09:35.744654
Epoch:[ 249 14 ] loss: 0.3591533303260803 2022-07-01 19:09:36.180290
Epoch:[ 249 15 ] loss: 0.35972967743873596 2022-07-01 19:09:36.610951
Epoch:[ 249 16 ] loss: 0.3600611686706543 2022-07-01 19:09:41.755101
Epoch:[ 249 17 ] loss: 0.36032626032829285 2022-07-01 19:09:42.203569
Epoch:[ 249 18 ] loss: 0.3621661067008972 2022-07-01 19:09:42.639578
Epoch:[ 249 19 ] loss: 0.35954970121383667 2022-07-01 19:09:43.068824
Training_Epoch:[ 249 ] Training_loss: 0.36024596244096757 2022-07-01 19:09:43.069526
learning rate:  4.722366482869652e-06
val: 1 0.3859042823314667
val: 2 0.39918047189712524
val: 3 0.39720067381858826
val: 4 0.38841649889945984
val: 5 0.3936276137828827
val: 6 0.38894689083099365
val: 7 0.3945101201534271
val: 8 0.38732942938804626
val: 9 0.39545977115631104
val: 10 0.38284870982170105
val: 11 0.3957902789115906
val: 12 0.39044564962387085
val: 13 0.3896481394767761
val: 14 0.39158210158348083
val: 15 0.38991060853004456
val: 16 0.3888651728630066
val: 17 0.3916853368282318
val: 18 0.39348456263542175
val: 19 0.39240536093711853
val: 20 0.3919515609741211
val_Epoch:[ 249 ] val_loss: 0.3914596617221832 2022-07-01 19:09:46.931035
start training 2022-07-01 19:09:47.033202
Epoch:[ 250 0 ] loss: 0.36023321747779846 2022-07-01 19:10:01.159833
Epoch:[ 250 1 ] loss: 0.36036524176597595 2022-07-01 19:10:01.701196
Epoch:[ 250 2 ] loss: 0.3618607819080353 2022-07-01 19:10:02.133528
Epoch:[ 250 3 ] loss: 0.3593466877937317 2022-07-01 19:10:02.565057
Epoch:[ 250 4 ] loss: 0.35939255356788635 2022-07-01 19:10:02.984273
Epoch:[ 250 5 ] loss: 0.35972878336906433 2022-07-01 19:10:03.418838
Epoch:[ 250 6 ] loss: 0.3607935607433319 2022-07-01 19:10:03.853519
Epoch:[ 250 7 ] loss: 0.3603551983833313 2022-07-01 19:10:04.282846
Epoch:[ 250 8 ] loss: 0.36097344756126404 2022-07-01 19:10:04.711526
Epoch:[ 250 9 ] loss: 0.35983917117118835 2022-07-01 19:10:05.142079
Epoch:[ 250 10 ] loss: 0.3616198003292084 2022-07-01 19:10:05.574427
Epoch:[ 250 11 ] loss: 0.36071422696113586 2022-07-01 19:10:06.012102
Epoch:[ 250 12 ] loss: 0.3606411814689636 2022-07-01 19:10:06.447466
Epoch:[ 250 13 ] loss: 0.3596739172935486 2022-07-01 19:10:06.876879
Epoch:[ 250 14 ] loss: 0.3599569797515869 2022-07-01 19:10:07.308793
Epoch:[ 250 15 ] loss: 0.3595687747001648 2022-07-01 19:10:07.737525
Epoch:[ 250 16 ] loss: 0.3607091009616852 2022-07-01 19:10:13.370172
Epoch:[ 250 17 ] loss: 0.35966232419013977 2022-07-01 19:10:13.800601
Epoch:[ 250 18 ] loss: 0.35984110832214355 2022-07-01 19:10:14.240217
Epoch:[ 250 19 ] loss: 0.36010855436325073 2022-07-01 19:10:14.672586
Training_Epoch:[ 250 ] Training_loss: 0.36026923060417176 2022-07-01 19:10:14.673237
learning rate:  4.722366482869652e-06
netparams have been saved once 250
val: 1 0.393452525138855
val: 2 0.3798099458217621
val: 3 0.39766526222229004
val: 4 0.3921995162963867
val: 5 0.3888762593269348
val: 6 0.3903868794441223
val: 7 0.3936970829963684
val: 8 0.38972318172454834
val: 9 0.3944619596004486
val: 10 0.3892070949077606
val: 11 0.387638121843338
val: 12 0.39570921659469604
val: 13 0.3851504921913147
val: 14 0.3949883282184601
val: 15 0.39602896571159363
val: 16 0.38143378496170044
val: 17 0.3892848789691925
val: 18 0.39914649724960327
val: 19 0.39211776852607727
val: 20 0.3891605734825134
val_Epoch:[ 250 ] val_loss: 0.3910069167613983 2022-07-01 19:10:18.548407
