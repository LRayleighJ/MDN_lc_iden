GPU: True
80
start training 2022-08-11 23:54:55.695611
Epoch:[ 1 0 ] loss: 0.7052469849586487 2022-08-11 23:55:23.626322
Epoch:[ 1 1 ] loss: 0.6967548131942749 2022-08-11 23:55:24.159357
Epoch:[ 1 2 ] loss: 0.6915616393089294 2022-08-11 23:55:24.586923
Epoch:[ 1 3 ] loss: 0.671261191368103 2022-08-11 23:55:25.018909
Epoch:[ 1 4 ] loss: 0.6728567481040955 2022-08-11 23:55:25.445476
Epoch:[ 1 5 ] loss: 0.6554999351501465 2022-08-11 23:55:25.867767
Epoch:[ 1 6 ] loss: 0.6446658968925476 2022-08-11 23:55:26.289261
Epoch:[ 1 7 ] loss: 0.6357438564300537 2022-08-11 23:55:26.714981
Epoch:[ 1 8 ] loss: 0.6291253566741943 2022-08-11 23:55:27.142821
Epoch:[ 1 9 ] loss: 0.6213874220848083 2022-08-11 23:55:27.560664
Epoch:[ 1 10 ] loss: 0.6155446767807007 2022-08-11 23:55:27.989064
Epoch:[ 1 11 ] loss: 0.6091755628585815 2022-08-11 23:55:28.418040
Epoch:[ 1 12 ] loss: 0.6021878123283386 2022-08-11 23:55:28.846935
Epoch:[ 1 13 ] loss: 0.5965909361839294 2022-08-11 23:55:29.273392
Epoch:[ 1 14 ] loss: 0.5930313467979431 2022-08-11 23:55:29.702848
Epoch:[ 1 15 ] loss: 0.5864113569259644 2022-08-11 23:55:30.129386
Epoch:[ 1 16 ] loss: 0.5823001265525818 2022-08-11 23:55:35.990121
Epoch:[ 1 17 ] loss: 0.5776517987251282 2022-08-11 23:55:36.415967
Epoch:[ 1 18 ] loss: 0.5748172998428345 2022-08-11 23:55:36.842680
Epoch:[ 1 19 ] loss: 0.5692646503448486 2022-08-11 23:55:37.274961
Training_Epoch:[ 1 ] Training_loss: 0.6265539705753327 2022-08-11 23:55:37.275622
learning rate:  0.006
val: 1 0.5700032114982605
val: 2 0.570830762386322
val: 3 0.5692026615142822
val: 4 0.5676100850105286
val: 5 0.5773269534111023
val: 6 0.5763946175575256
val: 7 0.5730729699134827
val: 8 0.5783439874649048
val: 9 0.5712594389915466
val: 10 0.5696431398391724
val: 11 0.5654197335243225
val: 12 0.5710133910179138
val: 13 0.5740898251533508
val: 14 0.5671955943107605
val: 15 0.5727725028991699
val: 16 0.5682066679000854
val: 17 0.5771097540855408
val: 18 0.5661692023277283
val: 19 0.5666517019271851
val: 20 0.575610339641571
val_Epoch:[ 1 ] val_loss: 0.5713963270187378 2022-08-11 23:55:40.728137
start training 2022-08-11 23:55:40.834366
Epoch:[ 2 0 ] loss: 0.5671202540397644 2022-08-11 23:55:55.967427
Epoch:[ 2 1 ] loss: 0.5645519495010376 2022-08-11 23:55:56.392181
Epoch:[ 2 2 ] loss: 0.5626270174980164 2022-08-11 23:55:56.817945
Epoch:[ 2 3 ] loss: 0.5577024221420288 2022-08-11 23:55:57.244530
Epoch:[ 2 4 ] loss: 0.5538957118988037 2022-08-11 23:55:57.674413
Epoch:[ 2 5 ] loss: 0.5523734092712402 2022-08-11 23:55:58.095457
Epoch:[ 2 6 ] loss: 0.5494772791862488 2022-08-11 23:55:58.516203
Epoch:[ 2 7 ] loss: 0.5481677055358887 2022-08-11 23:55:58.938455
Epoch:[ 2 8 ] loss: 0.5494652986526489 2022-08-11 23:55:59.370062
Epoch:[ 2 9 ] loss: 0.5449919700622559 2022-08-11 23:55:59.794496
Epoch:[ 2 10 ] loss: 0.5454736351966858 2022-08-11 23:56:00.216217
Epoch:[ 2 11 ] loss: 0.5424368381500244 2022-08-11 23:56:00.639720
Epoch:[ 2 12 ] loss: 0.5415167808532715 2022-08-11 23:56:01.065790
Epoch:[ 2 13 ] loss: 0.5415339469909668 2022-08-11 23:56:01.497313
Epoch:[ 2 14 ] loss: 0.5406979918479919 2022-08-11 23:56:01.920810
Epoch:[ 2 15 ] loss: 0.5393758416175842 2022-08-11 23:56:02.351238
Epoch:[ 2 16 ] loss: 0.5403052568435669 2022-08-11 23:56:07.320717
Epoch:[ 2 17 ] loss: 0.5360288619995117 2022-08-11 23:56:07.746248
Epoch:[ 2 18 ] loss: 0.5340131521224976 2022-08-11 23:56:08.173558
Epoch:[ 2 19 ] loss: 0.5344445705413818 2022-08-11 23:56:08.599774
Training_Epoch:[ 2 ] Training_loss: 0.5473099946975708 2022-08-11 23:56:08.600467
learning rate:  0.006
val: 1 0.7390391826629639
val: 2 0.7422582507133484
val: 3 0.7420915961265564
val: 4 0.732200026512146
val: 5 0.7407860159873962
val: 6 0.7409886121749878
val: 7 0.735880434513092
val: 8 0.7336916327476501
val: 9 0.7396541833877563
val: 10 0.7448633909225464
val: 11 0.738930344581604
val: 12 0.7420477867126465
val: 13 0.7489149570465088
val: 14 0.7358567118644714
val: 15 0.7507336735725403
val: 16 0.7378746867179871
val: 17 0.7421597242355347
val: 18 0.738752543926239
val: 19 0.7364854216575623
val: 20 0.7363753318786621
val_Epoch:[ 2 ] val_loss: 0.73997922539711 2022-08-11 23:56:12.091116
start training 2022-08-11 23:56:12.195306
Epoch:[ 3 0 ] loss: 0.5303651690483093 2022-08-11 23:56:26.232751
Epoch:[ 3 1 ] loss: 0.5307939052581787 2022-08-11 23:56:26.684718
Epoch:[ 3 2 ] loss: 0.5294758081436157 2022-08-11 23:56:27.123157
Epoch:[ 3 3 ] loss: 0.5303237438201904 2022-08-11 23:56:27.551355
Epoch:[ 3 4 ] loss: 0.5328882336616516 2022-08-11 23:56:27.984993
Epoch:[ 3 5 ] loss: 0.527599036693573 2022-08-11 23:56:28.403781
Epoch:[ 3 6 ] loss: 0.5270445942878723 2022-08-11 23:56:28.819499
Epoch:[ 3 7 ] loss: 0.5259093642234802 2022-08-11 23:56:29.251301
Epoch:[ 3 8 ] loss: 0.5228819251060486 2022-08-11 23:56:29.683152
Epoch:[ 3 9 ] loss: 0.5206321477890015 2022-08-11 23:56:30.107819
Epoch:[ 3 10 ] loss: 0.5208562016487122 2022-08-11 23:56:30.535082
Epoch:[ 3 11 ] loss: 0.5194746255874634 2022-08-11 23:56:30.958707
Epoch:[ 3 12 ] loss: 0.5186808705329895 2022-08-11 23:56:31.381430
Epoch:[ 3 13 ] loss: 0.5145345330238342 2022-08-11 23:56:31.804255
Epoch:[ 3 14 ] loss: 0.5188044905662537 2022-08-11 23:56:32.232187
Epoch:[ 3 15 ] loss: 0.5182872414588928 2022-08-11 23:56:32.663617
Epoch:[ 3 16 ] loss: 0.5163977146148682 2022-08-11 23:56:38.080299
Epoch:[ 3 17 ] loss: 0.5149564146995544 2022-08-11 23:56:38.507258
Epoch:[ 3 18 ] loss: 0.5142117142677307 2022-08-11 23:56:38.932248
Epoch:[ 3 19 ] loss: 0.5110051035881042 2022-08-11 23:56:39.356942
Training_Epoch:[ 3 ] Training_loss: 0.5222561419010162 2022-08-11 23:56:39.357652
learning rate:  0.006
val: 1 0.5376988053321838
val: 2 0.5266392230987549
val: 3 0.5284900665283203
val: 4 0.5341706275939941
val: 5 0.518313467502594
val: 6 0.5408836603164673
val: 7 0.5333094000816345
val: 8 0.5364663600921631
val: 9 0.5289441347122192
val: 10 0.5370514988899231
val: 11 0.547889769077301
val: 12 0.5325532555580139
val: 13 0.5505696535110474
val: 14 0.5173459053039551
val: 15 0.5410990715026855
val: 16 0.5488326549530029
val: 17 0.539643406867981
val: 18 0.5406656265258789
val: 19 0.5327721238136292
val: 20 0.5226247310638428
val_Epoch:[ 3 ] val_loss: 0.5347981721162796 2022-08-11 23:56:42.824501
start training 2022-08-11 23:56:42.931157
Epoch:[ 4 0 ] loss: 0.5114484429359436 2022-08-11 23:56:57.159881
Epoch:[ 4 1 ] loss: 0.5141394734382629 2022-08-11 23:56:57.615653
Epoch:[ 4 2 ] loss: 0.5104141235351562 2022-08-11 23:56:58.046691
Epoch:[ 4 3 ] loss: 0.5122454166412354 2022-08-11 23:56:58.471809
Epoch:[ 4 4 ] loss: 0.5097267627716064 2022-08-11 23:56:58.904448
Epoch:[ 4 5 ] loss: 0.5093145370483398 2022-08-11 23:56:59.322489
Epoch:[ 4 6 ] loss: 0.5073729753494263 2022-08-11 23:56:59.740809
Epoch:[ 4 7 ] loss: 0.5082658529281616 2022-08-11 23:57:00.169533
Epoch:[ 4 8 ] loss: 0.5059337615966797 2022-08-11 23:57:00.599627
Epoch:[ 4 9 ] loss: 0.50462806224823 2022-08-11 23:57:01.022290
Epoch:[ 4 10 ] loss: 0.502708375453949 2022-08-11 23:57:01.444910
Epoch:[ 4 11 ] loss: 0.506400465965271 2022-08-11 23:57:01.872340
Epoch:[ 4 12 ] loss: 0.5051465034484863 2022-08-11 23:57:02.302474
Epoch:[ 4 13 ] loss: 0.5018346309661865 2022-08-11 23:57:02.724551
Epoch:[ 4 14 ] loss: 0.5011214017868042 2022-08-11 23:57:03.147269
Epoch:[ 4 15 ] loss: 0.501595675945282 2022-08-11 23:57:03.573166
Epoch:[ 4 16 ] loss: 0.5039961934089661 2022-08-11 23:57:09.109940
Epoch:[ 4 17 ] loss: 0.5010920763015747 2022-08-11 23:57:09.538647
Epoch:[ 4 18 ] loss: 0.5029105544090271 2022-08-11 23:57:09.973670
Epoch:[ 4 19 ] loss: 0.501891016960144 2022-08-11 23:57:10.390939
Training_Epoch:[ 4 ] Training_loss: 0.5061093151569367 2022-08-11 23:57:10.391634
learning rate:  0.006
