Traceback (most recent call last):
  File "/home/zerui603/MDN_lc_iden/unet/unet_kmt_500.py", line 198, in <module>
    training(paramsid=0)
  File "/home/zerui603/MDN_lc_iden/unet/unet_kmt_500.py", line 127, in training
    outputs = network(inputs)
  File "/home/zerui603/.conda/envs/PytorchCd11/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zerui603/.conda/envs/PytorchCd11/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/zerui603/.conda/envs/PytorchCd11/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/zerui603/.conda/envs/PytorchCd11/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/zerui603/.conda/envs/PytorchCd11/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/zerui603/.conda/envs/PytorchCd11/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/zerui603/.conda/envs/PytorchCd11/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zerui603/MDN_lc_iden/unet/netmodule/unetforkmt_500.py", line 233, in forward
    concat1 = torch.cat([convt1,conv4],dim=1)
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 62 for tensor number 1 in the list.

