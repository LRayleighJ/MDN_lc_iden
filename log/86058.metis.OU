GPU: True
80
start training 2022-05-29 16:20:14.809065
Epoch:[ 1 0 ] loss: 0.4968389570713043 2022-05-29 16:20:46.992708
Epoch:[ 1 1 ] loss: 0.5158776044845581 2022-05-29 16:20:47.824901
Epoch:[ 1 2 ] loss: 0.4985385239124298 2022-05-29 16:20:48.602686
Epoch:[ 1 3 ] loss: 0.49838966131210327 2022-05-29 16:20:49.394189
Epoch:[ 1 4 ] loss: 0.5016728639602661 2022-05-29 16:20:50.173339
Epoch:[ 1 5 ] loss: 0.4925348162651062 2022-05-29 16:20:50.948875
Epoch:[ 1 6 ] loss: 0.4904596209526062 2022-05-29 16:20:51.727537
Epoch:[ 1 7 ] loss: 0.49185407161712646 2022-05-29 16:20:52.515509
Epoch:[ 1 8 ] loss: 0.494994193315506 2022-05-29 16:20:53.293513
Epoch:[ 1 9 ] loss: 0.4902660846710205 2022-05-29 16:20:54.080022
Epoch:[ 1 10 ] loss: 0.4831443727016449 2022-05-29 16:20:54.855425
Epoch:[ 1 11 ] loss: 0.48865413665771484 2022-05-29 16:20:55.630491
Epoch:[ 1 12 ] loss: 0.48105236887931824 2022-05-29 16:20:56.408030
Epoch:[ 1 13 ] loss: 0.4853490889072418 2022-05-29 16:20:57.187033
Epoch:[ 1 14 ] loss: 0.4800231158733368 2022-05-29 16:20:57.961485
Epoch:[ 1 15 ] loss: 0.47754228115081787 2022-05-29 16:20:58.737824
Epoch:[ 1 16 ] loss: 0.47951626777648926 2022-05-29 16:20:59.523366
Epoch:[ 1 17 ] loss: 0.4820998013019562 2022-05-29 16:21:00.311367
Epoch:[ 1 18 ] loss: 0.48071587085723877 2022-05-29 16:21:01.098014
Epoch:[ 1 19 ] loss: 0.4786522388458252 2022-05-29 16:21:01.885494
Training_Epoch:[ 1 ] Training_loss: 0.4894087970256805 2022-05-29 16:21:01.886111
learning rate:  0.0004
val: 1 0.5386351943016052
val: 2 0.5149894952774048
val: 3 0.5313884615898132
val: 4 0.5136610865592957
val: 5 0.49924176931381226
val: 6 0.5227594375610352
val: 7 0.5064411759376526
val: 8 0.49672695994377136
val: 9 0.5252689719200134
val: 10 0.5389328598976135
val: 11 0.5510260462760925
val: 12 0.5164299607276917
val: 13 0.5284889936447144
val: 14 0.5204859375953674
val: 15 0.5275676250457764
val: 16 0.5009458065032959
val: 17 0.5194380879402161
val: 18 0.5142159461975098
val: 19 0.5165459513664246
val: 20 0.5221819281578064
val_Epoch:[ 1 ] val_loss: 0.5202685847878457 2022-05-29 16:21:07.831468
start training 2022-05-29 16:21:07.933430
Epoch:[ 2 0 ] loss: 0.47825250029563904 2022-05-29 16:21:30.793309
Epoch:[ 2 1 ] loss: 0.4816046953201294 2022-05-29 16:21:31.992615
Epoch:[ 2 2 ] loss: 0.4790925085544586 2022-05-29 16:21:32.781171
Epoch:[ 2 3 ] loss: 0.4785079061985016 2022-05-29 16:21:33.554816
Epoch:[ 2 4 ] loss: 0.4790375828742981 2022-05-29 16:21:34.329420
Epoch:[ 2 5 ] loss: 0.47605738043785095 2022-05-29 16:21:35.103643
Epoch:[ 2 6 ] loss: 0.477453351020813 2022-05-29 16:21:35.881479
Epoch:[ 2 7 ] loss: 0.47389063239097595 2022-05-29 16:21:36.670027
Epoch:[ 2 8 ] loss: 0.47660598158836365 2022-05-29 16:21:37.448765
Epoch:[ 2 9 ] loss: 0.47635775804519653 2022-05-29 16:21:38.225690
Epoch:[ 2 10 ] loss: 0.47876596450805664 2022-05-29 16:21:39.000058
Epoch:[ 2 11 ] loss: 0.4791637361049652 2022-05-29 16:21:39.778030
Epoch:[ 2 12 ] loss: 0.4798126220703125 2022-05-29 16:21:40.565276
Epoch:[ 2 13 ] loss: 0.48114538192749023 2022-05-29 16:21:41.344162
Epoch:[ 2 14 ] loss: 0.4776478111743927 2022-05-29 16:21:42.123585
Epoch:[ 2 15 ] loss: 0.48423969745635986 2022-05-29 16:21:42.901159
Epoch:[ 2 16 ] loss: 0.47932466864585876 2022-05-29 16:21:50.107925
Epoch:[ 2 17 ] loss: 0.472580224275589 2022-05-29 16:21:50.881720
Epoch:[ 2 18 ] loss: 0.47893962264060974 2022-05-29 16:21:51.673372
Epoch:[ 2 19 ] loss: 0.47713589668273926 2022-05-29 16:21:52.458705
Training_Epoch:[ 2 ] Training_loss: 0.47828079611063 2022-05-29 16:21:52.459458
learning rate:  0.0004
netparams have been saved once 2
val: 1 0.4949485659599304
val: 2 0.5128645300865173
val: 3 0.5517846345901489
val: 4 0.5220537185668945
val: 5 0.5112011432647705
val: 6 0.515681266784668
val: 7 0.5182433724403381
val: 8 0.5416743755340576
val: 9 0.5327586531639099
val: 10 0.5341367721557617
val: 11 0.5164296627044678
val: 12 0.5128951072692871
val: 13 0.5335910320281982
val: 14 0.5180192589759827
val: 15 0.5188738107681274
val: 16 0.5277153253555298
val: 17 0.5242528915405273
val: 18 0.5193440318107605
val: 19 0.5267425179481506
val: 20 0.5143191814422607
val_Epoch:[ 2 ] val_loss: 0.5223764926195145 2022-05-29 16:21:57.825918
start training 2022-05-29 16:21:57.920035
Epoch:[ 3 0 ] loss: 0.4737517535686493 2022-05-29 16:22:20.591495
Epoch:[ 3 1 ] loss: 0.47402867674827576 2022-05-29 16:22:21.399681
Epoch:[ 3 2 ] loss: 0.4728913903236389 2022-05-29 16:22:22.187609
Epoch:[ 3 3 ] loss: 0.479030966758728 2022-05-29 16:22:22.962743
Epoch:[ 3 4 ] loss: 0.470731258392334 2022-05-29 16:22:23.747770
Epoch:[ 3 5 ] loss: 0.4758012592792511 2022-05-29 16:22:24.522860
Epoch:[ 3 6 ] loss: 0.47403761744499207 2022-05-29 16:22:25.309384
Epoch:[ 3 7 ] loss: 0.4746147692203522 2022-05-29 16:22:26.085853
Epoch:[ 3 8 ] loss: 0.47451093792915344 2022-05-29 16:22:26.860774
Epoch:[ 3 9 ] loss: 0.4772675633430481 2022-05-29 16:22:27.639234
Epoch:[ 3 10 ] loss: 0.47682666778564453 2022-05-29 16:22:28.415095
Epoch:[ 3 11 ] loss: 0.477345734834671 2022-05-29 16:22:29.187505
Epoch:[ 3 12 ] loss: 0.47411543130874634 2022-05-29 16:22:29.959816
Epoch:[ 3 13 ] loss: 0.46986082196235657 2022-05-29 16:22:30.732874
Epoch:[ 3 14 ] loss: 0.4727758765220642 2022-05-29 16:22:31.509601
Epoch:[ 3 15 ] loss: 0.47839677333831787 2022-05-29 16:22:32.285903
Epoch:[ 3 16 ] loss: 0.4782286286354065 2022-05-29 16:22:39.786861
Epoch:[ 3 17 ] loss: 0.4771828055381775 2022-05-29 16:22:40.562267
Epoch:[ 3 18 ] loss: 0.47853848338127136 2022-05-29 16:22:41.352367
Epoch:[ 3 19 ] loss: 0.47941458225250244 2022-05-29 16:22:42.136111
Training_Epoch:[ 3 ] Training_loss: 0.47546759992837906 2022-05-29 16:22:42.136966
learning rate:  0.0004
val: 1 0.48583516478538513
val: 2 0.5135895013809204
val: 3 0.5182591080665588
val: 4 0.5285115838050842
val: 5 0.5115175247192383
val: 6 0.520114541053772
val: 7 0.501384437084198
val: 8 0.5167238712310791
val: 9 0.5039653182029724
val: 10 0.535548210144043
val: 11 0.5214706063270569
val: 12 0.5155727863311768
val: 13 0.5198608040809631
val: 14 0.5478304624557495
val: 15 0.5150048732757568
val: 16 0.5263739228248596
val: 17 0.5282768607139587
val: 18 0.5206927061080933
val: 19 0.5113121867179871
val: 20 0.510762631893158
val_Epoch:[ 3 ] val_loss: 0.5176303550601006 2022-05-29 16:22:47.375229
start training 2022-05-29 16:22:47.475266
Epoch:[ 4 0 ] loss: 0.47155189514160156 2022-05-29 16:23:09.923085
Epoch:[ 4 1 ] loss: 0.4740052819252014 2022-05-29 16:23:10.746660
Epoch:[ 4 2 ] loss: 0.4726390242576599 2022-05-29 16:23:11.666130
Epoch:[ 4 3 ] loss: 0.47440198063850403 2022-05-29 16:23:12.454271
Epoch:[ 4 4 ] loss: 0.47245338559150696 2022-05-29 16:23:13.232036
Epoch:[ 4 5 ] loss: 0.4723035395145416 2022-05-29 16:23:14.007717
Epoch:[ 4 6 ] loss: 0.47307300567626953 2022-05-29 16:23:14.782535
Epoch:[ 4 7 ] loss: 0.472051203250885 2022-05-29 16:23:15.558478
Epoch:[ 4 8 ] loss: 0.4698837995529175 2022-05-29 16:23:16.347651
Epoch:[ 4 9 ] loss: 0.4756956100463867 2022-05-29 16:23:17.125643
Epoch:[ 4 10 ] loss: 0.47446975111961365 2022-05-29 16:23:17.903041
Epoch:[ 4 11 ] loss: 0.47412532567977905 2022-05-29 16:23:18.678568
Epoch:[ 4 12 ] loss: 0.47199535369873047 2022-05-29 16:23:19.453453
Epoch:[ 4 13 ] loss: 0.47381874918937683 2022-05-29 16:23:20.231155
Epoch:[ 4 14 ] loss: 0.4762234389781952 2022-05-29 16:23:21.017219
Epoch:[ 4 15 ] loss: 0.47447580099105835 2022-05-29 16:23:21.793846
Epoch:[ 4 16 ] loss: 0.47194379568099976 2022-05-29 16:23:29.877514
Epoch:[ 4 17 ] loss: 0.4772590398788452 2022-05-29 16:23:30.667805
Epoch:[ 4 18 ] loss: 0.4705798625946045 2022-05-29 16:23:31.459806
Epoch:[ 4 19 ] loss: 0.4757203161716461 2022-05-29 16:23:32.244349
Training_Epoch:[ 4 ] Training_loss: 0.47343350797891615 2022-05-29 16:23:32.245057
learning rate:  0.0004
netparams have been saved once 4
val: 1 0.5151623487472534
val: 2 0.5279924869537354
val: 3 0.5153570771217346
val: 4 0.5355892181396484
val: 5 0.5299588441848755
val: 6 0.5024852752685547
val: 7 0.5143818855285645
val: 8 0.5150038003921509
val: 9 0.5175822973251343
val: 10 0.5270398259162903
val: 11 0.5086725950241089
val: 12 0.511047899723053
val: 13 0.5105637907981873
val: 14 0.5301328897476196
val: 15 0.5128170251846313
val: 16 0.5159117579460144
val: 17 0.5068106651306152
val: 18 0.5220301747322083
val: 19 0.5038884878158569
val: 20 0.5067979693412781
val_Epoch:[ 4 ] val_loss: 0.5164613157510758 2022-05-29 16:23:37.670415
start training 2022-05-29 16:23:37.766412
Epoch:[ 5 0 ] loss: 0.46650630235671997 2022-05-29 16:24:00.157784
Epoch:[ 5 1 ] loss: 0.473718523979187 2022-05-29 16:24:00.960562
Epoch:[ 5 2 ] loss: 0.46944087743759155 2022-05-29 16:24:01.788892
Epoch:[ 5 3 ] loss: 0.47302037477493286 2022-05-29 16:24:02.567658
Epoch:[ 5 4 ] loss: 0.47038209438323975 2022-05-29 16:24:03.345401
Epoch:[ 5 5 ] loss: 0.4692361354827881 2022-05-29 16:24:04.123665
Epoch:[ 5 6 ] loss: 0.4713216722011566 2022-05-29 16:24:04.903600
Epoch:[ 5 7 ] loss: 0.47068169713020325 2022-05-29 16:24:05.679935
Epoch:[ 5 8 ] loss: 0.47670799493789673 2022-05-29 16:24:06.455108
Epoch:[ 5 9 ] loss: 0.4677213728427887 2022-05-29 16:24:07.221665
Epoch:[ 5 10 ] loss: 0.4712633490562439 2022-05-29 16:24:08.003338
Epoch:[ 5 11 ] loss: 0.47222083806991577 2022-05-29 16:24:08.783436
Epoch:[ 5 12 ] loss: 0.472072958946228 2022-05-29 16:24:09.561201
Epoch:[ 5 13 ] loss: 0.47231242060661316 2022-05-29 16:24:10.338288
Epoch:[ 5 14 ] loss: 0.4696129858493805 2022-05-29 16:24:11.128224
Epoch:[ 5 15 ] loss: 0.47478100657463074 2022-05-29 16:24:11.915966
Epoch:[ 5 16 ] loss: 0.4753132462501526 2022-05-29 16:24:20.274225
Epoch:[ 5 17 ] loss: 0.4694891571998596 2022-05-29 16:24:21.063614
Epoch:[ 5 18 ] loss: 0.46980345249176025 2022-05-29 16:24:21.844506
Epoch:[ 5 19 ] loss: 0.47548800706863403 2022-05-29 16:24:22.631792
Training_Epoch:[ 5 ] Training_loss: 0.47155472338199617 2022-05-29 16:24:22.632636
learning rate:  0.0004
val: 1 0.49341198801994324
val: 2 0.5208323001861572
val: 3 0.4946463704109192
val: 4 0.5181920528411865
val: 5 0.5338506102561951
val: 6 0.5029848217964172
val: 7 0.5221448540687561
val: 8 0.49528414011001587
val: 9 0.5473959445953369
val: 10 0.5412003993988037
val: 11 0.5304328799247742
val: 12 0.5225266814231873
val: 13 0.5110669136047363
val: 14 0.5153297781944275
val: 15 0.5040568709373474
val: 16 0.5130367875099182
val: 17 0.5304585099220276
val: 18 0.5256525278091431
val: 19 0.5333760380744934
val: 20 0.5123880505561829
val_Epoch:[ 5 ] val_loss: 0.5184134259819985 2022-05-29 16:24:27.925207
start training 2022-05-29 16:24:28.026352
Epoch:[ 6 0 ] loss: 0.470609575510025 2022-05-29 16:24:51.251037
Epoch:[ 6 1 ] loss: 0.47204041481018066 2022-05-29 16:24:52.064586
Epoch:[ 6 2 ] loss: 0.47097864747047424 2022-05-29 16:24:52.836848
Epoch:[ 6 3 ] loss: 0.4672676920890808 2022-05-29 16:24:53.616542
Epoch:[ 6 4 ] loss: 0.47151023149490356 2022-05-29 16:24:54.406400
Epoch:[ 6 5 ] loss: 0.4704500138759613 2022-05-29 16:24:55.183114
Epoch:[ 6 6 ] loss: 0.4720706343650818 2022-05-29 16:24:55.958680
Epoch:[ 6 7 ] loss: 0.46611925959587097 2022-05-29 16:24:56.739437
Epoch:[ 6 8 ] loss: 0.469226211309433 2022-05-29 16:24:57.516819
Epoch:[ 6 9 ] loss: 0.4639497697353363 2022-05-29 16:24:58.295877
Epoch:[ 6 10 ] loss: 0.47724413871765137 2022-05-29 16:24:59.077156
Epoch:[ 6 11 ] loss: 0.4695214629173279 2022-05-29 16:24:59.856980
Epoch:[ 6 12 ] loss: 0.4666149318218231 2022-05-29 16:25:00.635509
Epoch:[ 6 13 ] loss: 0.4654260277748108 2022-05-29 16:25:01.413833
Epoch:[ 6 14 ] loss: 0.46726474165916443 2022-05-29 16:25:02.199520
Epoch:[ 6 15 ] loss: 0.4742234945297241 2022-05-29 16:25:02.985320
Epoch:[ 6 16 ] loss: 0.4706088900566101 2022-05-29 16:25:10.511176
Epoch:[ 6 17 ] loss: 0.47091010212898254 2022-05-29 16:25:11.300179
Epoch:[ 6 18 ] loss: 0.4705558121204376 2022-05-29 16:25:12.091585
Epoch:[ 6 19 ] loss: 0.47000977396965027 2022-05-29 16:25:12.870132
Training_Epoch:[ 6 ] Training_loss: 0.4698300912976265 2022-05-29 16:25:12.870851
learning rate:  0.0004
netparams have been saved once 6
val: 1 0.5142855644226074
val: 2 0.5212619304656982
val: 3 0.5170000791549683
val: 4 0.5136801600456238
val: 5 0.514959990978241
val: 6 0.5163153409957886
val: 7 0.497593492269516
val: 8 0.5170463919639587
val: 9 0.5287660956382751
val: 10 0.49493321776390076
val: 11 0.5117844343185425
val: 12 0.5238270163536072
val: 13 0.5120840072631836
val: 14 0.5071524381637573
val: 15 0.5085129141807556
val: 16 0.5255534052848816
val: 17 0.4951012432575226
val: 18 0.5244460701942444
val: 19 0.5193200707435608
val: 20 0.5375216007232666
val_Epoch:[ 6 ] val_loss: 0.515057273209095 2022-05-29 16:25:18.130143
start training 2022-05-29 16:25:18.229321
Epoch:[ 7 0 ] loss: 0.4610392153263092 2022-05-29 16:25:41.150243
Epoch:[ 7 1 ] loss: 0.46715641021728516 2022-05-29 16:25:41.983819
Epoch:[ 7 2 ] loss: 0.4690493941307068 2022-05-29 16:25:42.775334
Epoch:[ 7 3 ] loss: 0.4688143730163574 2022-05-29 16:25:43.561216
Epoch:[ 7 4 ] loss: 0.464420348405838 2022-05-29 16:25:44.337974
Epoch:[ 7 5 ] loss: 0.46721717715263367 2022-05-29 16:25:45.115996
Epoch:[ 7 6 ] loss: 0.46774446964263916 2022-05-29 16:25:45.892935
Epoch:[ 7 7 ] loss: 0.4683253765106201 2022-05-29 16:25:46.667969
Epoch:[ 7 8 ] loss: 0.4652165472507477 2022-05-29 16:25:47.442247
Epoch:[ 7 9 ] loss: 0.4633391499519348 2022-05-29 16:25:48.216082
Epoch:[ 7 10 ] loss: 0.46666455268859863 2022-05-29 16:25:49.001549
Epoch:[ 7 11 ] loss: 0.4699822962284088 2022-05-29 16:25:49.777172
Epoch:[ 7 12 ] loss: 0.47211483120918274 2022-05-29 16:25:50.554895
Epoch:[ 7 13 ] loss: 0.46781593561172485 2022-05-29 16:25:51.331815
Epoch:[ 7 14 ] loss: 0.4713834226131439 2022-05-29 16:25:52.109250
Epoch:[ 7 15 ] loss: 0.46464526653289795 2022-05-29 16:25:52.884247
Epoch:[ 7 16 ] loss: 0.46695783734321594 2022-05-29 16:26:00.912893
Epoch:[ 7 17 ] loss: 0.4685664474964142 2022-05-29 16:26:01.699243
Epoch:[ 7 18 ] loss: 0.46666213870048523 2022-05-29 16:26:02.497122
Epoch:[ 7 19 ] loss: 0.46784934401512146 2022-05-29 16:26:03.288229
Training_Epoch:[ 7 ] Training_loss: 0.4672482267022133 2022-05-29 16:26:03.289034
learning rate:  0.0004
val: 1 0.516845703125
val: 2 0.5131635069847107
val: 3 0.5073152184486389
val: 4 0.5358744263648987
val: 5 0.5257255434989929
val: 6 0.500717043876648
val: 7 0.5201544761657715
val: 8 0.5189802050590515
val: 9 0.512437105178833
val: 10 0.5220577120780945
val: 11 0.4978247284889221
val: 12 0.5403341054916382
val: 13 0.5197524428367615
val: 14 0.5323020815849304
val: 15 0.5065804123878479
val: 16 0.5254147052764893
val: 17 0.5070521235466003
val: 18 0.5164619088172913
val: 19 0.49992620944976807
val: 20 0.5255906581878662
val_Epoch:[ 7 ] val_loss: 0.5172255158424377 2022-05-29 16:26:08.507490
start training 2022-05-29 16:26:08.601938
Epoch:[ 8 0 ] loss: 0.46442440152168274 2022-05-29 16:26:31.028421
Epoch:[ 8 1 ] loss: 0.46456724405288696 2022-05-29 16:26:31.890301
Epoch:[ 8 2 ] loss: 0.46724265813827515 2022-05-29 16:26:32.712339
Epoch:[ 8 3 ] loss: 0.46502238512039185 2022-05-29 16:26:33.504447
Epoch:[ 8 4 ] loss: 0.4619085192680359 2022-05-29 16:26:34.283572
Epoch:[ 8 5 ] loss: 0.46756094694137573 2022-05-29 16:26:35.069022
Epoch:[ 8 6 ] loss: 0.46712982654571533 2022-05-29 16:26:35.850654
Epoch:[ 8 7 ] loss: 0.466082900762558 2022-05-29 16:26:36.633477
Epoch:[ 8 8 ] loss: 0.4680107831954956 2022-05-29 16:26:37.418758
Epoch:[ 8 9 ] loss: 0.46970057487487793 2022-05-29 16:26:38.203025
Epoch:[ 8 10 ] loss: 0.4661300778388977 2022-05-29 16:26:38.982361
Epoch:[ 8 11 ] loss: 0.4654189646244049 2022-05-29 16:26:39.773534
Epoch:[ 8 12 ] loss: 0.4664366841316223 2022-05-29 16:26:40.557368
Epoch:[ 8 13 ] loss: 0.46908143162727356 2022-05-29 16:26:41.341076
Epoch:[ 8 14 ] loss: 0.4615063965320587 2022-05-29 16:26:42.124353
Epoch:[ 8 15 ] loss: 0.47209689021110535 2022-05-29 16:26:42.905523
Epoch:[ 8 16 ] loss: 0.4606850743293762 2022-05-29 16:26:50.883647
Epoch:[ 8 17 ] loss: 0.4683537781238556 2022-05-29 16:26:51.663676
Epoch:[ 8 18 ] loss: 0.46562063694000244 2022-05-29 16:26:52.453109
Epoch:[ 8 19 ] loss: 0.46701279282569885 2022-05-29 16:26:53.246679
Training_Epoch:[ 8 ] Training_loss: 0.46619964838027955 2022-05-29 16:26:53.247562
learning rate:  0.0004
netparams have been saved once 8
val: 1 0.49924540519714355
val: 2 0.5162338018417358
val: 3 0.507550835609436
val: 4 0.514332115650177
val: 5 0.5146003365516663
val: 6 0.5124813318252563
val: 7 0.517118513584137
val: 8 0.5216968655586243
val: 9 0.522803544998169
val: 10 0.5056948065757751
val: 11 0.5177358984947205
val: 12 0.5121927261352539
val: 13 0.5197342038154602
val: 14 0.5213785767555237
val: 15 0.5127233266830444
val: 16 0.5226410627365112
val: 17 0.5289389491081238
val: 18 0.5150434970855713
val: 19 0.5269046425819397
val: 20 0.5187086462974548
val_Epoch:[ 8 ] val_loss: 0.5163879543542862 2022-05-29 16:26:59.166005
start training 2022-05-29 16:26:59.262705
Epoch:[ 9 0 ] loss: 0.4624590277671814 2022-05-29 16:27:30.047162
Epoch:[ 9 1 ] loss: 0.4649505019187927 2022-05-29 16:27:30.863143
Epoch:[ 9 2 ] loss: 0.4641115069389343 2022-05-29 16:27:31.677428
Epoch:[ 9 3 ] loss: 0.46640923619270325 2022-05-29 16:27:32.493638
Epoch:[ 9 4 ] loss: 0.4684047996997833 2022-05-29 16:27:33.306822
Epoch:[ 9 5 ] loss: 0.46873512864112854 2022-05-29 16:27:34.125531
Epoch:[ 9 6 ] loss: 0.4614913761615753 2022-05-29 16:27:34.942347
Epoch:[ 9 7 ] loss: 0.4652620851993561 2022-05-29 16:27:35.760231
Epoch:[ 9 8 ] loss: 0.46332690119743347 2022-05-29 16:27:36.574539
Epoch:[ 9 9 ] loss: 0.46524858474731445 2022-05-29 16:27:37.389567
Epoch:[ 9 10 ] loss: 0.4694503843784332 2022-05-29 16:27:38.212192
Epoch:[ 9 11 ] loss: 0.4665865898132324 2022-05-29 16:27:39.024441
Epoch:[ 9 12 ] loss: 0.46662962436676025 2022-05-29 16:27:39.839362
Epoch:[ 9 13 ] loss: 0.4667406678199768 2022-05-29 16:27:40.653566
Epoch:[ 9 14 ] loss: 0.46226227283477783 2022-05-29 16:27:41.472073
Epoch:[ 9 15 ] loss: 0.4558064043521881 2022-05-29 16:27:42.287213
Epoch:[ 9 16 ] loss: 0.46227967739105225 2022-05-29 16:27:52.602482
Epoch:[ 9 17 ] loss: 0.4616442024707794 2022-05-29 16:27:53.415467
Epoch:[ 9 18 ] loss: 0.4599088728427887 2022-05-29 16:27:54.284560
Epoch:[ 9 19 ] loss: 0.4652726352214813 2022-05-29 16:27:55.111162
Training_Epoch:[ 9 ] Training_loss: 0.46434902399778366 2022-05-29 16:27:55.111939
learning rate:  0.0004
val: 1 0.5276293158531189
val: 2 0.5304098725318909
val: 3 0.5026887655258179
val: 4 0.5140024423599243
val: 5 0.5115644931793213
val: 6 0.5083232522010803
val: 7 0.5150827765464783
val: 8 0.5213807225227356
val: 9 0.5197286605834961
val: 10 0.5082889795303345
val: 11 0.5210228562355042
val: 12 0.5033426284790039
val: 13 0.5141340494155884
val: 14 0.5191456079483032
val: 15 0.5184023976325989
val: 16 0.5062143206596375
val: 17 0.5117652416229248
val: 18 0.5118476152420044
val: 19 0.5164857506752014
val: 20 0.5128223299980164
val_Epoch:[ 9 ] val_loss: 0.514714103937149 2022-05-29 16:28:01.124719
start training 2022-05-29 16:28:01.247395
Epoch:[ 10 0 ] loss: 0.4619522988796234 2022-05-29 16:28:28.332232
Epoch:[ 10 1 ] loss: 0.46341416239738464 2022-05-29 16:28:29.150173
Epoch:[ 10 2 ] loss: 0.4567899703979492 2022-05-29 16:28:29.970472
Epoch:[ 10 3 ] loss: 0.4621969163417816 2022-05-29 16:28:30.781931
Epoch:[ 10 4 ] loss: 0.4639272093772888 2022-05-29 16:28:31.600328
Epoch:[ 10 5 ] loss: 0.46136173605918884 2022-05-29 16:28:32.425251
Epoch:[ 10 6 ] loss: 0.46490150690078735 2022-05-29 16:28:33.242515
Epoch:[ 10 7 ] loss: 0.4634043574333191 2022-05-29 16:28:34.066089
Epoch:[ 10 8 ] loss: 0.4609144330024719 2022-05-29 16:28:34.884313
Epoch:[ 10 9 ] loss: 0.4643654227256775 2022-05-29 16:28:35.697178
Epoch:[ 10 10 ] loss: 0.462977796792984 2022-05-29 16:28:36.513179
Epoch:[ 10 11 ] loss: 0.4639762043952942 2022-05-29 16:28:37.310080
Epoch:[ 10 12 ] loss: 0.4586344361305237 2022-05-29 16:28:38.094476
Epoch:[ 10 13 ] loss: 0.4650173783302307 2022-05-29 16:28:38.892976
Epoch:[ 10 14 ] loss: 0.46087372303009033 2022-05-29 16:28:39.680639
Epoch:[ 10 15 ] loss: 0.46213406324386597 2022-05-29 16:28:40.466811
Epoch:[ 10 16 ] loss: 0.46393024921417236 2022-05-29 16:28:48.816412
Epoch:[ 10 17 ] loss: 0.4650212824344635 2022-05-29 16:28:49.623167
Epoch:[ 10 18 ] loss: 0.46176865696907043 2022-05-29 16:28:50.436975
Epoch:[ 10 19 ] loss: 0.4643523097038269 2022-05-29 16:28:51.250330
Training_Epoch:[ 10 ] Training_loss: 0.46259570568799974 2022-05-29 16:28:51.251232
learning rate:  0.0004
netparams have been saved once 10
val: 1 0.5023630857467651
val: 2 0.5192602276802063
val: 3 0.530170202255249
val: 4 0.5202968716621399
val: 5 0.5137132406234741
val: 6 0.5399467349052429
val: 7 0.4982317090034485
val: 8 0.5224740505218506
val: 9 0.5126944184303284
val: 10 0.518065869808197
val: 11 0.5127326250076294
val: 12 0.5193077325820923
val: 13 0.5225810408592224
val: 14 0.5219378471374512
val: 15 0.5298197269439697
val: 16 0.514087438583374
val: 17 0.523624062538147
val: 18 0.4917502999305725
val: 19 0.5168246626853943
val: 20 0.4997129440307617
val_Epoch:[ 10 ] val_loss: 0.5164797395467758 2022-05-29 16:28:57.035663
start training 2022-05-29 16:28:57.138337
Epoch:[ 11 0 ] loss: 0.46228519082069397 2022-05-29 16:29:25.307957
Epoch:[ 11 1 ] loss: 0.463003009557724 2022-05-29 16:29:26.158748
Epoch:[ 11 2 ] loss: 0.4600342810153961 2022-05-29 16:29:26.981079
Epoch:[ 11 3 ] loss: 0.4533369839191437 2022-05-29 16:29:27.801557
Epoch:[ 11 4 ] loss: 0.4623495936393738 2022-05-29 16:29:28.613744
Epoch:[ 11 5 ] loss: 0.45582345128059387 2022-05-29 16:29:29.430678
Epoch:[ 11 6 ] loss: 0.4586484432220459 2022-05-29 16:29:30.247177
Epoch:[ 11 7 ] loss: 0.4618845283985138 2022-05-29 16:29:31.055501
Epoch:[ 11 8 ] loss: 0.46629610657691956 2022-05-29 16:29:31.881120
Epoch:[ 11 9 ] loss: 0.45967817306518555 2022-05-29 16:29:32.697347
Epoch:[ 11 10 ] loss: 0.45923539996147156 2022-05-29 16:29:33.516090
Epoch:[ 11 11 ] loss: 0.4621164798736572 2022-05-29 16:29:34.332984
Epoch:[ 11 12 ] loss: 0.4565109610557556 2022-05-29 16:29:35.141758
Epoch:[ 11 13 ] loss: 0.45600566267967224 2022-05-29 16:29:35.957203
Epoch:[ 11 14 ] loss: 0.4596268832683563 2022-05-29 16:29:36.773801
Epoch:[ 11 15 ] loss: 0.4653925895690918 2022-05-29 16:29:37.594565
Epoch:[ 11 16 ] loss: 0.46054452657699585 2022-05-29 16:29:46.673339
Epoch:[ 11 17 ] loss: 0.46086251735687256 2022-05-29 16:29:47.493499
Epoch:[ 11 18 ] loss: 0.45830097794532776 2022-05-29 16:29:48.350390
Epoch:[ 11 19 ] loss: 0.4586879312992096 2022-05-29 16:29:49.167563
Training_Epoch:[ 11 ] Training_loss: 0.4600311845541 2022-05-29 16:29:49.168409
learning rate:  0.00032
val: 1 0.5121835470199585
val: 2 0.5105240345001221
val: 3 0.5220499634742737
val: 4 0.5176730751991272
val: 5 0.5188639760017395
val: 6 0.5086318254470825
val: 7 0.4990967810153961
val: 8 0.520153820514679
val: 9 0.5184258818626404
val: 10 0.5388121008872986
val: 11 0.5249983072280884
val: 12 0.5319643616676331
val: 13 0.5219059586524963
val: 14 0.5160504579544067
val: 15 0.5002020597457886
val: 16 0.511002779006958
val: 17 0.5336121916770935
val: 18 0.5126326084136963
val: 19 0.5127370357513428
val: 20 0.5083332061767578
val_Epoch:[ 11 ] val_loss: 0.516992698609829 2022-05-29 16:29:55.126961
start training 2022-05-29 16:29:55.244276
Epoch:[ 12 0 ] loss: 0.4578288197517395 2022-05-29 16:30:23.195416
Epoch:[ 12 1 ] loss: 0.45986124873161316 2022-05-29 16:30:24.049411
Epoch:[ 12 2 ] loss: 0.45730867981910706 2022-05-29 16:30:24.881382
Epoch:[ 12 3 ] loss: 0.4591599404811859 2022-05-29 16:30:25.695417
Epoch:[ 12 4 ] loss: 0.4551638066768646 2022-05-29 16:30:26.512413
Epoch:[ 12 5 ] loss: 0.45866188406944275 2022-05-29 16:30:27.340694
Epoch:[ 12 6 ] loss: 0.4578627049922943 2022-05-29 16:30:28.155263
Epoch:[ 12 7 ] loss: 0.4609791040420532 2022-05-29 16:30:28.966412
Epoch:[ 12 8 ] loss: 0.4572269022464752 2022-05-29 16:30:29.782936
Epoch:[ 12 9 ] loss: 0.45314300060272217 2022-05-29 16:30:30.600842
Epoch:[ 12 10 ] loss: 0.45845380425453186 2022-05-29 16:30:31.422278
Epoch:[ 12 11 ] loss: 0.4569997489452362 2022-05-29 16:30:32.236524
Epoch:[ 12 12 ] loss: 0.45853421092033386 2022-05-29 16:30:33.053672
Epoch:[ 12 13 ] loss: 0.4611494243144989 2022-05-29 16:30:33.868285
Epoch:[ 12 14 ] loss: 0.4574678838253021 2022-05-29 16:30:34.688492
Epoch:[ 12 15 ] loss: 0.4575246274471283 2022-05-29 16:30:35.494619
Epoch:[ 12 16 ] loss: 0.4583287835121155 2022-05-29 16:30:44.952127
Epoch:[ 12 17 ] loss: 0.46030670404434204 2022-05-29 16:30:45.773693
Epoch:[ 12 18 ] loss: 0.46562179923057556 2022-05-29 16:30:46.653500
Epoch:[ 12 19 ] loss: 0.4600073993206024 2022-05-29 16:30:47.470956
Training_Epoch:[ 12 ] Training_loss: 0.4585795238614082 2022-05-29 16:30:47.471946
learning rate:  0.00032
netparams have been saved once 12
val: 1 0.5182651877403259
val: 2 0.5241062045097351
val: 3 0.5212767720222473
val: 4 0.5249571204185486
val: 5 0.5047337412834167
val: 6 0.5278457999229431
val: 7 0.5278434157371521
val: 8 0.5388398170471191
val: 9 0.5205913782119751
val: 10 0.5174176692962646
val: 11 0.5123197436332703
val: 12 0.5071909427642822
val: 13 0.5166635513305664
val: 14 0.5158817172050476
val: 15 0.511019766330719
val: 16 0.5123820900917053
val: 17 0.5236608982086182
val: 18 0.5302441716194153
val: 19 0.5188585519790649
val: 20 0.5253700017929077
val_Epoch:[ 12 ] val_loss: 0.5199734270572662 2022-05-29 16:30:53.305032
start training 2022-05-29 16:30:53.401512
Epoch:[ 13 0 ] loss: 0.45876526832580566 2022-05-29 16:31:21.993800
Epoch:[ 13 1 ] loss: 0.4590892195701599 2022-05-29 16:31:23.786944
Epoch:[ 13 2 ] loss: 0.45368558168411255 2022-05-29 16:31:24.620432
Epoch:[ 13 3 ] loss: 0.4522308111190796 2022-05-29 16:31:25.436977
Epoch:[ 13 4 ] loss: 0.4598064720630646 2022-05-29 16:31:26.254389
Epoch:[ 13 5 ] loss: 0.4555925130844116 2022-05-29 16:31:27.073531
Epoch:[ 13 6 ] loss: 0.461055725812912 2022-05-29 16:31:27.885804
Epoch:[ 13 7 ] loss: 0.45816439390182495 2022-05-29 16:31:28.701730
Epoch:[ 13 8 ] loss: 0.45642802119255066 2022-05-29 16:31:29.510820
Epoch:[ 13 9 ] loss: 0.45339682698249817 2022-05-29 16:31:30.325243
Epoch:[ 13 10 ] loss: 0.4574122726917267 2022-05-29 16:31:31.152334
Epoch:[ 13 11 ] loss: 0.4619077444076538 2022-05-29 16:31:31.963508
Epoch:[ 13 12 ] loss: 0.45770278573036194 2022-05-29 16:31:32.783822
Epoch:[ 13 13 ] loss: 0.4560326635837555 2022-05-29 16:31:33.600630
Epoch:[ 13 14 ] loss: 0.4551316201686859 2022-05-29 16:31:34.413569
Epoch:[ 13 15 ] loss: 0.4598478376865387 2022-05-29 16:31:35.228824
Epoch:[ 13 16 ] loss: 0.4551598131656647 2022-05-29 16:31:44.138743
Epoch:[ 13 17 ] loss: 0.45828011631965637 2022-05-29 16:31:46.200963
Epoch:[ 13 18 ] loss: 0.4568016827106476 2022-05-29 16:31:46.985269
Epoch:[ 13 19 ] loss: 0.4592326581478119 2022-05-29 16:31:47.777861
Training_Epoch:[ 13 ] Training_loss: 0.45728620141744614 2022-05-29 16:31:47.778612
learning rate:  0.00032
val: 1 0.5394297242164612
val: 2 0.5178134441375732
val: 3 0.534824550151825
val: 4 0.527726411819458
val: 5 0.5125736594200134
val: 6 0.517587423324585
val: 7 0.5182911157608032
val: 8 0.515874981880188
val: 9 0.510968029499054
val: 10 0.4990394115447998
val: 11 0.5234673619270325
val: 12 0.5098751783370972
val: 13 0.5088834762573242
val: 14 0.5127595663070679
val: 15 0.5209836363792419
val: 16 0.528878390789032
val: 17 0.5225151181221008
val: 18 0.4935188889503479
val: 19 0.5105922818183899
val: 20 0.5043613314628601
val_Epoch:[ 13 ] val_loss: 0.5164981991052627 2022-05-29 16:31:53.883792
start training 2022-05-29 16:31:53.995855
Epoch:[ 14 0 ] loss: 0.4542219638824463 2022-05-29 16:32:21.263280
Epoch:[ 14 1 ] loss: 0.4568655490875244 2022-05-29 16:32:22.085115
Epoch:[ 14 2 ] loss: 0.45468541979789734 2022-05-29 16:32:22.873815
Epoch:[ 14 3 ] loss: 0.4573485851287842 2022-05-29 16:32:23.655179
Epoch:[ 14 4 ] loss: 0.44978317618370056 2022-05-29 16:32:24.438697
Epoch:[ 14 5 ] loss: 0.45871293544769287 2022-05-29 16:32:25.223540
Epoch:[ 14 6 ] loss: 0.4620820879936218 2022-05-29 16:32:26.018230
Epoch:[ 14 7 ] loss: 0.45432910323143005 2022-05-29 16:32:26.811043
Epoch:[ 14 8 ] loss: 0.4591098725795746 2022-05-29 16:32:27.598388
Epoch:[ 14 9 ] loss: 0.4580506682395935 2022-05-29 16:32:28.385927
Epoch:[ 14 10 ] loss: 0.45423394441604614 2022-05-29 16:32:29.167156
Epoch:[ 14 11 ] loss: 0.4572485685348511 2022-05-29 16:32:29.948418
Epoch:[ 14 12 ] loss: 0.45083996653556824 2022-05-29 16:32:30.744841
Epoch:[ 14 13 ] loss: 0.4587675631046295 2022-05-29 16:32:31.530361
Epoch:[ 14 14 ] loss: 0.4550878703594208 2022-05-29 16:32:32.311649
Epoch:[ 14 15 ] loss: 0.45767953991889954 2022-05-29 16:32:33.097269
Epoch:[ 14 16 ] loss: 0.45341578125953674 2022-05-29 16:32:42.707763
Epoch:[ 14 17 ] loss: 0.4589865505695343 2022-05-29 16:32:43.488264
Epoch:[ 14 18 ] loss: 0.4541797339916229 2022-05-29 16:32:44.285411
Epoch:[ 14 19 ] loss: 0.45962223410606384 2022-05-29 16:32:45.079958
Training_Epoch:[ 14 ] Training_loss: 0.45626255571842195 2022-05-29 16:32:45.080791
learning rate:  0.00032
netparams have been saved once 14
val: 1 0.5030840635299683
val: 2 0.5100975632667542
val: 3 0.5178192257881165
val: 4 0.509972333908081
val: 5 0.5185868740081787
val: 6 0.5071960687637329
val: 7 0.5147191286087036
val: 8 0.5343360304832458
val: 9 0.517372190952301
val: 10 0.5253801941871643
val: 11 0.5091583728790283
val: 12 0.542851984500885
val: 13 0.5204740762710571
val: 14 0.5224486589431763
val: 15 0.5223756432533264
val: 16 0.5105941295623779
val: 17 0.5163159370422363
val: 18 0.5186262130737305
val: 19 0.5088249444961548
val: 20 0.509881854057312
val_Epoch:[ 14 ] val_loss: 0.5170057743787766 2022-05-29 16:32:50.575847
start training 2022-05-29 16:32:50.674234
Epoch:[ 15 0 ] loss: 0.45122572779655457 2022-05-29 16:33:14.579595
Epoch:[ 15 1 ] loss: 0.45379436016082764 2022-05-29 16:33:16.313413
Epoch:[ 15 2 ] loss: 0.4557211697101593 2022-05-29 16:33:17.136138
Epoch:[ 15 3 ] loss: 0.45884156227111816 2022-05-29 16:33:17.922986
Epoch:[ 15 4 ] loss: 0.45200493931770325 2022-05-29 16:33:18.717968
Epoch:[ 15 5 ] loss: 0.4548508822917938 2022-05-29 16:33:19.507250
Epoch:[ 15 6 ] loss: 0.4567909240722656 2022-05-29 16:33:20.295577
Epoch:[ 15 7 ] loss: 0.4564218819141388 2022-05-29 16:33:21.092880
Epoch:[ 15 8 ] loss: 0.45622381567955017 2022-05-29 16:33:21.880831
Epoch:[ 15 9 ] loss: 0.4518275856971741 2022-05-29 16:33:22.672399
Epoch:[ 15 10 ] loss: 0.4546748101711273 2022-05-29 16:33:23.458105
Epoch:[ 15 11 ] loss: 0.45248085260391235 2022-05-29 16:33:24.245501
Epoch:[ 15 12 ] loss: 0.44964900612831116 2022-05-29 16:33:25.039667
Epoch:[ 15 13 ] loss: 0.45491790771484375 2022-05-29 16:33:25.826875
Epoch:[ 15 14 ] loss: 0.4566332995891571 2022-05-29 16:33:26.613641
Epoch:[ 15 15 ] loss: 0.4570614993572235 2022-05-29 16:33:27.403964
Epoch:[ 15 16 ] loss: 0.4534200429916382 2022-05-29 16:33:35.252618
Epoch:[ 15 17 ] loss: 0.4551297724246979 2022-05-29 16:33:37.994399
Epoch:[ 15 18 ] loss: 0.45682206749916077 2022-05-29 16:33:38.821057
Epoch:[ 15 19 ] loss: 0.45753610134124756 2022-05-29 16:33:39.602946
Training_Epoch:[ 15 ] Training_loss: 0.45480141043663025 2022-05-29 16:33:39.603676
learning rate:  0.00032
val: 1 0.513838529586792
val: 2 0.530765175819397
val: 3 0.5140339732170105
val: 4 0.48881441354751587
val: 5 0.5093339085578918
val: 6 0.5117377042770386
val: 7 0.5177069306373596
val: 8 0.5274302959442139
val: 9 0.5070586800575256
val: 10 0.5242041945457458
val: 11 0.5260521173477173
val: 12 0.5156861543655396
val: 13 0.5383527874946594
val: 14 0.5173338055610657
val: 15 0.5080312490463257
val: 16 0.4998190701007843
val: 17 0.5107415914535522
val: 18 0.5025114417076111
val: 19 0.526126503944397
val: 20 0.5135239958763123
val_Epoch:[ 15 ] val_loss: 0.5151551261544227 2022-05-29 16:33:45.578932
start training 2022-05-29 16:33:45.680703
Epoch:[ 16 0 ] loss: 0.45404964685440063 2022-05-29 16:34:12.009054
Epoch:[ 16 1 ] loss: 0.4525607228279114 2022-05-29 16:34:12.811033
Epoch:[ 16 2 ] loss: 0.457247257232666 2022-05-29 16:34:13.611033
Epoch:[ 16 3 ] loss: 0.4527275860309601 2022-05-29 16:34:14.398669
Epoch:[ 16 4 ] loss: 0.4536673426628113 2022-05-29 16:34:15.187927
Epoch:[ 16 5 ] loss: 0.453424870967865 2022-05-29 16:34:15.975492
Epoch:[ 16 6 ] loss: 0.4510425329208374 2022-05-29 16:34:16.767538
Epoch:[ 16 7 ] loss: 0.45384663343429565 2022-05-29 16:34:17.559023
Epoch:[ 16 8 ] loss: 0.45290258526802063 2022-05-29 16:34:18.350113
Epoch:[ 16 9 ] loss: 0.45329177379608154 2022-05-29 16:34:19.136860
Epoch:[ 16 10 ] loss: 0.451683908700943 2022-05-29 16:34:19.939477
Epoch:[ 16 11 ] loss: 0.4535622298717499 2022-05-29 16:34:20.726696
Epoch:[ 16 12 ] loss: 0.4517577290534973 2022-05-29 16:34:21.516975
Epoch:[ 16 13 ] loss: 0.45237407088279724 2022-05-29 16:34:22.308186
Epoch:[ 16 14 ] loss: 0.4517468512058258 2022-05-29 16:34:23.094743
Epoch:[ 16 15 ] loss: 0.4491126537322998 2022-05-29 16:34:23.883981
Epoch:[ 16 16 ] loss: 0.45114973187446594 2022-05-29 16:34:33.884319
Epoch:[ 16 17 ] loss: 0.4530732035636902 2022-05-29 16:34:34.673566
Epoch:[ 16 18 ] loss: 0.4574723541736603 2022-05-29 16:34:35.467090
Epoch:[ 16 19 ] loss: 0.4519839584827423 2022-05-29 16:34:36.263688
Training_Epoch:[ 16 ] Training_loss: 0.4529338821768761 2022-05-29 16:34:36.264563
learning rate:  0.00032
netparams have been saved once 16
val: 1 0.5091656446456909
val: 2 0.5145692825317383
val: 3 0.5378640294075012
val: 4 0.5098533630371094
val: 5 0.5301185250282288
val: 6 0.5067020058631897
val: 7 0.5127267837524414
val: 8 0.501402735710144
val: 9 0.5104069709777832
val: 10 0.5505385398864746
val: 11 0.5229888558387756
val: 12 0.5140278935432434
val: 13 0.5290542840957642
val: 14 0.5376811623573303
val: 15 0.5265473127365112
val: 16 0.5037776827812195
val: 17 0.5248013138771057
val: 18 0.5182933211326599
val: 19 0.49248531460762024
val: 20 0.5327773690223694
val_Epoch:[ 16 ] val_loss: 0.519289119541645 2022-05-29 16:34:42.109645
start training 2022-05-29 16:34:42.234204
Epoch:[ 17 0 ] loss: 0.4463144540786743 2022-05-29 16:35:09.437260
Epoch:[ 17 1 ] loss: 0.4539959728717804 2022-05-29 16:35:11.172961
Epoch:[ 17 2 ] loss: 0.45194122195243835 2022-05-29 16:35:11.963572
Epoch:[ 17 3 ] loss: 0.451111376285553 2022-05-29 16:35:12.756256
Epoch:[ 17 4 ] loss: 0.4514194130897522 2022-05-29 16:35:13.541145
Epoch:[ 17 5 ] loss: 0.4484213590621948 2022-05-29 16:35:14.340126
Epoch:[ 17 6 ] loss: 0.45367589592933655 2022-05-29 16:35:15.135102
Epoch:[ 17 7 ] loss: 0.45061254501342773 2022-05-29 16:35:15.932877
Epoch:[ 17 8 ] loss: 0.45623156428337097 2022-05-29 16:35:16.726409
Epoch:[ 17 9 ] loss: 0.4475390613079071 2022-05-29 16:35:17.529775
Epoch:[ 17 10 ] loss: 0.45303571224212646 2022-05-29 16:35:18.322090
Epoch:[ 17 11 ] loss: 0.45070338249206543 2022-05-29 16:35:19.118495
Epoch:[ 17 12 ] loss: 0.451219767332077 2022-05-29 16:35:19.910353
Epoch:[ 17 13 ] loss: 0.45763885974884033 2022-05-29 16:35:20.699639
Epoch:[ 17 14 ] loss: 0.44944649934768677 2022-05-29 16:35:21.490425
Epoch:[ 17 15 ] loss: 0.45515599846839905 2022-05-29 16:35:22.290027
Epoch:[ 17 16 ] loss: 0.45459750294685364 2022-05-29 16:35:31.516712
Epoch:[ 17 17 ] loss: 0.4516403377056122 2022-05-29 16:35:32.464365
Epoch:[ 17 18 ] loss: 0.4509786069393158 2022-05-29 16:35:33.262218
Epoch:[ 17 19 ] loss: 0.45218613743782043 2022-05-29 16:35:34.048343
Training_Epoch:[ 17 ] Training_loss: 0.4518932834267616 2022-05-29 16:35:34.049198
learning rate:  0.00032
val: 1 0.5327239036560059
val: 2 0.5172306299209595
val: 3 0.518084704875946
val: 4 0.5174919366836548
val: 5 0.5133611559867859
val: 6 0.521747887134552
val: 7 0.5219705104827881
val: 8 0.5094512701034546
val: 9 0.522361695766449
val: 10 0.5204840302467346
val: 11 0.5213913321495056
val: 12 0.5135659575462341
val: 13 0.5213906764984131
val: 14 0.5191175937652588
val: 15 0.5107054114341736
val: 16 0.5140998363494873
val: 17 0.5279555320739746
val: 18 0.5196983814239502
val: 19 0.5107868909835815
val: 20 0.5190691947937012
val_Epoch:[ 17 ] val_loss: 0.5186344265937806 2022-05-29 16:35:40.092642
start training 2022-05-29 16:35:40.211462
Epoch:[ 18 0 ] loss: 0.45143556594848633 2022-05-29 16:36:09.231112
Epoch:[ 18 1 ] loss: 0.45140838623046875 2022-05-29 16:36:10.049824
Epoch:[ 18 2 ] loss: 0.4517115354537964 2022-05-29 16:36:10.835911
Epoch:[ 18 3 ] loss: 0.4463143050670624 2022-05-29 16:36:11.625005
Epoch:[ 18 4 ] loss: 0.4521650969982147 2022-05-29 16:36:12.432059
Epoch:[ 18 5 ] loss: 0.4500894844532013 2022-05-29 16:36:13.219580
Epoch:[ 18 6 ] loss: 0.44647416472435 2022-05-29 16:36:14.006120
Epoch:[ 18 7 ] loss: 0.45313483476638794 2022-05-29 16:36:14.793727
Epoch:[ 18 8 ] loss: 0.4482772946357727 2022-05-29 16:36:15.586009
Epoch:[ 18 9 ] loss: 0.4544082283973694 2022-05-29 16:36:16.376941
Epoch:[ 18 10 ] loss: 0.45136013627052307 2022-05-29 16:36:17.169949
Epoch:[ 18 11 ] loss: 0.4505551755428314 2022-05-29 16:36:17.968836
Epoch:[ 18 12 ] loss: 0.44990405440330505 2022-05-29 16:36:18.768284
Epoch:[ 18 13 ] loss: 0.45286673307418823 2022-05-29 16:36:19.556904
Epoch:[ 18 14 ] loss: 0.44859105348587036 2022-05-29 16:36:20.344715
Epoch:[ 18 15 ] loss: 0.4501809775829315 2022-05-29 16:36:21.134022
Epoch:[ 18 16 ] loss: 0.4529207944869995 2022-05-29 16:36:30.130030
Epoch:[ 18 17 ] loss: 0.45278605818748474 2022-05-29 16:36:30.931087
Epoch:[ 18 18 ] loss: 0.4519122540950775 2022-05-29 16:36:31.730347
Epoch:[ 18 19 ] loss: 0.453670471906662 2022-05-29 16:36:32.526320
Training_Epoch:[ 18 ] Training_loss: 0.45100833028554915 2022-05-29 16:36:32.527126
learning rate:  0.00032
netparams have been saved once 18
val: 1 0.5267360210418701
val: 2 0.5306756496429443
val: 3 0.5029667019844055
val: 4 0.5264937281608582
val: 5 0.5294147729873657
val: 6 0.5104087591171265
val: 7 0.5248993039131165
val: 8 0.5297062993049622
val: 9 0.5213055610656738
val: 10 0.5098404884338379
val: 11 0.49990105628967285
val: 12 0.5216881632804871
val: 13 0.5085446238517761
val: 14 0.5122144818305969
val: 15 0.5150431990623474
val: 16 0.5078288912773132
val: 17 0.5136327147483826
val: 18 0.5262889266014099
val: 19 0.5371703505516052
val: 20 0.5200343728065491
val_Epoch:[ 18 ] val_loss: 0.5187397032976151 2022-05-29 16:36:38.568316
start training 2022-05-29 16:36:38.692051
Epoch:[ 19 0 ] loss: 0.4495062530040741 2022-05-29 16:37:06.357241
Epoch:[ 19 1 ] loss: 0.4526963233947754 2022-05-29 16:37:07.192186
Epoch:[ 19 2 ] loss: 0.45137205719947815 2022-05-29 16:37:07.979629
Epoch:[ 19 3 ] loss: 0.4474762976169586 2022-05-29 16:37:08.768271
Epoch:[ 19 4 ] loss: 0.446842759847641 2022-05-29 16:37:09.565733
Epoch:[ 19 5 ] loss: 0.44802817702293396 2022-05-29 16:37:10.352565
Epoch:[ 19 6 ] loss: 0.4530779719352722 2022-05-29 16:37:11.138785
Epoch:[ 19 7 ] loss: 0.4505554437637329 2022-05-29 16:37:11.926653
Epoch:[ 19 8 ] loss: 0.45121827721595764 2022-05-29 16:37:12.714092
Epoch:[ 19 9 ] loss: 0.4543847441673279 2022-05-29 16:37:13.502877
Epoch:[ 19 10 ] loss: 0.4518173933029175 2022-05-29 16:37:14.291356
Epoch:[ 19 11 ] loss: 0.45115357637405396 2022-05-29 16:37:15.080954
Epoch:[ 19 12 ] loss: 0.45206883549690247 2022-05-29 16:37:15.868153
Epoch:[ 19 13 ] loss: 0.45751333236694336 2022-05-29 16:37:16.665122
Epoch:[ 19 14 ] loss: 0.4511282444000244 2022-05-29 16:37:17.463510
Epoch:[ 19 15 ] loss: 0.4529748558998108 2022-05-29 16:37:18.263144
Epoch:[ 19 16 ] loss: 0.45084378123283386 2022-05-29 16:37:28.027949
Epoch:[ 19 17 ] loss: 0.4485228955745697 2022-05-29 16:37:28.818251
Epoch:[ 19 18 ] loss: 0.44547003507614136 2022-05-29 16:37:29.651474
Epoch:[ 19 19 ] loss: 0.4486210346221924 2022-05-29 16:37:30.464692
Training_Epoch:[ 19 ] Training_loss: 0.4507636144757271 2022-05-29 16:37:30.465857
learning rate:  0.00032
val: 1 0.5295723080635071
val: 2 0.5097160339355469
val: 3 0.5292665362358093
val: 4 0.5065800547599792
val: 5 0.5098415613174438
val: 6 0.5303135514259338
val: 7 0.5162648558616638
val: 8 0.534105658531189
val: 9 0.5209381580352783
val: 10 0.5118946433067322
val: 11 0.5238505005836487
val: 12 0.519568145275116
val: 13 0.5110522508621216
val: 14 0.5101990699768066
val: 15 0.5212221741676331
val: 16 0.5007633566856384
val: 17 0.5223966836929321
val: 18 0.5244724154472351
val: 19 0.5110572576522827
val: 20 0.5314693450927734
val_Epoch:[ 19 ] val_loss: 0.5187272280454636 2022-05-29 16:37:36.565232
start training 2022-05-29 16:37:36.668761
Epoch:[ 20 0 ] loss: 0.4494353234767914 2022-05-29 16:38:05.509853
Epoch:[ 20 1 ] loss: 0.4482557475566864 2022-05-29 16:38:06.290486
Epoch:[ 20 2 ] loss: 0.44858184456825256 2022-05-29 16:38:07.078718
Epoch:[ 20 3 ] loss: 0.44605451822280884 2022-05-29 16:38:07.858958
Epoch:[ 20 4 ] loss: 0.4495369493961334 2022-05-29 16:38:08.643220
Epoch:[ 20 5 ] loss: 0.448448121547699 2022-05-29 16:38:09.433283
Epoch:[ 20 6 ] loss: 0.44758298993110657 2022-05-29 16:38:10.223472
Epoch:[ 20 7 ] loss: 0.44844961166381836 2022-05-29 16:38:11.004506
Epoch:[ 20 8 ] loss: 0.4500698149204254 2022-05-29 16:38:11.782482
Epoch:[ 20 9 ] loss: 0.44806620478630066 2022-05-29 16:38:12.566878
Epoch:[ 20 10 ] loss: 0.4539896249771118 2022-05-29 16:38:13.350163
Epoch:[ 20 11 ] loss: 0.4490815997123718 2022-05-29 16:38:14.133391
Epoch:[ 20 12 ] loss: 0.4518192410469055 2022-05-29 16:38:14.914516
Epoch:[ 20 13 ] loss: 0.4464229345321655 2022-05-29 16:38:15.695440
Epoch:[ 20 14 ] loss: 0.44681838154792786 2022-05-29 16:38:16.485752
Epoch:[ 20 15 ] loss: 0.4481094479560852 2022-05-29 16:38:17.261632
Epoch:[ 20 16 ] loss: 0.44599223136901855 2022-05-29 16:38:27.172268
Epoch:[ 20 17 ] loss: 0.45230832695961 2022-05-29 16:38:27.966957
Epoch:[ 20 18 ] loss: 0.44758284091949463 2022-05-29 16:38:28.764096
Epoch:[ 20 19 ] loss: 0.4510124623775482 2022-05-29 16:38:29.540591
Training_Epoch:[ 20 ] Training_loss: 0.4488809108734131 2022-05-29 16:38:29.541469
learning rate:  0.00032
netparams have been saved once 20
val: 1 0.5012755393981934
val: 2 0.5266316533088684
val: 3 0.5309244990348816
val: 4 0.5211784839630127
val: 5 0.509932279586792
val: 6 0.5427460670471191
val: 7 0.532776415348053
val: 8 0.5081754922866821
val: 9 0.5143415927886963
val: 10 0.5095909833908081
val: 11 0.5069534182548523
val: 12 0.5132428407669067
val: 13 0.5187164545059204
val: 14 0.5264508724212646
val: 15 0.5417172312736511
val: 16 0.5242741107940674
val: 17 0.5121600031852722
val: 18 0.5157960653305054
val: 19 0.5201097726821899
val: 20 0.5036996603012085
val_Epoch:[ 20 ] val_loss: 0.5190346717834473 2022-05-29 16:38:35.454209
start training 2022-05-29 16:38:35.561501
Epoch:[ 21 0 ] loss: 0.45083293318748474 2022-05-29 16:39:04.179162
Epoch:[ 21 1 ] loss: 0.44403326511383057 2022-05-29 16:39:04.966480
Epoch:[ 21 2 ] loss: 0.4492461383342743 2022-05-29 16:39:05.751692
Epoch:[ 21 3 ] loss: 0.443877637386322 2022-05-29 16:39:06.548448
Epoch:[ 21 4 ] loss: 0.44895073771476746 2022-05-29 16:39:07.346246
Epoch:[ 21 5 ] loss: 0.4460320770740509 2022-05-29 16:39:08.133453
Epoch:[ 21 6 ] loss: 0.4421796500682831 2022-05-29 16:39:08.919801
Epoch:[ 21 7 ] loss: 0.4471578896045685 2022-05-29 16:39:09.718417
Epoch:[ 21 8 ] loss: 0.44957754015922546 2022-05-29 16:39:10.504968
Epoch:[ 21 9 ] loss: 0.44785642623901367 2022-05-29 16:39:11.288119
Epoch:[ 21 10 ] loss: 0.44311872124671936 2022-05-29 16:39:12.070858
Epoch:[ 21 11 ] loss: 0.4478507339954376 2022-05-29 16:39:12.857206
Epoch:[ 21 12 ] loss: 0.44658008217811584 2022-05-29 16:39:13.642404
Epoch:[ 21 13 ] loss: 0.4428829252719879 2022-05-29 16:39:14.428513
Epoch:[ 21 14 ] loss: 0.44768109917640686 2022-05-29 16:39:15.211821
Epoch:[ 21 15 ] loss: 0.44694000482559204 2022-05-29 16:39:15.993875
Epoch:[ 21 16 ] loss: 0.4448757469654083 2022-05-29 16:39:24.074321
Epoch:[ 21 17 ] loss: 0.4472632110118866 2022-05-29 16:39:24.861119
Epoch:[ 21 18 ] loss: 0.4439895749092102 2022-05-29 16:39:25.669239
Epoch:[ 21 19 ] loss: 0.44630947709083557 2022-05-29 16:39:26.450137
Training_Epoch:[ 21 ] Training_loss: 0.44636179357767103 2022-05-29 16:39:26.450860
learning rate:  0.00025600000000000004
val: 1 0.5132260322570801
val: 2 0.5137535929679871
val: 3 0.5267114043235779
val: 4 0.50932776927948
val: 5 0.5231490135192871
val: 6 0.5075345039367676
val: 7 0.5209710001945496
val: 8 0.5302732586860657
val: 9 0.5319564342498779
val: 10 0.4908651113510132
val: 11 0.5068321228027344
val: 12 0.5199021697044373
val: 13 0.5213239192962646
val: 14 0.5273190140724182
val: 15 0.5265839695930481
val: 16 0.5217326879501343
val: 17 0.5283743739128113
val: 18 0.514892578125
val: 19 0.5179582834243774
val: 20 0.5270928740501404
val_Epoch:[ 21 ] val_loss: 0.5189890056848526 2022-05-29 16:39:32.094838
start training 2022-05-29 16:39:32.224344
Epoch:[ 22 0 ] loss: 0.4415941834449768 2022-05-29 16:40:00.033769
Epoch:[ 22 1 ] loss: 0.44339755177497864 2022-05-29 16:40:00.842743
Epoch:[ 22 2 ] loss: 0.4477963447570801 2022-05-29 16:40:01.619997
Epoch:[ 22 3 ] loss: 0.4448181390762329 2022-05-29 16:40:02.397121
Epoch:[ 22 4 ] loss: 0.44390106201171875 2022-05-29 16:40:03.175271
Epoch:[ 22 5 ] loss: 0.4443230926990509 2022-05-29 16:40:03.956460
Epoch:[ 22 6 ] loss: 0.44421446323394775 2022-05-29 16:40:04.737771
Epoch:[ 22 7 ] loss: 0.44489040970802307 2022-05-29 16:40:05.530487
Epoch:[ 22 8 ] loss: 0.44945764541625977 2022-05-29 16:40:06.309398
Epoch:[ 22 9 ] loss: 0.44404515624046326 2022-05-29 16:40:07.087186
Epoch:[ 22 10 ] loss: 0.4479764997959137 2022-05-29 16:40:07.876899
Epoch:[ 22 11 ] loss: 0.4453466236591339 2022-05-29 16:40:08.654660
Epoch:[ 22 12 ] loss: 0.4428997337818146 2022-05-29 16:40:09.433244
Epoch:[ 22 13 ] loss: 0.4470863342285156 2022-05-29 16:40:10.215658
Epoch:[ 22 14 ] loss: 0.4427121579647064 2022-05-29 16:40:11.006460
Epoch:[ 22 15 ] loss: 0.44936802983283997 2022-05-29 16:40:11.784468
Epoch:[ 22 16 ] loss: 0.4417009651660919 2022-05-29 16:40:19.595451
Epoch:[ 22 17 ] loss: 0.44406500458717346 2022-05-29 16:40:20.386293
Epoch:[ 22 18 ] loss: 0.44273024797439575 2022-05-29 16:40:21.197998
Epoch:[ 22 19 ] loss: 0.44169437885284424 2022-05-29 16:40:21.975539
Training_Epoch:[ 22 ] Training_loss: 0.4447009012103081 2022-05-29 16:40:21.976362
learning rate:  0.00025600000000000004
netparams have been saved once 22
val: 1 0.4985538721084595
val: 2 0.5172384977340698
val: 3 0.5177949070930481
val: 4 0.5035710334777832
val: 5 0.516656219959259
val: 6 0.5269725918769836
val: 7 0.5218473672866821
val: 8 0.5188859701156616
val: 9 0.5179082155227661
val: 10 0.5287331342697144
val: 11 0.509774923324585
val: 12 0.5182183980941772
val: 13 0.5205226540565491
val: 14 0.5395402312278748
val: 15 0.5418194532394409
val: 16 0.502485990524292
val: 17 0.5355001091957092
val: 18 0.5121488571166992
val: 19 0.5219946503639221
val: 20 0.5236533880233765
val_Epoch:[ 22 ] val_loss: 0.5196910232305527 2022-05-29 16:40:27.704676
start training 2022-05-29 16:40:27.799452
Epoch:[ 23 0 ] loss: 0.4413801431655884 2022-05-29 16:40:53.798474
Epoch:[ 23 1 ] loss: 0.4419262707233429 2022-05-29 16:40:54.622276
Epoch:[ 23 2 ] loss: 0.4427531957626343 2022-05-29 16:40:55.400478
Epoch:[ 23 3 ] loss: 0.44558167457580566 2022-05-29 16:40:56.178144
Epoch:[ 23 4 ] loss: 0.44383901357650757 2022-05-29 16:40:56.956893
Epoch:[ 23 5 ] loss: 0.4433066248893738 2022-05-29 16:40:57.732571
Epoch:[ 23 6 ] loss: 0.44549694657325745 2022-05-29 16:40:58.512252
Epoch:[ 23 7 ] loss: 0.441609263420105 2022-05-29 16:40:59.303383
Epoch:[ 23 8 ] loss: 0.44274282455444336 2022-05-29 16:41:00.095368
Epoch:[ 23 9 ] loss: 0.44139400124549866 2022-05-29 16:41:00.873975
Epoch:[ 23 10 ] loss: 0.44486352801322937 2022-05-29 16:41:01.651857
Epoch:[ 23 11 ] loss: 0.44608941674232483 2022-05-29 16:41:02.429708
Epoch:[ 23 12 ] loss: 0.4444426894187927 2022-05-29 16:41:03.206171
Epoch:[ 23 13 ] loss: 0.4431118071079254 2022-05-29 16:41:03.986877
Epoch:[ 23 14 ] loss: 0.44604066014289856 2022-05-29 16:41:04.768305
Epoch:[ 23 15 ] loss: 0.44317197799682617 2022-05-29 16:41:05.558743
Epoch:[ 23 16 ] loss: 0.4461190700531006 2022-05-29 16:41:13.481223
Epoch:[ 23 17 ] loss: 0.44733017683029175 2022-05-29 16:41:14.273657
Epoch:[ 23 18 ] loss: 0.4463037848472595 2022-05-29 16:41:15.055401
Epoch:[ 23 19 ] loss: 0.4444587528705597 2022-05-29 16:41:15.832518
Training_Epoch:[ 23 ] Training_loss: 0.44409809112548826 2022-05-29 16:41:15.833327
learning rate:  0.00025600000000000004
val: 1 0.5120950937271118
val: 2 0.520632803440094
val: 3 0.5147358775138855
val: 4 0.5289244055747986
val: 5 0.5157722234725952
val: 6 0.5257283449172974
val: 7 0.5158449411392212
val: 8 0.5204679369926453
val: 9 0.518853485584259
val: 10 0.5264929533004761
val: 11 0.5393939018249512
val: 12 0.5280588269233704
val: 13 0.5180371403694153
val: 14 0.5239091515541077
val: 15 0.5167105793952942
val: 16 0.5160734057426453
val: 17 0.49934548139572144
val: 18 0.5280188918113708
val: 19 0.5224445462226868
val: 20 0.5060970783233643
val_Epoch:[ 23 ] val_loss: 0.5198818534612656 2022-05-29 16:41:21.809920
start training 2022-05-29 16:41:21.907845
Epoch:[ 24 0 ] loss: 0.4451289474964142 2022-05-29 16:41:49.133859
Epoch:[ 24 1 ] loss: 0.4420180320739746 2022-05-29 16:41:49.958352
Epoch:[ 24 2 ] loss: 0.4455140233039856 2022-05-29 16:41:50.781109
Epoch:[ 24 3 ] loss: 0.44243794679641724 2022-05-29 16:41:51.571279
Epoch:[ 24 4 ] loss: 0.44041961431503296 2022-05-29 16:41:52.351056
Epoch:[ 24 5 ] loss: 0.44407111406326294 2022-05-29 16:41:53.132077
Epoch:[ 24 6 ] loss: 0.44321539998054504 2022-05-29 16:41:53.906597
Epoch:[ 24 7 ] loss: 0.44654780626296997 2022-05-29 16:41:54.689715
Epoch:[ 24 8 ] loss: 0.4376021921634674 2022-05-29 16:41:55.469753
Epoch:[ 24 9 ] loss: 0.444539874792099 2022-05-29 16:41:56.248479
Epoch:[ 24 10 ] loss: 0.4469175338745117 2022-05-29 16:41:57.028693
Epoch:[ 24 11 ] loss: 0.44477379322052 2022-05-29 16:41:57.806656
Epoch:[ 24 12 ] loss: 0.44211718440055847 2022-05-29 16:41:58.591381
Epoch:[ 24 13 ] loss: 0.4415980279445648 2022-05-29 16:41:59.369964
Epoch:[ 24 14 ] loss: 0.44404885172843933 2022-05-29 16:42:00.162743
Epoch:[ 24 15 ] loss: 0.4429469108581543 2022-05-29 16:42:00.946106
Epoch:[ 24 16 ] loss: 0.44199809432029724 2022-05-29 16:42:10.875120
Epoch:[ 24 17 ] loss: 0.4437449872493744 2022-05-29 16:42:11.662058
Epoch:[ 24 18 ] loss: 0.4490427076816559 2022-05-29 16:42:12.460904
Epoch:[ 24 19 ] loss: 0.442322701215744 2022-05-29 16:42:13.253192
Training_Epoch:[ 24 ] Training_loss: 0.44355028718709943 2022-05-29 16:42:13.253937
learning rate:  0.00025600000000000004
netparams have been saved once 24
val: 1 0.501024603843689
val: 2 0.5184015035629272
val: 3 0.5224149823188782
val: 4 0.5427326560020447
val: 5 0.5132774710655212
val: 6 0.5084640979766846
val: 7 0.5155181288719177
val: 8 0.5000168085098267
val: 9 0.5249606966972351
val: 10 0.514140248298645
val: 11 0.5191048979759216
val: 12 0.5146790146827698
val: 13 0.5132147073745728
val: 14 0.5325194597244263
val: 15 0.5294979810714722
val: 16 0.5251619815826416
val: 17 0.5258992910385132
val: 18 0.5362238883972168
val: 19 0.526313304901123
val: 20 0.5126047134399414
val_Epoch:[ 24 ] val_loss: 0.5198085218667984 2022-05-29 16:42:19.339286
start training 2022-05-29 16:42:19.450841
Epoch:[ 25 0 ] loss: 0.44483432173728943 2022-05-29 16:42:48.184433
Epoch:[ 25 1 ] loss: 0.44101613759994507 2022-05-29 16:42:48.999812
Epoch:[ 25 2 ] loss: 0.4409677982330322 2022-05-29 16:42:49.795733
Epoch:[ 25 3 ] loss: 0.4402164816856384 2022-05-29 16:42:50.591505
Epoch:[ 25 4 ] loss: 0.4403378963470459 2022-05-29 16:42:51.376454
Epoch:[ 25 5 ] loss: 0.44306352734565735 2022-05-29 16:42:52.157127
Epoch:[ 25 6 ] loss: 0.43801212310791016 2022-05-29 16:42:52.936853
Epoch:[ 25 7 ] loss: 0.4461831748485565 2022-05-29 16:42:53.716440
Epoch:[ 25 8 ] loss: 0.4435245990753174 2022-05-29 16:42:54.501784
Epoch:[ 25 9 ] loss: 0.438148558139801 2022-05-29 16:42:55.283084
Epoch:[ 25 10 ] loss: 0.44157499074935913 2022-05-29 16:42:56.068906
Epoch:[ 25 11 ] loss: 0.4406130909919739 2022-05-29 16:42:56.851608
Epoch:[ 25 12 ] loss: 0.4441913664340973 2022-05-29 16:42:57.632568
Epoch:[ 25 13 ] loss: 0.44124817848205566 2022-05-29 16:42:58.425467
Epoch:[ 25 14 ] loss: 0.4393927752971649 2022-05-29 16:42:59.203851
Epoch:[ 25 15 ] loss: 0.44550061225891113 2022-05-29 16:42:59.988765
Epoch:[ 25 16 ] loss: 0.44514018297195435 2022-05-29 16:43:09.253420
Epoch:[ 25 17 ] loss: 0.43850621581077576 2022-05-29 16:43:10.046098
Epoch:[ 25 18 ] loss: 0.44289153814315796 2022-05-29 16:43:10.833347
Epoch:[ 25 19 ] loss: 0.440142959356308 2022-05-29 16:43:11.623824
Training_Epoch:[ 25 ] Training_loss: 0.4417753264307976 2022-05-29 16:43:11.624744
learning rate:  0.00025600000000000004
val: 1 0.548563539981842
val: 2 0.5419244766235352
val: 3 0.5365141034126282
val: 4 0.536693811416626
val: 5 0.5190192461013794
val: 6 0.5098230242729187
val: 7 0.5123313069343567
val: 8 0.5144994854927063
val: 9 0.5112956762313843
val: 10 0.5211337804794312
val: 11 0.5355443358421326
val: 12 0.5102409720420837
val: 13 0.5423433184623718
val: 14 0.5159344673156738
val: 15 0.5287443399429321
val: 16 0.5061132907867432
val: 17 0.5053746104240417
val: 18 0.5250060558319092
val: 19 0.5076208710670471
val: 20 0.5125692486763
val_Epoch:[ 25 ] val_loss: 0.5220644980669021 2022-05-29 16:43:17.636064
start training 2022-05-29 16:43:17.759615
Epoch:[ 26 0 ] loss: 0.43698981404304504 2022-05-29 16:43:45.261410
Epoch:[ 26 1 ] loss: 0.4394855797290802 2022-05-29 16:43:46.813834
Epoch:[ 26 2 ] loss: 0.44245007634162903 2022-05-29 16:43:47.590039
Epoch:[ 26 3 ] loss: 0.44028240442276 2022-05-29 16:43:48.370941
Epoch:[ 26 4 ] loss: 0.44211530685424805 2022-05-29 16:43:49.150647
Epoch:[ 26 5 ] loss: 0.43828633427619934 2022-05-29 16:43:49.928015
Epoch:[ 26 6 ] loss: 0.4417341351509094 2022-05-29 16:43:50.701667
Epoch:[ 26 7 ] loss: 0.44018322229385376 2022-05-29 16:43:51.476806
Epoch:[ 26 8 ] loss: 0.4402768909931183 2022-05-29 16:43:52.266413
Epoch:[ 26 9 ] loss: 0.43347427248954773 2022-05-29 16:43:53.049766
Epoch:[ 26 10 ] loss: 0.4412064552307129 2022-05-29 16:43:53.828197
Epoch:[ 26 11 ] loss: 0.4423849582672119 2022-05-29 16:43:54.611127
Epoch:[ 26 12 ] loss: 0.4396013915538788 2022-05-29 16:43:55.394376
Epoch:[ 26 13 ] loss: 0.44331011176109314 2022-05-29 16:43:56.180854
Epoch:[ 26 14 ] loss: 0.44601741433143616 2022-05-29 16:43:56.962753
Epoch:[ 26 15 ] loss: 0.4414128363132477 2022-05-29 16:43:57.756349
Epoch:[ 26 16 ] loss: 0.44466647505760193 2022-05-29 16:44:07.032155
Epoch:[ 26 17 ] loss: 0.43959495425224304 2022-05-29 16:44:08.676974
Epoch:[ 26 18 ] loss: 0.4431708753108978 2022-05-29 16:44:09.481471
Epoch:[ 26 19 ] loss: 0.4441774785518646 2022-05-29 16:44:10.265254
Training_Epoch:[ 26 ] Training_loss: 0.44104104936122895 2022-05-29 16:44:10.265916
learning rate:  0.00025600000000000004
netparams have been saved once 26
val: 1 0.5161735415458679
val: 2 0.5094254612922668
val: 3 0.5246925354003906
val: 4 0.522379994392395
val: 5 0.5169722437858582
val: 6 0.526117742061615
val: 7 0.5170496106147766
val: 8 0.49955132603645325
val: 9 0.5146467089653015
val: 10 0.5373668074607849
val: 11 0.5171958804130554
val: 12 0.509304940700531
val: 13 0.514678418636322
val: 14 0.5163989663124084
val: 15 0.526794970035553
val: 16 0.5228042602539062
val: 17 0.5026916265487671
val: 18 0.5154523253440857
val: 19 0.5219054818153381
val: 20 0.5154003500938416
val_Epoch:[ 26 ] val_loss: 0.5173501595854759 2022-05-29 16:44:15.729459
start training 2022-05-29 16:44:15.831033
Epoch:[ 27 0 ] loss: 0.44012656807899475 2022-05-29 16:44:41.785802
Epoch:[ 27 1 ] loss: 0.44030144810676575 2022-05-29 16:44:42.610255
Epoch:[ 27 2 ] loss: 0.4378805160522461 2022-05-29 16:44:43.387264
Epoch:[ 27 3 ] loss: 0.44015854597091675 2022-05-29 16:44:44.168959
Epoch:[ 27 4 ] loss: 0.4388315677642822 2022-05-29 16:44:44.958590
Epoch:[ 27 5 ] loss: 0.4405260980129242 2022-05-29 16:44:45.751121
Epoch:[ 27 6 ] loss: 0.43912169337272644 2022-05-29 16:44:46.531528
Epoch:[ 27 7 ] loss: 0.44182974100112915 2022-05-29 16:44:47.319621
Epoch:[ 27 8 ] loss: 0.43831709027290344 2022-05-29 16:44:48.097664
Epoch:[ 27 9 ] loss: 0.4407338798046112 2022-05-29 16:44:48.872132
Epoch:[ 27 10 ] loss: 0.44195234775543213 2022-05-29 16:44:49.651333
Epoch:[ 27 11 ] loss: 0.44238993525505066 2022-05-29 16:44:50.428231
Epoch:[ 27 12 ] loss: 0.44409075379371643 2022-05-29 16:44:51.208308
Epoch:[ 27 13 ] loss: 0.4401225745677948 2022-05-29 16:44:51.985355
Epoch:[ 27 14 ] loss: 0.4398839771747589 2022-05-29 16:44:52.764396
Epoch:[ 27 15 ] loss: 0.43974268436431885 2022-05-29 16:44:53.541707
Epoch:[ 27 16 ] loss: 0.4429939091205597 2022-05-29 16:45:01.505064
Epoch:[ 27 17 ] loss: 0.4413774907588959 2022-05-29 16:45:02.283559
Epoch:[ 27 18 ] loss: 0.4416559934616089 2022-05-29 16:45:03.065284
Epoch:[ 27 19 ] loss: 0.44357624650001526 2022-05-29 16:45:03.833576
Training_Epoch:[ 27 ] Training_loss: 0.44078065305948255 2022-05-29 16:45:03.834515
learning rate:  0.00025600000000000004
val: 1 0.5116495490074158
val: 2 0.5314139127731323
val: 3 0.515870213508606
val: 4 0.496985524892807
val: 5 0.5194615125656128
val: 6 0.522697925567627
val: 7 0.5229535698890686
val: 8 0.5082000494003296
val: 9 0.5241397619247437
val: 10 0.5031726956367493
val: 11 0.5218958854675293
val: 12 0.5221779942512512
val: 13 0.5199829936027527
val: 14 0.5317676067352295
val: 15 0.5192080736160278
val: 16 0.541111946105957
val: 17 0.5248218178749084
val: 18 0.5259014964103699
val: 19 0.5245257616043091
val: 20 0.5265752673149109
val_Epoch:[ 27 ] val_loss: 0.5207256779074669 2022-05-29 16:45:09.351754
start training 2022-05-29 16:45:09.458184
Epoch:[ 28 0 ] loss: 0.4412514269351959 2022-05-29 16:45:32.713857
Epoch:[ 28 1 ] loss: 0.43934282660484314 2022-05-29 16:45:33.530633
Epoch:[ 28 2 ] loss: 0.44168734550476074 2022-05-29 16:45:34.308560
Epoch:[ 28 3 ] loss: 0.4363004267215729 2022-05-29 16:45:35.083837
Epoch:[ 28 4 ] loss: 0.441119909286499 2022-05-29 16:45:35.861961
Epoch:[ 28 5 ] loss: 0.43450164794921875 2022-05-29 16:45:36.641223
Epoch:[ 28 6 ] loss: 0.4438926577568054 2022-05-29 16:45:37.415695
Epoch:[ 28 7 ] loss: 0.4411006569862366 2022-05-29 16:45:38.191504
Epoch:[ 28 8 ] loss: 0.4381905496120453 2022-05-29 16:45:38.966065
Epoch:[ 28 9 ] loss: 0.4415282905101776 2022-05-29 16:45:39.754874
Epoch:[ 28 10 ] loss: 0.4420774579048157 2022-05-29 16:45:40.529999
Epoch:[ 28 11 ] loss: 0.44653069972991943 2022-05-29 16:45:41.307744
Epoch:[ 28 12 ] loss: 0.4401893615722656 2022-05-29 16:45:42.086533
Epoch:[ 28 13 ] loss: 0.44364064931869507 2022-05-29 16:45:42.866602
Epoch:[ 28 14 ] loss: 0.4388376474380493 2022-05-29 16:45:43.655479
Epoch:[ 28 15 ] loss: 0.4472866356372833 2022-05-29 16:45:44.428924
Epoch:[ 28 16 ] loss: 0.44221967458724976 2022-05-29 16:45:52.135728
Epoch:[ 28 17 ] loss: 0.4393317997455597 2022-05-29 16:45:52.921500
Epoch:[ 28 18 ] loss: 0.44219034910202026 2022-05-29 16:45:53.702343
Epoch:[ 28 19 ] loss: 0.4402312636375427 2022-05-29 16:45:54.479827
Training_Epoch:[ 28 ] Training_loss: 0.4410725638270378 2022-05-29 16:45:54.480663
learning rate:  0.00025600000000000004
netparams have been saved once 28
val: 1 0.522998571395874
val: 2 0.5131356120109558
val: 3 0.5140098929405212
val: 4 0.5164995193481445
val: 5 0.5173817276954651
val: 6 0.5209357142448425
val: 7 0.5296304821968079
val: 8 0.5176304578781128
val: 9 0.5194964408874512
val: 10 0.5225117206573486
val: 11 0.5290575623512268
val: 12 0.5129650235176086
val: 13 0.528167188167572
val: 14 0.5051745772361755
val: 15 0.5297762155532837
val: 16 0.509502112865448
val: 17 0.5129549503326416
val: 18 0.5135514140129089
val: 19 0.5429990291595459
val: 20 0.5127224922180176
val_Epoch:[ 28 ] val_loss: 0.5195550352334977 2022-05-29 16:45:59.847569
start training 2022-05-29 16:45:59.949572
Epoch:[ 29 0 ] loss: 0.4389256536960602 2022-05-29 16:46:23.581338
Epoch:[ 29 1 ] loss: 0.4359378218650818 2022-05-29 16:46:24.359445
Epoch:[ 29 2 ] loss: 0.4372250735759735 2022-05-29 16:46:25.145954
Epoch:[ 29 3 ] loss: 0.4405340254306793 2022-05-29 16:46:25.923063
Epoch:[ 29 4 ] loss: 0.43964874744415283 2022-05-29 16:46:26.709033
Epoch:[ 29 5 ] loss: 0.4411488175392151 2022-05-29 16:46:27.498710
Epoch:[ 29 6 ] loss: 0.44224104285240173 2022-05-29 16:46:28.275214
Epoch:[ 29 7 ] loss: 0.4354998469352722 2022-05-29 16:46:29.054006
Epoch:[ 29 8 ] loss: 0.44172203540802 2022-05-29 16:46:29.831870
Epoch:[ 29 9 ] loss: 0.4371265172958374 2022-05-29 16:46:30.607365
Epoch:[ 29 10 ] loss: 0.44185590744018555 2022-05-29 16:46:31.383268
Epoch:[ 29 11 ] loss: 0.4371936023235321 2022-05-29 16:46:32.156861
Epoch:[ 29 12 ] loss: 0.4417465627193451 2022-05-29 16:46:32.933629
Epoch:[ 29 13 ] loss: 0.4363192021846771 2022-05-29 16:46:33.710864
Epoch:[ 29 14 ] loss: 0.43973663449287415 2022-05-29 16:46:34.487460
Epoch:[ 29 15 ] loss: 0.43992793560028076 2022-05-29 16:46:35.262625
Epoch:[ 29 16 ] loss: 0.44001466035842896 2022-05-29 16:46:41.949823
Epoch:[ 29 17 ] loss: 0.43927252292633057 2022-05-29 16:46:42.713190
Epoch:[ 29 18 ] loss: 0.44011715054512024 2022-05-29 16:46:43.481174
Epoch:[ 29 19 ] loss: 0.43924036622047424 2022-05-29 16:46:44.257289
Training_Epoch:[ 29 ] Training_loss: 0.43927170634269713 2022-05-29 16:46:44.258096
learning rate:  0.00025600000000000004
val: 1 0.5176218748092651
val: 2 0.519284188747406
val: 3 0.512146532535553
val: 4 0.5303494930267334
val: 5 0.5413696765899658
val: 6 0.5093895196914673
val: 7 0.5323683619499207
val: 8 0.5271349549293518
val: 9 0.5282726883888245
val: 10 0.5190761685371399
val: 11 0.5335596799850464
val: 12 0.5268707871437073
val: 13 0.5130799412727356
val: 14 0.5190122127532959
val: 15 0.5206205248832703
val: 16 0.5293096899986267
val: 17 0.5010734796524048
val: 18 0.5054386258125305
val: 19 0.5211034417152405
val: 20 0.5078526735305786
val_Epoch:[ 29 ] val_loss: 0.5207467257976532 2022-05-29 16:46:49.636608
start training 2022-05-29 16:46:49.733921
Epoch:[ 30 0 ] loss: 0.43901631236076355 2022-05-29 16:47:13.502042
Epoch:[ 30 1 ] loss: 0.43928030133247375 2022-05-29 16:47:14.279980
Epoch:[ 30 2 ] loss: 0.43560463190078735 2022-05-29 16:47:15.066065
Epoch:[ 30 3 ] loss: 0.4350590705871582 2022-05-29 16:47:15.841690
Epoch:[ 30 4 ] loss: 0.4370739161968231 2022-05-29 16:47:16.617883
Epoch:[ 30 5 ] loss: 0.4380527138710022 2022-05-29 16:47:17.392290
Epoch:[ 30 6 ] loss: 0.43560791015625 2022-05-29 16:47:18.168353
Epoch:[ 30 7 ] loss: 0.43976953625679016 2022-05-29 16:47:18.958912
Epoch:[ 30 8 ] loss: 0.44030508399009705 2022-05-29 16:47:19.745281
Epoch:[ 30 9 ] loss: 0.43958303332328796 2022-05-29 16:47:20.519522
Epoch:[ 30 10 ] loss: 0.43864312767982483 2022-05-29 16:47:21.293961
Epoch:[ 30 11 ] loss: 0.43690329790115356 2022-05-29 16:47:22.071664
Epoch:[ 30 12 ] loss: 0.4412814974784851 2022-05-29 16:47:22.845678
Epoch:[ 30 13 ] loss: 0.441536545753479 2022-05-29 16:47:23.622281
Epoch:[ 30 14 ] loss: 0.4382375478744507 2022-05-29 16:47:24.399766
Epoch:[ 30 15 ] loss: 0.43470314145088196 2022-05-29 16:47:25.177644
Epoch:[ 30 16 ] loss: 0.43355271220207214 2022-05-29 16:47:31.999942
Epoch:[ 30 17 ] loss: 0.4362236559391022 2022-05-29 16:47:32.764225
Epoch:[ 30 18 ] loss: 0.43801799416542053 2022-05-29 16:47:33.545519
Epoch:[ 30 19 ] loss: 0.4396378695964813 2022-05-29 16:47:34.320908
Training_Epoch:[ 30 ] Training_loss: 0.4379044950008392 2022-05-29 16:47:34.321880
learning rate:  0.00025600000000000004
netparams have been saved once 30
val: 1 0.5324028730392456
val: 2 0.5110737085342407
val: 3 0.530855119228363
val: 4 0.5111508965492249
val: 5 0.5115506052970886
val: 6 0.5166003704071045
val: 7 0.5335558652877808
val: 8 0.49097001552581787
val: 9 0.5022099018096924
val: 10 0.5301457047462463
val: 11 0.5395501255989075
val: 12 0.514489471912384
val: 13 0.5368833541870117
val: 14 0.5312610864639282
val: 15 0.5332104563713074
val: 16 0.5266268253326416
val: 17 0.5150173306465149
val: 18 0.5312057137489319
val: 19 0.5171670317649841
val: 20 0.5260204672813416
val_Epoch:[ 30 ] val_loss: 0.5220973461866378 2022-05-29 16:47:39.836605
start training 2022-05-29 16:47:39.934626
Epoch:[ 31 0 ] loss: 0.43603843450546265 2022-05-29 16:48:02.533277
Epoch:[ 31 1 ] loss: 0.4356677532196045 2022-05-29 16:48:03.367771
Epoch:[ 31 2 ] loss: 0.43489348888397217 2022-05-29 16:48:04.145399
Epoch:[ 31 3 ] loss: 0.43508484959602356 2022-05-29 16:48:04.922353
Epoch:[ 31 4 ] loss: 0.43558844923973083 2022-05-29 16:48:05.696468
Epoch:[ 31 5 ] loss: 0.43313518166542053 2022-05-29 16:48:06.473125
Epoch:[ 31 6 ] loss: 0.4370785057544708 2022-05-29 16:48:07.244920
Epoch:[ 31 7 ] loss: 0.4410814642906189 2022-05-29 16:48:08.022414
Epoch:[ 31 8 ] loss: 0.4390873610973358 2022-05-29 16:48:08.811754
Epoch:[ 31 9 ] loss: 0.43576735258102417 2022-05-29 16:48:09.590257
Epoch:[ 31 10 ] loss: 0.4323825240135193 2022-05-29 16:48:10.378188
Epoch:[ 31 11 ] loss: 0.43461164832115173 2022-05-29 16:48:11.151879
Epoch:[ 31 12 ] loss: 0.4335591793060303 2022-05-29 16:48:11.929401
Epoch:[ 31 13 ] loss: 0.43613675236701965 2022-05-29 16:48:12.703985
Epoch:[ 31 14 ] loss: 0.43428412079811096 2022-05-29 16:48:13.482324
Epoch:[ 31 15 ] loss: 0.4318658411502838 2022-05-29 16:48:14.258539
Epoch:[ 31 16 ] loss: 0.4316253364086151 2022-05-29 16:48:21.925266
Epoch:[ 31 17 ] loss: 0.4364759922027588 2022-05-29 16:48:22.713837
Epoch:[ 31 18 ] loss: 0.43619516491889954 2022-05-29 16:48:23.503104
Epoch:[ 31 19 ] loss: 0.4356994926929474 2022-05-29 16:48:24.277717
Training_Epoch:[ 31 ] Training_loss: 0.43531294465065 2022-05-29 16:48:24.278405
learning rate:  0.00020480000000000004
val: 1 0.5118049383163452
val: 2 0.5360679030418396
val: 3 0.5061840415000916
val: 4 0.5269606113433838
val: 5 0.5269176959991455
val: 6 0.519340991973877
val: 7 0.5298482179641724
val: 8 0.5167562961578369
val: 9 0.5188812613487244
val: 10 0.5174829363822937
val: 11 0.5289957523345947
val: 12 0.5249125957489014
val: 13 0.5185107588768005
val: 14 0.5164574384689331
val: 15 0.5176693797111511
val: 16 0.5079563856124878
val: 17 0.5240947008132935
val: 18 0.5216740965843201
val: 19 0.5379413962364197
val: 20 0.5107665061950684
val_Epoch:[ 31 ] val_loss: 0.520961195230484 2022-05-29 16:48:29.511170
start training 2022-05-29 16:48:29.607740
Epoch:[ 32 0 ] loss: 0.43474265933036804 2022-05-29 16:48:52.079456
Epoch:[ 32 1 ] loss: 0.43495631217956543 2022-05-29 16:48:52.935124
Epoch:[ 32 2 ] loss: 0.4300023019313812 2022-05-29 16:48:53.714081
Epoch:[ 32 3 ] loss: 0.43385061621665955 2022-05-29 16:48:54.489800
Epoch:[ 32 4 ] loss: 0.43326184153556824 2022-05-29 16:48:55.267082
Epoch:[ 32 5 ] loss: 0.434571772813797 2022-05-29 16:48:56.053879
Epoch:[ 32 6 ] loss: 0.43439459800720215 2022-05-29 16:48:56.828527
Epoch:[ 32 7 ] loss: 0.43900808691978455 2022-05-29 16:48:57.602672
Epoch:[ 32 8 ] loss: 0.4343756139278412 2022-05-29 16:48:58.377885
Epoch:[ 32 9 ] loss: 0.43759262561798096 2022-05-29 16:48:59.167495
Epoch:[ 32 10 ] loss: 0.43279120326042175 2022-05-29 16:48:59.943387
Epoch:[ 32 11 ] loss: 0.4337407648563385 2022-05-29 16:49:00.718874
Epoch:[ 32 12 ] loss: 0.4377865493297577 2022-05-29 16:49:01.491270
Epoch:[ 32 13 ] loss: 0.43359988927841187 2022-05-29 16:49:02.268799
Epoch:[ 32 14 ] loss: 0.43680813908576965 2022-05-29 16:49:03.053261
Epoch:[ 32 15 ] loss: 0.4333345890045166 2022-05-29 16:49:03.831049
Epoch:[ 32 16 ] loss: 0.4350101351737976 2022-05-29 16:49:11.643431
Epoch:[ 32 17 ] loss: 0.43125346302986145 2022-05-29 16:49:12.429895
Epoch:[ 32 18 ] loss: 0.4326845407485962 2022-05-29 16:49:13.223112
Epoch:[ 32 19 ] loss: 0.4346337616443634 2022-05-29 16:49:13.996692
Training_Epoch:[ 32 ] Training_loss: 0.43441997319459913 2022-05-29 16:49:13.997419
learning rate:  0.00020480000000000004
netparams have been saved once 32
val: 1 0.5262291431427002
val: 2 0.5231955647468567
val: 3 0.5395708680152893
val: 4 0.5100167393684387
val: 5 0.5130825638771057
val: 6 0.5375009775161743
val: 7 0.5066542029380798
val: 8 0.5300743579864502
val: 9 0.535687267780304
val: 10 0.506483793258667
val: 11 0.5204383730888367
val: 12 0.516801655292511
val: 13 0.5236398577690125
val: 14 0.5035873651504517
val: 15 0.5190132856369019
val: 16 0.5271815657615662
val: 17 0.5226945877075195
val: 18 0.5088309049606323
val: 19 0.5263530611991882
val: 20 0.5261585712432861
val_Epoch:[ 32 ] val_loss: 0.5211597353219986 2022-05-29 16:49:19.404850
start training 2022-05-29 16:49:19.498770
Epoch:[ 33 0 ] loss: 0.4325591027736664 2022-05-29 16:49:41.570879
Epoch:[ 33 1 ] loss: 0.4329530894756317 2022-05-29 16:49:42.494124
Epoch:[ 33 2 ] loss: 0.4329668879508972 2022-05-29 16:49:43.296558
Epoch:[ 33 3 ] loss: 0.43060311675071716 2022-05-29 16:49:44.075413
Epoch:[ 33 4 ] loss: 0.43265607953071594 2022-05-29 16:49:44.863641
Epoch:[ 33 5 ] loss: 0.4310823976993561 2022-05-29 16:49:45.650982
Epoch:[ 33 6 ] loss: 0.43322908878326416 2022-05-29 16:49:46.424146
Epoch:[ 33 7 ] loss: 0.4344325661659241 2022-05-29 16:49:47.198614
Epoch:[ 33 8 ] loss: 0.43485164642333984 2022-05-29 16:49:47.973064
Epoch:[ 33 9 ] loss: 0.4354398548603058 2022-05-29 16:49:48.751718
Epoch:[ 33 10 ] loss: 0.43585607409477234 2022-05-29 16:49:49.530587
Epoch:[ 33 11 ] loss: 0.43342283368110657 2022-05-29 16:49:50.318328
Epoch:[ 33 12 ] loss: 0.43457773327827454 2022-05-29 16:49:51.095901
Epoch:[ 33 13 ] loss: 0.4361174404621124 2022-05-29 16:49:51.871494
Epoch:[ 33 14 ] loss: 0.43543440103530884 2022-05-29 16:49:52.646736
Epoch:[ 33 15 ] loss: 0.43361136317253113 2022-05-29 16:49:53.420428
Epoch:[ 33 16 ] loss: 0.43541860580444336 2022-05-29 16:50:01.307213
Epoch:[ 33 17 ] loss: 0.42799410223960876 2022-05-29 16:50:02.084203
Epoch:[ 33 18 ] loss: 0.4352753758430481 2022-05-29 16:50:02.873523
Epoch:[ 33 19 ] loss: 0.43583351373672485 2022-05-29 16:50:03.659876
Training_Epoch:[ 33 ] Training_loss: 0.43371576368808745 2022-05-29 16:50:03.660586
learning rate:  0.00020480000000000004
val: 1 0.5338640809059143
val: 2 0.5099057555198669
val: 3 0.5277237892150879
val: 4 0.5332999229431152
val: 5 0.5412667393684387
val: 6 0.5253355503082275
val: 7 0.5175714492797852
val: 8 0.5019652843475342
val: 9 0.5186662673950195
val: 10 0.5256485939025879
val: 11 0.5326176881790161
val: 12 0.5283056497573853
val: 13 0.5284527540206909
val: 14 0.5226017832756042
val: 15 0.5226840376853943
val: 16 0.5513026714324951
val: 17 0.532034695148468
val: 18 0.5155768990516663
val: 19 0.5291888117790222
val: 20 0.523833692073822
val_Epoch:[ 33 ] val_loss: 0.5260923057794571 2022-05-29 16:50:08.909228
start training 2022-05-29 16:50:09.004026
Epoch:[ 34 0 ] loss: 0.4287809133529663 2022-05-29 16:50:32.533991
Epoch:[ 34 1 ] loss: 0.4324270784854889 2022-05-29 16:50:33.322370
Epoch:[ 34 2 ] loss: 0.4322671592235565 2022-05-29 16:50:34.094413
Epoch:[ 34 3 ] loss: 0.43584826588630676 2022-05-29 16:50:34.871406
Epoch:[ 34 4 ] loss: 0.43008798360824585 2022-05-29 16:50:35.660361
Epoch:[ 34 5 ] loss: 0.431429922580719 2022-05-29 16:50:36.439591
Epoch:[ 34 6 ] loss: 0.4320663809776306 2022-05-29 16:50:37.215550
Epoch:[ 34 7 ] loss: 0.43093928694725037 2022-05-29 16:50:37.989444
Epoch:[ 34 8 ] loss: 0.43332573771476746 2022-05-29 16:50:38.762665
Epoch:[ 34 9 ] loss: 0.43962815403938293 2022-05-29 16:50:39.536798
Epoch:[ 34 10 ] loss: 0.43212267756462097 2022-05-29 16:50:40.327078
Epoch:[ 34 11 ] loss: 0.4369080066680908 2022-05-29 16:50:41.103635
Epoch:[ 34 12 ] loss: 0.43240886926651 2022-05-29 16:50:41.881806
Epoch:[ 34 13 ] loss: 0.4334365129470825 2022-05-29 16:50:42.656948
Epoch:[ 34 14 ] loss: 0.4305337071418762 2022-05-29 16:50:43.431155
Epoch:[ 34 15 ] loss: 0.4303324818611145 2022-05-29 16:50:44.203091
Epoch:[ 34 16 ] loss: 0.439775288105011 2022-05-29 16:50:51.147520
Epoch:[ 34 17 ] loss: 0.43370965123176575 2022-05-29 16:50:51.924207
Epoch:[ 34 18 ] loss: 0.4327866733074188 2022-05-29 16:50:52.716950
Epoch:[ 34 19 ] loss: 0.4360302984714508 2022-05-29 16:50:53.507262
Training_Epoch:[ 34 ] Training_loss: 0.4332422524690628 2022-05-29 16:50:53.507988
learning rate:  0.00020480000000000004
netparams have been saved once 34
val: 1 0.5094653367996216
val: 2 0.5327964425086975
val: 3 0.5309547185897827
val: 4 0.5335464477539062
val: 5 0.5214669108390808
val: 6 0.5123031735420227
val: 7 0.53513503074646
val: 8 0.5181344747543335
val: 9 0.5201448798179626
val: 10 0.5166892409324646
val: 11 0.5073079466819763
val: 12 0.5082150101661682
val: 13 0.5176071524620056
val: 14 0.5295879244804382
val: 15 0.5314615964889526
val: 16 0.5198389291763306
val: 17 0.4933646023273468
val: 18 0.5172080993652344
val: 19 0.5188820958137512
val: 20 0.5270082950592041
val_Epoch:[ 34 ] val_loss: 0.5200559154152871 2022-05-29 16:50:58.865883
start training 2022-05-29 16:50:58.968790
Epoch:[ 35 0 ] loss: 0.4299423098564148 2022-05-29 16:51:23.463444
Epoch:[ 35 1 ] loss: 0.4342699944972992 2022-05-29 16:51:24.241168
Epoch:[ 35 2 ] loss: 0.43333396315574646 2022-05-29 16:51:25.017300
Epoch:[ 35 3 ] loss: 0.43129539489746094 2022-05-29 16:51:25.796399
Epoch:[ 35 4 ] loss: 0.430990606546402 2022-05-29 16:51:26.563043
Epoch:[ 35 5 ] loss: 0.43133947253227234 2022-05-29 16:51:27.344119
Epoch:[ 35 6 ] loss: 0.4354587197303772 2022-05-29 16:51:28.125523
Epoch:[ 35 7 ] loss: 0.4336431324481964 2022-05-29 16:51:28.891064
Epoch:[ 35 8 ] loss: 0.4296453595161438 2022-05-29 16:51:29.669518
Epoch:[ 35 9 ] loss: 0.43227455019950867 2022-05-29 16:51:30.448921
Epoch:[ 35 10 ] loss: 0.4306829869747162 2022-05-29 16:51:31.226140
Epoch:[ 35 11 ] loss: 0.4319459795951843 2022-05-29 16:51:32.004721
Epoch:[ 35 12 ] loss: 0.4348472058773041 2022-05-29 16:51:32.784206
Epoch:[ 35 13 ] loss: 0.4289796054363251 2022-05-29 16:51:33.561974
Epoch:[ 35 14 ] loss: 0.4332943856716156 2022-05-29 16:51:34.328592
Epoch:[ 35 15 ] loss: 0.42965009808540344 2022-05-29 16:51:35.105189
Epoch:[ 35 16 ] loss: 0.43412917852401733 2022-05-29 16:51:41.839033
Epoch:[ 35 17 ] loss: 0.432409405708313 2022-05-29 16:51:42.602737
Epoch:[ 35 18 ] loss: 0.43628087639808655 2022-05-29 16:51:43.386449
Epoch:[ 35 19 ] loss: 0.4341967701911926 2022-05-29 16:51:44.163689
Training_Epoch:[ 35 ] Training_loss: 0.432430499792099 2022-05-29 16:51:44.164454
learning rate:  0.00020480000000000004
val: 1 0.5264155268669128
val: 2 0.5140024423599243
val: 3 0.5180598497390747
val: 4 0.5088427662849426
val: 5 0.5167346596717834
val: 6 0.5050057172775269
val: 7 0.5383802652359009
val: 8 0.5243291854858398
val: 9 0.5201486349105835
val: 10 0.5036191344261169
val: 11 0.5277081727981567
val: 12 0.5351446270942688
val: 13 0.5229882001876831
val: 14 0.5215855240821838
val: 15 0.5122685432434082
val: 16 0.5322405099868774
val: 17 0.519269585609436
val: 18 0.5308387875556946
val: 19 0.5211247205734253
val: 20 0.5271119475364685
val_Epoch:[ 35 ] val_loss: 0.5212909400463104 2022-05-29 16:51:49.510122
start training 2022-05-29 16:51:49.607551
Epoch:[ 36 0 ] loss: 0.43370455503463745 2022-05-29 16:52:13.411491
Epoch:[ 36 1 ] loss: 0.42908796668052673 2022-05-29 16:52:14.188021
Epoch:[ 36 2 ] loss: 0.4305729568004608 2022-05-29 16:52:14.962497
Epoch:[ 36 3 ] loss: 0.43284210562705994 2022-05-29 16:52:15.738159
Epoch:[ 36 4 ] loss: 0.4305689036846161 2022-05-29 16:52:16.512996
Epoch:[ 36 5 ] loss: 0.430319219827652 2022-05-29 16:52:17.279292
Epoch:[ 36 6 ] loss: 0.4330083429813385 2022-05-29 16:52:18.058240
Epoch:[ 36 7 ] loss: 0.43261709809303284 2022-05-29 16:52:18.835087
Epoch:[ 36 8 ] loss: 0.4312317669391632 2022-05-29 16:52:19.602524
Epoch:[ 36 9 ] loss: 0.429647296667099 2022-05-29 16:52:20.379550
Epoch:[ 36 10 ] loss: 0.4327036440372467 2022-05-29 16:52:21.153438
Epoch:[ 36 11 ] loss: 0.42750096321105957 2022-05-29 16:52:21.929773
Epoch:[ 36 12 ] loss: 0.42974764108657837 2022-05-29 16:52:22.696106
Epoch:[ 36 13 ] loss: 0.4290521442890167 2022-05-29 16:52:23.475588
Epoch:[ 36 14 ] loss: 0.430084764957428 2022-05-29 16:52:24.254822
Epoch:[ 36 15 ] loss: 0.4317857027053833 2022-05-29 16:52:25.032734
Epoch:[ 36 16 ] loss: 0.4320714473724365 2022-05-29 16:52:32.165573
Epoch:[ 36 17 ] loss: 0.43383753299713135 2022-05-29 16:52:32.942543
Epoch:[ 36 18 ] loss: 0.4342159032821655 2022-05-29 16:52:33.709127
Epoch:[ 36 19 ] loss: 0.4322075843811035 2022-05-29 16:52:34.486974
Training_Epoch:[ 36 ] Training_loss: 0.4313403770327568 2022-05-29 16:52:34.487839
learning rate:  0.00020480000000000004
netparams have been saved once 36
val: 1 0.519408106803894
val: 2 0.5307847857475281
val: 3 0.5272064805030823
val: 4 0.5349650979042053
val: 5 0.511082112789154
val: 6 0.5230228900909424
val: 7 0.5498499870300293
val: 8 0.5245992541313171
val: 9 0.5026912689208984
val: 10 0.5152894854545593
val: 11 0.519750714302063
val: 12 0.5471158027648926
val: 13 0.5266144871711731
val: 14 0.5207990407943726
val: 15 0.5347306132316589
val: 16 0.5084867477416992
val: 17 0.5376607179641724
val: 18 0.5008677840232849
val: 19 0.5187180042266846
val: 20 0.5115211009979248
val_Epoch:[ 36 ] val_loss: 0.5232582241296768 2022-05-29 16:52:40.003275
start training 2022-05-29 16:52:40.101818
Epoch:[ 37 0 ] loss: 0.43150296807289124 2022-05-29 16:53:03.133050
Epoch:[ 37 1 ] loss: 0.4280031621456146 2022-05-29 16:53:03.980733
Epoch:[ 37 2 ] loss: 0.4295150339603424 2022-05-29 16:53:04.754116
Epoch:[ 37 3 ] loss: 0.42924797534942627 2022-05-29 16:53:05.528510
Epoch:[ 37 4 ] loss: 0.4311147630214691 2022-05-29 16:53:06.305764
Epoch:[ 37 5 ] loss: 0.42897453904151917 2022-05-29 16:53:07.079788
Epoch:[ 37 6 ] loss: 0.4309596121311188 2022-05-29 16:53:07.857850
Epoch:[ 37 7 ] loss: 0.43088799715042114 2022-05-29 16:53:08.646612
Epoch:[ 37 8 ] loss: 0.4342207610607147 2022-05-29 16:53:09.435430
Epoch:[ 37 9 ] loss: 0.42772912979125977 2022-05-29 16:53:10.209777
Epoch:[ 37 10 ] loss: 0.4282993674278259 2022-05-29 16:53:10.984572
Epoch:[ 37 11 ] loss: 0.43209829926490784 2022-05-29 16:53:11.757745
Epoch:[ 37 12 ] loss: 0.4337080121040344 2022-05-29 16:53:12.532129
Epoch:[ 37 13 ] loss: 0.4330982267856598 2022-05-29 16:53:13.310330
Epoch:[ 37 14 ] loss: 0.4298289716243744 2022-05-29 16:53:14.086970
Epoch:[ 37 15 ] loss: 0.4319852590560913 2022-05-29 16:53:14.860829
Epoch:[ 37 16 ] loss: 0.43203598260879517 2022-05-29 16:53:22.513040
Epoch:[ 37 17 ] loss: 0.43508750200271606 2022-05-29 16:53:23.286991
Epoch:[ 37 18 ] loss: 0.43196502327919006 2022-05-29 16:53:24.064463
Epoch:[ 37 19 ] loss: 0.43043747544288635 2022-05-29 16:53:24.850914
Training_Epoch:[ 37 ] Training_loss: 0.4310350030660629 2022-05-29 16:53:24.851678
learning rate:  0.00020480000000000004
val: 1 0.5238733291625977
val: 2 0.5185691714286804
val: 3 0.5188673138618469
val: 4 0.5254819989204407
val: 5 0.5278360843658447
val: 6 0.5260190367698669
val: 7 0.5277661085128784
val: 8 0.5154210329055786
val: 9 0.5113000273704529
val: 10 0.5402196049690247
val: 11 0.5290748476982117
val: 12 0.537578284740448
val: 13 0.537222146987915
val: 14 0.5239434242248535
val: 15 0.5387505888938904
val: 16 0.5144959688186646
val: 17 0.518287181854248
val: 18 0.5252434015274048
val: 19 0.5145145058631897
val: 20 0.5007989406585693
val_Epoch:[ 37 ] val_loss: 0.5237631499767303 2022-05-29 16:53:30.008698
start training 2022-05-29 16:53:30.104619
Epoch:[ 38 0 ] loss: 0.42882925271987915 2022-05-29 16:53:52.772358
Epoch:[ 38 1 ] loss: 0.43056923151016235 2022-05-29 16:53:53.599719
Epoch:[ 38 2 ] loss: 0.43321916460990906 2022-05-29 16:53:54.379215
Epoch:[ 38 3 ] loss: 0.42812177538871765 2022-05-29 16:53:55.154650
Epoch:[ 38 4 ] loss: 0.4275588393211365 2022-05-29 16:53:55.929836
Epoch:[ 38 5 ] loss: 0.4322766661643982 2022-05-29 16:53:56.703284
Epoch:[ 38 6 ] loss: 0.43057093024253845 2022-05-29 16:53:57.481387
Epoch:[ 38 7 ] loss: 0.4301927983760834 2022-05-29 16:53:58.249457
Epoch:[ 38 8 ] loss: 0.43181172013282776 2022-05-29 16:53:59.042090
Epoch:[ 38 9 ] loss: 0.4291224479675293 2022-05-29 16:53:59.818398
Epoch:[ 38 10 ] loss: 0.42728883028030396 2022-05-29 16:54:00.592645
Epoch:[ 38 11 ] loss: 0.4337812066078186 2022-05-29 16:54:01.369173
Epoch:[ 38 12 ] loss: 0.43071770668029785 2022-05-29 16:54:02.156629
Epoch:[ 38 13 ] loss: 0.4298907220363617 2022-05-29 16:54:02.930818
Epoch:[ 38 14 ] loss: 0.42981672286987305 2022-05-29 16:54:03.708987
Epoch:[ 38 15 ] loss: 0.4306246042251587 2022-05-29 16:54:04.487015
Epoch:[ 38 16 ] loss: 0.43190649151802063 2022-05-29 16:54:11.998382
Epoch:[ 38 17 ] loss: 0.4277491867542267 2022-05-29 16:54:12.783580
Epoch:[ 38 18 ] loss: 0.42934322357177734 2022-05-29 16:54:13.561910
Epoch:[ 38 19 ] loss: 0.427796334028244 2022-05-29 16:54:14.346240
Training_Epoch:[ 38 ] Training_loss: 0.4300593927502632 2022-05-29 16:54:14.347000
learning rate:  0.00020480000000000004
netparams have been saved once 38
val: 1 0.5203365087509155
val: 2 0.5286742448806763
val: 3 0.505938708782196
val: 4 0.515506386756897
val: 5 0.5276117920875549
val: 6 0.5234057307243347
val: 7 0.5212386250495911
val: 8 0.5183181166648865
val: 9 0.5214329361915588
val: 10 0.5191166400909424
val: 11 0.5205498337745667
val: 12 0.5216946601867676
val: 13 0.5241952538490295
val: 14 0.5448480248451233
val: 15 0.5356481075286865
val: 16 0.535000205039978
val: 17 0.5387661457061768
val: 18 0.5214112401008606
val: 19 0.5227487683296204
val: 20 0.5405839681625366
val_Epoch:[ 38 ] val_loss: 0.525351294875145 2022-05-29 16:54:19.689971
start training 2022-05-29 16:54:19.786732
Epoch:[ 39 0 ] loss: 0.42912396788597107 2022-05-29 16:54:43.955838
Epoch:[ 39 1 ] loss: 0.4261474609375 2022-05-29 16:54:44.734794
Epoch:[ 39 2 ] loss: 0.4264213442802429 2022-05-29 16:54:45.513259
Epoch:[ 39 3 ] loss: 0.4303457736968994 2022-05-29 16:54:46.287453
Epoch:[ 39 4 ] loss: 0.4272160828113556 2022-05-29 16:54:47.062089
Epoch:[ 39 5 ] loss: 0.42988279461860657 2022-05-29 16:54:47.838966
Epoch:[ 39 6 ] loss: 0.4278089106082916 2022-05-29 16:54:48.605284
Epoch:[ 39 7 ] loss: 0.4297666847705841 2022-05-29 16:54:49.381124
Epoch:[ 39 8 ] loss: 0.43202275037765503 2022-05-29 16:54:50.160033
Epoch:[ 39 9 ] loss: 0.4298397898674011 2022-05-29 16:54:50.928916
Epoch:[ 39 10 ] loss: 0.43266499042510986 2022-05-29 16:54:51.696946
Epoch:[ 39 11 ] loss: 0.43598660826683044 2022-05-29 16:54:52.474608
Epoch:[ 39 12 ] loss: 0.43709707260131836 2022-05-29 16:54:53.250705
Epoch:[ 39 13 ] loss: 0.4318225681781769 2022-05-29 16:54:54.026327
Epoch:[ 39 14 ] loss: 0.43150925636291504 2022-05-29 16:54:54.801787
Epoch:[ 39 15 ] loss: 0.432368665933609 2022-05-29 16:54:55.582184
Epoch:[ 39 16 ] loss: 0.4306451380252838 2022-05-29 16:55:02.675386
Epoch:[ 39 17 ] loss: 0.43154698610305786 2022-05-29 16:55:03.451380
Epoch:[ 39 18 ] loss: 0.43105560541152954 2022-05-29 16:55:04.245688
Epoch:[ 39 19 ] loss: 0.43288102746009827 2022-05-29 16:55:05.019894
Training_Epoch:[ 39 ] Training_loss: 0.43080767393112185 2022-05-29 16:55:05.020666
learning rate:  0.00020480000000000004
val: 1 0.5311818718910217
val: 2 0.5297793745994568
val: 3 0.5158683657646179
val: 4 0.5301278829574585
val: 5 0.5020798444747925
val: 6 0.5315254926681519
val: 7 0.538324773311615
val: 8 0.5154353976249695
val: 9 0.5131233334541321
val: 10 0.5148741006851196
val: 11 0.5143309831619263
val: 12 0.5360057353973389
val: 13 0.503165602684021
val: 14 0.5309386849403381
val: 15 0.5331162810325623
val: 16 0.5279132723808289
val: 17 0.526968240737915
val: 18 0.5416257977485657
val: 19 0.5278764367103577
val: 20 0.5337036848068237
val_Epoch:[ 39 ] val_loss: 0.5248982578516006 2022-05-29 16:55:10.204183
start training 2022-05-29 16:55:10.304388
Epoch:[ 40 0 ] loss: 0.43113136291503906 2022-05-29 16:55:33.130240
Epoch:[ 40 1 ] loss: 0.43030259013175964 2022-05-29 16:55:34.252280
Epoch:[ 40 2 ] loss: 0.4270842373371124 2022-05-29 16:55:35.029646
Epoch:[ 40 3 ] loss: 0.4323995113372803 2022-05-29 16:55:35.805936
Epoch:[ 40 4 ] loss: 0.42948874831199646 2022-05-29 16:55:36.585672
Epoch:[ 40 5 ] loss: 0.42838722467422485 2022-05-29 16:55:37.376232
Epoch:[ 40 6 ] loss: 0.42824292182922363 2022-05-29 16:55:38.162047
Epoch:[ 40 7 ] loss: 0.43003225326538086 2022-05-29 16:55:38.936327
Epoch:[ 40 8 ] loss: 0.43027573823928833 2022-05-29 16:55:39.709972
Epoch:[ 40 9 ] loss: 0.4298701882362366 2022-05-29 16:55:40.487618
Epoch:[ 40 10 ] loss: 0.43152227997779846 2022-05-29 16:55:41.264691
Epoch:[ 40 11 ] loss: 0.42647498846054077 2022-05-29 16:55:42.039814
Epoch:[ 40 12 ] loss: 0.429917573928833 2022-05-29 16:55:42.815397
Epoch:[ 40 13 ] loss: 0.4283302426338196 2022-05-29 16:55:43.590080
Epoch:[ 40 14 ] loss: 0.43142879009246826 2022-05-29 16:55:44.378381
Epoch:[ 40 15 ] loss: 0.4287301003932953 2022-05-29 16:55:45.153470
Epoch:[ 40 16 ] loss: 0.43021491169929504 2022-05-29 16:55:52.244616
Epoch:[ 40 17 ] loss: 0.433121919631958 2022-05-29 16:55:53.077669
Epoch:[ 40 18 ] loss: 0.4311005771160126 2022-05-29 16:55:53.865673
Epoch:[ 40 19 ] loss: 0.4297060966491699 2022-05-29 16:55:54.640001
Training_Epoch:[ 40 ] Training_loss: 0.42988811284303663 2022-05-29 16:55:54.640851
learning rate:  0.00020480000000000004
netparams have been saved once 40
val: 1 0.5208514332771301
val: 2 0.5387465953826904
val: 3 0.5238469839096069
val: 4 0.5185080170631409
val: 5 0.5104401111602783
val: 6 0.5416742563247681
val: 7 0.5178563594818115
val: 8 0.5058115124702454
val: 9 0.5251165628433228
val: 10 0.5239765048027039
val: 11 0.5117307305335999
val: 12 0.5283007621765137
val: 13 0.5175159573554993
val: 14 0.531038224697113
val: 15 0.5258718729019165
val: 16 0.5237666368484497
val: 17 0.5384047627449036
val: 18 0.5432802438735962
val: 19 0.5083935856819153
val: 20 0.5195149183273315
val_Epoch:[ 40 ] val_loss: 0.5237323015928268 2022-05-29 16:56:00.010498
start training 2022-05-29 16:56:00.113378
Epoch:[ 41 0 ] loss: 0.43013113737106323 2022-05-29 16:56:23.765514
Epoch:[ 41 1 ] loss: 0.4246596097946167 2022-05-29 16:56:24.538794
Epoch:[ 41 2 ] loss: 0.4257897734642029 2022-05-29 16:56:25.314039
Epoch:[ 41 3 ] loss: 0.42838895320892334 2022-05-29 16:56:26.100600
Epoch:[ 41 4 ] loss: 0.42565059661865234 2022-05-29 16:56:26.876754
Epoch:[ 41 5 ] loss: 0.42818483710289 2022-05-29 16:56:27.655906
Epoch:[ 41 6 ] loss: 0.42585983872413635 2022-05-29 16:56:28.433181
Epoch:[ 41 7 ] loss: 0.432065486907959 2022-05-29 16:56:29.208864
Epoch:[ 41 8 ] loss: 0.4255867004394531 2022-05-29 16:56:29.983477
Epoch:[ 41 9 ] loss: 0.4268561005592346 2022-05-29 16:56:30.759386
Epoch:[ 41 10 ] loss: 0.4293968975543976 2022-05-29 16:56:31.548858
Epoch:[ 41 11 ] loss: 0.4270971417427063 2022-05-29 16:56:32.326398
Epoch:[ 41 12 ] loss: 0.43151259422302246 2022-05-29 16:56:33.103284
Epoch:[ 41 13 ] loss: 0.42929160594940186 2022-05-29 16:56:33.891158
Epoch:[ 41 14 ] loss: 0.4257138967514038 2022-05-29 16:56:34.666870
Epoch:[ 41 15 ] loss: 0.4266521632671356 2022-05-29 16:56:35.444259
Epoch:[ 41 16 ] loss: 0.42953068017959595 2022-05-29 16:56:42.543413
Epoch:[ 41 17 ] loss: 0.42722854018211365 2022-05-29 16:56:43.332212
Epoch:[ 41 18 ] loss: 0.42597541213035583 2022-05-29 16:56:44.116088
Epoch:[ 41 19 ] loss: 0.4333922863006592 2022-05-29 16:56:44.891343
Training_Epoch:[ 41 ] Training_loss: 0.42794821262359617 2022-05-29 16:56:44.891995
learning rate:  0.00016384000000000006
val: 1 0.5325288772583008
val: 2 0.5331361889839172
val: 3 0.5334145426750183
val: 4 0.5329054594039917
val: 5 0.5402124524116516
val: 6 0.5269867777824402
val: 7 0.506436288356781
val: 8 0.5222442746162415
val: 9 0.526535153388977
val: 10 0.5260085463523865
val: 11 0.5214299559593201
val: 12 0.530326247215271
val: 13 0.5152629613876343
val: 14 0.5138638615608215
val: 15 0.5182915329933167
val: 16 0.5163912177085876
val: 17 0.5296567678451538
val: 18 0.5244135856628418
val: 19 0.5100103616714478
val: 20 0.512836754322052
val_Epoch:[ 41 ] val_loss: 0.5236445903778076 2022-05-29 16:56:50.107815
start training 2022-05-29 16:56:50.205619
Epoch:[ 42 0 ] loss: 0.4258679151535034 2022-05-29 16:57:14.045511
Epoch:[ 42 1 ] loss: 0.4274485409259796 2022-05-29 16:57:14.820660
Epoch:[ 42 2 ] loss: 0.42898106575012207 2022-05-29 16:57:15.610399
Epoch:[ 42 3 ] loss: 0.4278908371925354 2022-05-29 16:57:16.385134
Epoch:[ 42 4 ] loss: 0.43047183752059937 2022-05-29 16:57:17.162169
Epoch:[ 42 5 ] loss: 0.4221859276294708 2022-05-29 16:57:17.939577
Epoch:[ 42 6 ] loss: 0.42672714591026306 2022-05-29 16:57:18.714827
Epoch:[ 42 7 ] loss: 0.425127774477005 2022-05-29 16:57:19.491219
Epoch:[ 42 8 ] loss: 0.42911022901535034 2022-05-29 16:57:20.264784
Epoch:[ 42 9 ] loss: 0.4259759485721588 2022-05-29 16:57:21.052600
Epoch:[ 42 10 ] loss: 0.4282253384590149 2022-05-29 16:57:21.825527
Epoch:[ 42 11 ] loss: 0.42740848660469055 2022-05-29 16:57:22.602290
Epoch:[ 42 12 ] loss: 0.42697012424468994 2022-05-29 16:57:23.380007
Epoch:[ 42 13 ] loss: 0.4284786581993103 2022-05-29 16:57:24.153880
Epoch:[ 42 14 ] loss: 0.4264466464519501 2022-05-29 16:57:24.942517
Epoch:[ 42 15 ] loss: 0.4266532063484192 2022-05-29 16:57:25.715076
Epoch:[ 42 16 ] loss: 0.4276365637779236 2022-05-29 16:57:32.871121
Epoch:[ 42 17 ] loss: 0.4271443486213684 2022-05-29 16:57:33.643817
Epoch:[ 42 18 ] loss: 0.4271916449069977 2022-05-29 16:57:34.425912
Epoch:[ 42 19 ] loss: 0.4279063642024994 2022-05-29 16:57:35.213314
Training_Epoch:[ 42 ] Training_loss: 0.4271924301981926 2022-05-29 16:57:35.213954
learning rate:  0.00016384000000000006
netparams have been saved once 42
val: 1 0.5374385118484497
val: 2 0.5277794599533081
val: 3 0.5363377928733826
val: 4 0.5186600089073181
val: 5 0.5248676538467407
val: 6 0.5318893790245056
val: 7 0.5202977657318115
val: 8 0.5059682130813599
val: 9 0.5298171043395996
val: 10 0.5014194846153259
val: 11 0.5111086368560791
val: 12 0.5473059415817261
val: 13 0.5126758813858032
val: 14 0.5386115312576294
val: 15 0.5238848924636841
val: 16 0.5262196063995361
val: 17 0.5248342156410217
val: 18 0.5306296348571777
val: 19 0.528986394405365
val: 20 0.5303175449371338
val_Epoch:[ 42 ] val_loss: 0.525452482700348 2022-05-29 16:57:40.406115
start training 2022-05-29 16:57:40.495582
Epoch:[ 43 0 ] loss: 0.4237866699695587 2022-05-29 16:58:03.923383
Epoch:[ 43 1 ] loss: 0.4280836284160614 2022-05-29 16:58:04.701934
Epoch:[ 43 2 ] loss: 0.43254074454307556 2022-05-29 16:58:05.477584
Epoch:[ 43 3 ] loss: 0.4240013062953949 2022-05-29 16:58:06.254179
Epoch:[ 43 4 ] loss: 0.425814151763916 2022-05-29 16:58:07.029575
Epoch:[ 43 5 ] loss: 0.4261513650417328 2022-05-29 16:58:07.808978
Epoch:[ 43 6 ] loss: 0.4252963960170746 2022-05-29 16:58:08.587795
Epoch:[ 43 7 ] loss: 0.4299635887145996 2022-05-29 16:58:09.374414
Epoch:[ 43 8 ] loss: 0.42884981632232666 2022-05-29 16:58:10.150789
Epoch:[ 43 9 ] loss: 0.42964276671409607 2022-05-29 16:58:10.925139
Epoch:[ 43 10 ] loss: 0.43015557527542114 2022-05-29 16:58:11.700059
Epoch:[ 43 11 ] loss: 0.4288257658481598 2022-05-29 16:58:12.488076
Epoch:[ 43 12 ] loss: 0.42599403858184814 2022-05-29 16:58:13.264746
Epoch:[ 43 13 ] loss: 0.42466017603874207 2022-05-29 16:58:14.055242
Epoch:[ 43 14 ] loss: 0.4243873357772827 2022-05-29 16:58:14.835024
Epoch:[ 43 15 ] loss: 0.42422980070114136 2022-05-29 16:58:15.610981
Epoch:[ 43 16 ] loss: 0.4252104163169861 2022-05-29 16:58:22.625915
Epoch:[ 43 17 ] loss: 0.4280956983566284 2022-05-29 16:58:23.401439
Epoch:[ 43 18 ] loss: 0.4238814115524292 2022-05-29 16:58:24.179834
Epoch:[ 43 19 ] loss: 0.42614859342575073 2022-05-29 16:58:24.970464
Training_Epoch:[ 43 ] Training_loss: 0.4267859622836113 2022-05-29 16:58:24.971060
learning rate:  0.00016384000000000006
val: 1 0.5142669677734375
val: 2 0.538729190826416
val: 3 0.5375639200210571
val: 4 0.5169181823730469
val: 5 0.5251299142837524
val: 6 0.5233497023582458
val: 7 0.5200082063674927
val: 8 0.5258799195289612
val: 9 0.5328739285469055
val: 10 0.5178751945495605
val: 11 0.5254305601119995
val: 12 0.5297502875328064
val: 13 0.5253996253013611
val: 14 0.5186771154403687
val: 15 0.5085616111755371
val: 16 0.5299311876296997
val: 17 0.5106906294822693
val: 18 0.5432308316230774
val: 19 0.521797239780426
val: 20 0.5120313167572021
val_Epoch:[ 43 ] val_loss: 0.5239047765731811 2022-05-29 16:58:30.153766
start training 2022-05-29 16:58:30.241739
Epoch:[ 44 0 ] loss: 0.42308324575424194 2022-05-29 16:58:52.697730
Epoch:[ 44 1 ] loss: 0.4268096089363098 2022-05-29 16:58:53.517937
Epoch:[ 44 2 ] loss: 0.41844865679740906 2022-05-29 16:58:54.352878
Epoch:[ 44 3 ] loss: 0.4287967085838318 2022-05-29 16:58:55.129223
Epoch:[ 44 4 ] loss: 0.4267662763595581 2022-05-29 16:58:55.903573
Epoch:[ 44 5 ] loss: 0.42287376523017883 2022-05-29 16:58:56.678396
Epoch:[ 44 6 ] loss: 0.42917338013648987 2022-05-29 16:58:57.457327
Epoch:[ 44 7 ] loss: 0.42044728994369507 2022-05-29 16:58:58.233734
Epoch:[ 44 8 ] loss: 0.42599743604660034 2022-05-29 16:58:59.022765
Epoch:[ 44 9 ] loss: 0.4235382080078125 2022-05-29 16:58:59.797466
Epoch:[ 44 10 ] loss: 0.42714980244636536 2022-05-29 16:59:00.572772
Epoch:[ 44 11 ] loss: 0.4264662265777588 2022-05-29 16:59:01.358186
Epoch:[ 44 12 ] loss: 0.42505693435668945 2022-05-29 16:59:02.131797
Epoch:[ 44 13 ] loss: 0.4267735481262207 2022-05-29 16:59:02.907621
Epoch:[ 44 14 ] loss: 0.42875903844833374 2022-05-29 16:59:03.683871
Epoch:[ 44 15 ] loss: 0.42480117082595825 2022-05-29 16:59:04.460475
Epoch:[ 44 16 ] loss: 0.42396414279937744 2022-05-29 16:59:12.445416
Epoch:[ 44 17 ] loss: 0.4265238642692566 2022-05-29 16:59:13.219175
Epoch:[ 44 18 ] loss: 0.42272812128067017 2022-05-29 16:59:13.999051
Epoch:[ 44 19 ] loss: 0.4300166368484497 2022-05-29 16:59:14.785144
Training_Epoch:[ 44 ] Training_loss: 0.4254087030887604 2022-05-29 16:59:14.785963
learning rate:  0.00016384000000000006
netparams have been saved once 44
val: 1 0.5175539255142212
val: 2 0.5167543888092041
val: 3 0.5197830200195312
val: 4 0.529069185256958
val: 5 0.5186273455619812
val: 6 0.5162062644958496
val: 7 0.5183354616165161
val: 8 0.5270817875862122
val: 9 0.5341397523880005
val: 10 0.5326935648918152
val: 11 0.5272793769836426
val: 12 0.5288845300674438
val: 13 0.51337069272995
val: 14 0.5287994742393494
val: 15 0.5138804316520691
val: 16 0.5045040845870972
val: 17 0.5231826305389404
val: 18 0.5464605093002319
val: 19 0.5284358263015747
val: 20 0.5141942501068115
val_Epoch:[ 44 ] val_loss: 0.52296182513237 2022-05-29 16:59:20.242326
start training 2022-05-29 16:59:20.335065
Epoch:[ 45 0 ] loss: 0.42728251218795776 2022-05-29 16:59:44.445182
Epoch:[ 45 1 ] loss: 0.42665350437164307 2022-05-29 16:59:45.223913
Epoch:[ 45 2 ] loss: 0.4229668080806732 2022-05-29 16:59:45.999250
Epoch:[ 45 3 ] loss: 0.42813071608543396 2022-05-29 16:59:46.775900
Epoch:[ 45 4 ] loss: 0.4254905581474304 2022-05-29 16:59:47.550400
Epoch:[ 45 5 ] loss: 0.42360252141952515 2022-05-29 16:59:48.339513
Epoch:[ 45 6 ] loss: 0.42231082916259766 2022-05-29 16:59:49.113677
Epoch:[ 45 7 ] loss: 0.42221102118492126 2022-05-29 16:59:49.890406
Epoch:[ 45 8 ] loss: 0.42518824338912964 2022-05-29 16:59:50.666865
Epoch:[ 45 9 ] loss: 0.4219316244125366 2022-05-29 16:59:51.445372
Epoch:[ 45 10 ] loss: 0.42598605155944824 2022-05-29 16:59:52.223954
Epoch:[ 45 11 ] loss: 0.42510852217674255 2022-05-29 16:59:52.997930
Epoch:[ 45 12 ] loss: 0.42837926745414734 2022-05-29 16:59:53.774424
Epoch:[ 45 13 ] loss: 0.42514657974243164 2022-05-29 16:59:54.560383
Epoch:[ 45 14 ] loss: 0.4242969751358032 2022-05-29 16:59:55.336864
Epoch:[ 45 15 ] loss: 0.4215134382247925 2022-05-29 16:59:56.114352
Epoch:[ 45 16 ] loss: 0.4269121289253235 2022-05-29 17:00:03.594720
Epoch:[ 45 17 ] loss: 0.4219089150428772 2022-05-29 17:00:04.369278
Epoch:[ 45 18 ] loss: 0.4248456358909607 2022-05-29 17:00:05.163631
Epoch:[ 45 19 ] loss: 0.43100613355636597 2022-05-29 17:00:05.949593
Training_Epoch:[ 45 ] Training_loss: 0.4250435993075371 2022-05-29 17:00:05.950314
learning rate:  0.00016384000000000006
val: 1 0.51904296875
val: 2 0.5475069284439087
val: 3 0.5336987972259521
val: 4 0.5164792537689209
val: 5 0.5282302498817444
val: 6 0.5405021905899048
val: 7 0.5341762900352478
val: 8 0.5055621266365051
val: 9 0.5281611084938049
val: 10 0.5363963842391968
val: 11 0.5379921197891235
val: 12 0.5223357677459717
val: 13 0.5203730463981628
val: 14 0.5289332866668701
val: 15 0.5029186606407166
val: 16 0.5178046822547913
val: 17 0.5101645588874817
val: 18 0.5094021558761597
val: 19 0.5160766839981079
val: 20 0.5234301686286926
val_Epoch:[ 45 ] val_loss: 0.5239593714475632 2022-05-29 17:00:11.166915
start training 2022-05-29 17:00:11.265228
Epoch:[ 46 0 ] loss: 0.42559123039245605 2022-05-29 17:00:34.133607
Epoch:[ 46 1 ] loss: 0.42242154479026794 2022-05-29 17:00:35.609220
Epoch:[ 46 2 ] loss: 0.42550691962242126 2022-05-29 17:00:36.400125
Epoch:[ 46 3 ] loss: 0.4269065260887146 2022-05-29 17:00:37.176879
Epoch:[ 46 4 ] loss: 0.42021340131759644 2022-05-29 17:00:37.967466
Epoch:[ 46 5 ] loss: 0.4237026870250702 2022-05-29 17:00:38.741857
Epoch:[ 46 6 ] loss: 0.4254874885082245 2022-05-29 17:00:39.517303
Epoch:[ 46 7 ] loss: 0.4198048412799835 2022-05-29 17:00:40.292349
Epoch:[ 46 8 ] loss: 0.4231364130973816 2022-05-29 17:00:41.069734
Epoch:[ 46 9 ] loss: 0.4227111041545868 2022-05-29 17:00:41.848406
Epoch:[ 46 10 ] loss: 0.4236997663974762 2022-05-29 17:00:42.625290
Epoch:[ 46 11 ] loss: 0.4222071170806885 2022-05-29 17:00:43.412425
Epoch:[ 46 12 ] loss: 0.42456838488578796 2022-05-29 17:00:44.185734
Epoch:[ 46 13 ] loss: 0.428126722574234 2022-05-29 17:00:44.960966
Epoch:[ 46 14 ] loss: 0.4247375726699829 2022-05-29 17:00:45.735848
Epoch:[ 46 15 ] loss: 0.42765289545059204 2022-05-29 17:00:46.513284
Epoch:[ 46 16 ] loss: 0.4235840141773224 2022-05-29 17:00:53.448578
Epoch:[ 46 17 ] loss: 0.42414987087249756 2022-05-29 17:00:54.296933
Epoch:[ 46 18 ] loss: 0.42379122972488403 2022-05-29 17:00:55.077296
Epoch:[ 46 19 ] loss: 0.42559128999710083 2022-05-29 17:00:55.852544
Training_Epoch:[ 46 ] Training_loss: 0.4241795510053635 2022-05-29 17:00:55.853267
learning rate:  0.00016384000000000006
netparams have been saved once 46
val: 1 0.5365607142448425
val: 2 0.5249003767967224
val: 3 0.522533118724823
val: 4 0.5333508849143982
val: 5 0.5278169512748718
val: 6 0.5440447926521301
val: 7 0.5155177116394043
val: 8 0.5323208570480347
val: 9 0.5313648581504822
val: 10 0.5269812345504761
val: 11 0.512157142162323
val: 12 0.5357971787452698
val: 13 0.5350750088691711
val: 14 0.5270600914955139
val: 15 0.5232825875282288
val: 16 0.5145927667617798
val: 17 0.5242339968681335
val: 18 0.5472227334976196
val: 19 0.5338789820671082
val: 20 0.546859860420227
val_Epoch:[ 46 ] val_loss: 0.529777592420578 2022-05-29 17:01:01.283119
start training 2022-05-29 17:01:01.372824
Epoch:[ 47 0 ] loss: 0.4234379827976227 2022-05-29 17:01:23.832961
Epoch:[ 47 1 ] loss: 0.4236576557159424 2022-05-29 17:01:24.659460
Epoch:[ 47 2 ] loss: 0.42444735765457153 2022-05-29 17:01:25.492090
Epoch:[ 47 3 ] loss: 0.4262700378894806 2022-05-29 17:01:26.268513
Epoch:[ 47 4 ] loss: 0.4230489730834961 2022-05-29 17:01:27.056177
Epoch:[ 47 5 ] loss: 0.4234251379966736 2022-05-29 17:01:27.831250
Epoch:[ 47 6 ] loss: 0.4235678017139435 2022-05-29 17:01:28.606527
Epoch:[ 47 7 ] loss: 0.424521267414093 2022-05-29 17:01:29.384065
Epoch:[ 47 8 ] loss: 0.42611244320869446 2022-05-29 17:01:30.158477
Epoch:[ 47 9 ] loss: 0.424654096364975 2022-05-29 17:01:30.937013
Epoch:[ 47 10 ] loss: 0.424063116312027 2022-05-29 17:01:31.714343
Epoch:[ 47 11 ] loss: 0.42838793992996216 2022-05-29 17:01:32.491075
Epoch:[ 47 12 ] loss: 0.42703625559806824 2022-05-29 17:01:33.269077
Epoch:[ 47 13 ] loss: 0.4249460697174072 2022-05-29 17:01:34.044644
Epoch:[ 47 14 ] loss: 0.42361703515052795 2022-05-29 17:01:34.833752
Epoch:[ 47 15 ] loss: 0.42649635672569275 2022-05-29 17:01:35.610778
Epoch:[ 47 16 ] loss: 0.4237973690032959 2022-05-29 17:01:43.104730
Epoch:[ 47 17 ] loss: 0.4240679442882538 2022-05-29 17:01:43.892586
Epoch:[ 47 18 ] loss: 0.42395350337028503 2022-05-29 17:01:44.675167
Epoch:[ 47 19 ] loss: 0.4254308044910431 2022-05-29 17:01:45.462978
Training_Epoch:[ 47 ] Training_loss: 0.4247469574213028 2022-05-29 17:01:45.463661
learning rate:  0.00016384000000000006
val: 1 0.5293761491775513
val: 2 0.5328443646430969
val: 3 0.5239116549491882
val: 4 0.5398963093757629
val: 5 0.5334439277648926
val: 6 0.523292064666748
val: 7 0.528674840927124
val: 8 0.5231826305389404
val: 9 0.5138083696365356
val: 10 0.5177621841430664
val: 11 0.5166637897491455
val: 12 0.5257124304771423
val: 13 0.5357002019882202
val: 14 0.5220791697502136
val: 15 0.5346434712409973
val: 16 0.532244086265564
val: 17 0.522047221660614
val: 18 0.5004886984825134
val: 19 0.5153625011444092
val: 20 0.5183061361312866
val_Epoch:[ 47 ] val_loss: 0.5244720101356506 2022-05-29 17:01:50.653087
start training 2022-05-29 17:01:50.746011
Epoch:[ 48 0 ] loss: 0.4223727881908417 2022-05-29 17:02:13.406648
Epoch:[ 48 1 ] loss: 0.4264509379863739 2022-05-29 17:02:14.569816
Epoch:[ 48 2 ] loss: 0.42462995648384094 2022-05-29 17:02:15.355546
Epoch:[ 48 3 ] loss: 0.42362961173057556 2022-05-29 17:02:16.144235
Epoch:[ 48 4 ] loss: 0.42335212230682373 2022-05-29 17:02:16.921685
Epoch:[ 48 5 ] loss: 0.42350053787231445 2022-05-29 17:02:17.696674
Epoch:[ 48 6 ] loss: 0.420326828956604 2022-05-29 17:02:18.474394
Epoch:[ 48 7 ] loss: 0.4234348237514496 2022-05-29 17:02:19.249231
Epoch:[ 48 8 ] loss: 0.4273800849914551 2022-05-29 17:02:20.025412
Epoch:[ 48 9 ] loss: 0.42691993713378906 2022-05-29 17:02:20.799961
Epoch:[ 48 10 ] loss: 0.4250289797782898 2022-05-29 17:02:21.576581
Epoch:[ 48 11 ] loss: 0.42263343930244446 2022-05-29 17:02:22.355509
Epoch:[ 48 12 ] loss: 0.4228098690509796 2022-05-29 17:02:23.130718
Epoch:[ 48 13 ] loss: 0.4206984341144562 2022-05-29 17:02:23.908842
Epoch:[ 48 14 ] loss: 0.4210910201072693 2022-05-29 17:02:24.684033
Epoch:[ 48 15 ] loss: 0.42085886001586914 2022-05-29 17:02:25.472782
Epoch:[ 48 16 ] loss: 0.4308476150035858 2022-05-29 17:02:33.429240
Epoch:[ 48 17 ] loss: 0.42358168959617615 2022-05-29 17:02:34.203618
Epoch:[ 48 18 ] loss: 0.42218056321144104 2022-05-29 17:02:34.988831
Epoch:[ 48 19 ] loss: 0.42387092113494873 2022-05-29 17:02:35.792365
Training_Epoch:[ 48 ] Training_loss: 0.42377995103597643 2022-05-29 17:02:35.793082
learning rate:  0.00016384000000000006
netparams have been saved once 48
val: 1 0.5189276933670044
val: 2 0.5227115154266357
val: 3 0.52439284324646
val: 4 0.5187121033668518
val: 5 0.5261543989181519
val: 6 0.5248228907585144
val: 7 0.5183594822883606
val: 8 0.5353410840034485
val: 9 0.5427115559577942
val: 10 0.5253902673721313
val: 11 0.5304749011993408
val: 12 0.5425138473510742
val: 13 0.528146505355835
val: 14 0.5284160375595093
val: 15 0.5280115008354187
val: 16 0.5132114291191101
val: 17 0.5212482810020447
val: 18 0.5379215478897095
val: 19 0.5421972274780273
val: 20 0.5053356289863586
val_Epoch:[ 48 ] val_loss: 0.5267500370740891 2022-05-29 17:02:41.032961
start training 2022-05-29 17:02:41.128632
Epoch:[ 49 0 ] loss: 0.4182066023349762 2022-05-29 17:03:03.195541
Epoch:[ 49 1 ] loss: 0.42361530661582947 2022-05-29 17:03:04.036307
Epoch:[ 49 2 ] loss: 0.4213419258594513 2022-05-29 17:03:05.242840
Epoch:[ 49 3 ] loss: 0.4200759828090668 2022-05-29 17:03:06.017604
Epoch:[ 49 4 ] loss: 0.4228038191795349 2022-05-29 17:03:06.796688
Epoch:[ 49 5 ] loss: 0.4223417043685913 2022-05-29 17:03:07.589583
Epoch:[ 49 6 ] loss: 0.4225207567214966 2022-05-29 17:03:08.376493
Epoch:[ 49 7 ] loss: 0.42358994483947754 2022-05-29 17:03:09.154474
Epoch:[ 49 8 ] loss: 0.42511501908302307 2022-05-29 17:03:09.940994
Epoch:[ 49 9 ] loss: 0.42621129751205444 2022-05-29 17:03:10.719608
Epoch:[ 49 10 ] loss: 0.42621031403541565 2022-05-29 17:03:11.493800
Epoch:[ 49 11 ] loss: 0.4199216067790985 2022-05-29 17:03:12.272256
Epoch:[ 49 12 ] loss: 0.422297865152359 2022-05-29 17:03:13.049130
Epoch:[ 49 13 ] loss: 0.4222869277000427 2022-05-29 17:03:13.824630
Epoch:[ 49 14 ] loss: 0.4219207465648651 2022-05-29 17:03:14.600723
Epoch:[ 49 15 ] loss: 0.42400655150413513 2022-05-29 17:03:15.374944
Epoch:[ 49 16 ] loss: 0.42497846484184265 2022-05-29 17:03:22.851398
Epoch:[ 49 17 ] loss: 0.42303115129470825 2022-05-29 17:03:23.624645
Epoch:[ 49 18 ] loss: 0.42763832211494446 2022-05-29 17:03:24.406793
Epoch:[ 49 19 ] loss: 0.4245817959308624 2022-05-29 17:03:25.194071
Training_Epoch:[ 49 ] Training_loss: 0.4231348052620888 2022-05-29 17:03:25.194745
learning rate:  0.00016384000000000006
val: 1 0.5209813117980957
val: 2 0.5171296000480652
val: 3 0.5328935384750366
val: 4 0.5213176012039185
val: 5 0.5241637229919434
val: 6 0.5527360439300537
val: 7 0.5013399124145508
val: 8 0.5242621302604675
val: 9 0.5148177146911621
val: 10 0.5123379826545715
val: 11 0.499658465385437
val: 12 0.5546994805335999
val: 13 0.5363184213638306
val: 14 0.5304409861564636
val: 15 0.5222403407096863
val: 16 0.52208012342453
val: 17 0.5178600549697876
val: 18 0.530028760433197
val: 19 0.52826327085495
val: 20 0.5322363376617432
val_Epoch:[ 49 ] val_loss: 0.5247902899980545 2022-05-29 17:03:30.417723
start training 2022-05-29 17:03:30.514938
Epoch:[ 50 0 ] loss: 0.4201647639274597 2022-05-29 17:03:52.926968
Epoch:[ 50 1 ] loss: 0.4239998161792755 2022-05-29 17:03:53.752414
Epoch:[ 50 2 ] loss: 0.42166316509246826 2022-05-29 17:03:54.577098
Epoch:[ 50 3 ] loss: 0.4217561185359955 2022-05-29 17:03:55.352028
Epoch:[ 50 4 ] loss: 0.4221472442150116 2022-05-29 17:03:56.127287
Epoch:[ 50 5 ] loss: 0.42399507761001587 2022-05-29 17:03:56.906289
Epoch:[ 50 6 ] loss: 0.4237856864929199 2022-05-29 17:03:57.684850
Epoch:[ 50 7 ] loss: 0.4217328131198883 2022-05-29 17:03:58.461728
Epoch:[ 50 8 ] loss: 0.424233078956604 2022-05-29 17:03:59.236601
Epoch:[ 50 9 ] loss: 0.42260944843292236 2022-05-29 17:04:00.011267
Epoch:[ 50 10 ] loss: 0.41946348547935486 2022-05-29 17:04:00.788471
Epoch:[ 50 11 ] loss: 0.4246475398540497 2022-05-29 17:04:01.575372
Epoch:[ 50 12 ] loss: 0.4231727123260498 2022-05-29 17:04:02.353093
Epoch:[ 50 13 ] loss: 0.4243796467781067 2022-05-29 17:04:03.131039
Epoch:[ 50 14 ] loss: 0.42048409581184387 2022-05-29 17:04:03.919630
Epoch:[ 50 15 ] loss: 0.42076125741004944 2022-05-29 17:04:04.694162
Epoch:[ 50 16 ] loss: 0.42195838689804077 2022-05-29 17:04:12.679722
Epoch:[ 50 17 ] loss: 0.4250536561012268 2022-05-29 17:04:13.466556
Epoch:[ 50 18 ] loss: 0.42273107171058655 2022-05-29 17:04:14.245121
Epoch:[ 50 19 ] loss: 0.4217219054698944 2022-05-29 17:04:15.021442
Training_Epoch:[ 50 ] Training_loss: 0.4225230485200882 2022-05-29 17:04:15.022122
learning rate:  0.00016384000000000006
netparams have been saved once 50
val: 1 0.502315104007721
val: 2 0.5230451226234436
val: 3 0.5239490270614624
val: 4 0.5170618891716003
val: 5 0.5311329364776611
val: 6 0.5179812908172607
val: 7 0.5386844277381897
val: 8 0.5054587721824646
val: 9 0.5416891574859619
val: 10 0.5223842859268188
val: 11 0.5267030596733093
val: 12 0.5024119019508362
val: 13 0.546615719795227
val: 14 0.5219742655754089
val: 15 0.5346314311027527
val: 16 0.5125709772109985
val: 17 0.5408645272254944
val: 18 0.530292809009552
val: 19 0.5370100736618042
val: 20 0.5297106504440308
val_Epoch:[ 50 ] val_loss: 0.5253243714570999 2022-05-29 17:04:20.281019
start training 2022-05-29 17:04:20.374815
Epoch:[ 51 0 ] loss: 0.421284556388855 2022-05-29 17:04:43.832490
Epoch:[ 51 1 ] loss: 0.4209660589694977 2022-05-29 17:04:44.610162
Epoch:[ 51 2 ] loss: 0.4228786528110504 2022-05-29 17:04:45.384037
Epoch:[ 51 3 ] loss: 0.4184925854206085 2022-05-29 17:04:46.158602
Epoch:[ 51 4 ] loss: 0.41850900650024414 2022-05-29 17:04:46.931963
Epoch:[ 51 5 ] loss: 0.42120566964149475 2022-05-29 17:04:47.707275
Epoch:[ 51 6 ] loss: 0.41719937324523926 2022-05-29 17:04:48.483124
Epoch:[ 51 7 ] loss: 0.42189696431159973 2022-05-29 17:04:49.260878
Epoch:[ 51 8 ] loss: 0.42586448788642883 2022-05-29 17:04:50.047358
Epoch:[ 51 9 ] loss: 0.4220641851425171 2022-05-29 17:04:50.824965
Epoch:[ 51 10 ] loss: 0.42231032252311707 2022-05-29 17:04:51.613201
Epoch:[ 51 11 ] loss: 0.41870102286338806 2022-05-29 17:04:52.389772
Epoch:[ 51 12 ] loss: 0.41903120279312134 2022-05-29 17:04:53.167282
Epoch:[ 51 13 ] loss: 0.4176977276802063 2022-05-29 17:04:53.957252
Epoch:[ 51 14 ] loss: 0.424710750579834 2022-05-29 17:04:54.735878
Epoch:[ 51 15 ] loss: 0.42153114080429077 2022-05-29 17:04:55.510766
Epoch:[ 51 16 ] loss: 0.42564329504966736 2022-05-29 17:05:02.591396
Epoch:[ 51 17 ] loss: 0.4231358766555786 2022-05-29 17:05:03.377064
Epoch:[ 51 18 ] loss: 0.4201878607273102 2022-05-29 17:05:04.166855
Epoch:[ 51 19 ] loss: 0.42188289761543274 2022-05-29 17:05:04.943242
Training_Epoch:[ 51 ] Training_loss: 0.4212596818804741 2022-05-29 17:05:04.943939
learning rate:  0.00013107200000000006
val: 1 0.5306687355041504
val: 2 0.5470747351646423
val: 3 0.518429696559906
val: 4 0.5045791268348694
val: 5 0.5230267643928528
val: 6 0.5117560029029846
val: 7 0.5198805928230286
val: 8 0.5302015542984009
val: 9 0.5415774583816528
val: 10 0.5234290957450867
val: 11 0.528250515460968
val: 12 0.5213925838470459
val: 13 0.5492334365844727
val: 14 0.5218890309333801
val: 15 0.5206753015518188
val: 16 0.5441064238548279
val: 17 0.5252938270568848
val: 18 0.5309168696403503
val: 19 0.4969034194946289
val: 20 0.555374026298523
val_Epoch:[ 51 ] val_loss: 0.5272329598665237 2022-05-29 17:05:10.115793
start training 2022-05-29 17:05:10.207569
Epoch:[ 52 0 ] loss: 0.4210042655467987 2022-05-29 17:05:33.970274
Epoch:[ 52 1 ] loss: 0.4226002097129822 2022-05-29 17:05:34.748703
Epoch:[ 52 2 ] loss: 0.41707003116607666 2022-05-29 17:05:35.523066
Epoch:[ 52 3 ] loss: 0.41678115725517273 2022-05-29 17:05:36.309900
Epoch:[ 52 4 ] loss: 0.416196346282959 2022-05-29 17:05:37.096704
Epoch:[ 52 5 ] loss: 0.4189015030860901 2022-05-29 17:05:37.870965
Epoch:[ 52 6 ] loss: 0.42507877945899963 2022-05-29 17:05:38.656263
Epoch:[ 52 7 ] loss: 0.4196719825267792 2022-05-29 17:05:39.432586
Epoch:[ 52 8 ] loss: 0.41986820101737976 2022-05-29 17:05:40.210403
Epoch:[ 52 9 ] loss: 0.4236260652542114 2022-05-29 17:05:40.984742
Epoch:[ 52 10 ] loss: 0.42534971237182617 2022-05-29 17:05:41.761845
Epoch:[ 52 11 ] loss: 0.42443785071372986 2022-05-29 17:05:42.535320
Epoch:[ 52 12 ] loss: 0.41855454444885254 2022-05-29 17:05:43.309846
Epoch:[ 52 13 ] loss: 0.4217773675918579 2022-05-29 17:05:44.083753
Epoch:[ 52 14 ] loss: 0.41993391513824463 2022-05-29 17:05:44.860704
Epoch:[ 52 15 ] loss: 0.4220139980316162 2022-05-29 17:05:45.638468
Epoch:[ 52 16 ] loss: 0.4194985330104828 2022-05-29 17:05:52.748075
Epoch:[ 52 17 ] loss: 0.42525142431259155 2022-05-29 17:05:53.525190
Epoch:[ 52 18 ] loss: 0.4197486340999603 2022-05-29 17:05:54.314601
Epoch:[ 52 19 ] loss: 0.4223816692829132 2022-05-29 17:05:55.089292
Training_Epoch:[ 52 ] Training_loss: 0.42098730951547625 2022-05-29 17:05:55.089970
learning rate:  0.00013107200000000006
netparams have been saved once 52
val: 1 0.5182549357414246
val: 2 0.5303532481193542
val: 3 0.5240136981010437
val: 4 0.5298426151275635
val: 5 0.5470480918884277
val: 6 0.5329734683036804
val: 7 0.5064885020256042
val: 8 0.5325517058372498
val: 9 0.5226170420646667
val: 10 0.5430435538291931
val: 11 0.5143376588821411
val: 12 0.5227701663970947
val: 13 0.5206085443496704
val: 14 0.5169468522071838
val: 15 0.5206720232963562
val: 16 0.508597731590271
val: 17 0.5389704704284668
val: 18 0.5234949588775635
val: 19 0.5187745094299316
val: 20 0.5357877016067505
val_Epoch:[ 52 ] val_loss: 0.5254073739051819 2022-05-29 17:06:00.405473
start training 2022-05-29 17:06:00.500746
Epoch:[ 53 0 ] loss: 0.4200557768344879 2022-05-29 17:06:22.591138
Epoch:[ 53 1 ] loss: 0.4233231544494629 2022-05-29 17:06:23.382053
Epoch:[ 53 2 ] loss: 0.4209311902523041 2022-05-29 17:06:24.684593
Epoch:[ 53 3 ] loss: 0.4193394184112549 2022-05-29 17:06:25.463338
Epoch:[ 53 4 ] loss: 0.418282151222229 2022-05-29 17:06:26.239610
Epoch:[ 53 5 ] loss: 0.42352747917175293 2022-05-29 17:06:27.012907
Epoch:[ 53 6 ] loss: 0.41964128613471985 2022-05-29 17:06:27.787983
Epoch:[ 53 7 ] loss: 0.42014363408088684 2022-05-29 17:06:28.562347
Epoch:[ 53 8 ] loss: 0.42311665415763855 2022-05-29 17:06:29.340044
Epoch:[ 53 9 ] loss: 0.4207425117492676 2022-05-29 17:06:30.129328
Epoch:[ 53 10 ] loss: 0.42055433988571167 2022-05-29 17:06:30.908259
Epoch:[ 53 11 ] loss: 0.4189874529838562 2022-05-29 17:06:31.693619
Epoch:[ 53 12 ] loss: 0.4187743663787842 2022-05-29 17:06:32.468784
Epoch:[ 53 13 ] loss: 0.4219084084033966 2022-05-29 17:06:33.244933
Epoch:[ 53 14 ] loss: 0.417570561170578 2022-05-29 17:06:34.019274
Epoch:[ 53 15 ] loss: 0.4175673723220825 2022-05-29 17:06:34.796215
Epoch:[ 53 16 ] loss: 0.4201644957065582 2022-05-29 17:06:42.140625
Epoch:[ 53 17 ] loss: 0.42144662141799927 2022-05-29 17:06:42.918758
Epoch:[ 53 18 ] loss: 0.4247514009475708 2022-05-29 17:06:43.822125
Epoch:[ 53 19 ] loss: 0.42090415954589844 2022-05-29 17:06:44.596062
Training_Epoch:[ 53 ] Training_loss: 0.420586621761322 2022-05-29 17:06:44.596729
learning rate:  0.00013107200000000006
val: 1 0.5359769463539124
val: 2 0.5354722738265991
val: 3 0.5305067300796509
val: 4 0.5140756368637085
val: 5 0.5253860354423523
val: 6 0.5272307991981506
val: 7 0.5347281694412231
val: 8 0.523284912109375
val: 9 0.5406386852264404
val: 10 0.5592195391654968
val: 11 0.5352287888526917
val: 12 0.5166794657707214
val: 13 0.5368051528930664
val: 14 0.5172879099845886
val: 15 0.5135895013809204
val: 16 0.5012391805648804
val: 17 0.5178294777870178
val: 18 0.523457944393158
val: 19 0.5180045962333679
val: 20 0.5226879715919495
val_Epoch:[ 53 ] val_loss: 0.5264664858579635 2022-05-29 17:06:49.746448
start training 2022-05-29 17:06:49.842217
Epoch:[ 54 0 ] loss: 0.4189281463623047 2022-05-29 17:07:13.897452
Epoch:[ 54 1 ] loss: 0.4203442931175232 2022-05-29 17:07:14.684004
Epoch:[ 54 2 ] loss: 0.41874420642852783 2022-05-29 17:07:15.461843
Epoch:[ 54 3 ] loss: 0.41714054346084595 2022-05-29 17:07:16.238228
Epoch:[ 54 4 ] loss: 0.41977787017822266 2022-05-29 17:07:17.014309
Epoch:[ 54 5 ] loss: 0.4195300042629242 2022-05-29 17:07:17.792404
Epoch:[ 54 6 ] loss: 0.42077067494392395 2022-05-29 17:07:18.567568
Epoch:[ 54 7 ] loss: 0.4223152995109558 2022-05-29 17:07:19.353381
Epoch:[ 54 8 ] loss: 0.41856762766838074 2022-05-29 17:07:20.138180
Epoch:[ 54 9 ] loss: 0.42325031757354736 2022-05-29 17:07:20.914487
Epoch:[ 54 10 ] loss: 0.4162294268608093 2022-05-29 17:07:21.692683
Epoch:[ 54 11 ] loss: 0.4220523238182068 2022-05-29 17:07:22.468622
Epoch:[ 54 12 ] loss: 0.4217686653137207 2022-05-29 17:07:23.244401
Epoch:[ 54 13 ] loss: 0.4216114282608032 2022-05-29 17:07:24.017943
Epoch:[ 54 14 ] loss: 0.4215276837348938 2022-05-29 17:07:24.793006
Epoch:[ 54 15 ] loss: 0.4181433618068695 2022-05-29 17:07:25.567263
Epoch:[ 54 16 ] loss: 0.4235771894454956 2022-05-29 17:07:32.680002
Epoch:[ 54 17 ] loss: 0.420859694480896 2022-05-29 17:07:33.455034
Epoch:[ 54 18 ] loss: 0.4166179597377777 2022-05-29 17:07:34.259260
Epoch:[ 54 19 ] loss: 0.4165685772895813 2022-05-29 17:07:35.036814
Training_Epoch:[ 54 ] Training_loss: 0.4199162647128105 2022-05-29 17:07:35.037610
learning rate:  0.00013107200000000006
netparams have been saved once 54
val: 1 0.525540828704834
val: 2 0.540271520614624
val: 3 0.5214877724647522
val: 4 0.5157418251037598
val: 5 0.5267193913459778
val: 6 0.510601818561554
val: 7 0.5306297540664673
val: 8 0.5634085536003113
val: 9 0.5308786034584045
val: 10 0.5381287932395935
val: 11 0.5361661314964294
val: 12 0.5327500104904175
val: 13 0.520828902721405
val: 14 0.5183525085449219
val: 15 0.5456077456474304
val: 16 0.5269237160682678
val: 17 0.5465129613876343
val: 18 0.5307144522666931
val: 19 0.5297715067863464
val: 20 0.5355017185211182
val_Epoch:[ 54 ] val_loss: 0.5313269257545471 2022-05-29 17:07:40.362874
start training 2022-05-29 17:07:40.459932
Epoch:[ 55 0 ] loss: 0.4198751449584961 2022-05-29 17:08:03.634003
Epoch:[ 55 1 ] loss: 0.4195632338523865 2022-05-29 17:08:04.460134
Epoch:[ 55 2 ] loss: 0.41387704014778137 2022-05-29 17:08:05.234007
Epoch:[ 55 3 ] loss: 0.4163847863674164 2022-05-29 17:08:06.010343
Epoch:[ 55 4 ] loss: 0.41940686106681824 2022-05-29 17:08:06.788850
Epoch:[ 55 5 ] loss: 0.4193404018878937 2022-05-29 17:08:07.565612
Epoch:[ 55 6 ] loss: 0.42145857214927673 2022-05-29 17:08:08.342075
Epoch:[ 55 7 ] loss: 0.419662743806839 2022-05-29 17:08:09.116665
Epoch:[ 55 8 ] loss: 0.4211970269680023 2022-05-29 17:08:09.893847
Epoch:[ 55 9 ] loss: 0.416962593793869 2022-05-29 17:08:10.690837
Epoch:[ 55 10 ] loss: 0.420207142829895 2022-05-29 17:08:11.469301
Epoch:[ 55 11 ] loss: 0.4195491373538971 2022-05-29 17:08:12.248456
Epoch:[ 55 12 ] loss: 0.421028733253479 2022-05-29 17:08:13.034563
Epoch:[ 55 13 ] loss: 0.4212663471698761 2022-05-29 17:08:13.823839
Epoch:[ 55 14 ] loss: 0.4219686686992645 2022-05-29 17:08:14.598573
Epoch:[ 55 15 ] loss: 0.42027509212493896 2022-05-29 17:08:15.372824
Epoch:[ 55 16 ] loss: 0.41952019929885864 2022-05-29 17:08:23.810459
Epoch:[ 55 17 ] loss: 0.4188004732131958 2022-05-29 17:08:24.585450
Epoch:[ 55 18 ] loss: 0.41886481642723083 2022-05-29 17:08:25.366867
Epoch:[ 55 19 ] loss: 0.4214278757572174 2022-05-29 17:08:26.155162
Training_Epoch:[ 55 ] Training_loss: 0.41953184455633163 2022-05-29 17:08:26.155881
learning rate:  0.00013107200000000006
val: 1 0.5152759552001953
val: 2 0.5235735177993774
val: 3 0.5331214666366577
val: 4 0.5261056423187256
val: 5 0.5371927618980408
val: 6 0.5288072824478149
val: 7 0.5078206658363342
val: 8 0.5133476853370667
val: 9 0.5164000391960144
val: 10 0.5337415337562561
val: 11 0.5281633138656616
val: 12 0.5181325078010559
val: 13 0.5586451292037964
val: 14 0.5167766213417053
val: 15 0.5198094844818115
val: 16 0.5202227830886841
val: 17 0.528437614440918
val: 18 0.5408058166503906
val: 19 0.5168184041976929
val: 20 0.5282729864120483
val_Epoch:[ 55 ] val_loss: 0.5255735605955124 2022-05-29 17:08:31.445282
start training 2022-05-29 17:08:31.538816
Epoch:[ 56 0 ] loss: 0.4185592532157898 2022-05-29 17:08:54.932751
Epoch:[ 56 1 ] loss: 0.41885998845100403 2022-05-29 17:08:55.707447
Epoch:[ 56 2 ] loss: 0.41619953513145447 2022-05-29 17:08:56.482440
Epoch:[ 56 3 ] loss: 0.41424456238746643 2022-05-29 17:08:57.256526
Epoch:[ 56 4 ] loss: 0.41988661885261536 2022-05-29 17:08:58.033867
Epoch:[ 56 5 ] loss: 0.4219631850719452 2022-05-29 17:08:58.811807
Epoch:[ 56 6 ] loss: 0.41772058606147766 2022-05-29 17:08:59.589589
Epoch:[ 56 7 ] loss: 0.41779032349586487 2022-05-29 17:09:00.364402
Epoch:[ 56 8 ] loss: 0.4232530891895294 2022-05-29 17:09:01.137995
Epoch:[ 56 9 ] loss: 0.4217960238456726 2022-05-29 17:09:01.914615
Epoch:[ 56 10 ] loss: 0.41982483863830566 2022-05-29 17:09:02.688421
Epoch:[ 56 11 ] loss: 0.4183754324913025 2022-05-29 17:09:03.465845
Epoch:[ 56 12 ] loss: 0.4198176860809326 2022-05-29 17:09:04.252534
Epoch:[ 56 13 ] loss: 0.41863641142845154 2022-05-29 17:09:05.027600
Epoch:[ 56 14 ] loss: 0.4161466658115387 2022-05-29 17:09:05.816790
Epoch:[ 56 15 ] loss: 0.41835176944732666 2022-05-29 17:09:06.604388
Epoch:[ 56 16 ] loss: 0.42154720425605774 2022-05-29 17:09:14.362266
Epoch:[ 56 17 ] loss: 0.4180184304714203 2022-05-29 17:09:15.149290
Epoch:[ 56 18 ] loss: 0.4187198877334595 2022-05-29 17:09:15.941898
Epoch:[ 56 19 ] loss: 0.4197191298007965 2022-05-29 17:09:16.719046
Training_Epoch:[ 56 ] Training_loss: 0.4189715310931206 2022-05-29 17:09:16.719747
learning rate:  0.00013107200000000006
netparams have been saved once 56
val: 1 0.5439447164535522
val: 2 0.5275238752365112
val: 3 0.5170732736587524
val: 4 0.5321547985076904
val: 5 0.5359103083610535
val: 6 0.5244118571281433
val: 7 0.5260615348815918
val: 8 0.5465776324272156
val: 9 0.5147403478622437
val: 10 0.5223760008811951
val: 11 0.5377445816993713
val: 12 0.5047369003295898
val: 13 0.5199636816978455
val: 14 0.5109319686889648
val: 15 0.528670608997345
val: 16 0.5454245805740356
val: 17 0.5560020208358765
val: 18 0.5269882678985596
val: 19 0.5241400003433228
val: 20 0.5530150532722473
val_Epoch:[ 56 ] val_loss: 0.5299196004867553 2022-05-29 17:09:22.057749
start training 2022-05-29 17:09:22.151703
Epoch:[ 57 0 ] loss: 0.42220914363861084 2022-05-29 17:09:46.259357
Epoch:[ 57 1 ] loss: 0.41676610708236694 2022-05-29 17:09:47.034015
Epoch:[ 57 2 ] loss: 0.4186457693576813 2022-05-29 17:09:47.819889
Epoch:[ 57 3 ] loss: 0.4173583686351776 2022-05-29 17:09:48.597583
Epoch:[ 57 4 ] loss: 0.4172302484512329 2022-05-29 17:09:49.385282
Epoch:[ 57 5 ] loss: 0.4227948486804962 2022-05-29 17:09:50.162317
Epoch:[ 57 6 ] loss: 0.41827815771102905 2022-05-29 17:09:50.939539
Epoch:[ 57 7 ] loss: 0.41878730058670044 2022-05-29 17:09:51.717686
Epoch:[ 57 8 ] loss: 0.4206809401512146 2022-05-29 17:09:52.495475
Epoch:[ 57 9 ] loss: 0.4219747483730316 2022-05-29 17:09:53.272045
Epoch:[ 57 10 ] loss: 0.4220302104949951 2022-05-29 17:09:54.050182
Epoch:[ 57 11 ] loss: 0.42328694462776184 2022-05-29 17:09:54.923125
Epoch:[ 57 12 ] loss: 0.41624659299850464 2022-05-29 17:09:55.714598
Epoch:[ 57 13 ] loss: 0.41870346665382385 2022-05-29 17:09:56.493261
Epoch:[ 57 14 ] loss: 0.41722264885902405 2022-05-29 17:09:57.269630
Epoch:[ 57 15 ] loss: 0.4183507561683655 2022-05-29 17:09:58.046890
Epoch:[ 57 16 ] loss: 0.4209789037704468 2022-05-29 17:10:04.613994
Epoch:[ 57 17 ] loss: 0.42066842317581177 2022-05-29 17:10:05.399598
Epoch:[ 57 18 ] loss: 0.41799092292785645 2022-05-29 17:10:06.178560
Epoch:[ 57 19 ] loss: 0.42385923862457275 2022-05-29 17:10:06.953610
Training_Epoch:[ 57 ] Training_loss: 0.41970318704843523 2022-05-29 17:10:06.954327
learning rate:  0.00013107200000000006
val: 1 0.5269383192062378
val: 2 0.5224680304527283
val: 3 0.5143387317657471
val: 4 0.5240201950073242
val: 5 0.5260696411132812
val: 6 0.5300132036209106
val: 7 0.5343261361122131
val: 8 0.5414035320281982
val: 9 0.5286632776260376
val: 10 0.5199863910675049
val: 11 0.5408090353012085
val: 12 0.5334312319755554
val: 13 0.537497878074646
val: 14 0.5203591585159302
val: 15 0.5382063984870911
val: 16 0.5453141927719116
val: 17 0.5348434448242188
val: 18 0.5247377157211304
val: 19 0.5361257791519165
val: 20 0.5257216095924377
val_Epoch:[ 57 ] val_loss: 0.5302636951208115 2022-05-29 17:10:12.254570
start training 2022-05-29 17:10:12.345347
Epoch:[ 58 0 ] loss: 0.4186360836029053 2022-05-29 17:10:34.339281
Epoch:[ 58 1 ] loss: 0.4213395118713379 2022-05-29 17:10:35.154762
Epoch:[ 58 2 ] loss: 0.4214736223220825 2022-05-29 17:10:35.973502
Epoch:[ 58 3 ] loss: 0.42118149995803833 2022-05-29 17:10:36.747601
Epoch:[ 58 4 ] loss: 0.4162639379501343 2022-05-29 17:10:37.533310
Epoch:[ 58 5 ] loss: 0.4214998185634613 2022-05-29 17:10:38.306375
Epoch:[ 58 6 ] loss: 0.4181777834892273 2022-05-29 17:10:39.084006
Epoch:[ 58 7 ] loss: 0.42454656958580017 2022-05-29 17:10:39.874229
Epoch:[ 58 8 ] loss: 0.41674718260765076 2022-05-29 17:10:40.649523
Epoch:[ 58 9 ] loss: 0.4172019958496094 2022-05-29 17:10:41.434999
Epoch:[ 58 10 ] loss: 0.415249764919281 2022-05-29 17:10:42.208136
Epoch:[ 58 11 ] loss: 0.42164361476898193 2022-05-29 17:10:42.981716
Epoch:[ 58 12 ] loss: 0.4213842749595642 2022-05-29 17:10:43.754322
Epoch:[ 58 13 ] loss: 0.4177546203136444 2022-05-29 17:10:44.531916
Epoch:[ 58 14 ] loss: 0.42132797837257385 2022-05-29 17:10:45.308851
Epoch:[ 58 15 ] loss: 0.42077726125717163 2022-05-29 17:10:46.081782
Epoch:[ 58 16 ] loss: 0.41531556844711304 2022-05-29 17:10:54.453659
Epoch:[ 58 17 ] loss: 0.4150760769844055 2022-05-29 17:10:55.227216
Epoch:[ 58 18 ] loss: 0.4188576936721802 2022-05-29 17:10:56.005293
Epoch:[ 58 19 ] loss: 0.42012259364128113 2022-05-29 17:10:56.789617
Training_Epoch:[ 58 ] Training_loss: 0.4192288726568222 2022-05-29 17:10:56.790329
learning rate:  0.00013107200000000006
netparams have been saved once 58
val: 1 0.5118497610092163
val: 2 0.521043062210083
val: 3 0.5347604155540466
val: 4 0.5149443745613098
val: 5 0.5330431461334229
val: 6 0.5520690083503723
val: 7 0.527398407459259
val: 8 0.5280405282974243
val: 9 0.5234816074371338
val: 10 0.5352907180786133
val: 11 0.5344564318656921
val: 12 0.5136123299598694
val: 13 0.536756157875061
val: 14 0.5423464179039001
val: 15 0.5207003355026245
val: 16 0.5350750684738159
val: 17 0.524474561214447
val: 18 0.5244957804679871
val: 19 0.5180103182792664
val: 20 0.5199008584022522
val_Epoch:[ 58 ] val_loss: 0.5275874644517898 2022-05-29 17:11:02.004156
start training 2022-05-29 17:11:02.096581
Epoch:[ 59 0 ] loss: 0.4176579415798187 2022-05-29 17:11:24.261744
Epoch:[ 59 1 ] loss: 0.41847124695777893 2022-05-29 17:11:25.622170
Epoch:[ 59 2 ] loss: 0.41922298073768616 2022-05-29 17:11:26.411821
Epoch:[ 59 3 ] loss: 0.4187772274017334 2022-05-29 17:11:27.200940
Epoch:[ 59 4 ] loss: 0.4200392961502075 2022-05-29 17:11:27.974740
Epoch:[ 59 5 ] loss: 0.42100954055786133 2022-05-29 17:11:28.751892
Epoch:[ 59 6 ] loss: 0.41607969999313354 2022-05-29 17:11:29.524982
Epoch:[ 59 7 ] loss: 0.41702932119369507 2022-05-29 17:11:30.300835
Epoch:[ 59 8 ] loss: 0.4201134741306305 2022-05-29 17:11:31.075713
Epoch:[ 59 9 ] loss: 0.41879770159721375 2022-05-29 17:11:31.851442
Epoch:[ 59 10 ] loss: 0.4202587306499481 2022-05-29 17:11:32.625475
Epoch:[ 59 11 ] loss: 0.41706860065460205 2022-05-29 17:11:33.398785
Epoch:[ 59 12 ] loss: 0.4155823588371277 2022-05-29 17:11:34.172391
Epoch:[ 59 13 ] loss: 0.4185185134410858 2022-05-29 17:11:34.957321
Epoch:[ 59 14 ] loss: 0.4199085831642151 2022-05-29 17:11:35.735564
Epoch:[ 59 15 ] loss: 0.41819924116134644 2022-05-29 17:11:36.511161
Epoch:[ 59 16 ] loss: 0.41935238242149353 2022-05-29 17:11:43.802694
Epoch:[ 59 17 ] loss: 0.4199560880661011 2022-05-29 17:11:44.588807
Epoch:[ 59 18 ] loss: 0.4162170886993408 2022-05-29 17:11:45.378926
Epoch:[ 59 19 ] loss: 0.42133629322052 2022-05-29 17:11:46.162956
Training_Epoch:[ 59 ] Training_loss: 0.418679815530777 2022-05-29 17:11:46.163692
learning rate:  0.00013107200000000006
val: 1 0.5373150706291199
val: 2 0.5049596428871155
val: 3 0.541710615158081
val: 4 0.5419223308563232
val: 5 0.519370436668396
val: 6 0.5483262538909912
val: 7 0.5437749624252319
val: 8 0.5324549674987793
val: 9 0.5145549774169922
val: 10 0.5147006511688232
val: 11 0.5220365524291992
val: 12 0.5127192735671997
val: 13 0.5343195796012878
val: 14 0.5417938232421875
val: 15 0.5389285683631897
val: 16 0.5070493221282959
val: 17 0.5407893657684326
val: 18 0.5228111743927002
val: 19 0.5235490798950195
val: 20 0.5245261192321777
val_Epoch:[ 59 ] val_loss: 0.5283806383609772 2022-05-29 17:11:51.352805
start training 2022-05-29 17:11:51.451608
Epoch:[ 60 0 ] loss: 0.41855424642562866 2022-05-29 17:12:15.489663
Epoch:[ 60 1 ] loss: 0.4197966158390045 2022-05-29 17:12:16.266424
Epoch:[ 60 2 ] loss: 0.4198843538761139 2022-05-29 17:12:17.044656
Epoch:[ 60 3 ] loss: 0.41851651668548584 2022-05-29 17:12:17.823369
Epoch:[ 60 4 ] loss: 0.4189625084400177 2022-05-29 17:12:18.597586
Epoch:[ 60 5 ] loss: 0.4162536859512329 2022-05-29 17:12:19.370910
Epoch:[ 60 6 ] loss: 0.41957685351371765 2022-05-29 17:12:20.143135
Epoch:[ 60 7 ] loss: 0.4156525433063507 2022-05-29 17:12:20.916092
Epoch:[ 60 8 ] loss: 0.4170358180999756 2022-05-29 17:12:21.691458
Epoch:[ 60 9 ] loss: 0.42044469714164734 2022-05-29 17:12:22.468397
Epoch:[ 60 10 ] loss: 0.41602814197540283 2022-05-29 17:12:23.246914
Epoch:[ 60 11 ] loss: 0.41929638385772705 2022-05-29 17:12:24.023783
Epoch:[ 60 12 ] loss: 0.4184257686138153 2022-05-29 17:12:24.798738
Epoch:[ 60 13 ] loss: 0.42158108949661255 2022-05-29 17:12:25.574577
Epoch:[ 60 14 ] loss: 0.41912415623664856 2022-05-29 17:12:26.362808
Epoch:[ 60 15 ] loss: 0.4224904477596283 2022-05-29 17:12:27.150812
Epoch:[ 60 16 ] loss: 0.4183327257633209 2022-05-29 17:12:34.410326
Epoch:[ 60 17 ] loss: 0.41773349046707153 2022-05-29 17:12:35.183824
Epoch:[ 60 18 ] loss: 0.4175054728984833 2022-05-29 17:12:35.964855
Epoch:[ 60 19 ] loss: 0.4212299883365631 2022-05-29 17:12:36.751449
Training_Epoch:[ 60 ] Training_loss: 0.4188212752342224 2022-05-29 17:12:36.752218
learning rate:  0.00013107200000000006
netparams have been saved once 60
val: 1 0.5374320149421692
val: 2 0.5394049882888794
val: 3 0.5258055925369263
val: 4 0.5311028361320496
val: 5 0.518656313419342
val: 6 0.518731415271759
val: 7 0.5219528079032898
val: 8 0.5231808423995972
val: 9 0.5261046886444092
val: 10 0.5320197343826294
val: 11 0.5225920081138611
val: 12 0.5277285575866699
val: 13 0.544192373752594
val: 14 0.5285777449607849
val: 15 0.5234489440917969
val: 16 0.5243624448776245
val: 17 0.5441899299621582
val: 18 0.5232035517692566
val: 19 0.5453445911407471
val: 20 0.5140357613563538
val_Epoch:[ 60 ] val_loss: 0.5286033570766449 2022-05-29 17:12:42.112876
start training 2022-05-29 17:12:42.206303
Epoch:[ 61 0 ] loss: 0.41919469833374023 2022-05-29 17:13:07.522624
Epoch:[ 61 1 ] loss: 0.419307678937912 2022-05-29 17:13:08.310094
Epoch:[ 61 2 ] loss: 0.41664358973503113 2022-05-29 17:13:09.085767
Epoch:[ 61 3 ] loss: 0.41510245203971863 2022-05-29 17:13:09.873597
Epoch:[ 61 4 ] loss: 0.42010581493377686 2022-05-29 17:13:10.662216
Epoch:[ 61 5 ] loss: 0.4191931486129761 2022-05-29 17:13:11.439394
Epoch:[ 61 6 ] loss: 0.41896113753318787 2022-05-29 17:13:12.211827
Epoch:[ 61 7 ] loss: 0.41930246353149414 2022-05-29 17:13:12.988241
Epoch:[ 61 8 ] loss: 0.41698017716407776 2022-05-29 17:13:13.761980
Epoch:[ 61 9 ] loss: 0.4141441285610199 2022-05-29 17:13:14.539419
Epoch:[ 61 10 ] loss: 0.41963666677474976 2022-05-29 17:13:15.317633
Epoch:[ 61 11 ] loss: 0.4164524972438812 2022-05-29 17:13:16.091187
Epoch:[ 61 12 ] loss: 0.4158485531806946 2022-05-29 17:13:16.872005
Epoch:[ 61 13 ] loss: 0.4168165624141693 2022-05-29 17:13:17.658719
Epoch:[ 61 14 ] loss: 0.4198024868965149 2022-05-29 17:13:18.433857
Epoch:[ 61 15 ] loss: 0.41970738768577576 2022-05-29 17:13:19.207806
Epoch:[ 61 16 ] loss: 0.4138174057006836 2022-05-29 17:13:27.150764
Epoch:[ 61 17 ] loss: 0.41656121611595154 2022-05-29 17:13:27.941071
Epoch:[ 61 18 ] loss: 0.4213598966598511 2022-05-29 17:13:28.725635
Epoch:[ 61 19 ] loss: 0.4153881072998047 2022-05-29 17:13:29.502830
Training_Epoch:[ 61 ] Training_loss: 0.41771630346775057 2022-05-29 17:13:29.503474
learning rate:  0.00010485760000000006
val: 1 0.5283650755882263
val: 2 0.5357113480567932
val: 3 0.5316290855407715
val: 4 0.5360821485519409
val: 5 0.5181227326393127
val: 6 0.5260993838310242
val: 7 0.5226204991340637
val: 8 0.5403804183006287
val: 9 0.5142734050750732
val: 10 0.512172520160675
val: 11 0.5333113074302673
val: 12 0.5385980606079102
val: 13 0.5418707132339478
val: 14 0.5370434522628784
val: 15 0.5355428457260132
val: 16 0.5238589644432068
val: 17 0.5262448191642761
val: 18 0.5474873185157776
val: 19 0.5200873613357544
val: 20 0.5232555270195007
val_Epoch:[ 61 ] val_loss: 0.5296378493309021 2022-05-29 17:13:34.702061
start training 2022-05-29 17:13:34.799344
Epoch:[ 62 0 ] loss: 0.4218383729457855 2022-05-29 17:13:57.926498
Epoch:[ 62 1 ] loss: 0.4164634048938751 2022-05-29 17:13:58.730487
Epoch:[ 62 2 ] loss: 0.41606834530830383 2022-05-29 17:13:59.504614
Epoch:[ 62 3 ] loss: 0.4190843403339386 2022-05-29 17:14:00.282150
Epoch:[ 62 4 ] loss: 0.4199981987476349 2022-05-29 17:14:01.070452
Epoch:[ 62 5 ] loss: 0.416389137506485 2022-05-29 17:14:01.860811
Epoch:[ 62 6 ] loss: 0.4141624867916107 2022-05-29 17:14:02.637789
Epoch:[ 62 7 ] loss: 0.4196474254131317 2022-05-29 17:14:03.411976
Epoch:[ 62 8 ] loss: 0.41675588488578796 2022-05-29 17:14:04.185235
Epoch:[ 62 9 ] loss: 0.41767117381095886 2022-05-29 17:14:04.971158
Epoch:[ 62 10 ] loss: 0.4239530861377716 2022-05-29 17:14:05.747666
Epoch:[ 62 11 ] loss: 0.41556423902511597 2022-05-29 17:14:06.524769
Epoch:[ 62 12 ] loss: 0.41386380791664124 2022-05-29 17:14:07.300835
Epoch:[ 62 13 ] loss: 0.4174061119556427 2022-05-29 17:14:08.076382
Epoch:[ 62 14 ] loss: 0.4145522117614746 2022-05-29 17:14:08.850709
Epoch:[ 62 15 ] loss: 0.4173508286476135 2022-05-29 17:14:09.627136
Epoch:[ 62 16 ] loss: 0.4186024069786072 2022-05-29 17:14:17.096304
Epoch:[ 62 17 ] loss: 0.41322070360183716 2022-05-29 17:14:17.886788
Epoch:[ 62 18 ] loss: 0.41910579800605774 2022-05-29 17:14:18.678732
Epoch:[ 62 19 ] loss: 0.4139113426208496 2022-05-29 17:14:19.455887
Training_Epoch:[ 62 ] Training_loss: 0.4172804653644562 2022-05-29 17:14:19.456569
learning rate:  0.00010485760000000006
netparams have been saved once 62
val: 1 0.528386652469635
val: 2 0.5261061787605286
val: 3 0.5201544165611267
val: 4 0.529289186000824
val: 5 0.5285545587539673
val: 6 0.5296963453292847
val: 7 0.5253449082374573
val: 8 0.547050416469574
val: 9 0.5334917306900024
val: 10 0.5430197715759277
val: 11 0.5382089018821716
val: 12 0.5267016291618347
val: 13 0.5371649265289307
val: 14 0.5325438976287842
val: 15 0.538463830947876
val: 16 0.5191412568092346
val: 17 0.515727698802948
val: 18 0.5024897456169128
val: 19 0.522365152835846
val: 20 0.5235779285430908
val_Epoch:[ 62 ] val_loss: 0.5283739566802979 2022-05-29 17:14:24.966163
start training 2022-05-29 17:14:25.057209
Epoch:[ 63 0 ] loss: 0.4180351495742798 2022-05-29 17:14:47.384896
Epoch:[ 63 1 ] loss: 0.41568174958229065 2022-05-29 17:14:48.187450
Epoch:[ 63 2 ] loss: 0.41372591257095337 2022-05-29 17:14:48.974075
Epoch:[ 63 3 ] loss: 0.4162554144859314 2022-05-29 17:14:49.747981
Epoch:[ 63 4 ] loss: 0.41646409034729004 2022-05-29 17:14:50.537263
Epoch:[ 63 5 ] loss: 0.4189163148403168 2022-05-29 17:14:51.315124
Epoch:[ 63 6 ] loss: 0.4153045415878296 2022-05-29 17:14:52.104452
Epoch:[ 63 7 ] loss: 0.4175144135951996 2022-05-29 17:14:52.880253
Epoch:[ 63 8 ] loss: 0.41748037934303284 2022-05-29 17:14:53.667764
Epoch:[ 63 9 ] loss: 0.41660571098327637 2022-05-29 17:14:54.441782
Epoch:[ 63 10 ] loss: 0.415034681558609 2022-05-29 17:14:55.214100
Epoch:[ 63 11 ] loss: 0.41542500257492065 2022-05-29 17:14:55.991793
Epoch:[ 63 12 ] loss: 0.4210105836391449 2022-05-29 17:14:56.768459
Epoch:[ 63 13 ] loss: 0.4175757169723511 2022-05-29 17:14:57.547075
Epoch:[ 63 14 ] loss: 0.41586336493492126 2022-05-29 17:14:58.323742
Epoch:[ 63 15 ] loss: 0.4198668599128723 2022-05-29 17:14:59.098838
Epoch:[ 63 16 ] loss: 0.41752001643180847 2022-05-29 17:15:06.713998
Epoch:[ 63 17 ] loss: 0.4144859313964844 2022-05-29 17:15:07.486979
Epoch:[ 63 18 ] loss: 0.41500940918922424 2022-05-29 17:15:08.280951
Epoch:[ 63 19 ] loss: 0.4166055917739868 2022-05-29 17:15:09.072061
Training_Epoch:[ 63 ] Training_loss: 0.4167190417647362 2022-05-29 17:15:09.072775
learning rate:  0.00010485760000000006
val: 1 0.5230037569999695
val: 2 0.521148681640625
val: 3 0.5274165272712708
val: 4 0.5382291674613953
val: 5 0.5201329588890076
val: 6 0.5335602164268494
val: 7 0.5458582639694214
val: 8 0.5187416672706604
val: 9 0.5075066685676575
val: 10 0.5170210599899292
val: 11 0.5194045305252075
val: 12 0.5480191111564636
val: 13 0.5342007875442505
val: 14 0.5232047438621521
val: 15 0.5339683890342712
val: 16 0.5151643753051758
val: 17 0.5355105400085449
val: 18 0.5457480549812317
val: 19 0.5537732243537903
val: 20 0.5291935205459595
val_Epoch:[ 63 ] val_loss: 0.5295403122901916 2022-05-29 17:15:14.355767
start training 2022-05-29 17:15:14.452209
Epoch:[ 64 0 ] loss: 0.41255897283554077 2022-05-29 17:15:38.146086
Epoch:[ 64 1 ] loss: 0.4177677035331726 2022-05-29 17:15:38.920771
Epoch:[ 64 2 ] loss: 0.4175417721271515 2022-05-29 17:15:39.695358
Epoch:[ 64 3 ] loss: 0.4192379415035248 2022-05-29 17:15:40.469169
Epoch:[ 64 4 ] loss: 0.4151824116706848 2022-05-29 17:15:41.243350
Epoch:[ 64 5 ] loss: 0.4161975085735321 2022-05-29 17:15:42.019578
Epoch:[ 64 6 ] loss: 0.41753101348876953 2022-05-29 17:15:42.795881
Epoch:[ 64 7 ] loss: 0.4159919321537018 2022-05-29 17:15:43.569245
Epoch:[ 64 8 ] loss: 0.4155022203922272 2022-05-29 17:15:44.345107
Epoch:[ 64 9 ] loss: 0.41594889760017395 2022-05-29 17:15:45.118735
Epoch:[ 64 10 ] loss: 0.4187103807926178 2022-05-29 17:15:45.893425
Epoch:[ 64 11 ] loss: 0.4181940257549286 2022-05-29 17:15:46.668588
Epoch:[ 64 12 ] loss: 0.4152704179286957 2022-05-29 17:15:47.458386
Epoch:[ 64 13 ] loss: 0.4161469340324402 2022-05-29 17:15:48.248961
Epoch:[ 64 14 ] loss: 0.417759507894516 2022-05-29 17:15:49.025442
Epoch:[ 64 15 ] loss: 0.41760802268981934 2022-05-29 17:15:49.814064
Epoch:[ 64 16 ] loss: 0.4176788926124573 2022-05-29 17:15:56.779708
Epoch:[ 64 17 ] loss: 0.4169481098651886 2022-05-29 17:15:57.564451
Epoch:[ 64 18 ] loss: 0.41378623247146606 2022-05-29 17:15:58.343379
Epoch:[ 64 19 ] loss: 0.4182244539260864 2022-05-29 17:15:59.118884
Training_Epoch:[ 64 ] Training_loss: 0.41668936759233477 2022-05-29 17:15:59.119549
learning rate:  0.00010485760000000006
netparams have been saved once 64
val: 1 0.5302784442901611
val: 2 0.5366840958595276
val: 3 0.54157954454422
val: 4 0.524304211139679
val: 5 0.5386641621589661
val: 6 0.5288611054420471
val: 7 0.5348126292228699
val: 8 0.5301887392997742
val: 9 0.5288077592849731
val: 10 0.5306251049041748
val: 11 0.5116233229637146
val: 12 0.5310640335083008
val: 13 0.508948802947998
val: 14 0.5217732191085815
val: 15 0.5439693927764893
val: 16 0.5213363766670227
val: 17 0.5448819398880005
val: 18 0.5335995554924011
val: 19 0.5159747004508972
val: 20 0.5224886536598206
val_Epoch:[ 64 ] val_loss: 0.529023289680481 2022-05-29 17:16:04.443534
start training 2022-05-29 17:16:04.538694
Epoch:[ 65 0 ] loss: 0.41563862562179565 2022-05-29 17:16:27.725897
Epoch:[ 65 1 ] loss: 0.41603347659111023 2022-05-29 17:16:28.537695
Epoch:[ 65 2 ] loss: 0.41547346115112305 2022-05-29 17:16:29.315339
Epoch:[ 65 3 ] loss: 0.4177228510379791 2022-05-29 17:16:30.090957
Epoch:[ 65 4 ] loss: 0.41409924626350403 2022-05-29 17:16:30.864056
Epoch:[ 65 5 ] loss: 0.4136877655982971 2022-05-29 17:16:31.627441
Epoch:[ 65 6 ] loss: 0.41453608870506287 2022-05-29 17:16:32.393761
Epoch:[ 65 7 ] loss: 0.41982758045196533 2022-05-29 17:16:33.171064
Epoch:[ 65 8 ] loss: 0.41690555214881897 2022-05-29 17:16:33.938183
Epoch:[ 65 9 ] loss: 0.41665568947792053 2022-05-29 17:16:34.714643
Epoch:[ 65 10 ] loss: 0.41802674531936646 2022-05-29 17:16:35.489650
Epoch:[ 65 11 ] loss: 0.4135996997356415 2022-05-29 17:16:36.268866
Epoch:[ 65 12 ] loss: 0.41321200132369995 2022-05-29 17:16:37.045160
Epoch:[ 65 13 ] loss: 0.4193494915962219 2022-05-29 17:16:37.824148
Epoch:[ 65 14 ] loss: 0.4171876907348633 2022-05-29 17:16:38.603504
Epoch:[ 65 15 ] loss: 0.41948235034942627 2022-05-29 17:16:39.381028
Epoch:[ 65 16 ] loss: 0.41278502345085144 2022-05-29 17:16:46.652262
Epoch:[ 65 17 ] loss: 0.42169129848480225 2022-05-29 17:16:47.425859
Epoch:[ 65 18 ] loss: 0.41528454422950745 2022-05-29 17:16:48.227281
Epoch:[ 65 19 ] loss: 0.4169348180294037 2022-05-29 17:16:49.012588
Training_Epoch:[ 65 ] Training_loss: 0.4164067000150681 2022-05-29 17:16:49.013394
learning rate:  0.00010485760000000006
val: 1 0.501092255115509
val: 2 0.5459717512130737
val: 3 0.514589250087738
val: 4 0.5300185084342957
val: 5 0.5278793573379517
val: 6 0.5218343138694763
val: 7 0.5387265086174011
val: 8 0.5356594324111938
val: 9 0.5431807041168213
val: 10 0.5225058197975159
val: 11 0.5266845226287842
val: 12 0.5040689706802368
val: 13 0.5236349105834961
val: 14 0.5305080413818359
val: 15 0.5514903664588928
val: 16 0.5551531910896301
val: 17 0.5291897654533386
val: 18 0.5344685316085815
val: 19 0.519659161567688
val: 20 0.5291835069656372
val_Epoch:[ 65 ] val_loss: 0.5292749434709549 2022-05-29 17:16:54.209728
start training 2022-05-29 17:16:54.305371
Epoch:[ 66 0 ] loss: 0.412610799074173 2022-05-29 17:17:16.679394
Epoch:[ 66 1 ] loss: 0.42184799909591675 2022-05-29 17:17:18.475673
Epoch:[ 66 2 ] loss: 0.41339918971061707 2022-05-29 17:17:19.266294
Epoch:[ 66 3 ] loss: 0.41503024101257324 2022-05-29 17:17:20.043393
Epoch:[ 66 4 ] loss: 0.4158399701118469 2022-05-29 17:17:20.819649
Epoch:[ 66 5 ] loss: 0.41382884979248047 2022-05-29 17:17:21.608196
Epoch:[ 66 6 ] loss: 0.4201646149158478 2022-05-29 17:17:22.381057
Epoch:[ 66 7 ] loss: 0.41697850823402405 2022-05-29 17:17:23.158490
Epoch:[ 66 8 ] loss: 0.41494229435920715 2022-05-29 17:17:23.933624
Epoch:[ 66 9 ] loss: 0.41882577538490295 2022-05-29 17:17:24.709915
Epoch:[ 66 10 ] loss: 0.41658225655555725 2022-05-29 17:17:25.487049
Epoch:[ 66 11 ] loss: 0.41672083735466003 2022-05-29 17:17:26.260396
Epoch:[ 66 12 ] loss: 0.4145331382751465 2022-05-29 17:17:27.036796
Epoch:[ 66 13 ] loss: 0.41293591260910034 2022-05-29 17:17:27.810458
Epoch:[ 66 14 ] loss: 0.4153144955635071 2022-05-29 17:17:28.587254
Epoch:[ 66 15 ] loss: 0.41371625661849976 2022-05-29 17:17:29.365010
Epoch:[ 66 16 ] loss: 0.41156455874443054 2022-05-29 17:17:36.548004
Epoch:[ 66 17 ] loss: 0.415996253490448 2022-05-29 17:17:37.335918
Epoch:[ 66 18 ] loss: 0.4148102104663849 2022-05-29 17:17:38.115857
Epoch:[ 66 19 ] loss: 0.41444867849349976 2022-05-29 17:17:38.890306
Training_Epoch:[ 66 ] Training_loss: 0.4155045419931412 2022-05-29 17:17:38.890975
learning rate:  0.00010485760000000006
netparams have been saved once 66
val: 1 0.5248635411262512
val: 2 0.5273323655128479
val: 3 0.5361288189888
val: 4 0.5393106937408447
val: 5 0.5409443378448486
val: 6 0.5267933011054993
val: 7 0.5309365391731262
val: 8 0.5160853266716003
val: 9 0.5469986200332642
val: 10 0.5406114459037781
val: 11 0.5379977822303772
val: 12 0.518676221370697
val: 13 0.5158621668815613
val: 14 0.506848931312561
val: 15 0.5073611736297607
val: 16 0.5446967482566833
val: 17 0.5343698263168335
val: 18 0.5194083452224731
val: 19 0.5367215871810913
val: 20 0.524092972278595
val_Epoch:[ 66 ] val_loss: 0.5288020372390747 2022-05-29 17:17:44.102018
start training 2022-05-29 17:17:44.200388
Epoch:[ 67 0 ] loss: 0.4174152910709381 2022-05-29 17:18:07.722894
Epoch:[ 67 1 ] loss: 0.41305944323539734 2022-05-29 17:18:08.501254
Epoch:[ 67 2 ] loss: 0.41682422161102295 2022-05-29 17:18:09.278336
Epoch:[ 67 3 ] loss: 0.4122101962566376 2022-05-29 17:18:10.054299
Epoch:[ 67 4 ] loss: 0.41429272294044495 2022-05-29 17:18:10.831246
Epoch:[ 67 5 ] loss: 0.41596487164497375 2022-05-29 17:18:11.605492
Epoch:[ 67 6 ] loss: 0.4166922867298126 2022-05-29 17:18:12.393154
Epoch:[ 67 7 ] loss: 0.4117608070373535 2022-05-29 17:18:13.167071
Epoch:[ 67 8 ] loss: 0.41978126764297485 2022-05-29 17:18:13.943795
Epoch:[ 67 9 ] loss: 0.41653940081596375 2022-05-29 17:18:14.733370
Epoch:[ 67 10 ] loss: 0.41161587834358215 2022-05-29 17:18:15.509353
Epoch:[ 67 11 ] loss: 0.41426727175712585 2022-05-29 17:18:16.295579
Epoch:[ 67 12 ] loss: 0.41688692569732666 2022-05-29 17:18:17.069039
Epoch:[ 67 13 ] loss: 0.41460201144218445 2022-05-29 17:18:17.843401
Epoch:[ 67 14 ] loss: 0.41375532746315 2022-05-29 17:18:18.617016
Epoch:[ 67 15 ] loss: 0.4187207520008087 2022-05-29 17:18:19.394161
Epoch:[ 67 16 ] loss: 0.41637909412384033 2022-05-29 17:18:26.934024
Epoch:[ 67 17 ] loss: 0.4181947410106659 2022-05-29 17:18:27.722196
Epoch:[ 67 18 ] loss: 0.41324424743652344 2022-05-29 17:18:28.503543
Epoch:[ 67 19 ] loss: 0.4156406819820404 2022-05-29 17:18:29.277790
Training_Epoch:[ 67 ] Training_loss: 0.41539237201213836 2022-05-29 17:18:29.278616
learning rate:  0.00010485760000000006
val: 1 0.5500333309173584
val: 2 0.5333430171012878
val: 3 0.5285997986793518
val: 4 0.543017566204071
val: 5 0.5265572667121887
val: 6 0.5440310835838318
val: 7 0.5290313959121704
val: 8 0.5341787934303284
val: 9 0.5337498188018799
val: 10 0.5384983420372009
val: 11 0.5285971164703369
val: 12 0.5335094332695007
val: 13 0.5225860476493835
val: 14 0.522441029548645
val: 15 0.5266318321228027
val: 16 0.5215089917182922
val: 17 0.5391807556152344
val: 18 0.5357863903045654
val: 19 0.5457631945610046
val: 20 0.5138418078422546
val_Epoch:[ 67 ] val_loss: 0.5325443506240845 2022-05-29 17:18:34.512707
start training 2022-05-29 17:18:34.610136
Epoch:[ 68 0 ] loss: 0.42043209075927734 2022-05-29 17:18:57.815112
Epoch:[ 68 1 ] loss: 0.41196054220199585 2022-05-29 17:18:58.635844
Epoch:[ 68 2 ] loss: 0.4163195490837097 2022-05-29 17:18:59.412173
Epoch:[ 68 3 ] loss: 0.4126960039138794 2022-05-29 17:19:00.189384
Epoch:[ 68 4 ] loss: 0.4105362594127655 2022-05-29 17:19:00.977278
Epoch:[ 68 5 ] loss: 0.4158150255680084 2022-05-29 17:19:01.752440
Epoch:[ 68 6 ] loss: 0.41286563873291016 2022-05-29 17:19:02.526399
Epoch:[ 68 7 ] loss: 0.4138493835926056 2022-05-29 17:19:03.296946
Epoch:[ 68 8 ] loss: 0.4096081554889679 2022-05-29 17:19:04.061879
Epoch:[ 68 9 ] loss: 0.417599618434906 2022-05-29 17:19:04.839998
Epoch:[ 68 10 ] loss: 0.4145009219646454 2022-05-29 17:19:05.618637
Epoch:[ 68 11 ] loss: 0.41559186577796936 2022-05-29 17:19:06.381536
Epoch:[ 68 12 ] loss: 0.4183133542537689 2022-05-29 17:19:07.160439
Epoch:[ 68 13 ] loss: 0.41656017303466797 2022-05-29 17:19:07.937047
Epoch:[ 68 14 ] loss: 0.4164712131023407 2022-05-29 17:19:08.712210
Epoch:[ 68 15 ] loss: 0.4162684679031372 2022-05-29 17:19:09.487362
Epoch:[ 68 16 ] loss: 0.41785696148872375 2022-05-29 17:19:16.933658
Epoch:[ 68 17 ] loss: 0.41717156767845154 2022-05-29 17:19:17.713578
Epoch:[ 68 18 ] loss: 0.4168108403682709 2022-05-29 17:19:18.498125
Epoch:[ 68 19 ] loss: 0.41730496287345886 2022-05-29 17:19:19.287074
Training_Epoch:[ 68 ] Training_loss: 0.415426629781723 2022-05-29 17:19:19.287994
learning rate:  0.00010485760000000006
netparams have been saved once 68
val: 1 0.5311758518218994
val: 2 0.5356070399284363
val: 3 0.531593918800354
val: 4 0.5323415994644165
val: 5 0.5115012526512146
val: 6 0.5072479844093323
val: 7 0.5260097980499268
val: 8 0.5335391163825989
val: 9 0.5363847613334656
val: 10 0.535957396030426
val: 11 0.5049037933349609
val: 12 0.5374953150749207
val: 13 0.531125545501709
val: 14 0.5220152139663696
val: 15 0.5371348857879639
val: 16 0.5403513312339783
val: 17 0.5253499746322632
val: 18 0.517996609210968
val: 19 0.5365320444107056
val: 20 0.5294833183288574
val_Epoch:[ 68 ] val_loss: 0.5281873375177384 2022-05-29 17:19:24.593300
start training 2022-05-29 17:19:24.690666
Epoch:[ 69 0 ] loss: 0.41793012619018555 2022-05-29 17:19:46.932153
Epoch:[ 69 1 ] loss: 0.41587644815444946 2022-05-29 17:19:47.707206
Epoch:[ 69 2 ] loss: 0.4157290458679199 2022-05-29 17:19:48.522126
Epoch:[ 69 3 ] loss: 0.41858190298080444 2022-05-29 17:19:49.301430
Epoch:[ 69 4 ] loss: 0.41456902027130127 2022-05-29 17:19:50.078435
Epoch:[ 69 5 ] loss: 0.4142645299434662 2022-05-29 17:19:50.857417
Epoch:[ 69 6 ] loss: 0.4171034097671509 2022-05-29 17:19:51.633093
Epoch:[ 69 7 ] loss: 0.4155443608760834 2022-05-29 17:19:52.406944
Epoch:[ 69 8 ] loss: 0.41437241435050964 2022-05-29 17:19:53.180632
Epoch:[ 69 9 ] loss: 0.41543060541152954 2022-05-29 17:19:53.954600
Epoch:[ 69 10 ] loss: 0.4146743416786194 2022-05-29 17:19:54.732856
Epoch:[ 69 11 ] loss: 0.4161359369754791 2022-05-29 17:19:55.522819
Epoch:[ 69 12 ] loss: 0.41486695408821106 2022-05-29 17:19:56.297996
Epoch:[ 69 13 ] loss: 0.41506674885749817 2022-05-29 17:19:57.086760
Epoch:[ 69 14 ] loss: 0.4149956703186035 2022-05-29 17:19:57.874001
Epoch:[ 69 15 ] loss: 0.41512346267700195 2022-05-29 17:19:58.650254
Epoch:[ 69 16 ] loss: 0.4105875492095947 2022-05-29 17:20:07.071787
Epoch:[ 69 17 ] loss: 0.4143286347389221 2022-05-29 17:20:07.861178
Epoch:[ 69 18 ] loss: 0.41682228446006775 2022-05-29 17:20:08.644286
Epoch:[ 69 19 ] loss: 0.4123131334781647 2022-05-29 17:20:09.419819
Training_Epoch:[ 69 ] Training_loss: 0.41521582901477816 2022-05-29 17:20:09.420540
learning rate:  0.00010485760000000006
val: 1 0.5273894667625427
val: 2 0.5274073481559753
val: 3 0.5309845805168152
val: 4 0.5465230941772461
val: 5 0.5250994563102722
val: 6 0.5225620865821838
val: 7 0.5219656825065613
val: 8 0.50848388671875
val: 9 0.533503532409668
val: 10 0.5444516539573669
val: 11 0.5192829370498657
val: 12 0.5303938388824463
val: 13 0.5200734734535217
val: 14 0.5251045823097229
val: 15 0.5343438386917114
val: 16 0.5275073051452637
val: 17 0.540166974067688
val: 18 0.5323113799095154
val: 19 0.5464712381362915
val: 20 0.5360227823257446
val_Epoch:[ 69 ] val_loss: 0.5300024569034576 2022-05-29 17:20:14.652529
start training 2022-05-29 17:20:14.751909
Epoch:[ 70 0 ] loss: 0.4149295389652252 2022-05-29 17:20:37.707768
Epoch:[ 70 1 ] loss: 0.41782084107398987 2022-05-29 17:20:38.552627
Epoch:[ 70 2 ] loss: 0.4162149429321289 2022-05-29 17:20:39.339396
Epoch:[ 70 3 ] loss: 0.41383951902389526 2022-05-29 17:20:40.113747
Epoch:[ 70 4 ] loss: 0.41380029916763306 2022-05-29 17:20:40.890684
Epoch:[ 70 5 ] loss: 0.4112778902053833 2022-05-29 17:20:41.668905
Epoch:[ 70 6 ] loss: 0.4164822995662689 2022-05-29 17:20:42.445094
Epoch:[ 70 7 ] loss: 0.41323772072792053 2022-05-29 17:20:43.232808
Epoch:[ 70 8 ] loss: 0.4148646891117096 2022-05-29 17:20:44.008016
Epoch:[ 70 9 ] loss: 0.41653144359588623 2022-05-29 17:20:44.783854
Epoch:[ 70 10 ] loss: 0.4172745645046234 2022-05-29 17:20:45.558117
Epoch:[ 70 11 ] loss: 0.41579023003578186 2022-05-29 17:20:46.334682
Epoch:[ 70 12 ] loss: 0.41118067502975464 2022-05-29 17:20:47.111514
Epoch:[ 70 13 ] loss: 0.41070353984832764 2022-05-29 17:20:47.890108
Epoch:[ 70 14 ] loss: 0.4137847423553467 2022-05-29 17:20:48.666842
Epoch:[ 70 15 ] loss: 0.42058834433555603 2022-05-29 17:20:49.452216
Epoch:[ 70 16 ] loss: 0.4122593402862549 2022-05-29 17:20:56.958482
Epoch:[ 70 17 ] loss: 0.41571709513664246 2022-05-29 17:20:57.742667
Epoch:[ 70 18 ] loss: 0.41498127579689026 2022-05-29 17:20:58.523780
Epoch:[ 70 19 ] loss: 0.4177495241165161 2022-05-29 17:20:59.299323
Training_Epoch:[ 70 ] Training_loss: 0.41495142579078675 2022-05-29 17:20:59.299979
learning rate:  0.00010485760000000006
netparams have been saved once 70
val: 1 0.5245724320411682
val: 2 0.5202108025550842
val: 3 0.5286409258842468
val: 4 0.5182868838310242
val: 5 0.5456807613372803
val: 6 0.5463927388191223
val: 7 0.5404475331306458
val: 8 0.5307412147521973
val: 9 0.5206637978553772
val: 10 0.52989262342453
val: 11 0.49874791502952576
val: 12 0.5202963948249817
val: 13 0.5203086733818054
val: 14 0.5294083952903748
val: 15 0.5388438701629639
val: 16 0.5610660910606384
val: 17 0.5319865345954895
val: 18 0.525415301322937
val: 19 0.5172328352928162
val: 20 0.5284485816955566
val_Epoch:[ 70 ] val_loss: 0.5288642153143883 2022-05-29 17:21:04.572959
start training 2022-05-29 17:21:04.670008
Epoch:[ 71 0 ] loss: 0.41435760259628296 2022-05-29 17:21:27.039983
Epoch:[ 71 1 ] loss: 0.410847932100296 2022-05-29 17:21:27.923138
Epoch:[ 71 2 ] loss: 0.41444242000579834 2022-05-29 17:21:28.695839
Epoch:[ 71 3 ] loss: 0.4119098484516144 2022-05-29 17:21:29.469649
Epoch:[ 71 4 ] loss: 0.41163545846939087 2022-05-29 17:21:30.243077
Epoch:[ 71 5 ] loss: 0.4130097031593323 2022-05-29 17:21:31.020262
Epoch:[ 71 6 ] loss: 0.4140608608722687 2022-05-29 17:21:31.809381
Epoch:[ 71 7 ] loss: 0.4175325334072113 2022-05-29 17:21:32.584928
Epoch:[ 71 8 ] loss: 0.41533297300338745 2022-05-29 17:21:33.360321
Epoch:[ 71 9 ] loss: 0.41713833808898926 2022-05-29 17:21:34.147196
Epoch:[ 71 10 ] loss: 0.41718995571136475 2022-05-29 17:21:34.924162
Epoch:[ 71 11 ] loss: 0.41650649905204773 2022-05-29 17:21:35.699420
Epoch:[ 71 12 ] loss: 0.41171994805336 2022-05-29 17:21:36.476999
Epoch:[ 71 13 ] loss: 0.4112681746482849 2022-05-29 17:21:37.253597
Epoch:[ 71 14 ] loss: 0.4130520224571228 2022-05-29 17:21:38.031124
Epoch:[ 71 15 ] loss: 0.4119717478752136 2022-05-29 17:21:38.806123
Epoch:[ 71 16 ] loss: 0.4153907001018524 2022-05-29 17:21:47.331242
Epoch:[ 71 17 ] loss: 0.4154665768146515 2022-05-29 17:21:48.107244
Epoch:[ 71 18 ] loss: 0.41255101561546326 2022-05-29 17:21:48.897200
Epoch:[ 71 19 ] loss: 0.41328996419906616 2022-05-29 17:21:49.673151
Training_Epoch:[ 71 ] Training_loss: 0.41393371373414994 2022-05-29 17:21:49.673824
learning rate:  8.388608000000005e-05
val: 1 0.5706339478492737
val: 2 0.5314358472824097
val: 3 0.5185456275939941
val: 4 0.5120391249656677
val: 5 0.5470007061958313
val: 6 0.5198065638542175
val: 7 0.5417016744613647
val: 8 0.5187620520591736
val: 9 0.5300474762916565
val: 10 0.5481625199317932
val: 11 0.5438192486763
val: 12 0.5363303422927856
val: 13 0.5245674252510071
val: 14 0.5237435102462769
val: 15 0.5217640399932861
val: 16 0.5258627533912659
val: 17 0.5180720090866089
val: 18 0.5416396260261536
val: 19 0.5168778896331787
val: 20 0.520722508430481
val_Epoch:[ 71 ] val_loss: 0.5305767446756363 2022-05-29 17:21:54.856961
start training 2022-05-29 17:21:54.959698
Epoch:[ 72 0 ] loss: 0.4149203300476074 2022-05-29 17:22:18.136498
Epoch:[ 72 1 ] loss: 0.4109460115432739 2022-05-29 17:22:18.948190
Epoch:[ 72 2 ] loss: 0.41261938214302063 2022-05-29 17:22:19.724929
Epoch:[ 72 3 ] loss: 0.4158111810684204 2022-05-29 17:22:20.500763
Epoch:[ 72 4 ] loss: 0.4171670079231262 2022-05-29 17:22:21.274505
Epoch:[ 72 5 ] loss: 0.41132351756095886 2022-05-29 17:22:22.047855
Epoch:[ 72 6 ] loss: 0.40988650918006897 2022-05-29 17:22:22.837471
Epoch:[ 72 7 ] loss: 0.40974703431129456 2022-05-29 17:22:23.613376
Epoch:[ 72 8 ] loss: 0.41351816058158875 2022-05-29 17:22:24.403007
Epoch:[ 72 9 ] loss: 0.41107702255249023 2022-05-29 17:22:25.180273
Epoch:[ 72 10 ] loss: 0.4179341495037079 2022-05-29 17:22:25.955740
Epoch:[ 72 11 ] loss: 0.4101085066795349 2022-05-29 17:22:26.743539
Epoch:[ 72 12 ] loss: 0.41539299488067627 2022-05-29 17:22:27.516305
Epoch:[ 72 13 ] loss: 0.4154033362865448 2022-05-29 17:22:28.294450
Epoch:[ 72 14 ] loss: 0.4118334949016571 2022-05-29 17:22:29.071935
Epoch:[ 72 15 ] loss: 0.4186796247959137 2022-05-29 17:22:29.848371
Epoch:[ 72 16 ] loss: 0.4145185947418213 2022-05-29 17:22:36.880517
Epoch:[ 72 17 ] loss: 0.41205325722694397 2022-05-29 17:22:37.654186
Epoch:[ 72 18 ] loss: 0.41005194187164307 2022-05-29 17:22:38.432966
Epoch:[ 72 19 ] loss: 0.41546082496643066 2022-05-29 17:22:39.219412
Training_Epoch:[ 72 ] Training_loss: 0.4134226441383362 2022-05-29 17:22:39.220048
learning rate:  8.388608000000005e-05
netparams have been saved once 72
val: 1 0.5210108160972595
val: 2 0.5379488468170166
val: 3 0.5236159563064575
val: 4 0.5238147974014282
val: 5 0.5469567775726318
val: 6 0.5273974537849426
val: 7 0.5402461886405945
val: 8 0.5251922607421875
val: 9 0.5366779565811157
val: 10 0.532360315322876
val: 11 0.5323837995529175
val: 12 0.5198415517807007
val: 13 0.524747908115387
val: 14 0.5424697399139404
val: 15 0.5268843770027161
val: 16 0.5428965091705322
val: 17 0.5463666915893555
val: 18 0.5328149199485779
val: 19 0.5304476618766785
val: 20 0.5281921625137329
val_Epoch:[ 72 ] val_loss: 0.5321133345365524 2022-05-29 17:22:44.493508
start training 2022-05-29 17:22:44.587949
Epoch:[ 73 0 ] loss: 0.40947604179382324 2022-05-29 17:23:07.283995
Epoch:[ 73 1 ] loss: 0.4152054786682129 2022-05-29 17:23:08.111515
Epoch:[ 73 2 ] loss: 0.41069355607032776 2022-05-29 17:23:08.889469
Epoch:[ 73 3 ] loss: 0.41210484504699707 2022-05-29 17:23:09.664862
Epoch:[ 73 4 ] loss: 0.414115309715271 2022-05-29 17:23:10.439352
Epoch:[ 73 5 ] loss: 0.41420266032218933 2022-05-29 17:23:11.214000
Epoch:[ 73 6 ] loss: 0.4108295142650604 2022-05-29 17:23:12.000628
Epoch:[ 73 7 ] loss: 0.41379135847091675 2022-05-29 17:23:12.777588
Epoch:[ 73 8 ] loss: 0.4138718843460083 2022-05-29 17:23:13.556479
Epoch:[ 73 9 ] loss: 0.4167281985282898 2022-05-29 17:23:14.335255
Epoch:[ 73 10 ] loss: 0.4150954484939575 2022-05-29 17:23:15.111437
Epoch:[ 73 11 ] loss: 0.41228148341178894 2022-05-29 17:23:15.887312
Epoch:[ 73 12 ] loss: 0.41130635142326355 2022-05-29 17:23:16.676136
Epoch:[ 73 13 ] loss: 0.41025784611701965 2022-05-29 17:23:17.462986
Epoch:[ 73 14 ] loss: 0.4113195538520813 2022-05-29 17:23:18.240886
Epoch:[ 73 15 ] loss: 0.4133497476577759 2022-05-29 17:23:19.019094
Epoch:[ 73 16 ] loss: 0.4155377447605133 2022-05-29 17:23:27.157803
Epoch:[ 73 17 ] loss: 0.4171668291091919 2022-05-29 17:23:27.932383
Epoch:[ 73 18 ] loss: 0.40997064113616943 2022-05-29 17:23:28.722124
Epoch:[ 73 19 ] loss: 0.4160487651824951 2022-05-29 17:23:29.496386
Training_Epoch:[ 73 ] Training_loss: 0.41316766291856766 2022-05-29 17:23:29.497102
learning rate:  8.388608000000005e-05
val: 1 0.5294492840766907
val: 2 0.5398745536804199
val: 3 0.5270687341690063
val: 4 0.5295777320861816
val: 5 0.5242687463760376
val: 6 0.5279802083969116
val: 7 0.5253958106040955
val: 8 0.5355332493782043
val: 9 0.5400126576423645
val: 10 0.5232030749320984
val: 11 0.5424488186836243
val: 12 0.5259051322937012
val: 13 0.5305394530296326
val: 14 0.5218426585197449
val: 15 0.5248886346817017
val: 16 0.5198352932929993
val: 17 0.5334643125534058
val: 18 0.5208836793899536
val: 19 0.5375481843948364
val: 20 0.5360139012336731
val_Epoch:[ 73 ] val_loss: 0.5297867059707642 2022-05-29 17:23:34.698303
start training 2022-05-29 17:23:34.795018
Epoch:[ 74 0 ] loss: 0.4130307137966156 2022-05-29 17:23:56.913082
Epoch:[ 74 1 ] loss: 0.4144238531589508 2022-05-29 17:23:57.781903
Epoch:[ 74 2 ] loss: 0.41163647174835205 2022-05-29 17:23:58.606099
Epoch:[ 74 3 ] loss: 0.414578914642334 2022-05-29 17:23:59.379490
Epoch:[ 74 4 ] loss: 0.4126138985157013 2022-05-29 17:24:00.154800
Epoch:[ 74 5 ] loss: 0.41380974650382996 2022-05-29 17:24:00.928371
Epoch:[ 74 6 ] loss: 0.41160038113594055 2022-05-29 17:24:01.713850
Epoch:[ 74 7 ] loss: 0.41174671053886414 2022-05-29 17:24:02.487167
Epoch:[ 74 8 ] loss: 0.4144974648952484 2022-05-29 17:24:03.262825
Epoch:[ 74 9 ] loss: 0.411922812461853 2022-05-29 17:24:04.038814
Epoch:[ 74 10 ] loss: 0.41696661710739136 2022-05-29 17:24:04.828194
Epoch:[ 74 11 ] loss: 0.4117705523967743 2022-05-29 17:24:05.604318
Epoch:[ 74 12 ] loss: 0.4151642620563507 2022-05-29 17:24:06.378114
Epoch:[ 74 13 ] loss: 0.4091963469982147 2022-05-29 17:24:07.155375
Epoch:[ 74 14 ] loss: 0.41150981187820435 2022-05-29 17:24:07.929544
Epoch:[ 74 15 ] loss: 0.4132018983364105 2022-05-29 17:24:08.717529
Epoch:[ 74 16 ] loss: 0.41285786032676697 2022-05-29 17:24:17.062267
Epoch:[ 74 17 ] loss: 0.41210368275642395 2022-05-29 17:24:17.837025
Epoch:[ 74 18 ] loss: 0.41740065813064575 2022-05-29 17:24:18.641546
Epoch:[ 74 19 ] loss: 0.4164624810218811 2022-05-29 17:24:19.415533
Training_Epoch:[ 74 ] Training_loss: 0.41332475692033765 2022-05-29 17:24:19.416189
learning rate:  8.388608000000005e-05
netparams have been saved once 74
val: 1 0.5285577774047852
val: 2 0.5367496013641357
val: 3 0.5327357649803162
val: 4 0.5289974212646484
val: 5 0.530791163444519
val: 6 0.5349618196487427
val: 7 0.5463792085647583
val: 8 0.5215824246406555
val: 9 0.5197607278823853
val: 10 0.5271093845367432
val: 11 0.5343242883682251
val: 12 0.531162440776825
val: 13 0.527786910533905
val: 14 0.5280647277832031
val: 15 0.5179129838943481
val: 16 0.5356401801109314
val: 17 0.5379441380500793
val: 18 0.518104076385498
val: 19 0.5215319991111755
val: 20 0.5256274342536926
val_Epoch:[ 74 ] val_loss: 0.5292862236499787 2022-05-29 17:24:24.740114
start training 2022-05-29 17:24:24.832944
Epoch:[ 75 0 ] loss: 0.4132557809352875 2022-05-29 17:24:47.820136
Epoch:[ 75 1 ] loss: 0.4115774631500244 2022-05-29 17:24:48.621298
Epoch:[ 75 2 ] loss: 0.41284626722335815 2022-05-29 17:24:49.397431
Epoch:[ 75 3 ] loss: 0.4132000803947449 2022-05-29 17:24:50.174213
Epoch:[ 75 4 ] loss: 0.4157220721244812 2022-05-29 17:24:50.964414
Epoch:[ 75 5 ] loss: 0.41356977820396423 2022-05-29 17:24:51.752728
Epoch:[ 75 6 ] loss: 0.4117717444896698 2022-05-29 17:24:52.528131
Epoch:[ 75 7 ] loss: 0.4100489318370819 2022-05-29 17:24:53.300810
Epoch:[ 75 8 ] loss: 0.41175663471221924 2022-05-29 17:24:54.074808
Epoch:[ 75 9 ] loss: 0.41175705194473267 2022-05-29 17:24:54.865187
Epoch:[ 75 10 ] loss: 0.4139446020126343 2022-05-29 17:24:55.640336
Epoch:[ 75 11 ] loss: 0.4124211072921753 2022-05-29 17:24:56.416428
Epoch:[ 75 12 ] loss: 0.4131265878677368 2022-05-29 17:24:57.193655
Epoch:[ 75 13 ] loss: 0.41395115852355957 2022-05-29 17:24:57.969515
Epoch:[ 75 14 ] loss: 0.41330987215042114 2022-05-29 17:24:58.745964
Epoch:[ 75 15 ] loss: 0.4157067835330963 2022-05-29 17:24:59.519162
Epoch:[ 75 16 ] loss: 0.4112570881843567 2022-05-29 17:25:06.811490
Epoch:[ 75 17 ] loss: 0.41826528310775757 2022-05-29 17:25:07.586335
Epoch:[ 75 18 ] loss: 0.4142698645591736 2022-05-29 17:25:08.378625
Epoch:[ 75 19 ] loss: 0.4091598689556122 2022-05-29 17:25:09.165974
Training_Epoch:[ 75 ] Training_loss: 0.41304590106010436 2022-05-29 17:25:09.166690
learning rate:  8.388608000000005e-05
val: 1 0.5384123921394348
val: 2 0.5443117022514343
val: 3 0.5363495945930481
val: 4 0.5427429676055908
val: 5 0.5238912105560303
val: 6 0.5266536474227905
val: 7 0.5361176133155823
val: 8 0.5330097675323486
val: 9 0.5251160860061646
val: 10 0.5376438498497009
val: 11 0.5641232132911682
val: 12 0.5167131423950195
val: 13 0.5165584087371826
val: 14 0.5292863249778748
val: 15 0.5352848172187805
val: 16 0.5250968933105469
val: 17 0.5169219970703125
val: 18 0.532913863658905
val: 19 0.5178804993629456
val: 20 0.5308025479316711
val_Epoch:[ 75 ] val_loss: 0.5314915269613266 2022-05-29 17:25:14.370596
start training 2022-05-29 17:25:14.469676
Epoch:[ 76 0 ] loss: 0.41535213589668274 2022-05-29 17:25:37.149523
Epoch:[ 76 1 ] loss: 0.4108341634273529 2022-05-29 17:25:37.983557
Epoch:[ 76 2 ] loss: 0.413993775844574 2022-05-29 17:25:38.758959
Epoch:[ 76 3 ] loss: 0.41452571749687195 2022-05-29 17:25:39.536709
Epoch:[ 76 4 ] loss: 0.4137507677078247 2022-05-29 17:25:40.313938
Epoch:[ 76 5 ] loss: 0.4132370054721832 2022-05-29 17:25:41.101231
Epoch:[ 76 6 ] loss: 0.4126746952533722 2022-05-29 17:25:41.877205
Epoch:[ 76 7 ] loss: 0.41363441944122314 2022-05-29 17:25:42.651902
Epoch:[ 76 8 ] loss: 0.4145383834838867 2022-05-29 17:25:43.426430
Epoch:[ 76 9 ] loss: 0.40813833475112915 2022-05-29 17:25:44.200345
Epoch:[ 76 10 ] loss: 0.4149019718170166 2022-05-29 17:25:44.975225
Epoch:[ 76 11 ] loss: 0.4135817289352417 2022-05-29 17:25:45.753553
Epoch:[ 76 12 ] loss: 0.41172313690185547 2022-05-29 17:25:46.531669
Epoch:[ 76 13 ] loss: 0.4101523160934448 2022-05-29 17:25:47.318872
Epoch:[ 76 14 ] loss: 0.41349250078201294 2022-05-29 17:25:48.093676
Epoch:[ 76 15 ] loss: 0.4130943715572357 2022-05-29 17:25:48.869900
Epoch:[ 76 16 ] loss: 0.41574761271476746 2022-05-29 17:25:56.454832
Epoch:[ 76 17 ] loss: 0.4123488962650299 2022-05-29 17:25:57.263841
Epoch:[ 76 18 ] loss: 0.414049357175827 2022-05-29 17:25:58.061241
Epoch:[ 76 19 ] loss: 0.41260674595832825 2022-05-29 17:25:58.836263
Training_Epoch:[ 76 ] Training_loss: 0.413118901848793 2022-05-29 17:25:58.836981
learning rate:  8.388608000000005e-05
netparams have been saved once 76
val: 1 0.5302270650863647
val: 2 0.5212422013282776
val: 3 0.5418323278427124
val: 4 0.53461754322052
val: 5 0.5346783399581909
val: 6 0.5316274762153625
val: 7 0.5267705321311951
val: 8 0.5148820281028748
val: 9 0.5377792716026306
val: 10 0.5210396647453308
val: 11 0.5539396405220032
val: 12 0.536790668964386
val: 13 0.5335061550140381
val: 14 0.5181776881217957
val: 15 0.5526250600814819
val: 16 0.5248792767524719
val: 17 0.5484522581100464
val: 18 0.5345603227615356
val: 19 0.5536409616470337
val: 20 0.5315662622451782
val_Epoch:[ 76 ] val_loss: 0.5341417372226716 2022-05-29 17:26:04.098110
start training 2022-05-29 17:26:04.199649
Epoch:[ 77 0 ] loss: 0.415976881980896 2022-05-29 17:26:28.204665
Epoch:[ 77 1 ] loss: 0.4138375222682953 2022-05-29 17:26:28.991075
Epoch:[ 77 2 ] loss: 0.4110350012779236 2022-05-29 17:26:29.765238
Epoch:[ 77 3 ] loss: 0.4162224531173706 2022-05-29 17:26:30.539079
Epoch:[ 77 4 ] loss: 0.4115016460418701 2022-05-29 17:26:31.326076
Epoch:[ 77 5 ] loss: 0.4081163704395294 2022-05-29 17:26:32.116137
Epoch:[ 77 6 ] loss: 0.41704410314559937 2022-05-29 17:26:32.888531
Epoch:[ 77 7 ] loss: 0.41007882356643677 2022-05-29 17:26:33.662990
Epoch:[ 77 8 ] loss: 0.4114108085632324 2022-05-29 17:26:34.437515
Epoch:[ 77 9 ] loss: 0.4141373932361603 2022-05-29 17:26:35.211112
Epoch:[ 77 10 ] loss: 0.41556617617607117 2022-05-29 17:26:35.984834
Epoch:[ 77 11 ] loss: 0.4092744290828705 2022-05-29 17:26:36.763375
Epoch:[ 77 12 ] loss: 0.41131535172462463 2022-05-29 17:26:37.541584
Epoch:[ 77 13 ] loss: 0.41628777980804443 2022-05-29 17:26:38.319738
Epoch:[ 77 14 ] loss: 0.410007506608963 2022-05-29 17:26:39.093323
Epoch:[ 77 15 ] loss: 0.4067773222923279 2022-05-29 17:26:39.868564
Epoch:[ 77 16 ] loss: 0.4190049469470978 2022-05-29 17:26:46.453672
Epoch:[ 77 17 ] loss: 0.4136195182800293 2022-05-29 17:26:47.228043
Epoch:[ 77 18 ] loss: 0.41081318259239197 2022-05-29 17:26:48.021619
Epoch:[ 77 19 ] loss: 0.4122810661792755 2022-05-29 17:26:48.797833
Training_Epoch:[ 77 ] Training_loss: 0.4127154141664505 2022-05-29 17:26:48.798533
learning rate:  8.388608000000005e-05
val: 1 0.5449740290641785
val: 2 0.5351645350456238
val: 3 0.5247110724449158
val: 4 0.5244954824447632
val: 5 0.5055657029151917
val: 6 0.5300025343894958
val: 7 0.5407813787460327
val: 8 0.5376192927360535
val: 9 0.5534361600875854
val: 10 0.5276069641113281
val: 11 0.5313605666160583
val: 12 0.526041567325592
val: 13 0.5424612760543823
val: 14 0.5233920216560364
val: 15 0.5297947525978088
val: 16 0.5313198566436768
val: 17 0.5050342082977295
val: 18 0.5378068089485168
val: 19 0.5286884903907776
val: 20 0.5214409232139587
val_Epoch:[ 77 ] val_loss: 0.5300848811864853 2022-05-29 17:26:54.071434
start training 2022-05-29 17:26:54.168964
Epoch:[ 78 0 ] loss: 0.4130174219608307 2022-05-29 17:27:16.631098
Epoch:[ 78 1 ] loss: 0.4135389029979706 2022-05-29 17:27:17.442110
Epoch:[ 78 2 ] loss: 0.4145451784133911 2022-05-29 17:27:18.216438
Epoch:[ 78 3 ] loss: 0.41118964552879333 2022-05-29 17:27:18.991490
Epoch:[ 78 4 ] loss: 0.40901362895965576 2022-05-29 17:27:19.778200
Epoch:[ 78 5 ] loss: 0.4098440706729889 2022-05-29 17:27:20.556099
Epoch:[ 78 6 ] loss: 0.41072699427604675 2022-05-29 17:27:21.332010
Epoch:[ 78 7 ] loss: 0.41184812784194946 2022-05-29 17:27:22.109385
Epoch:[ 78 8 ] loss: 0.4116423726081848 2022-05-29 17:27:22.884947
Epoch:[ 78 9 ] loss: 0.4127635359764099 2022-05-29 17:27:23.672067
Epoch:[ 78 10 ] loss: 0.4107441008090973 2022-05-29 17:27:24.445986
Epoch:[ 78 11 ] loss: 0.4118971824645996 2022-05-29 17:27:25.220680
Epoch:[ 78 12 ] loss: 0.411191463470459 2022-05-29 17:27:25.998580
Epoch:[ 78 13 ] loss: 0.4167380928993225 2022-05-29 17:27:26.775153
Epoch:[ 78 14 ] loss: 0.4172995984554291 2022-05-29 17:27:27.564764
Epoch:[ 78 15 ] loss: 0.41007471084594727 2022-05-29 17:27:28.339475
Epoch:[ 78 16 ] loss: 0.4161403775215149 2022-05-29 17:27:36.467485
Epoch:[ 78 17 ] loss: 0.4151044487953186 2022-05-29 17:27:37.253082
Epoch:[ 78 18 ] loss: 0.41218310594558716 2022-05-29 17:27:38.041951
Epoch:[ 78 19 ] loss: 0.4125780761241913 2022-05-29 17:27:38.818810
Training_Epoch:[ 78 ] Training_loss: 0.4126040518283844 2022-05-29 17:27:38.819463
learning rate:  8.388608000000005e-05
netparams have been saved once 78
val: 1 0.5194787383079529
val: 2 0.5335038304328918
val: 3 0.5430536866188049
val: 4 0.524637758731842
val: 5 0.5369011759757996
val: 6 0.5354357957839966
val: 7 0.5349821448326111
val: 8 0.5312908291816711
val: 9 0.5267338156700134
val: 10 0.5141381621360779
val: 11 0.5322189927101135
val: 12 0.5482191443443298
val: 13 0.5581314563751221
val: 14 0.5372931957244873
val: 15 0.5326310396194458
val: 16 0.5310598015785217
val: 17 0.532071053981781
val: 18 0.534555196762085
val: 19 0.5280637741088867
val: 20 0.5459144115447998
val_Epoch:[ 78 ] val_loss: 0.5340157002210617 2022-05-29 17:27:44.221062
start training 2022-05-29 17:27:44.317001
Epoch:[ 79 0 ] loss: 0.4099661707878113 2022-05-29 17:28:07.354245
Epoch:[ 79 1 ] loss: 0.4122062921524048 2022-05-29 17:28:08.219711
Epoch:[ 79 2 ] loss: 0.4107176661491394 2022-05-29 17:28:09.006720
Epoch:[ 79 3 ] loss: 0.4148060977458954 2022-05-29 17:28:09.790404
Epoch:[ 79 4 ] loss: 0.4107457995414734 2022-05-29 17:28:10.566169
Epoch:[ 79 5 ] loss: 0.4090961813926697 2022-05-29 17:28:11.339997
Epoch:[ 79 6 ] loss: 0.40933850407600403 2022-05-29 17:28:12.115695
Epoch:[ 79 7 ] loss: 0.40965646505355835 2022-05-29 17:28:12.892535
Epoch:[ 79 8 ] loss: 0.41667115688323975 2022-05-29 17:28:13.680465
Epoch:[ 79 9 ] loss: 0.4155644476413727 2022-05-29 17:28:14.453277
Epoch:[ 79 10 ] loss: 0.4135822653770447 2022-05-29 17:28:15.227798
Epoch:[ 79 11 ] loss: 0.41377151012420654 2022-05-29 17:28:16.002298
Epoch:[ 79 12 ] loss: 0.4104284346103668 2022-05-29 17:28:16.777575
Epoch:[ 79 13 ] loss: 0.4139047861099243 2022-05-29 17:28:17.555889
Epoch:[ 79 14 ] loss: 0.4093725383281708 2022-05-29 17:28:18.332486
Epoch:[ 79 15 ] loss: 0.4118281304836273 2022-05-29 17:28:19.108557
Epoch:[ 79 16 ] loss: 0.4165247678756714 2022-05-29 17:28:26.352732
Epoch:[ 79 17 ] loss: 0.41272807121276855 2022-05-29 17:28:27.263483
Epoch:[ 79 18 ] loss: 0.4148688316345215 2022-05-29 17:28:28.054459
Epoch:[ 79 19 ] loss: 0.40883898735046387 2022-05-29 17:28:28.827315
Training_Epoch:[ 79 ] Training_loss: 0.4122308552265167 2022-05-29 17:28:28.827982
learning rate:  8.388608000000005e-05
val: 1 0.5138575434684753
val: 2 0.5375611186027527
val: 3 0.527138352394104
val: 4 0.544712483882904
val: 5 0.516771674156189
val: 6 0.5260317325592041
val: 7 0.5033398270606995
val: 8 0.5123502016067505
val: 9 0.5367452502250671
val: 10 0.5494440197944641
val: 11 0.5516428351402283
val: 12 0.5366392135620117
val: 13 0.5277106761932373
val: 14 0.5348021984100342
val: 15 0.5338526964187622
val: 16 0.5305524468421936
val: 17 0.5414638519287109
val: 18 0.5341242551803589
val: 19 0.5199683904647827
val: 20 0.5241386294364929
val_Epoch:[ 79 ] val_loss: 0.5301423698663712 2022-05-29 17:28:34.028854
start training 2022-05-29 17:28:34.127679
Epoch:[ 80 0 ] loss: 0.4098127782344818 2022-05-29 17:28:57.820034
Epoch:[ 80 1 ] loss: 0.4138107895851135 2022-05-29 17:28:58.608219
Epoch:[ 80 2 ] loss: 0.40565580129623413 2022-05-29 17:28:59.382306
Epoch:[ 80 3 ] loss: 0.41092005372047424 2022-05-29 17:29:00.156012
Epoch:[ 80 4 ] loss: 0.4117514491081238 2022-05-29 17:29:00.940586
Epoch:[ 80 5 ] loss: 0.4132986068725586 2022-05-29 17:29:01.715827
Epoch:[ 80 6 ] loss: 0.415005624294281 2022-05-29 17:29:02.488387
Epoch:[ 80 7 ] loss: 0.4102519154548645 2022-05-29 17:29:03.264518
Epoch:[ 80 8 ] loss: 0.4113191068172455 2022-05-29 17:29:04.053974
Epoch:[ 80 9 ] loss: 0.4114832878112793 2022-05-29 17:29:04.829980
Epoch:[ 80 10 ] loss: 0.412011981010437 2022-05-29 17:29:05.604962
Epoch:[ 80 11 ] loss: 0.41259995102882385 2022-05-29 17:29:06.379177
Epoch:[ 80 12 ] loss: 0.41475945711135864 2022-05-29 17:29:07.153033
Epoch:[ 80 13 ] loss: 0.4104156196117401 2022-05-29 17:29:07.926475
Epoch:[ 80 14 ] loss: 0.41073328256607056 2022-05-29 17:29:08.701749
Epoch:[ 80 15 ] loss: 0.4110824763774872 2022-05-29 17:29:09.477135
Epoch:[ 80 16 ] loss: 0.4107799232006073 2022-05-29 17:29:16.276014
Epoch:[ 80 17 ] loss: 0.41209056973457336 2022-05-29 17:29:17.064841
Epoch:[ 80 18 ] loss: 0.41215550899505615 2022-05-29 17:29:17.857044
Epoch:[ 80 19 ] loss: 0.41814717650413513 2022-05-29 17:29:18.644057
Training_Epoch:[ 80 ] Training_loss: 0.4119042679667473 2022-05-29 17:29:18.644719
learning rate:  8.388608000000005e-05
netparams have been saved once 80
val: 1 0.5220653414726257
val: 2 0.5313351154327393
val: 3 0.5298746228218079
val: 4 0.5253452658653259
val: 5 0.5361241102218628
val: 6 0.5374047160148621
val: 7 0.5446179509162903
val: 8 0.5611545443534851
val: 9 0.5197249054908752
val: 10 0.5310554504394531
val: 11 0.5032494068145752
val: 12 0.5427051782608032
val: 13 0.543235719203949
val: 14 0.5394754409790039
val: 15 0.5230218768119812
val: 16 0.5206226706504822
val: 17 0.5335504412651062
val: 18 0.5142123699188232
val: 19 0.5500590801239014
val: 20 0.5498127341270447
val_Epoch:[ 80 ] val_loss: 0.5329323470592499 2022-05-29 17:29:23.948964
start training 2022-05-29 17:29:24.047744
Epoch:[ 81 0 ] loss: 0.41116034984588623 2022-05-29 17:29:48.048864
Epoch:[ 81 1 ] loss: 0.4139273464679718 2022-05-29 17:29:48.826049
Epoch:[ 81 2 ] loss: 0.41529351472854614 2022-05-29 17:29:49.601856
Epoch:[ 81 3 ] loss: 0.40956082940101624 2022-05-29 17:29:50.391870
Epoch:[ 81 4 ] loss: 0.41564860939979553 2022-05-29 17:29:51.166522
Epoch:[ 81 5 ] loss: 0.4084164500236511 2022-05-29 17:29:51.940924
Epoch:[ 81 6 ] loss: 0.41059768199920654 2022-05-29 17:29:52.716147
Epoch:[ 81 7 ] loss: 0.4071075916290283 2022-05-29 17:29:53.491085
Epoch:[ 81 8 ] loss: 0.4121876358985901 2022-05-29 17:29:54.279682
Epoch:[ 81 9 ] loss: 0.4139046370983124 2022-05-29 17:29:55.057724
Epoch:[ 81 10 ] loss: 0.4110199213027954 2022-05-29 17:29:55.833825
Epoch:[ 81 11 ] loss: 0.4133281707763672 2022-05-29 17:29:56.606863
Epoch:[ 81 12 ] loss: 0.4127503037452698 2022-05-29 17:29:57.381589
Epoch:[ 81 13 ] loss: 0.4087676405906677 2022-05-29 17:29:58.155280
Epoch:[ 81 14 ] loss: 0.41117244958877563 2022-05-29 17:29:58.928461
Epoch:[ 81 15 ] loss: 0.4095480442047119 2022-05-29 17:29:59.706563
Epoch:[ 81 16 ] loss: 0.4121520519256592 2022-05-29 17:30:06.491014
Epoch:[ 81 17 ] loss: 0.41043025255203247 2022-05-29 17:30:07.267912
Epoch:[ 81 18 ] loss: 0.4149865210056305 2022-05-29 17:30:08.072311
Epoch:[ 81 19 ] loss: 0.412071168422699 2022-05-29 17:30:08.845252
Training_Epoch:[ 81 ] Training_loss: 0.41170155853033064 2022-05-29 17:30:08.845920
learning rate:  6.710886400000004e-05
val: 1 0.5373715758323669
val: 2 0.5281345844268799
val: 3 0.5446015000343323
val: 4 0.527319073677063
val: 5 0.5479280352592468
val: 6 0.5358383655548096
val: 7 0.5389012694358826
val: 8 0.527611494064331
val: 9 0.540013313293457
val: 10 0.5422174334526062
val: 11 0.5146875977516174
val: 12 0.5217084884643555
val: 13 0.5520005822181702
val: 14 0.5456980466842651
val: 15 0.5268669724464417
val: 16 0.5205548405647278
val: 17 0.5056807398796082
val: 18 0.5533673763275146
val: 19 0.524631917476654
val: 20 0.5409478545188904
val_Epoch:[ 81 ] val_loss: 0.533804053068161 2022-05-29 17:30:14.105771
start training 2022-05-29 17:30:14.205592
Epoch:[ 82 0 ] loss: 0.41390344500541687 2022-05-29 17:30:37.634643
Epoch:[ 82 1 ] loss: 0.4100535809993744 2022-05-29 17:30:38.439277
Epoch:[ 82 2 ] loss: 0.4085110127925873 2022-05-29 17:30:39.216641
Epoch:[ 82 3 ] loss: 0.4120960235595703 2022-05-29 17:30:39.994728
Epoch:[ 82 4 ] loss: 0.4078615605831146 2022-05-29 17:30:40.769395
Epoch:[ 82 5 ] loss: 0.41556084156036377 2022-05-29 17:30:41.555474
Epoch:[ 82 6 ] loss: 0.414568156003952 2022-05-29 17:30:42.342904
Epoch:[ 82 7 ] loss: 0.41185715794563293 2022-05-29 17:30:43.119238
Epoch:[ 82 8 ] loss: 0.41157954931259155 2022-05-29 17:30:43.893648
Epoch:[ 82 9 ] loss: 0.408333420753479 2022-05-29 17:30:44.671213
Epoch:[ 82 10 ] loss: 0.41189587116241455 2022-05-29 17:30:45.449049
Epoch:[ 82 11 ] loss: 0.41073212027549744 2022-05-29 17:30:46.225511
Epoch:[ 82 12 ] loss: 0.4094032347202301 2022-05-29 17:30:47.003386
Epoch:[ 82 13 ] loss: 0.4116346538066864 2022-05-29 17:30:47.779702
Epoch:[ 82 14 ] loss: 0.41162848472595215 2022-05-29 17:30:48.569479
Epoch:[ 82 15 ] loss: 0.40887394547462463 2022-05-29 17:30:49.344985
Epoch:[ 82 16 ] loss: 0.4117182195186615 2022-05-29 17:30:57.001030
Epoch:[ 82 17 ] loss: 0.4107024073600769 2022-05-29 17:30:57.790325
Epoch:[ 82 18 ] loss: 0.41080671548843384 2022-05-29 17:30:58.579523
Epoch:[ 82 19 ] loss: 0.41051197052001953 2022-05-29 17:30:59.354817
Training_Epoch:[ 82 ] Training_loss: 0.411111618578434 2022-05-29 17:30:59.355554
learning rate:  6.710886400000004e-05
netparams have been saved once 82
val: 1 0.5023000240325928
val: 2 0.5312435626983643
val: 3 0.5422942042350769
val: 4 0.5051073431968689
val: 5 0.5342399477958679
val: 6 0.512332022190094
val: 7 0.5498188734054565
val: 8 0.5329869985580444
val: 9 0.5245352387428284
val: 10 0.5377054214477539
val: 11 0.5229036211967468
val: 12 0.5547387003898621
val: 13 0.5446266531944275
val: 14 0.5533213019371033
val: 15 0.5408644080162048
val: 16 0.5210455656051636
val: 17 0.5364607572555542
val: 18 0.5406616926193237
val: 19 0.5139379501342773
val: 20 0.5390793681144714
val_Epoch:[ 82 ] val_loss: 0.5320101827383041 2022-05-29 17:31:04.664945
start training 2022-05-29 17:31:04.763198
Epoch:[ 83 0 ] loss: 0.40942612290382385 2022-05-29 17:31:27.656405
Epoch:[ 83 1 ] loss: 0.41112667322158813 2022-05-29 17:31:28.484350
Epoch:[ 83 2 ] loss: 0.4138602614402771 2022-05-29 17:31:29.258214
Epoch:[ 83 3 ] loss: 0.4124003052711487 2022-05-29 17:31:30.034052
Epoch:[ 83 4 ] loss: 0.4117925763130188 2022-05-29 17:31:30.822660
Epoch:[ 83 5 ] loss: 0.4118090569972992 2022-05-29 17:31:31.597926
Epoch:[ 83 6 ] loss: 0.4115520119667053 2022-05-29 17:31:32.386338
Epoch:[ 83 7 ] loss: 0.4104710817337036 2022-05-29 17:31:33.161642
Epoch:[ 83 8 ] loss: 0.4114665389060974 2022-05-29 17:31:33.938230
Epoch:[ 83 9 ] loss: 0.40892231464385986 2022-05-29 17:31:34.712513
Epoch:[ 83 10 ] loss: 0.4131900370121002 2022-05-29 17:31:35.488225
Epoch:[ 83 11 ] loss: 0.4094651937484741 2022-05-29 17:31:36.266573
Epoch:[ 83 12 ] loss: 0.4115675091743469 2022-05-29 17:31:37.043635
Epoch:[ 83 13 ] loss: 0.4119117558002472 2022-05-29 17:31:37.831242
Epoch:[ 83 14 ] loss: 0.4096830189228058 2022-05-29 17:31:38.604151
Epoch:[ 83 15 ] loss: 0.4150024950504303 2022-05-29 17:31:39.380116
Epoch:[ 83 16 ] loss: 0.409930020570755 2022-05-29 17:31:47.164566
Epoch:[ 83 17 ] loss: 0.41120925545692444 2022-05-29 17:31:47.941361
Epoch:[ 83 18 ] loss: 0.4103207290172577 2022-05-29 17:31:48.733463
Epoch:[ 83 19 ] loss: 0.409633994102478 2022-05-29 17:31:49.508424
Training_Epoch:[ 83 ] Training_loss: 0.4112370476126671 2022-05-29 17:31:49.509194
learning rate:  6.710886400000004e-05
val: 1 0.5211508870124817
val: 2 0.5332382321357727
val: 3 0.5447321534156799
val: 4 0.5201672315597534
val: 5 0.549647331237793
val: 6 0.5474449396133423
val: 7 0.5323777794837952
val: 8 0.5265061259269714
val: 9 0.5377436876296997
val: 10 0.5266900062561035
val: 11 0.5248292684555054
val: 12 0.5366371870040894
val: 13 0.544284999370575
val: 14 0.5467463731765747
val: 15 0.5532911419868469
val: 16 0.5342206954956055
val: 17 0.5175882577896118
val: 18 0.5372932553291321
val: 19 0.5395899415016174
val: 20 0.5382243394851685
val_Epoch:[ 83 ] val_loss: 0.535620191693306 2022-05-29 17:31:54.789038
start training 2022-05-29 17:31:54.884715
Epoch:[ 84 0 ] loss: 0.41337206959724426 2022-05-29 17:32:18.506358
Epoch:[ 84 1 ] loss: 0.41303372383117676 2022-05-29 17:32:19.293219
Epoch:[ 84 2 ] loss: 0.4108527898788452 2022-05-29 17:32:20.070061
Epoch:[ 84 3 ] loss: 0.4114815890789032 2022-05-29 17:32:20.843008
Epoch:[ 84 4 ] loss: 0.41178250312805176 2022-05-29 17:32:21.619240
Epoch:[ 84 5 ] loss: 0.4087870419025421 2022-05-29 17:32:22.395770
Epoch:[ 84 6 ] loss: 0.40957731008529663 2022-05-29 17:32:23.185500
Epoch:[ 84 7 ] loss: 0.41438329219818115 2022-05-29 17:32:23.975361
Epoch:[ 84 8 ] loss: 0.40837258100509644 2022-05-29 17:32:24.750873
Epoch:[ 84 9 ] loss: 0.4098380208015442 2022-05-29 17:32:25.528947
Epoch:[ 84 10 ] loss: 0.4111076891422272 2022-05-29 17:32:26.305562
Epoch:[ 84 11 ] loss: 0.4088701903820038 2022-05-29 17:32:27.084131
Epoch:[ 84 12 ] loss: 0.4132045805454254 2022-05-29 17:32:27.862143
Epoch:[ 84 13 ] loss: 0.4112497568130493 2022-05-29 17:32:28.641433
Epoch:[ 84 14 ] loss: 0.41387617588043213 2022-05-29 17:32:29.419457
Epoch:[ 84 15 ] loss: 0.41171056032180786 2022-05-29 17:32:30.195502
Epoch:[ 84 16 ] loss: 0.4067177474498749 2022-05-29 17:32:38.303310
Epoch:[ 84 17 ] loss: 0.41211065649986267 2022-05-29 17:32:39.082216
Epoch:[ 84 18 ] loss: 0.4137963652610779 2022-05-29 17:32:39.868066
Epoch:[ 84 19 ] loss: 0.407861590385437 2022-05-29 17:32:40.636403
Training_Epoch:[ 84 ] Training_loss: 0.411099311709404 2022-05-29 17:32:40.637205
learning rate:  6.710886400000004e-05
netparams have been saved once 84
val: 1 0.5391409397125244
val: 2 0.5193824768066406
val: 3 0.5346384644508362
val: 4 0.5327908396720886
val: 5 0.5484753251075745
val: 6 0.5402297973632812
val: 7 0.5361337661743164
val: 8 0.5350220203399658
val: 9 0.5373162627220154
val: 10 0.5418468117713928
val: 11 0.5474355816841125
val: 12 0.5074841976165771
val: 13 0.5408349633216858
val: 14 0.5149357318878174
val: 15 0.5376895666122437
val: 16 0.5255958437919617
val: 17 0.5222190022468567
val: 18 0.5540621280670166
val: 19 0.5226540565490723
val: 20 0.5337055325508118
val_Epoch:[ 84 ] val_loss: 0.5335796654224396 2022-05-29 17:32:46.560755
start training 2022-05-29 17:32:46.675712
Epoch:[ 85 0 ] loss: 0.40883567929267883 2022-05-29 17:33:12.563484
Epoch:[ 85 1 ] loss: 0.41256728768348694 2022-05-29 17:33:13.395512
Epoch:[ 85 2 ] loss: 0.4093106985092163 2022-05-29 17:33:14.174092
Epoch:[ 85 3 ] loss: 0.4087456464767456 2022-05-29 17:33:14.963538
Epoch:[ 85 4 ] loss: 0.40871280431747437 2022-05-29 17:33:15.740028
Epoch:[ 85 5 ] loss: 0.41266119480133057 2022-05-29 17:33:16.519765
Epoch:[ 85 6 ] loss: 0.40886029601097107 2022-05-29 17:33:17.311933
Epoch:[ 85 7 ] loss: 0.40829604864120483 2022-05-29 17:33:18.088500
Epoch:[ 85 8 ] loss: 0.40939465165138245 2022-05-29 17:33:18.865782
Epoch:[ 85 9 ] loss: 0.4130226671695709 2022-05-29 17:33:19.645946
Epoch:[ 85 10 ] loss: 0.4109736979007721 2022-05-29 17:33:20.421654
Epoch:[ 85 11 ] loss: 0.40577471256256104 2022-05-29 17:33:21.199608
Epoch:[ 85 12 ] loss: 0.4102652370929718 2022-05-29 17:33:21.978031
Epoch:[ 85 13 ] loss: 0.4129595458507538 2022-05-29 17:33:22.766737
Epoch:[ 85 14 ] loss: 0.4116664230823517 2022-05-29 17:33:23.547387
Epoch:[ 85 15 ] loss: 0.41525325179100037 2022-05-29 17:33:24.323974
Epoch:[ 85 16 ] loss: 0.4144631326198578 2022-05-29 17:33:32.438766
Epoch:[ 85 17 ] loss: 0.41267648339271545 2022-05-29 17:33:33.227098
Epoch:[ 85 18 ] loss: 0.41287052631378174 2022-05-29 17:33:34.021944
Epoch:[ 85 19 ] loss: 0.4103392958641052 2022-05-29 17:33:34.813932
Training_Epoch:[ 85 ] Training_loss: 0.4108824640512466 2022-05-29 17:33:34.814721
learning rate:  6.710886400000004e-05
val: 1 0.5449597239494324
val: 2 0.5322298407554626
val: 3 0.5479049682617188
val: 4 0.511274516582489
val: 5 0.5080603361129761
val: 6 0.512285590171814
val: 7 0.5460336208343506
val: 8 0.5295464992523193
val: 9 0.5244396924972534
val: 10 0.5182422995567322
val: 11 0.547527551651001
val: 12 0.525297224521637
val: 13 0.5411415696144104
val: 14 0.5292984843254089
val: 15 0.534188985824585
val: 16 0.535776674747467
val: 17 0.5418089032173157
val: 18 0.5376661419868469
val: 19 0.5467681884765625
val: 20 0.5181261897087097
val_Epoch:[ 85 ] val_loss: 0.5316288501024247 2022-05-29 17:33:40.239559
start training 2022-05-29 17:33:40.354856
Epoch:[ 86 0 ] loss: 0.411144882440567 2022-05-29 17:34:06.118945
Epoch:[ 86 1 ] loss: 0.4077690839767456 2022-05-29 17:34:06.897090
Epoch:[ 86 2 ] loss: 0.411894828081131 2022-05-29 17:34:07.675973
Epoch:[ 86 3 ] loss: 0.4112108051776886 2022-05-29 17:34:08.450470
Epoch:[ 86 4 ] loss: 0.4115646779537201 2022-05-29 17:34:09.224674
Epoch:[ 86 5 ] loss: 0.4064890146255493 2022-05-29 17:34:10.000362
Epoch:[ 86 6 ] loss: 0.40788352489471436 2022-05-29 17:34:10.789877
Epoch:[ 86 7 ] loss: 0.41129082441329956 2022-05-29 17:34:11.567156
Epoch:[ 86 8 ] loss: 0.4091276228427887 2022-05-29 17:34:12.354902
Epoch:[ 86 9 ] loss: 0.41150444746017456 2022-05-29 17:34:13.132807
Epoch:[ 86 10 ] loss: 0.40708792209625244 2022-05-29 17:34:13.908411
Epoch:[ 86 11 ] loss: 0.41413918137550354 2022-05-29 17:34:14.685447
Epoch:[ 86 12 ] loss: 0.4117577373981476 2022-05-29 17:34:15.471301
Epoch:[ 86 13 ] loss: 0.41139063239097595 2022-05-29 17:34:16.249987
Epoch:[ 86 14 ] loss: 0.4108099937438965 2022-05-29 17:34:17.029810
Epoch:[ 86 15 ] loss: 0.4145238697528839 2022-05-29 17:34:17.806921
Epoch:[ 86 16 ] loss: 0.4080016613006592 2022-05-29 17:34:29.725145
Epoch:[ 86 17 ] loss: 0.41297850012779236 2022-05-29 17:34:30.501609
Epoch:[ 86 18 ] loss: 0.41046658158302307 2022-05-29 17:34:31.292223
Epoch:[ 86 19 ] loss: 0.41025176644325256 2022-05-29 17:34:32.065764
Training_Epoch:[ 86 ] Training_loss: 0.4105643779039383 2022-05-29 17:34:32.066480
learning rate:  6.710886400000004e-05
netparams have been saved once 86
val: 1 0.536507785320282
val: 2 0.5196413993835449
val: 3 0.4926412105560303
val: 4 0.5301029682159424
val: 5 0.506156325340271
val: 6 0.5441830158233643
val: 7 0.5159536600112915
val: 8 0.5429195761680603
val: 9 0.5549923777580261
val: 10 0.5416706800460815
val: 11 0.54124516248703
val: 12 0.5414096117019653
val: 13 0.539027214050293
val: 14 0.5047637820243835
val: 15 0.5418672561645508
val: 16 0.530468761920929
val: 17 0.5366581678390503
val: 18 0.5621234178543091
val: 19 0.5263516902923584
val: 20 0.5454820990562439
val_Epoch:[ 86 ] val_loss: 0.5327083081007004 2022-05-29 17:34:37.516199
start training 2022-05-29 17:34:37.613392
Epoch:[ 87 0 ] loss: 0.4115794599056244 2022-05-29 17:35:01.578417
Epoch:[ 87 1 ] loss: 0.4130437672138214 2022-05-29 17:35:03.300958
Epoch:[ 87 2 ] loss: 0.41306036710739136 2022-05-29 17:35:04.077920
Epoch:[ 87 3 ] loss: 0.4074706435203552 2022-05-29 17:35:04.855990
Epoch:[ 87 4 ] loss: 0.4066190719604492 2022-05-29 17:35:05.631777
Epoch:[ 87 5 ] loss: 0.4080486297607422 2022-05-29 17:35:06.407872
Epoch:[ 87 6 ] loss: 0.4098004400730133 2022-05-29 17:35:07.183801
Epoch:[ 87 7 ] loss: 0.4110058844089508 2022-05-29 17:35:07.973954
Epoch:[ 87 8 ] loss: 0.4142049551010132 2022-05-29 17:35:08.761817
Epoch:[ 87 9 ] loss: 0.4159429371356964 2022-05-29 17:35:09.541131
Epoch:[ 87 10 ] loss: 0.41245540976524353 2022-05-29 17:35:10.317963
Epoch:[ 87 11 ] loss: 0.4078843593597412 2022-05-29 17:35:11.093245
Epoch:[ 87 12 ] loss: 0.41057148575782776 2022-05-29 17:35:11.880952
Epoch:[ 87 13 ] loss: 0.40785589814186096 2022-05-29 17:35:12.655886
Epoch:[ 87 14 ] loss: 0.40998104214668274 2022-05-29 17:35:13.434378
Epoch:[ 87 15 ] loss: 0.40948086977005005 2022-05-29 17:35:14.212722
Epoch:[ 87 16 ] loss: 0.4118894934654236 2022-05-29 17:35:21.720102
Epoch:[ 87 17 ] loss: 0.4052923619747162 2022-05-29 17:35:25.849009
Epoch:[ 87 18 ] loss: 0.4115935266017914 2022-05-29 17:35:26.642264
Epoch:[ 87 19 ] loss: 0.4110533595085144 2022-05-29 17:35:27.428933
Training_Epoch:[ 87 ] Training_loss: 0.4104416981339455 2022-05-29 17:35:27.429656
learning rate:  6.710886400000004e-05
val: 1 0.5403380393981934
val: 2 0.5311446189880371
val: 3 0.5263504385948181
val: 4 0.5295088887214661
val: 5 0.5514450669288635
val: 6 0.5251376032829285
val: 7 0.5379841923713684
val: 8 0.5213778018951416
val: 9 0.5217795968055725
val: 10 0.5344560146331787
val: 11 0.5152609348297119
val: 12 0.5531838536262512
val: 13 0.5531724691390991
val: 14 0.5238741636276245
val: 15 0.5340237617492676
val: 16 0.5366051197052002
val: 17 0.5304778814315796
val: 18 0.5379924178123474
val: 19 0.5297467112541199
val: 20 0.5471060872077942
val_Epoch:[ 87 ] val_loss: 0.5340482831001282 2022-05-29 17:35:32.913414
start training 2022-05-29 17:35:33.008556
Epoch:[ 88 0 ] loss: 0.4147408902645111 2022-05-29 17:35:56.629687
Epoch:[ 88 1 ] loss: 0.41100412607192993 2022-05-29 17:35:58.805724
Epoch:[ 88 2 ] loss: 0.40927597880363464 2022-05-29 17:35:59.583876
Epoch:[ 88 3 ] loss: 0.4073326885700226 2022-05-29 17:36:00.362437
Epoch:[ 88 4 ] loss: 0.40988031029701233 2022-05-29 17:36:01.141027
Epoch:[ 88 5 ] loss: 0.41218301653862 2022-05-29 17:36:01.928451
Epoch:[ 88 6 ] loss: 0.4109015166759491 2022-05-29 17:36:02.709535
Epoch:[ 88 7 ] loss: 0.4099189043045044 2022-05-29 17:36:03.485304
Epoch:[ 88 8 ] loss: 0.4116944968700409 2022-05-29 17:36:04.264696
Epoch:[ 88 9 ] loss: 0.4077673852443695 2022-05-29 17:36:05.043750
Epoch:[ 88 10 ] loss: 0.4106152653694153 2022-05-29 17:36:05.822066
Epoch:[ 88 11 ] loss: 0.4089949131011963 2022-05-29 17:36:06.600342
Epoch:[ 88 12 ] loss: 0.41184550523757935 2022-05-29 17:36:07.377171
Epoch:[ 88 13 ] loss: 0.4091399013996124 2022-05-29 17:36:08.165872
Epoch:[ 88 14 ] loss: 0.4057106077671051 2022-05-29 17:36:08.954282
Epoch:[ 88 15 ] loss: 0.40959033370018005 2022-05-29 17:36:09.731675
Epoch:[ 88 16 ] loss: 0.41267043352127075 2022-05-29 17:36:16.637958
Epoch:[ 88 17 ] loss: 0.41111788153648376 2022-05-29 17:36:21.468197
Epoch:[ 88 18 ] loss: 0.4124109148979187 2022-05-29 17:36:22.259357
Epoch:[ 88 19 ] loss: 0.41407060623168945 2022-05-29 17:36:23.037385
Training_Epoch:[ 88 ] Training_loss: 0.41054328382015226 2022-05-29 17:36:23.038138
learning rate:  6.710886400000004e-05
netparams have been saved once 88
val: 1 0.5400006771087646
val: 2 0.5192967653274536
val: 3 0.533778190612793
val: 4 0.5281844735145569
val: 5 0.5309666395187378
val: 6 0.5240446925163269
val: 7 0.5432089567184448
val: 8 0.5340420007705688
val: 9 0.5257025361061096
val: 10 0.534915030002594
val: 11 0.5237642526626587
val: 12 0.5342605113983154
val: 13 0.5420582890510559
val: 14 0.5420889258384705
val: 15 0.5280123949050903
val: 16 0.525071918964386
val: 17 0.5115723609924316
val: 18 0.5411044955253601
val: 19 0.5451748967170715
val: 20 0.5343992710113525
val_Epoch:[ 88 ] val_loss: 0.5320823639631271 2022-05-29 17:36:28.822366
start training 2022-05-29 17:36:28.917944
Epoch:[ 89 0 ] loss: 0.4082382619380951 2022-05-29 17:36:55.263345
Epoch:[ 89 1 ] loss: 0.4093383848667145 2022-05-29 17:36:56.037636
Epoch:[ 89 2 ] loss: 0.41279885172843933 2022-05-29 17:36:56.814539
Epoch:[ 89 3 ] loss: 0.41203364729881287 2022-05-29 17:36:57.603262
Epoch:[ 89 4 ] loss: 0.41191521286964417 2022-05-29 17:36:58.391353
Epoch:[ 89 5 ] loss: 0.4062846899032593 2022-05-29 17:36:59.167957
Epoch:[ 89 6 ] loss: 0.4155430793762207 2022-05-29 17:36:59.941902
Epoch:[ 89 7 ] loss: 0.4073536694049835 2022-05-29 17:37:00.717063
Epoch:[ 89 8 ] loss: 0.40554192662239075 2022-05-29 17:37:01.490924
Epoch:[ 89 9 ] loss: 0.4082311987876892 2022-05-29 17:37:02.268557
Epoch:[ 89 10 ] loss: 0.40942588448524475 2022-05-29 17:37:03.045396
Epoch:[ 89 11 ] loss: 0.4134170413017273 2022-05-29 17:37:03.821801
Epoch:[ 89 12 ] loss: 0.4124346375465393 2022-05-29 17:37:04.599675
Epoch:[ 89 13 ] loss: 0.410662442445755 2022-05-29 17:37:05.385188
Epoch:[ 89 14 ] loss: 0.4103033244609833 2022-05-29 17:37:06.161083
Epoch:[ 89 15 ] loss: 0.41283008456230164 2022-05-29 17:37:06.934863
Epoch:[ 89 16 ] loss: 0.4075714647769928 2022-05-29 17:37:18.463195
Epoch:[ 89 17 ] loss: 0.40994101762771606 2022-05-29 17:37:19.253340
Epoch:[ 89 18 ] loss: 0.4083673357963562 2022-05-29 17:37:20.051465
Epoch:[ 89 19 ] loss: 0.4086081385612488 2022-05-29 17:37:20.828720
Training_Epoch:[ 89 ] Training_loss: 0.41004201471805574 2022-05-29 17:37:20.829437
learning rate:  6.710886400000004e-05
val: 1 0.5416679978370667
val: 2 0.548932671546936
val: 3 0.5072682499885559
val: 4 0.5317647457122803
val: 5 0.5287372469902039
val: 6 0.544815182685852
val: 7 0.5336180329322815
val: 8 0.5345509052276611
val: 9 0.5264275074005127
val: 10 0.5180062055587769
val: 11 0.5504063367843628
val: 12 0.5378043055534363
val: 13 0.5530185699462891
val: 14 0.5468422770500183
val: 15 0.5242185592651367
val: 16 0.5207787752151489
val: 17 0.5366106033325195
val: 18 0.5471567511558533
val: 19 0.521240234375
val: 20 0.5191894769668579
val_Epoch:[ 89 ] val_loss: 0.5336527317762375 2022-05-29 17:37:26.114052
start training 2022-05-29 17:37:26.209327
Epoch:[ 90 0 ] loss: 0.4118312895298004 2022-05-29 17:37:52.331988
Epoch:[ 90 1 ] loss: 0.40841564536094666 2022-05-29 17:37:53.109796
Epoch:[ 90 2 ] loss: 0.4107978343963623 2022-05-29 17:37:53.883116
Epoch:[ 90 3 ] loss: 0.40534883737564087 2022-05-29 17:37:54.662589
Epoch:[ 90 4 ] loss: 0.41474512219429016 2022-05-29 17:37:55.441231
Epoch:[ 90 5 ] loss: 0.4106521010398865 2022-05-29 17:37:56.220428
Epoch:[ 90 6 ] loss: 0.41015803813934326 2022-05-29 17:37:56.998356
Epoch:[ 90 7 ] loss: 0.40875697135925293 2022-05-29 17:37:57.784606
Epoch:[ 90 8 ] loss: 0.4086366593837738 2022-05-29 17:37:58.560027
Epoch:[ 90 9 ] loss: 0.4092963635921478 2022-05-29 17:37:59.345448
Epoch:[ 90 10 ] loss: 0.4088788628578186 2022-05-29 17:38:00.134957
Epoch:[ 90 11 ] loss: 0.40951743721961975 2022-05-29 17:38:00.913683
Epoch:[ 90 12 ] loss: 0.41003698110580444 2022-05-29 17:38:01.692118
Epoch:[ 90 13 ] loss: 0.40837180614471436 2022-05-29 17:38:02.468536
Epoch:[ 90 14 ] loss: 0.41039273142814636 2022-05-29 17:38:03.244661
Epoch:[ 90 15 ] loss: 0.4085366725921631 2022-05-29 17:38:04.019960
Epoch:[ 90 16 ] loss: 0.41490036249160767 2022-05-29 17:38:15.895823
Epoch:[ 90 17 ] loss: 0.4147314727306366 2022-05-29 17:38:16.673544
Epoch:[ 90 18 ] loss: 0.40748146176338196 2022-05-29 17:38:17.458104
Epoch:[ 90 19 ] loss: 0.40710827708244324 2022-05-29 17:38:18.248197
Training_Epoch:[ 90 ] Training_loss: 0.40992974638938906 2022-05-29 17:38:18.249022
learning rate:  6.710886400000004e-05
netparams have been saved once 90
val: 1 0.5491193532943726
val: 2 0.5251453518867493
val: 3 0.5443645119667053
val: 4 0.5539432764053345
val: 5 0.5219799876213074
val: 6 0.5358142256736755
val: 7 0.5300614833831787
val: 8 0.5201841592788696
val: 9 0.5340629816055298
val: 10 0.5308218002319336
val: 11 0.5342769026756287
val: 12 0.5474380850791931
val: 13 0.5287600159645081
val: 14 0.5224703550338745
val: 15 0.538029670715332
val: 16 0.5390772819519043
val: 17 0.5250400900840759
val: 18 0.5364252328872681
val: 19 0.5388645529747009
val: 20 0.5441582798957825
val_Epoch:[ 90 ] val_loss: 0.5350018799304962 2022-05-29 17:38:24.112880
start training 2022-05-29 17:38:24.208277
Epoch:[ 91 0 ] loss: 0.4090842604637146 2022-05-29 17:38:50.352453
Epoch:[ 91 1 ] loss: 0.4094042479991913 2022-05-29 17:38:51.129032
Epoch:[ 91 2 ] loss: 0.4087037146091461 2022-05-29 17:38:51.905310
Epoch:[ 91 3 ] loss: 0.412357360124588 2022-05-29 17:38:52.681570
Epoch:[ 91 4 ] loss: 0.4096077084541321 2022-05-29 17:38:53.461251
Epoch:[ 91 5 ] loss: 0.40840452909469604 2022-05-29 17:38:54.251573
Epoch:[ 91 6 ] loss: 0.410785973072052 2022-05-29 17:38:55.030038
Epoch:[ 91 7 ] loss: 0.407955527305603 2022-05-29 17:38:55.807616
Epoch:[ 91 8 ] loss: 0.40755727887153625 2022-05-29 17:38:56.584998
Epoch:[ 91 9 ] loss: 0.4126562476158142 2022-05-29 17:38:57.361543
Epoch:[ 91 10 ] loss: 0.40860244631767273 2022-05-29 17:38:58.137256
Epoch:[ 91 11 ] loss: 0.4109426438808441 2022-05-29 17:38:58.917410
Epoch:[ 91 12 ] loss: 0.4093098044395447 2022-05-29 17:38:59.696869
Epoch:[ 91 13 ] loss: 0.4092370867729187 2022-05-29 17:39:00.487908
Epoch:[ 91 14 ] loss: 0.4101453721523285 2022-05-29 17:39:01.266165
Epoch:[ 91 15 ] loss: 0.41153088212013245 2022-05-29 17:39:02.042720
Epoch:[ 91 16 ] loss: 0.41034698486328125 2022-05-29 17:39:14.048706
Epoch:[ 91 17 ] loss: 0.4091531038284302 2022-05-29 17:39:14.824285
Epoch:[ 91 18 ] loss: 0.41442713141441345 2022-05-29 17:39:15.624574
Epoch:[ 91 19 ] loss: 0.40670523047447205 2022-05-29 17:39:16.415903
Training_Epoch:[ 91 ] Training_loss: 0.4098458766937256 2022-05-29 17:39:16.416698
learning rate:  5.3687091200000036e-05
val: 1 0.5407980680465698
val: 2 0.5386168360710144
val: 3 0.5174826979637146
val: 4 0.5481086373329163
val: 5 0.531694233417511
val: 6 0.5260990262031555
val: 7 0.5271829962730408
val: 8 0.5123051404953003
val: 9 0.5296217203140259
val: 10 0.5491542816162109
val: 11 0.5425822138786316
val: 12 0.512708306312561
val: 13 0.5304926037788391
val: 14 0.5312148928642273
val: 15 0.5506318807601929
val: 16 0.5184406638145447
val: 17 0.5347629189491272
val: 18 0.5474838614463806
val: 19 0.5534849166870117
val: 20 0.541365385055542
val_Epoch:[ 91 ] val_loss: 0.5342115640640259 2022-05-29 17:39:21.800969
start training 2022-05-29 17:39:21.900050
Epoch:[ 92 0 ] loss: 0.40946269035339355 2022-05-29 17:39:47.866581
Epoch:[ 92 1 ] loss: 0.4105773866176605 2022-05-29 17:39:48.657355
Epoch:[ 92 2 ] loss: 0.4050431251525879 2022-05-29 17:39:49.433298
Epoch:[ 92 3 ] loss: 0.4058738648891449 2022-05-29 17:39:50.209756
Epoch:[ 92 4 ] loss: 0.4099453091621399 2022-05-29 17:39:50.986564
Epoch:[ 92 5 ] loss: 0.41035768389701843 2022-05-29 17:39:51.776293
Epoch:[ 92 6 ] loss: 0.41032448410987854 2022-05-29 17:39:52.555570
Epoch:[ 92 7 ] loss: 0.41109901666641235 2022-05-29 17:39:53.333344
Epoch:[ 92 8 ] loss: 0.41302022337913513 2022-05-29 17:39:54.112299
Epoch:[ 92 9 ] loss: 0.4050185978412628 2022-05-29 17:39:54.889152
Epoch:[ 92 10 ] loss: 0.4116774797439575 2022-05-29 17:39:55.664479
Epoch:[ 92 11 ] loss: 0.4081730544567108 2022-05-29 17:39:56.441323
Epoch:[ 92 12 ] loss: 0.4091886281967163 2022-05-29 17:39:57.218990
Epoch:[ 92 13 ] loss: 0.4086707532405853 2022-05-29 17:39:57.998513
Epoch:[ 92 14 ] loss: 0.41104257106781006 2022-05-29 17:39:58.779169
Epoch:[ 92 15 ] loss: 0.406200647354126 2022-05-29 17:39:59.559033
Epoch:[ 92 16 ] loss: 0.4102022051811218 2022-05-29 17:40:10.721720
Epoch:[ 92 17 ] loss: 0.4087482988834381 2022-05-29 17:40:11.503792
Epoch:[ 92 18 ] loss: 0.4119721055030823 2022-05-29 17:40:12.295009
Epoch:[ 92 19 ] loss: 0.4074544608592987 2022-05-29 17:40:13.077227
Training_Epoch:[ 92 ] Training_loss: 0.40920262932777407 2022-05-29 17:40:13.078023
learning rate:  5.3687091200000036e-05
netparams have been saved once 92
val: 1 0.5434556603431702
val: 2 0.5333372950553894
val: 3 0.537568986415863
val: 4 0.5285439491271973
val: 5 0.5448541045188904
val: 6 0.5353409051895142
val: 7 0.5316652059555054
val: 8 0.5323204398155212
val: 9 0.5241039395332336
val: 10 0.5503920316696167
val: 11 0.5247339606285095
val: 12 0.5478276610374451
val: 13 0.5411407351493835
val: 14 0.5324718952178955
val: 15 0.5452944040298462
val: 16 0.49827420711517334
val: 17 0.5277723073959351
val: 18 0.5342244505882263
val: 19 0.5055086016654968
val: 20 0.5358515381813049
val_Epoch:[ 92 ] val_loss: 0.5327341139316559 2022-05-29 17:40:18.687254
start training 2022-05-29 17:40:18.781600
Epoch:[ 93 0 ] loss: 0.40856707096099854 2022-05-29 17:40:43.602441
Epoch:[ 93 1 ] loss: 0.4075692892074585 2022-05-29 17:40:44.387396
Epoch:[ 93 2 ] loss: 0.4071585237979889 2022-05-29 17:40:45.177983
Epoch:[ 93 3 ] loss: 0.4095126986503601 2022-05-29 17:40:45.954337
Epoch:[ 93 4 ] loss: 0.4072190225124359 2022-05-29 17:40:46.730159
Epoch:[ 93 5 ] loss: 0.40861719846725464 2022-05-29 17:40:47.504960
Epoch:[ 93 6 ] loss: 0.41026851534843445 2022-05-29 17:40:48.282754
Epoch:[ 93 7 ] loss: 0.403963178396225 2022-05-29 17:40:49.061875
Epoch:[ 93 8 ] loss: 0.40830403566360474 2022-05-29 17:40:49.837238
Epoch:[ 93 9 ] loss: 0.41224977374076843 2022-05-29 17:40:50.616538
Epoch:[ 93 10 ] loss: 0.4085729122161865 2022-05-29 17:40:51.392462
Epoch:[ 93 11 ] loss: 0.4063158631324768 2022-05-29 17:40:52.169065
Epoch:[ 93 12 ] loss: 0.4149201810359955 2022-05-29 17:40:52.954952
Epoch:[ 93 13 ] loss: 0.4085424244403839 2022-05-29 17:40:53.734991
Epoch:[ 93 14 ] loss: 0.41288360953330994 2022-05-29 17:40:54.524938
Epoch:[ 93 15 ] loss: 0.41246944665908813 2022-05-29 17:40:55.301634
Epoch:[ 93 16 ] loss: 0.4054065942764282 2022-05-29 17:41:03.048435
Epoch:[ 93 17 ] loss: 0.41114404797554016 2022-05-29 17:41:03.838418
Epoch:[ 93 18 ] loss: 0.41267964243888855 2022-05-29 17:41:04.616977
Epoch:[ 93 19 ] loss: 0.41119641065597534 2022-05-29 17:41:06.600509
Training_Epoch:[ 93 ] Training_loss: 0.4093780219554901 2022-05-29 17:41:06.601287
learning rate:  5.3687091200000036e-05
val: 1 0.5455121397972107
val: 2 0.5132415294647217
val: 3 0.5410405993461609
val: 4 0.5334969758987427
val: 5 0.551358699798584
val: 6 0.5288195610046387
val: 7 0.5219510793685913
val: 8 0.5304977893829346
val: 9 0.5579134821891785
val: 10 0.5209260582923889
val: 11 0.5369729399681091
val: 12 0.5337502956390381
val: 13 0.5421949028968811
val: 14 0.5103838443756104
val: 15 0.5347669720649719
val: 16 0.5272015333175659
val: 17 0.5448991060256958
val: 18 0.5323036909103394
val: 19 0.5518206357955933
val: 20 0.5089964866638184
val_Epoch:[ 93 ] val_loss: 0.5334024161100388 2022-05-29 17:41:12.002176
start training 2022-05-29 17:41:12.095745
Epoch:[ 94 0 ] loss: 0.4118436872959137 2022-05-29 17:41:36.837286
Epoch:[ 94 1 ] loss: 0.4096258282661438 2022-05-29 17:41:37.918623
Epoch:[ 94 2 ] loss: 0.41303110122680664 2022-05-29 17:41:38.697580
Epoch:[ 94 3 ] loss: 0.410319447517395 2022-05-29 17:41:39.474651
Epoch:[ 94 4 ] loss: 0.407949298620224 2022-05-29 17:41:40.251032
Epoch:[ 94 5 ] loss: 0.4101056754589081 2022-05-29 17:41:41.027030
Epoch:[ 94 6 ] loss: 0.4130885601043701 2022-05-29 17:41:41.812613
Epoch:[ 94 7 ] loss: 0.4067571461200714 2022-05-29 17:41:42.601434
Epoch:[ 94 8 ] loss: 0.4099470376968384 2022-05-29 17:41:43.378813
Epoch:[ 94 9 ] loss: 0.4092124104499817 2022-05-29 17:41:44.157479
Epoch:[ 94 10 ] loss: 0.4084223210811615 2022-05-29 17:41:44.933884
Epoch:[ 94 11 ] loss: 0.40969884395599365 2022-05-29 17:41:45.709230
Epoch:[ 94 12 ] loss: 0.4093700647354126 2022-05-29 17:41:46.485169
Epoch:[ 94 13 ] loss: 0.41131287813186646 2022-05-29 17:41:47.258550
Epoch:[ 94 14 ] loss: 0.40509116649627686 2022-05-29 17:41:48.037306
Epoch:[ 94 15 ] loss: 0.41268280148506165 2022-05-29 17:41:48.828910
Epoch:[ 94 16 ] loss: 0.4065741002559662 2022-05-29 17:41:56.120587
Epoch:[ 94 17 ] loss: 0.40623846650123596 2022-05-29 17:42:00.751230
Epoch:[ 94 18 ] loss: 0.4089919626712799 2022-05-29 17:42:01.541795
Epoch:[ 94 19 ] loss: 0.4098042845726013 2022-05-29 17:42:02.316166
Training_Epoch:[ 94 ] Training_loss: 0.4095033541321754 2022-05-29 17:42:02.316955
learning rate:  5.3687091200000036e-05
netparams have been saved once 94
val: 1 0.531288206577301
val: 2 0.5510582327842712
val: 3 0.5557770729064941
val: 4 0.5167673826217651
val: 5 0.5411807894706726
val: 6 0.5107338428497314
val: 7 0.5387742519378662
val: 8 0.5323895812034607
val: 9 0.5369893312454224
val: 10 0.5350990891456604
val: 11 0.540276288986206
val: 12 0.5413772463798523
val: 13 0.5637487173080444
val: 14 0.5271247625350952
val: 15 0.5452526807785034
val: 16 0.5231958627700806
val: 17 0.532680094242096
val: 18 0.5284544229507446
val: 19 0.5294675827026367
val: 20 0.5574659705162048
val_Epoch:[ 94 ] val_loss: 0.5369550704956054 2022-05-29 17:42:07.814595
start training 2022-05-29 17:42:07.911929
Epoch:[ 95 0 ] loss: 0.41229790449142456 2022-05-29 17:42:31.624858
Epoch:[ 95 1 ] loss: 0.40426912903785706 2022-05-29 17:42:32.481873
Epoch:[ 95 2 ] loss: 0.41091734170913696 2022-05-29 17:42:33.542267
Epoch:[ 95 3 ] loss: 0.4042876660823822 2022-05-29 17:42:34.319338
Epoch:[ 95 4 ] loss: 0.40902605652809143 2022-05-29 17:42:35.096396
Epoch:[ 95 5 ] loss: 0.40362146496772766 2022-05-29 17:42:35.871983
Epoch:[ 95 6 ] loss: 0.4064759612083435 2022-05-29 17:42:36.647556
Epoch:[ 95 7 ] loss: 0.41352933645248413 2022-05-29 17:42:37.422709
Epoch:[ 95 8 ] loss: 0.409726083278656 2022-05-29 17:42:38.213568
Epoch:[ 95 9 ] loss: 0.4116869866847992 2022-05-29 17:42:39.003833
Epoch:[ 95 10 ] loss: 0.41119080781936646 2022-05-29 17:42:39.781006
Epoch:[ 95 11 ] loss: 0.40689966082572937 2022-05-29 17:42:40.558198
Epoch:[ 95 12 ] loss: 0.412000834941864 2022-05-29 17:42:41.332513
Epoch:[ 95 13 ] loss: 0.4071812033653259 2022-05-29 17:42:42.120632
Epoch:[ 95 14 ] loss: 0.41027095913887024 2022-05-29 17:42:42.895178
Epoch:[ 95 15 ] loss: 0.4150015115737915 2022-05-29 17:42:43.677607
Epoch:[ 95 16 ] loss: 0.4081963896751404 2022-05-29 17:42:51.791912
Epoch:[ 95 17 ] loss: 0.4128795862197876 2022-05-29 17:42:52.569323
Epoch:[ 95 18 ] loss: 0.40750622749328613 2022-05-29 17:42:56.359050
Epoch:[ 95 19 ] loss: 0.40627360343933105 2022-05-29 17:42:57.133314
Training_Epoch:[ 95 ] Training_loss: 0.40916193574666976 2022-05-29 17:42:57.134125
learning rate:  5.3687091200000036e-05
val: 1 0.5288174748420715
val: 2 0.5553573369979858
val: 3 0.5160025358200073
val: 4 0.5484417080879211
val: 5 0.5308748483657837
val: 6 0.5157144069671631
val: 7 0.533558189868927
val: 8 0.5304632782936096
val: 9 0.5253378748893738
val: 10 0.5439110398292542
val: 11 0.5418567061424255
val: 12 0.5431193113327026
val: 13 0.536737859249115
val: 14 0.5300447344779968
val: 15 0.5325120091438293
val: 16 0.5386572480201721
val: 17 0.5368369817733765
val: 18 0.5429120659828186
val: 19 0.5365484952926636
val: 20 0.5185831785202026
val_Epoch:[ 95 ] val_loss: 0.53431436419487 2022-05-29 17:43:02.465859
start training 2022-05-29 17:43:02.567039
Epoch:[ 96 0 ] loss: 0.41070064902305603 2022-05-29 17:43:27.889444
Epoch:[ 96 1 ] loss: 0.4104914963245392 2022-05-29 17:43:28.664202
Epoch:[ 96 2 ] loss: 0.40876713395118713 2022-05-29 17:43:29.442787
Epoch:[ 96 3 ] loss: 0.4113944470882416 2022-05-29 17:43:30.221164
Epoch:[ 96 4 ] loss: 0.4085826873779297 2022-05-29 17:43:30.997646
Epoch:[ 96 5 ] loss: 0.4051525294780731 2022-05-29 17:43:31.773352
Epoch:[ 96 6 ] loss: 0.4085249900817871 2022-05-29 17:43:32.548868
Epoch:[ 96 7 ] loss: 0.40801846981048584 2022-05-29 17:43:33.326317
Epoch:[ 96 8 ] loss: 0.41061317920684814 2022-05-29 17:43:34.099354
Epoch:[ 96 9 ] loss: 0.41022148728370667 2022-05-29 17:43:34.888071
Epoch:[ 96 10 ] loss: 0.410896897315979 2022-05-29 17:43:35.664363
Epoch:[ 96 11 ] loss: 0.41120585799217224 2022-05-29 17:43:36.453811
Epoch:[ 96 12 ] loss: 0.40354031324386597 2022-05-29 17:43:37.232717
Epoch:[ 96 13 ] loss: 0.410486102104187 2022-05-29 17:43:38.021387
Epoch:[ 96 14 ] loss: 0.41346171498298645 2022-05-29 17:43:38.796938
Epoch:[ 96 15 ] loss: 0.40883690118789673 2022-05-29 17:43:39.572243
Epoch:[ 96 16 ] loss: 0.4053930640220642 2022-05-29 17:43:50.842922
Epoch:[ 96 17 ] loss: 0.40877121686935425 2022-05-29 17:43:51.618883
Epoch:[ 96 18 ] loss: 0.4040781259536743 2022-05-29 17:43:52.399662
Epoch:[ 96 19 ] loss: 0.40928566455841064 2022-05-29 17:43:53.187668
Training_Epoch:[ 96 ] Training_loss: 0.4089211463928223 2022-05-29 17:43:53.188350
learning rate:  5.3687091200000036e-05
netparams have been saved once 96
val: 1 0.5393834114074707
val: 2 0.526131808757782
val: 3 0.5431379079818726
val: 4 0.5066046118736267
val: 5 0.5258212685585022
val: 6 0.528631865978241
val: 7 0.5287337303161621
val: 8 0.553927481174469
val: 9 0.527673602104187
val: 10 0.5333501696586609
val: 11 0.5507211685180664
val: 12 0.5206129550933838
val: 13 0.5155479907989502
val: 14 0.5396722555160522
val: 15 0.5292785167694092
val: 16 0.5362541079521179
val: 17 0.5627636313438416
val: 18 0.5521360635757446
val: 19 0.5349845886230469
val: 20 0.5462422966957092
val_Epoch:[ 96 ] val_loss: 0.5350804716348648 2022-05-29 17:43:58.640125
start training 2022-05-29 17:43:58.755613
Epoch:[ 97 0 ] loss: 0.41085320711135864 2022-05-29 17:44:22.714011
Epoch:[ 97 1 ] loss: 0.4137933552265167 2022-05-29 17:44:23.503336
Epoch:[ 97 2 ] loss: 0.4075670838356018 2022-05-29 17:44:24.289058
Epoch:[ 97 3 ] loss: 0.41004371643066406 2022-05-29 17:44:25.065543
Epoch:[ 97 4 ] loss: 0.4104151129722595 2022-05-29 17:44:25.840657
Epoch:[ 97 5 ] loss: 0.4096110463142395 2022-05-29 17:44:26.619713
Epoch:[ 97 6 ] loss: 0.4052656292915344 2022-05-29 17:44:27.396073
Epoch:[ 97 7 ] loss: 0.40677565336227417 2022-05-29 17:44:28.169960
Epoch:[ 97 8 ] loss: 0.40968015789985657 2022-05-29 17:44:28.946028
Epoch:[ 97 9 ] loss: 0.40854179859161377 2022-05-29 17:44:29.719971
Epoch:[ 97 10 ] loss: 0.40969082713127136 2022-05-29 17:44:30.497677
Epoch:[ 97 11 ] loss: 0.4120166003704071 2022-05-29 17:44:31.275557
Epoch:[ 97 12 ] loss: 0.4073841869831085 2022-05-29 17:44:32.050769
Epoch:[ 97 13 ] loss: 0.40772080421447754 2022-05-29 17:44:32.840455
Epoch:[ 97 14 ] loss: 0.4106427729129791 2022-05-29 17:44:33.614202
Epoch:[ 97 15 ] loss: 0.404902845621109 2022-05-29 17:44:34.387321
Epoch:[ 97 16 ] loss: 0.40407079458236694 2022-05-29 17:44:41.154972
Epoch:[ 97 17 ] loss: 0.41183334589004517 2022-05-29 17:44:41.943766
Epoch:[ 97 18 ] loss: 0.4039148986339569 2022-05-29 17:44:42.725684
Epoch:[ 97 19 ] loss: 0.4109186828136444 2022-05-29 17:44:43.516248
Training_Epoch:[ 97 ] Training_loss: 0.4087821260094643 2022-05-29 17:44:43.516930
learning rate:  5.3687091200000036e-05
val: 1 0.5080658793449402
val: 2 0.5310451984405518
val: 3 0.5265858173370361
val: 4 0.5340163111686707
val: 5 0.5353991389274597
val: 6 0.5245007276535034
val: 7 0.5569031238555908
val: 8 0.5339879393577576
val: 9 0.5437631607055664
val: 10 0.5238673090934753
val: 11 0.5292540192604065
val: 12 0.5075660943984985
val: 13 0.5328384041786194
val: 14 0.5174123644828796
val: 15 0.5298194885253906
val: 16 0.53945392370224
val: 17 0.5544651746749878
val: 18 0.5467711687088013
val: 19 0.5394712090492249
val: 20 0.5558394193649292
val_Epoch:[ 97 ] val_loss: 0.5335512936115265 2022-05-29 17:44:48.801729
start training 2022-05-29 17:44:48.898415
Epoch:[ 98 0 ] loss: 0.4082161486148834 2022-05-29 17:45:11.165010
Epoch:[ 98 1 ] loss: 0.40788981318473816 2022-05-29 17:45:13.254591
Epoch:[ 98 2 ] loss: 0.41115057468414307 2022-05-29 17:45:14.030763
Epoch:[ 98 3 ] loss: 0.40674808621406555 2022-05-29 17:45:14.807334
Epoch:[ 98 4 ] loss: 0.40485647320747375 2022-05-29 17:45:15.586135
Epoch:[ 98 5 ] loss: 0.40990257263183594 2022-05-29 17:45:16.365905
Epoch:[ 98 6 ] loss: 0.40923410654067993 2022-05-29 17:45:17.129722
Epoch:[ 98 7 ] loss: 0.40607741475105286 2022-05-29 17:45:17.905633
Epoch:[ 98 8 ] loss: 0.4100055992603302 2022-05-29 17:45:18.682048
Epoch:[ 98 9 ] loss: 0.409532755613327 2022-05-29 17:45:19.457396
Epoch:[ 98 10 ] loss: 0.4136463403701782 2022-05-29 17:45:20.233431
Epoch:[ 98 11 ] loss: 0.4067935049533844 2022-05-29 17:45:21.011423
Epoch:[ 98 12 ] loss: 0.4089701473712921 2022-05-29 17:45:21.776966
Epoch:[ 98 13 ] loss: 0.4053528904914856 2022-05-29 17:45:22.554062
Epoch:[ 98 14 ] loss: 0.4135499596595764 2022-05-29 17:45:23.318935
Epoch:[ 98 15 ] loss: 0.41144832968711853 2022-05-29 17:45:24.094625
Epoch:[ 98 16 ] loss: 0.40618789196014404 2022-05-29 17:45:30.986845
Epoch:[ 98 17 ] loss: 0.4117913544178009 2022-05-29 17:45:31.772773
Epoch:[ 98 18 ] loss: 0.40831685066223145 2022-05-29 17:45:32.564563
Epoch:[ 98 19 ] loss: 0.4106874465942383 2022-05-29 17:45:33.342405
Training_Epoch:[ 98 ] Training_loss: 0.409017913043499 2022-05-29 17:45:33.343304
learning rate:  5.3687091200000036e-05
netparams have been saved once 98
val: 1 0.527385413646698
val: 2 0.513100802898407
val: 3 0.5290709137916565
val: 4 0.5248364806175232
val: 5 0.5290231108665466
val: 6 0.5357606410980225
val: 7 0.5410787463188171
val: 8 0.5373862385749817
val: 9 0.5349271297454834
val: 10 0.5308122038841248
val: 11 0.5497170090675354
val: 12 0.5469610095024109
val: 13 0.5502630472183228
val: 14 0.5344282388687134
val: 15 0.5524855256080627
val: 16 0.5221309065818787
val: 17 0.5317820906639099
val: 18 0.5342362523078918
val: 19 0.5449191927909851
val: 20 0.5322486162185669
val_Epoch:[ 98 ] val_loss: 0.5351276785135269 2022-05-29 17:45:38.644171
start training 2022-05-29 17:45:38.742177
Epoch:[ 99 0 ] loss: 0.4101995527744293 2022-05-29 17:46:02.386694
Epoch:[ 99 1 ] loss: 0.41078758239746094 2022-05-29 17:46:03.161979
Epoch:[ 99 2 ] loss: 0.40649187564849854 2022-05-29 17:46:03.952242
Epoch:[ 99 3 ] loss: 0.4075064957141876 2022-05-29 17:46:04.727992
Epoch:[ 99 4 ] loss: 0.4105157256126404 2022-05-29 17:46:05.514916
Epoch:[ 99 5 ] loss: 0.40962278842926025 2022-05-29 17:46:06.306037
Epoch:[ 99 6 ] loss: 0.4108330011367798 2022-05-29 17:46:07.098252
Epoch:[ 99 7 ] loss: 0.4075140058994293 2022-05-29 17:46:07.875739
Epoch:[ 99 8 ] loss: 0.4103314280509949 2022-05-29 17:46:08.652465
Epoch:[ 99 9 ] loss: 0.41171231865882874 2022-05-29 17:46:09.429247
Epoch:[ 99 10 ] loss: 0.40886667370796204 2022-05-29 17:46:10.203394
Epoch:[ 99 11 ] loss: 0.4095253050327301 2022-05-29 17:46:10.977903
Epoch:[ 99 12 ] loss: 0.4074450731277466 2022-05-29 17:46:11.756584
Epoch:[ 99 13 ] loss: 0.40259018540382385 2022-05-29 17:46:12.535397
Epoch:[ 99 14 ] loss: 0.41033098101615906 2022-05-29 17:46:13.311666
Epoch:[ 99 15 ] loss: 0.4062994420528412 2022-05-29 17:46:14.088446
Epoch:[ 99 16 ] loss: 0.40811780095100403 2022-05-29 17:46:20.828919
Epoch:[ 99 17 ] loss: 0.410194456577301 2022-05-29 17:46:21.601334
Epoch:[ 99 18 ] loss: 0.4066529870033264 2022-05-29 17:46:22.379797
Epoch:[ 99 19 ] loss: 0.40748313069343567 2022-05-29 17:46:23.167241
Training_Epoch:[ 99 ] Training_loss: 0.408651040494442 2022-05-29 17:46:23.167997
learning rate:  5.3687091200000036e-05
val: 1 0.5278305411338806
val: 2 0.5359096527099609
val: 3 0.5276067852973938
val: 4 0.5462590456008911
val: 5 0.515160858631134
val: 6 0.5281853675842285
val: 7 0.531293511390686
val: 8 0.5614888668060303
val: 9 0.5320574045181274
val: 10 0.5265684723854065
val: 11 0.5190105438232422
val: 12 0.5319195985794067
val: 13 0.5310389995574951
val: 14 0.5400748252868652
val: 15 0.5525438785552979
val: 16 0.5490456223487854
val: 17 0.5331390500068665
val: 18 0.5409314036369324
val: 19 0.5416126251220703
val: 20 0.5127243995666504
val_Epoch:[ 99 ] val_loss: 0.5342200726270676 2022-05-29 17:46:28.320240
start training 2022-05-29 17:46:28.418579
Epoch:[ 100 0 ] loss: 0.40691831707954407 2022-05-29 17:46:51.240418
Epoch:[ 100 1 ] loss: 0.410493940114975 2022-05-29 17:46:52.085663
Epoch:[ 100 2 ] loss: 0.4103812575340271 2022-05-29 17:46:52.863336
Epoch:[ 100 3 ] loss: 0.4097040295600891 2022-05-29 17:46:53.637445
Epoch:[ 100 4 ] loss: 0.4123085141181946 2022-05-29 17:46:54.412658
Epoch:[ 100 5 ] loss: 0.41001975536346436 2022-05-29 17:46:55.186703
Epoch:[ 100 6 ] loss: 0.40865933895111084 2022-05-29 17:46:55.963239
Epoch:[ 100 7 ] loss: 0.40503278374671936 2022-05-29 17:46:56.738254
Epoch:[ 100 8 ] loss: 0.4036945104598999 2022-05-29 17:46:57.516715
Epoch:[ 100 9 ] loss: 0.4096358120441437 2022-05-29 17:46:58.293371
Epoch:[ 100 10 ] loss: 0.4076181650161743 2022-05-29 17:46:59.079195
Epoch:[ 100 11 ] loss: 0.41353434324264526 2022-05-29 17:46:59.852222
Epoch:[ 100 12 ] loss: 0.4108724892139435 2022-05-29 17:47:00.626833
Epoch:[ 100 13 ] loss: 0.40674373507499695 2022-05-29 17:47:01.416275
Epoch:[ 100 14 ] loss: 0.40900668501853943 2022-05-29 17:47:02.205196
Epoch:[ 100 15 ] loss: 0.40500983595848083 2022-05-29 17:47:02.979640
Epoch:[ 100 16 ] loss: 0.4085930287837982 2022-05-29 17:47:10.623281
Epoch:[ 100 17 ] loss: 0.40511661767959595 2022-05-29 17:47:11.397701
Epoch:[ 100 18 ] loss: 0.4118177592754364 2022-05-29 17:47:12.184851
Epoch:[ 100 19 ] loss: 0.40964505076408386 2022-05-29 17:47:12.959109
Training_Epoch:[ 100 ] Training_loss: 0.40874029844999316 2022-05-29 17:47:12.959868
learning rate:  5.3687091200000036e-05
netparams have been saved once 100
val: 1 0.5378292202949524
val: 2 0.522976815700531
val: 3 0.5273373126983643
val: 4 0.5378439426422119
val: 5 0.542818546295166
val: 6 0.5181426405906677
val: 7 0.5308122038841248
val: 8 0.5256487131118774
val: 9 0.5261678695678711
val: 10 0.542752742767334
val: 11 0.5482879877090454
val: 12 0.5598495602607727
val: 13 0.5341282486915588
val: 14 0.5123217701911926
val: 15 0.5447977781295776
val: 16 0.5392626523971558
val: 17 0.5416971445083618
val: 18 0.5113285183906555
val: 19 0.5205570459365845
val: 20 0.5423988699913025
val_Epoch:[ 100 ] val_loss: 0.5333479791879654 2022-05-29 17:47:18.272340
start training 2022-05-29 17:47:18.367151
Epoch:[ 101 0 ] loss: 0.40891170501708984 2022-05-29 17:47:40.633183
Epoch:[ 101 1 ] loss: 0.4097665548324585 2022-05-29 17:47:42.169737
Epoch:[ 101 2 ] loss: 0.40995240211486816 2022-05-29 17:47:42.948210
Epoch:[ 101 3 ] loss: 0.40695759654045105 2022-05-29 17:47:43.723276
Epoch:[ 101 4 ] loss: 0.41143423318862915 2022-05-29 17:47:44.498133
Epoch:[ 101 5 ] loss: 0.40430015325546265 2022-05-29 17:47:45.275141
Epoch:[ 101 6 ] loss: 0.4070405066013336 2022-05-29 17:47:46.050791
Epoch:[ 101 7 ] loss: 0.4068703353404999 2022-05-29 17:47:46.827585
Epoch:[ 101 8 ] loss: 0.40765994787216187 2022-05-29 17:47:47.604237
Epoch:[ 101 9 ] loss: 0.4078403115272522 2022-05-29 17:47:48.380203
Epoch:[ 101 10 ] loss: 0.40953752398490906 2022-05-29 17:47:49.156217
Epoch:[ 101 11 ] loss: 0.409532755613327 2022-05-29 17:47:49.944936
Epoch:[ 101 12 ] loss: 0.4079381823539734 2022-05-29 17:47:50.733880
Epoch:[ 101 13 ] loss: 0.407113641500473 2022-05-29 17:47:51.507693
Epoch:[ 101 14 ] loss: 0.4103984236717224 2022-05-29 17:47:52.297223
Epoch:[ 101 15 ] loss: 0.4102974236011505 2022-05-29 17:47:53.072776
Epoch:[ 101 16 ] loss: 0.4060685634613037 2022-05-29 17:48:00.187821
Epoch:[ 101 17 ] loss: 0.4055212140083313 2022-05-29 17:48:00.975350
Epoch:[ 101 18 ] loss: 0.4061722755432129 2022-05-29 17:48:01.766348
Epoch:[ 101 19 ] loss: 0.4115425646305084 2022-05-29 17:48:02.539995
Training_Epoch:[ 101 ] Training_loss: 0.40824281573295595 2022-05-29 17:48:02.540697
learning rate:  4.2949672960000034e-05
val: 1 0.5184879899024963
val: 2 0.5207108855247498
val: 3 0.5318176746368408
val: 4 0.5423896908760071
val: 5 0.5258379578590393
val: 6 0.5184838175773621
val: 7 0.5583848357200623
val: 8 0.5192249417304993
val: 9 0.5328409671783447
val: 10 0.5342716574668884
val: 11 0.5250579714775085
val: 12 0.5325995087623596
val: 13 0.5404688119888306
val: 14 0.558915376663208
val: 15 0.5553852915763855
val: 16 0.5337170958518982
val: 17 0.5269955396652222
val: 18 0.5438143610954285
val: 19 0.5542501211166382
val: 20 0.5299621820449829
val_Epoch:[ 101 ] val_loss: 0.5351808339357376 2022-05-29 17:48:07.792684
start training 2022-05-29 17:48:07.884131
Epoch:[ 102 0 ] loss: 0.40571942925453186 2022-05-29 17:48:30.657884
Epoch:[ 102 1 ] loss: 0.4106987416744232 2022-05-29 17:48:31.467219
Epoch:[ 102 2 ] loss: 0.4088388681411743 2022-05-29 17:48:32.244328
Epoch:[ 102 3 ] loss: 0.40543225407600403 2022-05-29 17:48:33.021115
Epoch:[ 102 4 ] loss: 0.41006985306739807 2022-05-29 17:48:33.797878
Epoch:[ 102 5 ] loss: 0.4054171144962311 2022-05-29 17:48:34.572408
Epoch:[ 102 6 ] loss: 0.40786463022232056 2022-05-29 17:48:35.347248
Epoch:[ 102 7 ] loss: 0.40979546308517456 2022-05-29 17:48:36.120564
Epoch:[ 102 8 ] loss: 0.40978923439979553 2022-05-29 17:48:36.909097
Epoch:[ 102 9 ] loss: 0.4104953408241272 2022-05-29 17:48:37.687277
Epoch:[ 102 10 ] loss: 0.4121921956539154 2022-05-29 17:48:38.461508
Epoch:[ 102 11 ] loss: 0.40756091475486755 2022-05-29 17:48:39.247800
Epoch:[ 102 12 ] loss: 0.40620002150535583 2022-05-29 17:48:40.021175
Epoch:[ 102 13 ] loss: 0.4109888970851898 2022-05-29 17:48:40.810526
Epoch:[ 102 14 ] loss: 0.40844011306762695 2022-05-29 17:48:41.585034
Epoch:[ 102 15 ] loss: 0.40404054522514343 2022-05-29 17:48:42.361903
Epoch:[ 102 16 ] loss: 0.41003212332725525 2022-05-29 17:48:49.733525
Epoch:[ 102 17 ] loss: 0.40847334265708923 2022-05-29 17:48:50.520988
Epoch:[ 102 18 ] loss: 0.4074201285839081 2022-05-29 17:48:51.304617
Epoch:[ 102 19 ] loss: 0.4047134518623352 2022-05-29 17:48:52.091392
Training_Epoch:[ 102 ] Training_loss: 0.40820913314819335 2022-05-29 17:48:52.092025
learning rate:  4.2949672960000034e-05
netparams have been saved once 102
val: 1 0.5236721634864807
val: 2 0.5451588034629822
val: 3 0.539023756980896
val: 4 0.5188717246055603
val: 5 0.5368651747703552
val: 6 0.5498504042625427
val: 7 0.5406045913696289
val: 8 0.504698634147644
val: 9 0.5361623167991638
val: 10 0.5559647679328918
val: 11 0.511888325214386
val: 12 0.5541107654571533
val: 13 0.5371795892715454
val: 14 0.525894045829773
val: 15 0.5502883791923523
val: 16 0.5355520844459534
val: 17 0.5332797765731812
val: 18 0.5312185883522034
val: 19 0.5378695130348206
val: 20 0.5283571481704712
val_Epoch:[ 102 ] val_loss: 0.5348255276679993 2022-05-29 17:48:57.413545
start training 2022-05-29 17:48:57.511289
Epoch:[ 103 0 ] loss: 0.40514785051345825 2022-05-29 17:49:20.521499
Epoch:[ 103 1 ] loss: 0.40870705246925354 2022-05-29 17:49:21.337059
Epoch:[ 103 2 ] loss: 0.41239702701568604 2022-05-29 17:49:22.115130
Epoch:[ 103 3 ] loss: 0.41022926568984985 2022-05-29 17:49:22.892541
Epoch:[ 103 4 ] loss: 0.4059199094772339 2022-05-29 17:49:23.668776
Epoch:[ 103 5 ] loss: 0.40600892901420593 2022-05-29 17:49:24.443857
Epoch:[ 103 6 ] loss: 0.41142037510871887 2022-05-29 17:49:25.230095
Epoch:[ 103 7 ] loss: 0.4092419445514679 2022-05-29 17:49:26.007022
Epoch:[ 103 8 ] loss: 0.4068320095539093 2022-05-29 17:49:26.780771
Epoch:[ 103 9 ] loss: 0.40694746375083923 2022-05-29 17:49:27.558915
Epoch:[ 103 10 ] loss: 0.40289899706840515 2022-05-29 17:49:28.348408
Epoch:[ 103 11 ] loss: 0.40783458948135376 2022-05-29 17:49:29.125866
Epoch:[ 103 12 ] loss: 0.40983349084854126 2022-05-29 17:49:29.901668
Epoch:[ 103 13 ] loss: 0.4107665717601776 2022-05-29 17:49:30.688495
Epoch:[ 103 14 ] loss: 0.41189223527908325 2022-05-29 17:49:31.465038
Epoch:[ 103 15 ] loss: 0.4088028073310852 2022-05-29 17:49:32.239480
Epoch:[ 103 16 ] loss: 0.40717121958732605 2022-05-29 17:49:39.857121
Epoch:[ 103 17 ] loss: 0.4090285003185272 2022-05-29 17:49:40.634529
Epoch:[ 103 18 ] loss: 0.4063229262828827 2022-05-29 17:49:41.417698
Epoch:[ 103 19 ] loss: 0.40854761004447937 2022-05-29 17:49:42.207074
Training_Epoch:[ 103 ] Training_loss: 0.4082975387573242 2022-05-29 17:49:42.207718
learning rate:  4.2949672960000034e-05
val: 1 0.5448365807533264
val: 2 0.5080269575119019
val: 3 0.5313396453857422
val: 4 0.5379464626312256
val: 5 0.5356971025466919
val: 6 0.5245707035064697
val: 7 0.5345355272293091
val: 8 0.551956295967102
val: 9 0.5192906260490417
val: 10 0.5325958728790283
val: 11 0.5428559184074402
val: 12 0.5473276376724243
val: 13 0.524150013923645
val: 14 0.5309394001960754
val: 15 0.5389418601989746
val: 16 0.5522395372390747
val: 17 0.5190483927726746
val: 18 0.5423665642738342
val: 19 0.5207939147949219
val: 20 0.553536057472229
val_Epoch:[ 103 ] val_loss: 0.5346497535705567 2022-05-29 17:49:47.440601
start training 2022-05-29 17:49:47.534818
Epoch:[ 104 0 ] loss: 0.40904712677001953 2022-05-29 17:50:09.681744
Epoch:[ 104 1 ] loss: 0.40569350123405457 2022-05-29 17:50:10.489253
Epoch:[ 104 2 ] loss: 0.40930959582328796 2022-05-29 17:50:11.287726
Epoch:[ 104 3 ] loss: 0.4073103368282318 2022-05-29 17:50:12.075487
Epoch:[ 104 4 ] loss: 0.4050839841365814 2022-05-29 17:50:12.864058
Epoch:[ 104 5 ] loss: 0.41069021821022034 2022-05-29 17:50:13.639416
Epoch:[ 104 6 ] loss: 0.4098300337791443 2022-05-29 17:50:14.413128
Epoch:[ 104 7 ] loss: 0.4076748788356781 2022-05-29 17:50:15.187318
Epoch:[ 104 8 ] loss: 0.4102329611778259 2022-05-29 17:50:15.961768
Epoch:[ 104 9 ] loss: 0.4086611270904541 2022-05-29 17:50:16.734927
Epoch:[ 104 10 ] loss: 0.40708184242248535 2022-05-29 17:50:17.510258
Epoch:[ 104 11 ] loss: 0.4112248420715332 2022-05-29 17:50:18.286350
Epoch:[ 104 12 ] loss: 0.40596529841423035 2022-05-29 17:50:19.060209
Epoch:[ 104 13 ] loss: 0.405513197183609 2022-05-29 17:50:19.835999
Epoch:[ 104 14 ] loss: 0.4051801264286041 2022-05-29 17:50:20.611709
Epoch:[ 104 15 ] loss: 0.40670764446258545 2022-05-29 17:50:21.386023
Epoch:[ 104 16 ] loss: 0.4104163646697998 2022-05-29 17:50:29.562695
Epoch:[ 104 17 ] loss: 0.40970438718795776 2022-05-29 17:50:30.350769
Epoch:[ 104 18 ] loss: 0.4030781090259552 2022-05-29 17:50:31.131023
Epoch:[ 104 19 ] loss: 0.40907514095306396 2022-05-29 17:50:31.918593
Training_Epoch:[ 104 ] Training_loss: 0.4078740358352661 2022-05-29 17:50:31.919285
learning rate:  4.2949672960000034e-05
netparams have been saved once 104
val: 1 0.5306776165962219
val: 2 0.5312653183937073
val: 3 0.5497881770133972
val: 4 0.548939049243927
val: 5 0.5252178311347961
val: 6 0.5413582921028137
val: 7 0.5343002676963806
val: 8 0.5203191637992859
val: 9 0.5184057950973511
val: 10 0.5586576461791992
val: 11 0.5292385220527649
val: 12 0.5361276268959045
val: 13 0.5519222021102905
val: 14 0.5442898869514465
val: 15 0.5292242765426636
val: 16 0.5178470015525818
val: 17 0.5510197281837463
val: 18 0.5310859084129333
val: 19 0.5322180390357971
val: 20 0.5241960287094116
val_Epoch:[ 104 ] val_loss: 0.535304918885231 2022-05-29 17:50:37.263851
start training 2022-05-29 17:50:37.355590
Epoch:[ 105 0 ] loss: 0.4090849757194519 2022-05-29 17:51:01.249554
Epoch:[ 105 1 ] loss: 0.4068983495235443 2022-05-29 17:51:02.026555
Epoch:[ 105 2 ] loss: 0.40859732031822205 2022-05-29 17:51:02.815534
Epoch:[ 105 3 ] loss: 0.40536442399024963 2022-05-29 17:51:03.590636
Epoch:[ 105 4 ] loss: 0.409172385931015 2022-05-29 17:51:04.367484
Epoch:[ 105 5 ] loss: 0.4086167812347412 2022-05-29 17:51:05.144997
Epoch:[ 105 6 ] loss: 0.4081905484199524 2022-05-29 17:51:05.918999
Epoch:[ 105 7 ] loss: 0.40754687786102295 2022-05-29 17:51:06.696656
Epoch:[ 105 8 ] loss: 0.4065314829349518 2022-05-29 17:51:07.482523
Epoch:[ 105 9 ] loss: 0.4055913984775543 2022-05-29 17:51:08.270019
Epoch:[ 105 10 ] loss: 0.41207578778266907 2022-05-29 17:51:09.044795
Epoch:[ 105 11 ] loss: 0.40872982144355774 2022-05-29 17:51:09.820873
Epoch:[ 105 12 ] loss: 0.4070901870727539 2022-05-29 17:51:10.600771
Epoch:[ 105 13 ] loss: 0.4056621193885803 2022-05-29 17:51:11.376913
Epoch:[ 105 14 ] loss: 0.41201719641685486 2022-05-29 17:51:12.151797
Epoch:[ 105 15 ] loss: 0.407593309879303 2022-05-29 17:51:12.926905
Epoch:[ 105 16 ] loss: 0.4050291180610657 2022-05-29 17:51:19.379281
Epoch:[ 105 17 ] loss: 0.4060904383659363 2022-05-29 17:51:20.163770
Epoch:[ 105 18 ] loss: 0.40617281198501587 2022-05-29 17:51:20.955445
Epoch:[ 105 19 ] loss: 0.41207945346832275 2022-05-29 17:51:21.731341
Training_Epoch:[ 105 ] Training_loss: 0.40790673941373823 2022-05-29 17:51:21.732076
learning rate:  4.2949672960000034e-05
val: 1 0.539091944694519
val: 2 0.5222321152687073
val: 3 0.5434191226959229
val: 4 0.5233610272407532
val: 5 0.5442699193954468
val: 6 0.5384958982467651
val: 7 0.5138038396835327
val: 8 0.5440144538879395
val: 9 0.5441266894340515
val: 10 0.5443432927131653
val: 11 0.5437966585159302
val: 12 0.547580897808075
val: 13 0.5400930643081665
val: 14 0.5169731378555298
val: 15 0.5229344367980957
val: 16 0.5365655422210693
val: 17 0.5475350618362427
val: 18 0.5421018600463867
val: 19 0.5487027168273926
val: 20 0.5354841351509094
val_Epoch:[ 105 ] val_loss: 0.5369462907314301 2022-05-29 17:51:26.879792
start training 2022-05-29 17:51:26.975282
Epoch:[ 106 0 ] loss: 0.40791743993759155 2022-05-29 17:51:50.056179
Epoch:[ 106 1 ] loss: 0.4070371687412262 2022-05-29 17:51:50.885196
Epoch:[ 106 2 ] loss: 0.40776437520980835 2022-05-29 17:51:51.670476
Epoch:[ 106 3 ] loss: 0.40567222237586975 2022-05-29 17:51:52.446525
Epoch:[ 106 4 ] loss: 0.4136659502983093 2022-05-29 17:51:53.219321
Epoch:[ 106 5 ] loss: 0.4110431969165802 2022-05-29 17:51:53.994550
Epoch:[ 106 6 ] loss: 0.4068912863731384 2022-05-29 17:51:54.770829
Epoch:[ 106 7 ] loss: 0.40614786744117737 2022-05-29 17:51:55.544135
Epoch:[ 106 8 ] loss: 0.40508177876472473 2022-05-29 17:51:56.318902
Epoch:[ 106 9 ] loss: 0.4095330834388733 2022-05-29 17:51:57.093143
Epoch:[ 106 10 ] loss: 0.40780946612358093 2022-05-29 17:51:57.879032
Epoch:[ 106 11 ] loss: 0.405986487865448 2022-05-29 17:51:58.652493
Epoch:[ 106 12 ] loss: 0.407019704580307 2022-05-29 17:51:59.441089
Epoch:[ 106 13 ] loss: 0.4078555703163147 2022-05-29 17:52:00.217719
Epoch:[ 106 14 ] loss: 0.4080425798892975 2022-05-29 17:52:00.993262
Epoch:[ 106 15 ] loss: 0.40605831146240234 2022-05-29 17:52:01.765839
Epoch:[ 106 16 ] loss: 0.4025377333164215 2022-05-29 17:52:09.123844
Epoch:[ 106 17 ] loss: 0.41065263748168945 2022-05-29 17:52:09.907637
Epoch:[ 106 18 ] loss: 0.4058070480823517 2022-05-29 17:52:10.699709
Epoch:[ 106 19 ] loss: 0.40735292434692383 2022-05-29 17:52:11.487815
Training_Epoch:[ 106 ] Training_loss: 0.4074938416481018 2022-05-29 17:52:11.488487
learning rate:  4.2949672960000034e-05
netparams have been saved once 106
val: 1 0.5302277207374573
val: 2 0.538145124912262
val: 3 0.5551175475120544
val: 4 0.5247111916542053
val: 5 0.5433066487312317
val: 6 0.5748987793922424
val: 7 0.529689610004425
val: 8 0.5296145677566528
val: 9 0.5268288850784302
val: 10 0.5279696583747864
val: 11 0.5307777523994446
val: 12 0.5298094749450684
val: 13 0.5446084141731262
val: 14 0.5221050381660461
val: 15 0.5344054698944092
val: 16 0.5310763120651245
val: 17 0.5212406516075134
val: 18 0.5350334644317627
val: 19 0.5376788973808289
val: 20 0.5319542288780212
val_Epoch:[ 106 ] val_loss: 0.5349599719047546 2022-05-29 17:52:16.778852
start training 2022-05-29 17:52:16.876287
Epoch:[ 107 0 ] loss: 0.4033125638961792 2022-05-29 17:52:40.558541
Epoch:[ 107 1 ] loss: 0.40664684772491455 2022-05-29 17:52:41.336481
Epoch:[ 107 2 ] loss: 0.4046313762664795 2022-05-29 17:52:42.113949
Epoch:[ 107 3 ] loss: 0.40703144669532776 2022-05-29 17:52:42.887891
Epoch:[ 107 4 ] loss: 0.4022762179374695 2022-05-29 17:52:43.672844
Epoch:[ 107 5 ] loss: 0.40707674622535706 2022-05-29 17:52:44.446750
Epoch:[ 107 6 ] loss: 0.4048888087272644 2022-05-29 17:52:45.223095
Epoch:[ 107 7 ] loss: 0.41434258222579956 2022-05-29 17:52:46.001478
Epoch:[ 107 8 ] loss: 0.4074983596801758 2022-05-29 17:52:46.792963
Epoch:[ 107 9 ] loss: 0.40832141041755676 2022-05-29 17:52:47.566570
Epoch:[ 107 10 ] loss: 0.4055246114730835 2022-05-29 17:52:48.340689
Epoch:[ 107 11 ] loss: 0.40671834349632263 2022-05-29 17:52:49.116127
Epoch:[ 107 12 ] loss: 0.40673258900642395 2022-05-29 17:52:49.902651
Epoch:[ 107 13 ] loss: 0.4075571596622467 2022-05-29 17:52:50.678702
Epoch:[ 107 14 ] loss: 0.4111593961715698 2022-05-29 17:52:51.455343
Epoch:[ 107 15 ] loss: 0.40662825107574463 2022-05-29 17:52:52.231073
Epoch:[ 107 16 ] loss: 0.4075043201446533 2022-05-29 17:52:59.420072
Epoch:[ 107 17 ] loss: 0.40726497769355774 2022-05-29 17:53:00.193465
Epoch:[ 107 18 ] loss: 0.4111464321613312 2022-05-29 17:53:00.984506
Epoch:[ 107 19 ] loss: 0.4110824763774872 2022-05-29 17:53:01.770327
Training_Epoch:[ 107 ] Training_loss: 0.40736724585294726 2022-05-29 17:53:01.771092
learning rate:  4.2949672960000034e-05
val: 1 0.5385918021202087
val: 2 0.536907970905304
val: 3 0.5371629595756531
val: 4 0.5463119149208069
val: 5 0.5227505564689636
val: 6 0.5374513268470764
val: 7 0.538669228553772
val: 8 0.5273030400276184
val: 9 0.5343412160873413
val: 10 0.5303268432617188
val: 11 0.5497603416442871
val: 12 0.5410253405570984
val: 13 0.530394971370697
val: 14 0.5322213768959045
val: 15 0.520928144454956
val: 16 0.5534639358520508
val: 17 0.5425428748130798
val: 18 0.5523732900619507
val: 19 0.5565283298492432
val: 20 0.5125812292098999
val_Epoch:[ 107 ] val_loss: 0.5370818346738815 2022-05-29 17:53:07.015615
start training 2022-05-29 17:53:07.116610
Epoch:[ 108 0 ] loss: 0.40815576910972595 2022-05-29 17:53:29.265455
Epoch:[ 108 1 ] loss: 0.4030231535434723 2022-05-29 17:53:31.116749
Epoch:[ 108 2 ] loss: 0.40638819336891174 2022-05-29 17:53:31.893403
Epoch:[ 108 3 ] loss: 0.4106319844722748 2022-05-29 17:53:32.669311
Epoch:[ 108 4 ] loss: 0.4088178873062134 2022-05-29 17:53:33.443724
Epoch:[ 108 5 ] loss: 0.40656253695487976 2022-05-29 17:53:34.221799
Epoch:[ 108 6 ] loss: 0.4114108383655548 2022-05-29 17:53:34.996077
Epoch:[ 108 7 ] loss: 0.40832406282424927 2022-05-29 17:53:35.791256
Epoch:[ 108 8 ] loss: 0.40680089592933655 2022-05-29 17:53:36.575381
Epoch:[ 108 9 ] loss: 0.40688833594322205 2022-05-29 17:53:37.358402
Epoch:[ 108 10 ] loss: 0.40998587012290955 2022-05-29 17:53:38.152701
Epoch:[ 108 11 ] loss: 0.40721771121025085 2022-05-29 17:53:38.934571
Epoch:[ 108 12 ] loss: 0.40884000062942505 2022-05-29 17:53:39.716954
Epoch:[ 108 13 ] loss: 0.40726980566978455 2022-05-29 17:53:40.507133
Epoch:[ 108 14 ] loss: 0.40724989771842957 2022-05-29 17:53:41.291389
Epoch:[ 108 15 ] loss: 0.4083884060382843 2022-05-29 17:53:42.077143
Epoch:[ 108 16 ] loss: 0.40852174162864685 2022-05-29 17:53:49.160999
Epoch:[ 108 17 ] loss: 0.4078144431114197 2022-05-29 17:53:50.407350
Epoch:[ 108 18 ] loss: 0.4053177237510681 2022-05-29 17:53:51.514606
Epoch:[ 108 19 ] loss: 0.40503713488578796 2022-05-29 17:53:52.293478
Training_Epoch:[ 108 ] Training_loss: 0.40763231962919233 2022-05-29 17:53:52.294560
learning rate:  4.2949672960000034e-05
netparams have been saved once 108
val: 1 0.5557054877281189
val: 2 0.5297742486000061
val: 3 0.5431563854217529
val: 4 0.5445985198020935
val: 5 0.5182046294212341
val: 6 0.5346335172653198
val: 7 0.5089743733406067
val: 8 0.5414474606513977
val: 9 0.5284885168075562
val: 10 0.5270594954490662
val: 11 0.5204304456710815
val: 12 0.5315830111503601
val: 13 0.5619057416915894
val: 14 0.5368759036064148
val: 15 0.5268159508705139
val: 16 0.5324649214744568
val: 17 0.5336705446243286
val: 18 0.5318552851676941
val: 19 0.5446022748947144
val: 20 0.5484789609909058
val_Epoch:[ 108 ] val_loss: 0.5350362837314606 2022-05-29 17:53:58.468379
start training 2022-05-29 17:53:58.590743
Epoch:[ 109 0 ] loss: 0.4095423221588135 2022-05-29 17:54:29.298394
Epoch:[ 109 1 ] loss: 0.4042620062828064 2022-05-29 17:54:30.126923
Epoch:[ 109 2 ] loss: 0.4061146676540375 2022-05-29 17:54:30.943587
Epoch:[ 109 3 ] loss: 0.40719905495643616 2022-05-29 17:54:31.767011
Epoch:[ 109 4 ] loss: 0.4076169729232788 2022-05-29 17:54:32.584239
Epoch:[ 109 5 ] loss: 0.41321372985839844 2022-05-29 17:54:33.394754
Epoch:[ 109 6 ] loss: 0.40661484003067017 2022-05-29 17:54:34.207204
Epoch:[ 109 7 ] loss: 0.40776464343070984 2022-05-29 17:54:35.018608
Epoch:[ 109 8 ] loss: 0.40615418553352356 2022-05-29 17:54:35.839055
Epoch:[ 109 9 ] loss: 0.4123224914073944 2022-05-29 17:54:36.653405
Epoch:[ 109 10 ] loss: 0.40694916248321533 2022-05-29 17:54:37.467820
Epoch:[ 109 11 ] loss: 0.4076882302761078 2022-05-29 17:54:38.282535
Epoch:[ 109 12 ] loss: 0.40793678164482117 2022-05-29 17:54:39.094260
Epoch:[ 109 13 ] loss: 0.4104146361351013 2022-05-29 17:54:39.909858
Epoch:[ 109 14 ] loss: 0.4058746099472046 2022-05-29 17:54:40.720278
Epoch:[ 109 15 ] loss: 0.4071347415447235 2022-05-29 17:54:41.544568
Epoch:[ 109 16 ] loss: 0.4069850444793701 2022-05-29 17:54:52.480990
Epoch:[ 109 17 ] loss: 0.40483832359313965 2022-05-29 17:54:53.290431
Epoch:[ 109 18 ] loss: 0.4058898389339447 2022-05-29 17:54:54.192311
Epoch:[ 109 19 ] loss: 0.4059639871120453 2022-05-29 17:54:55.015868
Training_Epoch:[ 109 ] Training_loss: 0.40752401351928713 2022-05-29 17:54:55.016728
learning rate:  4.2949672960000034e-05
val: 1 0.516921877861023
val: 2 0.5412076115608215
val: 3 0.5229490995407104
val: 4 0.5271556377410889
val: 5 0.5270063281059265
val: 6 0.5089108943939209
val: 7 0.5471581220626831
val: 8 0.530622124671936
val: 9 0.5335772037506104
val: 10 0.5563127994537354
val: 11 0.5450741648674011
val: 12 0.5314205288887024
val: 13 0.5367698073387146
val: 14 0.5338471531867981
val: 15 0.5268266201019287
val: 16 0.553442120552063
val: 17 0.534625232219696
val: 18 0.5390176177024841
val: 19 0.5385761260986328
val: 20 0.5503148436546326
val_Epoch:[ 109 ] val_loss: 0.5350867956876755 2022-05-29 17:55:01.466073
start training 2022-05-29 17:55:01.588472
Epoch:[ 110 0 ] loss: 0.4054337441921234 2022-05-29 17:55:32.296904
Epoch:[ 110 1 ] loss: 0.40491509437561035 2022-05-29 17:55:33.110285
Epoch:[ 110 2 ] loss: 0.40946635603904724 2022-05-29 17:55:33.931823
Epoch:[ 110 3 ] loss: 0.40524011850357056 2022-05-29 17:55:34.758012
Epoch:[ 110 4 ] loss: 0.4092818796634674 2022-05-29 17:55:35.579732
Epoch:[ 110 5 ] loss: 0.4072563946247101 2022-05-29 17:55:36.391648
Epoch:[ 110 6 ] loss: 0.40815654397010803 2022-05-29 17:55:37.203379
Epoch:[ 110 7 ] loss: 0.4070064425468445 2022-05-29 17:55:38.014789
Epoch:[ 110 8 ] loss: 0.4088793396949768 2022-05-29 17:55:38.824455
Epoch:[ 110 9 ] loss: 0.4043179154396057 2022-05-29 17:55:39.640010
Epoch:[ 110 10 ] loss: 0.41196921467781067 2022-05-29 17:55:40.452755
Epoch:[ 110 11 ] loss: 0.40495437383651733 2022-05-29 17:55:41.265673
Epoch:[ 110 12 ] loss: 0.4074457287788391 2022-05-29 17:55:42.081311
Epoch:[ 110 13 ] loss: 0.40609532594680786 2022-05-29 17:55:42.900823
Epoch:[ 110 14 ] loss: 0.40764179825782776 2022-05-29 17:55:43.710550
Epoch:[ 110 15 ] loss: 0.4040335416793823 2022-05-29 17:55:44.521069
Epoch:[ 110 16 ] loss: 0.4061330258846283 2022-05-29 17:55:55.157156
Epoch:[ 110 17 ] loss: 0.40991926193237305 2022-05-29 17:55:55.973720
Epoch:[ 110 18 ] loss: 0.41145965456962585 2022-05-29 17:55:56.857086
Epoch:[ 110 19 ] loss: 0.4075208008289337 2022-05-29 17:55:57.669592
Training_Epoch:[ 110 ] Training_loss: 0.4073563277721405 2022-05-29 17:55:57.670479
learning rate:  4.2949672960000034e-05
netparams have been saved once 110
val: 1 0.5490145087242126
val: 2 0.5276889801025391
val: 3 0.5240511298179626
val: 4 0.5561949610710144
val: 5 0.518399178981781
val: 6 0.5459206104278564
val: 7 0.5128313302993774
val: 8 0.5284024477005005
val: 9 0.5243636965751648
val: 10 0.5335245132446289
val: 11 0.5398094058036804
val: 12 0.5255422592163086
val: 13 0.5322405695915222
val: 14 0.5577757954597473
val: 15 0.5601207613945007
val: 16 0.5440936088562012
val: 17 0.5439741015434265
val: 18 0.5134854316711426
val: 19 0.531926155090332
val: 20 0.5592933893203735
val_Epoch:[ 110 ] val_loss: 0.5364326417446137 2022-05-29 17:56:03.691277
start training 2022-05-29 17:56:03.809987
Epoch:[ 111 0 ] loss: 0.40369632840156555 2022-05-29 17:56:32.713179
Epoch:[ 111 1 ] loss: 0.40884363651275635 2022-05-29 17:56:33.527899
Epoch:[ 111 2 ] loss: 0.4058540165424347 2022-05-29 17:56:34.324497
Epoch:[ 111 3 ] loss: 0.4095931053161621 2022-05-29 17:56:35.119804
Epoch:[ 111 4 ] loss: 0.4071069657802582 2022-05-29 17:56:35.919060
Epoch:[ 111 5 ] loss: 0.40804553031921387 2022-05-29 17:56:36.719066
Epoch:[ 111 6 ] loss: 0.4049004018306732 2022-05-29 17:56:37.530694
Epoch:[ 111 7 ] loss: 0.40893903374671936 2022-05-29 17:56:38.345430
Epoch:[ 111 8 ] loss: 0.4065021574497223 2022-05-29 17:56:39.130308
Epoch:[ 111 9 ] loss: 0.40295442938804626 2022-05-29 17:56:39.923121
Epoch:[ 111 10 ] loss: 0.4055170714855194 2022-05-29 17:56:40.704552
Epoch:[ 111 11 ] loss: 0.40498462319374084 2022-05-29 17:56:41.485926
Epoch:[ 111 12 ] loss: 0.4106675684452057 2022-05-29 17:56:42.263297
Epoch:[ 111 13 ] loss: 0.40622684359550476 2022-05-29 17:56:43.040943
Epoch:[ 111 14 ] loss: 0.4086856544017792 2022-05-29 17:56:43.817903
Epoch:[ 111 15 ] loss: 0.40417739748954773 2022-05-29 17:56:44.594633
Epoch:[ 111 16 ] loss: 0.40776753425598145 2022-05-29 17:56:53.297321
Epoch:[ 111 17 ] loss: 0.4084770679473877 2022-05-29 17:56:54.107153
Epoch:[ 111 18 ] loss: 0.40705451369285583 2022-05-29 17:56:55.004152
Epoch:[ 111 19 ] loss: 0.41080519556999207 2022-05-29 17:56:55.817442
Training_Epoch:[ 111 ] Training_loss: 0.4070399537682533 2022-05-29 17:56:55.818648
learning rate:  3.435973836800003e-05
val: 1 0.53086256980896
val: 2 0.5695563554763794
val: 3 0.5221840739250183
val: 4 0.5207193493843079
val: 5 0.5268508791923523
val: 6 0.5394797325134277
val: 7 0.5385758876800537
val: 8 0.5415260195732117
val: 9 0.54123854637146
val: 10 0.5425395965576172
val: 11 0.5136851072311401
val: 12 0.5361482501029968
val: 13 0.527534544467926
val: 14 0.5468713045120239
val: 15 0.5260464549064636
val: 16 0.5451567769050598
val: 17 0.5350105166435242
val: 18 0.5550214648246765
val: 19 0.5247714519500732
val: 20 0.5218361616134644
val_Epoch:[ 111 ] val_loss: 0.5352807521820069 2022-05-29 17:57:02.041301
start training 2022-05-29 17:57:02.166135
Epoch:[ 112 0 ] loss: 0.40689152479171753 2022-05-29 17:57:33.158931
Epoch:[ 112 1 ] loss: 0.4046352207660675 2022-05-29 17:57:33.971430
Epoch:[ 112 2 ] loss: 0.4055226743221283 2022-05-29 17:57:34.790408
Epoch:[ 112 3 ] loss: 0.40336722135543823 2022-05-29 17:57:35.597544
Epoch:[ 112 4 ] loss: 0.4038075804710388 2022-05-29 17:57:36.407799
Epoch:[ 112 5 ] loss: 0.4069315493106842 2022-05-29 17:57:37.221014
Epoch:[ 112 6 ] loss: 0.40160804986953735 2022-05-29 17:57:38.031778
Epoch:[ 112 7 ] loss: 0.41036751866340637 2022-05-29 17:57:38.844951
Epoch:[ 112 8 ] loss: 0.4101446568965912 2022-05-29 17:57:39.654611
Epoch:[ 112 9 ] loss: 0.4109923839569092 2022-05-29 17:57:40.466221
Epoch:[ 112 10 ] loss: 0.4059343636035919 2022-05-29 17:57:41.276044
Epoch:[ 112 11 ] loss: 0.41172975301742554 2022-05-29 17:57:42.089971
Epoch:[ 112 12 ] loss: 0.40807265043258667 2022-05-29 17:57:42.911034
Epoch:[ 112 13 ] loss: 0.40783917903900146 2022-05-29 17:57:43.730279
Epoch:[ 112 14 ] loss: 0.40767359733581543 2022-05-29 17:57:44.543637
Epoch:[ 112 15 ] loss: 0.411083847284317 2022-05-29 17:57:45.357317
Epoch:[ 112 16 ] loss: 0.4020404517650604 2022-05-29 17:57:56.287350
Epoch:[ 112 17 ] loss: 0.4106980860233307 2022-05-29 17:57:57.102488
Epoch:[ 112 18 ] loss: 0.40738925337791443 2022-05-29 17:57:57.998968
Epoch:[ 112 19 ] loss: 0.40584316849708557 2022-05-29 17:57:58.813122
Training_Epoch:[ 112 ] Training_loss: 0.4071286365389824 2022-05-29 17:57:58.813994
learning rate:  3.435973836800003e-05
netparams have been saved once 112
val: 1 0.5366714596748352
val: 2 0.5389471054077148
val: 3 0.5223512649536133
val: 4 0.5316155552864075
val: 5 0.5373558402061462
val: 6 0.5380674600601196
val: 7 0.5406851172447205
val: 8 0.5284074544906616
val: 9 0.5339229702949524
val: 10 0.546176552772522
val: 11 0.5345069766044617
val: 12 0.541391909122467
val: 13 0.5318200588226318
val: 14 0.5490047335624695
val: 15 0.51811283826828
val: 16 0.5349587202072144
val: 17 0.5507932305335999
val: 18 0.5469818711280823
val: 19 0.5232638120651245
val: 20 0.5425233244895935
val_Epoch:[ 112 ] val_loss: 0.5363779127597809 2022-05-29 17:58:04.981290
start training 2022-05-29 17:58:05.094730
Epoch:[ 113 0 ] loss: 0.40721479058265686 2022-05-29 17:58:32.792179
Epoch:[ 113 1 ] loss: 0.4102703332901001 2022-05-29 17:58:33.607778
Epoch:[ 113 2 ] loss: 0.40849199891090393 2022-05-29 17:58:34.420222
Epoch:[ 113 3 ] loss: 0.40367478132247925 2022-05-29 17:58:35.234078
Epoch:[ 113 4 ] loss: 0.4072449207305908 2022-05-29 17:58:36.037300
Epoch:[ 113 5 ] loss: 0.4098144769668579 2022-05-29 17:58:36.843453
Epoch:[ 113 6 ] loss: 0.4073280394077301 2022-05-29 17:58:37.657581
Epoch:[ 113 7 ] loss: 0.40387266874313354 2022-05-29 17:58:38.477751
Epoch:[ 113 8 ] loss: 0.4045240879058838 2022-05-29 17:58:39.291194
Epoch:[ 113 9 ] loss: 0.4051680266857147 2022-05-29 17:58:40.100937
Epoch:[ 113 10 ] loss: 0.40373244881629944 2022-05-29 17:58:40.910416
Epoch:[ 113 11 ] loss: 0.40983888506889343 2022-05-29 17:58:41.720529
Epoch:[ 113 12 ] loss: 0.4032615125179291 2022-05-29 17:58:42.532516
Epoch:[ 113 13 ] loss: 0.4079166054725647 2022-05-29 17:58:43.346823
Epoch:[ 113 14 ] loss: 0.4129740595817566 2022-05-29 17:58:44.157623
Epoch:[ 113 15 ] loss: 0.40913012623786926 2022-05-29 17:58:44.970137
Epoch:[ 113 16 ] loss: 0.40582048892974854 2022-05-29 17:58:52.323424
Epoch:[ 113 17 ] loss: 0.40230026841163635 2022-05-29 17:58:53.931863
Epoch:[ 113 18 ] loss: 0.4077243506908417 2022-05-29 17:58:54.794986
Epoch:[ 113 19 ] loss: 0.4061509072780609 2022-05-29 17:58:55.610524
Training_Epoch:[ 113 ] Training_loss: 0.40682268887758255 2022-05-29 17:58:55.611348
learning rate:  3.435973836800003e-05
val: 1 0.5564919114112854
val: 2 0.5358004570007324
val: 3 0.525362491607666
val: 4 0.5459935069084167
val: 5 0.51060950756073
val: 6 0.5245094895362854
val: 7 0.5243279933929443
val: 8 0.5574682950973511
val: 9 0.5339400768280029
val: 10 0.5500484704971313
val: 11 0.5505335330963135
val: 12 0.5221412181854248
val: 13 0.5427480936050415
val: 14 0.5257822871208191
val: 15 0.5515122413635254
val: 16 0.5132813453674316
val: 17 0.5207171440124512
val: 18 0.5528382658958435
val: 19 0.5321279168128967
val: 20 0.5453436374664307
val_Epoch:[ 113 ] val_loss: 0.5360788941383362 2022-05-29 17:59:02.031355
start training 2022-05-29 17:59:02.150869
Epoch:[ 114 0 ] loss: 0.40646892786026 2022-05-29 17:59:33.760500
Epoch:[ 114 1 ] loss: 0.40581685304641724 2022-05-29 17:59:34.577318
Epoch:[ 114 2 ] loss: 0.40744492411613464 2022-05-29 17:59:35.390534
Epoch:[ 114 3 ] loss: 0.40608006715774536 2022-05-29 17:59:36.199561
Epoch:[ 114 4 ] loss: 0.40502920746803284 2022-05-29 17:59:37.016828
Epoch:[ 114 5 ] loss: 0.4104073941707611 2022-05-29 17:59:37.832806
Epoch:[ 114 6 ] loss: 0.4065307080745697 2022-05-29 17:59:38.644316
Epoch:[ 114 7 ] loss: 0.4058225452899933 2022-05-29 17:59:39.456677
Epoch:[ 114 8 ] loss: 0.407111257314682 2022-05-29 17:59:40.261507
Epoch:[ 114 9 ] loss: 0.40802180767059326 2022-05-29 17:59:41.067654
Epoch:[ 114 10 ] loss: 0.40666061639785767 2022-05-29 17:59:41.876334
Epoch:[ 114 11 ] loss: 0.4050168991088867 2022-05-29 17:59:42.685201
Epoch:[ 114 12 ] loss: 0.4077511429786682 2022-05-29 17:59:43.494767
Epoch:[ 114 13 ] loss: 0.4031733274459839 2022-05-29 17:59:44.304234
Epoch:[ 114 14 ] loss: 0.404325395822525 2022-05-29 17:59:45.116031
Epoch:[ 114 15 ] loss: 0.4119470715522766 2022-05-29 17:59:45.939185
Epoch:[ 114 16 ] loss: 0.4075111746788025 2022-05-29 17:59:56.263403
Epoch:[ 114 17 ] loss: 0.4071926772594452 2022-05-29 17:59:57.071577
Epoch:[ 114 18 ] loss: 0.4072963297367096 2022-05-29 17:59:58.006563
Epoch:[ 114 19 ] loss: 0.40679898858070374 2022-05-29 17:59:58.814344
Training_Epoch:[ 114 ] Training_loss: 0.40682036578655245 2022-05-29 17:59:58.815176
learning rate:  3.435973836800003e-05
netparams have been saved once 114
val: 1 0.5369160771369934
val: 2 0.5328693985939026
val: 3 0.5447544455528259
val: 4 0.5113163590431213
val: 5 0.5223414897918701
val: 6 0.5441673994064331
val: 7 0.5300860404968262
val: 8 0.5368690490722656
val: 9 0.5470697283744812
val: 10 0.5458886623382568
val: 11 0.5342463254928589
val: 12 0.5210733413696289
val: 13 0.5392845869064331
val: 14 0.521226167678833
val: 15 0.5410473942756653
val: 16 0.5504564046859741
val: 17 0.5348230600357056
val: 18 0.5447208285331726
val: 19 0.5396557450294495
val: 20 0.5302918553352356
val_Epoch:[ 114 ] val_loss: 0.5354552179574966 2022-05-29 18:00:04.599988
start training 2022-05-29 18:00:04.702016
Epoch:[ 115 0 ] loss: 0.4111848473548889 2022-05-29 18:00:31.600168
Epoch:[ 115 1 ] loss: 0.40704235434532166 2022-05-29 18:00:32.419256
Epoch:[ 115 2 ] loss: 0.40718594193458557 2022-05-29 18:00:33.232957
Epoch:[ 115 3 ] loss: 0.4086094796657562 2022-05-29 18:00:34.053957
Epoch:[ 115 4 ] loss: 0.40663281083106995 2022-05-29 18:00:34.871580
Epoch:[ 115 5 ] loss: 0.4100211560726166 2022-05-29 18:00:35.690990
Epoch:[ 115 6 ] loss: 0.40356874465942383 2022-05-29 18:00:36.500532
Epoch:[ 115 7 ] loss: 0.4035715162754059 2022-05-29 18:00:37.319470
Epoch:[ 115 8 ] loss: 0.40936917066574097 2022-05-29 18:00:38.139202
Epoch:[ 115 9 ] loss: 0.40481728315353394 2022-05-29 18:00:38.952759
Epoch:[ 115 10 ] loss: 0.4010108709335327 2022-05-29 18:00:39.767830
Epoch:[ 115 11 ] loss: 0.40862780809402466 2022-05-29 18:00:40.584831
Epoch:[ 115 12 ] loss: 0.40626275539398193 2022-05-29 18:00:41.395627
Epoch:[ 115 13 ] loss: 0.4054494798183441 2022-05-29 18:00:42.219782
Epoch:[ 115 14 ] loss: 0.40779003500938416 2022-05-29 18:00:43.039589
Epoch:[ 115 15 ] loss: 0.40850475430488586 2022-05-29 18:00:43.858975
Epoch:[ 115 16 ] loss: 0.4085477888584137 2022-05-29 18:00:53.184743
Epoch:[ 115 17 ] loss: 0.40378692746162415 2022-05-29 18:00:53.994181
Epoch:[ 115 18 ] loss: 0.40619468688964844 2022-05-29 18:00:54.877167
Epoch:[ 115 19 ] loss: 0.40943416953086853 2022-05-29 18:00:55.703638
Training_Epoch:[ 115 ] Training_loss: 0.4068806290626526 2022-05-29 18:00:55.704423
learning rate:  3.435973836800003e-05
val: 1 0.5306438207626343
val: 2 0.5424270033836365
val: 3 0.524673581123352
val: 4 0.527803361415863
val: 5 0.537839412689209
val: 6 0.5404937863349915
val: 7 0.5245451927185059
val: 8 0.5338017344474792
val: 9 0.5298048257827759
val: 10 0.5647664070129395
val: 11 0.5209166407585144
val: 12 0.5293424725532532
val: 13 0.5258592367172241
val: 14 0.5399566888809204
val: 15 0.530504047870636
val: 16 0.5429102182388306
val: 17 0.5456151962280273
val: 18 0.5168664455413818
val: 19 0.5458869934082031
val: 20 0.5501522421836853
val_Epoch:[ 115 ] val_loss: 0.5352404654026032 2022-05-29 18:01:01.309020
start training 2022-05-29 18:01:01.418067
Epoch:[ 116 0 ] loss: 0.4088461399078369 2022-05-29 18:01:26.695773
Epoch:[ 116 1 ] loss: 0.40184444189071655 2022-05-29 18:01:27.510189
Epoch:[ 116 2 ] loss: 0.40659719705581665 2022-05-29 18:01:28.321561
Epoch:[ 116 3 ] loss: 0.407947838306427 2022-05-29 18:01:29.133731
Epoch:[ 116 4 ] loss: 0.40839555859565735 2022-05-29 18:01:29.949195
Epoch:[ 116 5 ] loss: 0.40688633918762207 2022-05-29 18:01:30.772189
Epoch:[ 116 6 ] loss: 0.4062381088733673 2022-05-29 18:01:31.588070
Epoch:[ 116 7 ] loss: 0.410153865814209 2022-05-29 18:01:32.394389
Epoch:[ 116 8 ] loss: 0.4068414568901062 2022-05-29 18:01:33.206865
Epoch:[ 116 9 ] loss: 0.40608882904052734 2022-05-29 18:01:34.021557
Epoch:[ 116 10 ] loss: 0.40397077798843384 2022-05-29 18:01:34.835876
Epoch:[ 116 11 ] loss: 0.40468841791152954 2022-05-29 18:01:35.650109
Epoch:[ 116 12 ] loss: 0.40841954946517944 2022-05-29 18:01:36.462085
Epoch:[ 116 13 ] loss: 0.4062301814556122 2022-05-29 18:01:37.271607
Epoch:[ 116 14 ] loss: 0.40940746665000916 2022-05-29 18:01:38.075934
Epoch:[ 116 15 ] loss: 0.40771228075027466 2022-05-29 18:01:38.895581
Epoch:[ 116 16 ] loss: 0.4044651389122009 2022-05-29 18:01:47.251255
Epoch:[ 116 17 ] loss: 0.40598762035369873 2022-05-29 18:01:48.063281
Epoch:[ 116 18 ] loss: 0.4055604040622711 2022-05-29 18:01:48.954378
Epoch:[ 116 19 ] loss: 0.40643441677093506 2022-05-29 18:01:49.768514
Training_Epoch:[ 116 ] Training_loss: 0.40663580149412154 2022-05-29 18:01:49.769300
learning rate:  3.435973836800003e-05
netparams have been saved once 116
val: 1 0.5399121046066284
val: 2 0.5540316700935364
val: 3 0.5303373336791992
val: 4 0.5621858239173889
val: 5 0.5179382562637329
val: 6 0.5154016613960266
val: 7 0.5353367328643799
val: 8 0.5274215340614319
val: 9 0.5238922238349915
val: 10 0.5309275984764099
val: 11 0.545535683631897
val: 12 0.5536601543426514
val: 13 0.5431005954742432
val: 14 0.5470179915428162
val: 15 0.5451295375823975
val: 16 0.5218629240989685
val: 17 0.53551185131073
val: 18 0.5296447277069092
val: 19 0.5353847742080688
val: 20 0.5406306385993958
val_Epoch:[ 116 ] val_loss: 0.5367431908845901 2022-05-29 18:01:55.527964
start training 2022-05-29 18:01:55.632058
Epoch:[ 117 0 ] loss: 0.4085192382335663 2022-05-29 18:02:20.027820
Epoch:[ 117 1 ] loss: 0.40550506114959717 2022-05-29 18:02:21.367096
Epoch:[ 117 2 ] loss: 0.40769466757774353 2022-05-29 18:02:22.178850
Epoch:[ 117 3 ] loss: 0.40698006749153137 2022-05-29 18:02:22.994413
Epoch:[ 117 4 ] loss: 0.4080977141857147 2022-05-29 18:02:23.815458
Epoch:[ 117 5 ] loss: 0.40710556507110596 2022-05-29 18:02:24.627709
Epoch:[ 117 6 ] loss: 0.4057496190071106 2022-05-29 18:02:25.449473
Epoch:[ 117 7 ] loss: 0.4082740545272827 2022-05-29 18:02:26.261458
Epoch:[ 117 8 ] loss: 0.40672969818115234 2022-05-29 18:02:27.072237
Epoch:[ 117 9 ] loss: 0.4051036238670349 2022-05-29 18:02:27.894595
Epoch:[ 117 10 ] loss: 0.40519091486930847 2022-05-29 18:02:28.708340
Epoch:[ 117 11 ] loss: 0.4037015736103058 2022-05-29 18:02:29.521084
Epoch:[ 117 12 ] loss: 0.40842700004577637 2022-05-29 18:02:30.334205
Epoch:[ 117 13 ] loss: 0.4085999131202698 2022-05-29 18:02:31.143540
Epoch:[ 117 14 ] loss: 0.40720903873443604 2022-05-29 18:02:31.952526
Epoch:[ 117 15 ] loss: 0.4073827564716339 2022-05-29 18:02:32.762412
Epoch:[ 117 16 ] loss: 0.40073052048683167 2022-05-29 18:02:39.742631
Epoch:[ 117 17 ] loss: 0.40240588784217834 2022-05-29 18:02:40.561490
Epoch:[ 117 18 ] loss: 0.4112735986709595 2022-05-29 18:02:43.879368
Epoch:[ 117 19 ] loss: 0.40997084975242615 2022-05-29 18:02:44.698370
Training_Epoch:[ 117 ] Training_loss: 0.4067325681447983 2022-05-29 18:02:44.699169
learning rate:  3.435973836800003e-05
val: 1 0.536106526851654
val: 2 0.5297906994819641
val: 3 0.5488737225532532
val: 4 0.5271031856536865
val: 5 0.5456029176712036
val: 6 0.5203117728233337
val: 7 0.5517528653144836
val: 8 0.5411871671676636
val: 9 0.535275399684906
val: 10 0.5418003797531128
val: 11 0.5441514849662781
val: 12 0.5429724454879761
val: 13 0.5330127477645874
val: 14 0.5497680902481079
val: 15 0.5166370868682861
val: 16 0.5479044914245605
val: 17 0.528277575969696
val: 18 0.5226655602455139
val: 19 0.5494363903999329
val: 20 0.5322386622428894
val_Epoch:[ 117 ] val_loss: 0.5372434586286545 2022-05-29 18:02:50.331447
start training 2022-05-29 18:02:50.440987
Epoch:[ 118 0 ] loss: 0.4081574082374573 2022-05-29 18:03:16.425773
Epoch:[ 118 1 ] loss: 0.4093889892101288 2022-05-29 18:03:17.233185
Epoch:[ 118 2 ] loss: 0.40539824962615967 2022-05-29 18:03:18.037700
Epoch:[ 118 3 ] loss: 0.40548646450042725 2022-05-29 18:03:18.847022
Epoch:[ 118 4 ] loss: 0.40740713477134705 2022-05-29 18:03:19.665041
Epoch:[ 118 5 ] loss: 0.40081650018692017 2022-05-29 18:03:20.474717
Epoch:[ 118 6 ] loss: 0.40894976258277893 2022-05-29 18:03:21.292488
Epoch:[ 118 7 ] loss: 0.40675315260887146 2022-05-29 18:03:22.099389
Epoch:[ 118 8 ] loss: 0.4037204682826996 2022-05-29 18:03:22.907172
Epoch:[ 118 9 ] loss: 0.40380364656448364 2022-05-29 18:03:23.712753
Epoch:[ 118 10 ] loss: 0.4046842157840729 2022-05-29 18:03:24.531308
Epoch:[ 118 11 ] loss: 0.40464070439338684 2022-05-29 18:03:25.343014
Epoch:[ 118 12 ] loss: 0.41173458099365234 2022-05-29 18:03:26.151647
Epoch:[ 118 13 ] loss: 0.4099048972129822 2022-05-29 18:03:26.961690
Epoch:[ 118 14 ] loss: 0.4106074869632721 2022-05-29 18:03:27.769848
Epoch:[ 118 15 ] loss: 0.40768393874168396 2022-05-29 18:03:28.576865
Epoch:[ 118 16 ] loss: 0.4080803394317627 2022-05-29 18:03:39.827688
Epoch:[ 118 17 ] loss: 0.40559181571006775 2022-05-29 18:03:40.649325
Epoch:[ 118 18 ] loss: 0.40631890296936035 2022-05-29 18:03:41.515157
Epoch:[ 118 19 ] loss: 0.4057489037513733 2022-05-29 18:03:42.323017
Training_Epoch:[ 118 ] Training_loss: 0.40674387812614443 2022-05-29 18:03:42.323811
learning rate:  3.435973836800003e-05
netparams have been saved once 118
val: 1 0.5336993336677551
val: 2 0.5330655574798584
val: 3 0.5159341096878052
val: 4 0.5169674158096313
val: 5 0.5224112272262573
val: 6 0.5369794964790344
val: 7 0.5517154932022095
val: 8 0.5378473997116089
val: 9 0.5294436812400818
val: 10 0.5549538731575012
val: 11 0.5430534482002258
val: 12 0.5351152420043945
val: 13 0.5529228448867798
val: 14 0.5320080518722534
val: 15 0.5244554281234741
val: 16 0.5447707772254944
val: 17 0.5424527525901794
val: 18 0.534063458442688
val: 19 0.5386026501655579
val: 20 0.5332372784614563
val_Epoch:[ 118 ] val_loss: 0.5356849759817124 2022-05-29 18:03:47.910804
start training 2022-05-29 18:03:48.009722
Epoch:[ 119 0 ] loss: 0.4071478545665741 2022-05-29 18:04:12.260314
Epoch:[ 119 1 ] loss: 0.407004177570343 2022-05-29 18:04:13.132328
Epoch:[ 119 2 ] loss: 0.4070453643798828 2022-05-29 18:04:13.971105
Epoch:[ 119 3 ] loss: 0.4060349762439728 2022-05-29 18:04:14.782421
Epoch:[ 119 4 ] loss: 0.41003987193107605 2022-05-29 18:04:15.595866
Epoch:[ 119 5 ] loss: 0.40653178095817566 2022-05-29 18:04:16.406093
Epoch:[ 119 6 ] loss: 0.4034872055053711 2022-05-29 18:04:17.211841
Epoch:[ 119 7 ] loss: 0.4044429063796997 2022-05-29 18:04:18.017631
Epoch:[ 119 8 ] loss: 0.4077523946762085 2022-05-29 18:04:18.834941
Epoch:[ 119 9 ] loss: 0.40507739782333374 2022-05-29 18:04:19.648053
Epoch:[ 119 10 ] loss: 0.40484192967414856 2022-05-29 18:04:20.456069
Epoch:[ 119 11 ] loss: 0.4066423177719116 2022-05-29 18:04:21.261678
Epoch:[ 119 12 ] loss: 0.40345659852027893 2022-05-29 18:04:22.070501
Epoch:[ 119 13 ] loss: 0.40370988845825195 2022-05-29 18:04:22.881508
Epoch:[ 119 14 ] loss: 0.4074506163597107 2022-05-29 18:04:23.697074
Epoch:[ 119 15 ] loss: 0.4074840843677521 2022-05-29 18:04:24.512545
Epoch:[ 119 16 ] loss: 0.408712774515152 2022-05-29 18:04:32.937598
Epoch:[ 119 17 ] loss: 0.40969324111938477 2022-05-29 18:04:33.741652
Epoch:[ 119 18 ] loss: 0.4049599766731262 2022-05-29 18:04:35.485579
Epoch:[ 119 19 ] loss: 0.4106900095939636 2022-05-29 18:04:36.308249
Training_Epoch:[ 119 ] Training_loss: 0.4066102683544159 2022-05-29 18:04:36.309121
learning rate:  3.435973836800003e-05
val: 1 0.5400657653808594
val: 2 0.5284779667854309
val: 3 0.5264869332313538
val: 4 0.5454840064048767
val: 5 0.5344608426094055
val: 6 0.5490826368331909
val: 7 0.5331328511238098
val: 8 0.5210402011871338
val: 9 0.5338637232780457
val: 10 0.5449651479721069
val: 11 0.5211126208305359
val: 12 0.5520623326301575
val: 13 0.5485570430755615
val: 14 0.5385994911193848
val: 15 0.539950430393219
val: 16 0.5259588956832886
val: 17 0.5163499116897583
val: 18 0.5319222807884216
val: 19 0.5324442386627197
val: 20 0.5421949625015259
val_Epoch:[ 119 ] val_loss: 0.5353106141090394 2022-05-29 18:04:42.074913
start training 2022-05-29 18:04:42.190818
Epoch:[ 120 0 ] loss: 0.4053003191947937 2022-05-29 18:05:08.290433
Epoch:[ 120 1 ] loss: 0.4042671322822571 2022-05-29 18:05:09.098532
Epoch:[ 120 2 ] loss: 0.40181130170822144 2022-05-29 18:05:09.908973
Epoch:[ 120 3 ] loss: 0.40737324953079224 2022-05-29 18:05:10.724979
Epoch:[ 120 4 ] loss: 0.40722811222076416 2022-05-29 18:05:11.533681
Epoch:[ 120 5 ] loss: 0.4090639650821686 2022-05-29 18:05:12.347407
Epoch:[ 120 6 ] loss: 0.4050596356391907 2022-05-29 18:05:13.159423
Epoch:[ 120 7 ] loss: 0.4062969386577606 2022-05-29 18:05:13.975358
Epoch:[ 120 8 ] loss: 0.4077111482620239 2022-05-29 18:05:14.799533
Epoch:[ 120 9 ] loss: 0.4056115448474884 2022-05-29 18:05:15.616368
Epoch:[ 120 10 ] loss: 0.4079577922821045 2022-05-29 18:05:16.431209
Epoch:[ 120 11 ] loss: 0.4070722162723541 2022-05-29 18:05:17.247866
Epoch:[ 120 12 ] loss: 0.4085434079170227 2022-05-29 18:05:18.060103
Epoch:[ 120 13 ] loss: 0.40703651309013367 2022-05-29 18:05:18.871565
Epoch:[ 120 14 ] loss: 0.4071800410747528 2022-05-29 18:05:19.688334
Epoch:[ 120 15 ] loss: 0.40861809253692627 2022-05-29 18:05:20.502199
Epoch:[ 120 16 ] loss: 0.40516939759254456 2022-05-29 18:05:27.968328
Epoch:[ 120 17 ] loss: 0.40592387318611145 2022-05-29 18:05:28.773602
Epoch:[ 120 18 ] loss: 0.403878778219223 2022-05-29 18:05:29.671945
Epoch:[ 120 19 ] loss: 0.40805384516716003 2022-05-29 18:05:30.491390
Training_Epoch:[ 120 ] Training_loss: 0.4064578652381897 2022-05-29 18:05:30.492185
learning rate:  3.435973836800003e-05
netparams have been saved once 120
val: 1 0.5639437437057495
val: 2 0.5337092280387878
val: 3 0.5348416566848755
val: 4 0.5522052049636841
val: 5 0.5355275273323059
val: 6 0.5178298950195312
val: 7 0.5255371332168579
val: 8 0.5423751473426819
val: 9 0.5160820484161377
val: 10 0.5456075668334961
val: 11 0.541200578212738
val: 12 0.5496946573257446
val: 13 0.5343772768974304
val: 14 0.5250816345214844
val: 15 0.5229443907737732
val: 16 0.5286663770675659
val: 17 0.5615449547767639
val: 18 0.5305380821228027
val: 19 0.5304258465766907
val: 20 0.5422356128692627
val_Epoch:[ 120 ] val_loss: 0.5367184281349182 2022-05-29 18:05:35.924091
start training 2022-05-29 18:05:36.027827
Epoch:[ 121 0 ] loss: 0.40702149271965027 2022-05-29 18:06:00.496846
Epoch:[ 121 1 ] loss: 0.40542367100715637 2022-05-29 18:06:02.121734
Epoch:[ 121 2 ] loss: 0.40231990814208984 2022-05-29 18:06:02.933656
Epoch:[ 121 3 ] loss: 0.40599149465560913 2022-05-29 18:06:03.754171
Epoch:[ 121 4 ] loss: 0.40684404969215393 2022-05-29 18:06:04.565587
Epoch:[ 121 5 ] loss: 0.41185423731803894 2022-05-29 18:06:05.376739
Epoch:[ 121 6 ] loss: 0.40806469321250916 2022-05-29 18:06:06.198681
Epoch:[ 121 7 ] loss: 0.4023539125919342 2022-05-29 18:06:07.013721
Epoch:[ 121 8 ] loss: 0.40765732526779175 2022-05-29 18:06:07.827212
Epoch:[ 121 9 ] loss: 0.4061445891857147 2022-05-29 18:06:08.638686
Epoch:[ 121 10 ] loss: 0.41009849309921265 2022-05-29 18:06:09.447457
Epoch:[ 121 11 ] loss: 0.404073029756546 2022-05-29 18:06:10.268401
Epoch:[ 121 12 ] loss: 0.4050271809101105 2022-05-29 18:06:11.078171
Epoch:[ 121 13 ] loss: 0.40671810507774353 2022-05-29 18:06:11.892010
Epoch:[ 121 14 ] loss: 0.4077596068382263 2022-05-29 18:06:12.702294
Epoch:[ 121 15 ] loss: 0.40236690640449524 2022-05-29 18:06:13.516518
Epoch:[ 121 16 ] loss: 0.40916910767555237 2022-05-29 18:06:20.387363
Epoch:[ 121 17 ] loss: 0.4044603407382965 2022-05-29 18:06:24.740187
Epoch:[ 121 18 ] loss: 0.4052998423576355 2022-05-29 18:06:25.615662
Epoch:[ 121 19 ] loss: 0.4035499691963196 2022-05-29 18:06:26.434588
Training_Epoch:[ 121 ] Training_loss: 0.4061098977923393 2022-05-29 18:06:26.435422
learning rate:  2.7487790694400027e-05
val: 1 0.5446130633354187
val: 2 0.532382071018219
val: 3 0.5310119390487671
val: 4 0.5396081209182739
val: 5 0.5385401248931885
val: 6 0.5401405096054077
val: 7 0.5446441173553467
val: 8 0.534024715423584
val: 9 0.533428430557251
val: 10 0.5442913770675659
val: 11 0.5382696986198425
val: 12 0.5439677834510803
val: 13 0.531075119972229
val: 14 0.5386670827865601
val: 15 0.5469189882278442
val: 16 0.5032171607017517
val: 17 0.5313084125518799
val: 18 0.5404698848724365
val: 19 0.541716456413269
val: 20 0.5328624844551086
val_Epoch:[ 121 ] val_loss: 0.5365578770637512 2022-05-29 18:06:31.851979
start training 2022-05-29 18:06:31.955909
Epoch:[ 122 0 ] loss: 0.4039909541606903 2022-05-29 18:06:58.083127
Epoch:[ 122 1 ] loss: 0.40304797887802124 2022-05-29 18:06:58.893997
Epoch:[ 122 2 ] loss: 0.4081311821937561 2022-05-29 18:06:59.703264
Epoch:[ 122 3 ] loss: 0.40287700295448303 2022-05-29 18:07:00.523227
Epoch:[ 122 4 ] loss: 0.4061150550842285 2022-05-29 18:07:01.331330
Epoch:[ 122 5 ] loss: 0.40894225239753723 2022-05-29 18:07:02.149800
Epoch:[ 122 6 ] loss: 0.4004124701023102 2022-05-29 18:07:02.955917
Epoch:[ 122 7 ] loss: 0.403598427772522 2022-05-29 18:07:03.768980
Epoch:[ 122 8 ] loss: 0.40664142370224 2022-05-29 18:07:04.578464
Epoch:[ 122 9 ] loss: 0.40336331725120544 2022-05-29 18:07:05.388406
Epoch:[ 122 10 ] loss: 0.4118826687335968 2022-05-29 18:07:06.197179
Epoch:[ 122 11 ] loss: 0.40849384665489197 2022-05-29 18:07:07.015322
Epoch:[ 122 12 ] loss: 0.40424397587776184 2022-05-29 18:07:07.824528
Epoch:[ 122 13 ] loss: 0.40626201033592224 2022-05-29 18:07:08.630835
Epoch:[ 122 14 ] loss: 0.40831729769706726 2022-05-29 18:07:09.439963
Epoch:[ 122 15 ] loss: 0.40659770369529724 2022-05-29 18:07:10.249370
Epoch:[ 122 16 ] loss: 0.4071478545665741 2022-05-29 18:07:17.148028
Epoch:[ 122 17 ] loss: 0.40846601128578186 2022-05-29 18:07:17.954116
Epoch:[ 122 18 ] loss: 0.4068785607814789 2022-05-29 18:07:18.828202
Epoch:[ 122 19 ] loss: 0.40635353326797485 2022-05-29 18:07:19.647433
Training_Epoch:[ 122 ] Training_loss: 0.40608817636966704 2022-05-29 18:07:19.648168
learning rate:  2.7487790694400027e-05
netparams have been saved once 122
val: 1 0.5549375414848328
val: 2 0.5456740856170654
val: 3 0.5513753890991211
val: 4 0.5292964577674866
val: 5 0.5212370753288269
val: 6 0.543176531791687
val: 7 0.5264832377433777
val: 8 0.516909122467041
val: 9 0.5520179867744446
val: 10 0.5314921140670776
val: 11 0.5336629152297974
val: 12 0.5149566531181335
val: 13 0.5340570211410522
val: 14 0.5651108026504517
val: 15 0.5355367064476013
val: 16 0.5182679891586304
val: 17 0.5617731809616089
val: 18 0.540197491645813
val: 19 0.5409265756607056
val: 20 0.5175893902778625
val_Epoch:[ 122 ] val_loss: 0.5367339134216309 2022-05-29 18:07:25.295346
start training 2022-05-29 18:07:25.395077
Epoch:[ 123 0 ] loss: 0.4072764217853546 2022-05-29 18:07:49.989927
Epoch:[ 123 1 ] loss: 0.4072565734386444 2022-05-29 18:07:50.803806
Epoch:[ 123 2 ] loss: 0.4060620963573456 2022-05-29 18:07:51.615630
Epoch:[ 123 3 ] loss: 0.4086689054965973 2022-05-29 18:07:52.427181
Epoch:[ 123 4 ] loss: 0.4054872393608093 2022-05-29 18:07:53.247903
Epoch:[ 123 5 ] loss: 0.40461471676826477 2022-05-29 18:07:54.059272
Epoch:[ 123 6 ] loss: 0.40468674898147583 2022-05-29 18:07:54.868404
Epoch:[ 123 7 ] loss: 0.4086538851261139 2022-05-29 18:07:55.677504
Epoch:[ 123 8 ] loss: 0.4065150022506714 2022-05-29 18:07:56.494320
Epoch:[ 123 9 ] loss: 0.4048694968223572 2022-05-29 18:07:57.317296
Epoch:[ 123 10 ] loss: 0.40559375286102295 2022-05-29 18:07:58.129426
Epoch:[ 123 11 ] loss: 0.40236425399780273 2022-05-29 18:07:58.940784
Epoch:[ 123 12 ] loss: 0.40569740533828735 2022-05-29 18:07:59.751663
Epoch:[ 123 13 ] loss: 0.40660229325294495 2022-05-29 18:08:00.573416
Epoch:[ 123 14 ] loss: 0.406803160905838 2022-05-29 18:08:01.381764
Epoch:[ 123 15 ] loss: 0.4057249426841736 2022-05-29 18:08:02.201181
Epoch:[ 123 16 ] loss: 0.4023239314556122 2022-05-29 18:08:09.341699
Epoch:[ 123 17 ] loss: 0.40933486819267273 2022-05-29 18:08:10.162434
Epoch:[ 123 18 ] loss: 0.40633702278137207 2022-05-29 18:08:11.027237
Epoch:[ 123 19 ] loss: 0.4089995324611664 2022-05-29 18:08:11.835255
Training_Epoch:[ 123 ] Training_loss: 0.40619361251592634 2022-05-29 18:08:11.836069
learning rate:  2.7487790694400027e-05
val: 1 0.5473429560661316
val: 2 0.5086444020271301
val: 3 0.5363976955413818
val: 4 0.5428227782249451
val: 5 0.536342442035675
val: 6 0.5382716059684753
val: 7 0.5519766807556152
val: 8 0.5201103687286377
val: 9 0.5547433495521545
val: 10 0.524060070514679
val: 11 0.5371943116188049
val: 12 0.5375074148178101
val: 13 0.5153530836105347
val: 14 0.5469852089881897
val: 15 0.5417972803115845
val: 16 0.5537305474281311
val: 17 0.5290728211402893
val: 18 0.5437455177307129
val: 19 0.5212029814720154
val: 20 0.5363597273826599
val_Epoch:[ 123 ] val_loss: 0.5361830621957779 2022-05-29 18:08:17.226216
start training 2022-05-29 18:08:17.346465
Epoch:[ 124 0 ] loss: 0.4060307443141937 2022-05-29 18:08:40.233632
Epoch:[ 124 1 ] loss: 0.40566396713256836 2022-05-29 18:08:41.051040
Epoch:[ 124 2 ] loss: 0.40902426838874817 2022-05-29 18:08:41.883594
Epoch:[ 124 3 ] loss: 0.40262266993522644 2022-05-29 18:08:42.659916
Epoch:[ 124 4 ] loss: 0.4028695225715637 2022-05-29 18:08:43.433553
Epoch:[ 124 5 ] loss: 0.4076169729232788 2022-05-29 18:08:44.211457
Epoch:[ 124 6 ] loss: 0.406913161277771 2022-05-29 18:08:44.998113
Epoch:[ 124 7 ] loss: 0.4022320806980133 2022-05-29 18:08:45.788374
Epoch:[ 124 8 ] loss: 0.40320897102355957 2022-05-29 18:08:46.562849
Epoch:[ 124 9 ] loss: 0.4082479476928711 2022-05-29 18:08:47.340395
Epoch:[ 124 10 ] loss: 0.40579038858413696 2022-05-29 18:08:48.120095
Epoch:[ 124 11 ] loss: 0.4050867557525635 2022-05-29 18:08:48.894568
Epoch:[ 124 12 ] loss: 0.4086323380470276 2022-05-29 18:08:49.685555
Epoch:[ 124 13 ] loss: 0.40804624557495117 2022-05-29 18:08:50.458623
Epoch:[ 124 14 ] loss: 0.40518972277641296 2022-05-29 18:08:51.236635
Epoch:[ 124 15 ] loss: 0.40553733706474304 2022-05-29 18:08:52.010359
Epoch:[ 124 16 ] loss: 0.40997955203056335 2022-05-29 18:08:59.398658
Epoch:[ 124 17 ] loss: 0.4041527509689331 2022-05-29 18:09:00.174957
Epoch:[ 124 18 ] loss: 0.4096520245075226 2022-05-29 18:09:00.966779
Epoch:[ 124 19 ] loss: 0.407196044921875 2022-05-29 18:09:01.754846
Training_Epoch:[ 124 ] Training_loss: 0.40618467330932617 2022-05-29 18:09:01.755565
learning rate:  2.7487790694400027e-05
netparams have been saved once 124
val: 1 0.5300098657608032
val: 2 0.5381371974945068
val: 3 0.5264750719070435
val: 4 0.5626556873321533
val: 5 0.5273847579956055
val: 6 0.5524562001228333
val: 7 0.5133408308029175
val: 8 0.5379301309585571
val: 9 0.5220494866371155
val: 10 0.536435067653656
val: 11 0.5321395993232727
val: 12 0.5486018061637878
val: 13 0.5215660333633423
val: 14 0.5338229537010193
val: 15 0.5453301072120667
val: 16 0.5508171319961548
val: 17 0.5316420793533325
val: 18 0.5496751070022583
val: 19 0.5338554382324219
val: 20 0.5329590439796448
val_Epoch:[ 124 ] val_loss: 0.5363641798496246 2022-05-29 18:09:07.035630
start training 2022-05-29 18:09:07.133756
Epoch:[ 125 0 ] loss: 0.404203861951828 2022-05-29 18:09:29.178037
Epoch:[ 125 1 ] loss: 0.40659981966018677 2022-05-29 18:09:31.107180
Epoch:[ 125 2 ] loss: 0.4077722132205963 2022-05-29 18:09:31.882068
Epoch:[ 125 3 ] loss: 0.40719810128211975 2022-05-29 18:09:32.660633
Epoch:[ 125 4 ] loss: 0.40556132793426514 2022-05-29 18:09:33.437937
Epoch:[ 125 5 ] loss: 0.40836480259895325 2022-05-29 18:09:34.214043
Epoch:[ 125 6 ] loss: 0.4058360159397125 2022-05-29 18:09:35.004007
Epoch:[ 125 7 ] loss: 0.40581950545310974 2022-05-29 18:09:35.777834
Epoch:[ 125 8 ] loss: 0.4068455696105957 2022-05-29 18:09:36.552603
Epoch:[ 125 9 ] loss: 0.40494605898857117 2022-05-29 18:09:37.327455
Epoch:[ 125 10 ] loss: 0.40311530232429504 2022-05-29 18:09:38.117094
Epoch:[ 125 11 ] loss: 0.4060966670513153 2022-05-29 18:09:38.907679
Epoch:[ 125 12 ] loss: 0.4060702919960022 2022-05-29 18:09:39.685130
Epoch:[ 125 13 ] loss: 0.4076412618160248 2022-05-29 18:09:40.462834
Epoch:[ 125 14 ] loss: 0.4085615575313568 2022-05-29 18:09:41.236983
Epoch:[ 125 15 ] loss: 0.4031479060649872 2022-05-29 18:09:42.013898
Epoch:[ 125 16 ] loss: 0.40750205516815186 2022-05-29 18:09:49.524086
Epoch:[ 125 17 ] loss: 0.40595895051956177 2022-05-29 18:09:50.312715
Epoch:[ 125 18 ] loss: 0.40505051612854004 2022-05-29 18:09:51.110408
Epoch:[ 125 19 ] loss: 0.4077206254005432 2022-05-29 18:09:51.885208
Training_Epoch:[ 125 ] Training_loss: 0.4062006205320358 2022-05-29 18:09:51.885924
learning rate:  2.7487790694400027e-05
val: 1 0.5268429517745972
val: 2 0.5255111455917358
val: 3 0.523552656173706
val: 4 0.5426570177078247
val: 5 0.5246056914329529
val: 6 0.5635338425636292
val: 7 0.533747673034668
val: 8 0.5324097275733948
val: 9 0.5347694158554077
val: 10 0.5296189188957214
val: 11 0.5401391386985779
val: 12 0.5446504950523376
val: 13 0.5355607271194458
val: 14 0.5405584573745728
val: 15 0.5435879230499268
val: 16 0.5416068434715271
val: 17 0.5193167328834534
val: 18 0.5126842260360718
val: 19 0.5332909226417542
val: 20 0.5594920516014099
val_Epoch:[ 125 ] val_loss: 0.5354068279266357 2022-05-29 18:09:57.054904
start training 2022-05-29 18:09:57.153949
Epoch:[ 126 0 ] loss: 0.4035177528858185 2022-05-29 18:10:20.367503
Epoch:[ 126 1 ] loss: 0.4063411355018616 2022-05-29 18:10:21.142572
Epoch:[ 126 2 ] loss: 0.4048006534576416 2022-05-29 18:10:21.916033
Epoch:[ 126 3 ] loss: 0.40311798453330994 2022-05-29 18:10:22.689302
Epoch:[ 126 4 ] loss: 0.40398603677749634 2022-05-29 18:10:23.464947
Epoch:[ 126 5 ] loss: 0.4067777693271637 2022-05-29 18:10:24.240682
Epoch:[ 126 6 ] loss: 0.40518075227737427 2022-05-29 18:10:25.029715
Epoch:[ 126 7 ] loss: 0.41314393281936646 2022-05-29 18:10:25.806162
Epoch:[ 126 8 ] loss: 0.4062694311141968 2022-05-29 18:10:26.580361
Epoch:[ 126 9 ] loss: 0.41113829612731934 2022-05-29 18:10:27.354175
Epoch:[ 126 10 ] loss: 0.4039686620235443 2022-05-29 18:10:28.129819
Epoch:[ 126 11 ] loss: 0.4082958400249481 2022-05-29 18:10:28.904402
Epoch:[ 126 12 ] loss: 0.4030236005783081 2022-05-29 18:10:29.691083
Epoch:[ 126 13 ] loss: 0.4060404300689697 2022-05-29 18:10:30.480998
Epoch:[ 126 14 ] loss: 0.40424877405166626 2022-05-29 18:10:31.258360
Epoch:[ 126 15 ] loss: 0.4056282937526703 2022-05-29 18:10:32.033986
Epoch:[ 126 16 ] loss: 0.40596893429756165 2022-05-29 18:10:39.234676
Epoch:[ 126 17 ] loss: 0.40655964612960815 2022-05-29 18:10:40.010103
Epoch:[ 126 18 ] loss: 0.40918540954589844 2022-05-29 18:10:40.802761
Epoch:[ 126 19 ] loss: 0.40434297919273376 2022-05-29 18:10:41.591698
Training_Epoch:[ 126 ] Training_loss: 0.4060768157243729 2022-05-29 18:10:41.592410
learning rate:  2.7487790694400027e-05
netparams have been saved once 126
val: 1 0.5290760397911072
val: 2 0.5432446002960205
val: 3 0.5320398211479187
val: 4 0.5435329079627991
val: 5 0.5314393043518066
val: 6 0.5212410688400269
val: 7 0.5075579285621643
val: 8 0.5459551215171814
val: 9 0.5206720232963562
val: 10 0.5484265089035034
val: 11 0.5769150853157043
val: 12 0.5430318713188171
val: 13 0.5607982873916626
val: 14 0.5319125652313232
val: 15 0.542809009552002
val: 16 0.530009388923645
val: 17 0.5531412959098816
val: 18 0.5264769196510315
val: 19 0.5365410447120667
val: 20 0.5321823358535767
val_Epoch:[ 126 ] val_loss: 0.5378501564264297 2022-05-29 18:10:46.866488
start training 2022-05-29 18:10:46.969416
Epoch:[ 127 0 ] loss: 0.40511560440063477 2022-05-29 18:11:10.729136
Epoch:[ 127 1 ] loss: 0.40642401576042175 2022-05-29 18:11:11.505050
Epoch:[ 127 2 ] loss: 0.4049302041530609 2022-05-29 18:11:12.279734
Epoch:[ 127 3 ] loss: 0.40798792243003845 2022-05-29 18:11:13.053708
Epoch:[ 127 4 ] loss: 0.4039185643196106 2022-05-29 18:11:13.830280
Epoch:[ 127 5 ] loss: 0.40407460927963257 2022-05-29 18:11:14.607192
Epoch:[ 127 6 ] loss: 0.40492990612983704 2022-05-29 18:11:15.385960
Epoch:[ 127 7 ] loss: 0.40697136521339417 2022-05-29 18:11:16.160779
Epoch:[ 127 8 ] loss: 0.4098089933395386 2022-05-29 18:11:16.949000
Epoch:[ 127 9 ] loss: 0.4079345464706421 2022-05-29 18:11:17.736756
Epoch:[ 127 10 ] loss: 0.4063095450401306 2022-05-29 18:11:18.511554
Epoch:[ 127 11 ] loss: 0.4089854061603546 2022-05-29 18:11:19.287102
Epoch:[ 127 12 ] loss: 0.40228071808815 2022-05-29 18:11:20.065808
Epoch:[ 127 13 ] loss: 0.40356796979904175 2022-05-29 18:11:20.845906
Epoch:[ 127 14 ] loss: 0.4037364423274994 2022-05-29 18:11:21.635278
Epoch:[ 127 15 ] loss: 0.4035966098308563 2022-05-29 18:11:22.412965
Epoch:[ 127 16 ] loss: 0.4067220985889435 2022-05-29 18:11:29.246618
Epoch:[ 127 17 ] loss: 0.4094752371311188 2022-05-29 18:11:30.033559
Epoch:[ 127 18 ] loss: 0.40256404876708984 2022-05-29 18:11:30.823744
Epoch:[ 127 19 ] loss: 0.4070805013179779 2022-05-29 18:11:31.600869
Training_Epoch:[ 127 ] Training_loss: 0.40582071542739867 2022-05-29 18:11:31.601577
learning rate:  2.7487790694400027e-05
val: 1 0.5439823865890503
val: 2 0.5209693312644958
val: 3 0.5607293844223022
val: 4 0.509167492389679
val: 5 0.5366013646125793
val: 6 0.566820502281189
val: 7 0.5415706634521484
val: 8 0.5453610420227051
val: 9 0.5328295826911926
val: 10 0.5348166823387146
val: 11 0.5149454474449158
val: 12 0.5352797508239746
val: 13 0.5379143357276917
val: 14 0.5493844747543335
val: 15 0.5419989824295044
val: 16 0.5262502431869507
val: 17 0.532150387763977
val: 18 0.5375949144363403
val: 19 0.553642988204956
val: 20 0.5258625149726868
val_Epoch:[ 127 ] val_loss: 0.5373936235904694 2022-05-29 18:11:36.822188
start training 2022-05-29 18:11:36.930181
Epoch:[ 128 0 ] loss: 0.4081270098686218 2022-05-29 18:12:00.931367
Epoch:[ 128 1 ] loss: 0.4065093994140625 2022-05-29 18:12:01.708402
Epoch:[ 128 2 ] loss: 0.40555381774902344 2022-05-29 18:12:02.483785
Epoch:[ 128 3 ] loss: 0.40817785263061523 2022-05-29 18:12:03.259185
Epoch:[ 128 4 ] loss: 0.40134376287460327 2022-05-29 18:12:04.036904
Epoch:[ 128 5 ] loss: 0.4025287926197052 2022-05-29 18:12:04.810691
Epoch:[ 128 6 ] loss: 0.4067422151565552 2022-05-29 18:12:05.587247
Epoch:[ 128 7 ] loss: 0.4054448902606964 2022-05-29 18:12:06.377636
Epoch:[ 128 8 ] loss: 0.40998411178588867 2022-05-29 18:12:07.154491
Epoch:[ 128 9 ] loss: 0.4034554064273834 2022-05-29 18:12:07.932321
Epoch:[ 128 10 ] loss: 0.4061124324798584 2022-05-29 18:12:08.706808
Epoch:[ 128 11 ] loss: 0.4031665325164795 2022-05-29 18:12:09.483491
Epoch:[ 128 12 ] loss: 0.40780970454216003 2022-05-29 18:12:10.269377
Epoch:[ 128 13 ] loss: 0.4071310758590698 2022-05-29 18:12:11.047293
Epoch:[ 128 14 ] loss: 0.4037400186061859 2022-05-29 18:12:11.824835
Epoch:[ 128 15 ] loss: 0.40920594334602356 2022-05-29 18:12:12.612525
Epoch:[ 128 16 ] loss: 0.4018358290195465 2022-05-29 18:12:19.356806
Epoch:[ 128 17 ] loss: 0.410432368516922 2022-05-29 18:12:20.129631
Epoch:[ 128 18 ] loss: 0.40633687376976013 2022-05-29 18:12:20.919578
Epoch:[ 128 19 ] loss: 0.4054063856601715 2022-05-29 18:12:21.692804
Training_Epoch:[ 128 ] Training_loss: 0.4059522211551666 2022-05-29 18:12:21.693534
learning rate:  2.7487790694400027e-05
netparams have been saved once 128
val: 1 0.5310541987419128
val: 2 0.5340377688407898
val: 3 0.513546347618103
val: 4 0.5353220105171204
val: 5 0.528932511806488
val: 6 0.5355507135391235
val: 7 0.5595472455024719
val: 8 0.5258350968360901
val: 9 0.5343161821365356
val: 10 0.5292609333992004
val: 11 0.5363850593566895
val: 12 0.5289123058319092
val: 13 0.5359002947807312
val: 14 0.5441222190856934
val: 15 0.5484283566474915
val: 16 0.5244380831718445
val: 17 0.5382763743400574
val: 18 0.5434386134147644
val: 19 0.5467380285263062
val: 20 0.5507287979125977
val_Epoch:[ 128 ] val_loss: 0.536238557100296 2022-05-29 18:12:26.967167
start training 2022-05-29 18:12:27.067902
Epoch:[ 129 0 ] loss: 0.40826141834259033 2022-05-29 18:12:49.634503
Epoch:[ 129 1 ] loss: 0.40092381834983826 2022-05-29 18:12:50.459723
Epoch:[ 129 2 ] loss: 0.40813225507736206 2022-05-29 18:12:51.240247
Epoch:[ 129 3 ] loss: 0.4037856161594391 2022-05-29 18:12:52.027688
Epoch:[ 129 4 ] loss: 0.4030883312225342 2022-05-29 18:12:52.803451
Epoch:[ 129 5 ] loss: 0.40632760524749756 2022-05-29 18:12:53.580794
Epoch:[ 129 6 ] loss: 0.4029993712902069 2022-05-29 18:12:54.356813
Epoch:[ 129 7 ] loss: 0.4056822657585144 2022-05-29 18:12:55.147275
Epoch:[ 129 8 ] loss: 0.40605005621910095 2022-05-29 18:12:55.924441
Epoch:[ 129 9 ] loss: 0.40907758474349976 2022-05-29 18:12:56.704674
Epoch:[ 129 10 ] loss: 0.4044855535030365 2022-05-29 18:12:57.482403
Epoch:[ 129 11 ] loss: 0.40568163990974426 2022-05-29 18:12:58.257762
Epoch:[ 129 12 ] loss: 0.40850505232810974 2022-05-29 18:12:59.031916
Epoch:[ 129 13 ] loss: 0.40778136253356934 2022-05-29 18:12:59.818305
Epoch:[ 129 14 ] loss: 0.4028071165084839 2022-05-29 18:13:00.596981
Epoch:[ 129 15 ] loss: 0.4082197844982147 2022-05-29 18:13:01.375894
Epoch:[ 129 16 ] loss: 0.40186983346939087 2022-05-29 18:13:08.586243
Epoch:[ 129 17 ] loss: 0.40911024808883667 2022-05-29 18:13:09.380999
Epoch:[ 129 18 ] loss: 0.40465909242630005 2022-05-29 18:13:10.161593
Epoch:[ 129 19 ] loss: 0.407418429851532 2022-05-29 18:13:10.936312
Training_Epoch:[ 129 ] Training_loss: 0.40574332177639005 2022-05-29 18:13:10.936966
learning rate:  2.7487790694400027e-05
val: 1 0.5477514863014221
val: 2 0.5291618704795837
val: 3 0.5420941114425659
val: 4 0.5229986310005188
val: 5 0.5333713293075562
val: 6 0.5195899605751038
val: 7 0.5486071109771729
val: 8 0.5590165257453918
val: 9 0.5578043460845947
val: 10 0.5553601384162903
val: 11 0.5142336487770081
val: 12 0.5337053537368774
val: 13 0.5296781063079834
val: 14 0.5331591367721558
val: 15 0.534912109375
val: 16 0.5315115451812744
val: 17 0.5272261500358582
val: 18 0.5443781018257141
val: 19 0.5390405654907227
val: 20 0.5353678464889526
val_Epoch:[ 129 ] val_loss: 0.5369484037160873 2022-05-29 18:13:16.104771
start training 2022-05-29 18:13:16.207504
Epoch:[ 130 0 ] loss: 0.40702369809150696 2022-05-29 18:13:38.514482
Epoch:[ 130 1 ] loss: 0.4074942171573639 2022-05-29 18:13:40.309523
Epoch:[ 130 2 ] loss: 0.4039645791053772 2022-05-29 18:13:41.087526
Epoch:[ 130 3 ] loss: 0.40551960468292236 2022-05-29 18:13:41.863495
Epoch:[ 130 4 ] loss: 0.4050273597240448 2022-05-29 18:13:42.653456
Epoch:[ 130 5 ] loss: 0.4052083194255829 2022-05-29 18:13:43.441040
Epoch:[ 130 6 ] loss: 0.4073120653629303 2022-05-29 18:13:44.216974
Epoch:[ 130 7 ] loss: 0.4063318073749542 2022-05-29 18:13:44.993265
Epoch:[ 130 8 ] loss: 0.40632885694503784 2022-05-29 18:13:45.769930
Epoch:[ 130 9 ] loss: 0.40333718061447144 2022-05-29 18:13:46.548427
Epoch:[ 130 10 ] loss: 0.402201384305954 2022-05-29 18:13:47.327560
Epoch:[ 130 11 ] loss: 0.40602681040763855 2022-05-29 18:13:48.104091
Epoch:[ 130 12 ] loss: 0.4052099287509918 2022-05-29 18:13:48.878566
Epoch:[ 130 13 ] loss: 0.40867140889167786 2022-05-29 18:13:49.653802
Epoch:[ 130 14 ] loss: 0.40422511100769043 2022-05-29 18:13:50.428709
Epoch:[ 130 15 ] loss: 0.40213051438331604 2022-05-29 18:13:51.206882
Epoch:[ 130 16 ] loss: 0.40854212641716003 2022-05-29 18:13:58.234001
Epoch:[ 130 17 ] loss: 0.4110301434993744 2022-05-29 18:13:59.050193
Epoch:[ 130 18 ] loss: 0.40472614765167236 2022-05-29 18:13:59.831074
Epoch:[ 130 19 ] loss: 0.40683290362358093 2022-05-29 18:14:00.619521
Training_Epoch:[ 130 ] Training_loss: 0.4058572083711624 2022-05-29 18:14:00.620412
learning rate:  2.7487790694400027e-05
netparams have been saved once 130
val: 1 0.5551654696464539
val: 2 0.5414142608642578
val: 3 0.5380281209945679
val: 4 0.5372812151908875
val: 5 0.5488803386688232
val: 6 0.531130850315094
val: 7 0.5206660032272339
val: 8 0.5387486815452576
val: 9 0.5341499447822571
val: 10 0.5319430232048035
val: 11 0.5091339349746704
val: 12 0.5473471283912659
val: 13 0.519951581954956
val: 14 0.5535592436790466
val: 15 0.5272947549819946
val: 16 0.5338449478149414
val: 17 0.5408542156219482
val: 18 0.5344324111938477
val: 19 0.5436448454856873
val: 20 0.5468990206718445
val_Epoch:[ 130 ] val_loss: 0.5367184996604919 2022-05-29 18:14:05.895117
start training 2022-05-29 18:14:05.997839
Epoch:[ 131 0 ] loss: 0.4099076986312866 2022-05-29 18:14:29.855232
Epoch:[ 131 1 ] loss: 0.4047991633415222 2022-05-29 18:14:30.630592
Epoch:[ 131 2 ] loss: 0.40371236205101013 2022-05-29 18:14:31.408386
Epoch:[ 131 3 ] loss: 0.4106980860233307 2022-05-29 18:14:32.185886
Epoch:[ 131 4 ] loss: 0.40710482001304626 2022-05-29 18:14:32.965424
Epoch:[ 131 5 ] loss: 0.40452566742897034 2022-05-29 18:14:33.743542
Epoch:[ 131 6 ] loss: 0.4043773114681244 2022-05-29 18:14:34.530083
Epoch:[ 131 7 ] loss: 0.4056299030780792 2022-05-29 18:14:35.304414
Epoch:[ 131 8 ] loss: 0.40411773324012756 2022-05-29 18:14:36.090040
Epoch:[ 131 9 ] loss: 0.40392500162124634 2022-05-29 18:14:36.866644
Epoch:[ 131 10 ] loss: 0.40659481287002563 2022-05-29 18:14:37.656437
Epoch:[ 131 11 ] loss: 0.40659067034721375 2022-05-29 18:14:38.432842
Epoch:[ 131 12 ] loss: 0.4064811170101166 2022-05-29 18:14:39.210644
Epoch:[ 131 13 ] loss: 0.4065583646297455 2022-05-29 18:14:39.984633
Epoch:[ 131 14 ] loss: 0.40292423963546753 2022-05-29 18:14:40.759707
Epoch:[ 131 15 ] loss: 0.40511077642440796 2022-05-29 18:14:41.534746
Epoch:[ 131 16 ] loss: 0.4063915014266968 2022-05-29 18:14:48.555616
Epoch:[ 131 17 ] loss: 0.40412867069244385 2022-05-29 18:14:49.333586
Epoch:[ 131 18 ] loss: 0.403323769569397 2022-05-29 18:14:50.115630
Epoch:[ 131 19 ] loss: 0.4034527838230133 2022-05-29 18:14:50.902270
Training_Epoch:[ 131 ] Training_loss: 0.40551772266626357 2022-05-29 18:14:50.902939
learning rate:  2.1990232555520022e-05
val: 1 0.5382708311080933
val: 2 0.5326576232910156
val: 3 0.54255610704422
val: 4 0.5327266454696655
val: 5 0.5525650382041931
val: 6 0.5433275699615479
val: 7 0.5558404922485352
val: 8 0.5166212320327759
val: 9 0.5324270725250244
val: 10 0.5301041007041931
val: 11 0.5422374606132507
val: 12 0.5427008271217346
val: 13 0.5297318696975708
val: 14 0.546711802482605
val: 15 0.5155498385429382
val: 16 0.5474154949188232
val: 17 0.5330913662910461
val: 18 0.5393992066383362
val: 19 0.5444734692573547
val: 20 0.5309800505638123
val_Epoch:[ 131 ] val_loss: 0.5374694049358368 2022-05-29 18:14:56.131819
start training 2022-05-29 18:14:56.234038
Epoch:[ 132 0 ] loss: 0.40056759119033813 2022-05-29 18:15:19.535283
Epoch:[ 132 1 ] loss: 0.4060713052749634 2022-05-29 18:15:20.321770
Epoch:[ 132 2 ] loss: 0.4084515869617462 2022-05-29 18:15:21.097592
Epoch:[ 132 3 ] loss: 0.4044266939163208 2022-05-29 18:15:21.875067
Epoch:[ 132 4 ] loss: 0.4102074205875397 2022-05-29 18:15:22.652618
Epoch:[ 132 5 ] loss: 0.40519315004348755 2022-05-29 18:15:23.431479
Epoch:[ 132 6 ] loss: 0.40868961811065674 2022-05-29 18:15:24.207320
Epoch:[ 132 7 ] loss: 0.41089728474617004 2022-05-29 18:15:24.983162
Epoch:[ 132 8 ] loss: 0.400677353143692 2022-05-29 18:15:25.761034
Epoch:[ 132 9 ] loss: 0.4054332971572876 2022-05-29 18:15:26.547391
Epoch:[ 132 10 ] loss: 0.4043000638484955 2022-05-29 18:15:27.326214
Epoch:[ 132 11 ] loss: 0.40590256452560425 2022-05-29 18:15:28.101860
Epoch:[ 132 12 ] loss: 0.4064929783344269 2022-05-29 18:15:28.878482
Epoch:[ 132 13 ] loss: 0.40282174944877625 2022-05-29 18:15:29.653716
Epoch:[ 132 14 ] loss: 0.4038296043872833 2022-05-29 18:15:30.442024
Epoch:[ 132 15 ] loss: 0.4014717936515808 2022-05-29 18:15:31.219585
Epoch:[ 132 16 ] loss: 0.4030655026435852 2022-05-29 18:15:38.566750
Epoch:[ 132 17 ] loss: 0.40901491045951843 2022-05-29 18:15:39.343875
Epoch:[ 132 18 ] loss: 0.4056120812892914 2022-05-29 18:15:40.126490
Epoch:[ 132 19 ] loss: 0.40379786491394043 2022-05-29 18:15:40.915216
Training_Epoch:[ 132 ] Training_loss: 0.4053462207317352 2022-05-29 18:15:40.916083
learning rate:  2.1990232555520022e-05
netparams have been saved once 132
val: 1 0.5232425332069397
val: 2 0.5346711277961731
val: 3 0.5411490797996521
val: 4 0.5612382888793945
val: 5 0.5257834196090698
val: 6 0.5444024801254272
val: 7 0.5266403555870056
val: 8 0.5636453628540039
val: 9 0.5441773533821106
val: 10 0.5369317531585693
val: 11 0.5432569980621338
val: 12 0.5356427431106567
val: 13 0.5320971608161926
val: 14 0.5177028179168701
val: 15 0.5364534854888916
val: 16 0.5454378128051758
val: 17 0.5212043523788452
val: 18 0.5347106456756592
val: 19 0.559432864189148
val: 20 0.5284667015075684
val_Epoch:[ 132 ] val_loss: 0.5378143668174744 2022-05-29 18:15:46.291666
start training 2022-05-29 18:15:46.392649
Epoch:[ 133 0 ] loss: 0.405097633600235 2022-05-29 18:16:10.269941
Epoch:[ 133 1 ] loss: 0.4057900309562683 2022-05-29 18:16:11.045795
Epoch:[ 133 2 ] loss: 0.4061015546321869 2022-05-29 18:16:11.820992
Epoch:[ 133 3 ] loss: 0.4031974971294403 2022-05-29 18:16:12.597032
Epoch:[ 133 4 ] loss: 0.4023847281932831 2022-05-29 18:16:13.374052
Epoch:[ 133 5 ] loss: 0.40530040860176086 2022-05-29 18:16:14.151843
Epoch:[ 133 6 ] loss: 0.40473929047584534 2022-05-29 18:16:14.942129
Epoch:[ 133 7 ] loss: 0.40881869196891785 2022-05-29 18:16:15.720010
Epoch:[ 133 8 ] loss: 0.40475431084632874 2022-05-29 18:16:16.494854
Epoch:[ 133 9 ] loss: 0.4014167785644531 2022-05-29 18:16:17.271467
Epoch:[ 133 10 ] loss: 0.40452027320861816 2022-05-29 18:16:18.045594
Epoch:[ 133 11 ] loss: 0.4042259156703949 2022-05-29 18:16:18.823721
Epoch:[ 133 12 ] loss: 0.40431326627731323 2022-05-29 18:16:19.599840
Epoch:[ 133 13 ] loss: 0.4075565040111542 2022-05-29 18:16:20.377070
Epoch:[ 133 14 ] loss: 0.40356433391571045 2022-05-29 18:16:21.165535
Epoch:[ 133 15 ] loss: 0.40514516830444336 2022-05-29 18:16:21.940168
Epoch:[ 133 16 ] loss: 0.4092654883861542 2022-05-29 18:16:28.576731
Epoch:[ 133 17 ] loss: 0.4052865207195282 2022-05-29 18:16:29.361756
Epoch:[ 133 18 ] loss: 0.40675410628318787 2022-05-29 18:16:30.142002
Epoch:[ 133 19 ] loss: 0.41032594442367554 2022-05-29 18:16:30.918554
Training_Epoch:[ 133 ] Training_loss: 0.405427922308445 2022-05-29 18:16:30.919261
learning rate:  2.1990232555520022e-05
val: 1 0.5384641885757446
val: 2 0.5321972966194153
val: 3 0.5035979747772217
val: 4 0.5525179505348206
val: 5 0.5355138778686523
val: 6 0.5458244681358337
val: 7 0.5354152917861938
val: 8 0.5230554938316345
val: 9 0.5554148554801941
val: 10 0.5404286980628967
val: 11 0.510599672794342
val: 12 0.5287854671478271
val: 13 0.5273469090461731
val: 14 0.5555545687675476
val: 15 0.5425825119018555
val: 16 0.5353754162788391
val: 17 0.5397613048553467
val: 18 0.5442644953727722
val: 19 0.5608710050582886
val: 20 0.5471364855766296
val_Epoch:[ 133 ] val_loss: 0.5377353966236115 2022-05-29 18:16:36.094721
start training 2022-05-29 18:16:36.193634
Epoch:[ 134 0 ] loss: 0.40795260667800903 2022-05-29 18:16:58.199503
Epoch:[ 134 1 ] loss: 0.4075806438922882 2022-05-29 18:16:59.011518
Epoch:[ 134 2 ] loss: 0.40576693415641785 2022-05-29 18:16:59.834464
Epoch:[ 134 3 ] loss: 0.4063998758792877 2022-05-29 18:17:00.622176
Epoch:[ 134 4 ] loss: 0.4082898497581482 2022-05-29 18:17:01.395432
Epoch:[ 134 5 ] loss: 0.405387282371521 2022-05-29 18:17:02.173285
Epoch:[ 134 6 ] loss: 0.40569254755973816 2022-05-29 18:17:02.951342
Epoch:[ 134 7 ] loss: 0.405931293964386 2022-05-29 18:17:03.728173
Epoch:[ 134 8 ] loss: 0.4077383577823639 2022-05-29 18:17:04.503357
Epoch:[ 134 9 ] loss: 0.40274396538734436 2022-05-29 18:17:05.277853
Epoch:[ 134 10 ] loss: 0.4085652232170105 2022-05-29 18:17:06.053839
Epoch:[ 134 11 ] loss: 0.4079115688800812 2022-05-29 18:17:06.840402
Epoch:[ 134 12 ] loss: 0.4031839072704315 2022-05-29 18:17:07.628119
Epoch:[ 134 13 ] loss: 0.4054369032382965 2022-05-29 18:17:08.405256
Epoch:[ 134 14 ] loss: 0.4039803743362427 2022-05-29 18:17:09.183603
Epoch:[ 134 15 ] loss: 0.4023255705833435 2022-05-29 18:17:09.960064
Epoch:[ 134 16 ] loss: 0.4014095067977905 2022-05-29 18:17:18.237384
Epoch:[ 134 17 ] loss: 0.40541037917137146 2022-05-29 18:17:19.010803
Epoch:[ 134 18 ] loss: 0.4035515785217285 2022-05-29 18:17:19.789270
Epoch:[ 134 19 ] loss: 0.40300309658050537 2022-05-29 18:17:20.577567
Training_Epoch:[ 134 ] Training_loss: 0.4054130733013153 2022-05-29 18:17:20.578228
learning rate:  2.1990232555520022e-05
netparams have been saved once 134
val: 1 0.5505443215370178
val: 2 0.5452228784561157
val: 3 0.550110936164856
val: 4 0.5398969054222107
val: 5 0.5347090363502502
val: 6 0.5300091505050659
val: 7 0.5225781798362732
val: 8 0.5155096650123596
val: 9 0.5448864102363586
val: 10 0.5224648714065552
val: 11 0.5402547717094421
val: 12 0.5447188019752502
val: 13 0.528818666934967
val: 14 0.5316292643547058
val: 15 0.5393330454826355
val: 16 0.5408521890640259
val: 17 0.5244309902191162
val: 18 0.5542430877685547
val: 19 0.5495125651359558
val: 20 0.5359818935394287
val_Epoch:[ 134 ] val_loss: 0.5372853815555573 2022-05-29 18:17:25.805073
start training 2022-05-29 18:17:25.904821
Epoch:[ 135 0 ] loss: 0.4054613709449768 2022-05-29 18:17:48.365483
Epoch:[ 135 1 ] loss: 0.40953224897384644 2022-05-29 18:17:49.453275
Epoch:[ 135 2 ] loss: 0.40436336398124695 2022-05-29 18:17:50.242871
Epoch:[ 135 3 ] loss: 0.4035743474960327 2022-05-29 18:17:51.017102
Epoch:[ 135 4 ] loss: 0.40515315532684326 2022-05-29 18:17:51.791424
Epoch:[ 135 5 ] loss: 0.4067159593105316 2022-05-29 18:17:52.565878
Epoch:[ 135 6 ] loss: 0.40593767166137695 2022-05-29 18:17:53.342560
Epoch:[ 135 7 ] loss: 0.4069681763648987 2022-05-29 18:17:54.121387
Epoch:[ 135 8 ] loss: 0.4051991403102875 2022-05-29 18:17:54.898376
Epoch:[ 135 9 ] loss: 0.4014253318309784 2022-05-29 18:17:55.676196
Epoch:[ 135 10 ] loss: 0.4080960154533386 2022-05-29 18:17:56.450504
Epoch:[ 135 11 ] loss: 0.40572693943977356 2022-05-29 18:17:57.228577
Epoch:[ 135 12 ] loss: 0.4054222106933594 2022-05-29 18:17:58.015350
Epoch:[ 135 13 ] loss: 0.41012901067733765 2022-05-29 18:17:58.794014
Epoch:[ 135 14 ] loss: 0.4057888388633728 2022-05-29 18:17:59.573119
Epoch:[ 135 15 ] loss: 0.4047650396823883 2022-05-29 18:18:00.362454
Epoch:[ 135 16 ] loss: 0.4015958309173584 2022-05-29 18:18:07.817995
Epoch:[ 135 17 ] loss: 0.40789303183555603 2022-05-29 18:18:08.606002
Epoch:[ 135 18 ] loss: 0.4026247560977936 2022-05-29 18:18:09.384913
Epoch:[ 135 19 ] loss: 0.4075935184955597 2022-05-29 18:18:10.171313
Training_Epoch:[ 135 ] Training_loss: 0.40569829791784284 2022-05-29 18:18:10.172005
learning rate:  2.1990232555520022e-05
val: 1 0.5286557674407959
val: 2 0.548284649848938
val: 3 0.5394165515899658
val: 4 0.5312140583992004
val: 5 0.5309885740280151
val: 6 0.5259187817573547
val: 7 0.5431303381919861
val: 8 0.5374146699905396
val: 9 0.5409342050552368
val: 10 0.5221276879310608
val: 11 0.5417197942733765
val: 12 0.536431610584259
val: 13 0.5511206388473511
val: 14 0.5156494975090027
val: 15 0.5471181869506836
val: 16 0.522514283657074
val: 17 0.5454686880111694
val: 18 0.5280764698982239
val: 19 0.5481617450714111
val: 20 0.5463109612464905
val_Epoch:[ 135 ] val_loss: 0.5365328580141068 2022-05-29 18:18:15.298135
start training 2022-05-29 18:18:15.399869
Epoch:[ 136 0 ] loss: 0.4062435030937195 2022-05-29 18:18:37.549240
Epoch:[ 136 1 ] loss: 0.40874183177948 2022-05-29 18:18:38.684472
Epoch:[ 136 2 ] loss: 0.4026954472064972 2022-05-29 18:18:39.475570
Epoch:[ 136 3 ] loss: 0.40574032068252563 2022-05-29 18:18:40.263685
Epoch:[ 136 4 ] loss: 0.40547940135002136 2022-05-29 18:18:41.040751
Epoch:[ 136 5 ] loss: 0.4041202962398529 2022-05-29 18:18:41.817090
Epoch:[ 136 6 ] loss: 0.40618830919265747 2022-05-29 18:18:42.591393
Epoch:[ 136 7 ] loss: 0.4008278548717499 2022-05-29 18:18:43.368740
Epoch:[ 136 8 ] loss: 0.4046038091182709 2022-05-29 18:18:44.146496
Epoch:[ 136 9 ] loss: 0.4056972563266754 2022-05-29 18:18:44.925204
Epoch:[ 136 10 ] loss: 0.4042136073112488 2022-05-29 18:18:45.715436
Epoch:[ 136 11 ] loss: 0.4028434157371521 2022-05-29 18:18:46.489741
Epoch:[ 136 12 ] loss: 0.40535494685173035 2022-05-29 18:18:47.266254
Epoch:[ 136 13 ] loss: 0.4069955348968506 2022-05-29 18:18:48.039609
Epoch:[ 136 14 ] loss: 0.40628889203071594 2022-05-29 18:18:48.816867
Epoch:[ 136 15 ] loss: 0.40999650955200195 2022-05-29 18:18:49.594269
Epoch:[ 136 16 ] loss: 0.40629714727401733 2022-05-29 18:18:57.599704
Epoch:[ 136 17 ] loss: 0.4064372777938843 2022-05-29 18:18:58.387782
Epoch:[ 136 18 ] loss: 0.4062126576900482 2022-05-29 18:18:59.167512
Epoch:[ 136 19 ] loss: 0.4055400788784027 2022-05-29 18:18:59.945427
Training_Epoch:[ 136 ] Training_loss: 0.40552590489387513 2022-05-29 18:18:59.946117
learning rate:  2.1990232555520022e-05
netparams have been saved once 136
val: 1 0.5562329292297363
val: 2 0.5575295686721802
val: 3 0.5332204103469849
val: 4 0.5496358275413513
val: 5 0.5275447368621826
val: 6 0.5373664498329163
val: 7 0.5376405715942383
val: 8 0.5250319838523865
val: 9 0.541591465473175
val: 10 0.541144073009491
val: 11 0.5251408219337463
val: 12 0.5393034219741821
val: 13 0.524844765663147
val: 14 0.5301553606987
val: 15 0.5322904586791992
val: 16 0.5214622020721436
val: 17 0.5425155758857727
val: 18 0.5500572323799133
val: 19 0.5443668365478516
val: 20 0.531861424446106
val_Epoch:[ 136 ] val_loss: 0.5374468058347702 2022-05-29 18:19:05.253842
start training 2022-05-29 18:19:05.356413
Epoch:[ 137 0 ] loss: 0.4029461145401001 2022-05-29 18:19:28.117928
Epoch:[ 137 1 ] loss: 0.40810877084732056 2022-05-29 18:19:28.910553
Epoch:[ 137 2 ] loss: 0.4052456319332123 2022-05-29 18:19:29.688469
Epoch:[ 137 3 ] loss: 0.40668949484825134 2022-05-29 18:19:30.467324
Epoch:[ 137 4 ] loss: 0.40661054849624634 2022-05-29 18:19:31.242480
Epoch:[ 137 5 ] loss: 0.4082234799861908 2022-05-29 18:19:32.030145
Epoch:[ 137 6 ] loss: 0.40727874636650085 2022-05-29 18:19:32.806618
Epoch:[ 137 7 ] loss: 0.40447255969047546 2022-05-29 18:19:33.581381
Epoch:[ 137 8 ] loss: 0.4068126380443573 2022-05-29 18:19:34.357567
Epoch:[ 137 9 ] loss: 0.4032551646232605 2022-05-29 18:19:35.136309
Epoch:[ 137 10 ] loss: 0.4066677689552307 2022-05-29 18:19:35.927122
Epoch:[ 137 11 ] loss: 0.4051864445209503 2022-05-29 18:19:36.717451
Epoch:[ 137 12 ] loss: 0.4021035134792328 2022-05-29 18:19:37.491296
Epoch:[ 137 13 ] loss: 0.40945693850517273 2022-05-29 18:19:38.268546
Epoch:[ 137 14 ] loss: 0.4017116129398346 2022-05-29 18:19:39.043102
Epoch:[ 137 15 ] loss: 0.4044242203235626 2022-05-29 18:19:39.822206
Epoch:[ 137 16 ] loss: 0.40515264868736267 2022-05-29 18:19:47.091475
Epoch:[ 137 17 ] loss: 0.4026816189289093 2022-05-29 18:19:47.869888
Epoch:[ 137 18 ] loss: 0.4031051695346832 2022-05-29 18:19:48.659364
Epoch:[ 137 19 ] loss: 0.4056580364704132 2022-05-29 18:19:49.443017
Training_Epoch:[ 137 ] Training_loss: 0.4052895560860634 2022-05-29 18:19:49.443695
learning rate:  2.1990232555520022e-05
val: 1 0.5473147630691528
val: 2 0.5346194505691528
val: 3 0.5468113422393799
val: 4 0.5369788408279419
val: 5 0.5376783609390259
val: 6 0.5417223572731018
val: 7 0.5241644382476807
val: 8 0.5448447465896606
val: 9 0.5490747690200806
val: 10 0.5400102138519287
val: 11 0.5186432003974915
val: 12 0.5434264540672302
val: 13 0.5584468841552734
val: 14 0.524212658405304
val: 15 0.5262097120285034
val: 16 0.5334096550941467
val: 17 0.5457497835159302
val: 18 0.5345687866210938
val: 19 0.5254397988319397
val: 20 0.53873610496521
val_Epoch:[ 137 ] val_loss: 0.5376031160354614 2022-05-29 18:19:54.664269
start training 2022-05-29 18:19:54.768951
Epoch:[ 138 0 ] loss: 0.40160658955574036 2022-05-29 18:20:18.329775
Epoch:[ 138 1 ] loss: 0.4030086100101471 2022-05-29 18:20:19.104202
Epoch:[ 138 2 ] loss: 0.4058419167995453 2022-05-29 18:20:19.883224
Epoch:[ 138 3 ] loss: 0.4096389710903168 2022-05-29 18:20:20.662222
Epoch:[ 138 4 ] loss: 0.40238648653030396 2022-05-29 18:20:21.442269
Epoch:[ 138 5 ] loss: 0.4052792191505432 2022-05-29 18:20:22.218126
Epoch:[ 138 6 ] loss: 0.4044438898563385 2022-05-29 18:20:23.005884
Epoch:[ 138 7 ] loss: 0.4052862823009491 2022-05-29 18:20:23.782488
Epoch:[ 138 8 ] loss: 0.40317070484161377 2022-05-29 18:20:24.557720
Epoch:[ 138 9 ] loss: 0.40461158752441406 2022-05-29 18:20:25.336531
Epoch:[ 138 10 ] loss: 0.4048915207386017 2022-05-29 18:20:26.114375
Epoch:[ 138 11 ] loss: 0.4030917286872864 2022-05-29 18:20:26.904834
Epoch:[ 138 12 ] loss: 0.4021443724632263 2022-05-29 18:20:27.695235
Epoch:[ 138 13 ] loss: 0.4065576195716858 2022-05-29 18:20:28.469856
Epoch:[ 138 14 ] loss: 0.40830209851264954 2022-05-29 18:20:29.242800
Epoch:[ 138 15 ] loss: 0.4048847556114197 2022-05-29 18:20:30.017123
Epoch:[ 138 16 ] loss: 0.40871161222457886 2022-05-29 18:20:37.358751
Epoch:[ 138 17 ] loss: 0.40974411368370056 2022-05-29 18:20:38.147757
Epoch:[ 138 18 ] loss: 0.40831902623176575 2022-05-29 18:20:38.943800
Epoch:[ 138 19 ] loss: 0.4032289683818817 2022-05-29 18:20:39.719273
Training_Epoch:[ 138 ] Training_loss: 0.4052575036883354 2022-05-29 18:20:39.719957
learning rate:  2.1990232555520022e-05
netparams have been saved once 138
val: 1 0.530907154083252
val: 2 0.5484269261360168
val: 3 0.5209493637084961
val: 4 0.5273220539093018
val: 5 0.5386943817138672
val: 6 0.5400251150131226
val: 7 0.5456266403198242
val: 8 0.5470845103263855
val: 9 0.514487087726593
val: 10 0.5416712164878845
val: 11 0.5514059662818909
val: 12 0.5406858921051025
val: 13 0.5534677505493164
val: 14 0.5374147295951843
val: 15 0.540143609046936
val: 16 0.5163617730140686
val: 17 0.5252443552017212
val: 18 0.5174500942230225
val: 19 0.5314434766769409
val: 20 0.5569469928741455
val_Epoch:[ 138 ] val_loss: 0.5362879544496536 2022-05-29 18:20:45.064393
start training 2022-05-29 18:20:45.167893
Epoch:[ 139 0 ] loss: 0.4054126739501953 2022-05-29 18:21:08.264287
Epoch:[ 139 1 ] loss: 0.404289186000824 2022-05-29 18:21:09.064456
Epoch:[ 139 2 ] loss: 0.403147429227829 2022-05-29 18:21:09.840801
Epoch:[ 139 3 ] loss: 0.4060057997703552 2022-05-29 18:21:10.618256
Epoch:[ 139 4 ] loss: 0.4052954912185669 2022-05-29 18:21:11.395007
Epoch:[ 139 5 ] loss: 0.404371976852417 2022-05-29 18:21:12.185789
Epoch:[ 139 6 ] loss: 0.4050161838531494 2022-05-29 18:21:12.960521
Epoch:[ 139 7 ] loss: 0.4061349034309387 2022-05-29 18:21:13.747914
Epoch:[ 139 8 ] loss: 0.40550440549850464 2022-05-29 18:21:14.523188
Epoch:[ 139 9 ] loss: 0.41024088859558105 2022-05-29 18:21:15.297602
Epoch:[ 139 10 ] loss: 0.40651702880859375 2022-05-29 18:21:16.074611
Epoch:[ 139 11 ] loss: 0.4040682017803192 2022-05-29 18:21:16.865018
Epoch:[ 139 12 ] loss: 0.4037531018257141 2022-05-29 18:21:17.642040
Epoch:[ 139 13 ] loss: 0.4083837568759918 2022-05-29 18:21:18.415522
Epoch:[ 139 14 ] loss: 0.40463167428970337 2022-05-29 18:21:19.191686
Epoch:[ 139 15 ] loss: 0.40991201996803284 2022-05-29 18:21:19.968396
Epoch:[ 139 16 ] loss: 0.4024060070514679 2022-05-29 18:21:27.304170
Epoch:[ 139 17 ] loss: 0.4041888117790222 2022-05-29 18:21:28.078085
Epoch:[ 139 18 ] loss: 0.401815801858902 2022-05-29 18:21:28.872052
Epoch:[ 139 19 ] loss: 0.40491241216659546 2022-05-29 18:21:29.649567
Training_Epoch:[ 139 ] Training_loss: 0.4053003877401352 2022-05-29 18:21:29.650280
learning rate:  2.1990232555520022e-05
val: 1 0.5446306467056274
val: 2 0.512601912021637
val: 3 0.5245941877365112
val: 4 0.5321725010871887
val: 5 0.528694748878479
val: 6 0.5033416748046875
val: 7 0.5451428890228271
val: 8 0.551977813243866
val: 9 0.5370659232139587
val: 10 0.5484955310821533
val: 11 0.5351113677024841
val: 12 0.5325266122817993
val: 13 0.5644214153289795
val: 14 0.5483810305595398
val: 15 0.541049063205719
val: 16 0.5370941758155823
val: 17 0.531636118888855
val: 18 0.5418750643730164
val: 19 0.5525293350219727
val: 20 0.5340085625648499
val_Epoch:[ 139 ] val_loss: 0.5373675286769867 2022-05-29 18:21:34.843659
start training 2022-05-29 18:21:34.943523
Epoch:[ 140 0 ] loss: 0.4033234119415283 2022-05-29 18:21:56.956643
Epoch:[ 140 1 ] loss: 0.41091132164001465 2022-05-29 18:21:57.896823
Epoch:[ 140 2 ] loss: 0.40408626198768616 2022-05-29 18:21:58.700041
Epoch:[ 140 3 ] loss: 0.40906673669815063 2022-05-29 18:21:59.476128
Epoch:[ 140 4 ] loss: 0.4074304401874542 2022-05-29 18:22:00.266748
Epoch:[ 140 5 ] loss: 0.40152421593666077 2022-05-29 18:22:01.046360
Epoch:[ 140 6 ] loss: 0.40250271558761597 2022-05-29 18:22:01.832239
Epoch:[ 140 7 ] loss: 0.4027441442012787 2022-05-29 18:22:02.621391
Epoch:[ 140 8 ] loss: 0.40644240379333496 2022-05-29 18:22:03.396747
Epoch:[ 140 9 ] loss: 0.4048614203929901 2022-05-29 18:22:04.173096
Epoch:[ 140 10 ] loss: 0.4103813171386719 2022-05-29 18:22:04.948292
Epoch:[ 140 11 ] loss: 0.4066507816314697 2022-05-29 18:22:05.727541
Epoch:[ 140 12 ] loss: 0.40723633766174316 2022-05-29 18:22:06.506482
Epoch:[ 140 13 ] loss: 0.4046415388584137 2022-05-29 18:22:07.284018
Epoch:[ 140 14 ] loss: 0.4027891159057617 2022-05-29 18:22:08.062358
Epoch:[ 140 15 ] loss: 0.403007447719574 2022-05-29 18:22:08.837507
Epoch:[ 140 16 ] loss: 0.4052949547767639 2022-05-29 18:22:17.440368
Epoch:[ 140 17 ] loss: 0.4060347378253937 2022-05-29 18:22:18.213602
Epoch:[ 140 18 ] loss: 0.40597856044769287 2022-05-29 18:22:18.995159
Epoch:[ 140 19 ] loss: 0.4000660479068756 2022-05-29 18:22:19.784328
Training_Epoch:[ 140 ] Training_loss: 0.40524869561195376 2022-05-29 18:22:19.785087
learning rate:  2.1990232555520022e-05
netparams have been saved once 140
val: 1 0.5418015122413635
val: 2 0.5514787435531616
val: 3 0.5248396992683411
val: 4 0.519891619682312
val: 5 0.5293602347373962
val: 6 0.5337356925010681
val: 7 0.528336226940155
val: 8 0.5353466272354126
val: 9 0.5200040340423584
val: 10 0.5100163221359253
val: 11 0.5543103218078613
val: 12 0.5247249007225037
val: 13 0.5307732820510864
val: 14 0.5426971912384033
val: 15 0.5598493218421936
val: 16 0.5207607746124268
val: 17 0.5468013286590576
val: 18 0.5700576305389404
val: 19 0.5490840673446655
val: 20 0.570659875869751
val_Epoch:[ 140 ] val_loss: 0.5382264703512192 2022-05-29 18:22:25.033867
start training 2022-05-29 18:22:25.136369
Epoch:[ 141 0 ] loss: 0.40098822116851807 2022-05-29 18:22:48.922523
Epoch:[ 141 1 ] loss: 0.40682390332221985 2022-05-29 18:22:49.698408
Epoch:[ 141 2 ] loss: 0.40453702211380005 2022-05-29 18:22:50.473315
Epoch:[ 141 3 ] loss: 0.40566909313201904 2022-05-29 18:22:51.248659
Epoch:[ 141 4 ] loss: 0.4077332019805908 2022-05-29 18:22:52.035824
Epoch:[ 141 5 ] loss: 0.40433982014656067 2022-05-29 18:22:52.813535
Epoch:[ 141 6 ] loss: 0.4042293131351471 2022-05-29 18:22:53.589933
Epoch:[ 141 7 ] loss: 0.40540915727615356 2022-05-29 18:22:54.364729
Epoch:[ 141 8 ] loss: 0.40456709265708923 2022-05-29 18:22:55.143530
Epoch:[ 141 9 ] loss: 0.40496721863746643 2022-05-29 18:22:55.919400
Epoch:[ 141 10 ] loss: 0.4041728377342224 2022-05-29 18:22:56.706360
Epoch:[ 141 11 ] loss: 0.4046337604522705 2022-05-29 18:22:57.480550
Epoch:[ 141 12 ] loss: 0.40253493189811707 2022-05-29 18:22:58.259210
Epoch:[ 141 13 ] loss: 0.4076576828956604 2022-05-29 18:22:59.035341
Epoch:[ 141 14 ] loss: 0.40055105090141296 2022-05-29 18:22:59.821214
Epoch:[ 141 15 ] loss: 0.4069235324859619 2022-05-29 18:23:00.599602
Epoch:[ 141 16 ] loss: 0.4063175618648529 2022-05-29 18:23:07.368823
Epoch:[ 141 17 ] loss: 0.40641194581985474 2022-05-29 18:23:08.141447
Epoch:[ 141 18 ] loss: 0.4056326746940613 2022-05-29 18:23:08.944772
Epoch:[ 141 19 ] loss: 0.40525302290916443 2022-05-29 18:23:09.733485
Training_Epoch:[ 141 ] Training_loss: 0.4049676522612572 2022-05-29 18:23:09.734138
learning rate:  1.7592186044416018e-05
val: 1 0.532407820224762
val: 2 0.5413726568222046
val: 3 0.5350580215454102
val: 4 0.5423998236656189
val: 5 0.5319012999534607
val: 6 0.5167457461357117
val: 7 0.5420279502868652
val: 8 0.5649952292442322
val: 9 0.5310250520706177
val: 10 0.5351750254631042
val: 11 0.5213654041290283
val: 12 0.528560996055603
val: 13 0.5424984097480774
val: 14 0.541593611240387
val: 15 0.5270636677742004
val: 16 0.5470989346504211
val: 17 0.5239501595497131
val: 18 0.5425079464912415
val: 19 0.5422918200492859
val: 20 0.5634587407112122
val_Epoch:[ 141 ] val_loss: 0.5376749157905578 2022-05-29 18:23:14.926286
start training 2022-05-29 18:23:15.033714
Epoch:[ 142 0 ] loss: 0.40510374307632446 2022-05-29 18:23:39.115875
Epoch:[ 142 1 ] loss: 0.40749889612197876 2022-05-29 18:23:39.906712
Epoch:[ 142 2 ] loss: 0.4063168168067932 2022-05-29 18:23:40.682455
Epoch:[ 142 3 ] loss: 0.4008788466453552 2022-05-29 18:23:41.458017
Epoch:[ 142 4 ] loss: 0.40935397148132324 2022-05-29 18:23:42.232889
Epoch:[ 142 5 ] loss: 0.4040113687515259 2022-05-29 18:23:43.020573
Epoch:[ 142 6 ] loss: 0.4014739990234375 2022-05-29 18:23:43.810344
Epoch:[ 142 7 ] loss: 0.4040471315383911 2022-05-29 18:23:44.588926
Epoch:[ 142 8 ] loss: 0.40826907753944397 2022-05-29 18:23:45.368169
Epoch:[ 142 9 ] loss: 0.40334177017211914 2022-05-29 18:23:46.144605
Epoch:[ 142 10 ] loss: 0.4072088897228241 2022-05-29 18:23:46.920511
Epoch:[ 142 11 ] loss: 0.4081461727619171 2022-05-29 18:23:47.693354
Epoch:[ 142 12 ] loss: 0.40591153502464294 2022-05-29 18:23:48.467636
Epoch:[ 142 13 ] loss: 0.4048286974430084 2022-05-29 18:23:49.244270
Epoch:[ 142 14 ] loss: 0.4058123528957367 2022-05-29 18:23:50.021195
Epoch:[ 142 15 ] loss: 0.4037764072418213 2022-05-29 18:23:50.797524
Epoch:[ 142 16 ] loss: 0.403706818819046 2022-05-29 18:23:57.918035
Epoch:[ 142 17 ] loss: 0.4017845094203949 2022-05-29 18:23:58.691325
Epoch:[ 142 18 ] loss: 0.40705859661102295 2022-05-29 18:23:59.481277
Epoch:[ 142 19 ] loss: 0.4039965569972992 2022-05-29 18:24:00.267539
Training_Epoch:[ 142 ] Training_loss: 0.4051263079047203 2022-05-29 18:24:00.268396
learning rate:  1.7592186044416018e-05
netparams have been saved once 142
val: 1 0.5232911705970764
val: 2 0.5188629627227783
val: 3 0.5584259629249573
val: 4 0.5353186130523682
val: 5 0.5444760918617249
val: 6 0.552689790725708
val: 7 0.5295186042785645
val: 8 0.5419068932533264
val: 9 0.545045793056488
val: 10 0.5478701591491699
val: 11 0.545559287071228
val: 12 0.54820317029953
val: 13 0.5175246596336365
val: 14 0.5179575681686401
val: 15 0.5481195449829102
val: 16 0.5320823192596436
val: 17 0.5410184264183044
val: 18 0.5478094220161438
val: 19 0.5377590656280518
val: 20 0.5290766954421997
val_Epoch:[ 142 ] val_loss: 0.5381258100271225 2022-05-29 18:24:05.560508
start training 2022-05-29 18:24:05.663821
Epoch:[ 143 0 ] loss: 0.4004167318344116 2022-05-29 18:24:27.655885
Epoch:[ 143 1 ] loss: 0.40772879123687744 2022-05-29 18:24:28.469963
Epoch:[ 143 2 ] loss: 0.40510183572769165 2022-05-29 18:24:29.276389
Epoch:[ 143 3 ] loss: 0.40472400188446045 2022-05-29 18:24:30.053204
Epoch:[ 143 4 ] loss: 0.4097811281681061 2022-05-29 18:24:30.827489
Epoch:[ 143 5 ] loss: 0.40443962812423706 2022-05-29 18:24:31.613359
Epoch:[ 143 6 ] loss: 0.3998786509037018 2022-05-29 18:24:32.387478
Epoch:[ 143 7 ] loss: 0.4041334092617035 2022-05-29 18:24:33.164887
Epoch:[ 143 8 ] loss: 0.4045482277870178 2022-05-29 18:24:33.954597
Epoch:[ 143 9 ] loss: 0.40402543544769287 2022-05-29 18:24:34.743972
Epoch:[ 143 10 ] loss: 0.4068683981895447 2022-05-29 18:24:35.519506
Epoch:[ 143 11 ] loss: 0.4032992124557495 2022-05-29 18:24:36.293936
Epoch:[ 143 12 ] loss: 0.4009303152561188 2022-05-29 18:24:37.069099
Epoch:[ 143 13 ] loss: 0.4056583642959595 2022-05-29 18:24:37.842684
Epoch:[ 143 14 ] loss: 0.40405210852622986 2022-05-29 18:24:38.620665
Epoch:[ 143 15 ] loss: 0.4068194627761841 2022-05-29 18:24:39.397117
Epoch:[ 143 16 ] loss: 0.4095790982246399 2022-05-29 18:24:47.743457
Epoch:[ 143 17 ] loss: 0.40571537613868713 2022-05-29 18:24:48.517534
Epoch:[ 143 18 ] loss: 0.4056496024131775 2022-05-29 18:24:49.296113
Epoch:[ 143 19 ] loss: 0.40494096279144287 2022-05-29 18:24:50.083189
Training_Epoch:[ 143 ] Training_loss: 0.4049145370721817 2022-05-29 18:24:50.083886
learning rate:  1.7592186044416018e-05
val: 1 0.5463587641716003
val: 2 0.5344460010528564
val: 3 0.5379212498664856
val: 4 0.519162654876709
val: 5 0.5321604609489441
val: 6 0.5425554513931274
val: 7 0.5397226810455322
val: 8 0.5448049306869507
val: 9 0.5582473874092102
val: 10 0.542041540145874
val: 11 0.5212072730064392
val: 12 0.5364646911621094
val: 13 0.5533661246299744
val: 14 0.5415629744529724
val: 15 0.5457552671432495
val: 16 0.5309354662895203
val: 17 0.53122478723526
val: 18 0.5515578985214233
val: 19 0.5401417016983032
val: 20 0.5271285176277161
val_Epoch:[ 143 ] val_loss: 0.5388382911682129 2022-05-29 18:24:55.304808
start training 2022-05-29 18:24:55.405941
Epoch:[ 144 0 ] loss: 0.4033581614494324 2022-05-29 18:25:17.517375
Epoch:[ 144 1 ] loss: 0.40118125081062317 2022-05-29 18:25:18.359914
Epoch:[ 144 2 ] loss: 0.4048045575618744 2022-05-29 18:25:19.157615
Epoch:[ 144 3 ] loss: 0.4056084454059601 2022-05-29 18:25:19.933451
Epoch:[ 144 4 ] loss: 0.4082072377204895 2022-05-29 18:25:20.709241
Epoch:[ 144 5 ] loss: 0.4098551869392395 2022-05-29 18:25:21.484615
Epoch:[ 144 6 ] loss: 0.40430307388305664 2022-05-29 18:25:22.260911
Epoch:[ 144 7 ] loss: 0.40536943078041077 2022-05-29 18:25:23.035035
Epoch:[ 144 8 ] loss: 0.4045695662498474 2022-05-29 18:25:23.812066
Epoch:[ 144 9 ] loss: 0.40157580375671387 2022-05-29 18:25:24.588810
Epoch:[ 144 10 ] loss: 0.40315836668014526 2022-05-29 18:25:25.363503
Epoch:[ 144 11 ] loss: 0.4031761586666107 2022-05-29 18:25:26.150482
Epoch:[ 144 12 ] loss: 0.4035758674144745 2022-05-29 18:25:26.922258
Epoch:[ 144 13 ] loss: 0.4035624563694 2022-05-29 18:25:27.708493
Epoch:[ 144 14 ] loss: 0.40512824058532715 2022-05-29 18:25:28.494202
Epoch:[ 144 15 ] loss: 0.4064231514930725 2022-05-29 18:25:29.271639
Epoch:[ 144 16 ] loss: 0.40647754073143005 2022-05-29 18:25:37.431261
Epoch:[ 144 17 ] loss: 0.404052734375 2022-05-29 18:25:38.207629
Epoch:[ 144 18 ] loss: 0.4040221571922302 2022-05-29 18:25:38.985830
Epoch:[ 144 19 ] loss: 0.407235711812973 2022-05-29 18:25:39.771274
Training_Epoch:[ 144 ] Training_loss: 0.40478225499391557 2022-05-29 18:25:39.772017
learning rate:  1.7592186044416018e-05
netparams have been saved once 144
val: 1 0.5448107123374939
val: 2 0.5288469195365906
val: 3 0.5338937044143677
val: 4 0.516732394695282
val: 5 0.5522439479827881
val: 6 0.5573135018348694
val: 7 0.5322514772415161
val: 8 0.5381741523742676
val: 9 0.5464091897010803
val: 10 0.5316753387451172
val: 11 0.5367361307144165
val: 12 0.5495792031288147
val: 13 0.5395569205284119
val: 14 0.531606137752533
val: 15 0.5447338819503784
val: 16 0.5307186841964722
val: 17 0.5317944288253784
val: 18 0.5362516641616821
val: 19 0.5361782908439636
val: 20 0.5193514823913574
val_Epoch:[ 144 ] val_loss: 0.5369429081678391 2022-05-29 18:25:45.109898
start training 2022-05-29 18:25:45.210407
Epoch:[ 145 0 ] loss: 0.4040689170360565 2022-05-29 18:26:09.033843
Epoch:[ 145 1 ] loss: 0.4037754237651825 2022-05-29 18:26:09.808472
Epoch:[ 145 2 ] loss: 0.40221747756004333 2022-05-29 18:26:10.586409
Epoch:[ 145 3 ] loss: 0.40687137842178345 2022-05-29 18:26:11.364395
Epoch:[ 145 4 ] loss: 0.40404054522514343 2022-05-29 18:26:12.138993
Epoch:[ 145 5 ] loss: 0.4090742766857147 2022-05-29 18:26:12.916985
Epoch:[ 145 6 ] loss: 0.4063621163368225 2022-05-29 18:26:13.691059
Epoch:[ 145 7 ] loss: 0.40300145745277405 2022-05-29 18:26:14.467580
Epoch:[ 145 8 ] loss: 0.4054761826992035 2022-05-29 18:26:15.242424
Epoch:[ 145 9 ] loss: 0.4034329950809479 2022-05-29 18:26:16.031964
Epoch:[ 145 10 ] loss: 0.41204264760017395 2022-05-29 18:26:16.821316
Epoch:[ 145 11 ] loss: 0.40922799706459045 2022-05-29 18:26:17.611640
Epoch:[ 145 12 ] loss: 0.40470874309539795 2022-05-29 18:26:18.389311
Epoch:[ 145 13 ] loss: 0.40193676948547363 2022-05-29 18:26:19.165723
Epoch:[ 145 14 ] loss: 0.40415751934051514 2022-05-29 18:26:19.941252
Epoch:[ 145 15 ] loss: 0.4020811915397644 2022-05-29 18:26:20.715434
Epoch:[ 145 16 ] loss: 0.4044255018234253 2022-05-29 18:26:27.709682
Epoch:[ 145 17 ] loss: 0.40549522638320923 2022-05-29 18:26:28.486057
Epoch:[ 145 18 ] loss: 0.40222570300102234 2022-05-29 18:26:29.266647
Epoch:[ 145 19 ] loss: 0.40401729941368103 2022-05-29 18:26:30.054698
Training_Epoch:[ 145 ] Training_loss: 0.40493196845054624 2022-05-29 18:26:30.055372
learning rate:  1.7592186044416018e-05
val: 1 0.5195409655570984
val: 2 0.548530638217926
val: 3 0.5499598383903503
val: 4 0.5552927255630493
val: 5 0.5404961705207825
val: 6 0.540674090385437
val: 7 0.5316765308380127
val: 8 0.5387951731681824
val: 9 0.5371262431144714
val: 10 0.5474536418914795
val: 11 0.5411074161529541
val: 12 0.5346179008483887
val: 13 0.5268361568450928
val: 14 0.5304516553878784
val: 15 0.5394911766052246
val: 16 0.5238618850708008
val: 17 0.5427897572517395
val: 18 0.5362898111343384
val: 19 0.5374643206596375
val: 20 0.5338778495788574
val_Epoch:[ 145 ] val_loss: 0.5378166973590851 2022-05-29 18:26:35.199552
start training 2022-05-29 18:26:35.298113
Epoch:[ 146 0 ] loss: 0.406282514333725 2022-05-29 18:26:59.052286
Epoch:[ 146 1 ] loss: 0.4067923426628113 2022-05-29 18:26:59.838320
Epoch:[ 146 2 ] loss: 0.401037335395813 2022-05-29 18:27:00.612429
Epoch:[ 146 3 ] loss: 0.40309813618659973 2022-05-29 18:27:01.402810
Epoch:[ 146 4 ] loss: 0.4044526219367981 2022-05-29 18:27:02.180948
Epoch:[ 146 5 ] loss: 0.40427401661872864 2022-05-29 18:27:02.971573
Epoch:[ 146 6 ] loss: 0.4033687710762024 2022-05-29 18:27:03.749621
Epoch:[ 146 7 ] loss: 0.4049000144004822 2022-05-29 18:27:04.523999
Epoch:[ 146 8 ] loss: 0.4036731421947479 2022-05-29 18:27:05.300964
Epoch:[ 146 9 ] loss: 0.4062837064266205 2022-05-29 18:27:06.076014
Epoch:[ 146 10 ] loss: 0.40663081407546997 2022-05-29 18:27:06.854243
Epoch:[ 146 11 ] loss: 0.4054119884967804 2022-05-29 18:27:07.631304
Epoch:[ 146 12 ] loss: 0.4058489501476288 2022-05-29 18:27:08.406727
Epoch:[ 146 13 ] loss: 0.40537703037261963 2022-05-29 18:27:09.182032
Epoch:[ 146 14 ] loss: 0.4068151116371155 2022-05-29 18:27:09.957094
Epoch:[ 146 15 ] loss: 0.402251273393631 2022-05-29 18:27:10.731500
Epoch:[ 146 16 ] loss: 0.4049242436885834 2022-05-29 18:27:17.628346
Epoch:[ 146 17 ] loss: 0.4028119444847107 2022-05-29 18:27:18.404948
Epoch:[ 146 18 ] loss: 0.4081948697566986 2022-05-29 18:27:19.204924
Epoch:[ 146 19 ] loss: 0.40372467041015625 2022-05-29 18:27:19.980596
Training_Epoch:[ 146 ] Training_loss: 0.40480767488479613 2022-05-29 18:27:19.981355
learning rate:  1.7592186044416018e-05
netparams have been saved once 146
val: 1 0.5639755129814148
val: 2 0.5620303750038147
val: 3 0.5495508909225464
val: 4 0.5403082966804504
val: 5 0.5659775733947754
val: 6 0.5600147843360901
val: 7 0.5127149224281311
val: 8 0.5299793481826782
val: 9 0.5221245288848877
val: 10 0.5268037915229797
val: 11 0.5363894104957581
val: 12 0.5244694948196411
val: 13 0.544055700302124
val: 14 0.5355268120765686
val: 15 0.522253155708313
val: 16 0.5183665156364441
val: 17 0.5439693927764893
val: 18 0.5429086089134216
val: 19 0.5367879867553711
val: 20 0.5232203602790833
val_Epoch:[ 146 ] val_loss: 0.5380713731050492 2022-05-29 18:27:25.313976
start training 2022-05-29 18:27:25.414821
Epoch:[ 147 0 ] loss: 0.4018281102180481 2022-05-29 18:27:48.300312
Epoch:[ 147 1 ] loss: 0.40441253781318665 2022-05-29 18:27:49.140177
Epoch:[ 147 2 ] loss: 0.401620477437973 2022-05-29 18:27:49.925631
Epoch:[ 147 3 ] loss: 0.4062076508998871 2022-05-29 18:27:50.710990
Epoch:[ 147 4 ] loss: 0.4086364507675171 2022-05-29 18:27:51.489125
Epoch:[ 147 5 ] loss: 0.4044599235057831 2022-05-29 18:27:52.265011
Epoch:[ 147 6 ] loss: 0.40352097153663635 2022-05-29 18:27:53.039520
Epoch:[ 147 7 ] loss: 0.4041542410850525 2022-05-29 18:27:53.817587
Epoch:[ 147 8 ] loss: 0.4061896800994873 2022-05-29 18:27:54.592870
Epoch:[ 147 9 ] loss: 0.4063877463340759 2022-05-29 18:27:55.369860
Epoch:[ 147 10 ] loss: 0.40208181738853455 2022-05-29 18:27:56.155414
Epoch:[ 147 11 ] loss: 0.40752288699150085 2022-05-29 18:27:56.933391
Epoch:[ 147 12 ] loss: 0.40423938632011414 2022-05-29 18:27:57.709203
Epoch:[ 147 13 ] loss: 0.4063652455806732 2022-05-29 18:27:58.485122
Epoch:[ 147 14 ] loss: 0.4066474437713623 2022-05-29 18:27:59.263462
Epoch:[ 147 15 ] loss: 0.4067497253417969 2022-05-29 18:28:00.036845
Epoch:[ 147 16 ] loss: 0.40264615416526794 2022-05-29 18:28:06.920862
Epoch:[ 147 17 ] loss: 0.40675675868988037 2022-05-29 18:28:07.706853
Epoch:[ 147 18 ] loss: 0.4051513075828552 2022-05-29 18:28:08.501289
Epoch:[ 147 19 ] loss: 0.4055209159851074 2022-05-29 18:28:09.289653
Training_Epoch:[ 147 ] Training_loss: 0.405054971575737 2022-05-29 18:28:09.290347
learning rate:  1.7592186044416018e-05
val: 1 0.5267500877380371
val: 2 0.528363049030304
val: 3 0.5425921678543091
val: 4 0.5214961767196655
val: 5 0.5351825952529907
val: 6 0.5461371541023254
val: 7 0.5343435406684875
val: 8 0.5450271964073181
val: 9 0.5132348537445068
val: 10 0.5364360213279724
val: 11 0.5586466193199158
val: 12 0.5299986600875854
val: 13 0.5225907564163208
val: 14 0.5440383553504944
val: 15 0.5572500228881836
val: 16 0.5382524728775024
val: 17 0.541227400302887
val: 18 0.5515266060829163
val: 19 0.5447415709495544
val: 20 0.5250131487846375
val_Epoch:[ 147 ] val_loss: 0.5371424227952957 2022-05-29 18:28:14.459072
start training 2022-05-29 18:28:14.560687
Epoch:[ 148 0 ] loss: 0.4053017497062683 2022-05-29 18:28:38.595867
Epoch:[ 148 1 ] loss: 0.4074862599372864 2022-05-29 18:28:39.380401
Epoch:[ 148 2 ] loss: 0.40242618322372437 2022-05-29 18:28:40.154547
Epoch:[ 148 3 ] loss: 0.4034120440483093 2022-05-29 18:28:40.941617
Epoch:[ 148 4 ] loss: 0.40495944023132324 2022-05-29 18:28:41.715252
Epoch:[ 148 5 ] loss: 0.40330609679222107 2022-05-29 18:28:42.503705
Epoch:[ 148 6 ] loss: 0.4035239815711975 2022-05-29 18:28:43.279258
Epoch:[ 148 7 ] loss: 0.4085507392883301 2022-05-29 18:28:44.057958
Epoch:[ 148 8 ] loss: 0.4044630527496338 2022-05-29 18:28:44.835159
Epoch:[ 148 9 ] loss: 0.4062674939632416 2022-05-29 18:28:45.608788
Epoch:[ 148 10 ] loss: 0.4029620587825775 2022-05-29 18:28:46.385247
Epoch:[ 148 11 ] loss: 0.40217408537864685 2022-05-29 18:28:47.159919
Epoch:[ 148 12 ] loss: 0.40370839834213257 2022-05-29 18:28:47.937745
Epoch:[ 148 13 ] loss: 0.40505117177963257 2022-05-29 18:28:48.714571
Epoch:[ 148 14 ] loss: 0.40602371096611023 2022-05-29 18:28:49.493178
Epoch:[ 148 15 ] loss: 0.4067898392677307 2022-05-29 18:28:50.268345
Epoch:[ 148 16 ] loss: 0.40341633558273315 2022-05-29 18:28:57.026528
Epoch:[ 148 17 ] loss: 0.4031151235103607 2022-05-29 18:28:57.812571
Epoch:[ 148 18 ] loss: 0.4066615700721741 2022-05-29 18:28:58.591533
Epoch:[ 148 19 ] loss: 0.40653690695762634 2022-05-29 18:28:59.367628
Training_Epoch:[ 148 ] Training_loss: 0.40480681210756303 2022-05-29 18:28:59.368273
learning rate:  1.7592186044416018e-05
netparams have been saved once 148
val: 1 0.5431002974510193
val: 2 0.5453267097473145
val: 3 0.5306756496429443
val: 4 0.5400481224060059
val: 5 0.5395094752311707
val: 6 0.5187292098999023
val: 7 0.5293636918067932
val: 8 0.5527382493019104
val: 9 0.5242091417312622
val: 10 0.554597020149231
val: 11 0.5339793562889099
val: 12 0.5278484225273132
val: 13 0.5398311018943787
val: 14 0.5401497483253479
val: 15 0.5335561037063599
val: 16 0.5525773167610168
val: 17 0.5351963639259338
val: 18 0.5428133606910706
val: 19 0.5266938805580139
val: 20 0.5449292063713074
val_Epoch:[ 148 ] val_loss: 0.5377936214208603 2022-05-29 18:29:04.753062
start training 2022-05-29 18:29:04.855214
Epoch:[ 149 0 ] loss: 0.4040817320346832 2022-05-29 18:29:27.502783
Epoch:[ 149 1 ] loss: 0.40962961316108704 2022-05-29 18:29:28.582123
Epoch:[ 149 2 ] loss: 0.40465784072875977 2022-05-29 18:29:29.385818
Epoch:[ 149 3 ] loss: 0.40548115968704224 2022-05-29 18:29:30.160769
Epoch:[ 149 4 ] loss: 0.4094441831111908 2022-05-29 18:29:30.939271
Epoch:[ 149 5 ] loss: 0.4026069641113281 2022-05-29 18:29:31.714912
Epoch:[ 149 6 ] loss: 0.4043422043323517 2022-05-29 18:29:32.492837
Epoch:[ 149 7 ] loss: 0.4027236998081207 2022-05-29 18:29:33.273093
Epoch:[ 149 8 ] loss: 0.405561625957489 2022-05-29 18:29:34.059626
Epoch:[ 149 9 ] loss: 0.4040367007255554 2022-05-29 18:29:34.838370
Epoch:[ 149 10 ] loss: 0.405181348323822 2022-05-29 18:29:35.613929
Epoch:[ 149 11 ] loss: 0.40262821316719055 2022-05-29 18:29:36.390153
Epoch:[ 149 12 ] loss: 0.4033062160015106 2022-05-29 18:29:37.166048
Epoch:[ 149 13 ] loss: 0.4054010212421417 2022-05-29 18:29:37.945144
Epoch:[ 149 14 ] loss: 0.4040910601615906 2022-05-29 18:29:38.725740
Epoch:[ 149 15 ] loss: 0.4071930944919586 2022-05-29 18:29:39.514163
Epoch:[ 149 16 ] loss: 0.40642985701560974 2022-05-29 18:29:47.064101
Epoch:[ 149 17 ] loss: 0.40097901225090027 2022-05-29 18:29:47.850077
Epoch:[ 149 18 ] loss: 0.40251195430755615 2022-05-29 18:29:48.629428
Epoch:[ 149 19 ] loss: 0.40325936675071716 2022-05-29 18:29:49.404908
Training_Epoch:[ 149 ] Training_loss: 0.4046773433685303 2022-05-29 18:29:49.405663
learning rate:  1.7592186044416018e-05
val: 1 0.5427024364471436
val: 2 0.5466733574867249
val: 3 0.5480198860168457
val: 4 0.5527260303497314
val: 5 0.5180262923240662
val: 6 0.5388240814208984
val: 7 0.5527753233909607
val: 8 0.5340961217880249
val: 9 0.5435250401496887
val: 10 0.5433692336082458
val: 11 0.5483009815216064
val: 12 0.5332431793212891
val: 13 0.5275128483772278
val: 14 0.5298118591308594
val: 15 0.5326899886131287
val: 16 0.528255820274353
val: 17 0.5247399210929871
val: 18 0.538086473941803
val: 19 0.5648671388626099
val: 20 0.5230299234390259
val_Epoch:[ 149 ] val_loss: 0.538563796877861 2022-05-29 18:29:54.635795
start training 2022-05-29 18:29:54.736266
Epoch:[ 150 0 ] loss: 0.404188334941864 2022-05-29 18:30:18.869351
Epoch:[ 150 1 ] loss: 0.40564048290252686 2022-05-29 18:30:19.649570
Epoch:[ 150 2 ] loss: 0.40640658140182495 2022-05-29 18:30:20.430116
Epoch:[ 150 3 ] loss: 0.40314722061157227 2022-05-29 18:30:21.206934
Epoch:[ 150 4 ] loss: 0.4033639430999756 2022-05-29 18:30:21.994587
Epoch:[ 150 5 ] loss: 0.40228307247161865 2022-05-29 18:30:22.770358
Epoch:[ 150 6 ] loss: 0.4069112241268158 2022-05-29 18:30:23.545751
Epoch:[ 150 7 ] loss: 0.40150386095046997 2022-05-29 18:30:24.324178
Epoch:[ 150 8 ] loss: 0.4030110538005829 2022-05-29 18:30:25.103164
Epoch:[ 150 9 ] loss: 0.4034216105937958 2022-05-29 18:30:25.879247
Epoch:[ 150 10 ] loss: 0.40645045042037964 2022-05-29 18:30:26.669309
Epoch:[ 150 11 ] loss: 0.40868040919303894 2022-05-29 18:30:27.445535
Epoch:[ 150 12 ] loss: 0.40467914938926697 2022-05-29 18:30:28.221787
Epoch:[ 150 13 ] loss: 0.40177619457244873 2022-05-29 18:30:28.996701
Epoch:[ 150 14 ] loss: 0.40469011664390564 2022-05-29 18:30:29.775150
Epoch:[ 150 15 ] loss: 0.40601846575737 2022-05-29 18:30:30.566280
Epoch:[ 150 16 ] loss: 0.4040522575378418 2022-05-29 18:30:37.166702
Epoch:[ 150 17 ] loss: 0.40579235553741455 2022-05-29 18:30:37.942711
Epoch:[ 150 18 ] loss: 0.4081299304962158 2022-05-29 18:30:38.720706
Epoch:[ 150 19 ] loss: 0.4078182578086853 2022-05-29 18:30:39.505342
Training_Epoch:[ 150 ] Training_loss: 0.4048982486128807 2022-05-29 18:30:39.506068
learning rate:  1.7592186044416018e-05
netparams have been saved once 150
val: 1 0.5359225869178772
val: 2 0.5328986644744873
val: 3 0.5328631401062012
val: 4 0.525149941444397
val: 5 0.5344083905220032
val: 6 0.5365310907363892
val: 7 0.531559944152832
val: 8 0.5550910830497742
val: 9 0.5357581377029419
val: 10 0.5298928022384644
val: 11 0.542780876159668
val: 12 0.5350701808929443
val: 13 0.5392166972160339
val: 14 0.5407218337059021
val: 15 0.5399277210235596
val: 16 0.5399441719055176
val: 17 0.5407583117485046
val: 18 0.5573921799659729
val: 19 0.521600604057312
val: 20 0.5572303533554077
val_Epoch:[ 150 ] val_loss: 0.5382359355688096 2022-05-29 18:30:44.809087
start training 2022-05-29 18:30:44.913643
Epoch:[ 151 0 ] loss: 0.4037466049194336 2022-05-29 18:31:07.579886
Epoch:[ 151 1 ] loss: 0.40467414259910583 2022-05-29 18:31:08.445928
Epoch:[ 151 2 ] loss: 0.4005223214626312 2022-05-29 18:31:09.223101
Epoch:[ 151 3 ] loss: 0.40656548738479614 2022-05-29 18:31:10.000867
Epoch:[ 151 4 ] loss: 0.4049277901649475 2022-05-29 18:31:10.779508
Epoch:[ 151 5 ] loss: 0.4080258011817932 2022-05-29 18:31:11.553271
Epoch:[ 151 6 ] loss: 0.4003629684448242 2022-05-29 18:31:12.326949
Epoch:[ 151 7 ] loss: 0.4073541462421417 2022-05-29 18:31:13.101146
Epoch:[ 151 8 ] loss: 0.40321001410484314 2022-05-29 18:31:13.891755
Epoch:[ 151 9 ] loss: 0.40470126271247864 2022-05-29 18:31:14.669077
Epoch:[ 151 10 ] loss: 0.4043930768966675 2022-05-29 18:31:15.458308
Epoch:[ 151 11 ] loss: 0.4098770022392273 2022-05-29 18:31:16.236937
Epoch:[ 151 12 ] loss: 0.4044720232486725 2022-05-29 18:31:17.012529
Epoch:[ 151 13 ] loss: 0.4051957428455353 2022-05-29 18:31:17.802813
Epoch:[ 151 14 ] loss: 0.4040006995201111 2022-05-29 18:31:18.578271
Epoch:[ 151 15 ] loss: 0.40042710304260254 2022-05-29 18:31:19.356177
Epoch:[ 151 16 ] loss: 0.40308135747909546 2022-05-29 18:31:27.020463
Epoch:[ 151 17 ] loss: 0.4062592089176178 2022-05-29 18:31:27.798621
Epoch:[ 151 18 ] loss: 0.4027225971221924 2022-05-29 18:31:28.590196
Epoch:[ 151 19 ] loss: 0.4049626588821411 2022-05-29 18:31:29.377133
Training_Epoch:[ 151 ] Training_loss: 0.4044741004705429 2022-05-29 18:31:29.377973
learning rate:  1.4073748835532815e-05
val: 1 0.5506961345672607
val: 2 0.546488881111145
val: 3 0.5216635465621948
val: 4 0.5408639311790466
val: 5 0.5377674102783203
val: 6 0.5379852056503296
val: 7 0.5345699787139893
val: 8 0.5449791550636292
val: 9 0.526390016078949
val: 10 0.5380840301513672
val: 11 0.5513644218444824
val: 12 0.5209043622016907
val: 13 0.5515851378440857
val: 14 0.5278565287590027
val: 15 0.5303306579589844
val: 16 0.5428624153137207
val: 17 0.5191120505332947
val: 18 0.5401286482810974
val: 19 0.5642165541648865
val: 20 0.5436007380485535
val_Epoch:[ 151 ] val_loss: 0.5385724902153015 2022-05-29 18:31:34.604678
start training 2022-05-29 18:31:34.706192
Epoch:[ 152 0 ] loss: 0.4019797146320343 2022-05-29 18:31:58.149667
Epoch:[ 152 1 ] loss: 0.4017244577407837 2022-05-29 18:31:58.924265
Epoch:[ 152 2 ] loss: 0.40522268414497375 2022-05-29 18:31:59.700819
Epoch:[ 152 3 ] loss: 0.4042615592479706 2022-05-29 18:32:00.478221
Epoch:[ 152 4 ] loss: 0.40168997645378113 2022-05-29 18:32:01.254070
Epoch:[ 152 5 ] loss: 0.406981885433197 2022-05-29 18:32:02.030775
Epoch:[ 152 6 ] loss: 0.4037524163722992 2022-05-29 18:32:02.817005
Epoch:[ 152 7 ] loss: 0.40357187390327454 2022-05-29 18:32:03.589789
Epoch:[ 152 8 ] loss: 0.4064013957977295 2022-05-29 18:32:04.366259
Epoch:[ 152 9 ] loss: 0.40702512860298157 2022-05-29 18:32:05.143895
Epoch:[ 152 10 ] loss: 0.40087753534317017 2022-05-29 18:32:05.921598
Epoch:[ 152 11 ] loss: 0.40374860167503357 2022-05-29 18:32:06.696400
Epoch:[ 152 12 ] loss: 0.40596649050712585 2022-05-29 18:32:07.473709
Epoch:[ 152 13 ] loss: 0.4061312973499298 2022-05-29 18:32:08.260424
Epoch:[ 152 14 ] loss: 0.4036378860473633 2022-05-29 18:32:09.036906
Epoch:[ 152 15 ] loss: 0.4038901925086975 2022-05-29 18:32:09.823487
Epoch:[ 152 16 ] loss: 0.40660056471824646 2022-05-29 18:32:17.089237
Epoch:[ 152 17 ] loss: 0.40590760111808777 2022-05-29 18:32:17.866701
Epoch:[ 152 18 ] loss: 0.4086943566799164 2022-05-29 18:32:18.649117
Epoch:[ 152 19 ] loss: 0.4025092124938965 2022-05-29 18:32:19.436901
Training_Epoch:[ 152 ] Training_loss: 0.40452874153852464 2022-05-29 18:32:19.437571
learning rate:  1.4073748835532815e-05
netparams have been saved once 152
val: 1 0.5288308262825012
val: 2 0.5353882908821106
val: 3 0.5278398990631104
val: 4 0.5474345088005066
val: 5 0.5435143113136292
val: 6 0.5482213497161865
val: 7 0.5386967062950134
val: 8 0.5160223841667175
val: 9 0.542491614818573
val: 10 0.5504125356674194
val: 11 0.5303240418434143
val: 12 0.5323129892349243
val: 13 0.5414510369300842
val: 14 0.5537747144699097
val: 15 0.506873369216919
val: 16 0.5398339033126831
val: 17 0.5279808044433594
val: 18 0.5415990948677063
val: 19 0.5531425476074219
val: 20 0.5414390563964844
val_Epoch:[ 152 ] val_loss: 0.5373791992664337 2022-05-29 18:32:24.792798
start training 2022-05-29 18:32:24.892745
Epoch:[ 153 0 ] loss: 0.40566661953926086 2022-05-29 18:32:47.026828
Epoch:[ 153 1 ] loss: 0.4038911759853363 2022-05-29 18:32:47.856701
Epoch:[ 153 2 ] loss: 0.40503981709480286 2022-05-29 18:32:48.820390
Epoch:[ 153 3 ] loss: 0.40342292189598083 2022-05-29 18:32:49.596646
Epoch:[ 153 4 ] loss: 0.4062877595424652 2022-05-29 18:32:50.374935
Epoch:[ 153 5 ] loss: 0.40375757217407227 2022-05-29 18:32:51.149777
Epoch:[ 153 6 ] loss: 0.4062296748161316 2022-05-29 18:32:51.927435
Epoch:[ 153 7 ] loss: 0.40601739287376404 2022-05-29 18:32:52.700782
Epoch:[ 153 8 ] loss: 0.4047582745552063 2022-05-29 18:32:53.475193
Epoch:[ 153 9 ] loss: 0.40040239691734314 2022-05-29 18:32:54.260081
Epoch:[ 153 10 ] loss: 0.4030533730983734 2022-05-29 18:32:55.038215
Epoch:[ 153 11 ] loss: 0.40260910987854004 2022-05-29 18:32:55.825387
Epoch:[ 153 12 ] loss: 0.40131914615631104 2022-05-29 18:32:56.601692
Epoch:[ 153 13 ] loss: 0.40460437536239624 2022-05-29 18:32:57.378495
Epoch:[ 153 14 ] loss: 0.4016721844673157 2022-05-29 18:32:58.152957
Epoch:[ 153 15 ] loss: 0.40846219658851624 2022-05-29 18:32:58.939369
Epoch:[ 153 16 ] loss: 0.404413104057312 2022-05-29 18:33:07.264325
Epoch:[ 153 17 ] loss: 0.40858161449432373 2022-05-29 18:33:08.041282
Epoch:[ 153 18 ] loss: 0.404823899269104 2022-05-29 18:33:08.847659
Epoch:[ 153 19 ] loss: 0.40648844838142395 2022-05-29 18:33:09.623011
Training_Epoch:[ 153 ] Training_loss: 0.404575052857399 2022-05-29 18:33:09.623699
learning rate:  1.4073748835532815e-05
val: 1 0.5414198040962219
val: 2 0.5506197214126587
val: 3 0.5327231884002686
val: 4 0.5288751721382141
val: 5 0.5309621095657349
val: 6 0.5389630198478699
val: 7 0.5365316271781921
val: 8 0.5400809049606323
val: 9 0.5402927398681641
val: 10 0.5507734417915344
val: 11 0.5430981516838074
val: 12 0.5483098030090332
val: 13 0.5460578203201294
val: 14 0.5240611433982849
val: 15 0.5184139609336853
val: 16 0.5547129511833191
val: 17 0.5437659621238708
val: 18 0.5366315841674805
val: 19 0.5203746557235718
val: 20 0.5363261103630066
val_Epoch:[ 153 ] val_loss: 0.538149693608284 2022-05-29 18:33:14.773690
start training 2022-05-29 18:33:14.875320
Epoch:[ 154 0 ] loss: 0.40380117297172546 2022-05-29 18:33:38.667690
Epoch:[ 154 1 ] loss: 0.40436261892318726 2022-05-29 18:33:39.441135
Epoch:[ 154 2 ] loss: 0.40925541520118713 2022-05-29 18:33:40.227506
Epoch:[ 154 3 ] loss: 0.4054921865463257 2022-05-29 18:33:41.001722
Epoch:[ 154 4 ] loss: 0.40525203943252563 2022-05-29 18:33:41.779516
Epoch:[ 154 5 ] loss: 0.40132832527160645 2022-05-29 18:33:42.555436
Epoch:[ 154 6 ] loss: 0.40439286828041077 2022-05-29 18:33:43.330963
Epoch:[ 154 7 ] loss: 0.4037889540195465 2022-05-29 18:33:44.119948
Epoch:[ 154 8 ] loss: 0.4030078947544098 2022-05-29 18:33:44.907105
Epoch:[ 154 9 ] loss: 0.4041807949542999 2022-05-29 18:33:45.682399
Epoch:[ 154 10 ] loss: 0.40378740429878235 2022-05-29 18:33:46.457007
Epoch:[ 154 11 ] loss: 0.40480032563209534 2022-05-29 18:33:47.233741
Epoch:[ 154 12 ] loss: 0.40641915798187256 2022-05-29 18:33:48.011969
Epoch:[ 154 13 ] loss: 0.40585553646087646 2022-05-29 18:33:48.790851
Epoch:[ 154 14 ] loss: 0.40199586749076843 2022-05-29 18:33:49.567381
Epoch:[ 154 15 ] loss: 0.40614446997642517 2022-05-29 18:33:50.341371
Epoch:[ 154 16 ] loss: 0.4037576913833618 2022-05-29 18:33:57.982024
Epoch:[ 154 17 ] loss: 0.40654289722442627 2022-05-29 18:33:58.766876
Epoch:[ 154 18 ] loss: 0.4037187695503235 2022-05-29 18:33:59.555194
Epoch:[ 154 19 ] loss: 0.4028242528438568 2022-05-29 18:34:00.330418
Training_Epoch:[ 154 ] Training_loss: 0.4045354321599007 2022-05-29 18:34:00.331094
learning rate:  1.4073748835532815e-05
netparams have been saved once 154
val: 1 0.5573930740356445
val: 2 0.5442419648170471
val: 3 0.521420955657959
val: 4 0.5324606895446777
val: 5 0.5403158068656921
val: 6 0.5384975671768188
val: 7 0.5498397350311279
val: 8 0.5156423449516296
val: 9 0.5319216847419739
val: 10 0.5532835125923157
val: 11 0.539027750492096
val: 12 0.5298388600349426
val: 13 0.5297660231590271
val: 14 0.5446364283561707
val: 15 0.5550429224967957
val: 16 0.5319311618804932
val: 17 0.5328022837638855
val: 18 0.5363250374794006
val: 19 0.5424861311912537
val: 20 0.5557567477226257
val_Epoch:[ 154 ] val_loss: 0.5391315340995788 2022-05-29 18:34:05.724704
start training 2022-05-29 18:34:05.829041
Epoch:[ 155 0 ] loss: 0.4043722450733185 2022-05-29 18:34:27.803175
Epoch:[ 155 1 ] loss: 0.4039677381515503 2022-05-29 18:34:28.637043
Epoch:[ 155 2 ] loss: 0.40530940890312195 2022-05-29 18:34:29.480218
Epoch:[ 155 3 ] loss: 0.4037136435508728 2022-05-29 18:34:30.269009
Epoch:[ 155 4 ] loss: 0.40418416261672974 2022-05-29 18:34:31.042685
Epoch:[ 155 5 ] loss: 0.40163928270339966 2022-05-29 18:34:31.819925
Epoch:[ 155 6 ] loss: 0.40890613198280334 2022-05-29 18:34:32.598064
Epoch:[ 155 7 ] loss: 0.3978813886642456 2022-05-29 18:34:33.372445
Epoch:[ 155 8 ] loss: 0.40240439772605896 2022-05-29 18:34:34.150851
Epoch:[ 155 9 ] loss: 0.4024280607700348 2022-05-29 18:34:34.925017
Epoch:[ 155 10 ] loss: 0.4059777855873108 2022-05-29 18:34:35.714261
Epoch:[ 155 11 ] loss: 0.40410125255584717 2022-05-29 18:34:36.489939
Epoch:[ 155 12 ] loss: 0.40577009320259094 2022-05-29 18:34:37.265369
Epoch:[ 155 13 ] loss: 0.4054775536060333 2022-05-29 18:34:38.054930
Epoch:[ 155 14 ] loss: 0.4027145504951477 2022-05-29 18:34:38.834324
Epoch:[ 155 15 ] loss: 0.4037810266017914 2022-05-29 18:34:39.613456
Epoch:[ 155 16 ] loss: 0.40729188919067383 2022-05-29 18:34:47.739151
Epoch:[ 155 17 ] loss: 0.4052148461341858 2022-05-29 18:34:48.525148
Epoch:[ 155 18 ] loss: 0.4029296040534973 2022-05-29 18:34:49.314185
Epoch:[ 155 19 ] loss: 0.4122942388057709 2022-05-29 18:34:50.091462
Training_Epoch:[ 155 ] Training_loss: 0.40451796501874926 2022-05-29 18:34:50.092152
learning rate:  1.4073748835532815e-05
val: 1 0.5357941389083862
val: 2 0.5306404232978821
val: 3 0.5507936477661133
val: 4 0.5437300205230713
val: 5 0.5587896704673767
val: 6 0.528948187828064
val: 7 0.5351134538650513
val: 8 0.5466454029083252
val: 9 0.5498083829879761
val: 10 0.5322204232215881
val: 11 0.5414513945579529
val: 12 0.5484040975570679
val: 13 0.5311911106109619
val: 14 0.5498039722442627
val: 15 0.5418591499328613
val: 16 0.5303483605384827
val: 17 0.5565102696418762
val: 18 0.5311118364334106
val: 19 0.5304415225982666
val: 20 0.5071890950202942
val_Epoch:[ 155 ] val_loss: 0.5390397280454635 2022-05-29 18:34:55.284107
start training 2022-05-29 18:34:55.386011
Epoch:[ 156 0 ] loss: 0.4038763642311096 2022-05-29 18:35:18.118922
Epoch:[ 156 1 ] loss: 0.4031490683555603 2022-05-29 18:35:18.968417
Epoch:[ 156 2 ] loss: 0.405076265335083 2022-05-29 18:35:19.742640
Epoch:[ 156 3 ] loss: 0.4033055305480957 2022-05-29 18:35:20.515794
Epoch:[ 156 4 ] loss: 0.40759938955307007 2022-05-29 18:35:21.289252
Epoch:[ 156 5 ] loss: 0.40186408162117004 2022-05-29 18:35:22.061889
Epoch:[ 156 6 ] loss: 0.40392205119132996 2022-05-29 18:35:22.838741
Epoch:[ 156 7 ] loss: 0.40704646706581116 2022-05-29 18:35:23.628164
Epoch:[ 156 8 ] loss: 0.40348824858665466 2022-05-29 18:35:24.403938
Epoch:[ 156 9 ] loss: 0.4059998393058777 2022-05-29 18:35:25.191576
Epoch:[ 156 10 ] loss: 0.4052152633666992 2022-05-29 18:35:25.966874
Epoch:[ 156 11 ] loss: 0.40218061208724976 2022-05-29 18:35:26.743840
Epoch:[ 156 12 ] loss: 0.40463706851005554 2022-05-29 18:35:27.516311
Epoch:[ 156 13 ] loss: 0.40269744396209717 2022-05-29 18:35:28.295516
Epoch:[ 156 14 ] loss: 0.4086111783981323 2022-05-29 18:35:29.083398
Epoch:[ 156 15 ] loss: 0.4028891623020172 2022-05-29 18:35:29.861930
Epoch:[ 156 16 ] loss: 0.40487581491470337 2022-05-29 18:35:37.897338
Epoch:[ 156 17 ] loss: 0.4036143124103546 2022-05-29 18:35:38.671916
Epoch:[ 156 18 ] loss: 0.40520498156547546 2022-05-29 18:35:39.463370
Epoch:[ 156 19 ] loss: 0.40280264616012573 2022-05-29 18:35:40.236994
Training_Epoch:[ 156 ] Training_loss: 0.40440278947353364 2022-05-29 18:35:40.237668
learning rate:  1.4073748835532815e-05
netparams have been saved once 156
val: 1 0.5496509671211243
val: 2 0.5203017592430115
val: 3 0.5481559634208679
val: 4 0.529816210269928
val: 5 0.5264129042625427
val: 6 0.5513051748275757
val: 7 0.5516026616096497
val: 8 0.5322874188423157
val: 9 0.5481040477752686
val: 10 0.520760178565979
val: 11 0.5204596519470215
val: 12 0.528232753276825
val: 13 0.546590268611908
val: 14 0.5361186861991882
val: 15 0.5398692488670349
val: 16 0.5433542728424072
val: 17 0.5263312458992004
val: 18 0.5496834516525269
val: 19 0.5457225441932678
val: 20 0.5307542681694031
val_Epoch:[ 156 ] val_loss: 0.5372756838798523 2022-05-29 18:35:45.595063
start training 2022-05-29 18:35:45.699901
Epoch:[ 157 0 ] loss: 0.40597519278526306 2022-05-29 18:36:07.906553
Epoch:[ 157 1 ] loss: 0.4074344038963318 2022-05-29 18:36:08.974457
Epoch:[ 157 2 ] loss: 0.4038074314594269 2022-05-29 18:36:09.751659
Epoch:[ 157 3 ] loss: 0.4048914611339569 2022-05-29 18:36:10.528235
Epoch:[ 157 4 ] loss: 0.40263238549232483 2022-05-29 18:36:11.301917
Epoch:[ 157 5 ] loss: 0.40332818031311035 2022-05-29 18:36:12.079598
Epoch:[ 157 6 ] loss: 0.40416181087493896 2022-05-29 18:36:12.853585
Epoch:[ 157 7 ] loss: 0.40258389711380005 2022-05-29 18:36:13.644220
Epoch:[ 157 8 ] loss: 0.40010973811149597 2022-05-29 18:36:14.420814
Epoch:[ 157 9 ] loss: 0.4016752243041992 2022-05-29 18:36:15.198470
Epoch:[ 157 10 ] loss: 0.40608280897140503 2022-05-29 18:36:15.976172
Epoch:[ 157 11 ] loss: 0.4016791880130768 2022-05-29 18:36:16.751540
Epoch:[ 157 12 ] loss: 0.4077918529510498 2022-05-29 18:36:17.538727
Epoch:[ 157 13 ] loss: 0.4055308699607849 2022-05-29 18:36:18.325855
Epoch:[ 157 14 ] loss: 0.40299466252326965 2022-05-29 18:36:19.103405
Epoch:[ 157 15 ] loss: 0.40646612644195557 2022-05-29 18:36:19.881444
Epoch:[ 157 16 ] loss: 0.4084649085998535 2022-05-29 18:36:27.850476
Epoch:[ 157 17 ] loss: 0.4026598036289215 2022-05-29 18:36:28.639964
Epoch:[ 157 18 ] loss: 0.4046275317668915 2022-05-29 18:36:29.430380
Epoch:[ 157 19 ] loss: 0.4038834571838379 2022-05-29 18:36:30.206336
Training_Epoch:[ 157 ] Training_loss: 0.40433904677629473 2022-05-29 18:36:30.207043
learning rate:  1.4073748835532815e-05
val: 1 0.5259488821029663
val: 2 0.5490471720695496
val: 3 0.5382252931594849
val: 4 0.5380133986473083
val: 5 0.5313864350318909
val: 6 0.5416296720504761
val: 7 0.5364270806312561
val: 8 0.5328962802886963
val: 9 0.5425465703010559
val: 10 0.5265557765960693
val: 11 0.5423860549926758
val: 12 0.5341722965240479
val: 13 0.550226628780365
val: 14 0.5311723351478577
val: 15 0.5403690934181213
val: 16 0.5333604216575623
val: 17 0.5374990701675415
val: 18 0.5415196418762207
val: 19 0.539476215839386
val: 20 0.5416179299354553
val_Epoch:[ 157 ] val_loss: 0.5377238124608994 2022-05-29 18:36:35.434432
start training 2022-05-29 18:36:35.535554
Epoch:[ 158 0 ] loss: 0.4015733301639557 2022-05-29 18:36:57.686959
Epoch:[ 158 1 ] loss: 0.4032018482685089 2022-05-29 18:36:58.538707
Epoch:[ 158 2 ] loss: 0.40160414576530457 2022-05-29 18:36:59.352360
Epoch:[ 158 3 ] loss: 0.4035101532936096 2022-05-29 18:37:00.129924
Epoch:[ 158 4 ] loss: 0.4078080952167511 2022-05-29 18:37:00.906868
Epoch:[ 158 5 ] loss: 0.40409278869628906 2022-05-29 18:37:01.694880
Epoch:[ 158 6 ] loss: 0.4076288938522339 2022-05-29 18:37:02.468452
Epoch:[ 158 7 ] loss: 0.40372875332832336 2022-05-29 18:37:03.245140
Epoch:[ 158 8 ] loss: 0.39957112073898315 2022-05-29 18:37:04.022210
Epoch:[ 158 9 ] loss: 0.40351206064224243 2022-05-29 18:37:04.811608
Epoch:[ 158 10 ] loss: 0.40700796246528625 2022-05-29 18:37:05.590423
Epoch:[ 158 11 ] loss: 0.4081205427646637 2022-05-29 18:37:06.368403
Epoch:[ 158 12 ] loss: 0.40175196528434753 2022-05-29 18:37:07.153565
Epoch:[ 158 13 ] loss: 0.4050595462322235 2022-05-29 18:37:07.931225
Epoch:[ 158 14 ] loss: 0.40635520219802856 2022-05-29 18:37:08.706550
Epoch:[ 158 15 ] loss: 0.40524259209632874 2022-05-29 18:37:09.484939
Epoch:[ 158 16 ] loss: 0.4045281708240509 2022-05-29 18:37:17.562356
Epoch:[ 158 17 ] loss: 0.40641701221466064 2022-05-29 18:37:18.338060
Epoch:[ 158 18 ] loss: 0.4039026200771332 2022-05-29 18:37:19.129928
Epoch:[ 158 19 ] loss: 0.4059849977493286 2022-05-29 18:37:19.905313
Training_Epoch:[ 158 ] Training_loss: 0.4045300900936127 2022-05-29 18:37:19.906049
learning rate:  1.4073748835532815e-05
netparams have been saved once 158
val: 1 0.5319956541061401
val: 2 0.5461212992668152
val: 3 0.5423638224601746
val: 4 0.5400665998458862
val: 5 0.5675214529037476
val: 6 0.5294272899627686
val: 7 0.5436998605728149
val: 8 0.5257986783981323
val: 9 0.5598474144935608
val: 10 0.5281146764755249
val: 11 0.5422455072402954
val: 12 0.5208838582038879
val: 13 0.561514675617218
val: 14 0.5189909934997559
val: 15 0.5276631712913513
val: 16 0.5350123047828674
val: 17 0.531888484954834
val: 18 0.5324483513832092
val: 19 0.5459785461425781
val: 20 0.5395294427871704
val_Epoch:[ 158 ] val_loss: 0.5385556042194366 2022-05-29 18:37:25.270803
start training 2022-05-29 18:37:25.373518
Epoch:[ 159 0 ] loss: 0.40217161178588867 2022-05-29 18:37:49.226155
Epoch:[ 159 1 ] loss: 0.4074198007583618 2022-05-29 18:37:49.999176
Epoch:[ 159 2 ] loss: 0.4040006399154663 2022-05-29 18:37:50.774794
Epoch:[ 159 3 ] loss: 0.40372759103775024 2022-05-29 18:37:51.563227
Epoch:[ 159 4 ] loss: 0.4042940139770508 2022-05-29 18:37:52.338928
Epoch:[ 159 5 ] loss: 0.40378743410110474 2022-05-29 18:37:53.115080
Epoch:[ 159 6 ] loss: 0.4026046693325043 2022-05-29 18:37:53.900827
Epoch:[ 159 7 ] loss: 0.40363362431526184 2022-05-29 18:37:54.675997
Epoch:[ 159 8 ] loss: 0.40289366245269775 2022-05-29 18:37:55.451986
Epoch:[ 159 9 ] loss: 0.40387189388275146 2022-05-29 18:37:56.231231
Epoch:[ 159 10 ] loss: 0.40622377395629883 2022-05-29 18:37:57.022164
Epoch:[ 159 11 ] loss: 0.4040008783340454 2022-05-29 18:37:57.799486
Epoch:[ 159 12 ] loss: 0.40721964836120605 2022-05-29 18:37:58.577102
Epoch:[ 159 13 ] loss: 0.4058322310447693 2022-05-29 18:37:59.351276
Epoch:[ 159 14 ] loss: 0.4030286967754364 2022-05-29 18:38:00.124465
Epoch:[ 159 15 ] loss: 0.40091270208358765 2022-05-29 18:38:00.897384
Epoch:[ 159 16 ] loss: 0.40581879019737244 2022-05-29 18:38:07.450720
Epoch:[ 159 17 ] loss: 0.40705668926239014 2022-05-29 18:38:08.225775
Epoch:[ 159 18 ] loss: 0.4065265357494354 2022-05-29 18:38:09.016079
Epoch:[ 159 19 ] loss: 0.4038952887058258 2022-05-29 18:38:09.792731
Training_Epoch:[ 159 ] Training_loss: 0.40444600880146026 2022-05-29 18:38:09.793403
learning rate:  1.4073748835532815e-05
val: 1 0.5346558690071106
val: 2 0.5459982752799988
val: 3 0.5352118015289307
val: 4 0.5240219235420227
val: 5 0.5250251889228821
val: 6 0.5452527403831482
val: 7 0.5428282618522644
val: 8 0.5398337841033936
val: 9 0.5460390448570251
val: 10 0.5254951119422913
val: 11 0.5439180135726929
val: 12 0.557292103767395
val: 13 0.5313831567764282
val: 14 0.5403683185577393
val: 15 0.5184866786003113
val: 16 0.5429421663284302
val: 17 0.5337702631950378
val: 18 0.5390266180038452
val: 19 0.5393236875534058
val: 20 0.5358178615570068
val_Epoch:[ 159 ] val_loss: 0.537334543466568 2022-05-29 18:38:14.976241
start training 2022-05-29 18:38:15.081705
Epoch:[ 160 0 ] loss: 0.4018552005290985 2022-05-29 18:38:37.311266
Epoch:[ 160 1 ] loss: 0.4040955603122711 2022-05-29 18:38:38.120195
Epoch:[ 160 2 ] loss: 0.407850056886673 2022-05-29 18:38:38.931187
Epoch:[ 160 3 ] loss: 0.40793031454086304 2022-05-29 18:38:39.718981
Epoch:[ 160 4 ] loss: 0.4080384075641632 2022-05-29 18:38:40.494527
Epoch:[ 160 5 ] loss: 0.4049357771873474 2022-05-29 18:38:41.270627
Epoch:[ 160 6 ] loss: 0.40040892362594604 2022-05-29 18:38:42.047579
Epoch:[ 160 7 ] loss: 0.40188518166542053 2022-05-29 18:38:42.821077
Epoch:[ 160 8 ] loss: 0.4070115089416504 2022-05-29 18:38:43.596186
Epoch:[ 160 9 ] loss: 0.4045705795288086 2022-05-29 18:38:44.368975
Epoch:[ 160 10 ] loss: 0.4043022096157074 2022-05-29 18:38:45.145962
Epoch:[ 160 11 ] loss: 0.40316909551620483 2022-05-29 18:38:45.923943
Epoch:[ 160 12 ] loss: 0.4073505997657776 2022-05-29 18:38:46.702155
Epoch:[ 160 13 ] loss: 0.40312281250953674 2022-05-29 18:38:47.480898
Epoch:[ 160 14 ] loss: 0.40383321046829224 2022-05-29 18:38:48.266629
Epoch:[ 160 15 ] loss: 0.40482044219970703 2022-05-29 18:38:49.041341
Epoch:[ 160 16 ] loss: 0.40257638692855835 2022-05-29 18:38:57.116333
Epoch:[ 160 17 ] loss: 0.407774955034256 2022-05-29 18:38:57.893165
Epoch:[ 160 18 ] loss: 0.3999933898448944 2022-05-29 18:38:58.673043
Epoch:[ 160 19 ] loss: 0.4031178653240204 2022-05-29 18:38:59.462608
Training_Epoch:[ 160 ] Training_loss: 0.4044321238994598 2022-05-29 18:38:59.463251
learning rate:  1.4073748835532815e-05
netparams have been saved once 160
val: 1 0.5162150263786316
val: 2 0.5213777422904968
val: 3 0.5527414083480835
val: 4 0.5397366285324097
val: 5 0.5438908338546753
val: 6 0.5445932745933533
val: 7 0.5058618783950806
val: 8 0.5435117483139038
val: 9 0.5435606837272644
val: 10 0.5230122208595276
val: 11 0.5544230341911316
val: 12 0.5207030773162842
val: 13 0.5370135307312012
val: 14 0.556581974029541
val: 15 0.5464672446250916
val: 16 0.5377261638641357
val: 17 0.548530638217926
val: 18 0.5302217602729797
val: 19 0.5506851673126221
val: 20 0.5497937798500061
val_Epoch:[ 160 ] val_loss: 0.5383323907852173 2022-05-29 18:39:04.793612
start training 2022-05-29 18:39:04.897970
Epoch:[ 161 0 ] loss: 0.4014706611633301 2022-05-29 18:39:27.302050
Epoch:[ 161 1 ] loss: 0.4042683243751526 2022-05-29 18:39:28.135901
Epoch:[ 161 2 ] loss: 0.4058678448200226 2022-05-29 18:39:28.921236
Epoch:[ 161 3 ] loss: 0.4071924686431885 2022-05-29 18:39:29.696287
Epoch:[ 161 4 ] loss: 0.4057956039905548 2022-05-29 18:39:30.473333
Epoch:[ 161 5 ] loss: 0.4031922221183777 2022-05-29 18:39:31.251034
Epoch:[ 161 6 ] loss: 0.40401822328567505 2022-05-29 18:39:32.027592
Epoch:[ 161 7 ] loss: 0.4053739309310913 2022-05-29 18:39:32.802411
Epoch:[ 161 8 ] loss: 0.4041561782360077 2022-05-29 18:39:33.576814
Epoch:[ 161 9 ] loss: 0.40657538175582886 2022-05-29 18:39:34.352786
Epoch:[ 161 10 ] loss: 0.40126675367355347 2022-05-29 18:39:35.127084
Epoch:[ 161 11 ] loss: 0.40378814935684204 2022-05-29 18:39:35.915558
Epoch:[ 161 12 ] loss: 0.4009479880332947 2022-05-29 18:39:36.693756
Epoch:[ 161 13 ] loss: 0.4058763086795807 2022-05-29 18:39:37.472776
Epoch:[ 161 14 ] loss: 0.4002532958984375 2022-05-29 18:39:38.248485
Epoch:[ 161 15 ] loss: 0.40418824553489685 2022-05-29 18:39:39.035482
Epoch:[ 161 16 ] loss: 0.40699502825737 2022-05-29 18:39:46.781167
Epoch:[ 161 17 ] loss: 0.40551742911338806 2022-05-29 18:39:47.567269
Epoch:[ 161 18 ] loss: 0.40404200553894043 2022-05-29 18:39:48.348231
Epoch:[ 161 19 ] loss: 0.40434250235557556 2022-05-29 18:39:49.123855
Training_Epoch:[ 161 ] Training_loss: 0.40425642728805544 2022-05-29 18:39:49.124561
learning rate:  1.1258999068426253e-05
val: 1 0.5488616228103638
val: 2 0.546370804309845
val: 3 0.531730592250824
val: 4 0.5080713033676147
val: 5 0.5644296407699585
val: 6 0.544346809387207
val: 7 0.5464745759963989
val: 8 0.5345685482025146
val: 9 0.5396275520324707
val: 10 0.5578791499137878
val: 11 0.5253952145576477
val: 12 0.5313655734062195
val: 13 0.5284265279769897
val: 14 0.5329256653785706
val: 15 0.5569652318954468
val: 16 0.5442677736282349
val: 17 0.5310724377632141
val: 18 0.5360382795333862
val: 19 0.520869791507721
val: 20 0.5443072319030762
val_Epoch:[ 161 ] val_loss: 0.5386997163295746 2022-05-29 18:39:54.293278
start training 2022-05-29 18:39:54.397415
Epoch:[ 162 0 ] loss: 0.40454617142677307 2022-05-29 18:40:16.901182
Epoch:[ 162 1 ] loss: 0.40403085947036743 2022-05-29 18:40:18.323423
Epoch:[ 162 2 ] loss: 0.40113565325737 2022-05-29 18:40:19.097245
Epoch:[ 162 3 ] loss: 0.40444180369377136 2022-05-29 18:40:19.872943
Epoch:[ 162 4 ] loss: 0.40047889947891235 2022-05-29 18:40:20.647024
Epoch:[ 162 5 ] loss: 0.40566113591194153 2022-05-29 18:40:21.423399
Epoch:[ 162 6 ] loss: 0.4045671224594116 2022-05-29 18:40:22.201757
Epoch:[ 162 7 ] loss: 0.4033248722553253 2022-05-29 18:40:22.977763
Epoch:[ 162 8 ] loss: 0.4043612480163574 2022-05-29 18:40:23.765212
Epoch:[ 162 9 ] loss: 0.4016333818435669 2022-05-29 18:40:24.538874
Epoch:[ 162 10 ] loss: 0.40657496452331543 2022-05-29 18:40:25.313257
Epoch:[ 162 11 ] loss: 0.40502485632896423 2022-05-29 18:40:26.101412
Epoch:[ 162 12 ] loss: 0.4058644771575928 2022-05-29 18:40:26.877653
Epoch:[ 162 13 ] loss: 0.40784862637519836 2022-05-29 18:40:27.655604
Epoch:[ 162 14 ] loss: 0.40453803539276123 2022-05-29 18:40:28.443871
Epoch:[ 162 15 ] loss: 0.40428411960601807 2022-05-29 18:40:29.220669
Epoch:[ 162 16 ] loss: 0.40400394797325134 2022-05-29 18:40:36.875089
Epoch:[ 162 17 ] loss: 0.40500348806381226 2022-05-29 18:40:37.661744
Epoch:[ 162 18 ] loss: 0.40406012535095215 2022-05-29 18:40:38.439583
Epoch:[ 162 19 ] loss: 0.4009731113910675 2022-05-29 18:40:39.226395
Training_Epoch:[ 162 ] Training_loss: 0.4041178449988365 2022-05-29 18:40:39.227083
learning rate:  1.1258999068426253e-05
netparams have been saved once 162
val: 1 0.540228545665741
val: 2 0.5250490307807922
val: 3 0.5132811069488525
val: 4 0.541487455368042
val: 5 0.542640209197998
val: 6 0.5259853005409241
val: 7 0.5441064238548279
val: 8 0.5386244654655457
val: 9 0.5417630672454834
val: 10 0.5354676246643066
val: 11 0.5262280702590942
val: 12 0.536043643951416
val: 13 0.5536283850669861
val: 14 0.5558729767799377
val: 15 0.5402323603630066
val: 16 0.538335382938385
val: 17 0.5344099998474121
val: 18 0.5395992994308472
val: 19 0.5487001538276672
val: 20 0.5421768426895142
val_Epoch:[ 162 ] val_loss: 0.538193017244339 2022-05-29 18:40:44.559818
start training 2022-05-29 18:40:44.663198
Epoch:[ 163 0 ] loss: 0.4054962694644928 2022-05-29 18:41:07.457615
Epoch:[ 163 1 ] loss: 0.40427863597869873 2022-05-29 18:41:08.281452
Epoch:[ 163 2 ] loss: 0.4039272964000702 2022-05-29 18:41:09.058722
Epoch:[ 163 3 ] loss: 0.4024900197982788 2022-05-29 18:41:09.834496
Epoch:[ 163 4 ] loss: 0.4019824266433716 2022-05-29 18:41:10.612508
Epoch:[ 163 5 ] loss: 0.40461266040802 2022-05-29 18:41:11.399135
Epoch:[ 163 6 ] loss: 0.4015443027019501 2022-05-29 18:41:12.176012
Epoch:[ 163 7 ] loss: 0.40824538469314575 2022-05-29 18:41:12.950845
Epoch:[ 163 8 ] loss: 0.4007662832736969 2022-05-29 18:41:13.727067
Epoch:[ 163 9 ] loss: 0.4044969379901886 2022-05-29 18:41:14.504889
Epoch:[ 163 10 ] loss: 0.40149441361427307 2022-05-29 18:41:15.280870
Epoch:[ 163 11 ] loss: 0.4059220850467682 2022-05-29 18:41:16.055562
Epoch:[ 163 12 ] loss: 0.40499237179756165 2022-05-29 18:41:16.830478
Epoch:[ 163 13 ] loss: 0.4043620824813843 2022-05-29 18:41:17.609968
Epoch:[ 163 14 ] loss: 0.4051052927970886 2022-05-29 18:41:18.388381
Epoch:[ 163 15 ] loss: 0.4039560556411743 2022-05-29 18:41:19.177135
Epoch:[ 163 16 ] loss: 0.40377846360206604 2022-05-29 18:41:26.260343
Epoch:[ 163 17 ] loss: 0.40681740641593933 2022-05-29 18:41:27.047045
Epoch:[ 163 18 ] loss: 0.40308240056037903 2022-05-29 18:41:27.825682
Epoch:[ 163 19 ] loss: 0.4074101746082306 2022-05-29 18:41:28.599135
Training_Epoch:[ 163 ] Training_loss: 0.4042380481958389 2022-05-29 18:41:28.599881
learning rate:  1.1258999068426253e-05
val: 1 0.5286353826522827
val: 2 0.5354582667350769
val: 3 0.546973466873169
val: 4 0.5473910570144653
val: 5 0.5349398255348206
val: 6 0.5469658374786377
val: 7 0.530916690826416
val: 8 0.5397118926048279
val: 9 0.5306873917579651
val: 10 0.5541926026344299
val: 11 0.5237588286399841
val: 12 0.5424180626869202
val: 13 0.5227269530296326
val: 14 0.5452080368995667
val: 15 0.5169067978858948
val: 16 0.5336399674415588
val: 17 0.5346755981445312
val: 18 0.5459824204444885
val: 19 0.5519166588783264
val: 20 0.5385764241218567
val_Epoch:[ 163 ] val_loss: 0.5375841081142425 2022-05-29 18:41:33.816724
start training 2022-05-29 18:41:33.917874
Epoch:[ 164 0 ] loss: 0.40383949875831604 2022-05-29 18:41:57.651218
Epoch:[ 164 1 ] loss: 0.4082752764225006 2022-05-29 18:41:58.439323
Epoch:[ 164 2 ] loss: 0.40325793623924255 2022-05-29 18:41:59.215168
Epoch:[ 164 3 ] loss: 0.4025172293186188 2022-05-29 18:41:59.989514
Epoch:[ 164 4 ] loss: 0.3994449973106384 2022-05-29 18:42:00.762913
Epoch:[ 164 5 ] loss: 0.4054162800312042 2022-05-29 18:42:01.540099
Epoch:[ 164 6 ] loss: 0.4024715721607208 2022-05-29 18:42:02.314861
Epoch:[ 164 7 ] loss: 0.40529605746269226 2022-05-29 18:42:03.092265
Epoch:[ 164 8 ] loss: 0.4084760844707489 2022-05-29 18:42:03.868181
Epoch:[ 164 9 ] loss: 0.4045877158641815 2022-05-29 18:42:04.657736
Epoch:[ 164 10 ] loss: 0.40694913268089294 2022-05-29 18:42:05.447462
Epoch:[ 164 11 ] loss: 0.4050678014755249 2022-05-29 18:42:06.223290
Epoch:[ 164 12 ] loss: 0.39689210057258606 2022-05-29 18:42:06.996655
Epoch:[ 164 13 ] loss: 0.4062424302101135 2022-05-29 18:42:07.770865
Epoch:[ 164 14 ] loss: 0.4038795530796051 2022-05-29 18:42:08.546671
Epoch:[ 164 15 ] loss: 0.4052286744117737 2022-05-29 18:42:09.324923
Epoch:[ 164 16 ] loss: 0.40295374393463135 2022-05-29 18:42:16.155892
Epoch:[ 164 17 ] loss: 0.40130671858787537 2022-05-29 18:42:16.972599
Epoch:[ 164 18 ] loss: 0.40342381596565247 2022-05-29 18:42:17.751722
Epoch:[ 164 19 ] loss: 0.4058208167552948 2022-05-29 18:42:18.523924
Training_Epoch:[ 164 ] Training_loss: 0.4040673717856407 2022-05-29 18:42:18.524680
learning rate:  1.1258999068426253e-05
netparams have been saved once 164
val: 1 0.5307528376579285
val: 2 0.5173943042755127
val: 3 0.5402312278747559
val: 4 0.5560561418533325
val: 5 0.5198279619216919
val: 6 0.5355729460716248
val: 7 0.55298912525177
val: 8 0.5434064269065857
val: 9 0.5266894698143005
val: 10 0.5489458441734314
val: 11 0.5429928302764893
val: 12 0.542144238948822
val: 13 0.5466146469116211
val: 14 0.5379952788352966
val: 15 0.5381646156311035
val: 16 0.5525964498519897
val: 17 0.5509116649627686
val: 18 0.5449798107147217
val: 19 0.5351520776748657
val: 20 0.5158082842826843
val_Epoch:[ 164 ] val_loss: 0.5389613091945649 2022-05-29 18:42:23.913144
start training 2022-05-29 18:42:24.016119
Epoch:[ 165 0 ] loss: 0.4049530327320099 2022-05-29 18:42:47.983846
Epoch:[ 165 1 ] loss: 0.40471214056015015 2022-05-29 18:42:48.760808
Epoch:[ 165 2 ] loss: 0.4082338511943817 2022-05-29 18:42:49.536376
Epoch:[ 165 3 ] loss: 0.40240374207496643 2022-05-29 18:42:50.322972
Epoch:[ 165 4 ] loss: 0.4071548581123352 2022-05-29 18:42:51.112054
Epoch:[ 165 5 ] loss: 0.4031621217727661 2022-05-29 18:42:51.885271
Epoch:[ 165 6 ] loss: 0.4014451801776886 2022-05-29 18:42:52.661061
Epoch:[ 165 7 ] loss: 0.4030299484729767 2022-05-29 18:42:53.434945
Epoch:[ 165 8 ] loss: 0.40356504917144775 2022-05-29 18:42:54.212211
Epoch:[ 165 9 ] loss: 0.40266287326812744 2022-05-29 18:42:55.002872
Epoch:[ 165 10 ] loss: 0.40274935960769653 2022-05-29 18:42:55.778895
Epoch:[ 165 11 ] loss: 0.3992948830127716 2022-05-29 18:42:56.553420
Epoch:[ 165 12 ] loss: 0.39792492985725403 2022-05-29 18:42:57.327353
Epoch:[ 165 13 ] loss: 0.4051256477832794 2022-05-29 18:42:58.103550
Epoch:[ 165 14 ] loss: 0.4033282697200775 2022-05-29 18:42:58.877532
Epoch:[ 165 15 ] loss: 0.40468457341194153 2022-05-29 18:42:59.655145
Epoch:[ 165 16 ] loss: 0.40667882561683655 2022-05-29 18:43:07.039760
Epoch:[ 165 17 ] loss: 0.4074245095252991 2022-05-29 18:43:07.816504
Epoch:[ 165 18 ] loss: 0.40401971340179443 2022-05-29 18:43:08.607435
Epoch:[ 165 19 ] loss: 0.4073651432991028 2022-05-29 18:43:09.380103
Training_Epoch:[ 165 ] Training_loss: 0.4039959326386452 2022-05-29 18:43:09.380771
learning rate:  1.1258999068426253e-05
val: 1 0.5422654747962952
val: 2 0.5549111366271973
val: 3 0.5166102647781372
val: 4 0.5539765954017639
val: 5 0.5295160412788391
val: 6 0.5302538275718689
val: 7 0.5498504042625427
val: 8 0.5502001643180847
val: 9 0.5458059906959534
val: 10 0.5344467163085938
val: 11 0.5448396801948547
val: 12 0.5317296385765076
val: 13 0.5309938788414001
val: 14 0.5519272685050964
val: 15 0.5323185324668884
val: 16 0.5428789258003235
val: 17 0.5217506289482117
val: 18 0.5448650121688843
val: 19 0.53089439868927
val: 20 0.5413768887519836
val_Epoch:[ 165 ] val_loss: 0.5390705734491348 2022-05-29 18:43:14.579028
start training 2022-05-29 18:43:14.676558
Epoch:[ 166 0 ] loss: 0.4059095084667206 2022-05-29 18:43:36.925735
Epoch:[ 166 1 ] loss: 0.4032825231552124 2022-05-29 18:43:37.790532
Epoch:[ 166 2 ] loss: 0.40833932161331177 2022-05-29 18:43:38.622968
Epoch:[ 166 3 ] loss: 0.4074193239212036 2022-05-29 18:43:39.412788
Epoch:[ 166 4 ] loss: 0.4004373550415039 2022-05-29 18:43:40.188861
Epoch:[ 166 5 ] loss: 0.40588703751564026 2022-05-29 18:43:40.963029
Epoch:[ 166 6 ] loss: 0.40060532093048096 2022-05-29 18:43:41.738067
Epoch:[ 166 7 ] loss: 0.40210476517677307 2022-05-29 18:43:42.510915
Epoch:[ 166 8 ] loss: 0.4015759527683258 2022-05-29 18:43:43.286342
Epoch:[ 166 9 ] loss: 0.4049033224582672 2022-05-29 18:43:44.061519
Epoch:[ 166 10 ] loss: 0.4055827558040619 2022-05-29 18:43:44.850165
Epoch:[ 166 11 ] loss: 0.40122538805007935 2022-05-29 18:43:45.627735
Epoch:[ 166 12 ] loss: 0.40588322281837463 2022-05-29 18:43:46.404707
Epoch:[ 166 13 ] loss: 0.40312573313713074 2022-05-29 18:43:47.179547
Epoch:[ 166 14 ] loss: 0.40328001976013184 2022-05-29 18:43:47.954384
Epoch:[ 166 15 ] loss: 0.40260395407676697 2022-05-29 18:43:48.728713
Epoch:[ 166 16 ] loss: 0.4048636555671692 2022-05-29 18:43:56.685477
Epoch:[ 166 17 ] loss: 0.4034096896648407 2022-05-29 18:43:57.459227
Epoch:[ 166 18 ] loss: 0.40163180232048035 2022-05-29 18:43:58.240789
Epoch:[ 166 19 ] loss: 0.4071704149246216 2022-05-29 18:43:59.028198
Training_Epoch:[ 166 ] Training_loss: 0.40396205335855484 2022-05-29 18:43:59.028924
learning rate:  1.1258999068426253e-05
netparams have been saved once 166
val: 1 0.5401098728179932
val: 2 0.5375708341598511
val: 3 0.530024528503418
val: 4 0.5456690788269043
val: 5 0.5128054022789001
val: 6 0.5302919149398804
val: 7 0.5238889455795288
val: 8 0.5442146062850952
val: 9 0.5238214135169983
val: 10 0.5288299918174744
val: 11 0.5608401894569397
val: 12 0.5455127954483032
val: 13 0.5342867374420166
val: 14 0.5529510378837585
val: 15 0.522835910320282
val: 16 0.5476943850517273
val: 17 0.5722620487213135
val: 18 0.5374293923377991
val: 19 0.5265300869941711
val: 20 0.5606741309165955
val_Epoch:[ 166 ] val_loss: 0.5389121651649476 2022-05-29 18:44:04.313058
start training 2022-05-29 18:44:04.411826
Epoch:[ 167 0 ] loss: 0.40252935886383057 2022-05-29 18:44:26.739839
Epoch:[ 167 1 ] loss: 0.40936803817749023 2022-05-29 18:44:27.559263
Epoch:[ 167 2 ] loss: 0.40136954188346863 2022-05-29 18:44:28.391080
Epoch:[ 167 3 ] loss: 0.40271633863449097 2022-05-29 18:44:29.171714
Epoch:[ 167 4 ] loss: 0.40255460143089294 2022-05-29 18:44:29.947751
Epoch:[ 167 5 ] loss: 0.4050854444503784 2022-05-29 18:44:30.737631
Epoch:[ 167 6 ] loss: 0.40436166524887085 2022-05-29 18:44:31.516196
Epoch:[ 167 7 ] loss: 0.40774428844451904 2022-05-29 18:44:32.292227
Epoch:[ 167 8 ] loss: 0.4045056700706482 2022-05-29 18:44:33.069498
Epoch:[ 167 9 ] loss: 0.40644192695617676 2022-05-29 18:44:33.844033
Epoch:[ 167 10 ] loss: 0.4001433253288269 2022-05-29 18:44:34.622059
Epoch:[ 167 11 ] loss: 0.40668749809265137 2022-05-29 18:44:35.411284
Epoch:[ 167 12 ] loss: 0.40548422932624817 2022-05-29 18:44:36.186206
Epoch:[ 167 13 ] loss: 0.4059305489063263 2022-05-29 18:44:36.960943
Epoch:[ 167 14 ] loss: 0.4042074382305145 2022-05-29 18:44:37.736690
Epoch:[ 167 15 ] loss: 0.4045300781726837 2022-05-29 18:44:38.510969
Epoch:[ 167 16 ] loss: 0.4003055989742279 2022-05-29 18:44:45.956073
Epoch:[ 167 17 ] loss: 0.40287306904792786 2022-05-29 18:44:46.743844
Epoch:[ 167 18 ] loss: 0.4039836525917053 2022-05-29 18:44:47.526103
Epoch:[ 167 19 ] loss: 0.40290141105651855 2022-05-29 18:44:48.310622
Training_Epoch:[ 167 ] Training_loss: 0.40418618619441987 2022-05-29 18:44:48.311287
learning rate:  1.1258999068426253e-05
val: 1 0.5192511677742004
val: 2 0.539129376411438
val: 3 0.5253041982650757
val: 4 0.5404118299484253
val: 5 0.5273736119270325
val: 6 0.5415753722190857
val: 7 0.5405548214912415
val: 8 0.5545743107795715
val: 9 0.5450260043144226
val: 10 0.532034158706665
val: 11 0.5341934561729431
val: 12 0.530647337436676
val: 13 0.542933464050293
val: 14 0.5190423727035522
val: 15 0.5344918370246887
val: 16 0.5408079624176025
val: 17 0.5405088067054749
val: 18 0.5264734029769897
val: 19 0.5465565919876099
val: 20 0.5714938044548035
val_Epoch:[ 167 ] val_loss: 0.5376191943883896 2022-05-29 18:44:53.534842
start training 2022-05-29 18:44:53.635304
Epoch:[ 168 0 ] loss: 0.40251457691192627 2022-05-29 18:45:16.540468
Epoch:[ 168 1 ] loss: 0.4032713770866394 2022-05-29 18:45:17.368111
Epoch:[ 168 2 ] loss: 0.40118029713630676 2022-05-29 18:45:18.140852
Epoch:[ 168 3 ] loss: 0.40201160311698914 2022-05-29 18:45:18.913857
Epoch:[ 168 4 ] loss: 0.4004324674606323 2022-05-29 18:45:19.702095
Epoch:[ 168 5 ] loss: 0.40481746196746826 2022-05-29 18:45:20.478458
Epoch:[ 168 6 ] loss: 0.40770599246025085 2022-05-29 18:45:21.256149
Epoch:[ 168 7 ] loss: 0.40490612387657166 2022-05-29 18:45:22.044321
Epoch:[ 168 8 ] loss: 0.40370553731918335 2022-05-29 18:45:22.817506
Epoch:[ 168 9 ] loss: 0.4031236469745636 2022-05-29 18:45:23.604921
Epoch:[ 168 10 ] loss: 0.40002644062042236 2022-05-29 18:45:24.378615
Epoch:[ 168 11 ] loss: 0.4058256447315216 2022-05-29 18:45:25.155139
Epoch:[ 168 12 ] loss: 0.4014570713043213 2022-05-29 18:45:25.932215
Epoch:[ 168 13 ] loss: 0.40455400943756104 2022-05-29 18:45:26.706885
Epoch:[ 168 14 ] loss: 0.40622061491012573 2022-05-29 18:45:27.481932
Epoch:[ 168 15 ] loss: 0.4025968015193939 2022-05-29 18:45:28.253744
Epoch:[ 168 16 ] loss: 0.4062054455280304 2022-05-29 18:45:35.552016
Epoch:[ 168 17 ] loss: 0.40744146704673767 2022-05-29 18:45:36.323807
Epoch:[ 168 18 ] loss: 0.4059426188468933 2022-05-29 18:45:37.104625
Epoch:[ 168 19 ] loss: 0.40852388739585876 2022-05-29 18:45:37.892245
Training_Epoch:[ 168 ] Training_loss: 0.4041231542825699 2022-05-29 18:45:37.892929
learning rate:  1.1258999068426253e-05
netparams have been saved once 168
val: 1 0.5407616496086121
val: 2 0.5216365456581116
val: 3 0.5433250069618225
val: 4 0.5518832802772522
val: 5 0.5391669273376465
val: 6 0.5491576194763184
val: 7 0.5217969417572021
val: 8 0.5579875111579895
val: 9 0.5222421288490295
val: 10 0.5474499464035034
val: 11 0.5480367541313171
val: 12 0.5353002548217773
val: 13 0.5121386051177979
val: 14 0.5431987047195435
val: 15 0.5542149543762207
val: 16 0.5338646769523621
val: 17 0.5334007740020752
val: 18 0.5319564938545227
val: 19 0.5354419946670532
val: 20 0.5340222716331482
val_Epoch:[ 168 ] val_loss: 0.5378491520881653 2022-05-29 18:45:43.162634
start training 2022-05-29 18:45:43.261173
Epoch:[ 169 0 ] loss: 0.4050854444503784 2022-05-29 18:46:05.965049
Epoch:[ 169 1 ] loss: 0.40358832478523254 2022-05-29 18:46:07.038242
Epoch:[ 169 2 ] loss: 0.4070870578289032 2022-05-29 18:46:07.811078
Epoch:[ 169 3 ] loss: 0.4054573178291321 2022-05-29 18:46:08.587450
Epoch:[ 169 4 ] loss: 0.4020962417125702 2022-05-29 18:46:09.360788
Epoch:[ 169 5 ] loss: 0.40581509470939636 2022-05-29 18:46:10.137444
Epoch:[ 169 6 ] loss: 0.4078410565853119 2022-05-29 18:46:10.925089
Epoch:[ 169 7 ] loss: 0.40518760681152344 2022-05-29 18:46:11.700829
Epoch:[ 169 8 ] loss: 0.40364763140678406 2022-05-29 18:46:12.489142
Epoch:[ 169 9 ] loss: 0.40344807505607605 2022-05-29 18:46:13.263094
Epoch:[ 169 10 ] loss: 0.4055866301059723 2022-05-29 18:46:14.036779
Epoch:[ 169 11 ] loss: 0.40247541666030884 2022-05-29 18:46:14.810932
Epoch:[ 169 12 ] loss: 0.40798893570899963 2022-05-29 18:46:15.588327
Epoch:[ 169 13 ] loss: 0.4037492573261261 2022-05-29 18:46:16.365522
Epoch:[ 169 14 ] loss: 0.40427571535110474 2022-05-29 18:46:17.154607
Epoch:[ 169 15 ] loss: 0.4029930531978607 2022-05-29 18:46:17.928306
Epoch:[ 169 16 ] loss: 0.4048849642276764 2022-05-29 18:46:25.398610
Epoch:[ 169 17 ] loss: 0.39727991819381714 2022-05-29 18:46:26.181846
Epoch:[ 169 18 ] loss: 0.401899129152298 2022-05-29 18:46:26.960313
Epoch:[ 169 19 ] loss: 0.40324535965919495 2022-05-29 18:46:27.735820
Training_Epoch:[ 169 ] Training_loss: 0.40418161153793336 2022-05-29 18:46:27.736499
learning rate:  1.1258999068426253e-05
val: 1 0.525682270526886
val: 2 0.5275107622146606
val: 3 0.5598160624504089
val: 4 0.5224794745445251
val: 5 0.5343282222747803
val: 6 0.5234622359275818
val: 7 0.5579395890235901
val: 8 0.5406960844993591
val: 9 0.5461795330047607
val: 10 0.5261479020118713
val: 11 0.5439032912254333
val: 12 0.552176833152771
val: 13 0.5432671904563904
val: 14 0.5408592820167542
val: 15 0.5357963442802429
val: 16 0.5313092470169067
val: 17 0.5495964884757996
val: 18 0.5404049754142761
val: 19 0.5412653684616089
val: 20 0.5239722728729248
val_Epoch:[ 169 ] val_loss: 0.5383396714925766 2022-05-29 18:46:32.866495
start training 2022-05-29 18:46:32.967043
Epoch:[ 170 0 ] loss: 0.4041496515274048 2022-05-29 18:46:55.124523
Epoch:[ 170 1 ] loss: 0.40050724148750305 2022-05-29 18:46:55.958222
Epoch:[ 170 2 ] loss: 0.40281832218170166 2022-05-29 18:46:56.780344
Epoch:[ 170 3 ] loss: 0.40849795937538147 2022-05-29 18:46:57.566979
Epoch:[ 170 4 ] loss: 0.40433284640312195 2022-05-29 18:46:58.352847
Epoch:[ 170 5 ] loss: 0.4012352526187897 2022-05-29 18:46:59.127783
Epoch:[ 170 6 ] loss: 0.40794309973716736 2022-05-29 18:46:59.903849
Epoch:[ 170 7 ] loss: 0.40798041224479675 2022-05-29 18:47:00.681071
Epoch:[ 170 8 ] loss: 0.40087902545928955 2022-05-29 18:47:01.470209
Epoch:[ 170 9 ] loss: 0.402349054813385 2022-05-29 18:47:02.248226
Epoch:[ 170 10 ] loss: 0.4063278138637543 2022-05-29 18:47:03.023351
Epoch:[ 170 11 ] loss: 0.40232545137405396 2022-05-29 18:47:03.796781
Epoch:[ 170 12 ] loss: 0.39919620752334595 2022-05-29 18:47:04.570929
Epoch:[ 170 13 ] loss: 0.402082234621048 2022-05-29 18:47:05.348981
Epoch:[ 170 14 ] loss: 0.40638652443885803 2022-05-29 18:47:06.127726
Epoch:[ 170 15 ] loss: 0.40283459424972534 2022-05-29 18:47:06.905115
Epoch:[ 170 16 ] loss: 0.40872395038604736 2022-05-29 18:47:14.667939
Epoch:[ 170 17 ] loss: 0.4045143127441406 2022-05-29 18:47:15.453042
Epoch:[ 170 18 ] loss: 0.4036412239074707 2022-05-29 18:47:16.245476
Epoch:[ 170 19 ] loss: 0.40697652101516724 2022-05-29 18:47:17.020149
Training_Epoch:[ 170 ] Training_loss: 0.4041850849986076 2022-05-29 18:47:17.020846
learning rate:  1.1258999068426253e-05
netparams have been saved once 170
val: 1 0.5480778813362122
val: 2 0.5374242067337036
val: 3 0.5365074276924133
val: 4 0.5176560282707214
val: 5 0.5395570397377014
val: 6 0.5399877429008484
val: 7 0.5464283227920532
val: 8 0.5371258854866028
val: 9 0.5308995246887207
val: 10 0.5283962488174438
val: 11 0.5532482862472534
val: 12 0.5263901352882385
val: 13 0.5216049551963806
val: 14 0.5575010776519775
val: 15 0.5339494943618774
val: 16 0.5317914485931396
val: 17 0.5506588220596313
val: 18 0.5505239367485046
val: 19 0.5400697588920593
val: 20 0.5214738249778748
val_Epoch:[ 170 ] val_loss: 0.5374636024236679 2022-05-29 18:47:22.282778
start training 2022-05-29 18:47:22.384341
Epoch:[ 171 0 ] loss: 0.40400853753089905 2022-05-29 18:47:45.982764
Epoch:[ 171 1 ] loss: 0.40049320459365845 2022-05-29 18:47:46.772106
Epoch:[ 171 2 ] loss: 0.3984984755516052 2022-05-29 18:47:47.559392
Epoch:[ 171 3 ] loss: 0.40418535470962524 2022-05-29 18:47:48.346932
Epoch:[ 171 4 ] loss: 0.40183305740356445 2022-05-29 18:47:49.122472
Epoch:[ 171 5 ] loss: 0.4102916717529297 2022-05-29 18:47:49.896754
Epoch:[ 171 6 ] loss: 0.4021115303039551 2022-05-29 18:47:50.672957
Epoch:[ 171 7 ] loss: 0.401093453168869 2022-05-29 18:47:51.451073
Epoch:[ 171 8 ] loss: 0.4029117822647095 2022-05-29 18:47:52.228823
Epoch:[ 171 9 ] loss: 0.40310776233673096 2022-05-29 18:47:53.005309
Epoch:[ 171 10 ] loss: 0.40708744525909424 2022-05-29 18:47:53.783432
Epoch:[ 171 11 ] loss: 0.40499237179756165 2022-05-29 18:47:54.558197
Epoch:[ 171 12 ] loss: 0.4012606739997864 2022-05-29 18:47:55.335182
Epoch:[ 171 13 ] loss: 0.4074254035949707 2022-05-29 18:47:56.109083
Epoch:[ 171 14 ] loss: 0.40391674637794495 2022-05-29 18:47:56.887005
Epoch:[ 171 15 ] loss: 0.40642306208610535 2022-05-29 18:47:57.665190
Epoch:[ 171 16 ] loss: 0.40566134452819824 2022-05-29 18:48:05.088910
Epoch:[ 171 17 ] loss: 0.4045015573501587 2022-05-29 18:48:05.875733
Epoch:[ 171 18 ] loss: 0.40634340047836304 2022-05-29 18:48:06.655610
Epoch:[ 171 19 ] loss: 0.4080474078655243 2022-05-29 18:48:07.433023
Training_Epoch:[ 171 ] Training_loss: 0.40420971214771273 2022-05-29 18:48:07.433709
learning rate:  9.007199254741003e-06
val: 1 0.543933629989624
val: 2 0.534912109375
val: 3 0.5454630255699158
val: 4 0.5332156419754028
val: 5 0.5475867390632629
val: 6 0.5419117212295532
val: 7 0.5104254484176636
val: 8 0.5420067310333252
val: 9 0.5559253096580505
val: 10 0.563412606716156
val: 11 0.5295422077178955
val: 12 0.5551649928092957
val: 13 0.5211191773414612
val: 14 0.5379514694213867
val: 15 0.5336900353431702
val: 16 0.5306807160377502
val: 17 0.5474066138267517
val: 18 0.5258742570877075
val: 19 0.5331094264984131
val: 20 0.5353708267211914
val_Epoch:[ 171 ] val_loss: 0.5384351342916489 2022-05-29 18:48:12.628472
start training 2022-05-29 18:48:12.734500
Epoch:[ 172 0 ] loss: 0.40376701951026917 2022-05-29 18:48:36.618201
Epoch:[ 172 1 ] loss: 0.4018509089946747 2022-05-29 18:48:37.407502
Epoch:[ 172 2 ] loss: 0.40543538331985474 2022-05-29 18:48:38.184409
Epoch:[ 172 3 ] loss: 0.40081873536109924 2022-05-29 18:48:38.962550
Epoch:[ 172 4 ] loss: 0.4049307703971863 2022-05-29 18:48:39.740451
Epoch:[ 172 5 ] loss: 0.4047577381134033 2022-05-29 18:48:40.526348
Epoch:[ 172 6 ] loss: 0.4032479524612427 2022-05-29 18:48:41.299788
Epoch:[ 172 7 ] loss: 0.4055465757846832 2022-05-29 18:48:42.073549
Epoch:[ 172 8 ] loss: 0.4021623134613037 2022-05-29 18:48:42.851000
Epoch:[ 172 9 ] loss: 0.40028658509254456 2022-05-29 18:48:43.628178
Epoch:[ 172 10 ] loss: 0.40813305974006653 2022-05-29 18:48:44.404780
Epoch:[ 172 11 ] loss: 0.4010923206806183 2022-05-29 18:48:45.180014
Epoch:[ 172 12 ] loss: 0.4027695059776306 2022-05-29 18:48:45.954791
Epoch:[ 172 13 ] loss: 0.4035959839820862 2022-05-29 18:48:46.729733
Epoch:[ 172 14 ] loss: 0.40461084246635437 2022-05-29 18:48:47.514860
Epoch:[ 172 15 ] loss: 0.4042869508266449 2022-05-29 18:48:48.292583
Epoch:[ 172 16 ] loss: 0.4069719910621643 2022-05-29 18:48:55.451259
Epoch:[ 172 17 ] loss: 0.4049024283885956 2022-05-29 18:48:56.226080
Epoch:[ 172 18 ] loss: 0.4032670855522156 2022-05-29 18:48:57.032406
Epoch:[ 172 19 ] loss: 0.4065799117088318 2022-05-29 18:48:57.805712
Training_Epoch:[ 172 ] Training_loss: 0.4039507031440735 2022-05-29 18:48:57.806329
learning rate:  9.007199254741003e-06
netparams have been saved once 172
val: 1 0.5330408811569214
val: 2 0.5364078879356384
val: 3 0.5494590997695923
val: 4 0.5434730052947998
val: 5 0.5391560792922974
val: 6 0.5455201864242554
val: 7 0.5291979908943176
val: 8 0.5226193070411682
val: 9 0.5355308055877686
val: 10 0.5343566536903381
val: 11 0.5442520976066589
val: 12 0.5462977290153503
val: 13 0.5390516519546509
val: 14 0.5521245002746582
val: 15 0.5492123961448669
val: 16 0.5424287915229797
val: 17 0.5381777286529541
val: 18 0.536861777305603
val: 19 0.5355868339538574
val: 20 0.5374648571014404
val_Epoch:[ 172 ] val_loss: 0.5395110130310059 2022-05-29 18:49:03.042900
start training 2022-05-29 18:49:03.143458
Epoch:[ 173 0 ] loss: 0.40558430552482605 2022-05-29 18:49:26.727280
Epoch:[ 173 1 ] loss: 0.40457844734191895 2022-05-29 18:49:27.501033
Epoch:[ 173 2 ] loss: 0.4008182883262634 2022-05-29 18:49:28.278603
Epoch:[ 173 3 ] loss: 0.4096241891384125 2022-05-29 18:49:29.064738
Epoch:[ 173 4 ] loss: 0.4006709158420563 2022-05-29 18:49:29.841231
Epoch:[ 173 5 ] loss: 0.4089989960193634 2022-05-29 18:49:30.616817
Epoch:[ 173 6 ] loss: 0.40385231375694275 2022-05-29 18:49:31.392068
Epoch:[ 173 7 ] loss: 0.405100554227829 2022-05-29 18:49:32.168466
Epoch:[ 173 8 ] loss: 0.40003982186317444 2022-05-29 18:49:32.942380
Epoch:[ 173 9 ] loss: 0.40405571460723877 2022-05-29 18:49:33.719105
Epoch:[ 173 10 ] loss: 0.4016888737678528 2022-05-29 18:49:34.497579
Epoch:[ 173 11 ] loss: 0.4031168520450592 2022-05-29 18:49:35.274842
Epoch:[ 173 12 ] loss: 0.4028424024581909 2022-05-29 18:49:36.051600
Epoch:[ 173 13 ] loss: 0.40051740407943726 2022-05-29 18:49:36.838258
Epoch:[ 173 14 ] loss: 0.405068576335907 2022-05-29 18:49:37.610909
Epoch:[ 173 15 ] loss: 0.4041871130466461 2022-05-29 18:49:38.397744
Epoch:[ 173 16 ] loss: 0.4076302647590637 2022-05-29 18:49:45.734773
Epoch:[ 173 17 ] loss: 0.4034201204776764 2022-05-29 18:49:46.512102
Epoch:[ 173 18 ] loss: 0.40418702363967896 2022-05-29 18:49:47.304518
Epoch:[ 173 19 ] loss: 0.4029863774776459 2022-05-29 18:49:48.077773
Training_Epoch:[ 173 ] Training_loss: 0.4039484277367592 2022-05-29 18:49:48.078491
learning rate:  9.007199254741003e-06
val: 1 0.536143958568573
val: 2 0.5361501574516296
val: 3 0.544319212436676
val: 4 0.5163304805755615
val: 5 0.5371747016906738
val: 6 0.5291722416877747
val: 7 0.5286476016044617
val: 8 0.5309703946113586
val: 9 0.5416964292526245
val: 10 0.5333077907562256
val: 11 0.5391565561294556
val: 12 0.5373823046684265
val: 13 0.553661584854126
val: 14 0.536419153213501
val: 15 0.5575231313705444
val: 16 0.530486524105072
val: 17 0.5427258014678955
val: 18 0.5390142798423767
val: 19 0.54736328125
val: 20 0.5549960136413574
val_Epoch:[ 173 ] val_loss: 0.5386320799589157 2022-05-29 18:49:53.292776
start training 2022-05-29 18:49:53.397666
Epoch:[ 174 0 ] loss: 0.40305405855178833 2022-05-29 18:50:15.298710
Epoch:[ 174 1 ] loss: 0.4020613729953766 2022-05-29 18:50:16.133802
Epoch:[ 174 2 ] loss: 0.4050213396549225 2022-05-29 18:50:16.933294
Epoch:[ 174 3 ] loss: 0.407327264547348 2022-05-29 18:50:17.709138
Epoch:[ 174 4 ] loss: 0.40067875385284424 2022-05-29 18:50:18.486137
Epoch:[ 174 5 ] loss: 0.40414121747016907 2022-05-29 18:50:19.261384
Epoch:[ 174 6 ] loss: 0.40155869722366333 2022-05-29 18:50:20.037703
Epoch:[ 174 7 ] loss: 0.3996807634830475 2022-05-29 18:50:20.825273
Epoch:[ 174 8 ] loss: 0.40500617027282715 2022-05-29 18:50:21.602065
Epoch:[ 174 9 ] loss: 0.4087052643299103 2022-05-29 18:50:22.388410
Epoch:[ 174 10 ] loss: 0.40309762954711914 2022-05-29 18:50:23.167824
Epoch:[ 174 11 ] loss: 0.4042535126209259 2022-05-29 18:50:23.946756
Epoch:[ 174 12 ] loss: 0.40091830492019653 2022-05-29 18:50:24.721861
Epoch:[ 174 13 ] loss: 0.4031507968902588 2022-05-29 18:50:25.500129
Epoch:[ 174 14 ] loss: 0.40598154067993164 2022-05-29 18:50:26.274680
Epoch:[ 174 15 ] loss: 0.40621086955070496 2022-05-29 18:50:27.049683
Epoch:[ 174 16 ] loss: 0.404730886220932 2022-05-29 18:50:35.735785
Epoch:[ 174 17 ] loss: 0.4034527540206909 2022-05-29 18:50:36.511842
Epoch:[ 174 18 ] loss: 0.402902752161026 2022-05-29 18:50:37.304672
Epoch:[ 174 19 ] loss: 0.40564700961112976 2022-05-29 18:50:38.090041
Training_Epoch:[ 174 ] Training_loss: 0.40387904793024065 2022-05-29 18:50:38.090790
learning rate:  9.007199254741003e-06
netparams have been saved once 174
val: 1 0.5597782135009766
val: 2 0.5474173426628113
val: 3 0.5507602691650391
val: 4 0.5441028475761414
val: 5 0.5495254993438721
val: 6 0.5523225665092468
val: 7 0.5413036346435547
val: 8 0.5195958614349365
val: 9 0.5322643518447876
val: 10 0.5364984273910522
val: 11 0.5250350832939148
val: 12 0.5198201537132263
val: 13 0.5158879160881042
val: 14 0.5352243185043335
val: 15 0.5388886332511902
val: 16 0.5270652770996094
val: 17 0.5368984937667847
val: 18 0.5186942219734192
val: 19 0.5437127947807312
val: 20 0.5635959506034851
val_Epoch:[ 174 ] val_loss: 0.5379195928573608 2022-05-29 18:50:43.388476
start training 2022-05-29 18:50:43.487350
Epoch:[ 175 0 ] loss: 0.4018803536891937 2022-05-29 18:51:07.622150
Epoch:[ 175 1 ] loss: 0.4043581187725067 2022-05-29 18:51:08.399622
Epoch:[ 175 2 ] loss: 0.4039616882801056 2022-05-29 18:51:09.189922
Epoch:[ 175 3 ] loss: 0.4043017625808716 2022-05-29 18:51:09.967437
Epoch:[ 175 4 ] loss: 0.4032171964645386 2022-05-29 18:51:10.745602
Epoch:[ 175 5 ] loss: 0.40377503633499146 2022-05-29 18:51:11.527804
Epoch:[ 175 6 ] loss: 0.4029428958892822 2022-05-29 18:51:12.303595
Epoch:[ 175 7 ] loss: 0.40501657128334045 2022-05-29 18:51:13.082361
Epoch:[ 175 8 ] loss: 0.40587279200553894 2022-05-29 18:51:13.845756
Epoch:[ 175 9 ] loss: 0.40316712856292725 2022-05-29 18:51:14.610107
Epoch:[ 175 10 ] loss: 0.4086463153362274 2022-05-29 18:51:15.386662
Epoch:[ 175 11 ] loss: 0.40650850534439087 2022-05-29 18:51:16.166855
Epoch:[ 175 12 ] loss: 0.4028458297252655 2022-05-29 18:51:16.947910
Epoch:[ 175 13 ] loss: 0.40482401847839355 2022-05-29 18:51:17.726550
Epoch:[ 175 14 ] loss: 0.4011116921901703 2022-05-29 18:51:18.503429
Epoch:[ 175 15 ] loss: 0.4049467146396637 2022-05-29 18:51:19.279024
Epoch:[ 175 16 ] loss: 0.40280795097351074 2022-05-29 18:51:26.386403
Epoch:[ 175 17 ] loss: 0.40411680936813354 2022-05-29 18:51:27.160669
Epoch:[ 175 18 ] loss: 0.4033268690109253 2022-05-29 18:51:27.941659
Epoch:[ 175 19 ] loss: 0.39883866906166077 2022-05-29 18:51:28.729612
Training_Epoch:[ 175 ] Training_loss: 0.4038233458995819 2022-05-29 18:51:28.730392
learning rate:  9.007199254741003e-06
val: 1 0.5430077910423279
val: 2 0.5603785514831543
val: 3 0.5440605878829956
val: 4 0.5441820621490479
val: 5 0.5241334438323975
val: 6 0.5402756333351135
val: 7 0.5296372175216675
val: 8 0.5351795554161072
val: 9 0.5458283424377441
val: 10 0.5223381519317627
val: 11 0.5028525590896606
val: 12 0.5458667278289795
val: 13 0.5253520607948303
val: 14 0.5361276865005493
val: 15 0.5448193550109863
val: 16 0.5645090341567993
val: 17 0.5538470149040222
val: 18 0.5237331390380859
val: 19 0.5338897109031677
val: 20 0.5365972518920898
val_Epoch:[ 175 ] val_loss: 0.5378307938575745 2022-05-29 18:51:33.966041
start training 2022-05-29 18:51:34.070901
Epoch:[ 176 0 ] loss: 0.40191978216171265 2022-05-29 18:51:56.394285
Epoch:[ 176 1 ] loss: 0.40740275382995605 2022-05-29 18:51:58.097342
Epoch:[ 176 2 ] loss: 0.40416276454925537 2022-05-29 18:51:58.884379
Epoch:[ 176 3 ] loss: 0.4057282507419586 2022-05-29 18:51:59.670718
Epoch:[ 176 4 ] loss: 0.4042479395866394 2022-05-29 18:52:00.446402
Epoch:[ 176 5 ] loss: 0.4063590466976166 2022-05-29 18:52:01.227617
Epoch:[ 176 6 ] loss: 0.4028299152851105 2022-05-29 18:52:02.009815
Epoch:[ 176 7 ] loss: 0.4027130901813507 2022-05-29 18:52:02.789536
Epoch:[ 176 8 ] loss: 0.401795357465744 2022-05-29 18:52:03.568830
Epoch:[ 176 9 ] loss: 0.40510040521621704 2022-05-29 18:52:04.347549
Epoch:[ 176 10 ] loss: 0.40271249413490295 2022-05-29 18:52:05.124931
Epoch:[ 176 11 ] loss: 0.4009368121623993 2022-05-29 18:52:05.904067
Epoch:[ 176 12 ] loss: 0.40086421370506287 2022-05-29 18:52:06.682973
Epoch:[ 176 13 ] loss: 0.399247944355011 2022-05-29 18:52:07.464867
Epoch:[ 176 14 ] loss: 0.4024334251880646 2022-05-29 18:52:08.235030
Epoch:[ 176 15 ] loss: 0.405951589345932 2022-05-29 18:52:09.013689
Epoch:[ 176 16 ] loss: 0.40702617168426514 2022-05-29 18:52:16.152748
Epoch:[ 176 17 ] loss: 0.403672456741333 2022-05-29 18:52:16.940782
Epoch:[ 176 18 ] loss: 0.4067145586013794 2022-05-29 18:52:17.730073
Epoch:[ 176 19 ] loss: 0.4064587354660034 2022-05-29 18:52:18.507258
Training_Epoch:[ 176 ] Training_loss: 0.4039138853549957 2022-05-29 18:52:18.508171
learning rate:  9.007199254741003e-06
netparams have been saved once 176
val: 1 0.5530635118484497
val: 2 0.5472962856292725
val: 3 0.5286551713943481
val: 4 0.5309848785400391
val: 5 0.5248379707336426
val: 6 0.5473423600196838
val: 7 0.5449055433273315
val: 8 0.5442625880241394
val: 9 0.5150766968727112
val: 10 0.5444667935371399
val: 11 0.5397602319717407
val: 12 0.5390101075172424
val: 13 0.5483202934265137
val: 14 0.5376465916633606
val: 15 0.54786217212677
val: 16 0.5428594946861267
val: 17 0.5318601131439209
val: 18 0.5036569237709045
val: 19 0.5408717393875122
val: 20 0.5513874888420105
val_Epoch:[ 176 ] val_loss: 0.538206347823143 2022-05-29 18:52:23.808042
start training 2022-05-29 18:52:23.909694
Epoch:[ 177 0 ] loss: 0.40610843896865845 2022-05-29 18:52:47.929441
Epoch:[ 177 1 ] loss: 0.4059491455554962 2022-05-29 18:52:48.709260
Epoch:[ 177 2 ] loss: 0.4039340317249298 2022-05-29 18:52:49.483046
Epoch:[ 177 3 ] loss: 0.4026303291320801 2022-05-29 18:52:50.259489
Epoch:[ 177 4 ] loss: 0.39876317977905273 2022-05-29 18:52:51.044763
Epoch:[ 177 5 ] loss: 0.40427106618881226 2022-05-29 18:52:51.819958
Epoch:[ 177 6 ] loss: 0.40370845794677734 2022-05-29 18:52:52.598491
Epoch:[ 177 7 ] loss: 0.40281036496162415 2022-05-29 18:52:53.375952
Epoch:[ 177 8 ] loss: 0.403972864151001 2022-05-29 18:52:54.152872
Epoch:[ 177 9 ] loss: 0.40451693534851074 2022-05-29 18:52:54.928506
Epoch:[ 177 10 ] loss: 0.4019731283187866 2022-05-29 18:52:55.702899
Epoch:[ 177 11 ] loss: 0.40406638383865356 2022-05-29 18:52:56.493104
Epoch:[ 177 12 ] loss: 0.40069201588630676 2022-05-29 18:52:57.267695
Epoch:[ 177 13 ] loss: 0.40771806240081787 2022-05-29 18:52:58.057384
Epoch:[ 177 14 ] loss: 0.40319961309432983 2022-05-29 18:52:58.835406
Epoch:[ 177 15 ] loss: 0.40745383501052856 2022-05-29 18:52:59.611006
Epoch:[ 177 16 ] loss: 0.40313252806663513 2022-05-29 18:53:06.073493
Epoch:[ 177 17 ] loss: 0.4066987633705139 2022-05-29 18:53:07.135462
Epoch:[ 177 18 ] loss: 0.4049592614173889 2022-05-29 18:53:07.924294
Epoch:[ 177 19 ] loss: 0.4001656770706177 2022-05-29 18:53:08.699266
Training_Epoch:[ 177 ] Training_loss: 0.40383620411157606 2022-05-29 18:53:08.699972
learning rate:  9.007199254741003e-06
val: 1 0.553926408290863
val: 2 0.5377269387245178
val: 3 0.5528713464736938
val: 4 0.5219504237174988
val: 5 0.5320071578025818
val: 6 0.5392428636550903
val: 7 0.5236307978630066
val: 8 0.5194198489189148
val: 9 0.5514294505119324
val: 10 0.5436874628067017
val: 11 0.5340861678123474
val: 12 0.5367392897605896
val: 13 0.5390444993972778
val: 14 0.5501349568367004
val: 15 0.5170256495475769
val: 16 0.5523159503936768
val: 17 0.5339125990867615
val: 18 0.532693088054657
val: 19 0.5448353290557861
val: 20 0.541698694229126
val_Epoch:[ 177 ] val_loss: 0.537918946146965 2022-05-29 18:53:13.893249
start training 2022-05-29 18:53:13.991515
Epoch:[ 178 0 ] loss: 0.4035124182701111 2022-05-29 18:53:37.891282
Epoch:[ 178 1 ] loss: 0.4004850387573242 2022-05-29 18:53:38.669085
Epoch:[ 178 2 ] loss: 0.40285006165504456 2022-05-29 18:53:39.447014
Epoch:[ 178 3 ] loss: 0.4027431309223175 2022-05-29 18:53:40.233285
Epoch:[ 178 4 ] loss: 0.4053110182285309 2022-05-29 18:53:41.019034
Epoch:[ 178 5 ] loss: 0.4056580066680908 2022-05-29 18:53:41.795809
Epoch:[ 178 6 ] loss: 0.40119707584381104 2022-05-29 18:53:42.568512
Epoch:[ 178 7 ] loss: 0.40489497780799866 2022-05-29 18:53:43.346722
Epoch:[ 178 8 ] loss: 0.4038535952568054 2022-05-29 18:53:44.136580
Epoch:[ 178 9 ] loss: 0.4026683568954468 2022-05-29 18:53:44.914000
Epoch:[ 178 10 ] loss: 0.40501296520233154 2022-05-29 18:53:45.689629
Epoch:[ 178 11 ] loss: 0.40756097435951233 2022-05-29 18:53:46.461714
Epoch:[ 178 12 ] loss: 0.4051811993122101 2022-05-29 18:53:47.237071
Epoch:[ 178 13 ] loss: 0.4043976068496704 2022-05-29 18:53:48.010846
Epoch:[ 178 14 ] loss: 0.4038289487361908 2022-05-29 18:53:48.788046
Epoch:[ 178 15 ] loss: 0.40072816610336304 2022-05-29 18:53:49.564820
Epoch:[ 178 16 ] loss: 0.4039968252182007 2022-05-29 18:53:56.956445
Epoch:[ 178 17 ] loss: 0.40682321786880493 2022-05-29 18:53:57.742368
Epoch:[ 178 18 ] loss: 0.4022716283798218 2022-05-29 18:53:58.531793
Epoch:[ 178 19 ] loss: 0.40325838327407837 2022-05-29 18:53:59.307271
Training_Epoch:[ 178 ] Training_loss: 0.40381167978048327 2022-05-29 18:53:59.307903
learning rate:  9.007199254741003e-06
netparams have been saved once 178
val: 1 0.5429973006248474
val: 2 0.5391477346420288
val: 3 0.5541262030601501
val: 4 0.5318585634231567
val: 5 0.5555001497268677
val: 6 0.5381834506988525
val: 7 0.5223355889320374
val: 8 0.538188636302948
val: 9 0.5334290266036987
val: 10 0.5225884318351746
val: 11 0.5187850594520569
val: 12 0.5464416146278381
val: 13 0.5218756198883057
val: 14 0.5299790501594543
val: 15 0.5590837597846985
val: 16 0.5541718602180481
val: 17 0.5359634160995483
val: 18 0.5385986566543579
val: 19 0.5432597398757935
val: 20 0.5368860960006714
val_Epoch:[ 178 ] val_loss: 0.5381699979305268 2022-05-29 18:54:04.629486
start training 2022-05-29 18:54:04.736358
Epoch:[ 179 0 ] loss: 0.4017481505870819 2022-05-29 18:54:27.280938
Epoch:[ 179 1 ] loss: 0.407809317111969 2022-05-29 18:54:28.098555
Epoch:[ 179 2 ] loss: 0.4013258218765259 2022-05-29 18:54:28.973182
Epoch:[ 179 3 ] loss: 0.4047795236110687 2022-05-29 18:54:29.747491
Epoch:[ 179 4 ] loss: 0.4075809717178345 2022-05-29 18:54:30.522703
Epoch:[ 179 5 ] loss: 0.40218132734298706 2022-05-29 18:54:31.296022
Epoch:[ 179 6 ] loss: 0.4052620828151703 2022-05-29 18:54:32.070923
Epoch:[ 179 7 ] loss: 0.4022963047027588 2022-05-29 18:54:32.844831
Epoch:[ 179 8 ] loss: 0.4065854251384735 2022-05-29 18:54:33.621216
Epoch:[ 179 9 ] loss: 0.4011293053627014 2022-05-29 18:54:34.399597
Epoch:[ 179 10 ] loss: 0.40085136890411377 2022-05-29 18:54:35.189668
Epoch:[ 179 11 ] loss: 0.40586331486701965 2022-05-29 18:54:35.967363
Epoch:[ 179 12 ] loss: 0.4027135968208313 2022-05-29 18:54:36.740924
Epoch:[ 179 13 ] loss: 0.40563684701919556 2022-05-29 18:54:37.529994
Epoch:[ 179 14 ] loss: 0.40486177802085876 2022-05-29 18:54:38.316298
Epoch:[ 179 15 ] loss: 0.40140801668167114 2022-05-29 18:54:39.091724
Epoch:[ 179 16 ] loss: 0.4032127857208252 2022-05-29 18:54:47.281519
Epoch:[ 179 17 ] loss: 0.40439605712890625 2022-05-29 18:54:48.057449
Epoch:[ 179 18 ] loss: 0.40382397174835205 2022-05-29 18:54:48.849966
Epoch:[ 179 19 ] loss: 0.40259596705436707 2022-05-29 18:54:49.623824
Training_Epoch:[ 179 ] Training_loss: 0.4038030967116356 2022-05-29 18:54:49.624515
learning rate:  9.007199254741003e-06
val: 1 0.535761833190918
val: 2 0.5304369330406189
val: 3 0.5312602519989014
val: 4 0.5172827243804932
val: 5 0.5307218432426453
val: 6 0.5217964053153992
val: 7 0.5368003249168396
val: 8 0.547332763671875
val: 9 0.5508573055267334
val: 10 0.5436237454414368
val: 11 0.5434041619300842
val: 12 0.5124085545539856
val: 13 0.5540820956230164
val: 14 0.5254021883010864
val: 15 0.5430845618247986
val: 16 0.5291804671287537
val: 17 0.5524582862854004
val: 18 0.5316485166549683
val: 19 0.566487729549408
val: 20 0.5340926051139832
val_Epoch:[ 179 ] val_loss: 0.5369061648845672 2022-05-29 18:54:54.911157
start training 2022-05-29 18:54:55.010985
Epoch:[ 180 0 ] loss: 0.4021838307380676 2022-05-29 18:55:17.729614
Epoch:[ 180 1 ] loss: 0.39787474274635315 2022-05-29 18:55:18.538433
Epoch:[ 180 2 ] loss: 0.4090926945209503 2022-05-29 18:55:19.314888
Epoch:[ 180 3 ] loss: 0.4009408950805664 2022-05-29 18:55:20.094548
Epoch:[ 180 4 ] loss: 0.4056321382522583 2022-05-29 18:55:20.872490
Epoch:[ 180 5 ] loss: 0.40250515937805176 2022-05-29 18:55:21.658513
Epoch:[ 180 6 ] loss: 0.40639135241508484 2022-05-29 18:55:22.432851
Epoch:[ 180 7 ] loss: 0.40592309832572937 2022-05-29 18:55:23.207222
Epoch:[ 180 8 ] loss: 0.4021674394607544 2022-05-29 18:55:23.981073
Epoch:[ 180 9 ] loss: 0.40906548500061035 2022-05-29 18:55:24.758694
Epoch:[ 180 10 ] loss: 0.40521755814552307 2022-05-29 18:55:25.535867
Epoch:[ 180 11 ] loss: 0.4044431447982788 2022-05-29 18:55:26.322482
Epoch:[ 180 12 ] loss: 0.40524449944496155 2022-05-29 18:55:27.099624
Epoch:[ 180 13 ] loss: 0.40268197655677795 2022-05-29 18:55:27.875080
Epoch:[ 180 14 ] loss: 0.40287721157073975 2022-05-29 18:55:28.662723
Epoch:[ 180 15 ] loss: 0.40511423349380493 2022-05-29 18:55:29.437031
Epoch:[ 180 16 ] loss: 0.40350088477134705 2022-05-29 18:55:36.951341
Epoch:[ 180 17 ] loss: 0.4017787277698517 2022-05-29 18:55:37.741030
Epoch:[ 180 18 ] loss: 0.40243470668792725 2022-05-29 18:55:38.519805
Epoch:[ 180 19 ] loss: 0.40376728773117065 2022-05-29 18:55:39.307586
Training_Epoch:[ 180 ] Training_loss: 0.40394185334444044 2022-05-29 18:55:39.308241
learning rate:  9.007199254741003e-06
netparams have been saved once 180
val: 1 0.5379495620727539
val: 2 0.5465211272239685
val: 3 0.5308334827423096
val: 4 0.5321677923202515
val: 5 0.551982045173645
val: 6 0.54239821434021
val: 7 0.5298105478286743
val: 8 0.5391216278076172
val: 9 0.5284108519554138
val: 10 0.5406323075294495
val: 11 0.5332381725311279
val: 12 0.5315312743186951
val: 13 0.544444739818573
val: 14 0.5359631180763245
val: 15 0.5276796221733093
val: 16 0.5571102499961853
val: 17 0.5338533520698547
val: 18 0.5417064428329468
val: 19 0.5298721194267273
val: 20 0.5522021055221558
val_Epoch:[ 180 ] val_loss: 0.5383714377880097 2022-05-29 18:55:44.646686
start training 2022-05-29 18:55:44.749153
Epoch:[ 181 0 ] loss: 0.4021022915840149 2022-05-29 18:56:07.863402
Epoch:[ 181 1 ] loss: 0.4050339460372925 2022-05-29 18:56:08.684819
Epoch:[ 181 2 ] loss: 0.4030441343784332 2022-05-29 18:56:09.458595
Epoch:[ 181 3 ] loss: 0.4067875146865845 2022-05-29 18:56:10.236732
Epoch:[ 181 4 ] loss: 0.4030277132987976 2022-05-29 18:56:11.014943
Epoch:[ 181 5 ] loss: 0.4041752815246582 2022-05-29 18:56:11.791020
Epoch:[ 181 6 ] loss: 0.40262818336486816 2022-05-29 18:56:12.566614
Epoch:[ 181 7 ] loss: 0.4021252691745758 2022-05-29 18:56:13.354545
Epoch:[ 181 8 ] loss: 0.4004516303539276 2022-05-29 18:56:14.127655
Epoch:[ 181 9 ] loss: 0.400770366191864 2022-05-29 18:56:14.901134
Epoch:[ 181 10 ] loss: 0.40744203329086304 2022-05-29 18:56:15.688906
Epoch:[ 181 11 ] loss: 0.40608474612236023 2022-05-29 18:56:16.465121
Epoch:[ 181 12 ] loss: 0.40535950660705566 2022-05-29 18:56:17.243770
Epoch:[ 181 13 ] loss: 0.4022761285305023 2022-05-29 18:56:18.032367
Epoch:[ 181 14 ] loss: 0.40385332703590393 2022-05-29 18:56:18.807776
Epoch:[ 181 15 ] loss: 0.4040461480617523 2022-05-29 18:56:19.584023
Epoch:[ 181 16 ] loss: 0.4041255712509155 2022-05-29 18:56:26.383848
Epoch:[ 181 17 ] loss: 0.40518420934677124 2022-05-29 18:56:27.161365
Epoch:[ 181 18 ] loss: 0.40224888920783997 2022-05-29 18:56:27.944135
Epoch:[ 181 19 ] loss: 0.40729427337646484 2022-05-29 18:56:28.731196
Training_Epoch:[ 181 ] Training_loss: 0.40390305817127226 2022-05-29 18:56:28.731875
learning rate:  7.205759403792802e-06
val: 1 0.5324017405509949
val: 2 0.5274585485458374
val: 3 0.5554099082946777
val: 4 0.5252847075462341
val: 5 0.539823055267334
val: 6 0.5457066893577576
val: 7 0.5410527586936951
val: 8 0.539546012878418
val: 9 0.5530357956886292
val: 10 0.539389967918396
val: 11 0.5475010871887207
val: 12 0.5562427043914795
val: 13 0.5356378555297852
val: 14 0.5266175270080566
val: 15 0.5311662554740906
val: 16 0.5296834111213684
val: 17 0.5394012928009033
val: 18 0.5378044843673706
val: 19 0.5574221611022949
val: 20 0.5291128158569336
val_Epoch:[ 181 ] val_loss: 0.5394849389791488 2022-05-29 18:56:33.932500
start training 2022-05-29 18:56:34.034443
Epoch:[ 182 0 ] loss: 0.40491658449172974 2022-05-29 18:56:56.542960
Epoch:[ 182 1 ] loss: 0.4073622226715088 2022-05-29 18:56:57.359732
Epoch:[ 182 2 ] loss: 0.40444105863571167 2022-05-29 18:56:58.147751
Epoch:[ 182 3 ] loss: 0.40199920535087585 2022-05-29 18:56:58.921807
Epoch:[ 182 4 ] loss: 0.4043221175670624 2022-05-29 18:56:59.711639
Epoch:[ 182 5 ] loss: 0.40805068612098694 2022-05-29 18:57:00.489087
Epoch:[ 182 6 ] loss: 0.40400806069374084 2022-05-29 18:57:01.264663
Epoch:[ 182 7 ] loss: 0.4026590883731842 2022-05-29 18:57:02.040771
Epoch:[ 182 8 ] loss: 0.4027783274650574 2022-05-29 18:57:02.814545
Epoch:[ 182 9 ] loss: 0.40153834223747253 2022-05-29 18:57:03.589206
Epoch:[ 182 10 ] loss: 0.40278130769729614 2022-05-29 18:57:04.363322
Epoch:[ 182 11 ] loss: 0.4028063118457794 2022-05-29 18:57:05.141446
Epoch:[ 182 12 ] loss: 0.4060366749763489 2022-05-29 18:57:05.920441
Epoch:[ 182 13 ] loss: 0.40193742513656616 2022-05-29 18:57:06.708599
Epoch:[ 182 14 ] loss: 0.4040570557117462 2022-05-29 18:57:07.485105
Epoch:[ 182 15 ] loss: 0.4037519097328186 2022-05-29 18:57:08.260875
Epoch:[ 182 16 ] loss: 0.40182727575302124 2022-05-29 18:57:16.306719
Epoch:[ 182 17 ] loss: 0.4025871753692627 2022-05-29 18:57:17.090962
Epoch:[ 182 18 ] loss: 0.40294864773750305 2022-05-29 18:57:17.883564
Epoch:[ 182 19 ] loss: 0.4025924801826477 2022-05-29 18:57:18.659200
Training_Epoch:[ 182 ] Training_loss: 0.403670097887516 2022-05-29 18:57:18.659898
learning rate:  7.205759403792802e-06
netparams have been saved once 182
val: 1 0.5230647921562195
val: 2 0.5426828861236572
val: 3 0.5482161641120911
val: 4 0.5263539552688599
val: 5 0.547593355178833
val: 6 0.5612074136734009
val: 7 0.543437123298645
val: 8 0.5490841269493103
val: 9 0.5408568978309631
val: 10 0.5338310599327087
val: 11 0.5337496995925903
val: 12 0.5355642437934875
val: 13 0.5466727018356323
val: 14 0.5274328589439392
val: 15 0.5453203320503235
val: 16 0.5308835506439209
val: 17 0.5463060140609741
val: 18 0.5201911330223083
val: 19 0.5252128839492798
val: 20 0.548272430896759
val_Epoch:[ 182 ] val_loss: 0.5387966811656952 2022-05-29 18:57:23.960188
start training 2022-05-29 18:57:24.060040
Epoch:[ 183 0 ] loss: 0.4031916558742523 2022-05-29 18:57:47.800079
Epoch:[ 183 1 ] loss: 0.40736034512519836 2022-05-29 18:57:48.577641
Epoch:[ 183 2 ] loss: 0.4037465453147888 2022-05-29 18:57:49.352362
Epoch:[ 183 3 ] loss: 0.40041571855545044 2022-05-29 18:57:50.128636
Epoch:[ 183 4 ] loss: 0.40414294600486755 2022-05-29 18:57:50.914507
Epoch:[ 183 5 ] loss: 0.4008193016052246 2022-05-29 18:57:51.704139
Epoch:[ 183 6 ] loss: 0.4043548107147217 2022-05-29 18:57:52.481760
Epoch:[ 183 7 ] loss: 0.40150129795074463 2022-05-29 18:57:53.260445
Epoch:[ 183 8 ] loss: 0.40028369426727295 2022-05-29 18:57:54.038674
Epoch:[ 183 9 ] loss: 0.4053313434123993 2022-05-29 18:57:54.814647
Epoch:[ 183 10 ] loss: 0.40441927313804626 2022-05-29 18:57:55.590950
Epoch:[ 183 11 ] loss: 0.4043632745742798 2022-05-29 18:57:56.366480
Epoch:[ 183 12 ] loss: 0.4075612425804138 2022-05-29 18:57:57.143645
Epoch:[ 183 13 ] loss: 0.40308070182800293 2022-05-29 18:57:57.921980
Epoch:[ 183 14 ] loss: 0.4057888090610504 2022-05-29 18:57:58.712038
Epoch:[ 183 15 ] loss: 0.400608628988266 2022-05-29 18:57:59.490019
Epoch:[ 183 16 ] loss: 0.40184900164604187 2022-05-29 18:58:06.637227
Epoch:[ 183 17 ] loss: 0.40736687183380127 2022-05-29 18:58:07.409302
Epoch:[ 183 18 ] loss: 0.40376561880111694 2022-05-29 18:58:08.186982
Epoch:[ 183 19 ] loss: 0.402937114238739 2022-05-29 18:58:08.975694
Training_Epoch:[ 183 ] Training_loss: 0.40364440977573396 2022-05-29 18:58:08.976417
learning rate:  7.205759403792802e-06
val: 1 0.5319962501525879
val: 2 0.5435277819633484
val: 3 0.5411128401756287
val: 4 0.5494285821914673
val: 5 0.5564040541648865
val: 6 0.5373249650001526
val: 7 0.5528421401977539
val: 8 0.535737931728363
val: 9 0.5344728827476501
val: 10 0.5412277579307556
val: 11 0.522040843963623
val: 12 0.5411927700042725
val: 13 0.5324383974075317
val: 14 0.5501256585121155
val: 15 0.546438455581665
val: 16 0.5120353698730469
val: 17 0.5418868660926819
val: 18 0.539689302444458
val: 19 0.5473281145095825
val: 20 0.5352705121040344
val_Epoch:[ 183 ] val_loss: 0.5396260738372802 2022-05-29 18:58:14.224276
start training 2022-05-29 18:58:14.325523
Epoch:[ 184 0 ] loss: 0.4004893898963928 2022-05-29 18:58:36.229042
Epoch:[ 184 1 ] loss: 0.40359801054000854 2022-05-29 18:58:37.079831
Epoch:[ 184 2 ] loss: 0.4025111496448517 2022-05-29 18:58:37.936612
Epoch:[ 184 3 ] loss: 0.4024210572242737 2022-05-29 18:58:38.710477
Epoch:[ 184 4 ] loss: 0.4008030593395233 2022-05-29 18:58:39.484138
Epoch:[ 184 5 ] loss: 0.4044311046600342 2022-05-29 18:58:40.268999
Epoch:[ 184 6 ] loss: 0.4027068614959717 2022-05-29 18:58:41.045632
Epoch:[ 184 7 ] loss: 0.4056049585342407 2022-05-29 18:58:41.824121
Epoch:[ 184 8 ] loss: 0.4038517475128174 2022-05-29 18:58:42.599531
Epoch:[ 184 9 ] loss: 0.40165793895721436 2022-05-29 18:58:43.377626
Epoch:[ 184 10 ] loss: 0.40215644240379333 2022-05-29 18:58:44.152320
Epoch:[ 184 11 ] loss: 0.40315842628479004 2022-05-29 18:58:44.938065
Epoch:[ 184 12 ] loss: 0.40525907278060913 2022-05-29 18:58:45.713834
Epoch:[ 184 13 ] loss: 0.4066680371761322 2022-05-29 18:58:46.490498
Epoch:[ 184 14 ] loss: 0.4023757576942444 2022-05-29 18:58:47.269765
Epoch:[ 184 15 ] loss: 0.40547630190849304 2022-05-29 18:58:48.044098
Epoch:[ 184 16 ] loss: 0.40486857295036316 2022-05-29 18:58:56.244522
Epoch:[ 184 17 ] loss: 0.40194788575172424 2022-05-29 18:58:57.028719
Epoch:[ 184 18 ] loss: 0.40497615933418274 2022-05-29 18:58:57.807965
Epoch:[ 184 19 ] loss: 0.40894097089767456 2022-05-29 18:58:58.580463
Training_Epoch:[ 184 ] Training_loss: 0.4036951452493668 2022-05-29 18:58:58.581148
learning rate:  7.205759403792802e-06
netparams have been saved once 184
val: 1 0.5489702224731445
val: 2 0.5380966067314148
val: 3 0.5264379978179932
val: 4 0.535724937915802
val: 5 0.5337860584259033
val: 6 0.5271554589271545
val: 7 0.5249118208885193
val: 8 0.5434048175811768
val: 9 0.5492845773696899
val: 10 0.5405744314193726
val: 11 0.5281159281730652
val: 12 0.5290996432304382
val: 13 0.5471912622451782
val: 14 0.5376318097114563
val: 15 0.5469093322753906
val: 16 0.5551521182060242
val: 17 0.5355311632156372
val: 18 0.5496377944946289
val: 19 0.526911199092865
val: 20 0.5562753677368164
val_Epoch:[ 184 ] val_loss: 0.5390401273965836 2022-05-29 18:59:03.914276
start training 2022-05-29 18:59:04.014275
Epoch:[ 185 0 ] loss: 0.4044201672077179 2022-05-29 18:59:27.186223
Epoch:[ 185 1 ] loss: 0.4042677879333496 2022-05-29 18:59:27.988173
Epoch:[ 185 2 ] loss: 0.40815213322639465 2022-05-29 18:59:28.774064
Epoch:[ 185 3 ] loss: 0.4033239781856537 2022-05-29 18:59:29.563091
Epoch:[ 185 4 ] loss: 0.40553319454193115 2022-05-29 18:59:30.335847
Epoch:[ 185 5 ] loss: 0.4045978784561157 2022-05-29 18:59:31.113133
Epoch:[ 185 6 ] loss: 0.4006378948688507 2022-05-29 18:59:31.899138
Epoch:[ 185 7 ] loss: 0.40385201573371887 2022-05-29 18:59:32.678316
Epoch:[ 185 8 ] loss: 0.4029563367366791 2022-05-29 18:59:33.455242
Epoch:[ 185 9 ] loss: 0.4016318917274475 2022-05-29 18:59:34.234293
Epoch:[ 185 10 ] loss: 0.4066757559776306 2022-05-29 18:59:35.009785
Epoch:[ 185 11 ] loss: 0.4069725573062897 2022-05-29 18:59:35.783139
Epoch:[ 185 12 ] loss: 0.40104255080223083 2022-05-29 18:59:36.557999
Epoch:[ 185 13 ] loss: 0.4006781578063965 2022-05-29 18:59:37.331722
Epoch:[ 185 14 ] loss: 0.40521419048309326 2022-05-29 18:59:38.108464
Epoch:[ 185 15 ] loss: 0.400480717420578 2022-05-29 18:59:38.885962
Epoch:[ 185 16 ] loss: 0.403617262840271 2022-05-29 18:59:46.716448
Epoch:[ 185 17 ] loss: 0.4025782346725464 2022-05-29 18:59:47.503909
Epoch:[ 185 18 ] loss: 0.40157729387283325 2022-05-29 18:59:48.283008
Epoch:[ 185 19 ] loss: 0.4052911400794983 2022-05-29 18:59:49.054765
Training_Epoch:[ 185 ] Training_loss: 0.40367505699396133 2022-05-29 18:59:49.055454
learning rate:  7.205759403792802e-06
val: 1 0.5421192646026611
val: 2 0.5396206974983215
val: 3 0.5413230657577515
val: 4 0.5395196080207825
val: 5 0.5432378649711609
val: 6 0.5454238057136536
val: 7 0.5371736884117126
val: 8 0.5319147706031799
val: 9 0.5207656621932983
val: 10 0.5453354120254517
val: 11 0.5316793322563171
val: 12 0.5345432162284851
val: 13 0.5430742502212524
val: 14 0.5386459827423096
val: 15 0.5453831553459167
val: 16 0.5318959951400757
val: 17 0.5423009991645813
val: 18 0.5422472357749939
val: 19 0.554609477519989
val: 20 0.5352365970611572
val_Epoch:[ 185 ] val_loss: 0.5393025040626526 2022-05-29 18:59:54.314341
start training 2022-05-29 18:59:54.415398
Epoch:[ 186 0 ] loss: 0.4094713032245636 2022-05-29 19:00:17.137009
Epoch:[ 186 1 ] loss: 0.402494877576828 2022-05-29 19:00:18.180735
Epoch:[ 186 2 ] loss: 0.40679410099983215 2022-05-29 19:00:18.958884
Epoch:[ 186 3 ] loss: 0.4013080894947052 2022-05-29 19:00:19.735184
Epoch:[ 186 4 ] loss: 0.4034905731678009 2022-05-29 19:00:20.511559
Epoch:[ 186 5 ] loss: 0.40282633900642395 2022-05-29 19:00:21.286031
Epoch:[ 186 6 ] loss: 0.4027373790740967 2022-05-29 19:00:22.058786
Epoch:[ 186 7 ] loss: 0.4044933617115021 2022-05-29 19:00:22.831895
Epoch:[ 186 8 ] loss: 0.40180203318595886 2022-05-29 19:00:23.620119
Epoch:[ 186 9 ] loss: 0.4008312225341797 2022-05-29 19:00:24.410312
Epoch:[ 186 10 ] loss: 0.40190964937210083 2022-05-29 19:00:25.184829
Epoch:[ 186 11 ] loss: 0.40338051319122314 2022-05-29 19:00:25.971272
Epoch:[ 186 12 ] loss: 0.40211647748947144 2022-05-29 19:00:26.744868
Epoch:[ 186 13 ] loss: 0.4076424539089203 2022-05-29 19:00:27.520149
Epoch:[ 186 14 ] loss: 0.4031131863594055 2022-05-29 19:00:28.295540
Epoch:[ 186 15 ] loss: 0.4041198194026947 2022-05-29 19:00:29.072206
Epoch:[ 186 16 ] loss: 0.40600067377090454 2022-05-29 19:00:36.796049
Epoch:[ 186 17 ] loss: 0.40401339530944824 2022-05-29 19:00:37.582391
Epoch:[ 186 18 ] loss: 0.40049082040786743 2022-05-29 19:00:38.363450
Epoch:[ 186 19 ] loss: 0.4031265079975128 2022-05-29 19:00:39.148524
Training_Epoch:[ 186 ] Training_loss: 0.403608138859272 2022-05-29 19:00:39.149221
learning rate:  7.205759403792802e-06
netparams have been saved once 186
val: 1 0.5422843098640442
val: 2 0.5405808091163635
val: 3 0.5545232892036438
val: 4 0.5267961621284485
val: 5 0.5590954422950745
val: 6 0.5545151233673096
val: 7 0.5358763337135315
val: 8 0.5245206356048584
val: 9 0.5396714806556702
val: 10 0.5361800789833069
val: 11 0.5299961566925049
val: 12 0.5360329747200012
val: 13 0.5337591171264648
val: 14 0.5553619861602783
val: 15 0.5156680345535278
val: 16 0.5294419527053833
val: 17 0.5451004505157471
val: 18 0.5273751616477966
val: 19 0.5704958438873291
val: 20 0.5223599672317505
val_Epoch:[ 186 ] val_loss: 0.5389817655086517 2022-05-29 19:00:44.611245
start training 2022-05-29 19:00:44.715143
Epoch:[ 187 0 ] loss: 0.40260380506515503 2022-05-29 19:01:08.776339
Epoch:[ 187 1 ] loss: 0.401515394449234 2022-05-29 19:01:09.562025
Epoch:[ 187 2 ] loss: 0.4042680859565735 2022-05-29 19:01:10.338527
Epoch:[ 187 3 ] loss: 0.401258647441864 2022-05-29 19:01:11.115915
Epoch:[ 187 4 ] loss: 0.40364450216293335 2022-05-29 19:01:11.895184
Epoch:[ 187 5 ] loss: 0.40133053064346313 2022-05-29 19:01:12.672786
Epoch:[ 187 6 ] loss: 0.4035704731941223 2022-05-29 19:01:13.447424
Epoch:[ 187 7 ] loss: 0.40521979331970215 2022-05-29 19:01:14.224839
Epoch:[ 187 8 ] loss: 0.40309059619903564 2022-05-29 19:01:15.001525
Epoch:[ 187 9 ] loss: 0.4023585021495819 2022-05-29 19:01:15.778120
Epoch:[ 187 10 ] loss: 0.4073481261730194 2022-05-29 19:01:16.567895
Epoch:[ 187 11 ] loss: 0.4075590968132019 2022-05-29 19:01:17.344906
Epoch:[ 187 12 ] loss: 0.4043857157230377 2022-05-29 19:01:18.120003
Epoch:[ 187 13 ] loss: 0.4040032923221588 2022-05-29 19:01:18.894155
Epoch:[ 187 14 ] loss: 0.4037480056285858 2022-05-29 19:01:19.678988
Epoch:[ 187 15 ] loss: 0.4041776955127716 2022-05-29 19:01:20.454013
Epoch:[ 187 16 ] loss: 0.4023866057395935 2022-05-29 19:01:27.130893
Epoch:[ 187 17 ] loss: 0.40176650881767273 2022-05-29 19:01:27.919435
Epoch:[ 187 18 ] loss: 0.402340292930603 2022-05-29 19:01:28.701004
Epoch:[ 187 19 ] loss: 0.4034825563430786 2022-05-29 19:01:29.475338
Training_Epoch:[ 187 ] Training_loss: 0.4035029113292694 2022-05-29 19:01:29.476048
learning rate:  7.205759403792802e-06
val: 1 0.5279980897903442
val: 2 0.5477228164672852
val: 3 0.5414441227912903
val: 4 0.5281032919883728
val: 5 0.5527381896972656
val: 6 0.5074946284294128
val: 7 0.5416907072067261
val: 8 0.5285273194313049
val: 9 0.5496423840522766
val: 10 0.5391719937324524
val: 11 0.5275932550430298
val: 12 0.5474186539649963
val: 13 0.536047101020813
val: 14 0.5418384671211243
val: 15 0.5586247444152832
val: 16 0.5459280610084534
val: 17 0.5498718619346619
val: 18 0.5220528841018677
val: 19 0.5363373160362244
val: 20 0.5532971024513245
val_Epoch:[ 187 ] val_loss: 0.5391771495342255 2022-05-29 19:01:34.730013
start training 2022-05-29 19:01:34.830829
Epoch:[ 188 0 ] loss: 0.4065013527870178 2022-05-29 19:01:58.304718
Epoch:[ 188 1 ] loss: 0.405103862285614 2022-05-29 19:01:59.081473
Epoch:[ 188 2 ] loss: 0.4027057886123657 2022-05-29 19:01:59.868444
Epoch:[ 188 3 ] loss: 0.4023069143295288 2022-05-29 19:02:00.646413
Epoch:[ 188 4 ] loss: 0.4033561944961548 2022-05-29 19:02:01.435521
Epoch:[ 188 5 ] loss: 0.40326711535453796 2022-05-29 19:02:02.213860
Epoch:[ 188 6 ] loss: 0.400896281003952 2022-05-29 19:02:02.989976
Epoch:[ 188 7 ] loss: 0.4003073275089264 2022-05-29 19:02:03.765735
Epoch:[ 188 8 ] loss: 0.4021707773208618 2022-05-29 19:02:04.543407
Epoch:[ 188 9 ] loss: 0.4038325548171997 2022-05-29 19:02:05.317828
Epoch:[ 188 10 ] loss: 0.40408334136009216 2022-05-29 19:02:06.093945
Epoch:[ 188 11 ] loss: 0.40482932329177856 2022-05-29 19:02:06.872466
Epoch:[ 188 12 ] loss: 0.4057639241218567 2022-05-29 19:02:07.652116
Epoch:[ 188 13 ] loss: 0.40124306082725525 2022-05-29 19:02:08.430801
Epoch:[ 188 14 ] loss: 0.4061529040336609 2022-05-29 19:02:09.219015
Epoch:[ 188 15 ] loss: 0.40140804648399353 2022-05-29 19:02:09.995931
Epoch:[ 188 16 ] loss: 0.4060153365135193 2022-05-29 19:02:17.470804
Epoch:[ 188 17 ] loss: 0.4057523310184479 2022-05-29 19:02:18.260764
Epoch:[ 188 18 ] loss: 0.4041820168495178 2022-05-29 19:02:19.041601
Epoch:[ 188 19 ] loss: 0.4010555148124695 2022-05-29 19:02:19.816811
Training_Epoch:[ 188 ] Training_loss: 0.40354669839143753 2022-05-29 19:02:19.817585
learning rate:  7.205759403792802e-06
netparams have been saved once 188
val: 1 0.5204437375068665
val: 2 0.5415129065513611
val: 3 0.5402514338493347
val: 4 0.5555689334869385
val: 5 0.5331773161888123
val: 6 0.5400009155273438
val: 7 0.5455286502838135
val: 8 0.5503658652305603
val: 9 0.5356744527816772
val: 10 0.5331758856773376
val: 11 0.5547629594802856
val: 12 0.5366498827934265
val: 13 0.5443346500396729
val: 14 0.5247650146484375
val: 15 0.5482775568962097
val: 16 0.5436335802078247
val: 17 0.5243019461631775
val: 18 0.5256654620170593
val: 19 0.5402991771697998
val: 20 0.533509373664856
val_Epoch:[ 188 ] val_loss: 0.5385949850082398 2022-05-29 19:02:25.086598
start training 2022-05-29 19:02:25.189008
Epoch:[ 189 0 ] loss: 0.4035020172595978 2022-05-29 19:02:48.801814
Epoch:[ 189 1 ] loss: 0.4056845009326935 2022-05-29 19:02:49.576308
Epoch:[ 189 2 ] loss: 0.4044012427330017 2022-05-29 19:02:50.350584
Epoch:[ 189 3 ] loss: 0.40125685930252075 2022-05-29 19:02:51.124104
Epoch:[ 189 4 ] loss: 0.4050932228565216 2022-05-29 19:02:51.899736
Epoch:[ 189 5 ] loss: 0.4027418792247772 2022-05-29 19:02:52.688569
Epoch:[ 189 6 ] loss: 0.4038301110267639 2022-05-29 19:02:53.464408
Epoch:[ 189 7 ] loss: 0.40354830026626587 2022-05-29 19:02:54.240805
Epoch:[ 189 8 ] loss: 0.40222567319869995 2022-05-29 19:02:55.014315
Epoch:[ 189 9 ] loss: 0.4024858772754669 2022-05-29 19:02:55.790944
Epoch:[ 189 10 ] loss: 0.40195417404174805 2022-05-29 19:02:56.575948
Epoch:[ 189 11 ] loss: 0.40373557806015015 2022-05-29 19:02:57.351532
Epoch:[ 189 12 ] loss: 0.4032055139541626 2022-05-29 19:02:58.125788
Epoch:[ 189 13 ] loss: 0.4004620909690857 2022-05-29 19:02:58.900155
Epoch:[ 189 14 ] loss: 0.4059301018714905 2022-05-29 19:02:59.674725
Epoch:[ 189 15 ] loss: 0.40407323837280273 2022-05-29 19:03:00.461937
Epoch:[ 189 16 ] loss: 0.40774500370025635 2022-05-29 19:03:07.404405
Epoch:[ 189 17 ] loss: 0.40761491656303406 2022-05-29 19:03:08.176201
Epoch:[ 189 18 ] loss: 0.4012471139431 2022-05-29 19:03:08.966287
Epoch:[ 189 19 ] loss: 0.4013766348361969 2022-05-29 19:03:09.743070
Training_Epoch:[ 189 ] Training_loss: 0.4036057025194168 2022-05-29 19:03:09.743764
learning rate:  7.205759403792802e-06
val: 1 0.5451775193214417
val: 2 0.5106053948402405
val: 3 0.5451580286026001
val: 4 0.5689130425453186
val: 5 0.5271338224411011
val: 6 0.5426998138427734
val: 7 0.5250617265701294
val: 8 0.5458112955093384
val: 9 0.5478512644767761
val: 10 0.5369552969932556
val: 11 0.5191441774368286
val: 12 0.5383263230323792
val: 13 0.5412627458572388
val: 14 0.5254926681518555
val: 15 0.5498191118240356
val: 16 0.5470662117004395
val: 17 0.5409906506538391
val: 18 0.5419244170188904
val: 19 0.5388292074203491
val: 20 0.5370163321495056
val_Epoch:[ 189 ] val_loss: 0.5387619525194168 2022-05-29 19:03:15.058770
start training 2022-05-29 19:03:15.163201
Epoch:[ 190 0 ] loss: 0.4034445583820343 2022-05-29 19:03:38.998650
Epoch:[ 190 1 ] loss: 0.402042955160141 2022-05-29 19:03:39.788225
Epoch:[ 190 2 ] loss: 0.4057651162147522 2022-05-29 19:03:40.575112
Epoch:[ 190 3 ] loss: 0.40270817279815674 2022-05-29 19:03:41.348178
Epoch:[ 190 4 ] loss: 0.40951007604599 2022-05-29 19:03:42.125120
Epoch:[ 190 5 ] loss: 0.40622827410697937 2022-05-29 19:03:42.903638
Epoch:[ 190 6 ] loss: 0.40689244866371155 2022-05-29 19:03:43.681352
Epoch:[ 190 7 ] loss: 0.40806958079338074 2022-05-29 19:03:44.458677
Epoch:[ 190 8 ] loss: 0.3998713195323944 2022-05-29 19:03:45.234840
Epoch:[ 190 9 ] loss: 0.4006636142730713 2022-05-29 19:03:46.010339
Epoch:[ 190 10 ] loss: 0.40153735876083374 2022-05-29 19:03:46.789419
Epoch:[ 190 11 ] loss: 0.4049828052520752 2022-05-29 19:03:47.564581
Epoch:[ 190 12 ] loss: 0.40221065282821655 2022-05-29 19:03:48.341192
Epoch:[ 190 13 ] loss: 0.3989325761795044 2022-05-29 19:03:49.131730
Epoch:[ 190 14 ] loss: 0.40476781129837036 2022-05-29 19:03:49.908387
Epoch:[ 190 15 ] loss: 0.4057292342185974 2022-05-29 19:03:50.682826
Epoch:[ 190 16 ] loss: 0.4013121426105499 2022-05-29 19:03:57.710223
Epoch:[ 190 17 ] loss: 0.4056827127933502 2022-05-29 19:03:58.498717
Epoch:[ 190 18 ] loss: 0.39817580580711365 2022-05-29 19:03:59.289706
Epoch:[ 190 19 ] loss: 0.4056530296802521 2022-05-29 19:04:00.065643
Training_Epoch:[ 190 ] Training_loss: 0.40370901226997374 2022-05-29 19:04:00.066366
learning rate:  7.205759403792802e-06
netparams have been saved once 190
val: 1 0.5506945252418518
val: 2 0.5463228821754456
val: 3 0.5355098247528076
val: 4 0.5335500240325928
val: 5 0.5176756381988525
val: 6 0.5157737731933594
val: 7 0.5542870163917542
val: 8 0.5392685532569885
val: 9 0.5288580656051636
val: 10 0.5345345735549927
val: 11 0.5405822396278381
val: 12 0.5498437881469727
val: 13 0.5127454400062561
val: 14 0.5418001413345337
val: 15 0.5536817908287048
val: 16 0.5426270365715027
val: 17 0.5367015600204468
val: 18 0.5385758876800537
val: 19 0.5654376745223999
val: 20 0.5342010259628296
val_Epoch:[ 190 ] val_loss: 0.5386335730552674 2022-05-29 19:04:05.386434
start training 2022-05-29 19:04:05.488173
Epoch:[ 191 0 ] loss: 0.4011117219924927 2022-05-29 19:04:27.778402
Epoch:[ 191 1 ] loss: 0.4008364677429199 2022-05-29 19:04:28.547573
Epoch:[ 191 2 ] loss: 0.4028700888156891 2022-05-29 19:04:29.399456
Epoch:[ 191 3 ] loss: 0.40017199516296387 2022-05-29 19:04:30.173514
Epoch:[ 191 4 ] loss: 0.403062105178833 2022-05-29 19:04:30.946793
Epoch:[ 191 5 ] loss: 0.4009697735309601 2022-05-29 19:04:31.720287
Epoch:[ 191 6 ] loss: 0.4014662802219391 2022-05-29 19:04:32.510282
Epoch:[ 191 7 ] loss: 0.4060836732387543 2022-05-29 19:04:33.286937
Epoch:[ 191 8 ] loss: 0.40159741044044495 2022-05-29 19:04:34.061855
Epoch:[ 191 9 ] loss: 0.40679752826690674 2022-05-29 19:04:34.837884
Epoch:[ 191 10 ] loss: 0.4071127772331238 2022-05-29 19:04:35.613093
Epoch:[ 191 11 ] loss: 0.40681540966033936 2022-05-29 19:04:36.389868
Epoch:[ 191 12 ] loss: 0.4006368815898895 2022-05-29 19:04:37.164439
Epoch:[ 191 13 ] loss: 0.4030018150806427 2022-05-29 19:04:37.954680
Epoch:[ 191 14 ] loss: 0.40636080503463745 2022-05-29 19:04:38.733637
Epoch:[ 191 15 ] loss: 0.4038374125957489 2022-05-29 19:04:39.514581
Epoch:[ 191 16 ] loss: 0.4036482870578766 2022-05-29 19:04:47.362338
Epoch:[ 191 17 ] loss: 0.40691325068473816 2022-05-29 19:04:48.234427
Epoch:[ 191 18 ] loss: 0.4023717939853668 2022-05-29 19:04:49.025860
Epoch:[ 191 19 ] loss: 0.40629521012306213 2022-05-29 19:04:49.798790
Training_Epoch:[ 191 ] Training_loss: 0.4035980343818665 2022-05-29 19:04:49.799641
learning rate:  5.764607523034242e-06
val: 1 0.5569022297859192
val: 2 0.5519217252731323
val: 3 0.5390138030052185
val: 4 0.5490512847900391
val: 5 0.5357115864753723
val: 6 0.5374783277511597
val: 7 0.5162633061408997
val: 8 0.5261427164077759
val: 9 0.5517452955245972
val: 10 0.5293304324150085
val: 11 0.5422458648681641
val: 12 0.5359904170036316
val: 13 0.5423020720481873
val: 14 0.5451486706733704
val: 15 0.5431525707244873
val: 16 0.5130465626716614
val: 17 0.5189236998558044
val: 18 0.5484475493431091
val: 19 0.5366427898406982
val: 20 0.554750382900238
val_Epoch:[ 191 ] val_loss: 0.5387105643749237 2022-05-29 19:04:55.052644
start training 2022-05-29 19:04:55.156764
Epoch:[ 192 0 ] loss: 0.4051852524280548 2022-05-29 19:05:17.901089
Epoch:[ 192 1 ] loss: 0.4073915183544159 2022-05-29 19:05:18.729283
Epoch:[ 192 2 ] loss: 0.4049161374568939 2022-05-29 19:05:19.506077
Epoch:[ 192 3 ] loss: 0.4009495675563812 2022-05-29 19:05:20.283187
Epoch:[ 192 4 ] loss: 0.40497133135795593 2022-05-29 19:05:21.057536
Epoch:[ 192 5 ] loss: 0.40193650126457214 2022-05-29 19:05:21.835151
Epoch:[ 192 6 ] loss: 0.40171483159065247 2022-05-29 19:05:22.608487
Epoch:[ 192 7 ] loss: 0.4059595763683319 2022-05-29 19:05:23.385952
Epoch:[ 192 8 ] loss: 0.40149176120758057 2022-05-29 19:05:24.162186
Epoch:[ 192 9 ] loss: 0.4017029404640198 2022-05-29 19:05:24.941846
Epoch:[ 192 10 ] loss: 0.4029845893383026 2022-05-29 19:05:25.717339
Epoch:[ 192 11 ] loss: 0.40416818857192993 2022-05-29 19:05:26.493311
Epoch:[ 192 12 ] loss: 0.4017821252346039 2022-05-29 19:05:27.268085
Epoch:[ 192 13 ] loss: 0.4016304910182953 2022-05-29 19:05:28.055411
Epoch:[ 192 14 ] loss: 0.40345481038093567 2022-05-29 19:05:28.846133
Epoch:[ 192 15 ] loss: 0.4076066315174103 2022-05-29 19:05:29.624729
Epoch:[ 192 16 ] loss: 0.40572690963745117 2022-05-29 19:05:37.657996
Epoch:[ 192 17 ] loss: 0.40259185433387756 2022-05-29 19:05:38.446714
Epoch:[ 192 18 ] loss: 0.40528252720832825 2022-05-29 19:05:39.239295
Epoch:[ 192 19 ] loss: 0.3981538712978363 2022-05-29 19:05:40.012584
Training_Epoch:[ 192 ] Training_loss: 0.40348007082939147 2022-05-29 19:05:40.013339
learning rate:  5.764607523034242e-06
netparams have been saved once 192
val: 1 0.5180572867393494
val: 2 0.5424283146858215
val: 3 0.517850399017334
val: 4 0.5519034266471863
val: 5 0.5620484352111816
val: 6 0.5564762949943542
val: 7 0.5438239574432373
val: 8 0.5393752455711365
val: 9 0.504718542098999
val: 10 0.5383347272872925
val: 11 0.5437266230583191
val: 12 0.544638454914093
val: 13 0.5389174818992615
val: 14 0.525460422039032
val: 15 0.5408360362052917
val: 16 0.5523777008056641
val: 17 0.536200761795044
val: 18 0.5372514724731445
val: 19 0.5420359969139099
val: 20 0.546960711479187
val_Epoch:[ 192 ] val_loss: 0.539171114563942 2022-05-29 19:05:45.353462
start training 2022-05-29 19:05:45.459501
Epoch:[ 193 0 ] loss: 0.4011801779270172 2022-05-29 19:06:09.062765
Epoch:[ 193 1 ] loss: 0.4058881103992462 2022-05-29 19:06:09.840101
Epoch:[ 193 2 ] loss: 0.40100058913230896 2022-05-29 19:06:10.616109
Epoch:[ 193 3 ] loss: 0.40348169207572937 2022-05-29 19:06:11.394602
Epoch:[ 193 4 ] loss: 0.40329012274742126 2022-05-29 19:06:12.172567
Epoch:[ 193 5 ] loss: 0.4032893180847168 2022-05-29 19:06:12.958921
Epoch:[ 193 6 ] loss: 0.40294861793518066 2022-05-29 19:06:13.735071
Epoch:[ 193 7 ] loss: 0.4016442894935608 2022-05-29 19:06:14.522125
Epoch:[ 193 8 ] loss: 0.4025307595729828 2022-05-29 19:06:15.298158
Epoch:[ 193 9 ] loss: 0.4033123254776001 2022-05-29 19:06:16.075539
Epoch:[ 193 10 ] loss: 0.4038184881210327 2022-05-29 19:06:16.851037
Epoch:[ 193 11 ] loss: 0.40303835272789 2022-05-29 19:06:17.638251
Epoch:[ 193 12 ] loss: 0.4013461172580719 2022-05-29 19:06:18.414801
Epoch:[ 193 13 ] loss: 0.4026910364627838 2022-05-29 19:06:19.189335
Epoch:[ 193 14 ] loss: 0.4079228341579437 2022-05-29 19:06:19.963489
Epoch:[ 193 15 ] loss: 0.40525004267692566 2022-05-29 19:06:20.738720
Epoch:[ 193 16 ] loss: 0.40447568893432617 2022-05-29 19:06:27.954063
Epoch:[ 193 17 ] loss: 0.40452784299850464 2022-05-29 19:06:28.739619
Epoch:[ 193 18 ] loss: 0.4050055742263794 2022-05-29 19:06:29.543404
Epoch:[ 193 19 ] loss: 0.4032725691795349 2022-05-29 19:06:30.317147
Training_Epoch:[ 193 ] Training_loss: 0.40349572747945783 2022-05-29 19:06:30.317847
learning rate:  5.764607523034242e-06
val: 1 0.5493694543838501
val: 2 0.5575711727142334
val: 3 0.5486748814582825
val: 4 0.5216333866119385
val: 5 0.5401474833488464
val: 6 0.5417757034301758
val: 7 0.5482907295227051
val: 8 0.5108315348625183
val: 9 0.5364142060279846
val: 10 0.5491864681243896
val: 11 0.5412748456001282
val: 12 0.5367792844772339
val: 13 0.5398136377334595
val: 14 0.5469120144844055
val: 15 0.5395698547363281
val: 16 0.5205143690109253
val: 17 0.5373927354812622
val: 18 0.545123279094696
val: 19 0.5355830788612366
val: 20 0.5339945554733276
val_Epoch:[ 193 ] val_loss: 0.5390426337718963 2022-05-29 19:06:35.458557
start training 2022-05-29 19:06:35.563245
Epoch:[ 194 0 ] loss: 0.4075855314731598 2022-05-29 19:06:59.552458
Epoch:[ 194 1 ] loss: 0.40067338943481445 2022-05-29 19:07:00.326960
Epoch:[ 194 2 ] loss: 0.40469473600387573 2022-05-29 19:07:01.105980
Epoch:[ 194 3 ] loss: 0.4013836979866028 2022-05-29 19:07:01.896850
Epoch:[ 194 4 ] loss: 0.4063280522823334 2022-05-29 19:07:02.685946
Epoch:[ 194 5 ] loss: 0.4028179347515106 2022-05-29 19:07:03.465747
Epoch:[ 194 6 ] loss: 0.4038351774215698 2022-05-29 19:07:04.240102
Epoch:[ 194 7 ] loss: 0.3998009264469147 2022-05-29 19:07:05.017094
Epoch:[ 194 8 ] loss: 0.4071727991104126 2022-05-29 19:07:05.793034
Epoch:[ 194 9 ] loss: 0.4005582928657532 2022-05-29 19:07:06.571604
Epoch:[ 194 10 ] loss: 0.4003586173057556 2022-05-29 19:07:07.350494
Epoch:[ 194 11 ] loss: 0.4020562171936035 2022-05-29 19:07:08.129585
Epoch:[ 194 12 ] loss: 0.40616288781166077 2022-05-29 19:07:08.917289
Epoch:[ 194 13 ] loss: 0.4026183784008026 2022-05-29 19:07:09.693443
Epoch:[ 194 14 ] loss: 0.403260737657547 2022-05-29 19:07:10.468779
Epoch:[ 194 15 ] loss: 0.4022614657878876 2022-05-29 19:07:11.245027
Epoch:[ 194 16 ] loss: 0.40599706768989563 2022-05-29 19:07:18.309649
Epoch:[ 194 17 ] loss: 0.4061135947704315 2022-05-29 19:07:19.098872
Epoch:[ 194 18 ] loss: 0.4013751745223999 2022-05-29 19:07:19.891323
Epoch:[ 194 19 ] loss: 0.4046722948551178 2022-05-29 19:07:20.666947
Training_Epoch:[ 194 ] Training_loss: 0.40348634868860245 2022-05-29 19:07:20.667665
learning rate:  5.764607523034242e-06
netparams have been saved once 194
val: 1 0.5426420569419861
val: 2 0.561688244342804
val: 3 0.5362765192985535
val: 4 0.542838454246521
val: 5 0.5282865762710571
val: 6 0.5440282225608826
val: 7 0.5320358872413635
val: 8 0.5179307460784912
val: 9 0.545705258846283
val: 10 0.5414990782737732
val: 11 0.538932204246521
val: 12 0.5485446453094482
val: 13 0.5272256135940552
val: 14 0.5504642128944397
val: 15 0.5479025840759277
val: 16 0.5153718590736389
val: 17 0.5537387728691101
val: 18 0.5305907130241394
val: 19 0.5473926067352295
val: 20 0.5380124449729919
val_Epoch:[ 194 ] val_loss: 0.5395553350448609 2022-05-29 19:07:25.985041
start training 2022-05-29 19:07:26.088879
Epoch:[ 195 0 ] loss: 0.4014560580253601 2022-05-29 19:07:48.896557
Epoch:[ 195 1 ] loss: 0.40626010298728943 2022-05-29 19:07:49.716197
Epoch:[ 195 2 ] loss: 0.40732505917549133 2022-05-29 19:07:50.501522
Epoch:[ 195 3 ] loss: 0.40365928411483765 2022-05-29 19:07:51.279965
Epoch:[ 195 4 ] loss: 0.40241092443466187 2022-05-29 19:07:52.068498
Epoch:[ 195 5 ] loss: 0.4074016213417053 2022-05-29 19:07:52.842506
Epoch:[ 195 6 ] loss: 0.4024771451950073 2022-05-29 19:07:53.617910
Epoch:[ 195 7 ] loss: 0.39907199144363403 2022-05-29 19:07:54.391549
Epoch:[ 195 8 ] loss: 0.4062603712081909 2022-05-29 19:07:55.169835
Epoch:[ 195 9 ] loss: 0.40455082058906555 2022-05-29 19:07:55.943982
Epoch:[ 195 10 ] loss: 0.4017307460308075 2022-05-29 19:07:56.731724
Epoch:[ 195 11 ] loss: 0.39910489320755005 2022-05-29 19:07:57.508039
Epoch:[ 195 12 ] loss: 0.40422362089157104 2022-05-29 19:07:58.282826
Epoch:[ 195 13 ] loss: 0.4053749144077301 2022-05-29 19:07:59.060122
Epoch:[ 195 14 ] loss: 0.4012259542942047 2022-05-29 19:07:59.834387
Epoch:[ 195 15 ] loss: 0.40678519010543823 2022-05-29 19:08:00.609285
Epoch:[ 195 16 ] loss: 0.4012165367603302 2022-05-29 19:08:08.297799
Epoch:[ 195 17 ] loss: 0.40100881457328796 2022-05-29 19:08:09.074053
Epoch:[ 195 18 ] loss: 0.4024685323238373 2022-05-29 19:08:09.855771
Epoch:[ 195 19 ] loss: 0.4047423303127289 2022-05-29 19:08:10.641260
Training_Epoch:[ 195 ] Training_loss: 0.4034377455711365 2022-05-29 19:08:10.641978
learning rate:  5.764607523034242e-06
val: 1 0.5553306937217712
val: 2 0.5545281171798706
val: 3 0.51987624168396
val: 4 0.5301313996315002
val: 5 0.5424718260765076
val: 6 0.5301814079284668
val: 7 0.5502877831459045
val: 8 0.551879346370697
val: 9 0.5408326983451843
val: 10 0.5482350587844849
val: 11 0.5403689742088318
val: 12 0.5371696949005127
val: 13 0.5277268290519714
val: 14 0.5192587375640869
val: 15 0.5639451146125793
val: 16 0.5311760306358337
val: 17 0.5125716328620911
val: 18 0.5381639003753662
val: 19 0.5565016269683838
val: 20 0.5251094102859497
val_Epoch:[ 195 ] val_loss: 0.5387873262166977 2022-05-29 19:08:15.801223
start training 2022-05-29 19:08:15.903732
Epoch:[ 196 0 ] loss: 0.402565598487854 2022-05-29 19:08:39.161558
Epoch:[ 196 1 ] loss: 0.4008488953113556 2022-05-29 19:08:39.936034
Epoch:[ 196 2 ] loss: 0.4041968882083893 2022-05-29 19:08:40.724043
Epoch:[ 196 3 ] loss: 0.40590596199035645 2022-05-29 19:08:41.497986
Epoch:[ 196 4 ] loss: 0.4043225646018982 2022-05-29 19:08:42.274294
Epoch:[ 196 5 ] loss: 0.40378859639167786 2022-05-29 19:08:43.050519
Epoch:[ 196 6 ] loss: 0.4032551944255829 2022-05-29 19:08:43.825181
Epoch:[ 196 7 ] loss: 0.4062410891056061 2022-05-29 19:08:44.601923
Epoch:[ 196 8 ] loss: 0.40443140268325806 2022-05-29 19:08:45.376175
Epoch:[ 196 9 ] loss: 0.40237510204315186 2022-05-29 19:08:46.150425
Epoch:[ 196 10 ] loss: 0.40215936303138733 2022-05-29 19:08:46.923282
Epoch:[ 196 11 ] loss: 0.4029500484466553 2022-05-29 19:08:47.710756
Epoch:[ 196 12 ] loss: 0.4054921865463257 2022-05-29 19:08:48.486678
Epoch:[ 196 13 ] loss: 0.4079276919364929 2022-05-29 19:08:49.275900
Epoch:[ 196 14 ] loss: 0.4036090075969696 2022-05-29 19:08:50.050675
Epoch:[ 196 15 ] loss: 0.4051985740661621 2022-05-29 19:08:50.823493
Epoch:[ 196 16 ] loss: 0.4008479416370392 2022-05-29 19:08:58.089378
Epoch:[ 196 17 ] loss: 0.40210476517677307 2022-05-29 19:08:58.861715
Epoch:[ 196 18 ] loss: 0.40279483795166016 2022-05-29 19:08:59.643195
Epoch:[ 196 19 ] loss: 0.4007072150707245 2022-05-29 19:09:00.432928
Training_Epoch:[ 196 ] Training_loss: 0.403586146235466 2022-05-29 19:09:00.433636
learning rate:  5.764607523034242e-06
netparams have been saved once 196
val: 1 0.5524436831474304
val: 2 0.5546553134918213
val: 3 0.5249322056770325
val: 4 0.5344279408454895
val: 5 0.5333863496780396
val: 6 0.5205659866333008
val: 7 0.5468960404396057
val: 8 0.5764356255531311
val: 9 0.5347205400466919
val: 10 0.5324097275733948
val: 11 0.5560798048973083
val: 12 0.543137788772583
val: 13 0.5433669686317444
val: 14 0.5181347131729126
val: 15 0.5383182168006897
val: 16 0.54430091381073
val: 17 0.5266289710998535
val: 18 0.5325926542282104
val: 19 0.5351164937019348
val: 20 0.5333878397941589
val_Epoch:[ 196 ] val_loss: 0.5390968888998031 2022-05-29 19:09:05.771211
start training 2022-05-29 19:09:05.875239
Epoch:[ 197 0 ] loss: 0.4006683826446533 2022-05-29 19:09:28.255097
Epoch:[ 197 1 ] loss: 0.4061897397041321 2022-05-29 19:09:29.380642
Epoch:[ 197 2 ] loss: 0.4052585959434509 2022-05-29 19:09:30.155008
Epoch:[ 197 3 ] loss: 0.40227067470550537 2022-05-29 19:09:30.931309
Epoch:[ 197 4 ] loss: 0.40181228518486023 2022-05-29 19:09:31.703803
Epoch:[ 197 5 ] loss: 0.40486276149749756 2022-05-29 19:09:32.480942
Epoch:[ 197 6 ] loss: 0.4060715436935425 2022-05-29 19:09:33.259919
Epoch:[ 197 7 ] loss: 0.39983490109443665 2022-05-29 19:09:34.037882
Epoch:[ 197 8 ] loss: 0.409169465303421 2022-05-29 19:09:34.825985
Epoch:[ 197 9 ] loss: 0.403777152299881 2022-05-29 19:09:35.611050
Epoch:[ 197 10 ] loss: 0.40314584970474243 2022-05-29 19:09:36.386061
Epoch:[ 197 11 ] loss: 0.40107041597366333 2022-05-29 19:09:37.159260
Epoch:[ 197 12 ] loss: 0.4046752452850342 2022-05-29 19:09:37.936755
Epoch:[ 197 13 ] loss: 0.40306076407432556 2022-05-29 19:09:38.712223
Epoch:[ 197 14 ] loss: 0.4035153388977051 2022-05-29 19:09:39.488198
Epoch:[ 197 15 ] loss: 0.4063432812690735 2022-05-29 19:09:40.274218
Epoch:[ 197 16 ] loss: 0.4038298428058624 2022-05-29 19:09:47.529097
Epoch:[ 197 17 ] loss: 0.4034099578857422 2022-05-29 19:09:48.314581
Epoch:[ 197 18 ] loss: 0.39860931038856506 2022-05-29 19:09:49.103258
Epoch:[ 197 19 ] loss: 0.40188145637512207 2022-05-29 19:09:49.878194
Training_Epoch:[ 197 ] Training_loss: 0.4034728482365608 2022-05-29 19:09:49.878911
learning rate:  5.764607523034242e-06
val: 1 0.5436615347862244
val: 2 0.5274307727813721
val: 3 0.5635220408439636
val: 4 0.5515099763870239
val: 5 0.5244807004928589
val: 6 0.5112863779067993
val: 7 0.5354580879211426
val: 8 0.5489745736122131
val: 9 0.5249537229537964
val: 10 0.5392587780952454
val: 11 0.5522933602333069
val: 12 0.5655930638313293
val: 13 0.5501266717910767
val: 14 0.5134481191635132
val: 15 0.54047030210495
val: 16 0.5333994030952454
val: 17 0.5332228541374207
val: 18 0.5486989617347717
val: 19 0.5282264351844788
val: 20 0.5530169606208801
val_Epoch:[ 197 ] val_loss: 0.5394516348838806 2022-05-29 19:09:55.072748
start training 2022-05-29 19:09:55.175525
Epoch:[ 198 0 ] loss: 0.4075298309326172 2022-05-29 19:10:17.804284
Epoch:[ 198 1 ] loss: 0.40670713782310486 2022-05-29 19:10:18.614767
Epoch:[ 198 2 ] loss: 0.40391403436660767 2022-05-29 19:10:19.434643
Epoch:[ 198 3 ] loss: 0.40375053882598877 2022-05-29 19:10:20.221163
Epoch:[ 198 4 ] loss: 0.40338993072509766 2022-05-29 19:10:20.994429
Epoch:[ 198 5 ] loss: 0.4078746736049652 2022-05-29 19:10:21.768927
Epoch:[ 198 6 ] loss: 0.4038016200065613 2022-05-29 19:10:22.546845
Epoch:[ 198 7 ] loss: 0.4062190353870392 2022-05-29 19:10:23.336804
Epoch:[ 198 8 ] loss: 0.4016765356063843 2022-05-29 19:10:24.113304
Epoch:[ 198 9 ] loss: 0.40333911776542664 2022-05-29 19:10:24.888350
Epoch:[ 198 10 ] loss: 0.4007716774940491 2022-05-29 19:10:25.676074
Epoch:[ 198 11 ] loss: 0.40153321623802185 2022-05-29 19:10:26.448862
Epoch:[ 198 12 ] loss: 0.39999958872795105 2022-05-29 19:10:27.223051
Epoch:[ 198 13 ] loss: 0.40092048048973083 2022-05-29 19:10:28.000847
Epoch:[ 198 14 ] loss: 0.40151309967041016 2022-05-29 19:10:28.779914
Epoch:[ 198 15 ] loss: 0.39979615807533264 2022-05-29 19:10:29.559571
Epoch:[ 198 16 ] loss: 0.40576860308647156 2022-05-29 19:10:37.284743
Epoch:[ 198 17 ] loss: 0.39885368943214417 2022-05-29 19:10:38.071396
Epoch:[ 198 18 ] loss: 0.40744251012802124 2022-05-29 19:10:38.849043
Epoch:[ 198 19 ] loss: 0.4058424234390259 2022-05-29 19:10:39.634437
Training_Epoch:[ 198 ] Training_loss: 0.40353219509124755 2022-05-29 19:10:39.635150
learning rate:  5.764607523034242e-06
netparams have been saved once 198
val: 1 0.5252389311790466
val: 2 0.5501018762588501
val: 3 0.5322553515434265
val: 4 0.5413377285003662
val: 5 0.5482624173164368
val: 6 0.5385727286338806
val: 7 0.5420955419540405
val: 8 0.536286473274231
val: 9 0.5292366147041321
val: 10 0.543911874294281
val: 11 0.5553561449050903
val: 12 0.5536634922027588
val: 13 0.5396527647972107
val: 14 0.5168354511260986
val: 15 0.5570988655090332
val: 16 0.5455877780914307
val: 17 0.5550447106361389
val: 18 0.5315569639205933
val: 19 0.5227483510971069
val: 20 0.5153511166572571
val_Epoch:[ 198 ] val_loss: 0.5390097588300705 2022-05-29 19:10:45.020145
start training 2022-05-29 19:10:45.126079
Epoch:[ 199 0 ] loss: 0.40182188153266907 2022-05-29 19:11:07.981410
Epoch:[ 199 1 ] loss: 0.4042699635028839 2022-05-29 19:11:08.806297
Epoch:[ 199 2 ] loss: 0.4035200774669647 2022-05-29 19:11:09.584390
Epoch:[ 199 3 ] loss: 0.4049084186553955 2022-05-29 19:11:10.361164
Epoch:[ 199 4 ] loss: 0.40217962861061096 2022-05-29 19:11:11.137420
Epoch:[ 199 5 ] loss: 0.40735742449760437 2022-05-29 19:11:11.923959
Epoch:[ 199 6 ] loss: 0.4044901728630066 2022-05-29 19:11:12.709835
Epoch:[ 199 7 ] loss: 0.4028516411781311 2022-05-29 19:11:13.486503
Epoch:[ 199 8 ] loss: 0.403756707906723 2022-05-29 19:11:14.263727
Epoch:[ 199 9 ] loss: 0.40598875284194946 2022-05-29 19:11:15.051764
Epoch:[ 199 10 ] loss: 0.400794118642807 2022-05-29 19:11:15.829320
Epoch:[ 199 11 ] loss: 0.402052104473114 2022-05-29 19:11:16.603277
Epoch:[ 199 12 ] loss: 0.40475234389305115 2022-05-29 19:11:17.377518
Epoch:[ 199 13 ] loss: 0.40159493684768677 2022-05-29 19:11:18.152199
Epoch:[ 199 14 ] loss: 0.40239614248275757 2022-05-29 19:11:18.928751
Epoch:[ 199 15 ] loss: 0.4041580557823181 2022-05-29 19:11:19.707200
Epoch:[ 199 16 ] loss: 0.4031434953212738 2022-05-29 19:11:27.040515
Epoch:[ 199 17 ] loss: 0.402008056640625 2022-05-29 19:11:27.828266
Epoch:[ 199 18 ] loss: 0.40713265538215637 2022-05-29 19:11:28.616419
Epoch:[ 199 19 ] loss: 0.4019704759120941 2022-05-29 19:11:29.391972
Training_Epoch:[ 199 ] Training_loss: 0.40355735272169113 2022-05-29 19:11:29.392709
learning rate:  5.764607523034242e-06
val: 1 0.5318186283111572
val: 2 0.5340330004692078
val: 3 0.537788450717926
val: 4 0.5315588712692261
val: 5 0.5333277583122253
val: 6 0.5338736772537231
val: 7 0.5246397852897644
val: 8 0.5570510029792786
val: 9 0.5665573477745056
val: 10 0.5275005102157593
val: 11 0.5469205975532532
val: 12 0.5353604555130005
val: 13 0.5349736213684082
val: 14 0.5369787216186523
val: 15 0.52451491355896
val: 16 0.5492168664932251
val: 17 0.5495173931121826
val: 18 0.5315535664558411
val: 19 0.5455638766288757
val: 20 0.5385093092918396
val_Epoch:[ 199 ] val_loss: 0.5385629177093506 2022-05-29 19:11:34.583628
start training 2022-05-29 19:11:34.689163
Epoch:[ 200 0 ] loss: 0.4052548408508301 2022-05-29 19:11:58.943434
Epoch:[ 200 1 ] loss: 0.3993109464645386 2022-05-29 19:11:59.720398
Epoch:[ 200 2 ] loss: 0.4030963182449341 2022-05-29 19:12:00.510438
Epoch:[ 200 3 ] loss: 0.4063439667224884 2022-05-29 19:12:01.285315
Epoch:[ 200 4 ] loss: 0.40354275703430176 2022-05-29 19:12:02.061334
Epoch:[ 200 5 ] loss: 0.4012082815170288 2022-05-29 19:12:02.847713
Epoch:[ 200 6 ] loss: 0.4027194678783417 2022-05-29 19:12:03.621395
Epoch:[ 200 7 ] loss: 0.3995613157749176 2022-05-29 19:12:04.396311
Epoch:[ 200 8 ] loss: 0.4080069363117218 2022-05-29 19:12:05.173179
Epoch:[ 200 9 ] loss: 0.4021976888179779 2022-05-29 19:12:05.951477
Epoch:[ 200 10 ] loss: 0.40570640563964844 2022-05-29 19:12:06.725038
Epoch:[ 200 11 ] loss: 0.40069884061813354 2022-05-29 19:12:07.500637
Epoch:[ 200 12 ] loss: 0.4032987654209137 2022-05-29 19:12:08.274596
Epoch:[ 200 13 ] loss: 0.4040198028087616 2022-05-29 19:12:09.047691
Epoch:[ 200 14 ] loss: 0.40264394879341125 2022-05-29 19:12:09.832184
Epoch:[ 200 15 ] loss: 0.402880996465683 2022-05-29 19:12:10.608436
Epoch:[ 200 16 ] loss: 0.40548253059387207 2022-05-29 19:12:17.436953
Epoch:[ 200 17 ] loss: 0.4024391174316406 2022-05-29 19:12:18.223213
Epoch:[ 200 18 ] loss: 0.4011957347393036 2022-05-29 19:12:19.001749
Epoch:[ 200 19 ] loss: 0.407405287027359 2022-05-29 19:12:19.775152
Training_Epoch:[ 200 ] Training_loss: 0.4033506974577904 2022-05-29 19:12:19.775842
learning rate:  5.764607523034242e-06
netparams have been saved once 200
val: 1 0.5376652479171753
val: 2 0.527926504611969
val: 3 0.521926999092102
val: 4 0.5286973118782043
val: 5 0.5481081604957581
val: 6 0.536971926689148
val: 7 0.5313187837600708
val: 8 0.5687408447265625
val: 9 0.5377241969108582
val: 10 0.5401194095611572
val: 11 0.5297839641571045
val: 12 0.5437994003295898
val: 13 0.5386560559272766
val: 14 0.5579733848571777
val: 15 0.5357164144515991
val: 16 0.5385631918907166
val: 17 0.5414308309555054
val: 18 0.5501756072044373
val: 19 0.5337798595428467
val: 20 0.5388915538787842
val_Epoch:[ 200 ] val_loss: 0.5393984824419021 2022-05-29 19:12:25.194604
start training 2022-05-29 19:12:25.304519
Epoch:[ 201 0 ] loss: 0.4067041873931885 2022-05-29 19:12:47.968708
Epoch:[ 201 1 ] loss: 0.40338876843452454 2022-05-29 19:12:48.795256
Epoch:[ 201 2 ] loss: 0.40428152680397034 2022-05-29 19:12:49.626496
Epoch:[ 201 3 ] loss: 0.40428388118743896 2022-05-29 19:12:50.406139
Epoch:[ 201 4 ] loss: 0.4014829099178314 2022-05-29 19:12:51.171257
Epoch:[ 201 5 ] loss: 0.4061727523803711 2022-05-29 19:12:51.937778
Epoch:[ 201 6 ] loss: 0.39844393730163574 2022-05-29 19:12:52.716702
Epoch:[ 201 7 ] loss: 0.3998359739780426 2022-05-29 19:12:53.495146
Epoch:[ 201 8 ] loss: 0.4044744372367859 2022-05-29 19:12:54.271656
Epoch:[ 201 9 ] loss: 0.4039003252983093 2022-05-29 19:12:55.052129
Epoch:[ 201 10 ] loss: 0.40166717767715454 2022-05-29 19:12:55.818248
Epoch:[ 201 11 ] loss: 0.4043157398700714 2022-05-29 19:12:56.596039
Epoch:[ 201 12 ] loss: 0.4030406177043915 2022-05-29 19:12:57.371060
Epoch:[ 201 13 ] loss: 0.40146058797836304 2022-05-29 19:12:58.146403
Epoch:[ 201 14 ] loss: 0.40405842661857605 2022-05-29 19:12:58.924044
Epoch:[ 201 15 ] loss: 0.40258097648620605 2022-05-29 19:12:59.700396
Epoch:[ 201 16 ] loss: 0.4085342288017273 2022-05-29 19:13:07.670342
Epoch:[ 201 17 ] loss: 0.40484219789505005 2022-05-29 19:13:08.437125
Epoch:[ 201 18 ] loss: 0.404039591550827 2022-05-29 19:13:09.219658
Epoch:[ 201 19 ] loss: 0.3993549644947052 2022-05-29 19:13:09.985369
Training_Epoch:[ 201 ] Training_loss: 0.40334316045045854 2022-05-29 19:13:09.986195
learning rate:  4.611686018427394e-06
val: 1 0.5429955720901489
val: 2 0.563247561454773
val: 3 0.5392935276031494
val: 4 0.5315856337547302
val: 5 0.5563480854034424
val: 6 0.522411048412323
val: 7 0.5198287963867188
val: 8 0.5332015752792358
val: 9 0.5545868277549744
val: 10 0.5629401206970215
val: 11 0.5240383744239807
val: 12 0.5485440492630005
val: 13 0.5562325716018677
val: 14 0.5368869304656982
val: 15 0.523238480091095
val: 16 0.5424236059188843
val: 17 0.5363548994064331
val: 18 0.5201678276062012
val: 19 0.5288254022598267
val: 20 0.5386319160461426
val_Epoch:[ 201 ] val_loss: 0.5390891402959823 2022-05-29 19:13:15.363033
start training 2022-05-29 19:13:15.471171
Epoch:[ 202 0 ] loss: 0.4040020704269409 2022-05-29 19:13:39.837636
Epoch:[ 202 1 ] loss: 0.40166395902633667 2022-05-29 19:13:40.624461
Epoch:[ 202 2 ] loss: 0.40255749225616455 2022-05-29 19:13:41.401090
Epoch:[ 202 3 ] loss: 0.4011867344379425 2022-05-29 19:13:42.190290
Epoch:[ 202 4 ] loss: 0.40338268876075745 2022-05-29 19:13:42.969968
Epoch:[ 202 5 ] loss: 0.4027083218097687 2022-05-29 19:13:43.748797
Epoch:[ 202 6 ] loss: 0.4038824141025543 2022-05-29 19:13:44.524835
Epoch:[ 202 7 ] loss: 0.4019809365272522 2022-05-29 19:13:45.301027
Epoch:[ 202 8 ] loss: 0.40393900871276855 2022-05-29 19:13:46.076078
Epoch:[ 202 9 ] loss: 0.401231050491333 2022-05-29 19:13:46.863826
Epoch:[ 202 10 ] loss: 0.4047088325023651 2022-05-29 19:13:47.643027
Epoch:[ 202 11 ] loss: 0.406195729970932 2022-05-29 19:13:48.421205
Epoch:[ 202 12 ] loss: 0.40383827686309814 2022-05-29 19:13:49.198514
Epoch:[ 202 13 ] loss: 0.4025956392288208 2022-05-29 19:13:49.976679
Epoch:[ 202 14 ] loss: 0.4040246307849884 2022-05-29 19:13:50.753555
Epoch:[ 202 15 ] loss: 0.40563714504241943 2022-05-29 19:13:51.531665
Epoch:[ 202 16 ] loss: 0.40329787135124207 2022-05-29 19:13:58.165432
Epoch:[ 202 17 ] loss: 0.40557196736335754 2022-05-29 19:13:58.954355
Epoch:[ 202 18 ] loss: 0.40208280086517334 2022-05-29 19:13:59.735603
Epoch:[ 202 19 ] loss: 0.40185725688934326 2022-05-29 19:14:00.524176
Training_Epoch:[ 202 ] Training_loss: 0.4033172413706779 2022-05-29 19:14:00.525058
learning rate:  4.611686018427394e-06
netparams have been saved once 202
val: 1 0.5352680087089539
val: 2 0.5511972904205322
val: 3 0.5335440635681152
val: 4 0.5317299365997314
val: 5 0.5354923605918884
val: 6 0.5466213822364807
val: 7 0.5427451133728027
val: 8 0.5507097244262695
val: 9 0.5383819341659546
val: 10 0.541587769985199
val: 11 0.5292918086051941
val: 12 0.5209462642669678
val: 13 0.5718871355056763
val: 14 0.5232051610946655
val: 15 0.5317505598068237
val: 16 0.5215953588485718
val: 17 0.5512511730194092
val: 18 0.5453884601593018
val: 19 0.5460625886917114
val: 20 0.5359951853752136
val_Epoch:[ 202 ] val_loss: 0.5392325639724731 2022-05-29 19:14:05.936861
start training 2022-05-29 19:14:06.039504
Epoch:[ 203 0 ] loss: 0.3996652662754059 2022-05-29 19:14:28.329531
Epoch:[ 203 1 ] loss: 0.402446985244751 2022-05-29 19:14:29.886525
Epoch:[ 203 2 ] loss: 0.4028490483760834 2022-05-29 19:14:30.664804
Epoch:[ 203 3 ] loss: 0.4024817943572998 2022-05-29 19:14:31.438096
Epoch:[ 203 4 ] loss: 0.40044456720352173 2022-05-29 19:14:32.216330
Epoch:[ 203 5 ] loss: 0.4062332212924957 2022-05-29 19:14:32.995469
Epoch:[ 203 6 ] loss: 0.40541982650756836 2022-05-29 19:14:33.773216
Epoch:[ 203 7 ] loss: 0.4076065719127655 2022-05-29 19:14:34.551243
Epoch:[ 203 8 ] loss: 0.40136483311653137 2022-05-29 19:14:35.326868
Epoch:[ 203 9 ] loss: 0.40347784757614136 2022-05-29 19:14:36.101680
Epoch:[ 203 10 ] loss: 0.40148672461509705 2022-05-29 19:14:36.887469
Epoch:[ 203 11 ] loss: 0.4085597097873688 2022-05-29 19:14:37.665741
Epoch:[ 203 12 ] loss: 0.40140944719314575 2022-05-29 19:14:38.455388
Epoch:[ 203 13 ] loss: 0.40525853633880615 2022-05-29 19:14:39.234422
Epoch:[ 203 14 ] loss: 0.40303850173950195 2022-05-29 19:14:40.012121
Epoch:[ 203 15 ] loss: 0.40343090891838074 2022-05-29 19:14:40.799955
Epoch:[ 203 16 ] loss: 0.4058353900909424 2022-05-29 19:14:48.058750
Epoch:[ 203 17 ] loss: 0.40221187472343445 2022-05-29 19:14:48.832097
Epoch:[ 203 18 ] loss: 0.4015703499317169 2022-05-29 19:14:49.625480
Epoch:[ 203 19 ] loss: 0.404248982667923 2022-05-29 19:14:50.414838
Training_Epoch:[ 203 ] Training_loss: 0.40345201939344405 2022-05-29 19:14:50.415609
learning rate:  4.611686018427394e-06
val: 1 0.5377739071846008
val: 2 0.5621592998504639
val: 3 0.5292555689811707
val: 4 0.5547164082527161
val: 5 0.5212358832359314
val: 6 0.5260819792747498
val: 7 0.5394022464752197
val: 8 0.5376682281494141
val: 9 0.5219041705131531
val: 10 0.5399375557899475
val: 11 0.5543792247772217
val: 12 0.5468535423278809
val: 13 0.5409356355667114
val: 14 0.5459769368171692
val: 15 0.5388184189796448
val: 16 0.5269481539726257
val: 17 0.5164197087287903
val: 18 0.540203332901001
val: 19 0.5662124156951904
val: 20 0.5296755433082581
val_Epoch:[ 203 ] val_loss: 0.538827908039093 2022-05-29 19:14:55.665040
start training 2022-05-29 19:14:55.766723
Epoch:[ 204 0 ] loss: 0.40004080533981323 2022-05-29 19:15:19.578133
Epoch:[ 204 1 ] loss: 0.4062063992023468 2022-05-29 19:15:20.368960
Epoch:[ 204 2 ] loss: 0.4032273590564728 2022-05-29 19:15:21.145433
Epoch:[ 204 3 ] loss: 0.4014251232147217 2022-05-29 19:15:21.923141
Epoch:[ 204 4 ] loss: 0.4033642113208771 2022-05-29 19:15:22.697832
Epoch:[ 204 5 ] loss: 0.40208470821380615 2022-05-29 19:15:23.476165
Epoch:[ 204 6 ] loss: 0.4033094644546509 2022-05-29 19:15:24.255969
Epoch:[ 204 7 ] loss: 0.40328601002693176 2022-05-29 19:15:25.035944
Epoch:[ 204 8 ] loss: 0.3991060256958008 2022-05-29 19:15:25.810925
Epoch:[ 204 9 ] loss: 0.4048609137535095 2022-05-29 19:15:26.598461
Epoch:[ 204 10 ] loss: 0.4052596390247345 2022-05-29 19:15:27.373121
Epoch:[ 204 11 ] loss: 0.4010368585586548 2022-05-29 19:15:28.160693
Epoch:[ 204 12 ] loss: 0.4007211923599243 2022-05-29 19:15:28.939994
Epoch:[ 204 13 ] loss: 0.40246427059173584 2022-05-29 19:15:29.718776
Epoch:[ 204 14 ] loss: 0.40210118889808655 2022-05-29 19:15:30.494720
Epoch:[ 204 15 ] loss: 0.40478289127349854 2022-05-29 19:15:31.272570
Epoch:[ 204 16 ] loss: 0.40598511695861816 2022-05-29 19:15:38.408002
Epoch:[ 204 17 ] loss: 0.40343382954597473 2022-05-29 19:15:39.194302
Epoch:[ 204 18 ] loss: 0.4079645276069641 2022-05-29 19:15:39.972051
Epoch:[ 204 19 ] loss: 0.40628573298454285 2022-05-29 19:15:40.751203
Training_Epoch:[ 204 ] Training_loss: 0.40334731340408325 2022-05-29 19:15:40.751944
learning rate:  4.611686018427394e-06
netparams have been saved once 204
val: 1 0.5461233258247375
val: 2 0.5381246209144592
val: 3 0.5355120897293091
val: 4 0.5246303081512451
val: 5 0.5381876826286316
val: 6 0.534378707408905
val: 7 0.5519125461578369
val: 8 0.5601295232772827
val: 9 0.5404765009880066
val: 10 0.5542151927947998
val: 11 0.5361784100532532
val: 12 0.5408542156219482
val: 13 0.5406267046928406
val: 14 0.5326869487762451
val: 15 0.5267393589019775
val: 16 0.5390871167182922
val: 17 0.5358045101165771
val: 18 0.5350623726844788
val: 19 0.543770968914032
val: 20 0.523184597492218
val_Epoch:[ 204 ] val_loss: 0.5388842850923539 2022-05-29 19:15:46.142051
start training 2022-05-29 19:15:46.251408
Epoch:[ 205 0 ] loss: 0.40690913796424866 2022-05-29 19:16:08.794184
Epoch:[ 205 1 ] loss: 0.40597206354141235 2022-05-29 19:16:09.614778
Epoch:[ 205 2 ] loss: 0.4019586145877838 2022-05-29 19:16:10.413658
Epoch:[ 205 3 ] loss: 0.4024529755115509 2022-05-29 19:16:11.199895
Epoch:[ 205 4 ] loss: 0.4019417464733124 2022-05-29 19:16:11.974949
Epoch:[ 205 5 ] loss: 0.40451985597610474 2022-05-29 19:16:12.749190
Epoch:[ 205 6 ] loss: 0.40545809268951416 2022-05-29 19:16:13.535533
Epoch:[ 205 7 ] loss: 0.40321025252342224 2022-05-29 19:16:14.312577
Epoch:[ 205 8 ] loss: 0.4017831087112427 2022-05-29 19:16:15.088404
Epoch:[ 205 9 ] loss: 0.4069880247116089 2022-05-29 19:16:15.862710
Epoch:[ 205 10 ] loss: 0.40399596095085144 2022-05-29 19:16:16.638108
Epoch:[ 205 11 ] loss: 0.4035789370536804 2022-05-29 19:16:17.412202
Epoch:[ 205 12 ] loss: 0.4016805589199066 2022-05-29 19:16:18.184285
Epoch:[ 205 13 ] loss: 0.4032957851886749 2022-05-29 19:16:18.960984
Epoch:[ 205 14 ] loss: 0.39840003848075867 2022-05-29 19:16:19.746953
Epoch:[ 205 15 ] loss: 0.40471741557121277 2022-05-29 19:16:20.524956
Epoch:[ 205 16 ] loss: 0.401722252368927 2022-05-29 19:16:28.607578
Epoch:[ 205 17 ] loss: 0.40059563517570496 2022-05-29 19:16:29.382585
Epoch:[ 205 18 ] loss: 0.40490907430648804 2022-05-29 19:16:30.161187
Epoch:[ 205 19 ] loss: 0.4037041962146759 2022-05-29 19:16:30.948145
Training_Epoch:[ 205 ] Training_loss: 0.4033896863460541 2022-05-29 19:16:30.948927
learning rate:  4.611686018427394e-06
val: 1 0.5486535429954529
val: 2 0.506446361541748
val: 3 0.5278154015541077
val: 4 0.5374614596366882
val: 5 0.5442960262298584
val: 6 0.5289296507835388
val: 7 0.5582122206687927
val: 8 0.54258793592453
val: 9 0.5517092347145081
val: 10 0.5293989777565002
val: 11 0.5458106994628906
val: 12 0.5458288192749023
val: 13 0.5222250819206238
val: 14 0.5159822106361389
val: 15 0.5394688844680786
val: 16 0.5664111375808716
val: 17 0.5485384464263916
val: 18 0.540411651134491
val: 19 0.5437647104263306
val: 20 0.5378967523574829
val_Epoch:[ 205 ] val_loss: 0.5390924602746964 2022-05-29 19:16:36.111067
start training 2022-05-29 19:16:36.216881
Epoch:[ 206 0 ] loss: 0.4046948552131653 2022-05-29 19:16:59.224891
Epoch:[ 206 1 ] loss: 0.4018712639808655 2022-05-29 19:17:00.004898
Epoch:[ 206 2 ] loss: 0.40504005551338196 2022-05-29 19:17:00.783747
Epoch:[ 206 3 ] loss: 0.40343230962753296 2022-05-29 19:17:01.561301
Epoch:[ 206 4 ] loss: 0.40429893136024475 2022-05-29 19:17:02.335709
Epoch:[ 206 5 ] loss: 0.40097475051879883 2022-05-29 19:17:03.114222
Epoch:[ 206 6 ] loss: 0.4018152952194214 2022-05-29 19:17:03.887878
Epoch:[ 206 7 ] loss: 0.40188413858413696 2022-05-29 19:17:04.665327
Epoch:[ 206 8 ] loss: 0.40575724840164185 2022-05-29 19:17:05.443245
Epoch:[ 206 9 ] loss: 0.4061267673969269 2022-05-29 19:17:06.219630
Epoch:[ 206 10 ] loss: 0.40252962708473206 2022-05-29 19:17:06.994097
Epoch:[ 206 11 ] loss: 0.4001389741897583 2022-05-29 19:17:07.769352
Epoch:[ 206 12 ] loss: 0.4058721363544464 2022-05-29 19:17:08.555450
Epoch:[ 206 13 ] loss: 0.4037003815174103 2022-05-29 19:17:09.340415
Epoch:[ 206 14 ] loss: 0.40317532420158386 2022-05-29 19:17:10.118507
Epoch:[ 206 15 ] loss: 0.4008243978023529 2022-05-29 19:17:10.908757
Epoch:[ 206 16 ] loss: 0.4071681797504425 2022-05-29 19:17:18.215867
Epoch:[ 206 17 ] loss: 0.40435150265693665 2022-05-29 19:17:18.991745
Epoch:[ 206 18 ] loss: 0.40175434947013855 2022-05-29 19:17:19.781054
Epoch:[ 206 19 ] loss: 0.40126460790634155 2022-05-29 19:17:20.566498
Training_Epoch:[ 206 ] Training_loss: 0.403333754837513 2022-05-29 19:17:20.567225
learning rate:  4.611686018427394e-06
netparams have been saved once 206
val: 1 0.5242658257484436
val: 2 0.536772608757019
val: 3 0.5545531511306763
val: 4 0.558361291885376
val: 5 0.5389828681945801
val: 6 0.5429555773735046
val: 7 0.5464729070663452
val: 8 0.5282624959945679
val: 9 0.5539093017578125
val: 10 0.541670560836792
val: 11 0.5225730538368225
val: 12 0.5559847950935364
val: 13 0.5386579036712646
val: 14 0.5093058347702026
val: 15 0.5447092652320862
val: 16 0.5426638722419739
val: 17 0.5460314154624939
val: 18 0.538299560546875
val: 19 0.5317423939704895
val: 20 0.5172685980796814
val_Epoch:[ 206 ] val_loss: 0.5386721640825272 2022-05-29 19:17:25.915966
start training 2022-05-29 19:17:26.014530
Epoch:[ 207 0 ] loss: 0.4028727412223816 2022-05-29 19:17:48.203628
Epoch:[ 207 1 ] loss: 0.4030110239982605 2022-05-29 19:17:50.163093
Epoch:[ 207 2 ] loss: 0.3996983468532562 2022-05-29 19:17:50.953783
Epoch:[ 207 3 ] loss: 0.4038327932357788 2022-05-29 19:17:51.734153
Epoch:[ 207 4 ] loss: 0.40180492401123047 2022-05-29 19:17:52.512856
Epoch:[ 207 5 ] loss: 0.405685693025589 2022-05-29 19:17:53.288934
Epoch:[ 207 6 ] loss: 0.40768012404441833 2022-05-29 19:17:54.064813
Epoch:[ 207 7 ] loss: 0.4033236503601074 2022-05-29 19:17:54.840109
Epoch:[ 207 8 ] loss: 0.4018329083919525 2022-05-29 19:17:55.631128
Epoch:[ 207 9 ] loss: 0.40325120091438293 2022-05-29 19:17:56.409423
Epoch:[ 207 10 ] loss: 0.4045056998729706 2022-05-29 19:17:57.188974
Epoch:[ 207 11 ] loss: 0.4043726623058319 2022-05-29 19:17:57.977297
Epoch:[ 207 12 ] loss: 0.40170958638191223 2022-05-29 19:17:58.753485
Epoch:[ 207 13 ] loss: 0.40395015478134155 2022-05-29 19:17:59.531898
Epoch:[ 207 14 ] loss: 0.40342584252357483 2022-05-29 19:18:00.307184
Epoch:[ 207 15 ] loss: 0.4031987190246582 2022-05-29 19:18:01.086730
Epoch:[ 207 16 ] loss: 0.40179207921028137 2022-05-29 19:18:08.200232
Epoch:[ 207 17 ] loss: 0.4055881202220917 2022-05-29 19:18:09.143525
Epoch:[ 207 18 ] loss: 0.39877188205718994 2022-05-29 19:18:09.923369
Epoch:[ 207 19 ] loss: 0.4047452509403229 2022-05-29 19:18:10.710183
Training_Epoch:[ 207 ] Training_loss: 0.40325267016887667 2022-05-29 19:18:10.710860
learning rate:  4.611686018427394e-06
val: 1 0.5410728454589844
val: 2 0.5445488095283508
val: 3 0.5345585346221924
val: 4 0.5462245941162109
val: 5 0.5404305458068848
val: 6 0.5474152565002441
val: 7 0.5280163884162903
val: 8 0.5373914241790771
val: 9 0.5437535047531128
val: 10 0.5368841290473938
val: 11 0.5339897871017456
val: 12 0.5273029208183289
val: 13 0.544849157333374
val: 14 0.5557135343551636
val: 15 0.5398184061050415
val: 16 0.532193124294281
val: 17 0.5184469223022461
val: 18 0.5416521430015564
val: 19 0.5395933389663696
val: 20 0.5509230494499207
val_Epoch:[ 207 ] val_loss: 0.5392389208078384 2022-05-29 19:18:15.994558
start training 2022-05-29 19:18:16.096111
Epoch:[ 208 0 ] loss: 0.39796358346939087 2022-05-29 19:18:39.819887
Epoch:[ 208 1 ] loss: 0.4035833775997162 2022-05-29 19:18:40.595565
Epoch:[ 208 2 ] loss: 0.40456128120422363 2022-05-29 19:18:41.385759
Epoch:[ 208 3 ] loss: 0.4034551978111267 2022-05-29 19:18:42.162824
Epoch:[ 208 4 ] loss: 0.4060337543487549 2022-05-29 19:18:42.941025
Epoch:[ 208 5 ] loss: 0.3956470191478729 2022-05-29 19:18:43.729044
Epoch:[ 208 6 ] loss: 0.40646660327911377 2022-05-29 19:18:44.505194
Epoch:[ 208 7 ] loss: 0.40480634570121765 2022-05-29 19:18:45.283812
Epoch:[ 208 8 ] loss: 0.4032802879810333 2022-05-29 19:18:46.058314
Epoch:[ 208 9 ] loss: 0.4092468321323395 2022-05-29 19:18:46.847300
Epoch:[ 208 10 ] loss: 0.40309783816337585 2022-05-29 19:18:47.624353
Epoch:[ 208 11 ] loss: 0.4082922339439392 2022-05-29 19:18:48.401888
Epoch:[ 208 12 ] loss: 0.4031044542789459 2022-05-29 19:18:49.177248
Epoch:[ 208 13 ] loss: 0.403348833322525 2022-05-29 19:18:49.950859
Epoch:[ 208 14 ] loss: 0.40281209349632263 2022-05-29 19:18:50.724443
Epoch:[ 208 15 ] loss: 0.39887943863868713 2022-05-29 19:18:51.499633
Epoch:[ 208 16 ] loss: 0.4013511538505554 2022-05-29 19:18:58.546096
Epoch:[ 208 17 ] loss: 0.4032827615737915 2022-05-29 19:18:59.323306
Epoch:[ 208 18 ] loss: 0.4008132517337799 2022-05-29 19:19:00.104591
Epoch:[ 208 19 ] loss: 0.40482431650161743 2022-05-29 19:19:00.892882
Training_Epoch:[ 208 ] Training_loss: 0.4032425329089165 2022-05-29 19:19:00.893652
learning rate:  4.611686018427394e-06
netparams have been saved once 208
val: 1 0.55882328748703
val: 2 0.5121687054634094
val: 3 0.5529837608337402
val: 4 0.5187262892723083
val: 5 0.5178521275520325
val: 6 0.5332657694816589
val: 7 0.5259168744087219
val: 8 0.5503816604614258
val: 9 0.537190318107605
val: 10 0.5431115031242371
val: 11 0.5310580730438232
val: 12 0.5390686988830566
val: 13 0.5297010540962219
val: 14 0.549833357334137
val: 15 0.5441866517066956
val: 16 0.5524526238441467
val: 17 0.5520572066307068
val: 18 0.5385929346084595
val: 19 0.5516462922096252
val: 20 0.5573374629020691
val_Epoch:[ 208 ] val_loss: 0.5398177325725555 2022-05-29 19:19:06.208376
start training 2022-05-29 19:19:06.304971
Epoch:[ 209 0 ] loss: 0.40780651569366455 2022-05-29 19:19:28.604978
Epoch:[ 209 1 ] loss: 0.4021711051464081 2022-05-29 19:19:29.421734
Epoch:[ 209 2 ] loss: 0.4023420810699463 2022-05-29 19:19:30.210952
Epoch:[ 209 3 ] loss: 0.4047098457813263 2022-05-29 19:19:30.997851
Epoch:[ 209 4 ] loss: 0.40207093954086304 2022-05-29 19:19:31.787097
Epoch:[ 209 5 ] loss: 0.4028065502643585 2022-05-29 19:19:32.565620
Epoch:[ 209 6 ] loss: 0.40305429697036743 2022-05-29 19:19:33.340805
Epoch:[ 209 7 ] loss: 0.40397006273269653 2022-05-29 19:19:34.115183
Epoch:[ 209 8 ] loss: 0.40329670906066895 2022-05-29 19:19:34.889758
Epoch:[ 209 9 ] loss: 0.4022539258003235 2022-05-29 19:19:35.663727
Epoch:[ 209 10 ] loss: 0.403965562582016 2022-05-29 19:19:36.441023
Epoch:[ 209 11 ] loss: 0.40849289298057556 2022-05-29 19:19:37.220269
Epoch:[ 209 12 ] loss: 0.402506560087204 2022-05-29 19:19:38.011466
Epoch:[ 209 13 ] loss: 0.4045952558517456 2022-05-29 19:19:38.789480
Epoch:[ 209 14 ] loss: 0.40488654375076294 2022-05-29 19:19:39.564135
Epoch:[ 209 15 ] loss: 0.4049144387245178 2022-05-29 19:19:40.339253
Epoch:[ 209 16 ] loss: 0.4006838798522949 2022-05-29 19:19:48.899733
Epoch:[ 209 17 ] loss: 0.39974841475486755 2022-05-29 19:19:49.689006
Epoch:[ 209 18 ] loss: 0.4000132381916046 2022-05-29 19:19:50.481981
Epoch:[ 209 19 ] loss: 0.4011516869068146 2022-05-29 19:19:51.260111
Training_Epoch:[ 209 ] Training_loss: 0.40327202528715134 2022-05-29 19:19:51.260899
learning rate:  4.611686018427394e-06
val: 1 0.5305523872375488
val: 2 0.5381483435630798
val: 3 0.5575310587882996
val: 4 0.5398672819137573
val: 5 0.542086660861969
val: 6 0.5307173132896423
val: 7 0.5515223741531372
val: 8 0.5305657982826233
val: 9 0.5406404137611389
val: 10 0.5402141213417053
val: 11 0.5219959020614624
val: 12 0.5559367537498474
val: 13 0.5423069000244141
val: 14 0.5463950634002686
val: 15 0.5265186429023743
val: 16 0.5368291735649109
val: 17 0.5431550145149231
val: 18 0.548301100730896
val: 19 0.5384710431098938
val: 20 0.5330948829650879
val_Epoch:[ 209 ] val_loss: 0.539742511510849 2022-05-29 19:19:56.427011
start training 2022-05-29 19:19:56.523986
Epoch:[ 210 0 ] loss: 0.4045785367488861 2022-05-29 19:20:20.188083
Epoch:[ 210 1 ] loss: 0.4054180383682251 2022-05-29 19:20:20.962557
Epoch:[ 210 2 ] loss: 0.4022717773914337 2022-05-29 19:20:21.734861
Epoch:[ 210 3 ] loss: 0.39708298444747925 2022-05-29 19:20:22.508535
Epoch:[ 210 4 ] loss: 0.4019573926925659 2022-05-29 19:20:23.285303
Epoch:[ 210 5 ] loss: 0.40309280157089233 2022-05-29 19:20:24.074789
Epoch:[ 210 6 ] loss: 0.40265190601348877 2022-05-29 19:20:24.862382
Epoch:[ 210 7 ] loss: 0.4043063223361969 2022-05-29 19:20:25.638354
Epoch:[ 210 8 ] loss: 0.4038415849208832 2022-05-29 19:20:26.412089
Epoch:[ 210 9 ] loss: 0.4042600691318512 2022-05-29 19:20:27.187893
Epoch:[ 210 10 ] loss: 0.4048177897930145 2022-05-29 19:20:27.960908
Epoch:[ 210 11 ] loss: 0.4043969213962555 2022-05-29 19:20:28.737377
Epoch:[ 210 12 ] loss: 0.4038335680961609 2022-05-29 19:20:29.526525
Epoch:[ 210 13 ] loss: 0.40454986691474915 2022-05-29 19:20:30.302315
Epoch:[ 210 14 ] loss: 0.4023682177066803 2022-05-29 19:20:31.075831
Epoch:[ 210 15 ] loss: 0.3997989594936371 2022-05-29 19:20:31.851202
Epoch:[ 210 16 ] loss: 0.40358811616897583 2022-05-29 19:20:39.043818
Epoch:[ 210 17 ] loss: 0.405877023935318 2022-05-29 19:20:39.816578
Epoch:[ 210 18 ] loss: 0.406526654958725 2022-05-29 19:20:40.608369
Epoch:[ 210 19 ] loss: 0.40117013454437256 2022-05-29 19:20:41.394841
Training_Epoch:[ 210 ] Training_loss: 0.40331943333148956 2022-05-29 19:20:41.395531
learning rate:  4.611686018427394e-06
netparams have been saved once 210
val: 1 0.5359218120574951
val: 2 0.5410056114196777
val: 3 0.5448002219200134
val: 4 0.5513045191764832
val: 5 0.5449662804603577
val: 6 0.5501161813735962
val: 7 0.5665342807769775
val: 8 0.5178683996200562
val: 9 0.5471257567405701
val: 10 0.5481719970703125
val: 11 0.5550196766853333
val: 12 0.5324554443359375
val: 13 0.5347105860710144
val: 14 0.5248187184333801
val: 15 0.5095957517623901
val: 16 0.5288782119750977
val: 17 0.5557170510292053
val: 18 0.5262306332588196
val: 19 0.5470066666603088
val: 20 0.528821587562561
val_Epoch:[ 210 ] val_loss: 0.5395534694194793 2022-05-29 19:20:46.708957
start training 2022-05-29 19:20:46.803343
Epoch:[ 211 0 ] loss: 0.4007280766963959 2022-05-29 19:21:09.667682
Epoch:[ 211 1 ] loss: 0.4029439389705658 2022-05-29 19:21:10.482489
Epoch:[ 211 2 ] loss: 0.40393903851509094 2022-05-29 19:21:11.256495
Epoch:[ 211 3 ] loss: 0.4055083394050598 2022-05-29 19:21:12.032743
Epoch:[ 211 4 ] loss: 0.4052840769290924 2022-05-29 19:21:12.806305
Epoch:[ 211 5 ] loss: 0.4051223397254944 2022-05-29 19:21:13.582867
Epoch:[ 211 6 ] loss: 0.40397000312805176 2022-05-29 19:21:14.371396
Epoch:[ 211 7 ] loss: 0.4028359055519104 2022-05-29 19:21:15.148606
Epoch:[ 211 8 ] loss: 0.4008527994155884 2022-05-29 19:21:15.933652
Epoch:[ 211 9 ] loss: 0.3997422158718109 2022-05-29 19:21:16.708470
Epoch:[ 211 10 ] loss: 0.40513700246810913 2022-05-29 19:21:17.482038
Epoch:[ 211 11 ] loss: 0.4000851511955261 2022-05-29 19:21:18.267405
Epoch:[ 211 12 ] loss: 0.4060252606868744 2022-05-29 19:21:19.044648
Epoch:[ 211 13 ] loss: 0.40308353304862976 2022-05-29 19:21:19.821831
Epoch:[ 211 14 ] loss: 0.4086962640285492 2022-05-29 19:21:20.596408
Epoch:[ 211 15 ] loss: 0.40066805481910706 2022-05-29 19:21:21.371765
Epoch:[ 211 16 ] loss: 0.4033746123313904 2022-05-29 19:21:29.193986
Epoch:[ 211 17 ] loss: 0.40253517031669617 2022-05-29 19:21:29.968918
Epoch:[ 211 18 ] loss: 0.40425923466682434 2022-05-29 19:21:30.746075
Epoch:[ 211 19 ] loss: 0.40043923258781433 2022-05-29 19:21:31.534442
Training_Epoch:[ 211 ] Training_loss: 0.4032615125179291 2022-05-29 19:21:31.535114
learning rate:  3.6893488147419155e-06
val: 1 0.5423219203948975
val: 2 0.5451722741127014
val: 3 0.5447726249694824
val: 4 0.5716201663017273
val: 5 0.5138722062110901
val: 6 0.5312910079956055
val: 7 0.5348172783851624
val: 8 0.5336104035377502
val: 9 0.5396162271499634
val: 10 0.5391422510147095
val: 11 0.5481886863708496
val: 12 0.5554070472717285
val: 13 0.5275198817253113
val: 14 0.5493782162666321
val: 15 0.5371361374855042
val: 16 0.5297418236732483
val: 17 0.5484190583229065
val: 18 0.5431793928146362
val: 19 0.530748188495636
val: 20 0.5259193181991577
val_Epoch:[ 211 ] val_loss: 0.539593705534935 2022-05-29 19:21:36.776624
start training 2022-05-29 19:21:36.871315
Epoch:[ 212 0 ] loss: 0.4024773836135864 2022-05-29 19:22:00.875247
Epoch:[ 212 1 ] loss: 0.40430790185928345 2022-05-29 19:22:01.650315
Epoch:[ 212 2 ] loss: 0.40295273065567017 2022-05-29 19:22:02.436999
Epoch:[ 212 3 ] loss: 0.40710732340812683 2022-05-29 19:22:03.210916
Epoch:[ 212 4 ] loss: 0.4025811553001404 2022-05-29 19:22:03.984589
Epoch:[ 212 5 ] loss: 0.400995135307312 2022-05-29 19:22:04.759025
Epoch:[ 212 6 ] loss: 0.40285637974739075 2022-05-29 19:22:05.535087
Epoch:[ 212 7 ] loss: 0.40275147557258606 2022-05-29 19:22:06.323988
Epoch:[ 212 8 ] loss: 0.40392032265663147 2022-05-29 19:22:07.101868
Epoch:[ 212 9 ] loss: 0.4061044752597809 2022-05-29 19:22:07.877053
Epoch:[ 212 10 ] loss: 0.40134942531585693 2022-05-29 19:22:08.651771
Epoch:[ 212 11 ] loss: 0.40394389629364014 2022-05-29 19:22:09.427876
Epoch:[ 212 12 ] loss: 0.4021826386451721 2022-05-29 19:22:10.202075
Epoch:[ 212 13 ] loss: 0.4006509780883789 2022-05-29 19:22:10.978868
Epoch:[ 212 14 ] loss: 0.40296199917793274 2022-05-29 19:22:11.768874
Epoch:[ 212 15 ] loss: 0.4016491174697876 2022-05-29 19:22:12.542828
Epoch:[ 212 16 ] loss: 0.4028414785861969 2022-05-29 19:22:19.685461
Epoch:[ 212 17 ] loss: 0.40506234765052795 2022-05-29 19:22:20.470587
Epoch:[ 212 18 ] loss: 0.4070320427417755 2022-05-29 19:22:21.249185
Epoch:[ 212 19 ] loss: 0.4025810658931732 2022-05-29 19:22:22.022324
Training_Epoch:[ 212 ] Training_loss: 0.40331546366214754 2022-05-29 19:22:22.023007
learning rate:  3.6893488147419155e-06
netparams have been saved once 212
val: 1 0.521450936794281
val: 2 0.5449370741844177
val: 3 0.5463933348655701
val: 4 0.5458115935325623
val: 5 0.5228689312934875
val: 6 0.5375778079032898
val: 7 0.5214860439300537
val: 8 0.5311631560325623
val: 9 0.5369586944580078
val: 10 0.5541542768478394
val: 11 0.5266669392585754
val: 12 0.5352764129638672
val: 13 0.5450629591941833
val: 14 0.5581050515174866
val: 15 0.5470810532569885
val: 16 0.5399066805839539
val: 17 0.5441242456436157
val: 18 0.546511173248291
val: 19 0.5285784006118774
val: 20 0.5487712025642395
val_Epoch:[ 212 ] val_loss: 0.5391442984342575 2022-05-29 19:22:27.329148
start training 2022-05-29 19:22:27.426223
Epoch:[ 213 0 ] loss: 0.40766090154647827 2022-05-29 19:22:49.797309
Epoch:[ 213 1 ] loss: 0.39973634481430054 2022-05-29 19:22:51.583972
Epoch:[ 213 2 ] loss: 0.40673020482063293 2022-05-29 19:22:52.361253
Epoch:[ 213 3 ] loss: 0.39967378973960876 2022-05-29 19:22:53.149520
Epoch:[ 213 4 ] loss: 0.40237390995025635 2022-05-29 19:22:53.924878
Epoch:[ 213 5 ] loss: 0.3998372256755829 2022-05-29 19:22:54.702120
Epoch:[ 213 6 ] loss: 0.4047293961048126 2022-05-29 19:22:55.488865
Epoch:[ 213 7 ] loss: 0.40429064631462097 2022-05-29 19:22:56.266337
Epoch:[ 213 8 ] loss: 0.4033683240413666 2022-05-29 19:22:57.042205
Epoch:[ 213 9 ] loss: 0.4023403525352478 2022-05-29 19:22:57.816178
Epoch:[ 213 10 ] loss: 0.4047909080982208 2022-05-29 19:22:58.592415
Epoch:[ 213 11 ] loss: 0.40764716267585754 2022-05-29 19:22:59.379359
Epoch:[ 213 12 ] loss: 0.4052974283695221 2022-05-29 19:23:00.156290
Epoch:[ 213 13 ] loss: 0.4022819697856903 2022-05-29 19:23:00.930971
Epoch:[ 213 14 ] loss: 0.40105530619621277 2022-05-29 19:23:01.707977
Epoch:[ 213 15 ] loss: 0.4004569947719574 2022-05-29 19:23:02.484482
Epoch:[ 213 16 ] loss: 0.4062081277370453 2022-05-29 19:23:09.290906
Epoch:[ 213 17 ] loss: 0.39859074354171753 2022-05-29 19:23:10.675148
Epoch:[ 213 18 ] loss: 0.4022074341773987 2022-05-29 19:23:11.469149
Epoch:[ 213 19 ] loss: 0.4074234068393707 2022-05-29 19:23:12.245800
Training_Epoch:[ 213 ] Training_loss: 0.40333502888679507 2022-05-29 19:23:12.246546
learning rate:  3.6893488147419155e-06
val: 1 0.5461358428001404
val: 2 0.5534076690673828
val: 3 0.5320913195610046
val: 4 0.5336567759513855
val: 5 0.55089271068573
val: 6 0.5399259328842163
val: 7 0.5477175712585449
val: 8 0.5315733551979065
val: 9 0.5519275069236755
val: 10 0.53375244140625
val: 11 0.5330449938774109
val: 12 0.5225990414619446
val: 13 0.5375792980194092
val: 14 0.543436586856842
val: 15 0.5389416217803955
val: 16 0.5538479685783386
val: 17 0.5174283981323242
val: 18 0.5345702171325684
val: 19 0.5371636152267456
val: 20 0.5445725321769714
val_Epoch:[ 213 ] val_loss: 0.5392132699489594 2022-05-29 19:23:17.457736
start training 2022-05-29 19:23:17.552954
Epoch:[ 214 0 ] loss: 0.39934659004211426 2022-05-29 19:23:41.515274
Epoch:[ 214 1 ] loss: 0.40311726927757263 2022-05-29 19:23:42.293743
Epoch:[ 214 2 ] loss: 0.404055118560791 2022-05-29 19:23:43.069603
Epoch:[ 214 3 ] loss: 0.4026707708835602 2022-05-29 19:23:43.845320
Epoch:[ 214 4 ] loss: 0.41010284423828125 2022-05-29 19:23:44.622903
Epoch:[ 214 5 ] loss: 0.40203166007995605 2022-05-29 19:23:45.409307
Epoch:[ 214 6 ] loss: 0.4024178683757782 2022-05-29 19:23:46.184017
Epoch:[ 214 7 ] loss: 0.4067721962928772 2022-05-29 19:23:46.959409
Epoch:[ 214 8 ] loss: 0.40721219778060913 2022-05-29 19:23:47.748956
Epoch:[ 214 9 ] loss: 0.4012337327003479 2022-05-29 19:23:48.525849
Epoch:[ 214 10 ] loss: 0.40144988894462585 2022-05-29 19:23:49.313384
Epoch:[ 214 11 ] loss: 0.40753912925720215 2022-05-29 19:23:50.090286
Epoch:[ 214 12 ] loss: 0.39879360795021057 2022-05-29 19:23:50.864530
Epoch:[ 214 13 ] loss: 0.4014666676521301 2022-05-29 19:23:51.641795
Epoch:[ 214 14 ] loss: 0.4013046622276306 2022-05-29 19:23:52.415661
Epoch:[ 214 15 ] loss: 0.40093231201171875 2022-05-29 19:23:53.191635
Epoch:[ 214 16 ] loss: 0.4039061665534973 2022-05-29 19:24:00.254387
Epoch:[ 214 17 ] loss: 0.4038729667663574 2022-05-29 19:24:01.028937
Epoch:[ 214 18 ] loss: 0.4017851650714874 2022-05-29 19:24:01.820922
Epoch:[ 214 19 ] loss: 0.4064236581325531 2022-05-29 19:24:02.595932
Training_Epoch:[ 214 ] Training_loss: 0.40332172363996505 2022-05-29 19:24:02.596629
learning rate:  3.6893488147419155e-06
netparams have been saved once 214
val: 1 0.540730357170105
val: 2 0.5232822895050049
val: 3 0.5293992757797241
val: 4 0.5280740261077881
val: 5 0.5443587899208069
val: 6 0.5424388647079468
val: 7 0.5404750108718872
val: 8 0.5459210872650146
val: 9 0.5536037683486938
val: 10 0.5337287783622742
val: 11 0.5284469723701477
val: 12 0.576107382774353
val: 13 0.5393001437187195
val: 14 0.5381587743759155
val: 15 0.5285967588424683
val: 16 0.5427271127700806
val: 17 0.5453635454177856
val: 18 0.5341900587081909
val: 19 0.526452362537384
val: 20 0.546098530292511
val_Epoch:[ 214 ] val_loss: 0.53937269449234 2022-05-29 19:24:08.073483
start training 2022-05-29 19:24:08.172384
Epoch:[ 215 0 ] loss: 0.4033565819263458 2022-05-29 19:24:31.317560
Epoch:[ 215 1 ] loss: 0.4054240584373474 2022-05-29 19:24:32.144368
Epoch:[ 215 2 ] loss: 0.4039858877658844 2022-05-29 19:24:32.920845
Epoch:[ 215 3 ] loss: 0.40420734882354736 2022-05-29 19:24:33.699156
Epoch:[ 215 4 ] loss: 0.40315112471580505 2022-05-29 19:24:34.474498
Epoch:[ 215 5 ] loss: 0.399852454662323 2022-05-29 19:24:35.250207
Epoch:[ 215 6 ] loss: 0.40552404522895813 2022-05-29 19:24:36.038179
Epoch:[ 215 7 ] loss: 0.40684086084365845 2022-05-29 19:24:36.812113
Epoch:[ 215 8 ] loss: 0.4014851450920105 2022-05-29 19:24:37.586385
Epoch:[ 215 9 ] loss: 0.4030088186264038 2022-05-29 19:24:38.364765
Epoch:[ 215 10 ] loss: 0.40422457456588745 2022-05-29 19:24:39.154022
Epoch:[ 215 11 ] loss: 0.40306153893470764 2022-05-29 19:24:39.931874
Epoch:[ 215 12 ] loss: 0.4027850329875946 2022-05-29 19:24:40.707730
Epoch:[ 215 13 ] loss: 0.40566447377204895 2022-05-29 19:24:41.483712
Epoch:[ 215 14 ] loss: 0.40305349230766296 2022-05-29 19:24:42.259235
Epoch:[ 215 15 ] loss: 0.3995528519153595 2022-05-29 19:24:43.034548
Epoch:[ 215 16 ] loss: 0.40015631914138794 2022-05-29 19:24:50.266395
Epoch:[ 215 17 ] loss: 0.4009052813053131 2022-05-29 19:24:51.057496
Epoch:[ 215 18 ] loss: 0.4051424264907837 2022-05-29 19:24:51.851151
Epoch:[ 215 19 ] loss: 0.4040014147758484 2022-05-29 19:24:52.625750
Training_Epoch:[ 215 ] Training_loss: 0.4032691866159439 2022-05-29 19:24:52.626523
learning rate:  3.6893488147419155e-06
val: 1 0.5386161208152771
val: 2 0.5352586507797241
val: 3 0.5281888246536255
val: 4 0.5363643169403076
val: 5 0.5371362566947937
val: 6 0.5501851439476013
val: 7 0.5296306610107422
val: 8 0.5511431097984314
val: 9 0.5520395040512085
val: 10 0.5335056185722351
val: 11 0.5479161143302917
val: 12 0.5368473529815674
val: 13 0.5492342710494995
val: 14 0.5337964296340942
val: 15 0.5433511734008789
val: 16 0.5500516891479492
val: 17 0.5246369242668152
val: 18 0.5540500283241272
val: 19 0.5169405341148376
val: 20 0.5461210012435913
val_Epoch:[ 215 ] val_loss: 0.5397506862878799 2022-05-29 19:24:57.906763
start training 2022-05-29 19:24:58.003842
Epoch:[ 216 0 ] loss: 0.40140148997306824 2022-05-29 19:25:20.736052
Epoch:[ 216 1 ] loss: 0.40356937050819397 2022-05-29 19:25:21.804535
Epoch:[ 216 2 ] loss: 0.4003847539424896 2022-05-29 19:25:22.579194
Epoch:[ 216 3 ] loss: 0.40436452627182007 2022-05-29 19:25:23.369809
Epoch:[ 216 4 ] loss: 0.40278658270835876 2022-05-29 19:25:24.149700
Epoch:[ 216 5 ] loss: 0.4065109193325043 2022-05-29 19:25:24.929318
Epoch:[ 216 6 ] loss: 0.40182432532310486 2022-05-29 19:25:25.709169
Epoch:[ 216 7 ] loss: 0.4072244465351105 2022-05-29 19:25:26.485395
Epoch:[ 216 8 ] loss: 0.40246784687042236 2022-05-29 19:25:27.273601
Epoch:[ 216 9 ] loss: 0.3979848623275757 2022-05-29 19:25:28.049221
Epoch:[ 216 10 ] loss: 0.40247583389282227 2022-05-29 19:25:28.828795
Epoch:[ 216 11 ] loss: 0.40703511238098145 2022-05-29 19:25:29.607086
Epoch:[ 216 12 ] loss: 0.40388134121894836 2022-05-29 19:25:30.386318
Epoch:[ 216 13 ] loss: 0.4052542746067047 2022-05-29 19:25:31.165213
Epoch:[ 216 14 ] loss: 0.4045249819755554 2022-05-29 19:25:31.942465
Epoch:[ 216 15 ] loss: 0.4036633372306824 2022-05-29 19:25:32.733543
Epoch:[ 216 16 ] loss: 0.40595078468322754 2022-05-29 19:25:39.907924
Epoch:[ 216 17 ] loss: 0.40395259857177734 2022-05-29 19:25:40.697099
Epoch:[ 216 18 ] loss: 0.40153902769088745 2022-05-29 19:25:41.480565
Epoch:[ 216 19 ] loss: 0.4002794325351715 2022-05-29 19:25:42.259121
Training_Epoch:[ 216 ] Training_loss: 0.40335379242897035 2022-05-29 19:25:42.259925
learning rate:  3.6893488147419155e-06
netparams have been saved once 216
val: 1 0.5404691100120544
val: 2 0.5305600762367249
val: 3 0.5374787449836731
val: 4 0.5283104777336121
val: 5 0.5406386852264404
val: 6 0.5356144309043884
val: 7 0.5350018739700317
val: 8 0.5489025115966797
val: 9 0.5483835935592651
val: 10 0.541891872882843
val: 11 0.525408148765564
val: 12 0.5333805084228516
val: 13 0.5413444638252258
val: 14 0.5546362400054932
val: 15 0.5466413497924805
val: 16 0.5451881289482117
val: 17 0.5439190864562988
val: 18 0.5314375758171082
val: 19 0.5387629270553589
val: 20 0.5447472333908081
val_Epoch:[ 216 ] val_loss: 0.5396358519792557 2022-05-29 19:25:47.647186
start training 2022-05-29 19:25:47.745053
Epoch:[ 217 0 ] loss: 0.40474092960357666 2022-05-29 19:26:10.827002
Epoch:[ 217 1 ] loss: 0.4027726650238037 2022-05-29 19:26:11.628739
Epoch:[ 217 2 ] loss: 0.40266332030296326 2022-05-29 19:26:12.417246
Epoch:[ 217 3 ] loss: 0.40750691294670105 2022-05-29 19:26:13.189284
Epoch:[ 217 4 ] loss: 0.4011577069759369 2022-05-29 19:26:13.968517
Epoch:[ 217 5 ] loss: 0.39591437578201294 2022-05-29 19:26:14.745036
Epoch:[ 217 6 ] loss: 0.40427640080451965 2022-05-29 19:26:15.519979
Epoch:[ 217 7 ] loss: 0.4034425616264343 2022-05-29 19:26:16.296322
Epoch:[ 217 8 ] loss: 0.40498247742652893 2022-05-29 19:26:17.070651
Epoch:[ 217 9 ] loss: 0.40630170702934265 2022-05-29 19:26:17.847807
Epoch:[ 217 10 ] loss: 0.40550655126571655 2022-05-29 19:26:18.622465
Epoch:[ 217 11 ] loss: 0.39847734570503235 2022-05-29 19:26:19.400534
Epoch:[ 217 12 ] loss: 0.40442708134651184 2022-05-29 19:26:20.177517
Epoch:[ 217 13 ] loss: 0.39764875173568726 2022-05-29 19:26:20.955360
Epoch:[ 217 14 ] loss: 0.4043921232223511 2022-05-29 19:26:21.740894
Epoch:[ 217 15 ] loss: 0.4067668914794922 2022-05-29 19:26:22.515168
Epoch:[ 217 16 ] loss: 0.40307021141052246 2022-05-29 19:26:29.902880
Epoch:[ 217 17 ] loss: 0.4052561819553375 2022-05-29 19:26:30.676232
Epoch:[ 217 18 ] loss: 0.4035879671573639 2022-05-29 19:26:31.455578
Epoch:[ 217 19 ] loss: 0.4033961892127991 2022-05-29 19:26:32.244568
Training_Epoch:[ 217 ] Training_loss: 0.4033144176006317 2022-05-29 19:26:32.245238
learning rate:  3.6893488147419155e-06
val: 1 0.5665257573127747
val: 2 0.5331313610076904
val: 3 0.5444400906562805
val: 4 0.5219481587409973
val: 5 0.5467417240142822
val: 6 0.5446284413337708
val: 7 0.5321460962295532
val: 8 0.5287682414054871
val: 9 0.525100827217102
val: 10 0.5511945486068726
val: 11 0.5421630144119263
val: 12 0.532463788986206
val: 13 0.5266307592391968
val: 14 0.542296290397644
val: 15 0.5371357202529907
val: 16 0.5569239258766174
val: 17 0.5310224890708923
val: 18 0.5451875329017639
val: 19 0.5356274843215942
val: 20 0.5477201342582703
val_Epoch:[ 217 ] val_loss: 0.5395898193120956 2022-05-29 19:26:37.590209
start training 2022-05-29 19:26:37.689298
Epoch:[ 218 0 ] loss: 0.40428537130355835 2022-05-29 19:27:01.533238
Epoch:[ 218 1 ] loss: 0.4036594033241272 2022-05-29 19:27:02.309133
Epoch:[ 218 2 ] loss: 0.40181729197502136 2022-05-29 19:27:03.095188
Epoch:[ 218 3 ] loss: 0.40509283542633057 2022-05-29 19:27:03.871895
Epoch:[ 218 4 ] loss: 0.40540844202041626 2022-05-29 19:27:04.646745
Epoch:[ 218 5 ] loss: 0.4009054899215698 2022-05-29 19:27:05.424641
Epoch:[ 218 6 ] loss: 0.4061225354671478 2022-05-29 19:27:06.200657
Epoch:[ 218 7 ] loss: 0.4001237154006958 2022-05-29 19:27:06.986691
Epoch:[ 218 8 ] loss: 0.4024823307991028 2022-05-29 19:27:07.762975
Epoch:[ 218 9 ] loss: 0.40413492918014526 2022-05-29 19:27:08.537043
Epoch:[ 218 10 ] loss: 0.40324848890304565 2022-05-29 19:27:09.312981
Epoch:[ 218 11 ] loss: 0.3976907432079315 2022-05-29 19:27:10.086763
Epoch:[ 218 12 ] loss: 0.40044495463371277 2022-05-29 19:27:10.863378
Epoch:[ 218 13 ] loss: 0.40443921089172363 2022-05-29 19:27:11.642022
Epoch:[ 218 14 ] loss: 0.4046039283275604 2022-05-29 19:27:12.415763
Epoch:[ 218 15 ] loss: 0.4046784043312073 2022-05-29 19:27:13.203766
Epoch:[ 218 16 ] loss: 0.40246012806892395 2022-05-29 19:27:20.494676
Epoch:[ 218 17 ] loss: 0.40508854389190674 2022-05-29 19:27:21.279074
Epoch:[ 218 18 ] loss: 0.4050079882144928 2022-05-29 19:27:22.056383
Epoch:[ 218 19 ] loss: 0.403685599565506 2022-05-29 19:27:22.833532
Training_Epoch:[ 218 ] Training_loss: 0.4032690167427063 2022-05-29 19:27:22.834182
learning rate:  3.6893488147419155e-06
netparams have been saved once 218
val: 1 0.5383884310722351
val: 2 0.5449813008308411
val: 3 0.5476625561714172
val: 4 0.5447651743888855
val: 5 0.5194703936576843
val: 6 0.5278149247169495
val: 7 0.5235108137130737
val: 8 0.5502319931983948
val: 9 0.546832263469696
val: 10 0.5246846675872803
val: 11 0.5337848663330078
val: 12 0.5369188189506531
val: 13 0.5472603440284729
val: 14 0.5433539748191833
val: 15 0.5432317852973938
val: 16 0.5191881656646729
val: 17 0.5644684433937073
val: 18 0.534561276435852
val: 19 0.5520795583724976
val: 20 0.5412638783454895
val_Epoch:[ 218 ] val_loss: 0.5392226815223694 2022-05-29 19:27:28.142621
start training 2022-05-29 19:27:28.238679
Epoch:[ 219 0 ] loss: 0.40615713596343994 2022-05-29 19:27:50.931196
Epoch:[ 219 1 ] loss: 0.40589308738708496 2022-05-29 19:27:51.737363
Epoch:[ 219 2 ] loss: 0.40401044487953186 2022-05-29 19:27:52.513752
Epoch:[ 219 3 ] loss: 0.4079483449459076 2022-05-29 19:27:53.287692
Epoch:[ 219 4 ] loss: 0.4011233150959015 2022-05-29 19:27:54.063535
Epoch:[ 219 5 ] loss: 0.40362098813056946 2022-05-29 19:27:54.837545
Epoch:[ 219 6 ] loss: 0.3989453613758087 2022-05-29 19:27:55.615765
Epoch:[ 219 7 ] loss: 0.4001480042934418 2022-05-29 19:27:56.394010
Epoch:[ 219 8 ] loss: 0.3998478353023529 2022-05-29 19:27:57.169863
Epoch:[ 219 9 ] loss: 0.4021579921245575 2022-05-29 19:27:57.947844
Epoch:[ 219 10 ] loss: 0.4035261571407318 2022-05-29 19:27:58.721950
Epoch:[ 219 11 ] loss: 0.406314879655838 2022-05-29 19:27:59.507455
Epoch:[ 219 12 ] loss: 0.4014808237552643 2022-05-29 19:28:00.277211
Epoch:[ 219 13 ] loss: 0.4045276939868927 2022-05-29 19:28:01.046016
Epoch:[ 219 14 ] loss: 0.39798325300216675 2022-05-29 19:28:01.826705
Epoch:[ 219 15 ] loss: 0.3987762928009033 2022-05-29 19:28:02.593089
Epoch:[ 219 16 ] loss: 0.4074481725692749 2022-05-29 19:28:10.285725
Epoch:[ 219 17 ] loss: 0.4042434096336365 2022-05-29 19:28:11.062390
Epoch:[ 219 18 ] loss: 0.405238538980484 2022-05-29 19:28:11.855272
Epoch:[ 219 19 ] loss: 0.4047131836414337 2022-05-29 19:28:12.641773
Training_Epoch:[ 219 ] Training_loss: 0.4032052457332611 2022-05-29 19:28:12.642696
learning rate:  3.6893488147419155e-06
val: 1 0.5519145727157593
val: 2 0.540858805179596
val: 3 0.5359694361686707
val: 4 0.5351237058639526
val: 5 0.5294890403747559
val: 6 0.5398921966552734
val: 7 0.5473755598068237
val: 8 0.569210946559906
val: 9 0.5264785289764404
val: 10 0.5342453122138977
val: 11 0.5445452332496643
val: 12 0.539310872554779
val: 13 0.5419092774391174
val: 14 0.5483982563018799
val: 15 0.5357062816619873
val: 16 0.5221763849258423
val: 17 0.5488623380661011
val: 18 0.5588810443878174
val: 19 0.5162683129310608
val: 20 0.526465654373169
val_Epoch:[ 219 ] val_loss: 0.5396540880203247 2022-05-29 19:28:17.958343
start training 2022-05-29 19:28:18.053081
Epoch:[ 220 0 ] loss: 0.4030718207359314 2022-05-29 19:28:42.118838
Epoch:[ 220 1 ] loss: 0.4009212553501129 2022-05-29 19:28:42.909144
Epoch:[ 220 2 ] loss: 0.40042027831077576 2022-05-29 19:28:43.700368
Epoch:[ 220 3 ] loss: 0.40289512276649475 2022-05-29 19:28:44.475430
Epoch:[ 220 4 ] loss: 0.403781920671463 2022-05-29 19:28:45.250635
Epoch:[ 220 5 ] loss: 0.40186750888824463 2022-05-29 19:28:46.028246
Epoch:[ 220 6 ] loss: 0.4075755774974823 2022-05-29 19:28:46.802035
Epoch:[ 220 7 ] loss: 0.4015934467315674 2022-05-29 19:28:47.580226
Epoch:[ 220 8 ] loss: 0.40802785754203796 2022-05-29 19:28:48.370075
Epoch:[ 220 9 ] loss: 0.40154749155044556 2022-05-29 19:28:49.148029
Epoch:[ 220 10 ] loss: 0.3966829478740692 2022-05-29 19:28:49.923520
Epoch:[ 220 11 ] loss: 0.4019313454627991 2022-05-29 19:28:50.698947
Epoch:[ 220 12 ] loss: 0.40326711535453796 2022-05-29 19:28:51.471644
Epoch:[ 220 13 ] loss: 0.4027647078037262 2022-05-29 19:28:52.246628
Epoch:[ 220 14 ] loss: 0.4020380973815918 2022-05-29 19:28:53.023176
Epoch:[ 220 15 ] loss: 0.4044128358364105 2022-05-29 19:28:53.800801
Epoch:[ 220 16 ] loss: 0.40823808312416077 2022-05-29 19:29:00.714600
Epoch:[ 220 17 ] loss: 0.4022167921066284 2022-05-29 19:29:01.502906
Epoch:[ 220 18 ] loss: 0.4048663079738617 2022-05-29 19:29:02.292942
Epoch:[ 220 19 ] loss: 0.4057798385620117 2022-05-29 19:29:03.069612
Training_Epoch:[ 220 ] Training_loss: 0.4031950175762177 2022-05-29 19:29:03.070436
learning rate:  3.6893488147419155e-06
netparams have been saved once 220
val: 1 0.5617020726203918
val: 2 0.5461664795875549
val: 3 0.5527877807617188
val: 4 0.512888491153717
val: 5 0.5272095799446106
val: 6 0.5282752513885498
val: 7 0.5461715459823608
val: 8 0.5499487519264221
val: 9 0.5269260406494141
val: 10 0.5313922762870789
val: 11 0.5337721705436707
val: 12 0.54791659116745
val: 13 0.529473602771759
val: 14 0.5378696918487549
val: 15 0.5405130386352539
val: 16 0.5324212312698364
val: 17 0.5347051620483398
val: 18 0.5287144184112549
val: 19 0.556782066822052
val: 20 0.5523040890693665
val_Epoch:[ 220 ] val_loss: 0.5388970166444779 2022-05-29 19:29:08.425842
start training 2022-05-29 19:29:08.519668
Epoch:[ 221 0 ] loss: 0.4040619134902954 2022-05-29 19:29:31.319985
Epoch:[ 221 1 ] loss: 0.3997896909713745 2022-05-29 19:29:32.127917
Epoch:[ 221 2 ] loss: 0.4067724049091339 2022-05-29 19:29:32.906028
Epoch:[ 221 3 ] loss: 0.40429428219795227 2022-05-29 19:29:33.684578
Epoch:[ 221 4 ] loss: 0.4035714864730835 2022-05-29 19:29:34.462551
Epoch:[ 221 5 ] loss: 0.4068707227706909 2022-05-29 19:29:35.239695
Epoch:[ 221 6 ] loss: 0.4035305380821228 2022-05-29 19:29:36.016138
Epoch:[ 221 7 ] loss: 0.4003218710422516 2022-05-29 19:29:36.791066
Epoch:[ 221 8 ] loss: 0.40248188376426697 2022-05-29 19:29:37.569264
Epoch:[ 221 9 ] loss: 0.4037059247493744 2022-05-29 19:29:38.348111
Epoch:[ 221 10 ] loss: 0.4009874165058136 2022-05-29 19:29:39.134748
Epoch:[ 221 11 ] loss: 0.4056633412837982 2022-05-29 19:29:39.910807
Epoch:[ 221 12 ] loss: 0.4034273624420166 2022-05-29 19:29:40.697469
Epoch:[ 221 13 ] loss: 0.4050702452659607 2022-05-29 19:29:41.472490
Epoch:[ 221 14 ] loss: 0.40389102697372437 2022-05-29 19:29:42.259399
Epoch:[ 221 15 ] loss: 0.39973270893096924 2022-05-29 19:29:43.037665
Epoch:[ 221 16 ] loss: 0.3978305160999298 2022-05-29 19:29:50.966856
Epoch:[ 221 17 ] loss: 0.40569302439689636 2022-05-29 19:29:51.745562
Epoch:[ 221 18 ] loss: 0.40195634961128235 2022-05-29 19:29:52.536516
Epoch:[ 221 19 ] loss: 0.40310633182525635 2022-05-29 19:29:53.321108
Training_Epoch:[ 221 ] Training_loss: 0.4031379520893097 2022-05-29 19:29:53.321797
learning rate:  2.9514790517935326e-06
val: 1 0.5483859777450562
val: 2 0.5435863733291626
val: 3 0.5499594211578369
val: 4 0.5318606495857239
val: 5 0.529990017414093
val: 6 0.5451751351356506
val: 7 0.543165385723114
val: 8 0.5294783115386963
val: 9 0.5450883507728577
val: 10 0.5432641506195068
val: 11 0.5336148142814636
val: 12 0.5480588674545288
val: 13 0.5369666814804077
val: 14 0.5363192558288574
val: 15 0.555272102355957
val: 16 0.5403050184249878
val: 17 0.5356719493865967
val: 18 0.526961088180542
val: 19 0.5378392338752747
val: 20 0.5251908302307129
val_Epoch:[ 221 ] val_loss: 0.5393076807260513 2022-05-29 19:29:58.548957
start training 2022-05-29 19:29:58.645897
Epoch:[ 222 0 ] loss: 0.40886035561561584 2022-05-29 19:30:20.904048
Epoch:[ 222 1 ] loss: 0.40252748131752014 2022-05-29 19:30:22.083075
Epoch:[ 222 2 ] loss: 0.40648117661476135 2022-05-29 19:30:22.861522
Epoch:[ 222 3 ] loss: 0.4030824303627014 2022-05-29 19:30:23.641053
Epoch:[ 222 4 ] loss: 0.40326201915740967 2022-05-29 19:30:24.418317
Epoch:[ 222 5 ] loss: 0.40041807293891907 2022-05-29 19:30:25.205324
Epoch:[ 222 6 ] loss: 0.4055134057998657 2022-05-29 19:30:25.981447
Epoch:[ 222 7 ] loss: 0.4021822512149811 2022-05-29 19:30:26.756567
Epoch:[ 222 8 ] loss: 0.39978650212287903 2022-05-29 19:30:27.543312
Epoch:[ 222 9 ] loss: 0.40293192863464355 2022-05-29 19:30:28.320984
Epoch:[ 222 10 ] loss: 0.4029795527458191 2022-05-29 19:30:29.099021
Epoch:[ 222 11 ] loss: 0.40264415740966797 2022-05-29 19:30:29.877965
Epoch:[ 222 12 ] loss: 0.4060635566711426 2022-05-29 19:30:30.656222
Epoch:[ 222 13 ] loss: 0.40151217579841614 2022-05-29 19:30:31.430370
Epoch:[ 222 14 ] loss: 0.4015922546386719 2022-05-29 19:30:32.207777
Epoch:[ 222 15 ] loss: 0.40380093455314636 2022-05-29 19:30:32.993047
Epoch:[ 222 16 ] loss: 0.4047471284866333 2022-05-29 19:30:41.213713
Epoch:[ 222 17 ] loss: 0.4059082567691803 2022-05-29 19:30:41.991388
Epoch:[ 222 18 ] loss: 0.39930614829063416 2022-05-29 19:30:42.781519
Epoch:[ 222 19 ] loss: 0.4037628471851349 2022-05-29 19:30:43.555545
Training_Epoch:[ 222 ] Training_loss: 0.4033681318163872 2022-05-29 19:30:43.556202
learning rate:  2.9514790517935326e-06
netparams have been saved once 222
val: 1 0.5296313166618347
val: 2 0.5351806879043579
val: 3 0.5234373807907104
val: 4 0.5556296706199646
val: 5 0.552441418170929
val: 6 0.5351656079292297
val: 7 0.525722324848175
val: 8 0.5462557077407837
val: 9 0.5219886898994446
val: 10 0.5391036868095398
val: 11 0.5508105158805847
val: 12 0.5474174618721008
val: 13 0.5215930342674255
val: 14 0.5452222228050232
val: 15 0.5476348400115967
val: 16 0.5206437110900879
val: 17 0.5311663746833801
val: 18 0.5423210859298706
val: 19 0.558384120464325
val: 20 0.5657989382743835
val_Epoch:[ 222 ] val_loss: 0.5397774398326873 2022-05-29 19:30:48.842509
start training 2022-05-29 19:30:48.940942
Epoch:[ 223 0 ] loss: 0.40269845724105835 2022-05-29 19:31:12.239529
Epoch:[ 223 1 ] loss: 0.40382394194602966 2022-05-29 19:31:13.051621
Epoch:[ 223 2 ] loss: 0.3999709486961365 2022-05-29 19:31:13.838877
Epoch:[ 223 3 ] loss: 0.4027673006057739 2022-05-29 19:31:14.615065
Epoch:[ 223 4 ] loss: 0.4056464731693268 2022-05-29 19:31:15.405406
Epoch:[ 223 5 ] loss: 0.400827556848526 2022-05-29 19:31:16.182909
Epoch:[ 223 6 ] loss: 0.40294402837753296 2022-05-29 19:31:16.960648
Epoch:[ 223 7 ] loss: 0.4020927846431732 2022-05-29 19:31:17.736688
Epoch:[ 223 8 ] loss: 0.4018484950065613 2022-05-29 19:31:18.514414
Epoch:[ 223 9 ] loss: 0.4032377600669861 2022-05-29 19:31:19.287782
Epoch:[ 223 10 ] loss: 0.4026826024055481 2022-05-29 19:31:20.066137
Epoch:[ 223 11 ] loss: 0.40324240922927856 2022-05-29 19:31:20.842902
Epoch:[ 223 12 ] loss: 0.4012402892112732 2022-05-29 19:31:21.620073
Epoch:[ 223 13 ] loss: 0.402089923620224 2022-05-29 19:31:22.410800
Epoch:[ 223 14 ] loss: 0.40235060453414917 2022-05-29 19:31:23.185354
Epoch:[ 223 15 ] loss: 0.4038304388523102 2022-05-29 19:31:23.961202
Epoch:[ 223 16 ] loss: 0.40508753061294556 2022-05-29 19:31:31.890188
Epoch:[ 223 17 ] loss: 0.4039047956466675 2022-05-29 19:31:32.668057
Epoch:[ 223 18 ] loss: 0.40566685795783997 2022-05-29 19:31:33.464710
Epoch:[ 223 19 ] loss: 0.40652525424957275 2022-05-29 19:31:34.256180
Training_Epoch:[ 223 ] Training_loss: 0.4031239226460457 2022-05-29 19:31:34.256946
learning rate:  2.9514790517935326e-06
val: 1 0.5343549251556396
val: 2 0.5255485773086548
val: 3 0.5488439202308655
val: 4 0.545466423034668
val: 5 0.5197563171386719
val: 6 0.5392325520515442
val: 7 0.5640060305595398
val: 8 0.5318259596824646
val: 9 0.5424875020980835
val: 10 0.5408661961555481
val: 11 0.5386642217636108
val: 12 0.5176772475242615
val: 13 0.5429043769836426
val: 14 0.5515474081039429
val: 15 0.5502734184265137
val: 16 0.5399777889251709
val: 17 0.5340681076049805
val: 18 0.5401309132575989
val: 19 0.5415083765983582
val: 20 0.5436846017837524
val_Epoch:[ 223 ] val_loss: 0.5396412432193756 2022-05-29 19:31:39.436709
start training 2022-05-29 19:31:39.535636
Epoch:[ 224 0 ] loss: 0.401420921087265 2022-05-29 19:32:02.213505
Epoch:[ 224 1 ] loss: 0.40462103486061096 2022-05-29 19:32:03.607286
Epoch:[ 224 2 ] loss: 0.4036419093608856 2022-05-29 19:32:04.397712
Epoch:[ 224 3 ] loss: 0.40214264392852783 2022-05-29 19:32:05.174270
Epoch:[ 224 4 ] loss: 0.4030792713165283 2022-05-29 19:32:05.953797
Epoch:[ 224 5 ] loss: 0.4018794000148773 2022-05-29 19:32:06.733768
Epoch:[ 224 6 ] loss: 0.4010647237300873 2022-05-29 19:32:07.509857
Epoch:[ 224 7 ] loss: 0.4072590470314026 2022-05-29 19:32:08.299129
Epoch:[ 224 8 ] loss: 0.40330785512924194 2022-05-29 19:32:09.087554
Epoch:[ 224 9 ] loss: 0.3966858685016632 2022-05-29 19:32:09.863773
Epoch:[ 224 10 ] loss: 0.3981015086174011 2022-05-29 19:32:10.639466
Epoch:[ 224 11 ] loss: 0.40604159235954285 2022-05-29 19:32:11.418000
Epoch:[ 224 12 ] loss: 0.4000842273235321 2022-05-29 19:32:12.195479
Epoch:[ 224 13 ] loss: 0.4032174348831177 2022-05-29 19:32:12.974804
Epoch:[ 224 14 ] loss: 0.4061904847621918 2022-05-29 19:32:13.751994
Epoch:[ 224 15 ] loss: 0.4049140512943268 2022-05-29 19:32:14.527044
Epoch:[ 224 16 ] loss: 0.4043559730052948 2022-05-29 19:32:21.587797
Epoch:[ 224 17 ] loss: 0.4067744016647339 2022-05-29 19:32:22.587100
Epoch:[ 224 18 ] loss: 0.405963271856308 2022-05-29 19:32:23.377911
Epoch:[ 224 19 ] loss: 0.40339571237564087 2022-05-29 19:32:24.165252
Training_Epoch:[ 224 ] Training_loss: 0.403207066655159 2022-05-29 19:32:24.165989
learning rate:  2.9514790517935326e-06
netparams have been saved once 224
val: 1 0.532541811466217
val: 2 0.56996089220047
val: 3 0.5352506637573242
val: 4 0.528765082359314
val: 5 0.543379008769989
val: 6 0.5503126978874207
val: 7 0.5178039073944092
val: 8 0.5500637888908386
val: 9 0.5327019691467285
val: 10 0.5453207492828369
val: 11 0.5383380651473999
val: 12 0.5505711436271667
val: 13 0.5156579613685608
val: 14 0.558647632598877
val: 15 0.5337262153625488
val: 16 0.5527254343032837
val: 17 0.5421736836433411
val: 18 0.5533415675163269
val: 19 0.4999595582485199
val: 20 0.5346494317054749
val_Epoch:[ 224 ] val_loss: 0.5392945632338524 2022-05-29 19:32:29.582015
start training 2022-05-29 19:32:29.680263
Epoch:[ 225 0 ] loss: 0.4077419638633728 2022-05-29 19:32:52.257447
Epoch:[ 225 1 ] loss: 0.40078237652778625 2022-05-29 19:32:53.427997
Epoch:[ 225 2 ] loss: 0.401949405670166 2022-05-29 19:32:54.214036
Epoch:[ 225 3 ] loss: 0.4064232409000397 2022-05-29 19:32:54.990354
Epoch:[ 225 4 ] loss: 0.3983760178089142 2022-05-29 19:32:55.765144
Epoch:[ 225 5 ] loss: 0.40529105067253113 2022-05-29 19:32:56.543989
Epoch:[ 225 6 ] loss: 0.4058816730976105 2022-05-29 19:32:57.335160
Epoch:[ 225 7 ] loss: 0.39881032705307007 2022-05-29 19:32:58.123021
Epoch:[ 225 8 ] loss: 0.4047434329986572 2022-05-29 19:32:58.898257
Epoch:[ 225 9 ] loss: 0.4030468463897705 2022-05-29 19:32:59.673722
Epoch:[ 225 10 ] loss: 0.40028899908065796 2022-05-29 19:33:00.450164
Epoch:[ 225 11 ] loss: 0.4078074097633362 2022-05-29 19:33:01.226039
Epoch:[ 225 12 ] loss: 0.4048005938529968 2022-05-29 19:33:02.004514
Epoch:[ 225 13 ] loss: 0.40225404500961304 2022-05-29 19:33:02.782087
Epoch:[ 225 14 ] loss: 0.4013550579547882 2022-05-29 19:33:03.556338
Epoch:[ 225 15 ] loss: 0.4028628170490265 2022-05-29 19:33:04.333333
Epoch:[ 225 16 ] loss: 0.4033929705619812 2022-05-29 19:33:12.181457
Epoch:[ 225 17 ] loss: 0.4037109613418579 2022-05-29 19:33:12.955994
Epoch:[ 225 18 ] loss: 0.4029805362224579 2022-05-29 19:33:13.733548
Epoch:[ 225 19 ] loss: 0.4023197591304779 2022-05-29 19:33:14.521897
Training_Epoch:[ 225 ] Training_loss: 0.4032409742474556 2022-05-29 19:33:14.522598
learning rate:  2.9514790517935326e-06
val: 1 0.5421652793884277
val: 2 0.5188699960708618
val: 3 0.538451075553894
val: 4 0.5362593531608582
val: 5 0.5514692068099976
val: 6 0.5304423570632935
val: 7 0.5579525232315063
val: 8 0.5413569808006287
val: 9 0.5369102954864502
val: 10 0.5684877038002014
val: 11 0.5320300459861755
val: 12 0.5222698450088501
val: 13 0.552506148815155
val: 14 0.5379375219345093
val: 15 0.5549517273902893
val: 16 0.5171488523483276
val: 17 0.541590690612793
val: 18 0.5409714579582214
val: 19 0.5416287183761597
val: 20 0.5281676054000854
val_Epoch:[ 225 ] val_loss: 0.5395783692598343 2022-05-29 19:33:19.941420
start training 2022-05-29 19:33:20.038816
Epoch:[ 226 0 ] loss: 0.4042278230190277 2022-05-29 19:33:43.117962
Epoch:[ 226 1 ] loss: 0.4031832218170166 2022-05-29 19:33:43.895291
Epoch:[ 226 2 ] loss: 0.40358200669288635 2022-05-29 19:33:44.671423
Epoch:[ 226 3 ] loss: 0.403931200504303 2022-05-29 19:33:45.459274
Epoch:[ 226 4 ] loss: 0.40660643577575684 2022-05-29 19:33:46.236013
Epoch:[ 226 5 ] loss: 0.39815619587898254 2022-05-29 19:33:47.010589
Epoch:[ 226 6 ] loss: 0.40514329075813293 2022-05-29 19:33:47.800795
Epoch:[ 226 7 ] loss: 0.4028793275356293 2022-05-29 19:33:48.579138
Epoch:[ 226 8 ] loss: 0.4041304290294647 2022-05-29 19:33:49.356655
Epoch:[ 226 9 ] loss: 0.4026869833469391 2022-05-29 19:33:50.144772
Epoch:[ 226 10 ] loss: 0.4035573899745941 2022-05-29 19:33:50.920263
Epoch:[ 226 11 ] loss: 0.4002068340778351 2022-05-29 19:33:51.694874
Epoch:[ 226 12 ] loss: 0.40398985147476196 2022-05-29 19:33:52.469961
Epoch:[ 226 13 ] loss: 0.40618109703063965 2022-05-29 19:33:53.249909
Epoch:[ 226 14 ] loss: 0.39862293004989624 2022-05-29 19:33:54.027137
Epoch:[ 226 15 ] loss: 0.403814435005188 2022-05-29 19:33:54.803396
Epoch:[ 226 16 ] loss: 0.4004668593406677 2022-05-29 19:34:02.261229
Epoch:[ 226 17 ] loss: 0.40754711627960205 2022-05-29 19:34:03.073351
Epoch:[ 226 18 ] loss: 0.40071916580200195 2022-05-29 19:34:03.876085
Epoch:[ 226 19 ] loss: 0.4025237560272217 2022-05-29 19:34:04.650480
Training_Epoch:[ 226 ] Training_loss: 0.40310781747102736 2022-05-29 19:34:04.651204
learning rate:  2.9514790517935326e-06
netparams have been saved once 226
val: 1 0.5422853827476501
val: 2 0.5665494203567505
val: 3 0.5375221967697144
val: 4 0.529179036617279
val: 5 0.546042799949646
val: 6 0.53481125831604
val: 7 0.5360413789749146
val: 8 0.5216025114059448
val: 9 0.5371776223182678
val: 10 0.5634199380874634
val: 11 0.5410097241401672
val: 12 0.5378304719924927
val: 13 0.5289658308029175
val: 14 0.5429460406303406
val: 15 0.5430543422698975
val: 16 0.5366138815879822
val: 17 0.5386214852333069
val: 18 0.5281985998153687
val: 19 0.5433217883110046
val: 20 0.5410730838775635
val_Epoch:[ 226 ] val_loss: 0.5398133397102356 2022-05-29 19:34:09.881796
start training 2022-05-29 19:34:09.979323
Epoch:[ 227 0 ] loss: 0.40470561385154724 2022-05-29 19:34:33.733962
Epoch:[ 227 1 ] loss: 0.40444010496139526 2022-05-29 19:34:34.509910
Epoch:[ 227 2 ] loss: 0.40191397070884705 2022-05-29 19:34:35.286913
Epoch:[ 227 3 ] loss: 0.4040035009384155 2022-05-29 19:34:36.075975
Epoch:[ 227 4 ] loss: 0.39990144968032837 2022-05-29 19:34:36.850277
Epoch:[ 227 5 ] loss: 0.4012271463871002 2022-05-29 19:34:37.626789
Epoch:[ 227 6 ] loss: 0.4066983759403229 2022-05-29 19:34:38.400886
Epoch:[ 227 7 ] loss: 0.4010574519634247 2022-05-29 19:34:39.177581
Epoch:[ 227 8 ] loss: 0.40365472435951233 2022-05-29 19:34:39.955302
Epoch:[ 227 9 ] loss: 0.40187084674835205 2022-05-29 19:34:40.742526
Epoch:[ 227 10 ] loss: 0.40239647030830383 2022-05-29 19:34:41.530788
Epoch:[ 227 11 ] loss: 0.40509533882141113 2022-05-29 19:34:42.305349
Epoch:[ 227 12 ] loss: 0.40342652797698975 2022-05-29 19:34:43.080447
Epoch:[ 227 13 ] loss: 0.40032854676246643 2022-05-29 19:34:43.855315
Epoch:[ 227 14 ] loss: 0.4090859591960907 2022-05-29 19:34:44.632486
Epoch:[ 227 15 ] loss: 0.40398094058036804 2022-05-29 19:34:45.411066
Epoch:[ 227 16 ] loss: 0.4011823236942291 2022-05-29 19:34:52.839001
Epoch:[ 227 17 ] loss: 0.402337908744812 2022-05-29 19:34:53.625394
Epoch:[ 227 18 ] loss: 0.40243279933929443 2022-05-29 19:34:54.405656
Epoch:[ 227 19 ] loss: 0.4035624861717224 2022-05-29 19:34:55.180074
Training_Epoch:[ 227 ] Training_loss: 0.4031651243567467 2022-05-29 19:34:55.180762
learning rate:  2.9514790517935326e-06
val: 1 0.5327386260032654
val: 2 0.5363320112228394
val: 3 0.5515743494033813
val: 4 0.547355055809021
val: 5 0.5281992554664612
val: 6 0.5356523394584656
val: 7 0.5443111062049866
val: 8 0.5406766533851624
val: 9 0.5577700734138489
val: 10 0.5304732918739319
val: 11 0.533910870552063
val: 12 0.5400516986846924
val: 13 0.5424910187721252
val: 14 0.5628346800804138
val: 15 0.5424328446388245
val: 16 0.5123215913772583
val: 17 0.5366678237915039
val: 18 0.5214410424232483
val: 19 0.5467886924743652
val: 20 0.5409131050109863
val_Epoch:[ 227 ] val_loss: 0.5392468065023422 2022-05-29 19:35:00.413686
start training 2022-05-29 19:35:00.507499
Epoch:[ 228 0 ] loss: 0.4018756151199341 2022-05-29 19:35:25.020773
Epoch:[ 228 1 ] loss: 0.4028395414352417 2022-05-29 19:35:25.798738
Epoch:[ 228 2 ] loss: 0.400370717048645 2022-05-29 19:35:26.574741
Epoch:[ 228 3 ] loss: 0.40538719296455383 2022-05-29 19:35:27.362431
Epoch:[ 228 4 ] loss: 0.40617635846138 2022-05-29 19:35:28.137819
Epoch:[ 228 5 ] loss: 0.40066903829574585 2022-05-29 19:35:28.924453
Epoch:[ 228 6 ] loss: 0.40216222405433655 2022-05-29 19:35:29.701014
Epoch:[ 228 7 ] loss: 0.4001564681529999 2022-05-29 19:35:30.473709
Epoch:[ 228 8 ] loss: 0.4033162593841553 2022-05-29 19:35:31.249375
Epoch:[ 228 9 ] loss: 0.4049776792526245 2022-05-29 19:35:32.026019
Epoch:[ 228 10 ] loss: 0.3998110592365265 2022-05-29 19:35:32.815996
Epoch:[ 228 11 ] loss: 0.4033721089363098 2022-05-29 19:35:33.594520
Epoch:[ 228 12 ] loss: 0.402569442987442 2022-05-29 19:35:34.368939
Epoch:[ 228 13 ] loss: 0.4030950665473938 2022-05-29 19:35:35.142917
Epoch:[ 228 14 ] loss: 0.40065109729766846 2022-05-29 19:35:35.917118
Epoch:[ 228 15 ] loss: 0.40099990367889404 2022-05-29 19:35:36.692882
Epoch:[ 228 16 ] loss: 0.4025174379348755 2022-05-29 19:35:44.229839
Epoch:[ 228 17 ] loss: 0.4081631600856781 2022-05-29 19:35:45.006372
Epoch:[ 228 18 ] loss: 0.404926598072052 2022-05-29 19:35:45.798727
Epoch:[ 228 19 ] loss: 0.4059749245643616 2022-05-29 19:35:46.572598
Training_Epoch:[ 228 ] Training_loss: 0.40300059467554095 2022-05-29 19:35:46.573280
learning rate:  2.9514790517935326e-06
netparams have been saved once 228
val: 1 0.5439057350158691
val: 2 0.5660373568534851
val: 3 0.5261743068695068
val: 4 0.5424889922142029
val: 5 0.5216689705848694
val: 6 0.5579344034194946
val: 7 0.5339157581329346
val: 8 0.5187876224517822
val: 9 0.5432581305503845
val: 10 0.5405166149139404
val: 11 0.5284999012947083
val: 12 0.5517346262931824
val: 13 0.538303554058075
val: 14 0.5195059776306152
val: 15 0.5487439036369324
val: 16 0.549267053604126
val: 17 0.5415782332420349
val: 18 0.5336138606071472
val: 19 0.5297444462776184
val: 20 0.5469685792922974
val_Epoch:[ 228 ] val_loss: 0.5391324013471603 2022-05-29 19:35:51.901586
start training 2022-05-29 19:35:51.997976
Epoch:[ 229 0 ] loss: 0.40314069390296936 2022-05-29 19:36:14.914205
Epoch:[ 229 1 ] loss: 0.40366050601005554 2022-05-29 19:36:16.036394
Epoch:[ 229 2 ] loss: 0.4023357331752777 2022-05-29 19:36:16.827589
Epoch:[ 229 3 ] loss: 0.4027198851108551 2022-05-29 19:36:17.605706
Epoch:[ 229 4 ] loss: 0.4012224078178406 2022-05-29 19:36:18.394280
Epoch:[ 229 5 ] loss: 0.4046686887741089 2022-05-29 19:36:19.171826
Epoch:[ 229 6 ] loss: 0.4015164077281952 2022-05-29 19:36:19.947951
Epoch:[ 229 7 ] loss: 0.40352413058280945 2022-05-29 19:36:20.723087
Epoch:[ 229 8 ] loss: 0.40422648191452026 2022-05-29 19:36:21.511000
Epoch:[ 229 9 ] loss: 0.40596216917037964 2022-05-29 19:36:22.289705
Epoch:[ 229 10 ] loss: 0.4047168493270874 2022-05-29 19:36:23.067695
Epoch:[ 229 11 ] loss: 0.40437760949134827 2022-05-29 19:36:23.847592
Epoch:[ 229 12 ] loss: 0.4033419191837311 2022-05-29 19:36:24.623937
Epoch:[ 229 13 ] loss: 0.403635710477829 2022-05-29 19:36:25.400100
Epoch:[ 229 14 ] loss: 0.4005078077316284 2022-05-29 19:36:26.176860
Epoch:[ 229 15 ] loss: 0.4030724763870239 2022-05-29 19:36:26.953021
Epoch:[ 229 16 ] loss: 0.40026581287384033 2022-05-29 19:36:34.502005
Epoch:[ 229 17 ] loss: 0.40397894382476807 2022-05-29 19:36:35.290557
Epoch:[ 229 18 ] loss: 0.4038943648338318 2022-05-29 19:36:36.069508
Epoch:[ 229 19 ] loss: 0.40322232246398926 2022-05-29 19:36:36.844741
Training_Epoch:[ 229 ] Training_loss: 0.40319954603910446 2022-05-29 19:36:36.845400
learning rate:  2.9514790517935326e-06
val: 1 0.5369216203689575
val: 2 0.5362494587898254
val: 3 0.5521795749664307
val: 4 0.5413236618041992
val: 5 0.5452430248260498
val: 6 0.5477063059806824
val: 7 0.556265652179718
val: 8 0.5305541157722473
val: 9 0.5316741466522217
val: 10 0.5255258679389954
val: 11 0.5193305611610413
val: 12 0.5355245471000671
val: 13 0.5455762147903442
val: 14 0.5505362153053284
val: 15 0.555033802986145
val: 16 0.541124165058136
val: 17 0.553316593170166
val: 18 0.5405448079109192
val: 19 0.5125918984413147
val: 20 0.5287927389144897
val_Epoch:[ 229 ] val_loss: 0.539300748705864 2022-05-29 19:36:42.048945
start training 2022-05-29 19:36:42.147556
Epoch:[ 230 0 ] loss: 0.40245839953422546 2022-05-29 19:37:06.055762
Epoch:[ 230 1 ] loss: 0.39960959553718567 2022-05-29 19:37:06.829694
Epoch:[ 230 2 ] loss: 0.4046033024787903 2022-05-29 19:37:07.604660
Epoch:[ 230 3 ] loss: 0.40077418088912964 2022-05-29 19:37:08.382946
Epoch:[ 230 4 ] loss: 0.40849417448043823 2022-05-29 19:37:09.171556
Epoch:[ 230 5 ] loss: 0.404705286026001 2022-05-29 19:37:09.951007
Epoch:[ 230 6 ] loss: 0.4025438725948334 2022-05-29 19:37:10.725355
Epoch:[ 230 7 ] loss: 0.40449103713035583 2022-05-29 19:37:11.499607
Epoch:[ 230 8 ] loss: 0.40201354026794434 2022-05-29 19:37:12.276039
Epoch:[ 230 9 ] loss: 0.4028024673461914 2022-05-29 19:37:13.051743
Epoch:[ 230 10 ] loss: 0.3992284834384918 2022-05-29 19:37:13.839809
Epoch:[ 230 11 ] loss: 0.39995601773262024 2022-05-29 19:37:14.617189
Epoch:[ 230 12 ] loss: 0.4007638692855835 2022-05-29 19:37:15.397255
Epoch:[ 230 13 ] loss: 0.40116843581199646 2022-05-29 19:37:16.174932
Epoch:[ 230 14 ] loss: 0.4039444029331207 2022-05-29 19:37:16.963278
Epoch:[ 230 15 ] loss: 0.40203365683555603 2022-05-29 19:37:17.738055
Epoch:[ 230 16 ] loss: 0.4032404124736786 2022-05-29 19:37:25.436371
Epoch:[ 230 17 ] loss: 0.40598830580711365 2022-05-29 19:37:26.213241
Epoch:[ 230 18 ] loss: 0.4064159691333771 2022-05-29 19:37:27.006213
Epoch:[ 230 19 ] loss: 0.4062933325767517 2022-05-29 19:37:27.779391
Training_Epoch:[ 230 ] Training_loss: 0.40307643711566926 2022-05-29 19:37:27.780122
learning rate:  2.9514790517935326e-06
netparams have been saved once 230
val: 1 0.5297039151191711
val: 2 0.5315878987312317
val: 3 0.5583008527755737
val: 4 0.5317258238792419
val: 5 0.5413021445274353
val: 6 0.5416110754013062
val: 7 0.5326257944107056
val: 8 0.5423843860626221
val: 9 0.5325672030448914
val: 10 0.5434744954109192
val: 11 0.5374378561973572
val: 12 0.5406640768051147
val: 13 0.528740644454956
val: 14 0.5310962200164795
val: 15 0.5496196150779724
val: 16 0.537480890750885
val: 17 0.5398349761962891
val: 18 0.5515493750572205
val: 19 0.5359095931053162
val: 20 0.5499049425125122
val_Epoch:[ 230 ] val_loss: 0.5393760889768601 2022-05-29 19:37:33.037322
start training 2022-05-29 19:37:33.143021
Epoch:[ 231 0 ] loss: 0.40197017788887024 2022-05-29 19:37:56.501654
Epoch:[ 231 1 ] loss: 0.4005294740200043 2022-05-29 19:37:57.276381
Epoch:[ 231 2 ] loss: 0.40202707052230835 2022-05-29 19:37:58.050785
Epoch:[ 231 3 ] loss: 0.4036492705345154 2022-05-29 19:37:58.825700
Epoch:[ 231 4 ] loss: 0.4046381115913391 2022-05-29 19:37:59.603444
Epoch:[ 231 5 ] loss: 0.4032607674598694 2022-05-29 19:38:00.380438
Epoch:[ 231 6 ] loss: 0.40018510818481445 2022-05-29 19:38:01.156424
Epoch:[ 231 7 ] loss: 0.40542957186698914 2022-05-29 19:38:01.946592
Epoch:[ 231 8 ] loss: 0.40422824025154114 2022-05-29 19:38:02.720358
Epoch:[ 231 9 ] loss: 0.4064341187477112 2022-05-29 19:38:03.507014
Epoch:[ 231 10 ] loss: 0.40556055307388306 2022-05-29 19:38:04.281456
Epoch:[ 231 11 ] loss: 0.40349942445755005 2022-05-29 19:38:05.059076
Epoch:[ 231 12 ] loss: 0.4016091823577881 2022-05-29 19:38:05.837497
Epoch:[ 231 13 ] loss: 0.40244626998901367 2022-05-29 19:38:06.624686
Epoch:[ 231 14 ] loss: 0.3956926465034485 2022-05-29 19:38:07.399845
Epoch:[ 231 15 ] loss: 0.4045514762401581 2022-05-29 19:38:08.174888
Epoch:[ 231 16 ] loss: 0.4056593179702759 2022-05-29 19:38:15.605731
Epoch:[ 231 17 ] loss: 0.40335193276405334 2022-05-29 19:38:16.384783
Epoch:[ 231 18 ] loss: 0.39940211176872253 2022-05-29 19:38:17.177168
Epoch:[ 231 19 ] loss: 0.4071708619594574 2022-05-29 19:38:17.954794
Training_Epoch:[ 231 ] Training_loss: 0.4030647844076157 2022-05-29 19:38:17.955562
learning rate:  2.361183241434826e-06
val: 1 0.5559390783309937
val: 2 0.5297594666481018
val: 3 0.539059579372406
val: 4 0.5274228453636169
val: 5 0.5780190229415894
val: 6 0.5547881722450256
val: 7 0.5385988354682922
val: 8 0.5432267189025879
val: 9 0.5262044668197632
val: 10 0.5368350148200989
val: 11 0.5295388698577881
val: 12 0.5418238043785095
val: 13 0.5188173651695251
val: 14 0.5373936891555786
val: 15 0.541894257068634
val: 16 0.5475571155548096
val: 17 0.5299229025840759
val: 18 0.541530966758728
val: 19 0.54556804895401
val: 20 0.5327422618865967
val_Epoch:[ 231 ] val_loss: 0.5398321241140366 2022-05-29 19:38:23.123161
start training 2022-05-29 19:38:23.218630
Epoch:[ 232 0 ] loss: 0.39991509914398193 2022-05-29 19:38:46.621117
Epoch:[ 232 1 ] loss: 0.4025615453720093 2022-05-29 19:38:47.397321
Epoch:[ 232 2 ] loss: 0.4064754247665405 2022-05-29 19:38:48.183218
Epoch:[ 232 3 ] loss: 0.40307968854904175 2022-05-29 19:38:48.957096
Epoch:[ 232 4 ] loss: 0.40372586250305176 2022-05-29 19:38:49.730935
Epoch:[ 232 5 ] loss: 0.4034534990787506 2022-05-29 19:38:50.508429
Epoch:[ 232 6 ] loss: 0.401406466960907 2022-05-29 19:38:51.286508
Epoch:[ 232 7 ] loss: 0.40202653408050537 2022-05-29 19:38:52.061971
Epoch:[ 232 8 ] loss: 0.4068185091018677 2022-05-29 19:38:52.839061
Epoch:[ 232 9 ] loss: 0.40208861231803894 2022-05-29 19:38:53.614372
Epoch:[ 232 10 ] loss: 0.4044424891471863 2022-05-29 19:38:54.388383
Epoch:[ 232 11 ] loss: 0.4029744565486908 2022-05-29 19:38:55.163179
Epoch:[ 232 12 ] loss: 0.4043542146682739 2022-05-29 19:38:55.952966
Epoch:[ 232 13 ] loss: 0.40001633763313293 2022-05-29 19:38:56.742750
Epoch:[ 232 14 ] loss: 0.4045599400997162 2022-05-29 19:38:57.521617
Epoch:[ 232 15 ] loss: 0.40237078070640564 2022-05-29 19:38:58.298271
Epoch:[ 232 16 ] loss: 0.40531665086746216 2022-05-29 19:39:05.808198
Epoch:[ 232 17 ] loss: 0.4044293463230133 2022-05-29 19:39:06.584215
Epoch:[ 232 18 ] loss: 0.40251725912094116 2022-05-29 19:39:07.362002
Epoch:[ 232 19 ] loss: 0.40234610438346863 2022-05-29 19:39:08.151617
Training_Epoch:[ 232 ] Training_loss: 0.4032439410686493 2022-05-29 19:39:08.152343
learning rate:  2.361183241434826e-06
netparams have been saved once 232
val: 1 0.5322876572608948
val: 2 0.5449966788291931
val: 3 0.5332496166229248
val: 4 0.5317811369895935
val: 5 0.5263547301292419
val: 6 0.5652679800987244
val: 7 0.5449389219284058
val: 8 0.5577114224433899
val: 9 0.5383723378181458
val: 10 0.5559128522872925
val: 11 0.5214775800704956
val: 12 0.5431630611419678
val: 13 0.5475711822509766
val: 14 0.5164762139320374
val: 15 0.5460776686668396
val: 16 0.5370683073997498
val: 17 0.5185046195983887
val: 18 0.5298110246658325
val: 19 0.5290117263793945
val: 20 0.5691123604774475
val_Epoch:[ 232 ] val_loss: 0.5394573539495469 2022-05-29 19:39:13.350661
start training 2022-05-29 19:39:13.450071
Epoch:[ 233 0 ] loss: 0.4031651020050049 2022-05-29 19:39:36.126158
Epoch:[ 233 1 ] loss: 0.40340813994407654 2022-05-29 19:39:36.938343
Epoch:[ 233 2 ] loss: 0.40338262915611267 2022-05-29 19:39:37.716943
Epoch:[ 233 3 ] loss: 0.402683824300766 2022-05-29 19:39:38.492897
Epoch:[ 233 4 ] loss: 0.40294238924980164 2022-05-29 19:39:39.280859
Epoch:[ 233 5 ] loss: 0.40804237127304077 2022-05-29 19:39:40.067073
Epoch:[ 233 6 ] loss: 0.3997578024864197 2022-05-29 19:39:40.844994
Epoch:[ 233 7 ] loss: 0.40600526332855225 2022-05-29 19:39:41.622296
Epoch:[ 233 8 ] loss: 0.3971153795719147 2022-05-29 19:39:42.399962
Epoch:[ 233 9 ] loss: 0.4048323631286621 2022-05-29 19:39:43.177893
Epoch:[ 233 10 ] loss: 0.4049910008907318 2022-05-29 19:39:43.952313
Epoch:[ 233 11 ] loss: 0.4045124351978302 2022-05-29 19:39:44.727883
Epoch:[ 233 12 ] loss: 0.40307989716529846 2022-05-29 19:39:45.502761
Epoch:[ 233 13 ] loss: 0.4043687582015991 2022-05-29 19:39:46.291530
Epoch:[ 233 14 ] loss: 0.40024060010910034 2022-05-29 19:39:47.070644
Epoch:[ 233 15 ] loss: 0.3969074487686157 2022-05-29 19:39:47.847728
Epoch:[ 233 16 ] loss: 0.4053085744380951 2022-05-29 19:39:55.929656
Epoch:[ 233 17 ] loss: 0.40572118759155273 2022-05-29 19:39:56.706157
Epoch:[ 233 18 ] loss: 0.40487438440322876 2022-05-29 19:39:57.495476
Epoch:[ 233 19 ] loss: 0.40088385343551636 2022-05-29 19:39:58.271648
Training_Epoch:[ 233 ] Training_loss: 0.403111170232296 2022-05-29 19:39:58.272353
learning rate:  2.361183241434826e-06
val: 1 0.5466131567955017
val: 2 0.5502493977546692
val: 3 0.5263739228248596
val: 4 0.5393625497817993
val: 5 0.5400668382644653
val: 6 0.5358829498291016
val: 7 0.5351266264915466
val: 8 0.5489608645439148
val: 9 0.5267737507820129
val: 10 0.5520557761192322
val: 11 0.5446184873580933
val: 12 0.5362526774406433
val: 13 0.5442718267440796
val: 14 0.5280606150627136
val: 15 0.5367288589477539
val: 16 0.5323206186294556
val: 17 0.5364596247673035
val: 18 0.5324546694755554
val: 19 0.5195353031158447
val: 20 0.5670572519302368
val_Epoch:[ 233 ] val_loss: 0.5389612883329391 2022-05-29 19:40:03.548509
start training 2022-05-29 19:40:03.642282
Epoch:[ 234 0 ] loss: 0.4042038917541504 2022-05-29 19:40:27.038493
Epoch:[ 234 1 ] loss: 0.40296825766563416 2022-05-29 19:40:27.817119
Epoch:[ 234 2 ] loss: 0.4035235047340393 2022-05-29 19:40:28.593127
Epoch:[ 234 3 ] loss: 0.4013764262199402 2022-05-29 19:40:29.383281
Epoch:[ 234 4 ] loss: 0.40182262659072876 2022-05-29 19:40:30.157457
Epoch:[ 234 5 ] loss: 0.3997538685798645 2022-05-29 19:40:30.932922
Epoch:[ 234 6 ] loss: 0.4020712971687317 2022-05-29 19:40:31.708764
Epoch:[ 234 7 ] loss: 0.4053140878677368 2022-05-29 19:40:32.487868
Epoch:[ 234 8 ] loss: 0.4006904363632202 2022-05-29 19:40:33.266265
Epoch:[ 234 9 ] loss: 0.40298333764076233 2022-05-29 19:40:34.046100
Epoch:[ 234 10 ] loss: 0.40555283427238464 2022-05-29 19:40:34.821185
Epoch:[ 234 11 ] loss: 0.40285083651542664 2022-05-29 19:40:35.597472
Epoch:[ 234 12 ] loss: 0.40337273478507996 2022-05-29 19:40:36.373704
Epoch:[ 234 13 ] loss: 0.40669599175453186 2022-05-29 19:40:37.161679
Epoch:[ 234 14 ] loss: 0.4005105197429657 2022-05-29 19:40:37.952794
Epoch:[ 234 15 ] loss: 0.40433835983276367 2022-05-29 19:40:38.730422
Epoch:[ 234 16 ] loss: 0.4025964140892029 2022-05-29 19:40:45.852007
Epoch:[ 234 17 ] loss: 0.4037231504917145 2022-05-29 19:40:46.641224
Epoch:[ 234 18 ] loss: 0.40475866198539734 2022-05-29 19:40:47.419392
Epoch:[ 234 19 ] loss: 0.4016459882259369 2022-05-29 19:40:48.194945
Training_Epoch:[ 234 ] Training_loss: 0.40303766131401064 2022-05-29 19:40:48.195626
learning rate:  2.361183241434826e-06
netparams have been saved once 234
val: 1 0.5241053104400635
val: 2 0.5408803820610046
val: 3 0.5386789441108704
val: 4 0.5280129909515381
val: 5 0.5440056920051575
val: 6 0.5511199235916138
val: 7 0.5588404536247253
val: 8 0.5541003346443176
val: 9 0.553203821182251
val: 10 0.5336600542068481
val: 11 0.5707205533981323
val: 12 0.5339745283126831
val: 13 0.5451997518539429
val: 14 0.5340824127197266
val: 15 0.5299481153488159
val: 16 0.5547457933425903
val: 17 0.523914098739624
val: 18 0.521735429763794
val: 19 0.5229040384292603
val: 20 0.5278326869010925
val_Epoch:[ 234 ] val_loss: 0.5395832657814026 2022-05-29 19:40:53.552725
start training 2022-05-29 19:40:53.652591
Epoch:[ 235 0 ] loss: 0.402286559343338 2022-05-29 19:41:17.162092
Epoch:[ 235 1 ] loss: 0.40248218178749084 2022-05-29 19:41:17.938541
Epoch:[ 235 2 ] loss: 0.40341705083847046 2022-05-29 19:41:18.715217
Epoch:[ 235 3 ] loss: 0.40232276916503906 2022-05-29 19:41:19.492178
Epoch:[ 235 4 ] loss: 0.40409427881240845 2022-05-29 19:41:20.268281
Epoch:[ 235 5 ] loss: 0.40124836564064026 2022-05-29 19:41:21.044013
Epoch:[ 235 6 ] loss: 0.4052298069000244 2022-05-29 19:41:21.819965
Epoch:[ 235 7 ] loss: 0.39951446652412415 2022-05-29 19:41:22.604560
Epoch:[ 235 8 ] loss: 0.4010138213634491 2022-05-29 19:41:23.381658
Epoch:[ 235 9 ] loss: 0.40336570143699646 2022-05-29 19:41:24.158651
Epoch:[ 235 10 ] loss: 0.4032081365585327 2022-05-29 19:41:24.945809
Epoch:[ 235 11 ] loss: 0.4051930904388428 2022-05-29 19:41:25.720599
Epoch:[ 235 12 ] loss: 0.40370973944664 2022-05-29 19:41:26.495676
Epoch:[ 235 13 ] loss: 0.40214118361473083 2022-05-29 19:41:27.272916
Epoch:[ 235 14 ] loss: 0.40335896611213684 2022-05-29 19:41:28.058586
Epoch:[ 235 15 ] loss: 0.4065045118331909 2022-05-29 19:41:28.835297
Epoch:[ 235 16 ] loss: 0.40481656789779663 2022-05-29 19:41:35.957735
Epoch:[ 235 17 ] loss: 0.4027336835861206 2022-05-29 19:41:36.744428
Epoch:[ 235 18 ] loss: 0.4032735526561737 2022-05-29 19:41:37.523141
Epoch:[ 235 19 ] loss: 0.4049922823905945 2022-05-29 19:41:38.296523
Training_Epoch:[ 235 ] Training_loss: 0.403245335817337 2022-05-29 19:41:38.297161
learning rate:  2.361183241434826e-06
val: 1 0.5217195153236389
val: 2 0.5504257082939148
val: 3 0.5483567118644714
val: 4 0.5470262169837952
val: 5 0.5380321145057678
val: 6 0.5596571564674377
val: 7 0.531091034412384
val: 8 0.5565912127494812
val: 9 0.5420058369636536
val: 10 0.5382696986198425
val: 11 0.5349463224411011
val: 12 0.5266594290733337
val: 13 0.5430271625518799
val: 14 0.5461366176605225
val: 15 0.5388304591178894
val: 16 0.5281804203987122
val: 17 0.5203941464424133
val: 18 0.5450292825698853
val: 19 0.5325495004653931
val: 20 0.5309030413627625
val_Epoch:[ 235 ] val_loss: 0.538991579413414 2022-05-29 19:41:43.570965
start training 2022-05-29 19:41:43.666458
Epoch:[ 236 0 ] loss: 0.4058050513267517 2022-05-29 19:42:07.667897
Epoch:[ 236 1 ] loss: 0.4042240381240845 2022-05-29 19:42:08.442775
Epoch:[ 236 2 ] loss: 0.4042433500289917 2022-05-29 19:42:09.220556
Epoch:[ 236 3 ] loss: 0.39683595299720764 2022-05-29 19:42:09.997137
Epoch:[ 236 4 ] loss: 0.40512731671333313 2022-05-29 19:42:10.773801
Epoch:[ 236 5 ] loss: 0.4047485291957855 2022-05-29 19:42:11.560553
Epoch:[ 236 6 ] loss: 0.40410304069519043 2022-05-29 19:42:12.335815
Epoch:[ 236 7 ] loss: 0.4047479033470154 2022-05-29 19:42:13.111076
Epoch:[ 236 8 ] loss: 0.40360262989997864 2022-05-29 19:42:13.887134
Epoch:[ 236 9 ] loss: 0.4033391773700714 2022-05-29 19:42:14.665363
Epoch:[ 236 10 ] loss: 0.40470555424690247 2022-05-29 19:42:15.444400
Epoch:[ 236 11 ] loss: 0.39823102951049805 2022-05-29 19:42:16.233905
Epoch:[ 236 12 ] loss: 0.401808500289917 2022-05-29 19:42:17.012085
Epoch:[ 236 13 ] loss: 0.4013727307319641 2022-05-29 19:42:17.787849
Epoch:[ 236 14 ] loss: 0.40282756090164185 2022-05-29 19:42:18.561900
Epoch:[ 236 15 ] loss: 0.4054073691368103 2022-05-29 19:42:19.350430
Epoch:[ 236 16 ] loss: 0.4036193788051605 2022-05-29 19:42:26.242433
Epoch:[ 236 17 ] loss: 0.40102460980415344 2022-05-29 19:42:27.022707
Epoch:[ 236 18 ] loss: 0.40447306632995605 2022-05-29 19:42:27.818512
Epoch:[ 236 19 ] loss: 0.40359818935394287 2022-05-29 19:42:28.610612
Training_Epoch:[ 236 ] Training_loss: 0.40319224894046785 2022-05-29 19:42:28.611299
learning rate:  2.361183241434826e-06
netparams have been saved once 236
val: 1 0.5427922010421753
val: 2 0.5361292958259583
val: 3 0.5343075394630432
val: 4 0.540851354598999
val: 5 0.5370450019836426
val: 6 0.5397759079933167
val: 7 0.5577725172042847
val: 8 0.5426655411720276
val: 9 0.520054817199707
val: 10 0.5295413732528687
val: 11 0.5432935953140259
val: 12 0.5310792326927185
val: 13 0.5117795467376709
val: 14 0.5553675889968872
val: 15 0.5426313281059265
val: 16 0.5443066954612732
val: 17 0.5255808234214783
val: 18 0.5450799465179443
val: 19 0.5513116121292114
val: 20 0.5565288662910461
val_Epoch:[ 236 ] val_loss: 0.5393947392702103 2022-05-29 19:42:34.002742
start training 2022-05-29 19:42:34.097821
Epoch:[ 237 0 ] loss: 0.40279051661491394 2022-05-29 19:42:56.277960
Epoch:[ 237 1 ] loss: 0.4074465036392212 2022-05-29 19:42:57.337861
Epoch:[ 237 2 ] loss: 0.4033627510070801 2022-05-29 19:42:58.113426
Epoch:[ 237 3 ] loss: 0.4000442922115326 2022-05-29 19:42:58.891380
Epoch:[ 237 4 ] loss: 0.4028594493865967 2022-05-29 19:42:59.670425
Epoch:[ 237 5 ] loss: 0.40209904313087463 2022-05-29 19:43:00.447251
Epoch:[ 237 6 ] loss: 0.40474259853363037 2022-05-29 19:43:01.224711
Epoch:[ 237 7 ] loss: 0.39802777767181396 2022-05-29 19:43:02.000675
Epoch:[ 237 8 ] loss: 0.4011812210083008 2022-05-29 19:43:02.777153
Epoch:[ 237 9 ] loss: 0.4003000855445862 2022-05-29 19:43:03.552138
Epoch:[ 237 10 ] loss: 0.40407994389533997 2022-05-29 19:43:04.328458
Epoch:[ 237 11 ] loss: 0.4014495313167572 2022-05-29 19:43:05.117524
Epoch:[ 237 12 ] loss: 0.4048839807510376 2022-05-29 19:43:05.895284
Epoch:[ 237 13 ] loss: 0.40897876024246216 2022-05-29 19:43:06.686100
Epoch:[ 237 14 ] loss: 0.4052891731262207 2022-05-29 19:43:07.471835
Epoch:[ 237 15 ] loss: 0.39560505747795105 2022-05-29 19:43:08.248794
Epoch:[ 237 16 ] loss: 0.4023846685886383 2022-05-29 19:43:15.744668
Epoch:[ 237 17 ] loss: 0.4069167971611023 2022-05-29 19:43:16.524949
Epoch:[ 237 18 ] loss: 0.40456464886665344 2022-05-29 19:43:17.319347
Epoch:[ 237 19 ] loss: 0.40481847524642944 2022-05-29 19:43:18.097139
Training_Epoch:[ 237 ] Training_loss: 0.40309126377105714 2022-05-29 19:43:18.097825
learning rate:  2.361183241434826e-06
val: 1 0.5287380218505859
val: 2 0.5438530445098877
val: 3 0.5373343825340271
val: 4 0.5462484359741211
val: 5 0.5331918597221375
val: 6 0.5445050001144409
val: 7 0.5372032523155212
val: 8 0.5419419407844543
val: 9 0.5367210507392883
val: 10 0.5383883714675903
val: 11 0.5350820422172546
val: 12 0.5156965851783752
val: 13 0.5435035228729248
val: 14 0.5327215790748596
val: 15 0.5413055419921875
val: 16 0.542312741279602
val: 17 0.5408141613006592
val: 18 0.5466382503509521
val: 19 0.5421985983848572
val: 20 0.5573746562004089
val_Epoch:[ 237 ] val_loss: 0.5392886519432067 2022-05-29 19:43:23.414733
start training 2022-05-29 19:43:23.510457
Epoch:[ 238 0 ] loss: 0.4012516140937805 2022-05-29 19:43:46.469708
Epoch:[ 238 1 ] loss: 0.40378880500793457 2022-05-29 19:43:47.911201
Epoch:[ 238 2 ] loss: 0.4012695550918579 2022-05-29 19:43:48.684934
Epoch:[ 238 3 ] loss: 0.402011901140213 2022-05-29 19:43:49.469131
Epoch:[ 238 4 ] loss: 0.40559205412864685 2022-05-29 19:43:50.247131
Epoch:[ 238 5 ] loss: 0.40342438220977783 2022-05-29 19:43:51.036708
Epoch:[ 238 6 ] loss: 0.4019346833229065 2022-05-29 19:43:51.824252
Epoch:[ 238 7 ] loss: 0.40464287996292114 2022-05-29 19:43:52.601732
Epoch:[ 238 8 ] loss: 0.4043489098548889 2022-05-29 19:43:53.377290
Epoch:[ 238 9 ] loss: 0.40239864587783813 2022-05-29 19:43:54.150686
Epoch:[ 238 10 ] loss: 0.4034281075000763 2022-05-29 19:43:54.925376
Epoch:[ 238 11 ] loss: 0.40407538414001465 2022-05-29 19:43:55.704138
Epoch:[ 238 12 ] loss: 0.40213659405708313 2022-05-29 19:43:56.477982
Epoch:[ 238 13 ] loss: 0.40697041153907776 2022-05-29 19:43:57.255055
Epoch:[ 238 14 ] loss: 0.4051441252231598 2022-05-29 19:43:58.031219
Epoch:[ 238 15 ] loss: 0.3968680500984192 2022-05-29 19:43:58.805608
Epoch:[ 238 16 ] loss: 0.40370991826057434 2022-05-29 19:44:05.795387
Epoch:[ 238 17 ] loss: 0.4036730229854584 2022-05-29 19:44:06.832254
Epoch:[ 238 18 ] loss: 0.40269166231155396 2022-05-29 19:44:07.612833
Epoch:[ 238 19 ] loss: 0.40345075726509094 2022-05-29 19:44:08.391053
Training_Epoch:[ 238 ] Training_loss: 0.40314057320356367 2022-05-29 19:44:08.391786
learning rate:  2.361183241434826e-06
netparams have been saved once 238
val: 1 0.5498916506767273
val: 2 0.5347525477409363
val: 3 0.5296764969825745
val: 4 0.5460704565048218
val: 5 0.5336340069770813
val: 6 0.5455595254898071
val: 7 0.5378018021583557
val: 8 0.531903088092804
val: 9 0.5496195554733276
val: 10 0.5418021082878113
val: 11 0.5308430790901184
val: 12 0.5386030673980713
val: 13 0.5554378032684326
val: 14 0.5483022928237915
val: 15 0.5475291013717651
val: 16 0.5328094363212585
val: 17 0.5182380676269531
val: 18 0.5346242189407349
val: 19 0.5448554158210754
val: 20 0.539770781993866
val_Epoch:[ 238 ] val_loss: 0.5395862251520157 2022-05-29 19:44:13.652638
start training 2022-05-29 19:44:13.754044
Epoch:[ 239 0 ] loss: 0.3985161781311035 2022-05-29 19:44:38.092040
Epoch:[ 239 1 ] loss: 0.40678834915161133 2022-05-29 19:44:38.878802
Epoch:[ 239 2 ] loss: 0.40456411242485046 2022-05-29 19:44:39.655338
Epoch:[ 239 3 ] loss: 0.4044151306152344 2022-05-29 19:44:40.429504
Epoch:[ 239 4 ] loss: 0.4043356776237488 2022-05-29 19:44:41.203711
Epoch:[ 239 5 ] loss: 0.403423547744751 2022-05-29 19:44:41.982165
Epoch:[ 239 6 ] loss: 0.40470531582832336 2022-05-29 19:44:42.760841
Epoch:[ 239 7 ] loss: 0.4000930190086365 2022-05-29 19:44:43.536526
Epoch:[ 239 8 ] loss: 0.4024280309677124 2022-05-29 19:44:44.310759
Epoch:[ 239 9 ] loss: 0.406735360622406 2022-05-29 19:44:45.086224
Epoch:[ 239 10 ] loss: 0.40757322311401367 2022-05-29 19:44:45.875545
Epoch:[ 239 11 ] loss: 0.40073737502098083 2022-05-29 19:44:46.650807
Epoch:[ 239 12 ] loss: 0.40561455488204956 2022-05-29 19:44:47.430409
Epoch:[ 239 13 ] loss: 0.4015887677669525 2022-05-29 19:44:48.207286
Epoch:[ 239 14 ] loss: 0.3990398049354553 2022-05-29 19:44:48.984035
Epoch:[ 239 15 ] loss: 0.40066370368003845 2022-05-29 19:44:49.773212
Epoch:[ 239 16 ] loss: 0.4056805372238159 2022-05-29 19:44:56.643737
Epoch:[ 239 17 ] loss: 0.4011918306350708 2022-05-29 19:44:57.416086
Epoch:[ 239 18 ] loss: 0.3997790515422821 2022-05-29 19:44:58.219214
Epoch:[ 239 19 ] loss: 0.4031241834163666 2022-05-29 19:44:58.995739
Training_Epoch:[ 239 ] Training_loss: 0.4030498877167702 2022-05-29 19:44:58.996414
learning rate:  2.361183241434826e-06
val: 1 0.5539517998695374
val: 2 0.5593681335449219
val: 3 0.5315508246421814
val: 4 0.5443024635314941
val: 5 0.5395463705062866
val: 6 0.538507342338562
val: 7 0.5407083630561829
val: 8 0.547623872756958
val: 9 0.5400866866111755
val: 10 0.5433173179626465
val: 11 0.5305198431015015
val: 12 0.5300073027610779
val: 13 0.5327883958816528
val: 14 0.5332626700401306
val: 15 0.5333763360977173
val: 16 0.5349248051643372
val: 17 0.5336920022964478
val: 18 0.5432551503181458
val: 19 0.5512649416923523
val: 20 0.5297307968139648
val_Epoch:[ 239 ] val_loss: 0.5395892709493637 2022-05-29 19:45:04.331165
start training 2022-05-29 19:45:04.430852
Epoch:[ 240 0 ] loss: 0.40443071722984314 2022-05-29 19:45:27.019277
Epoch:[ 240 1 ] loss: 0.402426540851593 2022-05-29 19:45:27.869763
Epoch:[ 240 2 ] loss: 0.40115976333618164 2022-05-29 19:45:28.647506
Epoch:[ 240 3 ] loss: 0.4037168025970459 2022-05-29 19:45:29.434867
Epoch:[ 240 4 ] loss: 0.4031992554664612 2022-05-29 19:45:30.209600
Epoch:[ 240 5 ] loss: 0.39773279428482056 2022-05-29 19:45:30.986300
Epoch:[ 240 6 ] loss: 0.401455819606781 2022-05-29 19:45:31.764438
Epoch:[ 240 7 ] loss: 0.40602925419807434 2022-05-29 19:45:32.544495
Epoch:[ 240 8 ] loss: 0.40386179089546204 2022-05-29 19:45:33.322853
Epoch:[ 240 9 ] loss: 0.40686556696891785 2022-05-29 19:45:34.101422
Epoch:[ 240 10 ] loss: 0.4047498404979706 2022-05-29 19:45:34.877610
Epoch:[ 240 11 ] loss: 0.4079999625682831 2022-05-29 19:45:35.652401
Epoch:[ 240 12 ] loss: 0.40292665362358093 2022-05-29 19:45:36.428514
Epoch:[ 240 13 ] loss: 0.40270107984542847 2022-05-29 19:45:37.206296
Epoch:[ 240 14 ] loss: 0.4023555517196655 2022-05-29 19:45:37.985511
Epoch:[ 240 15 ] loss: 0.40393245220184326 2022-05-29 19:45:38.771751
Epoch:[ 240 16 ] loss: 0.40112408995628357 2022-05-29 19:45:46.576563
Epoch:[ 240 17 ] loss: 0.40238386392593384 2022-05-29 19:45:47.350878
Epoch:[ 240 18 ] loss: 0.4035736620426178 2022-05-29 19:45:48.140453
Epoch:[ 240 19 ] loss: 0.39997708797454834 2022-05-29 19:45:48.927000
Training_Epoch:[ 240 ] Training_loss: 0.4031301274895668 2022-05-29 19:45:48.927735
learning rate:  2.361183241434826e-06
netparams have been saved once 240
val: 1 0.5299726724624634
val: 2 0.5531624555587769
val: 3 0.520578145980835
val: 4 0.5385509133338928
val: 5 0.5304508805274963
val: 6 0.5790974497795105
val: 7 0.5106767416000366
val: 8 0.5353178977966309
val: 9 0.5306760668754578
val: 10 0.5285008549690247
val: 11 0.5533828735351562
val: 12 0.5406948924064636
val: 13 0.5393408536911011
val: 14 0.5243527293205261
val: 15 0.5669863820075989
val: 16 0.530612587928772
val: 17 0.5289812088012695
val: 18 0.5571834444999695
val: 19 0.5207269191741943
val: 20 0.5665966272354126
val_Epoch:[ 240 ] val_loss: 0.5392921298742295 2022-05-29 19:45:54.328873
start training 2022-05-29 19:45:54.425526
Epoch:[ 241 0 ] loss: 0.4034818112850189 2022-05-29 19:46:16.957579
Epoch:[ 241 1 ] loss: 0.4048677384853363 2022-05-29 19:46:17.839161
Epoch:[ 241 2 ] loss: 0.4070103168487549 2022-05-29 19:46:18.664835
Epoch:[ 241 3 ] loss: 0.40517503023147583 2022-05-29 19:46:19.452343
Epoch:[ 241 4 ] loss: 0.4023829996585846 2022-05-29 19:46:20.238207
Epoch:[ 241 5 ] loss: 0.3978063762187958 2022-05-29 19:46:21.014356
Epoch:[ 241 6 ] loss: 0.40214404463768005 2022-05-29 19:46:21.787209
Epoch:[ 241 7 ] loss: 0.40486401319503784 2022-05-29 19:46:22.564445
Epoch:[ 241 8 ] loss: 0.40054890513420105 2022-05-29 19:46:23.343204
Epoch:[ 241 9 ] loss: 0.40528079867362976 2022-05-29 19:46:24.119980
Epoch:[ 241 10 ] loss: 0.4051761329174042 2022-05-29 19:46:24.897154
Epoch:[ 241 11 ] loss: 0.40165677666664124 2022-05-29 19:46:25.671977
Epoch:[ 241 12 ] loss: 0.3994590640068054 2022-05-29 19:46:26.459839
Epoch:[ 241 13 ] loss: 0.40626490116119385 2022-05-29 19:46:27.235890
Epoch:[ 241 14 ] loss: 0.4031226634979248 2022-05-29 19:46:28.014988
Epoch:[ 241 15 ] loss: 0.4000852406024933 2022-05-29 19:46:28.793666
Epoch:[ 241 16 ] loss: 0.40482333302497864 2022-05-29 19:46:37.012716
Epoch:[ 241 17 ] loss: 0.4021330773830414 2022-05-29 19:46:37.788869
Epoch:[ 241 18 ] loss: 0.4004184305667877 2022-05-29 19:46:38.588973
Epoch:[ 241 19 ] loss: 0.40317049622535706 2022-05-29 19:46:39.375602
Training_Epoch:[ 241 ] Training_loss: 0.4029936075210571 2022-05-29 19:46:39.376318
learning rate:  1.888946593147861e-06
val: 1 0.550190806388855
val: 2 0.5490725636482239
val: 3 0.5177299380302429
val: 4 0.5336225628852844
val: 5 0.534629225730896
val: 6 0.5357160568237305
val: 7 0.5292831659317017
val: 8 0.5360679626464844
val: 9 0.5672176480293274
val: 10 0.5411629676818848
val: 11 0.5392093658447266
val: 12 0.5401920676231384
val: 13 0.5492127537727356
val: 14 0.5506392121315002
val: 15 0.539007306098938
val: 16 0.5363523364067078
val: 17 0.5359676480293274
val: 18 0.5283849239349365
val: 19 0.5292990207672119
val: 20 0.5459613800048828
val_Epoch:[ 241 ] val_loss: 0.5394459456205368 2022-05-29 19:46:44.600541
start training 2022-05-29 19:46:44.695240
Epoch:[ 242 0 ] loss: 0.40249165892601013 2022-05-29 19:47:08.294320
Epoch:[ 242 1 ] loss: 0.4033268392086029 2022-05-29 19:47:09.072116
Epoch:[ 242 2 ] loss: 0.40385666489601135 2022-05-29 19:47:09.847446
Epoch:[ 242 3 ] loss: 0.40410876274108887 2022-05-29 19:47:10.636195
Epoch:[ 242 4 ] loss: 0.4015085697174072 2022-05-29 19:47:11.412583
Epoch:[ 242 5 ] loss: 0.40427476167678833 2022-05-29 19:47:12.186645
Epoch:[ 242 6 ] loss: 0.4073459804058075 2022-05-29 19:47:12.974476
Epoch:[ 242 7 ] loss: 0.4056190252304077 2022-05-29 19:47:13.749599
Epoch:[ 242 8 ] loss: 0.4026406705379486 2022-05-29 19:47:14.528964
Epoch:[ 242 9 ] loss: 0.407423198223114 2022-05-29 19:47:15.317801
Epoch:[ 242 10 ] loss: 0.404902845621109 2022-05-29 19:47:16.093095
Epoch:[ 242 11 ] loss: 0.40209031105041504 2022-05-29 19:47:16.868009
Epoch:[ 242 12 ] loss: 0.4011251628398895 2022-05-29 19:47:17.642531
Epoch:[ 242 13 ] loss: 0.4024971127510071 2022-05-29 19:47:18.416586
Epoch:[ 242 14 ] loss: 0.40344730019569397 2022-05-29 19:47:19.190825
Epoch:[ 242 15 ] loss: 0.4041990339756012 2022-05-29 19:47:19.967732
Epoch:[ 242 16 ] loss: 0.4030589163303375 2022-05-29 19:47:27.167178
Epoch:[ 242 17 ] loss: 0.39793825149536133 2022-05-29 19:47:27.945311
Epoch:[ 242 18 ] loss: 0.4022369682788849 2022-05-29 19:47:28.726217
Epoch:[ 242 19 ] loss: 0.4003000259399414 2022-05-29 19:47:29.511553
Training_Epoch:[ 242 ] Training_loss: 0.4032196030020714 2022-05-29 19:47:29.512226
learning rate:  1.888946593147861e-06
netparams have been saved once 242
val: 1 0.5322821140289307
val: 2 0.5079450607299805
val: 3 0.5414735078811646
val: 4 0.5075791478157043
val: 5 0.5539398193359375
val: 6 0.5358169674873352
val: 7 0.5432842373847961
val: 8 0.5283453464508057
val: 9 0.5599733591079712
val: 10 0.5383045077323914
val: 11 0.536327600479126
val: 12 0.5218000411987305
val: 13 0.5693169832229614
val: 14 0.54286789894104
val: 15 0.5349349975585938
val: 16 0.5452035665512085
val: 17 0.5429589748382568
val: 18 0.5468074679374695
val: 19 0.5564261078834534
val: 20 0.5465590357780457
val_Epoch:[ 242 ] val_loss: 0.5396073371171951 2022-05-29 19:47:34.905481
start training 2022-05-29 19:47:35.009423
Epoch:[ 243 0 ] loss: 0.40690499544143677 2022-05-29 19:47:57.839919
Epoch:[ 243 1 ] loss: 0.40028274059295654 2022-05-29 19:47:58.690054
Epoch:[ 243 2 ] loss: 0.4032687246799469 2022-05-29 19:47:59.466539
Epoch:[ 243 3 ] loss: 0.4030950665473938 2022-05-29 19:48:00.243670
Epoch:[ 243 4 ] loss: 0.40325862169265747 2022-05-29 19:48:01.034648
Epoch:[ 243 5 ] loss: 0.40544360876083374 2022-05-29 19:48:01.811379
Epoch:[ 243 6 ] loss: 0.40154966711997986 2022-05-29 19:48:02.599825
Epoch:[ 243 7 ] loss: 0.40318265557289124 2022-05-29 19:48:03.378304
Epoch:[ 243 8 ] loss: 0.4027233123779297 2022-05-29 19:48:04.152857
Epoch:[ 243 9 ] loss: 0.40229490399360657 2022-05-29 19:48:04.941976
Epoch:[ 243 10 ] loss: 0.4035407304763794 2022-05-29 19:48:05.719150
Epoch:[ 243 11 ] loss: 0.4007314145565033 2022-05-29 19:48:06.495407
Epoch:[ 243 12 ] loss: 0.40070271492004395 2022-05-29 19:48:07.270716
Epoch:[ 243 13 ] loss: 0.4015773832798004 2022-05-29 19:48:08.045319
Epoch:[ 243 14 ] loss: 0.3998369574546814 2022-05-29 19:48:08.822732
Epoch:[ 243 15 ] loss: 0.39920932054519653 2022-05-29 19:48:09.597929
Epoch:[ 243 16 ] loss: 0.40235647559165955 2022-05-29 19:48:17.780217
Epoch:[ 243 17 ] loss: 0.40867191553115845 2022-05-29 19:48:18.559085
Epoch:[ 243 18 ] loss: 0.40637707710266113 2022-05-29 19:48:19.361092
Epoch:[ 243 19 ] loss: 0.40786272287368774 2022-05-29 19:48:20.139696
Training_Epoch:[ 243 ] Training_loss: 0.4031435504555702 2022-05-29 19:48:20.140409
learning rate:  1.888946593147861e-06
val: 1 0.556011438369751
val: 2 0.5225576758384705
val: 3 0.5456386208534241
val: 4 0.5395118594169617
val: 5 0.5316694974899292
val: 6 0.538500189781189
val: 7 0.5382581949234009
val: 8 0.539938747882843
val: 9 0.5526638031005859
val: 10 0.5307847261428833
val: 11 0.5365825891494751
val: 12 0.5383080244064331
val: 13 0.5301293730735779
val: 14 0.5377359390258789
val: 15 0.5400218963623047
val: 16 0.5507012009620667
val: 17 0.5411360859870911
val: 18 0.5592488646507263
val: 19 0.5202034711837769
val: 20 0.5381932854652405
val_Epoch:[ 243 ] val_loss: 0.5393897742033005 2022-05-29 19:48:25.399824
start training 2022-05-29 19:48:25.498408
Epoch:[ 244 0 ] loss: 0.4046602249145508 2022-05-29 19:48:48.372588
Epoch:[ 244 1 ] loss: 0.4049624800682068 2022-05-29 19:48:49.194039
Epoch:[ 244 2 ] loss: 0.4043469727039337 2022-05-29 19:48:49.967845
Epoch:[ 244 3 ] loss: 0.4023835361003876 2022-05-29 19:48:50.757261
Epoch:[ 244 4 ] loss: 0.40152707695961 2022-05-29 19:48:51.546456
Epoch:[ 244 5 ] loss: 0.39955219626426697 2022-05-29 19:48:52.323083
Epoch:[ 244 6 ] loss: 0.3991461396217346 2022-05-29 19:48:53.101772
Epoch:[ 244 7 ] loss: 0.40252795815467834 2022-05-29 19:48:53.889181
Epoch:[ 244 8 ] loss: 0.40429332852363586 2022-05-29 19:48:54.665937
Epoch:[ 244 9 ] loss: 0.40577349066734314 2022-05-29 19:48:55.440997
Epoch:[ 244 10 ] loss: 0.40469256043434143 2022-05-29 19:48:56.218550
Epoch:[ 244 11 ] loss: 0.401824414730072 2022-05-29 19:48:56.996382
Epoch:[ 244 12 ] loss: 0.4086492359638214 2022-05-29 19:48:57.771418
Epoch:[ 244 13 ] loss: 0.39978593587875366 2022-05-29 19:48:58.551296
Epoch:[ 244 14 ] loss: 0.3993171155452728 2022-05-29 19:48:59.325660
Epoch:[ 244 15 ] loss: 0.4040769636631012 2022-05-29 19:49:00.101033
Epoch:[ 244 16 ] loss: 0.402871698141098 2022-05-29 19:49:07.465435
Epoch:[ 244 17 ] loss: 0.40486854314804077 2022-05-29 19:49:08.255644
Epoch:[ 244 18 ] loss: 0.40399470925331116 2022-05-29 19:49:09.037309
Epoch:[ 244 19 ] loss: 0.40031248331069946 2022-05-29 19:49:09.816584
Training_Epoch:[ 244 ] Training_loss: 0.402978353202343 2022-05-29 19:49:09.817306
learning rate:  1.888946593147861e-06
netparams have been saved once 244
val: 1 0.5398746728897095
val: 2 0.5365762114524841
val: 3 0.547508180141449
val: 4 0.5373734831809998
val: 5 0.5347973108291626
val: 6 0.549524188041687
val: 7 0.5400223135948181
val: 8 0.5303279161453247
val: 9 0.5503302216529846
val: 10 0.5386836528778076
val: 11 0.524709939956665
val: 12 0.5389535427093506
val: 13 0.5240144729614258
val: 14 0.5306358933448792
val: 15 0.5421479940414429
val: 16 0.5515381693840027
val: 17 0.5391497015953064
val: 18 0.547444760799408
val: 19 0.5500221848487854
val: 20 0.5374194979667664
val_Epoch:[ 244 ] val_loss: 0.5395527154207229 2022-05-29 19:49:15.183876
start training 2022-05-29 19:49:15.278328
Epoch:[ 245 0 ] loss: 0.40929633378982544 2022-05-29 19:49:39.352287
Epoch:[ 245 1 ] loss: 0.39999815821647644 2022-05-29 19:49:40.126518
Epoch:[ 245 2 ] loss: 0.4039434492588043 2022-05-29 19:49:40.913549
Epoch:[ 245 3 ] loss: 0.39742639660835266 2022-05-29 19:49:41.688737
Epoch:[ 245 4 ] loss: 0.4059726297855377 2022-05-29 19:49:42.465471
Epoch:[ 245 5 ] loss: 0.40375009179115295 2022-05-29 19:49:43.243117
Epoch:[ 245 6 ] loss: 0.4080599248409271 2022-05-29 19:49:44.020188
Epoch:[ 245 7 ] loss: 0.4002961814403534 2022-05-29 19:49:44.796583
Epoch:[ 245 8 ] loss: 0.40027594566345215 2022-05-29 19:49:45.583848
Epoch:[ 245 9 ] loss: 0.4019524157047272 2022-05-29 19:49:46.357782
Epoch:[ 245 10 ] loss: 0.4011833071708679 2022-05-29 19:49:47.132560
Epoch:[ 245 11 ] loss: 0.40138503909111023 2022-05-29 19:49:47.910006
Epoch:[ 245 12 ] loss: 0.4028465151786804 2022-05-29 19:49:48.686731
Epoch:[ 245 13 ] loss: 0.4053349196910858 2022-05-29 19:49:49.462700
Epoch:[ 245 14 ] loss: 0.4026601314544678 2022-05-29 19:49:50.249056
Epoch:[ 245 15 ] loss: 0.40457600355148315 2022-05-29 19:49:51.023734
Epoch:[ 245 16 ] loss: 0.4057316184043884 2022-05-29 19:49:58.539448
Epoch:[ 245 17 ] loss: 0.4026382267475128 2022-05-29 19:49:59.312206
Epoch:[ 245 18 ] loss: 0.4030951261520386 2022-05-29 19:50:00.104499
Epoch:[ 245 19 ] loss: 0.4005969166755676 2022-05-29 19:50:00.885236
Training_Epoch:[ 245 ] Training_loss: 0.4030509665608406 2022-05-29 19:50:00.886171
learning rate:  1.888946593147861e-06
val: 1 0.5164415836334229
val: 2 0.5493990182876587
val: 3 0.5338801741600037
val: 4 0.5272621512413025
val: 5 0.554492712020874
val: 6 0.5596888065338135
val: 7 0.5485429167747498
val: 8 0.5448554158210754
val: 9 0.538629412651062
val: 10 0.5410206317901611
val: 11 0.5491092205047607
val: 12 0.5532330274581909
val: 13 0.5473595857620239
val: 14 0.5420607328414917
val: 15 0.5414491295814514
val: 16 0.5201362371444702
val: 17 0.519741952419281
val: 18 0.5245600342750549
val: 19 0.5453553199768066
val: 20 0.5257681608200073
val_Epoch:[ 245 ] val_loss: 0.5391493111848831 2022-05-29 19:50:06.180501
start training 2022-05-29 19:50:06.277391
Epoch:[ 246 0 ] loss: 0.40369701385498047 2022-05-29 19:50:29.849810
Epoch:[ 246 1 ] loss: 0.4022877812385559 2022-05-29 19:50:30.625373
Epoch:[ 246 2 ] loss: 0.405722439289093 2022-05-29 19:50:31.400604
Epoch:[ 246 3 ] loss: 0.40285158157348633 2022-05-29 19:50:32.180386
Epoch:[ 246 4 ] loss: 0.40483996272087097 2022-05-29 19:50:32.968618
Epoch:[ 246 5 ] loss: 0.4061090350151062 2022-05-29 19:50:33.757794
Epoch:[ 246 6 ] loss: 0.40128010511398315 2022-05-29 19:50:34.535619
Epoch:[ 246 7 ] loss: 0.402837336063385 2022-05-29 19:50:35.312886
Epoch:[ 246 8 ] loss: 0.40348154306411743 2022-05-29 19:50:36.088957
Epoch:[ 246 9 ] loss: 0.4048502445220947 2022-05-29 19:50:36.865012
Epoch:[ 246 10 ] loss: 0.4011603593826294 2022-05-29 19:50:37.652373
Epoch:[ 246 11 ] loss: 0.4064320921897888 2022-05-29 19:50:38.428339
Epoch:[ 246 12 ] loss: 0.3996981084346771 2022-05-29 19:50:39.205787
Epoch:[ 246 13 ] loss: 0.4063953459262848 2022-05-29 19:50:39.985151
Epoch:[ 246 14 ] loss: 0.40213969349861145 2022-05-29 19:50:40.761961
Epoch:[ 246 15 ] loss: 0.4026784300804138 2022-05-29 19:50:41.539724
Epoch:[ 246 16 ] loss: 0.40270674228668213 2022-05-29 19:50:48.900509
Epoch:[ 246 17 ] loss: 0.39976227283477783 2022-05-29 19:50:49.675475
Epoch:[ 246 18 ] loss: 0.3989866375923157 2022-05-29 19:50:50.465317
Epoch:[ 246 19 ] loss: 0.40335404872894287 2022-05-29 19:50:51.241975
Training_Epoch:[ 246 ] Training_loss: 0.40306353867053984 2022-05-29 19:50:51.242685
learning rate:  1.888946593147861e-06
netparams have been saved once 246
val: 1 0.5478851795196533
val: 2 0.546034038066864
val: 3 0.5528863072395325
val: 4 0.547510027885437
val: 5 0.5286170840263367
val: 6 0.5357474684715271
val: 7 0.53948575258255
val: 8 0.5221433639526367
val: 9 0.5483997464179993
val: 10 0.5293819904327393
val: 11 0.5294628739356995
val: 12 0.5424785614013672
val: 13 0.5478573441505432
val: 14 0.5396453142166138
val: 15 0.5579447746276855
val: 16 0.5392850041389465
val: 17 0.534660279750824
val: 18 0.5424771904945374
val: 19 0.529578447341919
val: 20 0.530846893787384
val_Epoch:[ 246 ] val_loss: 0.5396163821220398 2022-05-29 19:50:56.494573
start training 2022-05-29 19:50:56.589742
Epoch:[ 247 0 ] loss: 0.4021494388580322 2022-05-29 19:51:19.663481
Epoch:[ 247 1 ] loss: 0.3988046646118164 2022-05-29 19:51:20.478173
Epoch:[ 247 2 ] loss: 0.4026644825935364 2022-05-29 19:51:21.255515
Epoch:[ 247 3 ] loss: 0.40589380264282227 2022-05-29 19:51:22.029886
Epoch:[ 247 4 ] loss: 0.4001956284046173 2022-05-29 19:51:22.804637
Epoch:[ 247 5 ] loss: 0.40417081117630005 2022-05-29 19:51:23.591070
Epoch:[ 247 6 ] loss: 0.40511688590049744 2022-05-29 19:51:24.380162
Epoch:[ 247 7 ] loss: 0.404425710439682 2022-05-29 19:51:25.170714
Epoch:[ 247 8 ] loss: 0.40494462847709656 2022-05-29 19:51:25.947043
Epoch:[ 247 9 ] loss: 0.4007309079170227 2022-05-29 19:51:26.723061
Epoch:[ 247 10 ] loss: 0.40672674775123596 2022-05-29 19:51:27.498882
Epoch:[ 247 11 ] loss: 0.4032697081565857 2022-05-29 19:51:28.277106
Epoch:[ 247 12 ] loss: 0.4039304256439209 2022-05-29 19:51:29.052388
Epoch:[ 247 13 ] loss: 0.40401196479797363 2022-05-29 19:51:29.829997
Epoch:[ 247 14 ] loss: 0.40401172637939453 2022-05-29 19:51:30.608415
Epoch:[ 247 15 ] loss: 0.3997824490070343 2022-05-29 19:51:31.385065
Epoch:[ 247 16 ] loss: 0.4034537971019745 2022-05-29 19:51:38.688376
Epoch:[ 247 17 ] loss: 0.4018400013446808 2022-05-29 19:51:39.473354
Epoch:[ 247 18 ] loss: 0.40223053097724915 2022-05-29 19:51:40.269931
Epoch:[ 247 19 ] loss: 0.40208640694618225 2022-05-29 19:51:41.057029
Training_Epoch:[ 247 ] Training_loss: 0.40302203595638275 2022-05-29 19:51:41.057692
learning rate:  1.888946593147861e-06
val: 1 0.5389739871025085
val: 2 0.5385821461677551
val: 3 0.5455310940742493
val: 4 0.5433043241500854
val: 5 0.5292911529541016
val: 6 0.5108687281608582
val: 7 0.5354434847831726
val: 8 0.5627528429031372
val: 9 0.5578948855400085
val: 10 0.5355288982391357
val: 11 0.5264593958854675
val: 12 0.5216752290725708
val: 13 0.5493470430374146
val: 14 0.5255917906761169
val: 15 0.5328960418701172
val: 16 0.5524415969848633
val: 17 0.5443989634513855
val: 18 0.5493713617324829
val: 19 0.5343968868255615
val: 20 0.5514312386512756
val_Epoch:[ 247 ] val_loss: 0.5393090546131134 2022-05-29 19:51:46.278513
start training 2022-05-29 19:51:46.373502
Epoch:[ 248 0 ] loss: 0.40223926305770874 2022-05-29 19:52:09.924982
Epoch:[ 248 1 ] loss: 0.4046725034713745 2022-05-29 19:52:10.703144
Epoch:[ 248 2 ] loss: 0.4024079740047455 2022-05-29 19:52:11.479214
Epoch:[ 248 3 ] loss: 0.4029771685600281 2022-05-29 19:52:12.255435
Epoch:[ 248 4 ] loss: 0.4041019678115845 2022-05-29 19:52:13.030192
Epoch:[ 248 5 ] loss: 0.40011677145957947 2022-05-29 19:52:13.806094
Epoch:[ 248 6 ] loss: 0.4028044641017914 2022-05-29 19:52:14.581574
Epoch:[ 248 7 ] loss: 0.40222862362861633 2022-05-29 19:52:15.358212
Epoch:[ 248 8 ] loss: 0.4009954035282135 2022-05-29 19:52:16.147935
Epoch:[ 248 9 ] loss: 0.4027780592441559 2022-05-29 19:52:16.939102
Epoch:[ 248 10 ] loss: 0.40017449855804443 2022-05-29 19:52:17.714604
Epoch:[ 248 11 ] loss: 0.40615543723106384 2022-05-29 19:52:18.490900
Epoch:[ 248 12 ] loss: 0.4031236171722412 2022-05-29 19:52:19.278361
Epoch:[ 248 13 ] loss: 0.4049881100654602 2022-05-29 19:52:20.053226
Epoch:[ 248 14 ] loss: 0.404795378446579 2022-05-29 19:52:20.831838
Epoch:[ 248 15 ] loss: 0.40098485350608826 2022-05-29 19:52:21.611074
Epoch:[ 248 16 ] loss: 0.4040904641151428 2022-05-29 19:52:28.667540
Epoch:[ 248 17 ] loss: 0.4039314389228821 2022-05-29 19:52:29.457375
Epoch:[ 248 18 ] loss: 0.4042195677757263 2022-05-29 19:52:30.251890
Epoch:[ 248 19 ] loss: 0.404800683259964 2022-05-29 19:52:31.040199
Training_Epoch:[ 248 ] Training_loss: 0.4031293123960495 2022-05-29 19:52:31.040939
learning rate:  1.888946593147861e-06
netparams have been saved once 248
val: 1 0.5378235578536987
val: 2 0.5324479937553406
val: 3 0.5409817695617676
val: 4 0.5396984219551086
val: 5 0.5533208250999451
val: 6 0.5431685447692871
val: 7 0.5256239175796509
val: 8 0.5390055775642395
val: 9 0.5452412962913513
val: 10 0.5521111488342285
val: 11 0.5457296967506409
val: 12 0.5241032838821411
val: 13 0.5299193263053894
val: 14 0.5650427341461182
val: 15 0.525521993637085
val: 16 0.5376997590065002
val: 17 0.5307455062866211
val: 18 0.5388646125793457
val: 19 0.557502031326294
val: 20 0.5319450497627258
val_Epoch:[ 248 ] val_loss: 0.539824852347374 2022-05-29 19:52:36.391304
start training 2022-05-29 19:52:36.490648
Epoch:[ 249 0 ] loss: 0.40052032470703125 2022-05-29 19:52:58.980994
Epoch:[ 249 1 ] loss: 0.4041905105113983 2022-05-29 19:52:59.842325
Epoch:[ 249 2 ] loss: 0.3982057571411133 2022-05-29 19:53:00.660136
Epoch:[ 249 3 ] loss: 0.4044966399669647 2022-05-29 19:53:01.437493
Epoch:[ 249 4 ] loss: 0.40620267391204834 2022-05-29 19:53:02.216098
Epoch:[ 249 5 ] loss: 0.40688252449035645 2022-05-29 19:53:03.004231
Epoch:[ 249 6 ] loss: 0.40652045607566833 2022-05-29 19:53:03.777956
Epoch:[ 249 7 ] loss: 0.398803174495697 2022-05-29 19:53:04.554683
Epoch:[ 249 8 ] loss: 0.4025099277496338 2022-05-29 19:53:05.334279
Epoch:[ 249 9 ] loss: 0.40532758831977844 2022-05-29 19:53:06.111605
Epoch:[ 249 10 ] loss: 0.40103527903556824 2022-05-29 19:53:06.901383
Epoch:[ 249 11 ] loss: 0.40449196100234985 2022-05-29 19:53:07.678486
Epoch:[ 249 12 ] loss: 0.4028560221195221 2022-05-29 19:53:08.455586
Epoch:[ 249 13 ] loss: 0.40554824471473694 2022-05-29 19:53:09.241605
Epoch:[ 249 14 ] loss: 0.4043336808681488 2022-05-29 19:53:10.015703
Epoch:[ 249 15 ] loss: 0.401991069316864 2022-05-29 19:53:10.794029
Epoch:[ 249 16 ] loss: 0.4002753794193268 2022-05-29 19:53:18.837659
Epoch:[ 249 17 ] loss: 0.40371131896972656 2022-05-29 19:53:19.612514
Epoch:[ 249 18 ] loss: 0.40015295147895813 2022-05-29 19:53:20.391397
Epoch:[ 249 19 ] loss: 0.40244123339653015 2022-05-29 19:53:21.175995
Training_Epoch:[ 249 ] Training_loss: 0.40302483588457105 2022-05-29 19:53:21.176650
learning rate:  1.888946593147861e-06
val: 1 0.5451706647872925
val: 2 0.5366929173469543
val: 3 0.5508036017417908
val: 4 0.5401647090911865
val: 5 0.5178773999214172
val: 6 0.5497404336929321
val: 7 0.5512710809707642
val: 8 0.5194395184516907
val: 9 0.5526115298271179
val: 10 0.5527293086051941
val: 11 0.5408873558044434
val: 12 0.5277096629142761
val: 13 0.5355684757232666
val: 14 0.5378799438476562
val: 15 0.567699670791626
val: 16 0.531732976436615
val: 17 0.524983286857605
val: 18 0.5460640788078308
val: 19 0.527455747127533
val: 20 0.5334994792938232
val_Epoch:[ 249 ] val_loss: 0.5394990921020508 2022-05-29 19:53:26.495981
start training 2022-05-29 19:53:26.592081
Epoch:[ 250 0 ] loss: 0.39842143654823303 2022-05-29 19:53:50.217271
Epoch:[ 250 1 ] loss: 0.403988778591156 2022-05-29 19:53:50.994057
Epoch:[ 250 2 ] loss: 0.4060627222061157 2022-05-29 19:53:51.772177
Epoch:[ 250 3 ] loss: 0.4025111496448517 2022-05-29 19:53:52.563052
Epoch:[ 250 4 ] loss: 0.4009874761104584 2022-05-29 19:53:53.351129
Epoch:[ 250 5 ] loss: 0.39908549189567566 2022-05-29 19:53:54.129647
Epoch:[ 250 6 ] loss: 0.4064234793186188 2022-05-29 19:53:54.903691
Epoch:[ 250 7 ] loss: 0.4025280773639679 2022-05-29 19:53:55.679418
Epoch:[ 250 8 ] loss: 0.4054790437221527 2022-05-29 19:53:56.455562
Epoch:[ 250 9 ] loss: 0.4061809182167053 2022-05-29 19:53:57.233465
Epoch:[ 250 10 ] loss: 0.40134748816490173 2022-05-29 19:53:58.024824
Epoch:[ 250 11 ] loss: 0.40529656410217285 2022-05-29 19:53:58.803383
Epoch:[ 250 12 ] loss: 0.4028228521347046 2022-05-29 19:53:59.582885
Epoch:[ 250 13 ] loss: 0.4013727903366089 2022-05-29 19:54:00.358297
Epoch:[ 250 14 ] loss: 0.4026946425437927 2022-05-29 19:54:01.133478
Epoch:[ 250 15 ] loss: 0.4059481918811798 2022-05-29 19:54:01.909367
Epoch:[ 250 16 ] loss: 0.4033470153808594 2022-05-29 19:54:08.999013
Epoch:[ 250 17 ] loss: 0.40167227387428284 2022-05-29 19:54:09.776606
Epoch:[ 250 18 ] loss: 0.402925580739975 2022-05-29 19:54:10.559356
Epoch:[ 250 19 ] loss: 0.4000197649002075 2022-05-29 19:54:11.349427
Training_Epoch:[ 250 ] Training_loss: 0.40295578688383105 2022-05-29 19:54:11.350118
learning rate:  1.888946593147861e-06
netparams have been saved once 250
val: 1 0.5331391096115112
val: 2 0.5549988746643066
val: 3 0.5548357367515564
val: 4 0.5363354086875916
val: 5 0.5466209650039673
val: 6 0.5581499934196472
val: 7 0.5416995882987976
val: 8 0.526508092880249
val: 9 0.544463574886322
val: 10 0.523126482963562
val: 11 0.5500839948654175
val: 12 0.5588136315345764
val: 13 0.5334669947624207
val: 14 0.5317511558532715
val: 15 0.546525776386261
val: 16 0.5105114579200745
val: 17 0.525676965713501
val: 18 0.5276500582695007
val: 19 0.5520174503326416
val: 20 0.5402801632881165
val_Epoch:[ 250 ] val_loss: 0.5398327738046647 2022-05-29 19:54:16.743023
