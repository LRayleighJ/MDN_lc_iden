GPU: True
80
start training 2022-06-30 20:35:08.157393
Epoch:[ 1 0 ] loss: 0.7115824818611145 2022-06-30 20:35:30.779844
Epoch:[ 1 1 ] loss: 0.7343066930770874 2022-06-30 20:35:31.257823
Epoch:[ 1 2 ] loss: 0.6856158375740051 2022-06-30 20:35:31.674075
Epoch:[ 1 3 ] loss: 0.6799653172492981 2022-06-30 20:35:32.097739
Epoch:[ 1 4 ] loss: 0.6742018461227417 2022-06-30 20:35:32.520801
Epoch:[ 1 5 ] loss: 0.6712436676025391 2022-06-30 20:35:32.941688
Epoch:[ 1 6 ] loss: 0.6643394827842712 2022-06-30 20:35:33.363351
Epoch:[ 1 7 ] loss: 0.6607992053031921 2022-06-30 20:35:33.778375
Epoch:[ 1 8 ] loss: 0.655499279499054 2022-06-30 20:35:34.191627
Epoch:[ 1 9 ] loss: 0.6525498628616333 2022-06-30 20:35:34.609393
Epoch:[ 1 10 ] loss: 0.6467561721801758 2022-06-30 20:35:35.025306
Epoch:[ 1 11 ] loss: 0.6419731378555298 2022-06-30 20:35:35.441148
Epoch:[ 1 12 ] loss: 0.6390234231948853 2022-06-30 20:35:35.856317
Epoch:[ 1 13 ] loss: 0.6327983140945435 2022-06-30 20:35:36.278056
Epoch:[ 1 14 ] loss: 0.6268649101257324 2022-06-30 20:35:36.698746
Epoch:[ 1 15 ] loss: 0.6248034238815308 2022-06-30 20:35:37.118517
Epoch:[ 1 16 ] loss: 0.6194919943809509 2022-06-30 20:35:37.532560
Epoch:[ 1 17 ] loss: 0.6164035201072693 2022-06-30 20:35:37.948915
Epoch:[ 1 18 ] loss: 0.6131297945976257 2022-06-30 20:35:38.367640
Epoch:[ 1 19 ] loss: 0.6105957627296448 2022-06-30 20:35:38.784735
Training_Epoch:[ 1 ] Training_loss: 0.6530972063541413 2022-06-30 20:35:38.785415
learning rate:  0.005
val: 1 0.6708674430847168
val: 2 0.6701948642730713
val: 3 0.6694366931915283
val: 4 0.6729589700698853
val: 5 0.6722832322120667
val: 6 0.6686761379241943
val: 7 0.6708704233169556
val: 8 0.6696925163269043
val: 9 0.6723424792289734
val: 10 0.669517457485199
val: 11 0.6687484383583069
val: 12 0.6706461310386658
val: 13 0.670325756072998
val: 14 0.6695551872253418
val: 15 0.6706675291061401
val: 16 0.6715987324714661
val: 17 0.6711528897285461
val: 18 0.6695064902305603
val: 19 0.6715992093086243
val: 20 0.6703914999961853
val_Epoch:[ 1 ] val_loss: 0.6705516040325165 2022-06-30 20:35:42.096585
start training 2022-06-30 20:35:42.206995
Epoch:[ 2 0 ] loss: 0.6044977903366089 2022-06-30 20:35:56.221289
Epoch:[ 2 1 ] loss: 0.6024931073188782 2022-06-30 20:35:56.637016
Epoch:[ 2 2 ] loss: 0.5988361835479736 2022-06-30 20:35:57.051222
Epoch:[ 2 3 ] loss: 0.5954123735427856 2022-06-30 20:35:57.472543
Epoch:[ 2 4 ] loss: 0.594662070274353 2022-06-30 20:35:57.887496
Epoch:[ 2 5 ] loss: 0.5907774567604065 2022-06-30 20:35:58.302216
Epoch:[ 2 6 ] loss: 0.5873281955718994 2022-06-30 20:35:58.724486
Epoch:[ 2 7 ] loss: 0.5862569808959961 2022-06-30 20:35:59.141189
Epoch:[ 2 8 ] loss: 0.5831246972084045 2022-06-30 20:35:59.566050
Epoch:[ 2 9 ] loss: 0.580437421798706 2022-06-30 20:35:59.994615
Epoch:[ 2 10 ] loss: 0.5817059874534607 2022-06-30 20:36:00.412684
Epoch:[ 2 11 ] loss: 0.5799449682235718 2022-06-30 20:36:00.833826
Epoch:[ 2 12 ] loss: 0.5777624845504761 2022-06-30 20:36:01.254992
Epoch:[ 2 13 ] loss: 0.5734082460403442 2022-06-30 20:36:01.671807
Epoch:[ 2 14 ] loss: 0.5744772553443909 2022-06-30 20:36:02.087542
Epoch:[ 2 15 ] loss: 0.5719570517539978 2022-06-30 20:36:02.504699
Epoch:[ 2 16 ] loss: 0.5714751482009888 2022-06-30 20:36:07.860742
Epoch:[ 2 17 ] loss: 0.572209358215332 2022-06-30 20:36:08.277287
Epoch:[ 2 18 ] loss: 0.5708371996879578 2022-06-30 20:36:08.694823
Epoch:[ 2 19 ] loss: 0.5674932599067688 2022-06-30 20:36:09.111283
Training_Epoch:[ 2 ] Training_loss: 0.5832548618316651 2022-06-30 20:36:09.112026
learning rate:  0.005
netparams have been saved once 2
val: 1 0.580565869808197
val: 2 0.596255898475647
val: 3 0.5788782238960266
val: 4 0.5776424407958984
val: 5 0.5673360228538513
val: 6 0.5656571388244629
val: 7 0.5831663012504578
val: 8 0.5623869299888611
val: 9 0.5602397918701172
val: 10 0.5843303203582764
val: 11 0.5725088715553284
val: 12 0.5819027423858643
val: 13 0.570221483707428
val: 14 0.5783957839012146
val: 15 0.5826830863952637
val: 16 0.5704842209815979
val: 17 0.5680631995201111
val: 18 0.5794593095779419
val: 19 0.5714097023010254
val: 20 0.5594795942306519
val_Epoch:[ 2 ] val_loss: 0.5745533466339111 2022-06-30 20:36:12.615087
start training 2022-06-30 20:36:12.709960
Epoch:[ 3 0 ] loss: 0.5670477747917175 2022-06-30 20:36:26.780115
Epoch:[ 3 1 ] loss: 0.5675762891769409 2022-06-30 20:36:27.213836
Epoch:[ 3 2 ] loss: 0.5652695894241333 2022-06-30 20:36:27.636600
Epoch:[ 3 3 ] loss: 0.564399242401123 2022-06-30 20:36:28.057290
Epoch:[ 3 4 ] loss: 0.5640089511871338 2022-06-30 20:36:28.478853
Epoch:[ 3 5 ] loss: 0.565112292766571 2022-06-30 20:36:28.898448
Epoch:[ 3 6 ] loss: 0.563479483127594 2022-06-30 20:36:29.310107
Epoch:[ 3 7 ] loss: 0.5652561187744141 2022-06-30 20:36:29.731726
Epoch:[ 3 8 ] loss: 0.5641900897026062 2022-06-30 20:36:30.161946
Epoch:[ 3 9 ] loss: 0.5624096989631653 2022-06-30 20:36:30.579988
Epoch:[ 3 10 ] loss: 0.5609859228134155 2022-06-30 20:36:30.995312
Epoch:[ 3 11 ] loss: 0.5566615462303162 2022-06-30 20:36:31.410616
Epoch:[ 3 12 ] loss: 0.5614022612571716 2022-06-30 20:36:31.825378
Epoch:[ 3 13 ] loss: 0.560075044631958 2022-06-30 20:36:32.239390
Epoch:[ 3 14 ] loss: 0.5602673888206482 2022-06-30 20:36:32.654721
Epoch:[ 3 15 ] loss: 0.5604445934295654 2022-06-30 20:36:33.077106
Epoch:[ 3 16 ] loss: 0.5548022985458374 2022-06-30 20:36:38.398212
Epoch:[ 3 17 ] loss: 0.5575641393661499 2022-06-30 20:36:39.019869
Epoch:[ 3 18 ] loss: 0.5552526712417603 2022-06-30 20:36:39.437092
Epoch:[ 3 19 ] loss: 0.5566344261169434 2022-06-30 20:36:39.851954
Training_Epoch:[ 3 ] Training_loss: 0.5616419911384583 2022-06-30 20:36:39.852598
learning rate:  0.005
val: 1 0.5673928260803223
val: 2 0.5645773410797119
val: 3 0.5574219822883606
val: 4 0.5580766201019287
val: 5 0.558448076248169
val: 6 0.5577201247215271
val: 7 0.5735384225845337
val: 8 0.5635322332382202
val: 9 0.5716375112533569
val: 10 0.5553796291351318
val: 11 0.557853639125824
val: 12 0.560126543045044
val: 13 0.5610587000846863
val: 14 0.556515097618103
val: 15 0.5569486021995544
val: 16 0.558597207069397
val: 17 0.5587906837463379
val: 18 0.5642954707145691
val: 19 0.5510613918304443
val: 20 0.5565876364707947
val_Epoch:[ 3 ] val_loss: 0.5604779869318008 2022-06-30 20:36:43.230129
start training 2022-06-30 20:36:43.330174
Epoch:[ 4 0 ] loss: 0.5566757917404175 2022-06-30 20:36:57.094688
Epoch:[ 4 1 ] loss: 0.5579522252082825 2022-06-30 20:36:57.883367
Epoch:[ 4 2 ] loss: 0.5565189123153687 2022-06-30 20:36:58.300444
Epoch:[ 4 3 ] loss: 0.5521092414855957 2022-06-30 20:36:58.723423
Epoch:[ 4 4 ] loss: 0.5562516450881958 2022-06-30 20:36:59.145430
Epoch:[ 4 5 ] loss: 0.557584822177887 2022-06-30 20:36:59.581579
Epoch:[ 4 6 ] loss: 0.5530503392219543 2022-06-30 20:36:59.996130
Epoch:[ 4 7 ] loss: 0.5562708377838135 2022-06-30 20:37:00.411673
Epoch:[ 4 8 ] loss: 0.5539357662200928 2022-06-30 20:37:00.828837
Epoch:[ 4 9 ] loss: 0.5572572946548462 2022-06-30 20:37:01.245944
Epoch:[ 4 10 ] loss: 0.5539801716804504 2022-06-30 20:37:01.660102
Epoch:[ 4 11 ] loss: 0.5533087253570557 2022-06-30 20:37:02.083992
Epoch:[ 4 12 ] loss: 0.5522509813308716 2022-06-30 20:37:02.504559
Epoch:[ 4 13 ] loss: 0.5556226372718811 2022-06-30 20:37:02.919063
Epoch:[ 4 14 ] loss: 0.553080677986145 2022-06-30 20:37:03.335988
Epoch:[ 4 15 ] loss: 0.5522505640983582 2022-06-30 20:37:03.753977
Epoch:[ 4 16 ] loss: 0.5498158931732178 2022-06-30 20:37:09.150066
Epoch:[ 4 17 ] loss: 0.5550938844680786 2022-06-30 20:37:09.572344
Epoch:[ 4 18 ] loss: 0.5508320331573486 2022-06-30 20:37:09.994329
Epoch:[ 4 19 ] loss: 0.5499948263168335 2022-06-30 20:37:10.410959
Training_Epoch:[ 4 ] Training_loss: 0.5541918635368347 2022-06-30 20:37:10.411768
learning rate:  0.005
netparams have been saved once 4
val: 1 0.5735445022583008
val: 2 0.5689173936843872
val: 3 0.5765333771705627
val: 4 0.5733422040939331
val: 5 0.5729761719703674
val: 6 0.5818400979042053
val: 7 0.5747039914131165
val: 8 0.5691218376159668
val: 9 0.5830843448638916
val: 10 0.5705007314682007
val: 11 0.5842713117599487
val: 12 0.5756974220275879
val: 13 0.5782713890075684
val: 14 0.581239640712738
val: 15 0.5637134909629822
val: 16 0.5777297616004944
val: 17 0.5799582600593567
val: 18 0.5846906900405884
val: 19 0.5850992798805237
val: 20 0.5645323991775513
val_Epoch:[ 4 ] val_loss: 0.5759884148836136 2022-06-30 20:37:13.920641
start training 2022-06-30 20:37:14.018154
Epoch:[ 5 0 ] loss: 0.5521663427352905 2022-06-30 20:37:27.996581
Epoch:[ 5 1 ] loss: 0.5546907782554626 2022-06-30 20:37:28.423811
Epoch:[ 5 2 ] loss: 0.5525199770927429 2022-06-30 20:37:28.840445
Epoch:[ 5 3 ] loss: 0.5461728572845459 2022-06-30 20:37:29.270936
Epoch:[ 5 4 ] loss: 0.5493922233581543 2022-06-30 20:37:29.690098
Epoch:[ 5 5 ] loss: 0.550006628036499 2022-06-30 20:37:30.105578
Epoch:[ 5 6 ] loss: 0.5459635257720947 2022-06-30 20:37:30.527410
Epoch:[ 5 7 ] loss: 0.5489931106567383 2022-06-30 20:37:30.943444
Epoch:[ 5 8 ] loss: 0.550058901309967 2022-06-30 20:37:31.366919
Epoch:[ 5 9 ] loss: 0.5464378595352173 2022-06-30 20:37:31.789922
Epoch:[ 5 10 ] loss: 0.5466976761817932 2022-06-30 20:37:32.210919
Epoch:[ 5 11 ] loss: 0.5502927899360657 2022-06-30 20:37:32.627937
Epoch:[ 5 12 ] loss: 0.5520814657211304 2022-06-30 20:37:33.048159
Epoch:[ 5 13 ] loss: 0.550104558467865 2022-06-30 20:37:33.465464
Epoch:[ 5 14 ] loss: 0.5468021631240845 2022-06-30 20:37:33.878298
Epoch:[ 5 15 ] loss: 0.5430175065994263 2022-06-30 20:37:34.299297
Epoch:[ 5 16 ] loss: 0.5476952195167542 2022-06-30 20:37:39.586676
Epoch:[ 5 17 ] loss: 0.5477133989334106 2022-06-30 20:37:40.008523
Epoch:[ 5 18 ] loss: 0.5477526783943176 2022-06-30 20:37:40.426820
Epoch:[ 5 19 ] loss: 0.5435221791267395 2022-06-30 20:37:40.841308
Training_Epoch:[ 5 ] Training_loss: 0.548604092001915 2022-06-30 20:37:40.841989
learning rate:  0.005
val: 1 0.6363431215286255
val: 2 0.6317504048347473
val: 3 0.6376463174819946
val: 4 0.6365367770195007
val: 5 0.628551721572876
val: 6 0.6324265599250793
val: 7 0.6333954930305481
val: 8 0.6410880088806152
val: 9 0.6416661143302917
val: 10 0.6382331848144531
val: 11 0.6379896998405457
val: 12 0.6340318918228149
val: 13 0.6384254693984985
val: 14 0.646828293800354
val: 15 0.6518213152885437
val: 16 0.630339503288269
val: 17 0.6297221183776855
val: 18 0.6295758485794067
val: 19 0.6311410665512085
val: 20 0.6217305660247803
val_Epoch:[ 5 ] val_loss: 0.635462173819542 2022-06-30 20:37:44.223635
start training 2022-06-30 20:37:44.324575
Epoch:[ 6 0 ] loss: 0.5424185991287231 2022-06-30 20:37:58.559545
Epoch:[ 6 1 ] loss: 0.5444609522819519 2022-06-30 20:37:58.990221
Epoch:[ 6 2 ] loss: 0.5427938103675842 2022-06-30 20:37:59.406800
Epoch:[ 6 3 ] loss: 0.5461927652359009 2022-06-30 20:37:59.827063
Epoch:[ 6 4 ] loss: 0.5423254370689392 2022-06-30 20:38:00.251578
Epoch:[ 6 5 ] loss: 0.5448371171951294 2022-06-30 20:38:00.668194
Epoch:[ 6 6 ] loss: 0.5474646091461182 2022-06-30 20:38:01.085101
Epoch:[ 6 7 ] loss: 0.5410330295562744 2022-06-30 20:38:01.507926
Epoch:[ 6 8 ] loss: 0.5465577244758606 2022-06-30 20:38:01.928766
Epoch:[ 6 9 ] loss: 0.5410254597663879 2022-06-30 20:38:02.348264
Epoch:[ 6 10 ] loss: 0.5432026982307434 2022-06-30 20:38:02.765120
Epoch:[ 6 11 ] loss: 0.5393845438957214 2022-06-30 20:38:03.186795
Epoch:[ 6 12 ] loss: 0.5405486822128296 2022-06-30 20:38:03.603424
Epoch:[ 6 13 ] loss: 0.5470752716064453 2022-06-30 20:38:04.025549
Epoch:[ 6 14 ] loss: 0.5419697761535645 2022-06-30 20:38:04.440520
Epoch:[ 6 15 ] loss: 0.5461511015892029 2022-06-30 20:38:04.855079
Epoch:[ 6 16 ] loss: 0.5435595512390137 2022-06-30 20:38:10.343226
Epoch:[ 6 17 ] loss: 0.5420911312103271 2022-06-30 20:38:10.761002
Epoch:[ 6 18 ] loss: 0.5464377403259277 2022-06-30 20:38:11.195291
Epoch:[ 6 19 ] loss: 0.5476420521736145 2022-06-30 20:38:11.618659
Training_Epoch:[ 6 ] Training_loss: 0.543858602643013 2022-06-30 20:38:11.619390
learning rate:  0.005
netparams have been saved once 6
val: 1 0.5426110029220581
val: 2 0.5621479153633118
val: 3 0.5520003437995911
val: 4 0.5509840250015259
val: 5 0.558133065700531
val: 6 0.5498011708259583
val: 7 0.5467721223831177
val: 8 0.5519025325775146
val: 9 0.5523515343666077
val: 10 0.553774893283844
val: 11 0.5483081340789795
val: 12 0.5518376231193542
val: 13 0.5547753572463989
val: 14 0.5511185526847839
val: 15 0.5457732677459717
val: 16 0.5517162680625916
val: 17 0.5661671757698059
val: 18 0.5417779684066772
val: 19 0.5551153421401978
val: 20 0.5600440502166748
val_Epoch:[ 6 ] val_loss: 0.5523556172847748 2022-06-30 20:38:15.122714
start training 2022-06-30 20:38:15.222045
Epoch:[ 7 0 ] loss: 0.5394402146339417 2022-06-30 20:38:29.320322
Epoch:[ 7 1 ] loss: 0.5413454174995422 2022-06-30 20:38:29.751481
Epoch:[ 7 2 ] loss: 0.5391573905944824 2022-06-30 20:38:30.172108
Epoch:[ 7 3 ] loss: 0.5430364608764648 2022-06-30 20:38:30.587320
Epoch:[ 7 4 ] loss: 0.5410770773887634 2022-06-30 20:38:31.009810
Epoch:[ 7 5 ] loss: 0.5419002771377563 2022-06-30 20:38:31.433084
Epoch:[ 7 6 ] loss: 0.5390428304672241 2022-06-30 20:38:31.848714
Epoch:[ 7 7 ] loss: 0.53708815574646 2022-06-30 20:38:32.264643
Epoch:[ 7 8 ] loss: 0.5375567674636841 2022-06-30 20:38:32.679348
Epoch:[ 7 9 ] loss: 0.539149820804596 2022-06-30 20:38:33.095515
Epoch:[ 7 10 ] loss: 0.5395945906639099 2022-06-30 20:38:33.518113
Epoch:[ 7 11 ] loss: 0.5369364023208618 2022-06-30 20:38:33.941061
Epoch:[ 7 12 ] loss: 0.5389073491096497 2022-06-30 20:38:34.356870
Epoch:[ 7 13 ] loss: 0.5362006425857544 2022-06-30 20:38:34.773628
Epoch:[ 7 14 ] loss: 0.5416852235794067 2022-06-30 20:38:35.186753
Epoch:[ 7 15 ] loss: 0.5364768505096436 2022-06-30 20:38:35.602537
Epoch:[ 7 16 ] loss: 0.5392394065856934 2022-06-30 20:38:41.137117
Epoch:[ 7 17 ] loss: 0.5353913903236389 2022-06-30 20:38:41.554234
Epoch:[ 7 18 ] loss: 0.5383077263832092 2022-06-30 20:38:41.972169
Epoch:[ 7 19 ] loss: 0.5371319055557251 2022-06-30 20:38:42.388789
Training_Epoch:[ 7 ] Training_loss: 0.5389332950115204 2022-06-30 20:38:42.389536
learning rate:  0.005
val: 1 0.6470562815666199
val: 2 0.6507303714752197
val: 3 0.6347944140434265
val: 4 0.6435274481773376
val: 5 0.6517850160598755
val: 6 0.6439208984375
val: 7 0.6509513258934021
val: 8 0.6452128291130066
val: 9 0.6522424221038818
val: 10 0.6390630006790161
val: 11 0.6522886157035828
val: 12 0.6510219573974609
val: 13 0.6510416865348816
val: 14 0.657433807849884
val: 15 0.648754894733429
val: 16 0.6469228267669678
val: 17 0.6448436379432678
val: 18 0.6535583138465881
val: 19 0.6496520042419434
val: 20 0.6503717303276062
val_Epoch:[ 7 ] val_loss: 0.6482586741447449 2022-06-30 20:38:45.721641
start training 2022-06-30 20:38:45.821233
Epoch:[ 8 0 ] loss: 0.534378170967102 2022-06-30 20:38:59.727858
Epoch:[ 8 1 ] loss: 0.535050630569458 2022-06-30 20:39:00.241572
Epoch:[ 8 2 ] loss: 0.535895586013794 2022-06-30 20:39:00.655075
Epoch:[ 8 3 ] loss: 0.5381497740745544 2022-06-30 20:39:01.069015
Epoch:[ 8 4 ] loss: 0.5375833511352539 2022-06-30 20:39:01.483193
Epoch:[ 8 5 ] loss: 0.5343398451805115 2022-06-30 20:39:01.916285
Epoch:[ 8 6 ] loss: 0.5382019281387329 2022-06-30 20:39:02.338467
Epoch:[ 8 7 ] loss: 0.5348770022392273 2022-06-30 20:39:02.761781
Epoch:[ 8 8 ] loss: 0.5363106727600098 2022-06-30 20:39:03.182094
Epoch:[ 8 9 ] loss: 0.5339019298553467 2022-06-30 20:39:03.604052
Epoch:[ 8 10 ] loss: 0.5326122641563416 2022-06-30 20:39:04.018039
Epoch:[ 8 11 ] loss: 0.529725968837738 2022-06-30 20:39:04.432478
Epoch:[ 8 12 ] loss: 0.5371276140213013 2022-06-30 20:39:04.848767
Epoch:[ 8 13 ] loss: 0.5419794917106628 2022-06-30 20:39:05.264181
Epoch:[ 8 14 ] loss: 0.5380163788795471 2022-06-30 20:39:05.678490
Epoch:[ 8 15 ] loss: 0.5417407751083374 2022-06-30 20:39:06.094187
Epoch:[ 8 16 ] loss: 0.5361618399620056 2022-06-30 20:39:11.610806
Epoch:[ 8 17 ] loss: 0.5366091728210449 2022-06-30 20:39:12.023697
Epoch:[ 8 18 ] loss: 0.5331249833106995 2022-06-30 20:39:12.444366
Epoch:[ 8 19 ] loss: 0.5346558690071106 2022-06-30 20:39:12.862228
Training_Epoch:[ 8 ] Training_loss: 0.5360221624374389 2022-06-30 20:39:12.862928
learning rate:  0.005
netparams have been saved once 8
val: 1 0.572368323802948
val: 2 0.5649589896202087
val: 3 0.5695953369140625
val: 4 0.5783463716506958
val: 5 0.5907257199287415
val: 6 0.5719255805015564
val: 7 0.566392719745636
val: 8 0.5601231455802917
val: 9 0.554994523525238
val: 10 0.5653669834136963
val: 11 0.5611705780029297
val: 12 0.5777177810668945
val: 13 0.5754624009132385
val: 14 0.5703943967819214
val: 15 0.5651258230209351
val: 16 0.5695289969444275
val: 17 0.5669700503349304
val: 18 0.557081401348114
val: 19 0.5650818347930908
val: 20 0.5692746043205261
val_Epoch:[ 8 ] val_loss: 0.5686302781105042 2022-06-30 20:39:16.374619
start training 2022-06-30 20:39:16.477606
Epoch:[ 9 0 ] loss: 0.5361429452896118 2022-06-30 20:39:31.108521
Epoch:[ 9 1 ] loss: 0.5418103337287903 2022-06-30 20:39:31.523980
Epoch:[ 9 2 ] loss: 0.5358541011810303 2022-06-30 20:39:31.938298
Epoch:[ 9 3 ] loss: 0.5354209542274475 2022-06-30 20:39:32.354530
Epoch:[ 9 4 ] loss: 0.5352584719657898 2022-06-30 20:39:32.769013
Epoch:[ 9 5 ] loss: 0.5317447185516357 2022-06-30 20:39:33.190513
Epoch:[ 9 6 ] loss: 0.5331851243972778 2022-06-30 20:39:33.612968
Epoch:[ 9 7 ] loss: 0.532476007938385 2022-06-30 20:39:34.031158
Epoch:[ 9 8 ] loss: 0.5328845977783203 2022-06-30 20:39:34.458464
Epoch:[ 9 9 ] loss: 0.5291824340820312 2022-06-30 20:39:34.880951
Epoch:[ 9 10 ] loss: 0.5336215496063232 2022-06-30 20:39:35.294129
Epoch:[ 9 11 ] loss: 0.5325089693069458 2022-06-30 20:39:35.709982
Epoch:[ 9 12 ] loss: 0.5293624401092529 2022-06-30 20:39:36.130572
Epoch:[ 9 13 ] loss: 0.5335768461227417 2022-06-30 20:39:36.546969
Epoch:[ 9 14 ] loss: 0.5326939225196838 2022-06-30 20:39:36.969613
Epoch:[ 9 15 ] loss: 0.5306118130683899 2022-06-30 20:39:37.387437
Epoch:[ 9 16 ] loss: 0.5321082472801208 2022-06-30 20:39:42.859774
Epoch:[ 9 17 ] loss: 0.5340889692306519 2022-06-30 20:39:43.274848
Epoch:[ 9 18 ] loss: 0.5310577750205994 2022-06-30 20:39:43.697299
Epoch:[ 9 19 ] loss: 0.5310301780700684 2022-06-30 20:39:44.112430
Training_Epoch:[ 9 ] Training_loss: 0.5332310199737549 2022-06-30 20:39:44.113227
learning rate:  0.005
val: 1 0.5339677333831787
val: 2 0.5431525111198425
val: 3 0.5437835454940796
val: 4 0.5399171113967896
val: 5 0.5366225242614746
val: 6 0.5606662631034851
val: 7 0.5357924699783325
val: 8 0.5462949872016907
val: 9 0.5343521237373352
val: 10 0.5590516924858093
val: 11 0.5550225973129272
val: 12 0.5448128581047058
val: 13 0.5467265248298645
val: 14 0.5645532608032227
val: 15 0.5374522805213928
val: 16 0.5608918070793152
val: 17 0.5544165372848511
val: 18 0.5369388461112976
val: 19 0.5367264151573181
val: 20 0.5402487516403198
val_Epoch:[ 9 ] val_loss: 0.5455695420503617 2022-06-30 20:39:47.499149
start training 2022-06-30 20:39:47.606595
Epoch:[ 10 0 ] loss: 0.5326693058013916 2022-06-30 20:40:01.532476
Epoch:[ 10 1 ] loss: 0.5306788086891174 2022-06-30 20:40:01.947949
Epoch:[ 10 2 ] loss: 0.530678927898407 2022-06-30 20:40:02.363238
Epoch:[ 10 3 ] loss: 0.5282479524612427 2022-06-30 20:40:02.778446
Epoch:[ 10 4 ] loss: 0.5300535559654236 2022-06-30 20:40:03.201372
Epoch:[ 10 5 ] loss: 0.5285478234291077 2022-06-30 20:40:03.614537
Epoch:[ 10 6 ] loss: 0.5293096303939819 2022-06-30 20:40:04.034296
Epoch:[ 10 7 ] loss: 0.5303927063941956 2022-06-30 20:40:04.461260
Epoch:[ 10 8 ] loss: 0.5307875871658325 2022-06-30 20:40:04.878535
Epoch:[ 10 9 ] loss: 0.532875120639801 2022-06-30 20:40:05.293279
Epoch:[ 10 10 ] loss: 0.5311022400856018 2022-06-30 20:40:05.721376
Epoch:[ 10 11 ] loss: 0.5305832028388977 2022-06-30 20:40:06.137180
Epoch:[ 10 12 ] loss: 0.5309510231018066 2022-06-30 20:40:06.551475
Epoch:[ 10 13 ] loss: 0.5302947163581848 2022-06-30 20:40:06.971780
Epoch:[ 10 14 ] loss: 0.5327013731002808 2022-06-30 20:40:07.395241
Epoch:[ 10 15 ] loss: 0.534614622592926 2022-06-30 20:40:07.810470
Epoch:[ 10 16 ] loss: 0.5307165384292603 2022-06-30 20:40:13.663593
Epoch:[ 10 17 ] loss: 0.5333146452903748 2022-06-30 20:40:14.078542
Epoch:[ 10 18 ] loss: 0.5328578352928162 2022-06-30 20:40:14.494227
Epoch:[ 10 19 ] loss: 0.5366740226745605 2022-06-30 20:40:14.910370
Training_Epoch:[ 10 ] Training_loss: 0.5314025819301605 2022-06-30 20:40:14.911117
learning rate:  0.005
netparams have been saved once 10
val: 1 0.6078333258628845
val: 2 0.6116569638252258
val: 3 0.5998744964599609
val: 4 0.6167185306549072
val: 5 0.6291850209236145
val: 6 0.6097966432571411
val: 7 0.6003150939941406
val: 8 0.6059109568595886
val: 9 0.6157230138778687
val: 10 0.6023210287094116
val: 11 0.6118977069854736
val: 12 0.6199063062667847
val: 13 0.6182053685188293
val: 14 0.5932571291923523
val: 15 0.6013619899749756
val: 16 0.5945092439651489
val: 17 0.6275325417518616
val: 18 0.6296890377998352
val: 19 0.6172792315483093
val: 20 0.6064965128898621
val_Epoch:[ 10 ] val_loss: 0.6109735071659088 2022-06-30 20:40:18.349026
start training 2022-06-30 20:40:18.448473
Epoch:[ 11 0 ] loss: 0.5290756225585938 2022-06-30 20:40:32.569339
Epoch:[ 11 1 ] loss: 0.5315557718276978 2022-06-30 20:40:32.995486
Epoch:[ 11 2 ] loss: 0.5329042077064514 2022-06-30 20:40:33.416499
Epoch:[ 11 3 ] loss: 0.5297974944114685 2022-06-30 20:40:33.834178
Epoch:[ 11 4 ] loss: 0.5260552763938904 2022-06-30 20:40:34.248837
Epoch:[ 11 5 ] loss: 0.5262634754180908 2022-06-30 20:40:34.663264
Epoch:[ 11 6 ] loss: 0.5311015844345093 2022-06-30 20:40:35.079997
Epoch:[ 11 7 ] loss: 0.5290847420692444 2022-06-30 20:40:35.496137
Epoch:[ 11 8 ] loss: 0.531075119972229 2022-06-30 20:40:35.929788
Epoch:[ 11 9 ] loss: 0.5266892910003662 2022-06-30 20:40:36.356634
Epoch:[ 11 10 ] loss: 0.5252888202667236 2022-06-30 20:40:36.778846
Epoch:[ 11 11 ] loss: 0.5258417129516602 2022-06-30 20:40:37.203241
Epoch:[ 11 12 ] loss: 0.526573896408081 2022-06-30 20:40:37.626428
Epoch:[ 11 13 ] loss: 0.5269059538841248 2022-06-30 20:40:38.043013
Epoch:[ 11 14 ] loss: 0.5275800228118896 2022-06-30 20:40:38.459911
Epoch:[ 11 15 ] loss: 0.5230347514152527 2022-06-30 20:40:38.883879
Epoch:[ 11 16 ] loss: 0.5322538614273071 2022-06-30 20:40:44.387567
Epoch:[ 11 17 ] loss: 0.5305501818656921 2022-06-30 20:40:44.825103
Epoch:[ 11 18 ] loss: 0.531907856464386 2022-06-30 20:40:45.241963
Epoch:[ 11 19 ] loss: 0.5298542380332947 2022-06-30 20:40:45.660175
Training_Epoch:[ 11 ] Training_loss: 0.5286696940660477 2022-06-30 20:40:45.660955
learning rate:  0.004
val: 1 0.5975705981254578
val: 2 0.5975916385650635
val: 3 0.6009726524353027
val: 4 0.5963340401649475
val: 5 0.6014597415924072
val: 6 0.6109652519226074
val: 7 0.6151808500289917
val: 8 0.6171558499336243
val: 9 0.6095495820045471
val: 10 0.6051135063171387
val: 11 0.606799304485321
val: 12 0.6023336052894592
val: 13 0.5899585485458374
val: 14 0.6042349338531494
val: 15 0.6011155247688293
val: 16 0.6027716994285583
val: 17 0.5958772301673889
val: 18 0.6149119734764099
val: 19 0.6202453970909119
val: 20 0.6074585318565369
val_Epoch:[ 11 ] val_loss: 0.6048800230026246 2022-06-30 20:40:49.089605
start training 2022-06-30 20:40:49.189392
Epoch:[ 12 0 ] loss: 0.525242805480957 2022-06-30 20:41:03.339637
Epoch:[ 12 1 ] loss: 0.5247183442115784 2022-06-30 20:41:03.871889
Epoch:[ 12 2 ] loss: 0.5274956822395325 2022-06-30 20:41:04.288950
Epoch:[ 12 3 ] loss: 0.5265592932701111 2022-06-30 20:41:04.707002
Epoch:[ 12 4 ] loss: 0.5252059698104858 2022-06-30 20:41:05.125717
Epoch:[ 12 5 ] loss: 0.5249324440956116 2022-06-30 20:41:05.541378
Epoch:[ 12 6 ] loss: 0.5266677737236023 2022-06-30 20:41:05.957585
Epoch:[ 12 7 ] loss: 0.5281608700752258 2022-06-30 20:41:06.381337
Epoch:[ 12 8 ] loss: 0.52586430311203 2022-06-30 20:41:06.801777
Epoch:[ 12 9 ] loss: 0.5263538360595703 2022-06-30 20:41:07.220231
Epoch:[ 12 10 ] loss: 0.5264824628829956 2022-06-30 20:41:07.637001
Epoch:[ 12 11 ] loss: 0.5265680551528931 2022-06-30 20:41:08.061391
Epoch:[ 12 12 ] loss: 0.5266690254211426 2022-06-30 20:41:08.483007
Epoch:[ 12 13 ] loss: 0.5303270220756531 2022-06-30 20:41:08.903098
Epoch:[ 12 14 ] loss: 0.5263955593109131 2022-06-30 20:41:09.336176
Epoch:[ 12 15 ] loss: 0.5238160490989685 2022-06-30 20:41:09.758474
Epoch:[ 12 16 ] loss: 0.5239524841308594 2022-06-30 20:41:15.532382
Epoch:[ 12 17 ] loss: 0.5227816700935364 2022-06-30 20:41:15.950816
Epoch:[ 12 18 ] loss: 0.5250853896141052 2022-06-30 20:41:16.369235
Epoch:[ 12 19 ] loss: 0.5250884890556335 2022-06-30 20:41:16.786493
Training_Epoch:[ 12 ] Training_loss: 0.5259183764457702 2022-06-30 20:41:16.787312
learning rate:  0.004
netparams have been saved once 12
val: 1 0.6382237076759338
val: 2 0.6501216888427734
val: 3 0.6245315670967102
val: 4 0.6170350909233093
val: 5 0.64478600025177
val: 6 0.6342319250106812
val: 7 0.6290793418884277
val: 8 0.6497664451599121
val: 9 0.6369907855987549
val: 10 0.6430823802947998
val: 11 0.6351661086082458
val: 12 0.6292749047279358
val: 13 0.6332676410675049
val: 14 0.6419408321380615
val: 15 0.6358759999275208
val: 16 0.6348173022270203
val: 17 0.6290990114212036
val: 18 0.6374477744102478
val: 19 0.6526604890823364
val: 20 0.6406151652336121
val_Epoch:[ 12 ] val_loss: 0.6369007080793381 2022-06-30 20:41:20.226596
start training 2022-06-30 20:41:20.333225
Epoch:[ 13 0 ] loss: 0.521172821521759 2022-06-30 20:41:35.227119
Epoch:[ 13 1 ] loss: 0.5277683138847351 2022-06-30 20:41:35.642296
Epoch:[ 13 2 ] loss: 0.5205757021903992 2022-06-30 20:41:36.066483
Epoch:[ 13 3 ] loss: 0.5234799385070801 2022-06-30 20:41:36.486661
Epoch:[ 13 4 ] loss: 0.5223202109336853 2022-06-30 20:41:36.910877
Epoch:[ 13 5 ] loss: 0.5239236950874329 2022-06-30 20:41:37.333998
Epoch:[ 13 6 ] loss: 0.5239826440811157 2022-06-30 20:41:37.749839
Epoch:[ 13 7 ] loss: 0.5235328078269958 2022-06-30 20:41:38.167532
Epoch:[ 13 8 ] loss: 0.5280394554138184 2022-06-30 20:41:38.581643
Epoch:[ 13 9 ] loss: 0.5236331820487976 2022-06-30 20:41:38.996358
Epoch:[ 13 10 ] loss: 0.5255618691444397 2022-06-30 20:41:39.415132
Epoch:[ 13 11 ] loss: 0.5269229412078857 2022-06-30 20:41:39.833316
Epoch:[ 13 12 ] loss: 0.5295533537864685 2022-06-30 20:41:40.251284
Epoch:[ 13 13 ] loss: 0.5251461267471313 2022-06-30 20:41:40.674343
Epoch:[ 13 14 ] loss: 0.5258594155311584 2022-06-30 20:41:41.111463
Epoch:[ 13 15 ] loss: 0.5222961902618408 2022-06-30 20:41:41.526443
Epoch:[ 13 16 ] loss: 0.5230449438095093 2022-06-30 20:41:47.155782
Epoch:[ 13 17 ] loss: 0.5267649292945862 2022-06-30 20:41:47.572041
Epoch:[ 13 18 ] loss: 0.5227838158607483 2022-06-30 20:41:47.992494
Epoch:[ 13 19 ] loss: 0.520696222782135 2022-06-30 20:41:48.409698
Training_Epoch:[ 13 ] Training_loss: 0.5243529289960861 2022-06-30 20:41:48.410548
learning rate:  0.004
val: 1 0.5359929800033569
val: 2 0.5452505946159363
val: 3 0.549714207649231
val: 4 0.5375246405601501
val: 5 0.5588929057121277
val: 6 0.5399417877197266
val: 7 0.55687016248703
val: 8 0.5413993000984192
val: 9 0.5599008202552795
val: 10 0.5508643388748169
val: 11 0.5579822063446045
val: 12 0.5461265444755554
val: 13 0.5528039336204529
val: 14 0.5617020726203918
val: 15 0.5454287528991699
val: 16 0.5502961277961731
val: 17 0.5447473526000977
val: 18 0.5438514947891235
val: 19 0.555275559425354
val: 20 0.5509581565856934
val_Epoch:[ 13 ] val_loss: 0.5492761969566345 2022-06-30 20:41:51.779613
start training 2022-06-30 20:41:51.884753
Epoch:[ 14 0 ] loss: 0.5228384733200073 2022-06-30 20:42:06.773370
Epoch:[ 14 1 ] loss: 0.5262899994850159 2022-06-30 20:42:07.188926
Epoch:[ 14 2 ] loss: 0.5242261290550232 2022-06-30 20:42:07.635882
Epoch:[ 14 3 ] loss: 0.525603175163269 2022-06-30 20:42:08.120718
Epoch:[ 14 4 ] loss: 0.5256356596946716 2022-06-30 20:42:08.543066
Epoch:[ 14 5 ] loss: 0.526334822177887 2022-06-30 20:42:08.960692
Epoch:[ 14 6 ] loss: 0.5228328108787537 2022-06-30 20:42:09.383620
Epoch:[ 14 7 ] loss: 0.5249778032302856 2022-06-30 20:42:09.802110
Epoch:[ 14 8 ] loss: 0.5245049595832825 2022-06-30 20:42:10.224891
Epoch:[ 14 9 ] loss: 0.5249497294425964 2022-06-30 20:42:10.642259
Epoch:[ 14 10 ] loss: 0.523628830909729 2022-06-30 20:42:11.058472
Epoch:[ 14 11 ] loss: 0.5238461494445801 2022-06-30 20:42:11.476723
Epoch:[ 14 12 ] loss: 0.5220209956169128 2022-06-30 20:42:11.899846
Epoch:[ 14 13 ] loss: 0.5234749913215637 2022-06-30 20:42:12.317055
Epoch:[ 14 14 ] loss: 0.5219840407371521 2022-06-30 20:42:12.740135
Epoch:[ 14 15 ] loss: 0.5254173278808594 2022-06-30 20:42:13.160139
Epoch:[ 14 16 ] loss: 0.5206069946289062 2022-06-30 20:42:17.925847
Epoch:[ 14 17 ] loss: 0.5211762189865112 2022-06-30 20:42:18.338820
Epoch:[ 14 18 ] loss: 0.5201508402824402 2022-06-30 20:42:18.761822
Epoch:[ 14 19 ] loss: 0.5194323658943176 2022-06-30 20:42:19.177977
Training_Epoch:[ 14 ] Training_loss: 0.5234966158866883 2022-06-30 20:42:19.178683
learning rate:  0.004
netparams have been saved once 14
val: 1 0.5608182549476624
val: 2 0.5525510907173157
val: 3 0.5497034788131714
val: 4 0.5455529689788818
val: 5 0.5518084764480591
val: 6 0.5586451292037964
val: 7 0.5625532269477844
val: 8 0.5430562496185303
val: 9 0.5495761632919312
val: 10 0.554286539554596
val: 11 0.5625232458114624
val: 12 0.5492700934410095
val: 13 0.547438383102417
val: 14 0.5575798153877258
val: 15 0.5700601935386658
val: 16 0.5623447895050049
val: 17 0.5617043972015381
val: 18 0.5568729639053345
val: 19 0.555544376373291
val: 20 0.5615444779396057
val_Epoch:[ 14 ] val_loss: 0.5556717157363892 2022-06-30 20:42:22.552315
start training 2022-06-30 20:42:22.656677
Epoch:[ 15 0 ] loss: 0.5154974460601807 2022-06-30 20:42:36.599972
Epoch:[ 15 1 ] loss: 0.5173323750495911 2022-06-30 20:42:37.050730
Epoch:[ 15 2 ] loss: 0.5179455280303955 2022-06-30 20:42:37.464898
Epoch:[ 15 3 ] loss: 0.5202713012695312 2022-06-30 20:42:37.878681
Epoch:[ 15 4 ] loss: 0.5245320200920105 2022-06-30 20:42:38.298412
Epoch:[ 15 5 ] loss: 0.5185557007789612 2022-06-30 20:42:38.715727
Epoch:[ 15 6 ] loss: 0.5211233496665955 2022-06-30 20:42:39.131655
Epoch:[ 15 7 ] loss: 0.5224288105964661 2022-06-30 20:42:39.592299
Epoch:[ 15 8 ] loss: 0.5230939984321594 2022-06-30 20:42:40.076718
Epoch:[ 15 9 ] loss: 0.5233380794525146 2022-06-30 20:42:40.491557
Epoch:[ 15 10 ] loss: 0.5210649371147156 2022-06-30 20:42:40.903957
Epoch:[ 15 11 ] loss: 0.5205405354499817 2022-06-30 20:42:41.318839
Epoch:[ 15 12 ] loss: 0.5188969969749451 2022-06-30 20:42:41.734184
Epoch:[ 15 13 ] loss: 0.5223448872566223 2022-06-30 20:42:42.156829
Epoch:[ 15 14 ] loss: 0.5231881737709045 2022-06-30 20:42:42.572953
Epoch:[ 15 15 ] loss: 0.5234391689300537 2022-06-30 20:42:42.987729
Epoch:[ 15 16 ] loss: 0.520783007144928 2022-06-30 20:42:49.146129
Epoch:[ 15 17 ] loss: 0.5217521786689758 2022-06-30 20:42:49.559636
Epoch:[ 15 18 ] loss: 0.5193910002708435 2022-06-30 20:42:49.975319
Epoch:[ 15 19 ] loss: 0.5181905031204224 2022-06-30 20:42:50.391750
Training_Epoch:[ 15 ] Training_loss: 0.5206854999065399 2022-06-30 20:42:50.392537
learning rate:  0.004
val: 1 0.5994914174079895
val: 2 0.5735135078430176
val: 3 0.5818478465080261
val: 4 0.5846284031867981
val: 5 0.5929581522941589
val: 6 0.5824262499809265
val: 7 0.5963723659515381
val: 8 0.5954846143722534
val: 9 0.5890563130378723
val: 10 0.5838924050331116
val: 11 0.5869014859199524
val: 12 0.5882257223129272
val: 13 0.585562527179718
val: 14 0.5810598731040955
val: 15 0.5835966467857361
val: 16 0.5720014572143555
val: 17 0.5783202648162842
val: 18 0.5974109172821045
val: 19 0.5851112008094788
val: 20 0.5725997090339661
val_Epoch:[ 15 ] val_loss: 0.5855230540037155 2022-06-30 20:42:53.847537
start training 2022-06-30 20:42:53.951593
Epoch:[ 16 0 ] loss: 0.5207836031913757 2022-06-30 20:43:07.577282
Epoch:[ 16 1 ] loss: 0.5196905732154846 2022-06-30 20:43:08.205196
Epoch:[ 16 2 ] loss: 0.520149290561676 2022-06-30 20:43:08.621344
Epoch:[ 16 3 ] loss: 0.5159255862236023 2022-06-30 20:43:09.041186
Epoch:[ 16 4 ] loss: 0.5133839249610901 2022-06-30 20:43:09.454436
Epoch:[ 16 5 ] loss: 0.5183544158935547 2022-06-30 20:43:09.866770
Epoch:[ 16 6 ] loss: 0.5161406993865967 2022-06-30 20:43:10.290578
Epoch:[ 16 7 ] loss: 0.5133808255195618 2022-06-30 20:43:10.774162
Epoch:[ 16 8 ] loss: 0.5198733806610107 2022-06-30 20:43:11.194861
Epoch:[ 16 9 ] loss: 0.5193701386451721 2022-06-30 20:43:11.615454
Epoch:[ 16 10 ] loss: 0.5183159112930298 2022-06-30 20:43:12.030866
Epoch:[ 16 11 ] loss: 0.5200554728507996 2022-06-30 20:43:12.445974
Epoch:[ 16 12 ] loss: 0.51792311668396 2022-06-30 20:43:12.860200
Epoch:[ 16 13 ] loss: 0.5175560116767883 2022-06-30 20:43:13.281921
Epoch:[ 16 14 ] loss: 0.5117247700691223 2022-06-30 20:43:13.697291
Epoch:[ 16 15 ] loss: 0.5152955055236816 2022-06-30 20:43:14.114135
Epoch:[ 16 16 ] loss: 0.5182814002037048 2022-06-30 20:43:19.386034
Epoch:[ 16 17 ] loss: 0.5116633772850037 2022-06-30 20:43:19.968862
Epoch:[ 16 18 ] loss: 0.5162616968154907 2022-06-30 20:43:20.384163
Epoch:[ 16 19 ] loss: 0.5181657671928406 2022-06-30 20:43:20.797629
Training_Epoch:[ 16 ] Training_loss: 0.5171147733926773 2022-06-30 20:43:20.798388
learning rate:  0.004
netparams have been saved once 16
val: 1 0.5980238914489746
val: 2 0.5808572173118591
val: 3 0.5994746088981628
val: 4 0.5881083607673645
val: 5 0.6079902052879333
val: 6 0.591252863407135
val: 7 0.5914716720581055
val: 8 0.6095720529556274
val: 9 0.5964180827140808
val: 10 0.5929495692253113
val: 11 0.5929490327835083
val: 12 0.6014754176139832
val: 13 0.603897213935852
val: 14 0.5896912813186646
val: 15 0.601229727268219
val: 16 0.5884008407592773
val: 17 0.5988004207611084
val: 18 0.584929347038269
val: 19 0.5899498462677002
val: 20 0.590559720993042
val_Epoch:[ 16 ] val_loss: 0.5949000686407089 2022-06-30 20:43:24.303936
start training 2022-06-30 20:43:24.411442
Epoch:[ 17 0 ] loss: 0.5187036395072937 2022-06-30 20:43:38.254326
Epoch:[ 17 1 ] loss: 0.5215682983398438 2022-06-30 20:43:38.697679
Epoch:[ 17 2 ] loss: 0.5191645622253418 2022-06-30 20:43:39.111093
Epoch:[ 17 3 ] loss: 0.5196307897567749 2022-06-30 20:43:39.527019
Epoch:[ 17 4 ] loss: 0.5212615728378296 2022-06-30 20:43:39.949941
Epoch:[ 17 5 ] loss: 0.5222292542457581 2022-06-30 20:43:40.363227
Epoch:[ 17 6 ] loss: 0.5233493447303772 2022-06-30 20:43:40.783865
Epoch:[ 17 7 ] loss: 0.5258280038833618 2022-06-30 20:43:41.203269
Epoch:[ 17 8 ] loss: 0.5314911603927612 2022-06-30 20:43:41.695408
Epoch:[ 17 9 ] loss: 0.5238842964172363 2022-06-30 20:43:42.112802
Epoch:[ 17 10 ] loss: 0.5218920111656189 2022-06-30 20:43:42.526624
Epoch:[ 17 11 ] loss: 0.5261797308921814 2022-06-30 20:43:42.944047
Epoch:[ 17 12 ] loss: 0.5267708897590637 2022-06-30 20:43:43.360259
Epoch:[ 17 13 ] loss: 0.5251135230064392 2022-06-30 20:43:43.782145
Epoch:[ 17 14 ] loss: 0.5209794044494629 2022-06-30 20:43:44.199388
Epoch:[ 17 15 ] loss: 0.5209997892379761 2022-06-30 20:43:44.623434
Epoch:[ 17 16 ] loss: 0.5268876552581787 2022-06-30 20:43:50.144254
Epoch:[ 17 17 ] loss: 0.5201709270477295 2022-06-30 20:43:50.559528
Epoch:[ 17 18 ] loss: 0.5148001909255981 2022-06-30 20:43:50.976073
Epoch:[ 17 19 ] loss: 0.5223857164382935 2022-06-30 20:43:51.389920
Training_Epoch:[ 17 ] Training_loss: 0.522664538025856 2022-06-30 20:43:51.390582
learning rate:  0.004
val: 1 0.6243383288383484
val: 2 0.6333532929420471
val: 3 0.6313812136650085
val: 4 0.6144739985466003
val: 5 0.6163180470466614
val: 6 0.6094297170639038
val: 7 0.6251465082168579
val: 8 0.6287845373153687
val: 9 0.6190477013587952
val: 10 0.6281394362449646
val: 11 0.6351483464241028
val: 12 0.6352890133857727
val: 13 0.6272009611129761
val: 14 0.630711555480957
val: 15 0.6071175932884216
val: 16 0.6364893317222595
val: 17 0.6345693469047546
val: 18 0.6236439943313599
val: 19 0.6284000277519226
val: 20 0.6304159760475159
val_Epoch:[ 17 ] val_loss: 0.6259699463844299 2022-06-30 20:43:54.757925
start training 2022-06-30 20:43:54.861992
Epoch:[ 18 0 ] loss: 0.5211151242256165 2022-06-30 20:44:09.454804
Epoch:[ 18 1 ] loss: 0.5217708945274353 2022-06-30 20:44:09.876910
Epoch:[ 18 2 ] loss: 0.52426677942276 2022-06-30 20:44:10.298998
Epoch:[ 18 3 ] loss: 0.522794246673584 2022-06-30 20:44:10.716902
Epoch:[ 18 4 ] loss: 0.5198022127151489 2022-06-30 20:44:11.137215
Epoch:[ 18 5 ] loss: 0.5176903605461121 2022-06-30 20:44:11.573630
Epoch:[ 18 6 ] loss: 0.5230790376663208 2022-06-30 20:44:12.055351
Epoch:[ 18 7 ] loss: 0.5262015461921692 2022-06-30 20:44:12.476897
Epoch:[ 18 8 ] loss: 0.5146615505218506 2022-06-30 20:44:12.899908
Epoch:[ 18 9 ] loss: 0.5170885324478149 2022-06-30 20:44:13.316499
Epoch:[ 18 10 ] loss: 0.5192777514457703 2022-06-30 20:44:13.732336
Epoch:[ 18 11 ] loss: 0.516834557056427 2022-06-30 20:44:14.146915
Epoch:[ 18 12 ] loss: 0.5159280300140381 2022-06-30 20:44:14.562139
Epoch:[ 18 13 ] loss: 0.5170155763626099 2022-06-30 20:44:14.977999
Epoch:[ 18 14 ] loss: 0.5114029049873352 2022-06-30 20:44:15.391187
Epoch:[ 18 15 ] loss: 0.5120552778244019 2022-06-30 20:44:15.808635
Epoch:[ 18 16 ] loss: 0.5125970244407654 2022-06-30 20:44:21.382273
Epoch:[ 18 17 ] loss: 0.516998291015625 2022-06-30 20:44:21.798584
Epoch:[ 18 18 ] loss: 0.5136798024177551 2022-06-30 20:44:22.213702
Epoch:[ 18 19 ] loss: 0.516919732093811 2022-06-30 20:44:22.630168
Training_Epoch:[ 18 ] Training_loss: 0.5180589616298675 2022-06-30 20:44:22.630885
learning rate:  0.004
netparams have been saved once 18
val: 1 0.521651566028595
val: 2 0.5281296968460083
val: 3 0.5360676050186157
val: 4 0.5255439877510071
val: 5 0.5244413018226624
val: 6 0.5278787016868591
val: 7 0.5304505825042725
val: 8 0.5249872803688049
val: 9 0.54180508852005
val: 10 0.5329675674438477
val: 11 0.5257575511932373
val: 12 0.5162572264671326
val: 13 0.5346348881721497
val: 14 0.5297132730484009
val: 15 0.5168545842170715
val: 16 0.5281528830528259
val: 17 0.5246752500534058
val: 18 0.5216970443725586
val: 19 0.5200291872024536
val: 20 0.5263643860816956
val_Epoch:[ 18 ] val_loss: 0.5269029825925827 2022-06-30 20:44:26.008755
start training 2022-06-30 20:44:26.112535
Epoch:[ 19 0 ] loss: 0.5146869421005249 2022-06-30 20:44:40.043007
Epoch:[ 19 1 ] loss: 0.5152106285095215 2022-06-30 20:44:40.456132
Epoch:[ 19 2 ] loss: 0.5160852670669556 2022-06-30 20:44:40.877824
Epoch:[ 19 3 ] loss: 0.5171851515769958 2022-06-30 20:44:41.294520
Epoch:[ 19 4 ] loss: 0.5151466131210327 2022-06-30 20:44:41.715983
Epoch:[ 19 5 ] loss: 0.517079770565033 2022-06-30 20:44:42.131493
Epoch:[ 19 6 ] loss: 0.5115630626678467 2022-06-30 20:44:42.584087
Epoch:[ 19 7 ] loss: 0.5146204233169556 2022-06-30 20:44:43.054139
Epoch:[ 19 8 ] loss: 0.5123459100723267 2022-06-30 20:44:43.467731
Epoch:[ 19 9 ] loss: 0.5079852938652039 2022-06-30 20:44:43.884014
Epoch:[ 19 10 ] loss: 0.5159111618995667 2022-06-30 20:44:44.298708
Epoch:[ 19 11 ] loss: 0.5099879503250122 2022-06-30 20:44:44.721975
Epoch:[ 19 12 ] loss: 0.5124493837356567 2022-06-30 20:44:45.141871
Epoch:[ 19 13 ] loss: 0.5106461644172668 2022-06-30 20:44:45.557502
Epoch:[ 19 14 ] loss: 0.5092009902000427 2022-06-30 20:44:45.976757
Epoch:[ 19 15 ] loss: 0.5111382007598877 2022-06-30 20:44:46.399579
Epoch:[ 19 16 ] loss: 0.5070945024490356 2022-06-30 20:44:51.751034
Epoch:[ 19 17 ] loss: 0.5136818289756775 2022-06-30 20:44:52.167769
Epoch:[ 19 18 ] loss: 0.5084535479545593 2022-06-30 20:44:52.655621
Epoch:[ 19 19 ] loss: 0.5087557435035706 2022-06-30 20:44:53.070877
Training_Epoch:[ 19 ] Training_loss: 0.5124614268541337 2022-06-30 20:44:53.071613
learning rate:  0.004
val: 1 0.5278260707855225
val: 2 0.5311524271965027
val: 3 0.5202943682670593
val: 4 0.5234039425849915
val: 5 0.5230440497398376
val: 6 0.5134815573692322
val: 7 0.5261424779891968
val: 8 0.5213133096694946
val: 9 0.5213328003883362
val: 10 0.5260999202728271
val: 11 0.517909049987793
val: 12 0.5233678817749023
val: 13 0.5231245756149292
val: 14 0.5218571424484253
val: 15 0.5361362099647522
val: 16 0.5195989012718201
val: 17 0.5398825407028198
val: 18 0.5206549763679504
val: 19 0.5245905518531799
val: 20 0.5210478901863098
val_Epoch:[ 19 ] val_loss: 0.5241130322217942 2022-06-30 20:44:56.465517
start training 2022-06-30 20:44:56.570290
Epoch:[ 20 0 ] loss: 0.5094919204711914 2022-06-30 20:45:10.187652
Epoch:[ 20 1 ] loss: 0.5067643523216248 2022-06-30 20:45:10.606297
Epoch:[ 20 2 ] loss: 0.503608763217926 2022-06-30 20:45:11.027623
Epoch:[ 20 3 ] loss: 0.5047129392623901 2022-06-30 20:45:11.450646
Epoch:[ 20 4 ] loss: 0.5066604614257812 2022-06-30 20:45:11.866923
Epoch:[ 20 5 ] loss: 0.5055429339408875 2022-06-30 20:45:12.288681
Epoch:[ 20 6 ] loss: 0.5062339901924133 2022-06-30 20:45:12.702227
Epoch:[ 20 7 ] loss: 0.5065832138061523 2022-06-30 20:45:13.122564
Epoch:[ 20 8 ] loss: 0.5060155987739563 2022-06-30 20:45:13.604611
Epoch:[ 20 9 ] loss: 0.5088874697685242 2022-06-30 20:45:14.018408
Epoch:[ 20 10 ] loss: 0.5081026554107666 2022-06-30 20:45:14.441033
Epoch:[ 20 11 ] loss: 0.5074014663696289 2022-06-30 20:45:14.856844
Epoch:[ 20 12 ] loss: 0.5075740218162537 2022-06-30 20:45:15.271246
Epoch:[ 20 13 ] loss: 0.5048220157623291 2022-06-30 20:45:15.691842
Epoch:[ 20 14 ] loss: 0.5021712779998779 2022-06-30 20:45:16.106136
Epoch:[ 20 15 ] loss: 0.5047166347503662 2022-06-30 20:45:16.519782
Epoch:[ 20 16 ] loss: 0.5035025477409363 2022-06-30 20:45:22.003568
Epoch:[ 20 17 ] loss: 0.5033182501792908 2022-06-30 20:45:22.419971
Epoch:[ 20 18 ] loss: 0.502383291721344 2022-06-30 20:45:22.835320
Epoch:[ 20 19 ] loss: 0.5100284814834595 2022-06-30 20:45:23.431115
Training_Epoch:[ 20 ] Training_loss: 0.505926114320755 2022-06-30 20:45:23.431697
learning rate:  0.004
netparams have been saved once 20
val: 1 0.5829269886016846
val: 2 0.5825241208076477
val: 3 0.582847535610199
val: 4 0.5672162771224976
val: 5 0.5886791944503784
val: 6 0.5865926742553711
val: 7 0.5831194519996643
val: 8 0.5664226412773132
val: 9 0.5863433480262756
val: 10 0.5849196314811707
val: 11 0.571351170539856
val: 12 0.5929684042930603
val: 13 0.5726596713066101
val: 14 0.5690334439277649
val: 15 0.5808413028717041
val: 16 0.5904247164726257
val: 17 0.5758504271507263
val: 18 0.582277774810791
val: 19 0.5812941193580627
val: 20 0.5802937150001526
val_Epoch:[ 20 ] val_loss: 0.5804293304681778 2022-06-30 20:45:26.800318
start training 2022-06-30 20:45:26.910198
Epoch:[ 21 0 ] loss: 0.510256826877594 2022-06-30 20:45:41.288138
Epoch:[ 21 1 ] loss: 0.5090147256851196 2022-06-30 20:45:41.708986
Epoch:[ 21 2 ] loss: 0.5143786668777466 2022-06-30 20:45:42.122148
Epoch:[ 21 3 ] loss: 0.5168217420578003 2022-06-30 20:45:42.537093
Epoch:[ 21 4 ] loss: 0.5084202289581299 2022-06-30 20:45:42.953263
Epoch:[ 21 5 ] loss: 0.5084418058395386 2022-06-30 20:45:43.370608
Epoch:[ 21 6 ] loss: 0.5126494765281677 2022-06-30 20:45:43.822657
Epoch:[ 21 7 ] loss: 0.5087676644325256 2022-06-30 20:45:44.307978
Epoch:[ 21 8 ] loss: 0.5091416835784912 2022-06-30 20:45:44.730244
Epoch:[ 21 9 ] loss: 0.509421169757843 2022-06-30 20:45:45.143175
Epoch:[ 21 10 ] loss: 0.5054807066917419 2022-06-30 20:45:45.563855
Epoch:[ 21 11 ] loss: 0.5053606033325195 2022-06-30 20:45:45.980127
Epoch:[ 21 12 ] loss: 0.502201497554779 2022-06-30 20:45:46.402420
Epoch:[ 21 13 ] loss: 0.508762001991272 2022-06-30 20:45:46.818607
Epoch:[ 21 14 ] loss: 0.5089136362075806 2022-06-30 20:45:47.232680
Epoch:[ 21 15 ] loss: 0.5051257014274597 2022-06-30 20:45:47.648320
Epoch:[ 21 16 ] loss: 0.5051038861274719 2022-06-30 20:45:53.136049
Epoch:[ 21 17 ] loss: 0.5056820511817932 2022-06-30 20:45:53.550024
Epoch:[ 21 18 ] loss: 0.5003542900085449 2022-06-30 20:45:53.967673
Epoch:[ 21 19 ] loss: 0.5084747672080994 2022-06-30 20:45:54.383276
Training_Epoch:[ 21 ] Training_loss: 0.5081386566162109 2022-06-30 20:45:54.383921
learning rate:  0.0032
val: 1 0.5064157247543335
val: 2 0.5069031119346619
val: 3 0.5263672471046448
val: 4 0.5114481449127197
val: 5 0.5142539739608765
val: 6 0.5103570222854614
val: 7 0.5061415433883667
val: 8 0.5111422538757324
val: 9 0.5070134997367859
val: 10 0.5073431730270386
val: 11 0.5006721615791321
val: 12 0.5124802589416504
val: 13 0.5152509808540344
val: 14 0.5143361687660217
val: 15 0.5015000700950623
val: 16 0.5156760811805725
val: 17 0.5042325854301453
val: 18 0.5015135407447815
val: 19 0.5164378881454468
val: 20 0.5159851908683777
val_Epoch:[ 21 ] val_loss: 0.5102735310792923 2022-06-30 20:45:57.811507
start training 2022-06-30 20:45:57.917195
Epoch:[ 22 0 ] loss: 0.49913743138313293 2022-06-30 20:46:12.054086
Epoch:[ 22 1 ] loss: 0.505407989025116 2022-06-30 20:46:12.474944
Epoch:[ 22 2 ] loss: 0.5012023448944092 2022-06-30 20:46:12.889116
Epoch:[ 22 3 ] loss: 0.5008552670478821 2022-06-30 20:46:13.308209
Epoch:[ 22 4 ] loss: 0.5013781785964966 2022-06-30 20:46:13.786592
Epoch:[ 22 5 ] loss: 0.5010973811149597 2022-06-30 20:46:14.203314
Epoch:[ 22 6 ] loss: 0.503749430179596 2022-06-30 20:46:14.625720
Epoch:[ 22 7 ] loss: 0.5029705762863159 2022-06-30 20:46:15.049200
Epoch:[ 22 8 ] loss: 0.5010080933570862 2022-06-30 20:46:15.463860
Epoch:[ 22 9 ] loss: 0.49838560819625854 2022-06-30 20:46:15.885959
Epoch:[ 22 10 ] loss: 0.49952831864356995 2022-06-30 20:46:16.307650
Epoch:[ 22 11 ] loss: 0.5015806555747986 2022-06-30 20:46:16.722171
Epoch:[ 22 12 ] loss: 0.49563395977020264 2022-06-30 20:46:17.139218
Epoch:[ 22 13 ] loss: 0.4997815191745758 2022-06-30 20:46:17.556131
Epoch:[ 22 14 ] loss: 0.49408456683158875 2022-06-30 20:46:17.970986
Epoch:[ 22 15 ] loss: 0.49993687868118286 2022-06-30 20:46:18.393377
Epoch:[ 22 16 ] loss: 0.500970721244812 2022-06-30 20:46:24.032419
Epoch:[ 22 17 ] loss: 0.49733319878578186 2022-06-30 20:46:24.446459
Epoch:[ 22 18 ] loss: 0.49525269865989685 2022-06-30 20:46:24.868762
Epoch:[ 22 19 ] loss: 0.4970015287399292 2022-06-30 20:46:25.285786
Training_Epoch:[ 22 ] Training_loss: 0.4998148173093796 2022-06-30 20:46:25.286449
learning rate:  0.0032
netparams have been saved once 22
val: 1 0.5001518130302429
val: 2 0.5089550018310547
val: 3 0.5016535520553589
val: 4 0.5104042887687683
val: 5 0.5084521770477295
val: 6 0.5100059509277344
val: 7 0.5065886378288269
val: 8 0.5015437006950378
val: 9 0.4939614236354828
val: 10 0.505149245262146
val: 11 0.5072567462921143
val: 12 0.5041621923446655
val: 13 0.4959690272808075
val: 14 0.5015717148780823
val: 15 0.5056028366088867
val: 16 0.5008196830749512
val: 17 0.5186150074005127
val: 18 0.4973200559616089
val: 19 0.49423837661743164
val: 20 0.49457788467407227
val_Epoch:[ 22 ] val_loss: 0.5033499658107757 2022-06-30 20:46:28.659693
start training 2022-06-30 20:46:28.762090
Epoch:[ 23 0 ] loss: 0.49586763978004456 2022-06-30 20:46:43.160808
Epoch:[ 23 1 ] loss: 0.4971729815006256 2022-06-30 20:46:43.633211
Epoch:[ 23 2 ] loss: 0.4978603422641754 2022-06-30 20:46:44.053526
Epoch:[ 23 3 ] loss: 0.49509334564208984 2022-06-30 20:46:44.470488
Epoch:[ 23 4 ] loss: 0.4952065646648407 2022-06-30 20:46:44.884854
Epoch:[ 23 5 ] loss: 0.4946039319038391 2022-06-30 20:46:45.298788
Epoch:[ 23 6 ] loss: 0.5003147125244141 2022-06-30 20:46:45.719799
Epoch:[ 23 7 ] loss: 0.49356529116630554 2022-06-30 20:46:46.136179
Epoch:[ 23 8 ] loss: 0.49089372158050537 2022-06-30 20:46:46.551615
Epoch:[ 23 9 ] loss: 0.4942867159843445 2022-06-30 20:46:46.968390
Epoch:[ 23 10 ] loss: 0.49079838395118713 2022-06-30 20:46:47.382441
Epoch:[ 23 11 ] loss: 0.49686697125434875 2022-06-30 20:46:47.797561
Epoch:[ 23 12 ] loss: 0.49682191014289856 2022-06-30 20:46:48.211271
Epoch:[ 23 13 ] loss: 0.49248552322387695 2022-06-30 20:46:48.628087
Epoch:[ 23 14 ] loss: 0.49544447660446167 2022-06-30 20:46:49.050251
Epoch:[ 23 15 ] loss: 0.49374741315841675 2022-06-30 20:46:49.487749
Epoch:[ 23 16 ] loss: 0.49304765462875366 2022-06-30 20:46:54.749821
Epoch:[ 23 17 ] loss: 0.4924180507659912 2022-06-30 20:46:55.165013
Epoch:[ 23 18 ] loss: 0.49091318249702454 2022-06-30 20:46:55.584769
Epoch:[ 23 19 ] loss: 0.4940296709537506 2022-06-30 20:46:55.999036
Training_Epoch:[ 23 ] Training_loss: 0.4945719242095947 2022-06-30 20:46:55.999737
learning rate:  0.0032
val: 1 0.5213387608528137
val: 2 0.5062235593795776
val: 3 0.49879106879234314
val: 4 0.5132424235343933
val: 5 0.5103982090950012
val: 6 0.5111827254295349
val: 7 0.5017277598381042
val: 8 0.5086398720741272
val: 9 0.5059686303138733
val: 10 0.5088563561439514
val: 11 0.5105557441711426
val: 12 0.4906919598579407
val: 13 0.5334020853042603
val: 14 0.5083187222480774
val: 15 0.5103851556777954
val: 16 0.5152339935302734
val: 17 0.4905058443546295
val: 18 0.516544759273529
val: 19 0.5095319747924805
val: 20 0.49637338519096375
val_Epoch:[ 23 ] val_loss: 0.5083956494927406 2022-06-30 20:46:59.446120
start training 2022-06-30 20:46:59.547316
Epoch:[ 24 0 ] loss: 0.4934452474117279 2022-06-30 20:47:13.370647
Epoch:[ 24 1 ] loss: 0.49088162183761597 2022-06-30 20:47:13.969649
Epoch:[ 24 2 ] loss: 0.49313023686408997 2022-06-30 20:47:14.458755
Epoch:[ 24 3 ] loss: 0.4902021884918213 2022-06-30 20:47:14.873563
Epoch:[ 24 4 ] loss: 0.49189677834510803 2022-06-30 20:47:15.288921
Epoch:[ 24 5 ] loss: 0.490924209356308 2022-06-30 20:47:15.709832
Epoch:[ 24 6 ] loss: 0.4903119206428528 2022-06-30 20:47:16.123945
Epoch:[ 24 7 ] loss: 0.4891766309738159 2022-06-30 20:47:16.547050
Epoch:[ 24 8 ] loss: 0.49142971634864807 2022-06-30 20:47:16.964233
Epoch:[ 24 9 ] loss: 0.4919494092464447 2022-06-30 20:47:17.380356
Epoch:[ 24 10 ] loss: 0.4945818781852722 2022-06-30 20:47:17.793999
Epoch:[ 24 11 ] loss: 0.48837482929229736 2022-06-30 20:47:18.209994
Epoch:[ 24 12 ] loss: 0.48684579133987427 2022-06-30 20:47:18.626413
Epoch:[ 24 13 ] loss: 0.48867595195770264 2022-06-30 20:47:19.041028
Epoch:[ 24 14 ] loss: 0.489918977022171 2022-06-30 20:47:19.464426
Epoch:[ 24 15 ] loss: 0.48846039175987244 2022-06-30 20:47:19.880390
Epoch:[ 24 16 ] loss: 0.4920836389064789 2022-06-30 20:47:25.144402
Epoch:[ 24 17 ] loss: 0.4898921847343445 2022-06-30 20:47:25.560029
Epoch:[ 24 18 ] loss: 0.4905395209789276 2022-06-30 20:47:25.974694
Epoch:[ 24 19 ] loss: 0.4899177551269531 2022-06-30 20:47:26.392078
Training_Epoch:[ 24 ] Training_loss: 0.4906319439411163 2022-06-30 20:47:26.392822
learning rate:  0.0032
netparams have been saved once 24
val: 1 0.49685773253440857
val: 2 0.49186620116233826
val: 3 0.5057859420776367
val: 4 0.4932807683944702
val: 5 0.4903697967529297
val: 6 0.49188515543937683
val: 7 0.5018704533576965
val: 8 0.49591848254203796
val: 9 0.5059175491333008
val: 10 0.49195238947868347
val: 11 0.49689561128616333
val: 12 0.491258829832077
val: 13 0.5022759437561035
val: 14 0.49450233578681946
val: 15 0.49080902338027954
val: 16 0.48962143063545227
val: 17 0.49234750866889954
val: 18 0.49374932050704956
val: 19 0.4871072471141815
val: 20 0.4991362690925598
val_Epoch:[ 24 ] val_loss: 0.49517039954662323 2022-06-30 20:47:29.815016
start training 2022-06-30 20:47:29.917341
Epoch:[ 25 0 ] loss: 0.4934636652469635 2022-06-30 20:47:43.552016
Epoch:[ 25 1 ] loss: 0.4879263937473297 2022-06-30 20:47:44.018658
Epoch:[ 25 2 ] loss: 0.4908903241157532 2022-06-30 20:47:44.501524
Epoch:[ 25 3 ] loss: 0.48889634013175964 2022-06-30 20:47:44.922460
Epoch:[ 25 4 ] loss: 0.4861671030521393 2022-06-30 20:47:45.337887
Epoch:[ 25 5 ] loss: 0.485318124294281 2022-06-30 20:47:45.759365
Epoch:[ 25 6 ] loss: 0.48381364345550537 2022-06-30 20:47:46.174206
Epoch:[ 25 7 ] loss: 0.4892314076423645 2022-06-30 20:47:46.589936
Epoch:[ 25 8 ] loss: 0.4832620918750763 2022-06-30 20:47:47.021620
Epoch:[ 25 9 ] loss: 0.4835338890552521 2022-06-30 20:47:47.454613
Epoch:[ 25 10 ] loss: 0.4857831299304962 2022-06-30 20:47:47.880114
Epoch:[ 25 11 ] loss: 0.4873638153076172 2022-06-30 20:47:48.306562
Epoch:[ 25 12 ] loss: 0.4908648729324341 2022-06-30 20:47:48.739001
Epoch:[ 25 13 ] loss: 0.4845486879348755 2022-06-30 20:47:49.172456
Epoch:[ 25 14 ] loss: 0.48637378215789795 2022-06-30 20:47:49.596084
Epoch:[ 25 15 ] loss: 0.48906317353248596 2022-06-30 20:47:50.023903
Epoch:[ 25 16 ] loss: 0.4882720708847046 2022-06-30 20:47:55.349181
Epoch:[ 25 17 ] loss: 0.48385030031204224 2022-06-30 20:47:55.763701
Epoch:[ 25 18 ] loss: 0.4898820221424103 2022-06-30 20:47:56.185760
Epoch:[ 25 19 ] loss: 0.49459850788116455 2022-06-30 20:47:56.600983
Training_Epoch:[ 25 ] Training_loss: 0.48765516728162767 2022-06-30 20:47:56.601665
learning rate:  0.0032
val: 1 0.490423321723938
val: 2 0.4945981204509735
val: 3 0.48715755343437195
val: 4 0.5011529326438904
val: 5 0.4958111643791199
val: 6 0.489118367433548
val: 7 0.5004147291183472
val: 8 0.4826775789260864
val: 9 0.4919945299625397
val: 10 0.5014506578445435
val: 11 0.49030885100364685
val: 12 0.48760220408439636
val: 13 0.4919501543045044
val: 14 0.48534876108169556
val: 15 0.492837131023407
val: 16 0.4875636696815491
val: 17 0.4864252209663391
val: 18 0.5030596256256104
val: 19 0.5013595819473267
val: 20 0.49021098017692566
val_Epoch:[ 25 ] val_loss: 0.49257325679063796 2022-06-30 20:48:00.006416
start training 2022-06-30 20:48:00.111512
Epoch:[ 26 0 ] loss: 0.48333829641342163 2022-06-30 20:48:14.911771
Epoch:[ 26 1 ] loss: 0.4898450970649719 2022-06-30 20:48:15.331495
Epoch:[ 26 2 ] loss: 0.4847620129585266 2022-06-30 20:48:15.746706
Epoch:[ 26 3 ] loss: 0.48558953404426575 2022-06-30 20:48:16.169108
Epoch:[ 26 4 ] loss: 0.48389938473701477 2022-06-30 20:48:16.586561
Epoch:[ 26 5 ] loss: 0.484561026096344 2022-06-30 20:48:17.000957
Epoch:[ 26 6 ] loss: 0.48737725615501404 2022-06-30 20:48:17.416160
Epoch:[ 26 7 ] loss: 0.48564931750297546 2022-06-30 20:48:17.837461
Epoch:[ 26 8 ] loss: 0.4885496199131012 2022-06-30 20:48:18.251178
Epoch:[ 26 9 ] loss: 0.48693084716796875 2022-06-30 20:48:18.667478
Epoch:[ 26 10 ] loss: 0.48319289088249207 2022-06-30 20:48:19.090343
Epoch:[ 26 11 ] loss: 0.480599969625473 2022-06-30 20:48:19.513305
Epoch:[ 26 12 ] loss: 0.4825262129306793 2022-06-30 20:48:19.943545
Epoch:[ 26 13 ] loss: 0.4835876524448395 2022-06-30 20:48:20.365366
Epoch:[ 26 14 ] loss: 0.485818475484848 2022-06-30 20:48:20.779374
Epoch:[ 26 15 ] loss: 0.47978100180625916 2022-06-30 20:48:21.195187
Epoch:[ 26 16 ] loss: 0.48603010177612305 2022-06-30 20:48:26.569028
Epoch:[ 26 17 ] loss: 0.48099565505981445 2022-06-30 20:48:26.986453
Epoch:[ 26 18 ] loss: 0.482851505279541 2022-06-30 20:48:27.403517
Epoch:[ 26 19 ] loss: 0.4805111289024353 2022-06-30 20:48:27.818634
Training_Epoch:[ 26 ] Training_loss: 0.48431984931230543 2022-06-30 20:48:27.819360
learning rate:  0.0032
netparams have been saved once 26
val: 1 0.4870316982269287
val: 2 0.477932870388031
val: 3 0.48705941438674927
val: 4 0.4838411509990692
val: 5 0.48696959018707275
val: 6 0.4919799566268921
val: 7 0.49201899766921997
val: 8 0.4814261496067047
val: 9 0.48002633452415466
val: 10 0.47613921761512756
val: 11 0.4774186611175537
val: 12 0.48002249002456665
val: 13 0.4815567433834076
val: 14 0.4909892976284027
val: 15 0.48333337903022766
val: 16 0.47000852227211
val: 17 0.485067218542099
val: 18 0.4794023036956787
val: 19 0.49531203508377075
val: 20 0.5055420994758606
val_Epoch:[ 26 ] val_loss: 0.4846539065241814 2022-06-30 20:48:31.243080
start training 2022-06-30 20:48:31.347036
Epoch:[ 27 0 ] loss: 0.47844722867012024 2022-06-30 20:48:45.543634
Epoch:[ 27 1 ] loss: 0.48125356435775757 2022-06-30 20:48:45.981529
Epoch:[ 27 2 ] loss: 0.4815666973590851 2022-06-30 20:48:46.395627
Epoch:[ 27 3 ] loss: 0.48538070917129517 2022-06-30 20:48:46.813531
Epoch:[ 27 4 ] loss: 0.4852071702480316 2022-06-30 20:48:47.231809
Epoch:[ 27 5 ] loss: 0.48425301909446716 2022-06-30 20:48:47.647373
Epoch:[ 27 6 ] loss: 0.4844077229499817 2022-06-30 20:48:48.067143
Epoch:[ 27 7 ] loss: 0.4827948808670044 2022-06-30 20:48:48.483343
Epoch:[ 27 8 ] loss: 0.48457035422325134 2022-06-30 20:48:48.897463
Epoch:[ 27 9 ] loss: 0.4798915982246399 2022-06-30 20:48:49.317323
Epoch:[ 27 10 ] loss: 0.48262855410575867 2022-06-30 20:48:49.747245
Epoch:[ 27 11 ] loss: 0.481352835893631 2022-06-30 20:48:50.166360
Epoch:[ 27 12 ] loss: 0.4767657220363617 2022-06-30 20:48:50.581338
Epoch:[ 27 13 ] loss: 0.48407047986984253 2022-06-30 20:48:50.997183
Epoch:[ 27 14 ] loss: 0.4788329601287842 2022-06-30 20:48:51.421888
Epoch:[ 27 15 ] loss: 0.4849284589290619 2022-06-30 20:48:51.842397
Epoch:[ 27 16 ] loss: 0.4794417917728424 2022-06-30 20:48:57.204844
Epoch:[ 27 17 ] loss: 0.4828338623046875 2022-06-30 20:48:57.685216
Epoch:[ 27 18 ] loss: 0.48089849948883057 2022-06-30 20:48:58.102816
Epoch:[ 27 19 ] loss: 0.4790537655353546 2022-06-30 20:48:58.518791
Training_Epoch:[ 27 ] Training_loss: 0.48192899376153947 2022-06-30 20:48:58.519549
learning rate:  0.0032
val: 1 0.49024417996406555
val: 2 0.4817158281803131
val: 3 0.4647427499294281
val: 4 0.4855484962463379
val: 5 0.48848944902420044
val: 6 0.4838045537471771
val: 7 0.4829339385032654
val: 8 0.4711669981479645
val: 9 0.49221551418304443
val: 10 0.4765211343765259
val: 11 0.49072015285491943
val: 12 0.4829831123352051
val: 13 0.47889429330825806
val: 14 0.4847441613674164
val: 15 0.48527276515960693
val: 16 0.47548457980155945
val: 17 0.48903873562812805
val: 18 0.48055848479270935
val: 19 0.480859637260437
val: 20 0.4909978210926056
val_Epoch:[ 27 ] val_loss: 0.4828468292951584 2022-06-30 20:49:01.905391
start training 2022-06-30 20:49:02.009588
Epoch:[ 28 0 ] loss: 0.47837117314338684 2022-06-30 20:49:15.800684
Epoch:[ 28 1 ] loss: 0.4800277352333069 2022-06-30 20:49:16.233064
Epoch:[ 28 2 ] loss: 0.48192182183265686 2022-06-30 20:49:16.653354
Epoch:[ 28 3 ] loss: 0.4811222553253174 2022-06-30 20:49:17.069073
Epoch:[ 28 4 ] loss: 0.4764872193336487 2022-06-30 20:49:17.484290
Epoch:[ 28 5 ] loss: 0.4757457375526428 2022-06-30 20:49:17.907186
Epoch:[ 28 6 ] loss: 0.47707366943359375 2022-06-30 20:49:18.321872
Epoch:[ 28 7 ] loss: 0.4765629470348358 2022-06-30 20:49:18.736987
Epoch:[ 28 8 ] loss: 0.47603341937065125 2022-06-30 20:49:19.152647
Epoch:[ 28 9 ] loss: 0.4763898551464081 2022-06-30 20:49:19.583811
Epoch:[ 28 10 ] loss: 0.4783285856246948 2022-06-30 20:49:20.003399
Epoch:[ 28 11 ] loss: 0.4775984585285187 2022-06-30 20:49:20.421463
Epoch:[ 28 12 ] loss: 0.4752822518348694 2022-06-30 20:49:20.837521
Epoch:[ 28 13 ] loss: 0.47681725025177 2022-06-30 20:49:21.253003
Epoch:[ 28 14 ] loss: 0.4789738059043884 2022-06-30 20:49:21.675321
Epoch:[ 28 15 ] loss: 0.4761574864387512 2022-06-30 20:49:22.093184
Epoch:[ 28 16 ] loss: 0.4786412715911865 2022-06-30 20:49:27.512951
Epoch:[ 28 17 ] loss: 0.4732447862625122 2022-06-30 20:49:27.926379
Epoch:[ 28 18 ] loss: 0.4730657637119293 2022-06-30 20:49:28.344570
Epoch:[ 28 19 ] loss: 0.4805305600166321 2022-06-30 20:49:28.760594
Training_Epoch:[ 28 ] Training_loss: 0.47741880267858505 2022-06-30 20:49:28.761327
learning rate:  0.0032
netparams have been saved once 28
val: 1 0.4803014099597931
val: 2 0.47657495737075806
val: 3 0.48830315470695496
val: 4 0.47525209188461304
val: 5 0.48461008071899414
val: 6 0.4816892445087433
val: 7 0.48070982098579407
val: 8 0.489471435546875
val: 9 0.48334047198295593
val: 10 0.4868508577346802
val: 11 0.47811463475227356
val: 12 0.46439340710639954
val: 13 0.47550058364868164
val: 14 0.47499287128448486
val: 15 0.47588980197906494
val: 16 0.4810051918029785
val: 17 0.47996610403060913
val: 18 0.4779772162437439
val: 19 0.4853895604610443
val: 20 0.49360960721969604
val_Epoch:[ 28 ] val_loss: 0.4806971251964569 2022-06-30 20:49:32.161170
start training 2022-06-30 20:49:32.270885
Epoch:[ 29 0 ] loss: 0.47653546929359436 2022-06-30 20:49:45.852690
Epoch:[ 29 1 ] loss: 0.47615963220596313 2022-06-30 20:49:46.617618
Epoch:[ 29 2 ] loss: 0.47738680243492126 2022-06-30 20:49:47.037784
Epoch:[ 29 3 ] loss: 0.4741699695587158 2022-06-30 20:49:47.453054
Epoch:[ 29 4 ] loss: 0.4743165373802185 2022-06-30 20:49:47.867217
Epoch:[ 29 5 ] loss: 0.47495609521865845 2022-06-30 20:49:48.284590
Epoch:[ 29 6 ] loss: 0.4721711277961731 2022-06-30 20:49:48.700106
Epoch:[ 29 7 ] loss: 0.47755661606788635 2022-06-30 20:49:49.116455
Epoch:[ 29 8 ] loss: 0.4830479919910431 2022-06-30 20:49:49.531385
Epoch:[ 29 9 ] loss: 0.48491209745407104 2022-06-30 20:49:49.953438
Epoch:[ 29 10 ] loss: 0.4835026264190674 2022-06-30 20:49:50.369504
Epoch:[ 29 11 ] loss: 0.48165369033813477 2022-06-30 20:49:50.785887
Epoch:[ 29 12 ] loss: 0.48300379514694214 2022-06-30 20:49:51.212978
Epoch:[ 29 13 ] loss: 0.481876403093338 2022-06-30 20:49:51.632012
Epoch:[ 29 14 ] loss: 0.4808804988861084 2022-06-30 20:49:52.052770
Epoch:[ 29 15 ] loss: 0.4819287061691284 2022-06-30 20:49:52.467961
Epoch:[ 29 16 ] loss: 0.48188140988349915 2022-06-30 20:49:57.550393
Epoch:[ 29 17 ] loss: 0.48116856813430786 2022-06-30 20:49:58.261893
Epoch:[ 29 18 ] loss: 0.4783056378364563 2022-06-30 20:49:58.683690
Epoch:[ 29 19 ] loss: 0.48030564188957214 2022-06-30 20:49:59.100111
Training_Epoch:[ 29 ] Training_loss: 0.47928596585989 2022-06-30 20:49:59.100738
learning rate:  0.0032
val: 1 0.48178166151046753
val: 2 0.48624280095100403
val: 3 0.4815738797187805
val: 4 0.4759928286075592
val: 5 0.48046109080314636
val: 6 0.4827788770198822
val: 7 0.4853847622871399
val: 8 0.47818470001220703
val: 9 0.49309587478637695
val: 10 0.48919448256492615
val: 11 0.4738484025001526
val: 12 0.47421443462371826
val: 13 0.47475606203079224
val: 14 0.4830971658229828
val: 15 0.4729677438735962
val: 16 0.4786008596420288
val: 17 0.47966688871383667
val: 18 0.47685590386390686
val: 19 0.47295987606048584
val: 20 0.4781745672225952
val_Epoch:[ 29 ] val_loss: 0.47999164313077924 2022-06-30 20:50:02.477900
start training 2022-06-30 20:50:02.583694
Epoch:[ 30 0 ] loss: 0.47609177231788635 2022-06-30 20:50:16.905969
Epoch:[ 30 1 ] loss: 0.47449764609336853 2022-06-30 20:50:17.322285
Epoch:[ 30 2 ] loss: 0.4773297905921936 2022-06-30 20:50:17.737501
Epoch:[ 30 3 ] loss: 0.4744739830493927 2022-06-30 20:50:18.153836
Epoch:[ 30 4 ] loss: 0.47252631187438965 2022-06-30 20:50:18.574232
Epoch:[ 30 5 ] loss: 0.477676123380661 2022-06-30 20:50:18.989369
Epoch:[ 30 6 ] loss: 0.4746754467487335 2022-06-30 20:50:19.406984
Epoch:[ 30 7 ] loss: 0.47595351934432983 2022-06-30 20:50:19.825774
Epoch:[ 30 8 ] loss: 0.47259521484375 2022-06-30 20:50:20.247601
Epoch:[ 30 9 ] loss: 0.4735068380832672 2022-06-30 20:50:20.662534
Epoch:[ 30 10 ] loss: 0.47567206621170044 2022-06-30 20:50:21.101196
Epoch:[ 30 11 ] loss: 0.47584986686706543 2022-06-30 20:50:21.518960
Epoch:[ 30 12 ] loss: 0.4769911766052246 2022-06-30 20:50:21.941831
Epoch:[ 30 13 ] loss: 0.4710293412208557 2022-06-30 20:50:22.359721
Epoch:[ 30 14 ] loss: 0.4746832847595215 2022-06-30 20:50:22.782880
Epoch:[ 30 15 ] loss: 0.47542038559913635 2022-06-30 20:50:23.199297
Epoch:[ 30 16 ] loss: 0.4735994338989258 2022-06-30 20:50:28.499849
Epoch:[ 30 17 ] loss: 0.47733840346336365 2022-06-30 20:50:28.914162
Epoch:[ 30 18 ] loss: 0.47741058468818665 2022-06-30 20:50:29.329981
Epoch:[ 30 19 ] loss: 0.47822993993759155 2022-06-30 20:50:29.744116
Training_Epoch:[ 30 ] Training_loss: 0.4752775564789772 2022-06-30 20:50:29.744809
learning rate:  0.0032
netparams have been saved once 30
val: 1 0.48974624276161194
val: 2 0.49931055307388306
val: 3 0.4739556312561035
val: 4 0.48822954297065735
val: 5 0.4860738515853882
val: 6 0.48906564712524414
val: 7 0.49260494112968445
val: 8 0.47999945282936096
val: 9 0.4897136688232422
val: 10 0.4881007671356201
val: 11 0.4783523380756378
val: 12 0.48322129249572754
val: 13 0.49732619524002075
val: 14 0.48953208327293396
val: 15 0.48095494508743286
val: 16 0.4862484335899353
val: 17 0.47501078248023987
val: 18 0.4876750707626343
val: 19 0.48331812024116516
val: 20 0.4881688356399536
val_Epoch:[ 30 ] val_loss: 0.48633041977882385 2022-06-30 20:50:33.152075
start training 2022-06-30 20:50:33.256775
Epoch:[ 31 0 ] loss: 0.47385287284851074 2022-06-30 20:50:47.033183
Epoch:[ 31 1 ] loss: 0.4720754623413086 2022-06-30 20:50:47.840590
Epoch:[ 31 2 ] loss: 0.4688712954521179 2022-06-30 20:50:48.260488
Epoch:[ 31 3 ] loss: 0.47409096360206604 2022-06-30 20:50:48.677484
Epoch:[ 31 4 ] loss: 0.4734876751899719 2022-06-30 20:50:49.092530
Epoch:[ 31 5 ] loss: 0.4719287157058716 2022-06-30 20:50:49.507196
Epoch:[ 31 6 ] loss: 0.4733728766441345 2022-06-30 20:50:49.921003
Epoch:[ 31 7 ] loss: 0.4740160405635834 2022-06-30 20:50:50.343772
Epoch:[ 31 8 ] loss: 0.4687592387199402 2022-06-30 20:50:50.767042
Epoch:[ 31 9 ] loss: 0.4717833399772644 2022-06-30 20:50:51.186263
Epoch:[ 31 10 ] loss: 0.4727475345134735 2022-06-30 20:50:51.600095
Epoch:[ 31 11 ] loss: 0.4736980199813843 2022-06-30 20:50:52.016626
Epoch:[ 31 12 ] loss: 0.47121790051460266 2022-06-30 20:50:52.437458
Epoch:[ 31 13 ] loss: 0.4642980694770813 2022-06-30 20:50:52.851982
Epoch:[ 31 14 ] loss: 0.4719054698944092 2022-06-30 20:50:53.269421
Epoch:[ 31 15 ] loss: 0.4682447016239166 2022-06-30 20:50:53.691842
Epoch:[ 31 16 ] loss: 0.4696345329284668 2022-06-30 20:50:58.909260
Epoch:[ 31 17 ] loss: 0.471325546503067 2022-06-30 20:51:00.158373
Epoch:[ 31 18 ] loss: 0.4688545763492584 2022-06-30 20:51:00.580916
Epoch:[ 31 19 ] loss: 0.4657021462917328 2022-06-30 20:51:00.996667
Training_Epoch:[ 31 ] Training_loss: 0.4709933489561081 2022-06-30 20:51:00.997390
learning rate:  0.00256
val: 1 0.47534140944480896
val: 2 0.46100178360939026
val: 3 0.4726659655570984
val: 4 0.47893205285072327
val: 5 0.47967565059661865
val: 6 0.47369638085365295
val: 7 0.47138094902038574
val: 8 0.4766612946987152
val: 9 0.4881815016269684
val: 10 0.4737931489944458
val: 11 0.47968819737434387
val: 12 0.47405165433883667
val: 13 0.462581604719162
val: 14 0.47507330775260925
val: 15 0.47470128536224365
val: 16 0.4734765291213989
val: 17 0.46911171078681946
val: 18 0.47514045238494873
val: 19 0.48242539167404175
val: 20 0.4712825417518616
val_Epoch:[ 31 ] val_loss: 0.47444314062595366 2022-06-30 20:51:04.344524
start training 2022-06-30 20:51:04.451594
Epoch:[ 32 0 ] loss: 0.4706164300441742 2022-06-30 20:51:18.294479
Epoch:[ 32 1 ] loss: 0.4658713936805725 2022-06-30 20:51:18.729301
Epoch:[ 32 2 ] loss: 0.46577954292297363 2022-06-30 20:51:19.145195
Epoch:[ 32 3 ] loss: 0.4714815318584442 2022-06-30 20:51:19.568339
Epoch:[ 32 4 ] loss: 0.46634620428085327 2022-06-30 20:51:19.982938
Epoch:[ 32 5 ] loss: 0.4670300781726837 2022-06-30 20:51:20.405670
Epoch:[ 32 6 ] loss: 0.4665165841579437 2022-06-30 20:51:20.821410
Epoch:[ 32 7 ] loss: 0.4716423749923706 2022-06-30 20:51:21.238045
Epoch:[ 32 8 ] loss: 0.4687429666519165 2022-06-30 20:51:21.662053
Epoch:[ 32 9 ] loss: 0.46691659092903137 2022-06-30 20:51:22.078631
Epoch:[ 32 10 ] loss: 0.4637987017631531 2022-06-30 20:51:22.508851
Epoch:[ 32 11 ] loss: 0.4660363495349884 2022-06-30 20:51:22.927421
Epoch:[ 32 12 ] loss: 0.4632948040962219 2022-06-30 20:51:23.342259
Epoch:[ 32 13 ] loss: 0.46567225456237793 2022-06-30 20:51:23.758339
Epoch:[ 32 14 ] loss: 0.46700409054756165 2022-06-30 20:51:24.180582
Epoch:[ 32 15 ] loss: 0.4694501459598541 2022-06-30 20:51:24.604640
Epoch:[ 32 16 ] loss: 0.4666024446487427 2022-06-30 20:51:30.242628
Epoch:[ 32 17 ] loss: 0.4661629796028137 2022-06-30 20:51:30.659025
Epoch:[ 32 18 ] loss: 0.47058141231536865 2022-06-30 20:51:31.076161
Epoch:[ 32 19 ] loss: 0.46740418672561646 2022-06-30 20:51:31.493634
Training_Epoch:[ 32 ] Training_loss: 0.4673475533723831 2022-06-30 20:51:31.494349
learning rate:  0.00256
netparams have been saved once 32
val: 1 0.46456843614578247
val: 2 0.479240745306015
val: 3 0.47941043972969055
val: 4 0.4746876060962677
val: 5 0.4778280556201935
val: 6 0.47113555669784546
val: 7 0.4776389002799988
val: 8 0.47587013244628906
val: 9 0.4716334939002991
val: 10 0.47803881764411926
val: 11 0.47202813625335693
val: 12 0.47842445969581604
val: 13 0.47613999247550964
val: 14 0.46966081857681274
val: 15 0.4757494032382965
val: 16 0.47565510869026184
val: 17 0.47652846574783325
val: 18 0.4721262454986572
val: 19 0.4769565761089325
val: 20 0.47989848256111145
val_Epoch:[ 32 ] val_loss: 0.47516099363565445 2022-06-30 20:51:34.995911
start training 2022-06-30 20:51:35.102754
Epoch:[ 33 0 ] loss: 0.46741026639938354 2022-06-30 20:51:49.111009
Epoch:[ 33 1 ] loss: 0.4622512459754944 2022-06-30 20:51:49.526312
Epoch:[ 33 2 ] loss: 0.4683483839035034 2022-06-30 20:51:49.942884
Epoch:[ 33 3 ] loss: 0.46676865220069885 2022-06-30 20:51:50.365221
Epoch:[ 33 4 ] loss: 0.4645724892616272 2022-06-30 20:51:50.786391
Epoch:[ 33 5 ] loss: 0.4633556008338928 2022-06-30 20:51:51.206930
Epoch:[ 33 6 ] loss: 0.46298423409461975 2022-06-30 20:51:51.621631
Epoch:[ 33 7 ] loss: 0.46650105714797974 2022-06-30 20:51:52.035891
Epoch:[ 33 8 ] loss: 0.4658125042915344 2022-06-30 20:51:52.456061
Epoch:[ 33 9 ] loss: 0.46124738454818726 2022-06-30 20:51:52.872264
Epoch:[ 33 10 ] loss: 0.46638450026512146 2022-06-30 20:51:53.288547
Epoch:[ 33 11 ] loss: 0.4650729298591614 2022-06-30 20:51:53.705210
Epoch:[ 33 12 ] loss: 0.4631536602973938 2022-06-30 20:51:54.119216
Epoch:[ 33 13 ] loss: 0.46866586804389954 2022-06-30 20:51:54.549759
Epoch:[ 33 14 ] loss: 0.46269461512565613 2022-06-30 20:51:54.970159
Epoch:[ 33 15 ] loss: 0.46524152159690857 2022-06-30 20:51:55.391930
Epoch:[ 33 16 ] loss: 0.4666725993156433 2022-06-30 20:52:00.603160
Epoch:[ 33 17 ] loss: 0.4650644361972809 2022-06-30 20:52:01.020816
Epoch:[ 33 18 ] loss: 0.4685676693916321 2022-06-30 20:52:01.439947
Epoch:[ 33 19 ] loss: 0.4698525369167328 2022-06-30 20:52:01.858411
Training_Epoch:[ 33 ] Training_loss: 0.4655311077833176 2022-06-30 20:52:01.859082
learning rate:  0.00256
val: 1 0.4578256905078888
val: 2 0.48158031702041626
val: 3 0.46761423349380493
val: 4 0.4846011996269226
val: 5 0.46133488416671753
val: 6 0.4672936499118805
val: 7 0.4818766117095947
val: 8 0.4830645024776459
val: 9 0.46979597210884094
val: 10 0.4715910255908966
val: 11 0.4601875841617584
val: 12 0.47196727991104126
val: 13 0.471524178981781
val: 14 0.4770206809043884
val: 15 0.4654475748538971
val: 16 0.4709870219230652
val: 17 0.46477010846138
val: 18 0.4712986946105957
val: 19 0.472563236951828
val: 20 0.4666704833507538
val_Epoch:[ 33 ] val_loss: 0.4709507465362549 2022-06-30 20:52:05.209974
start training 2022-06-30 20:52:05.309703
Epoch:[ 34 0 ] loss: 0.46975797414779663 2022-06-30 20:52:19.681805
Epoch:[ 34 1 ] loss: 0.46651777625083923 2022-06-30 20:52:20.096895
Epoch:[ 34 2 ] loss: 0.46704912185668945 2022-06-30 20:52:20.511583
Epoch:[ 34 3 ] loss: 0.4641546308994293 2022-06-30 20:52:20.929224
Epoch:[ 34 4 ] loss: 0.4633045494556427 2022-06-30 20:52:21.346401
Epoch:[ 34 5 ] loss: 0.4656287431716919 2022-06-30 20:52:21.767822
Epoch:[ 34 6 ] loss: 0.46554064750671387 2022-06-30 20:52:22.188019
Epoch:[ 34 7 ] loss: 0.46585512161254883 2022-06-30 20:52:22.612650
Epoch:[ 34 8 ] loss: 0.46449014544487 2022-06-30 20:52:23.029324
Epoch:[ 34 9 ] loss: 0.4643608629703522 2022-06-30 20:52:23.449508
Epoch:[ 34 10 ] loss: 0.470998615026474 2022-06-30 20:52:23.866013
Epoch:[ 34 11 ] loss: 0.46647530794143677 2022-06-30 20:52:24.283560
Epoch:[ 34 12 ] loss: 0.46684855222702026 2022-06-30 20:52:24.707097
Epoch:[ 34 13 ] loss: 0.4667545557022095 2022-06-30 20:52:25.121839
Epoch:[ 34 14 ] loss: 0.46379342675209045 2022-06-30 20:52:25.556746
Epoch:[ 34 15 ] loss: 0.4704791307449341 2022-06-30 20:52:25.974749
Epoch:[ 34 16 ] loss: 0.46477872133255005 2022-06-30 20:52:31.792928
Epoch:[ 34 17 ] loss: 0.46484389901161194 2022-06-30 20:52:32.213074
Epoch:[ 34 18 ] loss: 0.4692801535129547 2022-06-30 20:52:32.629659
Epoch:[ 34 19 ] loss: 0.46181994676589966 2022-06-30 20:52:33.048408
Training_Epoch:[ 34 ] Training_loss: 0.4661365941166878 2022-06-30 20:52:33.049192
learning rate:  0.00256
netparams have been saved once 34
val: 1 0.473669171333313
val: 2 0.47604697942733765
val: 3 0.4663448929786682
val: 4 0.48005765676498413
val: 5 0.4663005769252777
val: 6 0.48565027117729187
val: 7 0.4742065668106079
val: 8 0.4689955711364746
val: 9 0.471717894077301
val: 10 0.4613836109638214
val: 11 0.4677227735519409
val: 12 0.47437602281570435
val: 13 0.47320324182510376
val: 14 0.4639476239681244
val: 15 0.479377418756485
val: 16 0.47862792015075684
val: 17 0.46527570486068726
val: 18 0.4627269208431244
val: 19 0.46474629640579224
val: 20 0.46234646439552307
val_Epoch:[ 34 ] val_loss: 0.470836178958416 2022-06-30 20:52:36.527834
start training 2022-06-30 20:52:36.629347
Epoch:[ 35 0 ] loss: 0.46649831533432007 2022-06-30 20:52:51.245459
Epoch:[ 35 1 ] loss: 0.4620583951473236 2022-06-30 20:52:51.690145
Epoch:[ 35 2 ] loss: 0.46851781010627747 2022-06-30 20:52:52.106146
Epoch:[ 35 3 ] loss: 0.46033570170402527 2022-06-30 20:52:52.521473
Epoch:[ 35 4 ] loss: 0.46124088764190674 2022-06-30 20:52:52.937771
Epoch:[ 35 5 ] loss: 0.4623759388923645 2022-06-30 20:52:53.354727
Epoch:[ 35 6 ] loss: 0.46044591069221497 2022-06-30 20:52:53.772095
Epoch:[ 35 7 ] loss: 0.4646326005458832 2022-06-30 20:52:54.189473
Epoch:[ 35 8 ] loss: 0.4562065899372101 2022-06-30 20:52:54.607797
Epoch:[ 35 9 ] loss: 0.4585590660572052 2022-06-30 20:52:55.023912
Epoch:[ 35 10 ] loss: 0.460222989320755 2022-06-30 20:52:55.449476
Epoch:[ 35 11 ] loss: 0.4651262164115906 2022-06-30 20:52:55.873327
Epoch:[ 35 12 ] loss: 0.4637826681137085 2022-06-30 20:52:56.291934
Epoch:[ 35 13 ] loss: 0.46909594535827637 2022-06-30 20:52:56.722444
Epoch:[ 35 14 ] loss: 0.4709579050540924 2022-06-30 20:52:57.150306
Epoch:[ 35 15 ] loss: 0.4680112898349762 2022-06-30 20:52:57.572584
Epoch:[ 35 16 ] loss: 0.47247886657714844 2022-06-30 20:53:03.410052
Epoch:[ 35 17 ] loss: 0.46476104855537415 2022-06-30 20:53:03.827609
Epoch:[ 35 18 ] loss: 0.4735174775123596 2022-06-30 20:53:04.246612
Epoch:[ 35 19 ] loss: 0.46224769949913025 2022-06-30 20:53:04.663148
Training_Epoch:[ 35 ] Training_loss: 0.46455366611480714 2022-06-30 20:53:04.663868
learning rate:  0.00256
val: 1 0.48304298520088196
val: 2 0.48095351457595825
val: 3 0.4755936563014984
val: 4 0.48409783840179443
val: 5 0.48203542828559875
val: 6 0.48309388756752014
val: 7 0.4850466251373291
val: 8 0.47285163402557373
val: 9 0.4799918234348297
val: 10 0.4872198700904846
val: 11 0.4910038411617279
val: 12 0.4789109528064728
val: 13 0.4851105809211731
val: 14 0.4710409641265869
val: 15 0.4874931573867798
val: 16 0.4717833995819092
val: 17 0.4786667823791504
val: 18 0.4760747253894806
val: 19 0.4782850444316864
val: 20 0.4858979284763336
val_Epoch:[ 35 ] val_loss: 0.4809097319841385 2022-06-30 20:53:08.075680
start training 2022-06-30 20:53:08.174102
Epoch:[ 36 0 ] loss: 0.4696769714355469 2022-06-30 20:53:22.784753
Epoch:[ 36 1 ] loss: 0.4625607132911682 2022-06-30 20:53:23.214864
Epoch:[ 36 2 ] loss: 0.46617424488067627 2022-06-30 20:53:23.630217
Epoch:[ 36 3 ] loss: 0.4627591073513031 2022-06-30 20:53:24.045312
Epoch:[ 36 4 ] loss: 0.4641367793083191 2022-06-30 20:53:24.463130
Epoch:[ 36 5 ] loss: 0.46480458974838257 2022-06-30 20:53:24.888125
Epoch:[ 36 6 ] loss: 0.4637428820133209 2022-06-30 20:53:25.306726
Epoch:[ 36 7 ] loss: 0.46508628129959106 2022-06-30 20:53:25.731765
Epoch:[ 36 8 ] loss: 0.46006274223327637 2022-06-30 20:53:26.146184
Epoch:[ 36 9 ] loss: 0.4590073525905609 2022-06-30 20:53:26.564926
Epoch:[ 36 10 ] loss: 0.46197158098220825 2022-06-30 20:53:26.989632
Epoch:[ 36 11 ] loss: 0.46535155177116394 2022-06-30 20:53:27.409094
Epoch:[ 36 12 ] loss: 0.46225082874298096 2022-06-30 20:53:27.828436
Epoch:[ 36 13 ] loss: 0.4625597894191742 2022-06-30 20:53:28.245844
Epoch:[ 36 14 ] loss: 0.46004197001457214 2022-06-30 20:53:28.683036
Epoch:[ 36 15 ] loss: 0.4626501500606537 2022-06-30 20:53:29.108056
Epoch:[ 36 16 ] loss: 0.46481138467788696 2022-06-30 20:53:34.339085
Epoch:[ 36 17 ] loss: 0.4617524743080139 2022-06-30 20:53:34.756772
Epoch:[ 36 18 ] loss: 0.46323099732398987 2022-06-30 20:53:35.177769
Epoch:[ 36 19 ] loss: 0.4636249244213104 2022-06-30 20:53:35.597553
Training_Epoch:[ 36 ] Training_loss: 0.463312865793705 2022-06-30 20:53:35.598266
learning rate:  0.00256
netparams have been saved once 36
val: 1 0.4626269042491913
val: 2 0.4626538157463074
val: 3 0.4661790728569031
val: 4 0.47190234065055847
val: 5 0.4599475860595703
val: 6 0.47155293822288513
val: 7 0.459259957075119
val: 8 0.4752160906791687
val: 9 0.4808836877346039
val: 10 0.46603402495384216
val: 11 0.4680316746234894
val: 12 0.4525207281112671
val: 13 0.46754610538482666
val: 14 0.46086323261260986
val: 15 0.46948471665382385
val: 16 0.47089067101478577
val: 17 0.4743090271949768
val: 18 0.4768391251564026
val: 19 0.45508670806884766
val: 20 0.4505651891231537
val_Epoch:[ 36 ] val_loss: 0.4661196798086166 2022-06-30 20:53:38.974536
start training 2022-06-30 20:53:39.071386
Epoch:[ 37 0 ] loss: 0.46134933829307556 2022-06-30 20:53:53.133416
Epoch:[ 37 1 ] loss: 0.4608360230922699 2022-06-30 20:53:53.946767
Epoch:[ 37 2 ] loss: 0.46099570393562317 2022-06-30 20:53:54.435198
Epoch:[ 37 3 ] loss: 0.4600640833377838 2022-06-30 20:53:54.854343
Epoch:[ 37 4 ] loss: 0.46341994404792786 2022-06-30 20:53:55.267864
Epoch:[ 37 5 ] loss: 0.46183863282203674 2022-06-30 20:53:55.684886
Epoch:[ 37 6 ] loss: 0.45879852771759033 2022-06-30 20:53:56.104533
Epoch:[ 37 7 ] loss: 0.46057942509651184 2022-06-30 20:53:56.528662
Epoch:[ 37 8 ] loss: 0.45811939239501953 2022-06-30 20:53:56.950553
Epoch:[ 37 9 ] loss: 0.4602205455303192 2022-06-30 20:53:57.375480
Epoch:[ 37 10 ] loss: 0.4581708014011383 2022-06-30 20:53:57.799023
Epoch:[ 37 11 ] loss: 0.4572257101535797 2022-06-30 20:53:58.216711
Epoch:[ 37 12 ] loss: 0.460107684135437 2022-06-30 20:53:58.634091
Epoch:[ 37 13 ] loss: 0.45880424976348877 2022-06-30 20:53:59.051213
Epoch:[ 37 14 ] loss: 0.4618132710456848 2022-06-30 20:53:59.467951
Epoch:[ 37 15 ] loss: 0.4595243036746979 2022-06-30 20:53:59.891040
Epoch:[ 37 16 ] loss: 0.4589427411556244 2022-06-30 20:54:05.091530
Epoch:[ 37 17 ] loss: 0.45797088742256165 2022-06-30 20:54:05.505577
Epoch:[ 37 18 ] loss: 0.45826372504234314 2022-06-30 20:54:05.925669
Epoch:[ 37 19 ] loss: 0.4627409875392914 2022-06-30 20:54:06.339555
Training_Epoch:[ 37 ] Training_loss: 0.45998929888010026 2022-06-30 20:54:06.340223
learning rate:  0.00256
val: 1 0.4720112085342407
val: 2 0.46304985880851746
val: 3 0.47733595967292786
val: 4 0.48136332631111145
val: 5 0.4671509563922882
val: 6 0.4706871211528778
val: 7 0.46883782744407654
val: 8 0.47273358702659607
val: 9 0.4744682013988495
val: 10 0.4689372479915619
val: 11 0.47249355912208557
val: 12 0.4639908969402313
val: 13 0.481784850358963
val: 14 0.47179096937179565
val: 15 0.47979217767715454
val: 16 0.47981297969818115
val: 17 0.47903433442115784
val: 18 0.47344285249710083
val: 19 0.47581660747528076
val: 20 0.4641122817993164
val_Epoch:[ 37 ] val_loss: 0.47293234020471575 2022-06-30 20:54:09.700673
start training 2022-06-30 20:54:09.801617
Epoch:[ 38 0 ] loss: 0.463956356048584 2022-06-30 20:54:24.351716
Epoch:[ 38 1 ] loss: 0.4589634835720062 2022-06-30 20:54:24.813447
Epoch:[ 38 2 ] loss: 0.46129584312438965 2022-06-30 20:54:25.295418
Epoch:[ 38 3 ] loss: 0.4634319543838501 2022-06-30 20:54:25.710491
Epoch:[ 38 4 ] loss: 0.4614293575286865 2022-06-30 20:54:26.125539
Epoch:[ 38 5 ] loss: 0.4606884717941284 2022-06-30 20:54:26.539950
Epoch:[ 38 6 ] loss: 0.45881330966949463 2022-06-30 20:54:26.954097
Epoch:[ 38 7 ] loss: 0.46095672249794006 2022-06-30 20:54:27.372737
Epoch:[ 38 8 ] loss: 0.4579431712627411 2022-06-30 20:54:27.790639
Epoch:[ 38 9 ] loss: 0.45972490310668945 2022-06-30 20:54:28.212603
Epoch:[ 38 10 ] loss: 0.45752739906311035 2022-06-30 20:54:28.633808
Epoch:[ 38 11 ] loss: 0.46109166741371155 2022-06-30 20:54:29.055012
Epoch:[ 38 12 ] loss: 0.4598616063594818 2022-06-30 20:54:29.472358
Epoch:[ 38 13 ] loss: 0.45771047472953796 2022-06-30 20:54:29.887036
Epoch:[ 38 14 ] loss: 0.46013882756233215 2022-06-30 20:54:30.311711
Epoch:[ 38 15 ] loss: 0.4601837396621704 2022-06-30 20:54:30.727447
Epoch:[ 38 16 ] loss: 0.4609341621398926 2022-06-30 20:54:35.938228
Epoch:[ 38 17 ] loss: 0.45772621035575867 2022-06-30 20:54:36.352311
Epoch:[ 38 18 ] loss: 0.4618304669857025 2022-06-30 20:54:36.768646
Epoch:[ 38 19 ] loss: 0.46133890748023987 2022-06-30 20:54:37.185013
Training_Epoch:[ 38 ] Training_loss: 0.4602773517370224 2022-06-30 20:54:37.185851
learning rate:  0.00256
netparams have been saved once 38
val: 1 0.464285284280777
val: 2 0.45693549513816833
val: 3 0.48202088475227356
val: 4 0.4633904993534088
val: 5 0.46461039781570435
val: 6 0.4614241421222687
val: 7 0.4700837731361389
val: 8 0.4617447257041931
val: 9 0.4648047983646393
val: 10 0.4708998501300812
val: 11 0.46657732129096985
val: 12 0.48046085238456726
val: 13 0.46506601572036743
val: 14 0.4646020829677582
val: 15 0.4589742124080658
val: 16 0.4763798117637634
val: 17 0.4842831790447235
val: 18 0.4648166000843048
val: 19 0.4619712829589844
val: 20 0.4770156443119049
val_Epoch:[ 38 ] val_loss: 0.4680173426866531 2022-06-30 20:54:40.646041
start training 2022-06-30 20:54:40.746320
Epoch:[ 39 0 ] loss: 0.4615638852119446 2022-06-30 20:54:54.449018
Epoch:[ 39 1 ] loss: 0.45894888043403625 2022-06-30 20:54:55.150201
Epoch:[ 39 2 ] loss: 0.4575725793838501 2022-06-30 20:54:55.572204
Epoch:[ 39 3 ] loss: 0.4587763845920563 2022-06-30 20:54:55.988796
Epoch:[ 39 4 ] loss: 0.4587445557117462 2022-06-30 20:54:56.413059
Epoch:[ 39 5 ] loss: 0.4611188769340515 2022-06-30 20:54:56.828626
Epoch:[ 39 6 ] loss: 0.460742712020874 2022-06-30 20:54:57.280787
Epoch:[ 39 7 ] loss: 0.45721694827079773 2022-06-30 20:54:57.759894
Epoch:[ 39 8 ] loss: 0.4573912024497986 2022-06-30 20:54:58.181993
Epoch:[ 39 9 ] loss: 0.458344966173172 2022-06-30 20:54:58.597356
Epoch:[ 39 10 ] loss: 0.4592808187007904 2022-06-30 20:54:59.012512
Epoch:[ 39 11 ] loss: 0.46365687251091003 2022-06-30 20:54:59.428098
Epoch:[ 39 12 ] loss: 0.4572986662387848 2022-06-30 20:54:59.844035
Epoch:[ 39 13 ] loss: 0.4553023874759674 2022-06-30 20:55:00.258649
Epoch:[ 39 14 ] loss: 0.46255022287368774 2022-06-30 20:55:00.680724
Epoch:[ 39 15 ] loss: 0.45738235116004944 2022-06-30 20:55:01.099133
Epoch:[ 39 16 ] loss: 0.4544219970703125 2022-06-30 20:55:06.331185
Epoch:[ 39 17 ] loss: 0.4614025354385376 2022-06-30 20:55:07.071506
Epoch:[ 39 18 ] loss: 0.4591154456138611 2022-06-30 20:55:07.490313
Epoch:[ 39 19 ] loss: 0.45496267080307007 2022-06-30 20:55:07.905379
Training_Epoch:[ 39 ] Training_loss: 0.45878974795341493 2022-06-30 20:55:07.906184
learning rate:  0.00256
val: 1 0.46075862646102905
val: 2 0.46209362149238586
val: 3 0.4561958611011505
val: 4 0.45824751257896423
val: 5 0.46095865964889526
val: 6 0.4594564437866211
val: 7 0.48078081011772156
val: 8 0.4683132469654083
val: 9 0.4643944203853607
val: 10 0.4698796272277832
val: 11 0.464781254529953
val: 12 0.46850770711898804
val: 13 0.4719547927379608
val: 14 0.4726127088069916
val: 15 0.4596590995788574
val: 16 0.45587363839149475
val: 17 0.4731207489967346
val: 18 0.4647185504436493
val: 19 0.4717479646205902
val: 20 0.4644627273082733
val_Epoch:[ 39 ] val_loss: 0.46542590111494064 2022-06-30 20:55:11.213231
start training 2022-06-30 20:55:11.312240
Epoch:[ 40 0 ] loss: 0.45498913526535034 2022-06-30 20:55:24.920971
Epoch:[ 40 1 ] loss: 0.4582865834236145 2022-06-30 20:55:25.575364
Epoch:[ 40 2 ] loss: 0.45665180683135986 2022-06-30 20:55:25.991707
Epoch:[ 40 3 ] loss: 0.45434466004371643 2022-06-30 20:55:26.406413
Epoch:[ 40 4 ] loss: 0.4555879533290863 2022-06-30 20:55:26.821722
Epoch:[ 40 5 ] loss: 0.45537108182907104 2022-06-30 20:55:27.271735
Epoch:[ 40 6 ] loss: 0.4545733332633972 2022-06-30 20:55:27.752749
Epoch:[ 40 7 ] loss: 0.45672792196273804 2022-06-30 20:55:28.173470
Epoch:[ 40 8 ] loss: 0.4573545455932617 2022-06-30 20:55:28.587201
Epoch:[ 40 9 ] loss: 0.4597380757331848 2022-06-30 20:55:29.003670
Epoch:[ 40 10 ] loss: 0.45946574211120605 2022-06-30 20:55:29.418433
Epoch:[ 40 11 ] loss: 0.46198949217796326 2022-06-30 20:55:29.835380
Epoch:[ 40 12 ] loss: 0.45919913053512573 2022-06-30 20:55:30.256100
Epoch:[ 40 13 ] loss: 0.4584750235080719 2022-06-30 20:55:30.679606
Epoch:[ 40 14 ] loss: 0.4651806056499481 2022-06-30 20:55:31.093255
Epoch:[ 40 15 ] loss: 0.4609968364238739 2022-06-30 20:55:31.514329
Epoch:[ 40 16 ] loss: 0.45455777645111084 2022-06-30 20:55:36.557177
Epoch:[ 40 17 ] loss: 0.45561546087265015 2022-06-30 20:55:37.091117
Epoch:[ 40 18 ] loss: 0.4552008807659149 2022-06-30 20:55:37.510604
Epoch:[ 40 19 ] loss: 0.4550684690475464 2022-06-30 20:55:37.925035
Training_Epoch:[ 40 ] Training_loss: 0.4574687257409096 2022-06-30 20:55:37.925667
learning rate:  0.00256
netparams have been saved once 40
val: 1 0.45796629786491394
val: 2 0.4848679006099701
val: 3 0.4664943814277649
val: 4 0.46293413639068604
val: 5 0.46688932180404663
val: 6 0.4580361843109131
val: 7 0.46072036027908325
val: 8 0.46479448676109314
val: 9 0.4594854712486267
val: 10 0.4473422169685364
val: 11 0.4661867022514343
val: 12 0.45015788078308105
val: 13 0.44958212971687317
val: 14 0.4653051793575287
val: 15 0.46285784244537354
val: 16 0.46458184719085693
val: 17 0.4654681384563446
val: 18 0.4648596942424774
val: 19 0.462104469537735
val: 20 0.46146804094314575
val_Epoch:[ 40 ] val_loss: 0.46210513412952425 2022-06-30 20:55:41.321834
start training 2022-06-30 20:55:41.421922
Epoch:[ 41 0 ] loss: 0.4568575322628021 2022-06-30 20:55:55.630648
Epoch:[ 41 1 ] loss: 0.4532213807106018 2022-06-30 20:55:56.102492
Epoch:[ 41 2 ] loss: 0.45468828082084656 2022-06-30 20:55:56.521558
Epoch:[ 41 3 ] loss: 0.4560110867023468 2022-06-30 20:55:56.956365
Epoch:[ 41 4 ] loss: 0.451823353767395 2022-06-30 20:55:57.445461
Epoch:[ 41 5 ] loss: 0.45842882990837097 2022-06-30 20:55:57.862920
Epoch:[ 41 6 ] loss: 0.4554811418056488 2022-06-30 20:55:58.277063
Epoch:[ 41 7 ] loss: 0.4531005322933197 2022-06-30 20:55:58.693077
Epoch:[ 41 8 ] loss: 0.4557821750640869 2022-06-30 20:55:59.107182
Epoch:[ 41 9 ] loss: 0.4544576406478882 2022-06-30 20:55:59.525147
Epoch:[ 41 10 ] loss: 0.45241236686706543 2022-06-30 20:55:59.941140
Epoch:[ 41 11 ] loss: 0.45585545897483826 2022-06-30 20:56:00.357313
Epoch:[ 41 12 ] loss: 0.45004740357398987 2022-06-30 20:56:00.780986
Epoch:[ 41 13 ] loss: 0.45459064841270447 2022-06-30 20:56:01.201769
Epoch:[ 41 14 ] loss: 0.4548327326774597 2022-06-30 20:56:01.621991
Epoch:[ 41 15 ] loss: 0.4536936283111572 2022-06-30 20:56:02.040130
Epoch:[ 41 16 ] loss: 0.45468342304229736 2022-06-30 20:56:07.479813
Epoch:[ 41 17 ] loss: 0.45321786403656006 2022-06-30 20:56:07.895878
Epoch:[ 41 18 ] loss: 0.4589986801147461 2022-06-30 20:56:08.319437
Epoch:[ 41 19 ] loss: 0.45248568058013916 2022-06-30 20:56:08.740104
Training_Epoch:[ 41 ] Training_loss: 0.45453349202871324 2022-06-30 20:56:08.740770
learning rate:  0.0020480000000000003
val: 1 0.463238000869751
val: 2 0.4617142677307129
val: 3 0.46783819794654846
val: 4 0.471640944480896
val: 5 0.45783981680870056
val: 6 0.47057074308395386
val: 7 0.47837528586387634
val: 8 0.4693048596382141
val: 9 0.46354401111602783
val: 10 0.4721044600009918
val: 11 0.46661296486854553
val: 12 0.4720343053340912
val: 13 0.4709082841873169
val: 14 0.46796706318855286
val: 15 0.46498045325279236
val: 16 0.46342527866363525
val: 17 0.4727610945701599
val: 18 0.465839147567749
val: 19 0.46922728419303894
val: 20 0.46578389406204224
val_Epoch:[ 41 ] val_loss: 0.46778551787137984 2022-06-30 20:56:12.060433
start training 2022-06-30 20:56:12.168598
Epoch:[ 42 0 ] loss: 0.4548684060573578 2022-06-30 20:56:26.327077
Epoch:[ 42 1 ] loss: 0.4538942575454712 2022-06-30 20:56:26.838336
Epoch:[ 42 2 ] loss: 0.454646497964859 2022-06-30 20:56:27.319979
Epoch:[ 42 3 ] loss: 0.45162278413772583 2022-06-30 20:56:27.735095
Epoch:[ 42 4 ] loss: 0.45313072204589844 2022-06-30 20:56:28.157236
Epoch:[ 42 5 ] loss: 0.45106151700019836 2022-06-30 20:56:28.572908
Epoch:[ 42 6 ] loss: 0.45442670583724976 2022-06-30 20:56:28.993756
Epoch:[ 42 7 ] loss: 0.45408105850219727 2022-06-30 20:56:29.409353
Epoch:[ 42 8 ] loss: 0.4493030607700348 2022-06-30 20:56:29.824435
Epoch:[ 42 9 ] loss: 0.4544886648654938 2022-06-30 20:56:30.238953
Epoch:[ 42 10 ] loss: 0.451972633600235 2022-06-30 20:56:30.652441
Epoch:[ 42 11 ] loss: 0.4475468397140503 2022-06-30 20:56:31.069307
Epoch:[ 42 12 ] loss: 0.453207403421402 2022-06-30 20:56:31.491078
Epoch:[ 42 13 ] loss: 0.4536481499671936 2022-06-30 20:56:31.911461
Epoch:[ 42 14 ] loss: 0.4534800052642822 2022-06-30 20:56:32.333235
Epoch:[ 42 15 ] loss: 0.449784517288208 2022-06-30 20:56:32.748198
Epoch:[ 42 16 ] loss: 0.45164889097213745 2022-06-30 20:56:38.196024
Epoch:[ 42 17 ] loss: 0.45059841871261597 2022-06-30 20:56:38.610574
Epoch:[ 42 18 ] loss: 0.4535536766052246 2022-06-30 20:56:39.030346
Epoch:[ 42 19 ] loss: 0.4545762836933136 2022-06-30 20:56:39.447562
Training_Epoch:[ 42 ] Training_loss: 0.45257702469825745 2022-06-30 20:56:39.448257
learning rate:  0.0020480000000000003
netparams have been saved once 42
val: 1 0.46492135524749756
val: 2 0.45546573400497437
val: 3 0.46939462423324585
val: 4 0.46011775732040405
val: 5 0.46228376030921936
val: 6 0.45864585041999817
val: 7 0.46468088030815125
val: 8 0.4639279544353485
val: 9 0.46093130111694336
val: 10 0.47248610854148865
val: 11 0.4673171043395996
val: 12 0.45142725110054016
val: 13 0.46537649631500244
val: 14 0.4630139470100403
val: 15 0.4599169194698334
val: 16 0.4625457227230072
val: 17 0.46188148856163025
val: 18 0.45542261004447937
val: 19 0.45085981488227844
val: 20 0.4604930579662323
val_Epoch:[ 42 ] val_loss: 0.4615554869174957 2022-06-30 20:56:42.842990
start training 2022-06-30 20:56:42.935704
Epoch:[ 43 0 ] loss: 0.45089393854141235 2022-06-30 20:56:56.538485
Epoch:[ 43 1 ] loss: 0.452668160200119 2022-06-30 20:56:57.153408
Epoch:[ 43 2 ] loss: 0.448647677898407 2022-06-30 20:56:57.573897
Epoch:[ 43 3 ] loss: 0.45226749777793884 2022-06-30 20:56:57.988829
Epoch:[ 43 4 ] loss: 0.45110374689102173 2022-06-30 20:56:58.402741
Epoch:[ 43 5 ] loss: 0.45603033900260925 2022-06-30 20:56:58.824772
Epoch:[ 43 6 ] loss: 0.4520206153392792 2022-06-30 20:56:59.245824
Epoch:[ 43 7 ] loss: 0.4537621736526489 2022-06-30 20:56:59.671265
Epoch:[ 43 8 ] loss: 0.45328792929649353 2022-06-30 20:57:00.085230
Epoch:[ 43 9 ] loss: 0.45135167241096497 2022-06-30 20:57:00.500183
Epoch:[ 43 10 ] loss: 0.45381906628608704 2022-06-30 20:57:00.916864
Epoch:[ 43 11 ] loss: 0.45174485445022583 2022-06-30 20:57:01.331138
Epoch:[ 43 12 ] loss: 0.4522705376148224 2022-06-30 20:57:01.748728
Epoch:[ 43 13 ] loss: 0.44979578256607056 2022-06-30 20:57:02.165667
Epoch:[ 43 14 ] loss: 0.44667261838912964 2022-06-30 20:57:02.586131
Epoch:[ 43 15 ] loss: 0.4507198929786682 2022-06-30 20:57:03.016233
Epoch:[ 43 16 ] loss: 0.4514068067073822 2022-06-30 20:57:08.888946
Epoch:[ 43 17 ] loss: 0.4497225284576416 2022-06-30 20:57:09.301790
Epoch:[ 43 18 ] loss: 0.45348814129829407 2022-06-30 20:57:09.716212
Epoch:[ 43 19 ] loss: 0.45111653208732605 2022-06-30 20:57:10.134037
Training_Epoch:[ 43 ] Training_loss: 0.4516395255923271 2022-06-30 20:57:10.134825
learning rate:  0.0020480000000000003
val: 1 0.45558255910873413
val: 2 0.45358583331108093
val: 3 0.4682808220386505
val: 4 0.46527957916259766
val: 5 0.4579439163208008
val: 6 0.464923620223999
val: 7 0.45590704679489136
val: 8 0.4556542932987213
val: 9 0.4595515727996826
val: 10 0.4684318006038666
val: 11 0.46356597542762756
val: 12 0.47214630246162415
val: 13 0.45843809843063354
val: 14 0.46224722266197205
val: 15 0.447657972574234
val: 16 0.4522031843662262
val: 17 0.4604012370109558
val: 18 0.45826420187950134
val: 19 0.46380186080932617
val: 20 0.46170589327812195
val_Epoch:[ 43 ] val_loss: 0.4602786496281624 2022-06-30 20:57:13.607105
start training 2022-06-30 20:57:13.702591
Epoch:[ 44 0 ] loss: 0.447128027677536 2022-06-30 20:57:27.877278
Epoch:[ 44 1 ] loss: 0.4466307461261749 2022-06-30 20:57:28.296183
Epoch:[ 44 2 ] loss: 0.4517107903957367 2022-06-30 20:57:28.711257
Epoch:[ 44 3 ] loss: 0.4471145570278168 2022-06-30 20:57:29.129084
Epoch:[ 44 4 ] loss: 0.4499998092651367 2022-06-30 20:57:29.544411
Epoch:[ 44 5 ] loss: 0.4485570788383484 2022-06-30 20:57:29.959261
Epoch:[ 44 6 ] loss: 0.45055249333381653 2022-06-30 20:57:30.376366
Epoch:[ 44 7 ] loss: 0.449369341135025 2022-06-30 20:57:30.799665
Epoch:[ 44 8 ] loss: 0.4485833942890167 2022-06-30 20:57:31.217593
Epoch:[ 44 9 ] loss: 0.45047932863235474 2022-06-30 20:57:31.632275
Epoch:[ 44 10 ] loss: 0.4520207345485687 2022-06-30 20:57:32.053600
Epoch:[ 44 11 ] loss: 0.44926849007606506 2022-06-30 20:57:32.489197
Epoch:[ 44 12 ] loss: 0.4506797790527344 2022-06-30 20:57:32.912219
Epoch:[ 44 13 ] loss: 0.4498428404331207 2022-06-30 20:57:33.329144
Epoch:[ 44 14 ] loss: 0.4540793299674988 2022-06-30 20:57:33.754341
Epoch:[ 44 15 ] loss: 0.4522073268890381 2022-06-30 20:57:34.180869
Epoch:[ 44 16 ] loss: 0.4515104591846466 2022-06-30 20:57:39.548159
Epoch:[ 44 17 ] loss: 0.45010876655578613 2022-06-30 20:57:39.962965
Epoch:[ 44 18 ] loss: 0.4505884051322937 2022-06-30 20:57:40.385506
Epoch:[ 44 19 ] loss: 0.45322829484939575 2022-06-30 20:57:40.801616
Training_Epoch:[ 44 ] Training_loss: 0.4501829996705055 2022-06-30 20:57:40.802408
learning rate:  0.0020480000000000003
netparams have been saved once 44
val: 1 0.46050626039505005
val: 2 0.4725767970085144
val: 3 0.46184995770454407
val: 4 0.4720796048641205
val: 5 0.46639588475227356
val: 6 0.47088170051574707
val: 7 0.4630788564682007
val: 8 0.4454304575920105
val: 9 0.45694637298583984
val: 10 0.4515455961227417
val: 11 0.4489901661872864
val: 12 0.47120362520217896
val: 13 0.4719085395336151
val: 14 0.45850542187690735
val: 15 0.4644666612148285
val: 16 0.45645231008529663
val: 17 0.45806950330734253
val: 18 0.4620710015296936
val: 19 0.4657042622566223
val: 20 0.4644647240638733
val_Epoch:[ 44 ] val_loss: 0.46215638518333435 2022-06-30 20:57:44.192270
start training 2022-06-30 20:57:44.286196
Epoch:[ 45 0 ] loss: 0.45245400071144104 2022-06-30 20:57:58.989513
Epoch:[ 45 1 ] loss: 0.44961005449295044 2022-06-30 20:57:59.405838
Epoch:[ 45 2 ] loss: 0.4478558599948883 2022-06-30 20:57:59.821214
Epoch:[ 45 3 ] loss: 0.44588717818260193 2022-06-30 20:58:00.236474
Epoch:[ 45 4 ] loss: 0.4494975805282593 2022-06-30 20:58:00.659806
Epoch:[ 45 5 ] loss: 0.44887298345565796 2022-06-30 20:58:01.079451
Epoch:[ 45 6 ] loss: 0.4476219117641449 2022-06-30 20:58:01.492559
Epoch:[ 45 7 ] loss: 0.4480326473712921 2022-06-30 20:58:01.910054
Epoch:[ 45 8 ] loss: 0.4476746618747711 2022-06-30 20:58:02.350043
Epoch:[ 45 9 ] loss: 0.449121356010437 2022-06-30 20:58:02.765514
Epoch:[ 45 10 ] loss: 0.44523048400878906 2022-06-30 20:58:03.179714
Epoch:[ 45 11 ] loss: 0.4535467028617859 2022-06-30 20:58:03.596034
Epoch:[ 45 12 ] loss: 0.45058879256248474 2022-06-30 20:58:04.016355
Epoch:[ 45 13 ] loss: 0.452658087015152 2022-06-30 20:58:04.436141
Epoch:[ 45 14 ] loss: 0.4482525587081909 2022-06-30 20:58:04.851349
Epoch:[ 45 15 ] loss: 0.44895368814468384 2022-06-30 20:58:05.267297
Epoch:[ 45 16 ] loss: 0.44757962226867676 2022-06-30 20:58:10.874348
Epoch:[ 45 17 ] loss: 0.45006561279296875 2022-06-30 20:58:11.287429
Epoch:[ 45 18 ] loss: 0.4529563784599304 2022-06-30 20:58:11.703874
Epoch:[ 45 19 ] loss: 0.4529378116130829 2022-06-30 20:58:12.119173
Training_Epoch:[ 45 ] Training_loss: 0.4494698986411095 2022-06-30 20:58:12.119876
learning rate:  0.0020480000000000003
val: 1 0.4720192849636078
val: 2 0.46016430854797363
val: 3 0.4530982971191406
val: 4 0.4653226435184479
val: 5 0.46795785427093506
val: 6 0.4648551940917969
val: 7 0.47842374444007874
val: 8 0.46184635162353516
val: 9 0.45802924036979675
val: 10 0.46276530623435974
val: 11 0.4583509564399719
val: 12 0.4593610167503357
val: 13 0.4638858139514923
val: 14 0.4652087688446045
val: 15 0.45619112253189087
val: 16 0.4593110680580139
val: 17 0.47375941276550293
val: 18 0.46289125084877014
val: 19 0.4606615900993347
val: 20 0.4611128568649292
val_Epoch:[ 45 ] val_loss: 0.46326080411672593 2022-06-30 20:58:15.485781
start training 2022-06-30 20:58:15.578706
Epoch:[ 46 0 ] loss: 0.4519957900047302 2022-06-30 20:58:29.340224
Epoch:[ 46 1 ] loss: 0.44604501128196716 2022-06-30 20:58:29.771638
Epoch:[ 46 2 ] loss: 0.44875839352607727 2022-06-30 20:58:30.188503
Epoch:[ 46 3 ] loss: 0.4521898329257965 2022-06-30 20:58:30.606659
Epoch:[ 46 4 ] loss: 0.4495442509651184 2022-06-30 20:58:31.021980
Epoch:[ 46 5 ] loss: 0.44834572076797485 2022-06-30 20:58:31.442849
Epoch:[ 46 6 ] loss: 0.4489685595035553 2022-06-30 20:58:31.860200
Epoch:[ 46 7 ] loss: 0.44572240114212036 2022-06-30 20:58:32.290326
Epoch:[ 46 8 ] loss: 0.44915223121643066 2022-06-30 20:58:32.714819
Epoch:[ 46 9 ] loss: 0.4490548074245453 2022-06-30 20:58:33.131768
Epoch:[ 46 10 ] loss: 0.4476226568222046 2022-06-30 20:58:33.549762
Epoch:[ 46 11 ] loss: 0.4522702693939209 2022-06-30 20:58:33.972015
Epoch:[ 46 12 ] loss: 0.4488562345504761 2022-06-30 20:58:34.386820
Epoch:[ 46 13 ] loss: 0.4519120752811432 2022-06-30 20:58:34.806890
Epoch:[ 46 14 ] loss: 0.44671082496643066 2022-06-30 20:58:35.227689
Epoch:[ 46 15 ] loss: 0.4471375644207001 2022-06-30 20:58:35.645087
Epoch:[ 46 16 ] loss: 0.44741061329841614 2022-06-30 20:58:41.088769
Epoch:[ 46 17 ] loss: 0.4492991268634796 2022-06-30 20:58:41.504854
Epoch:[ 46 18 ] loss: 0.4493427574634552 2022-06-30 20:58:41.920244
Epoch:[ 46 19 ] loss: 0.44624799489974976 2022-06-30 20:58:42.337603
Training_Epoch:[ 46 ] Training_loss: 0.4488293558359146 2022-06-30 20:58:42.338284
learning rate:  0.0020480000000000003
netparams have been saved once 46
val: 1 0.462658166885376
val: 2 0.45728155970573425
val: 3 0.4575708210468292
val: 4 0.45114824175834656
val: 5 0.4589657485485077
val: 6 0.45306146144866943
val: 7 0.4572175145149231
val: 8 0.4632014334201813
val: 9 0.4628527760505676
val: 10 0.4679204225540161
val: 11 0.47250068187713623
val: 12 0.46659591794013977
val: 13 0.4646666347980499
val: 14 0.46921607851982117
val: 15 0.46121105551719666
val: 16 0.4600527882575989
val: 17 0.46883270144462585
val: 18 0.4570876359939575
val: 19 0.45773255825042725
val: 20 0.4651395380496979
val_Epoch:[ 46 ] val_loss: 0.4617456868290901 2022-06-30 20:58:45.785952
start training 2022-06-30 20:58:45.877927
Epoch:[ 47 0 ] loss: 0.44412344694137573 2022-06-30 20:59:00.114652
Epoch:[ 47 1 ] loss: 0.45168229937553406 2022-06-30 20:59:00.528170
Epoch:[ 47 2 ] loss: 0.44941553473472595 2022-06-30 20:59:00.944202
Epoch:[ 47 3 ] loss: 0.446292906999588 2022-06-30 20:59:01.367523
Epoch:[ 47 4 ] loss: 0.4488070607185364 2022-06-30 20:59:01.799030
Epoch:[ 47 5 ] loss: 0.4484519362449646 2022-06-30 20:59:02.221473
Epoch:[ 47 6 ] loss: 0.44859153032302856 2022-06-30 20:59:02.637689
Epoch:[ 47 7 ] loss: 0.44916269183158875 2022-06-30 20:59:03.054086
Epoch:[ 47 8 ] loss: 0.4491579532623291 2022-06-30 20:59:03.474760
Epoch:[ 47 9 ] loss: 0.4483477473258972 2022-06-30 20:59:03.891356
Epoch:[ 47 10 ] loss: 0.44354352355003357 2022-06-30 20:59:04.305467
Epoch:[ 47 11 ] loss: 0.44829419255256653 2022-06-30 20:59:04.723227
Epoch:[ 47 12 ] loss: 0.4475845694541931 2022-06-30 20:59:05.140635
Epoch:[ 47 13 ] loss: 0.4500909745693207 2022-06-30 20:59:05.562702
Epoch:[ 47 14 ] loss: 0.44797375798225403 2022-06-30 20:59:05.983128
Epoch:[ 47 15 ] loss: 0.4522780478000641 2022-06-30 20:59:06.397854
Epoch:[ 47 16 ] loss: 0.4438006579875946 2022-06-30 20:59:12.115940
Epoch:[ 47 17 ] loss: 0.4460909366607666 2022-06-30 20:59:12.532565
Epoch:[ 47 18 ] loss: 0.4483857750892639 2022-06-30 20:59:12.960212
Epoch:[ 47 19 ] loss: 0.44722968339920044 2022-06-30 20:59:13.376849
Training_Epoch:[ 47 ] Training_loss: 0.4479652613401413 2022-06-30 20:59:13.377559
learning rate:  0.0020480000000000003
val: 1 0.46685072779655457
val: 2 0.4456283152103424
val: 3 0.46331435441970825
val: 4 0.4629657566547394
val: 5 0.461505264043808
val: 6 0.45329749584198
val: 7 0.45513176918029785
val: 8 0.46870478987693787
val: 9 0.4639970660209656
val: 10 0.46935710310935974
val: 11 0.44960978627204895
val: 12 0.4586656391620636
val: 13 0.4628744423389435
val: 14 0.45660400390625
val: 15 0.45691296458244324
val: 16 0.46730899810791016
val: 17 0.4594675600528717
val: 18 0.46190345287323
val: 19 0.452789843082428
val: 20 0.45692792534828186
val_Epoch:[ 47 ] val_loss: 0.45969086289405825 2022-06-30 20:59:16.784551
start training 2022-06-30 20:59:16.880050
Epoch:[ 48 0 ] loss: 0.44395044445991516 2022-06-30 20:59:30.557431
Epoch:[ 48 1 ] loss: 0.4484497010707855 2022-06-30 20:59:31.196544
Epoch:[ 48 2 ] loss: 0.44414058327674866 2022-06-30 20:59:31.628527
Epoch:[ 48 3 ] loss: 0.44473910331726074 2022-06-30 20:59:32.046114
Epoch:[ 48 4 ] loss: 0.44252434372901917 2022-06-30 20:59:32.462571
Epoch:[ 48 5 ] loss: 0.4478558599948883 2022-06-30 20:59:32.879836
Epoch:[ 48 6 ] loss: 0.44556060433387756 2022-06-30 20:59:33.301193
Epoch:[ 48 7 ] loss: 0.44707784056663513 2022-06-30 20:59:33.716871
Epoch:[ 48 8 ] loss: 0.44499245285987854 2022-06-30 20:59:34.131855
Epoch:[ 48 9 ] loss: 0.44952020049095154 2022-06-30 20:59:34.554460
Epoch:[ 48 10 ] loss: 0.4497263431549072 2022-06-30 20:59:34.977914
Epoch:[ 48 11 ] loss: 0.44936317205429077 2022-06-30 20:59:35.395662
Epoch:[ 48 12 ] loss: 0.45091041922569275 2022-06-30 20:59:35.813530
Epoch:[ 48 13 ] loss: 0.4506288766860962 2022-06-30 20:59:36.234769
Epoch:[ 48 14 ] loss: 0.444495290517807 2022-06-30 20:59:36.650238
Epoch:[ 48 15 ] loss: 0.4478874206542969 2022-06-30 20:59:37.070838
Epoch:[ 48 16 ] loss: 0.44850045442581177 2022-06-30 20:59:42.291053
Epoch:[ 48 17 ] loss: 0.448714017868042 2022-06-30 20:59:42.887208
Epoch:[ 48 18 ] loss: 0.4458865821361542 2022-06-30 20:59:43.305630
Epoch:[ 48 19 ] loss: 0.449798047542572 2022-06-30 20:59:43.723058
Training_Epoch:[ 48 ] Training_loss: 0.44723608791828157 2022-06-30 20:59:43.723767
learning rate:  0.0020480000000000003
netparams have been saved once 48
val: 1 0.46077823638916016
val: 2 0.4706942141056061
val: 3 0.46074944734573364
val: 4 0.46562933921813965
val: 5 0.46976959705352783
val: 6 0.4497550129890442
val: 7 0.46253594756126404
val: 8 0.46292516589164734
val: 9 0.46171191334724426
val: 10 0.4483516812324524
val: 11 0.4672299921512604
val: 12 0.44851958751678467
val: 13 0.45334097743034363
val: 14 0.46413448452949524
val: 15 0.46012935042381287
val: 16 0.4612483084201813
val: 17 0.47029998898506165
val: 18 0.46183040738105774
val: 19 0.45656439661979675
val: 20 0.4579567313194275
val_Epoch:[ 48 ] val_loss: 0.46070773899555206 2022-06-30 20:59:47.111804
start training 2022-06-30 20:59:47.206567
Epoch:[ 49 0 ] loss: 0.44750696420669556 2022-06-30 21:00:01.510908
Epoch:[ 49 1 ] loss: 0.44811132550239563 2022-06-30 21:00:01.924913
Epoch:[ 49 2 ] loss: 0.4475717842578888 2022-06-30 21:00:02.344815
Epoch:[ 49 3 ] loss: 0.4477144181728363 2022-06-30 21:00:02.763908
Epoch:[ 49 4 ] loss: 0.4494374394416809 2022-06-30 21:00:03.185822
Epoch:[ 49 5 ] loss: 0.45152702927589417 2022-06-30 21:00:03.602087
Epoch:[ 49 6 ] loss: 0.4478541314601898 2022-06-30 21:00:04.025044
Epoch:[ 49 7 ] loss: 0.44531574845314026 2022-06-30 21:00:04.441412
Epoch:[ 49 8 ] loss: 0.45086541771888733 2022-06-30 21:00:04.856651
Epoch:[ 49 9 ] loss: 0.44311776757240295 2022-06-30 21:00:05.279903
Epoch:[ 49 10 ] loss: 0.4460693299770355 2022-06-30 21:00:05.693460
Epoch:[ 49 11 ] loss: 0.44629374146461487 2022-06-30 21:00:06.111294
Epoch:[ 49 12 ] loss: 0.4488566517829895 2022-06-30 21:00:06.528635
Epoch:[ 49 13 ] loss: 0.44460877776145935 2022-06-30 21:00:06.944159
Epoch:[ 49 14 ] loss: 0.44346147775650024 2022-06-30 21:00:07.366070
Epoch:[ 49 15 ] loss: 0.44375285506248474 2022-06-30 21:00:07.782156
Epoch:[ 49 16 ] loss: 0.44554275274276733 2022-06-30 21:00:13.829739
Epoch:[ 49 17 ] loss: 0.4438231289386749 2022-06-30 21:00:14.244036
Epoch:[ 49 18 ] loss: 0.4493747651576996 2022-06-30 21:00:14.662157
Epoch:[ 49 19 ] loss: 0.44697096943855286 2022-06-30 21:00:15.079033
Training_Epoch:[ 49 ] Training_loss: 0.44688882380723954 2022-06-30 21:00:15.079803
learning rate:  0.0020480000000000003
val: 1 0.46502214670181274
val: 2 0.4701627492904663
val: 3 0.4637642502784729
val: 4 0.4639251232147217
val: 5 0.4664427638053894
val: 6 0.4664152264595032
val: 7 0.4687712788581848
val: 8 0.469981849193573
val: 9 0.4622044265270233
val: 10 0.45329713821411133
val: 11 0.4700615406036377
val: 12 0.4675745964050293
val: 13 0.4533267319202423
val: 14 0.46391561627388
val: 15 0.4589461386203766
val: 16 0.469027042388916
val: 17 0.45997071266174316
val: 18 0.4660298526287079
val: 19 0.46391087770462036
val: 20 0.4801599681377411
val_Epoch:[ 49 ] val_loss: 0.46514550149440764 2022-06-30 21:00:18.420889
start training 2022-06-30 21:00:18.516994
Epoch:[ 50 0 ] loss: 0.4468778669834137 2022-06-30 21:00:32.220118
Epoch:[ 50 1 ] loss: 0.44396480917930603 2022-06-30 21:00:32.650372
Epoch:[ 50 2 ] loss: 0.4470749795436859 2022-06-30 21:00:33.066213
Epoch:[ 50 3 ] loss: 0.4481598436832428 2022-06-30 21:00:33.482945
Epoch:[ 50 4 ] loss: 0.44691938161849976 2022-06-30 21:00:33.909856
Epoch:[ 50 5 ] loss: 0.44525080919265747 2022-06-30 21:00:34.334639
Epoch:[ 50 6 ] loss: 0.446176677942276 2022-06-30 21:00:34.750569
Epoch:[ 50 7 ] loss: 0.44620034098625183 2022-06-30 21:00:35.167875
Epoch:[ 50 8 ] loss: 0.4490690231323242 2022-06-30 21:00:35.586230
Epoch:[ 50 9 ] loss: 0.44645756483078003 2022-06-30 21:00:36.002920
Epoch:[ 50 10 ] loss: 0.44570741057395935 2022-06-30 21:00:36.426126
Epoch:[ 50 11 ] loss: 0.4514307379722595 2022-06-30 21:00:36.844334
Epoch:[ 50 12 ] loss: 0.4475536644458771 2022-06-30 21:00:37.268966
Epoch:[ 50 13 ] loss: 0.4444446563720703 2022-06-30 21:00:37.692685
Epoch:[ 50 14 ] loss: 0.450458288192749 2022-06-30 21:00:38.112559
Epoch:[ 50 15 ] loss: 0.44555768370628357 2022-06-30 21:00:38.528729
Epoch:[ 50 16 ] loss: 0.4474583864212036 2022-06-30 21:00:44.000936
Epoch:[ 50 17 ] loss: 0.44618260860443115 2022-06-30 21:00:44.415894
Epoch:[ 50 18 ] loss: 0.44843700528144836 2022-06-30 21:00:44.831720
Epoch:[ 50 19 ] loss: 0.4488352835178375 2022-06-30 21:00:45.248049
Training_Epoch:[ 50 ] Training_loss: 0.4471108511090279 2022-06-30 21:00:45.248783
learning rate:  0.0020480000000000003
netparams have been saved once 50
val: 1 0.45665183663368225
val: 2 0.4539320766925812
val: 3 0.44703638553619385
val: 4 0.453075110912323
val: 5 0.45442983508110046
val: 6 0.4606139063835144
val: 7 0.4605698883533478
val: 8 0.4602060616016388
val: 9 0.45962151885032654
val: 10 0.46029335260391235
val: 11 0.44838252663612366
val: 12 0.4575929641723633
val: 13 0.4499872624874115
val: 14 0.4551764726638794
val: 15 0.4685606062412262
val: 16 0.4560459554195404
val: 17 0.46167582273483276
val: 18 0.4575192332267761
val: 19 0.46357160806655884
val: 20 0.4536072611808777
val_Epoch:[ 50 ] val_loss: 0.4569274842739105 2022-06-30 21:00:48.706603
start training 2022-06-30 21:00:48.802349
Epoch:[ 51 0 ] loss: 0.444169819355011 2022-06-30 21:01:03.374665
Epoch:[ 51 1 ] loss: 0.4434715211391449 2022-06-30 21:01:03.807589
Epoch:[ 51 2 ] loss: 0.44436919689178467 2022-06-30 21:01:04.226935
Epoch:[ 51 3 ] loss: 0.4455426037311554 2022-06-30 21:01:04.643301
Epoch:[ 51 4 ] loss: 0.443645179271698 2022-06-30 21:01:05.061097
Epoch:[ 51 5 ] loss: 0.44192710518836975 2022-06-30 21:01:05.476818
Epoch:[ 51 6 ] loss: 0.44458067417144775 2022-06-30 21:01:05.893375
Epoch:[ 51 7 ] loss: 0.44158947467803955 2022-06-30 21:01:06.309484
Epoch:[ 51 8 ] loss: 0.44355958700180054 2022-06-30 21:01:06.724398
Epoch:[ 51 9 ] loss: 0.44344815611839294 2022-06-30 21:01:07.146087
Epoch:[ 51 10 ] loss: 0.44259747862815857 2022-06-30 21:01:07.565563
Epoch:[ 51 11 ] loss: 0.4444825053215027 2022-06-30 21:01:07.981090
Epoch:[ 51 12 ] loss: 0.44494178891181946 2022-06-30 21:01:08.400681
Epoch:[ 51 13 ] loss: 0.44089579582214355 2022-06-30 21:01:08.818042
Epoch:[ 51 14 ] loss: 0.44883403182029724 2022-06-30 21:01:09.234488
Epoch:[ 51 15 ] loss: 0.4465932250022888 2022-06-30 21:01:09.657737
Epoch:[ 51 16 ] loss: 0.44382765889167786 2022-06-30 21:01:14.979728
Epoch:[ 51 17 ] loss: 0.44353169202804565 2022-06-30 21:01:15.393181
Epoch:[ 51 18 ] loss: 0.44794851541519165 2022-06-30 21:01:15.807530
Epoch:[ 51 19 ] loss: 0.4432877004146576 2022-06-30 21:01:16.222946
Training_Epoch:[ 51 ] Training_loss: 0.44416218549013137 2022-06-30 21:01:16.223644
learning rate:  0.0016384000000000004
val: 1 0.4499886929988861
val: 2 0.45664316415786743
val: 3 0.4543023705482483
val: 4 0.45660895109176636
val: 5 0.45944586396217346
val: 6 0.4596484899520874
val: 7 0.4571082890033722
val: 8 0.45908287167549133
val: 9 0.4527713656425476
val: 10 0.45458945631980896
val: 11 0.4542334973812103
val: 12 0.46295639872550964
val: 13 0.4548216164112091
val: 14 0.44875794649124146
val: 15 0.4618355333805084
val: 16 0.4637126624584198
val: 17 0.4578521251678467
val: 18 0.45737332105636597
val: 19 0.4588734209537506
val: 20 0.45996689796447754
val_Epoch:[ 51 ] val_loss: 0.45702864676713945 2022-06-30 21:01:19.576721
start training 2022-06-30 21:01:19.672883
Epoch:[ 52 0 ] loss: 0.44267594814300537 2022-06-30 21:01:33.232633
Epoch:[ 52 1 ] loss: 0.44623544812202454 2022-06-30 21:01:33.666343
Epoch:[ 52 2 ] loss: 0.4430922269821167 2022-06-30 21:01:34.104301
Epoch:[ 52 3 ] loss: 0.4453938901424408 2022-06-30 21:01:34.542066
Epoch:[ 52 4 ] loss: 0.438854455947876 2022-06-30 21:01:34.955883
Epoch:[ 52 5 ] loss: 0.4373582899570465 2022-06-30 21:01:35.377036
Epoch:[ 52 6 ] loss: 0.4426575005054474 2022-06-30 21:01:35.790185
Epoch:[ 52 7 ] loss: 0.4403200149536133 2022-06-30 21:01:36.213911
Epoch:[ 52 8 ] loss: 0.44209060072898865 2022-06-30 21:01:36.632684
Epoch:[ 52 9 ] loss: 0.4412665367126465 2022-06-30 21:01:37.047212
Epoch:[ 52 10 ] loss: 0.4383282959461212 2022-06-30 21:01:37.460944
Epoch:[ 52 11 ] loss: 0.4396171569824219 2022-06-30 21:01:37.878754
Epoch:[ 52 12 ] loss: 0.4397352337837219 2022-06-30 21:01:38.293016
Epoch:[ 52 13 ] loss: 0.44410157203674316 2022-06-30 21:01:38.706754
Epoch:[ 52 14 ] loss: 0.44312456250190735 2022-06-30 21:01:39.122034
Epoch:[ 52 15 ] loss: 0.44245830178260803 2022-06-30 21:01:39.543873
Epoch:[ 52 16 ] loss: 0.44224798679351807 2022-06-30 21:01:45.001460
Epoch:[ 52 17 ] loss: 0.44444963335990906 2022-06-30 21:01:45.440958
Epoch:[ 52 18 ] loss: 0.44159361720085144 2022-06-30 21:01:46.187551
Epoch:[ 52 19 ] loss: 0.4428749680519104 2022-06-30 21:01:46.602207
Training_Epoch:[ 52 ] Training_loss: 0.4419238120317459 2022-06-30 21:01:46.602884
learning rate:  0.0016384000000000004
netparams have been saved once 52
val: 1 0.44950562715530396
val: 2 0.4459328353404999
val: 3 0.45596399903297424
val: 4 0.4543856680393219
val: 5 0.45192471146583557
val: 6 0.4568890631198883
val: 7 0.46943241357803345
val: 8 0.45180100202560425
val: 9 0.46255743503570557
val: 10 0.4676160216331482
val: 11 0.466063529253006
val: 12 0.4517230987548828
val: 13 0.4595155715942383
val: 14 0.46381646394729614
val: 15 0.45756566524505615
val: 16 0.4521729052066803
val: 17 0.4554668962955475
val: 18 0.4505167603492737
val: 19 0.4512488842010498
val: 20 0.4564802646636963
val_Epoch:[ 52 ] val_loss: 0.45652894079685213 2022-06-30 21:01:50.041996
start training 2022-06-30 21:01:50.136768
Epoch:[ 53 0 ] loss: 0.44157174229621887 2022-06-30 21:02:04.346147
Epoch:[ 53 1 ] loss: 0.4404304623603821 2022-06-30 21:02:04.778466
Epoch:[ 53 2 ] loss: 0.44241878390312195 2022-06-30 21:02:05.194941
Epoch:[ 53 3 ] loss: 0.44178617000579834 2022-06-30 21:02:05.612183
Epoch:[ 53 4 ] loss: 0.43945255875587463 2022-06-30 21:02:06.027626
Epoch:[ 53 5 ] loss: 0.4390712380409241 2022-06-30 21:02:06.442915
Epoch:[ 53 6 ] loss: 0.44176286458969116 2022-06-30 21:02:06.860326
Epoch:[ 53 7 ] loss: 0.44394204020500183 2022-06-30 21:02:07.283400
Epoch:[ 53 8 ] loss: 0.4419310986995697 2022-06-30 21:02:07.707088
Epoch:[ 53 9 ] loss: 0.4393066465854645 2022-06-30 21:02:08.124995
Epoch:[ 53 10 ] loss: 0.44231492280960083 2022-06-30 21:02:08.539530
Epoch:[ 53 11 ] loss: 0.4385010600090027 2022-06-30 21:02:08.961130
Epoch:[ 53 12 ] loss: 0.4401509463787079 2022-06-30 21:02:09.376659
Epoch:[ 53 13 ] loss: 0.44000160694122314 2022-06-30 21:02:09.797874
Epoch:[ 53 14 ] loss: 0.4429989457130432 2022-06-30 21:02:10.218217
Epoch:[ 53 15 ] loss: 0.4444746673107147 2022-06-30 21:02:10.636274
Epoch:[ 53 16 ] loss: 0.4394513964653015 2022-06-30 21:02:16.023707
Epoch:[ 53 17 ] loss: 0.4411572217941284 2022-06-30 21:02:16.437967
Epoch:[ 53 18 ] loss: 0.4359517991542816 2022-06-30 21:02:16.854070
Epoch:[ 53 19 ] loss: 0.4424561560153961 2022-06-30 21:02:17.287572
Training_Epoch:[ 53 ] Training_loss: 0.4409566164016724 2022-06-30 21:02:17.288213
learning rate:  0.0016384000000000004
val: 1 0.4557052254676819
val: 2 0.45856669545173645
val: 3 0.46055877208709717
val: 4 0.46334344148635864
val: 5 0.4719826579093933
val: 6 0.45867404341697693
val: 7 0.4592158794403076
val: 8 0.4561287760734558
val: 9 0.458475261926651
val: 10 0.45249128341674805
val: 11 0.46246063709259033
val: 12 0.4587389826774597
val: 13 0.4607158899307251
val: 14 0.45762893557548523
val: 15 0.4500502049922943
val: 16 0.4432046711444855
val: 17 0.4555402994155884
val: 18 0.4590913951396942
val: 19 0.44907811284065247
val: 20 0.4570903182029724
val_Epoch:[ 53 ] val_loss: 0.4574370741844177 2022-06-30 21:02:20.636469
start training 2022-06-30 21:02:20.732059
Epoch:[ 54 0 ] loss: 0.4377674162387848 2022-06-30 21:02:34.594180
Epoch:[ 54 1 ] loss: 0.43997886776924133 2022-06-30 21:02:35.034752
Epoch:[ 54 2 ] loss: 0.443665474653244 2022-06-30 21:02:35.453968
Epoch:[ 54 3 ] loss: 0.44017288088798523 2022-06-30 21:02:35.876643
Epoch:[ 54 4 ] loss: 0.44408106803894043 2022-06-30 21:02:36.291920
Epoch:[ 54 5 ] loss: 0.44408920407295227 2022-06-30 21:02:36.710159
Epoch:[ 54 6 ] loss: 0.4404589533805847 2022-06-30 21:02:37.127830
Epoch:[ 54 7 ] loss: 0.44515135884284973 2022-06-30 21:02:37.549353
Epoch:[ 54 8 ] loss: 0.43731924891471863 2022-06-30 21:02:37.964357
Epoch:[ 54 9 ] loss: 0.44019216299057007 2022-06-30 21:02:38.381324
Epoch:[ 54 10 ] loss: 0.43912968039512634 2022-06-30 21:02:38.797438
Epoch:[ 54 11 ] loss: 0.4417193830013275 2022-06-30 21:02:39.214721
Epoch:[ 54 12 ] loss: 0.44094833731651306 2022-06-30 21:02:39.635715
Epoch:[ 54 13 ] loss: 0.4389875531196594 2022-06-30 21:02:40.057861
Epoch:[ 54 14 ] loss: 0.4402807652950287 2022-06-30 21:02:40.473082
Epoch:[ 54 15 ] loss: 0.4420444965362549 2022-06-30 21:02:40.895050
Epoch:[ 54 16 ] loss: 0.44191259145736694 2022-06-30 21:02:46.286740
Epoch:[ 54 17 ] loss: 0.4357197880744934 2022-06-30 21:02:46.731112
Epoch:[ 54 18 ] loss: 0.43876686692237854 2022-06-30 21:02:47.155661
Epoch:[ 54 19 ] loss: 0.4391637146472931 2022-06-30 21:02:47.572103
Training_Epoch:[ 54 ] Training_loss: 0.44057749062776563 2022-06-30 21:02:47.572835
learning rate:  0.0016384000000000004
netparams have been saved once 54
val: 1 0.4555087387561798
val: 2 0.4472787380218506
val: 3 0.4555342197418213
val: 4 0.46586674451828003
val: 5 0.4537108242511749
val: 6 0.4640711545944214
val: 7 0.4694070518016815
val: 8 0.45425593852996826
val: 9 0.4541248381137848
val: 10 0.46332696080207825
val: 11 0.458695650100708
val: 12 0.4529377818107605
val: 13 0.45524686574935913
val: 14 0.4555663466453552
val: 15 0.4509187340736389
val: 16 0.45771414041519165
val: 17 0.44964393973350525
val: 18 0.45241525769233704
val: 19 0.4510769546031952
val: 20 0.4620957672595978
val_Epoch:[ 54 ] val_loss: 0.45646983236074445 2022-06-30 21:02:50.971424
start training 2022-06-30 21:02:51.070821
Epoch:[ 55 0 ] loss: 0.43943849205970764 2022-06-30 21:03:05.741792
Epoch:[ 55 1 ] loss: 0.4392649531364441 2022-06-30 21:03:06.161983
Epoch:[ 55 2 ] loss: 0.4386395812034607 2022-06-30 21:03:06.576470
Epoch:[ 55 3 ] loss: 0.4357852041721344 2022-06-30 21:03:06.993811
Epoch:[ 55 4 ] loss: 0.4368983507156372 2022-06-30 21:03:07.410694
Epoch:[ 55 5 ] loss: 0.43651068210601807 2022-06-30 21:03:07.825397
Epoch:[ 55 6 ] loss: 0.43687719106674194 2022-06-30 21:03:08.242784
Epoch:[ 55 7 ] loss: 0.4411134421825409 2022-06-30 21:03:08.664499
Epoch:[ 55 8 ] loss: 0.440458208322525 2022-06-30 21:03:09.080043
Epoch:[ 55 9 ] loss: 0.4402609169483185 2022-06-30 21:03:09.497242
Epoch:[ 55 10 ] loss: 0.4413447976112366 2022-06-30 21:03:09.919032
Epoch:[ 55 11 ] loss: 0.44026562571525574 2022-06-30 21:03:10.341654
Epoch:[ 55 12 ] loss: 0.4413197338581085 2022-06-30 21:03:10.765432
Epoch:[ 55 13 ] loss: 0.44135695695877075 2022-06-30 21:03:11.179736
Epoch:[ 55 14 ] loss: 0.44056111574172974 2022-06-30 21:03:11.599840
Epoch:[ 55 15 ] loss: 0.440170556306839 2022-06-30 21:03:12.019670
Epoch:[ 55 16 ] loss: 0.43861842155456543 2022-06-30 21:03:17.788158
Epoch:[ 55 17 ] loss: 0.44427627325057983 2022-06-30 21:03:18.203997
Epoch:[ 55 18 ] loss: 0.440459281206131 2022-06-30 21:03:18.621194
Epoch:[ 55 19 ] loss: 0.4412076473236084 2022-06-30 21:03:19.039778
Training_Epoch:[ 55 ] Training_loss: 0.43974137157201765 2022-06-30 21:03:19.040498
learning rate:  0.0016384000000000004
val: 1 0.45418211817741394
val: 2 0.46068206429481506
val: 3 0.46000558137893677
val: 4 0.4542422890663147
val: 5 0.4604742228984833
val: 6 0.4676456153392792
val: 7 0.4528391659259796
val: 8 0.46433186531066895
val: 9 0.4620751142501831
val: 10 0.45455244183540344
val: 11 0.46135419607162476
val: 12 0.4549734890460968
val: 13 0.45654812455177307
val: 14 0.4617132246494293
val: 15 0.45329761505126953
val: 16 0.46523991227149963
val: 17 0.460344523191452
val: 18 0.45421668887138367
val: 19 0.46957647800445557
val: 20 0.4565255641937256
val_Epoch:[ 55 ] val_loss: 0.4592410147190094 2022-06-30 21:03:22.408537
start training 2022-06-30 21:03:22.505345
Epoch:[ 56 0 ] loss: 0.4391428530216217 2022-06-30 21:03:37.027384
Epoch:[ 56 1 ] loss: 0.4386615753173828 2022-06-30 21:03:37.466192
Epoch:[ 56 2 ] loss: 0.43820032477378845 2022-06-30 21:03:37.883384
Epoch:[ 56 3 ] loss: 0.43944063782691956 2022-06-30 21:03:38.298497
Epoch:[ 56 4 ] loss: 0.4404641389846802 2022-06-30 21:03:38.714708
Epoch:[ 56 5 ] loss: 0.4433978199958801 2022-06-30 21:03:39.130666
Epoch:[ 56 6 ] loss: 0.44201022386550903 2022-06-30 21:03:39.552609
Epoch:[ 56 7 ] loss: 0.44046151638031006 2022-06-30 21:03:39.968387
Epoch:[ 56 8 ] loss: 0.44020265340805054 2022-06-30 21:03:40.391760
Epoch:[ 56 9 ] loss: 0.4386393129825592 2022-06-30 21:03:40.808094
Epoch:[ 56 10 ] loss: 0.44240716099739075 2022-06-30 21:03:41.222047
Epoch:[ 56 11 ] loss: 0.43837544322013855 2022-06-30 21:03:41.638992
Epoch:[ 56 12 ] loss: 0.4397191107273102 2022-06-30 21:03:42.062089
Epoch:[ 56 13 ] loss: 0.4407765567302704 2022-06-30 21:03:42.480548
Epoch:[ 56 14 ] loss: 0.43701693415641785 2022-06-30 21:03:42.896521
Epoch:[ 56 15 ] loss: 0.4406236708164215 2022-06-30 21:03:43.313221
Epoch:[ 56 16 ] loss: 0.4444909393787384 2022-06-30 21:03:49.111365
Epoch:[ 56 17 ] loss: 0.43817412853240967 2022-06-30 21:03:49.528502
Epoch:[ 56 18 ] loss: 0.4370937943458557 2022-06-30 21:03:49.947249
Epoch:[ 56 19 ] loss: 0.4414731562137604 2022-06-30 21:03:50.364531
Training_Epoch:[ 56 ] Training_loss: 0.44003859758377073 2022-06-30 21:03:50.365369
learning rate:  0.0016384000000000004
netparams have been saved once 56
val: 1 0.44874730706214905
val: 2 0.45847287774086
val: 3 0.46448051929473877
val: 4 0.4619067907333374
val: 5 0.45812541246414185
val: 6 0.45678719878196716
val: 7 0.4563189744949341
val: 8 0.45965129137039185
val: 9 0.4573220908641815
val: 10 0.4473239481449127
val: 11 0.4545975625514984
val: 12 0.44855839014053345
val: 13 0.45567595958709717
val: 14 0.44879624247550964
val: 15 0.4622659981250763
val: 16 0.44586968421936035
val: 17 0.45880427956581116
val: 18 0.4660148620605469
val: 19 0.45505502820014954
val: 20 0.4501073360443115
val_Epoch:[ 56 ] val_loss: 0.45574408769607544 2022-06-30 21:03:53.857836
start training 2022-06-30 21:03:53.955493
Epoch:[ 57 0 ] loss: 0.43749141693115234 2022-06-30 21:04:08.373557
Epoch:[ 57 1 ] loss: 0.43805962800979614 2022-06-30 21:04:09.032438
Epoch:[ 57 2 ] loss: 0.43781086802482605 2022-06-30 21:04:09.449677
Epoch:[ 57 3 ] loss: 0.43742838501930237 2022-06-30 21:04:09.864690
Epoch:[ 57 4 ] loss: 0.43709251284599304 2022-06-30 21:04:10.278017
Epoch:[ 57 5 ] loss: 0.4375969469547272 2022-06-30 21:04:10.700691
Epoch:[ 57 6 ] loss: 0.4363599717617035 2022-06-30 21:04:11.134844
Epoch:[ 57 7 ] loss: 0.4373260736465454 2022-06-30 21:04:11.553518
Epoch:[ 57 8 ] loss: 0.44022801518440247 2022-06-30 21:04:11.967785
Epoch:[ 57 9 ] loss: 0.43772071599960327 2022-06-30 21:04:12.382653
Epoch:[ 57 10 ] loss: 0.43996599316596985 2022-06-30 21:04:12.804444
Epoch:[ 57 11 ] loss: 0.4405882656574249 2022-06-30 21:04:13.221023
Epoch:[ 57 12 ] loss: 0.44111379981040955 2022-06-30 21:04:13.638225
Epoch:[ 57 13 ] loss: 0.4393564760684967 2022-06-30 21:04:14.060633
Epoch:[ 57 14 ] loss: 0.4393314719200134 2022-06-30 21:04:14.477414
Epoch:[ 57 15 ] loss: 0.4373147487640381 2022-06-30 21:04:14.900482
Epoch:[ 57 16 ] loss: 0.44139564037323 2022-06-30 21:04:19.875780
Epoch:[ 57 17 ] loss: 0.4336443245410919 2022-06-30 21:04:20.523472
Epoch:[ 57 18 ] loss: 0.44219210743904114 2022-06-30 21:04:20.938082
Epoch:[ 57 19 ] loss: 0.44118359684944153 2022-06-30 21:04:21.354999
Training_Epoch:[ 57 ] Training_loss: 0.43866004794836044 2022-06-30 21:04:21.355771
learning rate:  0.0016384000000000004
val: 1 0.4514220058917999
val: 2 0.462446004152298
val: 3 0.4517991542816162
val: 4 0.4660579562187195
val: 5 0.44972455501556396
val: 6 0.4692234992980957
val: 7 0.45171117782592773
val: 8 0.4593806564807892
val: 9 0.44643330574035645
val: 10 0.4603193700313568
val: 11 0.45170658826828003
val: 12 0.447870671749115
val: 13 0.4525344669818878
val: 14 0.4545089602470398
val: 15 0.4529978930950165
val: 16 0.46464285254478455
val: 17 0.45774373412132263
val: 18 0.45243141055107117
val: 19 0.4565339684486389
val: 20 0.4580552279949188
val_Epoch:[ 57 ] val_loss: 0.4558771729469299 2022-06-30 21:04:24.817763
start training 2022-06-30 21:04:24.916878
Epoch:[ 58 0 ] loss: 0.43981918692588806 2022-06-30 21:04:39.173270
Epoch:[ 58 1 ] loss: 0.4415031373500824 2022-06-30 21:04:39.620745
Epoch:[ 58 2 ] loss: 0.4345356822013855 2022-06-30 21:04:40.036445
Epoch:[ 58 3 ] loss: 0.43986794352531433 2022-06-30 21:04:40.452994
Epoch:[ 58 4 ] loss: 0.43923068046569824 2022-06-30 21:04:40.869878
Epoch:[ 58 5 ] loss: 0.4372183680534363 2022-06-30 21:04:41.287557
Epoch:[ 58 6 ] loss: 0.4366358518600464 2022-06-30 21:04:41.704757
Epoch:[ 58 7 ] loss: 0.4363356828689575 2022-06-30 21:04:42.121860
Epoch:[ 58 8 ] loss: 0.4389687478542328 2022-06-30 21:04:42.545374
Epoch:[ 58 9 ] loss: 0.43684282898902893 2022-06-30 21:04:42.966504
Epoch:[ 58 10 ] loss: 0.4393574297428131 2022-06-30 21:04:43.387221
Epoch:[ 58 11 ] loss: 0.4354555904865265 2022-06-30 21:04:43.822911
Epoch:[ 58 12 ] loss: 0.43947190046310425 2022-06-30 21:04:44.242787
Epoch:[ 58 13 ] loss: 0.44151437282562256 2022-06-30 21:04:44.662449
Epoch:[ 58 14 ] loss: 0.4395146071910858 2022-06-30 21:04:45.080772
Epoch:[ 58 15 ] loss: 0.4398476779460907 2022-06-30 21:04:45.501195
Epoch:[ 58 16 ] loss: 0.44103601574897766 2022-06-30 21:04:50.894600
Epoch:[ 58 17 ] loss: 0.43802696466445923 2022-06-30 21:04:51.312627
Epoch:[ 58 18 ] loss: 0.4466066360473633 2022-06-30 21:04:51.731329
Epoch:[ 58 19 ] loss: 0.4407593607902527 2022-06-30 21:04:52.149153
Training_Epoch:[ 58 ] Training_loss: 0.4391274333000183 2022-06-30 21:04:52.149989
learning rate:  0.0016384000000000004
netparams have been saved once 58
val: 1 0.4571203291416168
val: 2 0.4637254476547241
val: 3 0.46123695373535156
val: 4 0.45116037130355835
val: 5 0.44467398524284363
val: 6 0.4735632538795471
val: 7 0.47802966833114624
val: 8 0.4706059694290161
val: 9 0.460527241230011
val: 10 0.4632578194141388
val: 11 0.45631644129753113
val: 12 0.45566776394844055
val: 13 0.4578132927417755
val: 14 0.46258220076560974
val: 15 0.47150692343711853
val: 16 0.4475914537906647
val: 17 0.4598643183708191
val: 18 0.4614188075065613
val: 19 0.4710156321525574
val: 20 0.46239107847213745
val_Epoch:[ 58 ] val_loss: 0.4615034475922585 2022-06-30 21:04:55.613195
start training 2022-06-30 21:04:55.712483
Epoch:[ 59 0 ] loss: 0.44333764910697937 2022-06-30 21:05:09.588585
Epoch:[ 59 1 ] loss: 0.43835151195526123 2022-06-30 21:05:10.311302
Epoch:[ 59 2 ] loss: 0.43910178542137146 2022-06-30 21:05:10.725664
Epoch:[ 59 3 ] loss: 0.4384534955024719 2022-06-30 21:05:11.149307
Epoch:[ 59 4 ] loss: 0.43810373544692993 2022-06-30 21:05:11.566748
Epoch:[ 59 5 ] loss: 0.43493422865867615 2022-06-30 21:05:11.981819
Epoch:[ 59 6 ] loss: 0.43663689494132996 2022-06-30 21:05:12.413230
Epoch:[ 59 7 ] loss: 0.4392855167388916 2022-06-30 21:05:12.838707
Epoch:[ 59 8 ] loss: 0.4365062713623047 2022-06-30 21:05:13.258854
Epoch:[ 59 9 ] loss: 0.43625208735466003 2022-06-30 21:05:13.675467
Epoch:[ 59 10 ] loss: 0.4412737786769867 2022-06-30 21:05:14.093097
Epoch:[ 59 11 ] loss: 0.4351528584957123 2022-06-30 21:05:14.515448
Epoch:[ 59 12 ] loss: 0.4364941418170929 2022-06-30 21:05:14.931375
Epoch:[ 59 13 ] loss: 0.43565890192985535 2022-06-30 21:05:15.346379
Epoch:[ 59 14 ] loss: 0.43588724732398987 2022-06-30 21:05:15.764461
Epoch:[ 59 15 ] loss: 0.44112658500671387 2022-06-30 21:05:16.179761
Epoch:[ 59 16 ] loss: 0.43734753131866455 2022-06-30 21:05:21.292008
Epoch:[ 59 17 ] loss: 0.4344296157360077 2022-06-30 21:05:21.976540
Epoch:[ 59 18 ] loss: 0.4336985945701599 2022-06-30 21:05:22.416389
Epoch:[ 59 19 ] loss: 0.4392728805541992 2022-06-30 21:05:22.832937
Training_Epoch:[ 59 ] Training_loss: 0.4375652655959129 2022-06-30 21:05:22.833687
learning rate:  0.0016384000000000004
val: 1 0.45270398259162903
val: 2 0.4610385596752167
val: 3 0.4521814286708832
val: 4 0.45703622698783875
val: 5 0.4486563205718994
val: 6 0.44591236114501953
val: 7 0.45211562514305115
val: 8 0.440093070268631
val: 9 0.45598092675209045
val: 10 0.4452817440032959
val: 11 0.4622364044189453
val: 12 0.45058348774909973
val: 13 0.4560868740081787
val: 14 0.44017839431762695
val: 15 0.450994074344635
val: 16 0.45999324321746826
val: 17 0.4581911563873291
val: 18 0.45657292008399963
val: 19 0.46677103638648987
val: 20 0.45726820826530457
val_Epoch:[ 59 ] val_loss: 0.4534938022494316 2022-06-30 21:05:26.218449
start training 2022-06-30 21:05:26.319958
Epoch:[ 60 0 ] loss: 0.43547576665878296 2022-06-30 21:05:40.192981
Epoch:[ 60 1 ] loss: 0.43440112471580505 2022-06-30 21:05:40.620473
Epoch:[ 60 2 ] loss: 0.43507105112075806 2022-06-30 21:05:41.042823
Epoch:[ 60 3 ] loss: 0.4354512691497803 2022-06-30 21:05:41.458719
Epoch:[ 60 4 ] loss: 0.4366970956325531 2022-06-30 21:05:41.909153
Epoch:[ 60 5 ] loss: 0.43573325872421265 2022-06-30 21:05:42.388559
Epoch:[ 60 6 ] loss: 0.43177857995033264 2022-06-30 21:05:42.801819
Epoch:[ 60 7 ] loss: 0.4410143494606018 2022-06-30 21:05:43.222672
Epoch:[ 60 8 ] loss: 0.43599751591682434 2022-06-30 21:05:43.639362
Epoch:[ 60 9 ] loss: 0.4387526214122772 2022-06-30 21:05:44.062087
Epoch:[ 60 10 ] loss: 0.44480958580970764 2022-06-30 21:05:44.476888
Epoch:[ 60 11 ] loss: 0.43822577595710754 2022-06-30 21:05:44.892133
Epoch:[ 60 12 ] loss: 0.43831074237823486 2022-06-30 21:05:45.305683
Epoch:[ 60 13 ] loss: 0.43829891085624695 2022-06-30 21:05:45.719963
Epoch:[ 60 14 ] loss: 0.4393579959869385 2022-06-30 21:05:46.133266
Epoch:[ 60 15 ] loss: 0.43825462460517883 2022-06-30 21:05:46.556861
Epoch:[ 60 16 ] loss: 0.4403388202190399 2022-06-30 21:05:52.281959
Epoch:[ 60 17 ] loss: 0.4376031160354614 2022-06-30 21:05:52.696228
Epoch:[ 60 18 ] loss: 0.43494224548339844 2022-06-30 21:05:53.111522
Epoch:[ 60 19 ] loss: 0.43762657046318054 2022-06-30 21:05:53.527546
Training_Epoch:[ 60 ] Training_loss: 0.43740705102682115 2022-06-30 21:05:53.528221
learning rate:  0.0016384000000000004
netparams have been saved once 60
val: 1 0.46318817138671875
val: 2 0.46641042828559875
val: 3 0.44238823652267456
val: 4 0.4597521424293518
val: 5 0.4510549306869507
val: 6 0.45566388964653015
val: 7 0.44854891300201416
val: 8 0.4666265547275543
val: 9 0.46066296100616455
val: 10 0.4547160863876343
val: 11 0.46195515990257263
val: 12 0.46461617946624756
val: 13 0.45417630672454834
val: 14 0.4493006765842438
val: 15 0.46121928095817566
val: 16 0.4584280550479889
val: 17 0.4486742615699768
val: 18 0.45958369970321655
val: 19 0.4562624990940094
val: 20 0.45550984144210815
val_Epoch:[ 60 ] val_loss: 0.456936913728714 2022-06-30 21:05:56.874694
start training 2022-06-30 21:05:56.973134
Epoch:[ 61 0 ] loss: 0.437942773103714 2022-06-30 21:06:11.494801
Epoch:[ 61 1 ] loss: 0.4331265985965729 2022-06-30 21:06:11.907688
Epoch:[ 61 2 ] loss: 0.4390556514263153 2022-06-30 21:06:12.328895
Epoch:[ 61 3 ] loss: 0.4335246682167053 2022-06-30 21:06:12.751968
Epoch:[ 61 4 ] loss: 0.43429023027420044 2022-06-30 21:06:13.239596
Epoch:[ 61 5 ] loss: 0.43376556038856506 2022-06-30 21:06:13.654275
Epoch:[ 61 6 ] loss: 0.43517979979515076 2022-06-30 21:06:14.068365
Epoch:[ 61 7 ] loss: 0.43223708868026733 2022-06-30 21:06:14.482519
Epoch:[ 61 8 ] loss: 0.4356767535209656 2022-06-30 21:06:14.904336
Epoch:[ 61 9 ] loss: 0.4356636703014374 2022-06-30 21:06:15.320919
Epoch:[ 61 10 ] loss: 0.4366615414619446 2022-06-30 21:06:15.736483
Epoch:[ 61 11 ] loss: 0.4349193572998047 2022-06-30 21:06:16.155735
Epoch:[ 61 12 ] loss: 0.4377530515193939 2022-06-30 21:06:16.568982
Epoch:[ 61 13 ] loss: 0.4384089708328247 2022-06-30 21:06:16.984525
Epoch:[ 61 14 ] loss: 0.4331202208995819 2022-06-30 21:06:17.397452
Epoch:[ 61 15 ] loss: 0.43681979179382324 2022-06-30 21:06:17.817795
Epoch:[ 61 16 ] loss: 0.43300169706344604 2022-06-30 21:06:23.276260
Epoch:[ 61 17 ] loss: 0.4359470307826996 2022-06-30 21:06:23.692170
Epoch:[ 61 18 ] loss: 0.43393442034721375 2022-06-30 21:06:24.107732
Epoch:[ 61 19 ] loss: 0.4366809129714966 2022-06-30 21:06:24.522881
Training_Epoch:[ 61 ] Training_loss: 0.4353854894638062 2022-06-30 21:06:24.523511
learning rate:  0.0013107200000000005
val: 1 0.4520144760608673
val: 2 0.4564555585384369
val: 3 0.4513075053691864
val: 4 0.4574925899505615
val: 5 0.45341411232948303
val: 6 0.4575328528881073
val: 7 0.4578403830528259
val: 8 0.44955357909202576
val: 9 0.4499870836734772
val: 10 0.4456292688846588
val: 11 0.4549931287765503
val: 12 0.4538283348083496
val: 13 0.4536493420600891
val: 14 0.45726191997528076
val: 15 0.4570467174053192
val: 16 0.4536091089248657
val: 17 0.4502875506877899
val: 18 0.45964860916137695
val: 19 0.4533889889717102
val: 20 0.45509031414985657
val_Epoch:[ 61 ] val_loss: 0.4540015712380409 2022-06-30 21:06:27.840082
start training 2022-06-30 21:06:27.937794
Epoch:[ 62 0 ] loss: 0.4325086176395416 2022-06-30 21:06:41.753650
Epoch:[ 62 1 ] loss: 0.4387800395488739 2022-06-30 21:06:42.408579
Epoch:[ 62 2 ] loss: 0.4337577819824219 2022-06-30 21:06:42.822080
Epoch:[ 62 3 ] loss: 0.4344545602798462 2022-06-30 21:06:43.277195
Epoch:[ 62 4 ] loss: 0.43416276574134827 2022-06-30 21:06:43.753776
Epoch:[ 62 5 ] loss: 0.4336915910243988 2022-06-30 21:06:44.174870
Epoch:[ 62 6 ] loss: 0.43294674158096313 2022-06-30 21:06:44.595105
Epoch:[ 62 7 ] loss: 0.4311234951019287 2022-06-30 21:06:45.009674
Epoch:[ 62 8 ] loss: 0.43351081013679504 2022-06-30 21:06:45.431647
Epoch:[ 62 9 ] loss: 0.4320344626903534 2022-06-30 21:06:45.844645
Epoch:[ 62 10 ] loss: 0.4335102140903473 2022-06-30 21:06:46.260829
Epoch:[ 62 11 ] loss: 0.4340836703777313 2022-06-30 21:06:46.677098
Epoch:[ 62 12 ] loss: 0.430633544921875 2022-06-30 21:06:47.095098
Epoch:[ 62 13 ] loss: 0.4306192994117737 2022-06-30 21:06:47.509095
Epoch:[ 62 14 ] loss: 0.43385574221611023 2022-06-30 21:06:47.923257
Epoch:[ 62 15 ] loss: 0.4334815442562103 2022-06-30 21:06:48.337937
Epoch:[ 62 16 ] loss: 0.4376499354839325 2022-06-30 21:06:53.872953
Epoch:[ 62 17 ] loss: 0.4344998300075531 2022-06-30 21:06:54.288214
Epoch:[ 62 18 ] loss: 0.43437817692756653 2022-06-30 21:06:54.705765
Epoch:[ 62 19 ] loss: 0.43475040793418884 2022-06-30 21:06:55.122296
Training_Epoch:[ 62 ] Training_loss: 0.433721661567688 2022-06-30 21:06:55.122940
learning rate:  0.0013107200000000005
netparams have been saved once 62
val: 1 0.4523724615573883
val: 2 0.4491691589355469
val: 3 0.44035834074020386
val: 4 0.45977097749710083
val: 5 0.4594208002090454
val: 6 0.4519449472427368
val: 7 0.464061439037323
val: 8 0.45692718029022217
val: 9 0.45298072695732117
val: 10 0.46099352836608887
val: 11 0.44973358511924744
val: 12 0.4405387341976166
val: 13 0.4629663825035095
val: 14 0.46884119510650635
val: 15 0.46795427799224854
val: 16 0.4601583182811737
val: 17 0.4517320990562439
val: 18 0.4615090787410736
val: 19 0.4595867097377777
val: 20 0.4475454092025757
val_Epoch:[ 62 ] val_loss: 0.45592826753854754 2022-06-30 21:06:58.552558
start training 2022-06-30 21:06:58.649680
Epoch:[ 63 0 ] loss: 0.43330660462379456 2022-06-30 21:07:12.171654
Epoch:[ 63 1 ] loss: 0.43121960759162903 2022-06-30 21:07:12.594902
Epoch:[ 63 2 ] loss: 0.43088629841804504 2022-06-30 21:07:13.013357
Epoch:[ 63 3 ] loss: 0.433617502450943 2022-06-30 21:07:13.466422
Epoch:[ 63 4 ] loss: 0.4303465485572815 2022-06-30 21:07:13.945961
Epoch:[ 63 5 ] loss: 0.43053123354911804 2022-06-30 21:07:14.361477
Epoch:[ 63 6 ] loss: 0.4319288432598114 2022-06-30 21:07:14.775431
Epoch:[ 63 7 ] loss: 0.4333040416240692 2022-06-30 21:07:15.190825
Epoch:[ 63 8 ] loss: 0.4332844614982605 2022-06-30 21:07:15.606200
Epoch:[ 63 9 ] loss: 0.4317791759967804 2022-06-30 21:07:16.026294
Epoch:[ 63 10 ] loss: 0.43266531825065613 2022-06-30 21:07:16.439343
Epoch:[ 63 11 ] loss: 0.4295003116130829 2022-06-30 21:07:16.861099
Epoch:[ 63 12 ] loss: 0.43464386463165283 2022-06-30 21:07:17.283541
Epoch:[ 63 13 ] loss: 0.43012726306915283 2022-06-30 21:07:17.698320
Epoch:[ 63 14 ] loss: 0.43070876598358154 2022-06-30 21:07:18.110524
Epoch:[ 63 15 ] loss: 0.4294160008430481 2022-06-30 21:07:18.526109
Epoch:[ 63 16 ] loss: 0.4324585199356079 2022-06-30 21:07:23.898137
Epoch:[ 63 17 ] loss: 0.43087056279182434 2022-06-30 21:07:24.310657
Epoch:[ 63 18 ] loss: 0.4330507218837738 2022-06-30 21:07:24.727908
Epoch:[ 63 19 ] loss: 0.43342524766921997 2022-06-30 21:07:25.143259
Training_Epoch:[ 63 ] Training_loss: 0.43185354471206666 2022-06-30 21:07:25.143912
learning rate:  0.0013107200000000005
val: 1 0.4469248056411743
val: 2 0.46544721722602844
val: 3 0.4524521827697754
val: 4 0.45544686913490295
val: 5 0.4556410610675812
val: 6 0.45481908321380615
val: 7 0.4523504376411438
val: 8 0.4602021276950836
val: 9 0.4476757347583771
val: 10 0.457500159740448
val: 11 0.45348960161209106
val: 12 0.4518445134162903
val: 13 0.45914673805236816
val: 14 0.450967401266098
val: 15 0.44548988342285156
val: 16 0.44800758361816406
val: 17 0.459643691778183
val: 18 0.46793079376220703
val: 19 0.458950012922287
val: 20 0.4512316882610321
val_Epoch:[ 63 ] val_loss: 0.4547580793499947 2022-06-30 21:07:28.517723
start training 2022-06-30 21:07:28.614904
Epoch:[ 64 0 ] loss: 0.4287922978401184 2022-06-30 21:07:43.233815
Epoch:[ 64 1 ] loss: 0.429444819688797 2022-06-30 21:07:43.717457
Epoch:[ 64 2 ] loss: 0.43018198013305664 2022-06-30 21:07:44.133000
Epoch:[ 64 3 ] loss: 0.4292812645435333 2022-06-30 21:07:44.547946
Epoch:[ 64 4 ] loss: 0.4287687838077545 2022-06-30 21:07:44.961355
Epoch:[ 64 5 ] loss: 0.4296007752418518 2022-06-30 21:07:45.378162
Epoch:[ 64 6 ] loss: 0.43065890669822693 2022-06-30 21:07:45.798937
Epoch:[ 64 7 ] loss: 0.4306597113609314 2022-06-30 21:07:46.216188
Epoch:[ 64 8 ] loss: 0.4339246451854706 2022-06-30 21:07:46.631173
Epoch:[ 64 9 ] loss: 0.4293982684612274 2022-06-30 21:07:47.051191
Epoch:[ 64 10 ] loss: 0.4307231605052948 2022-06-30 21:07:47.466940
Epoch:[ 64 11 ] loss: 0.4324624538421631 2022-06-30 21:07:47.887882
Epoch:[ 64 12 ] loss: 0.43401139974594116 2022-06-30 21:07:48.309397
Epoch:[ 64 13 ] loss: 0.43517082929611206 2022-06-30 21:07:48.725949
Epoch:[ 64 14 ] loss: 0.4307710528373718 2022-06-30 21:07:49.141220
Epoch:[ 64 15 ] loss: 0.43427711725234985 2022-06-30 21:07:49.555209
Epoch:[ 64 16 ] loss: 0.4311286211013794 2022-06-30 21:07:55.198281
Epoch:[ 64 17 ] loss: 0.43192607164382935 2022-06-30 21:07:55.611471
Epoch:[ 64 18 ] loss: 0.43561768531799316 2022-06-30 21:07:56.031772
Epoch:[ 64 19 ] loss: 0.43098941445350647 2022-06-30 21:07:56.447752
Training_Epoch:[ 64 ] Training_loss: 0.43138946294784547 2022-06-30 21:07:56.448388
learning rate:  0.0013107200000000005
netparams have been saved once 64
val: 1 0.46364614367485046
val: 2 0.4531433582305908
val: 3 0.47068360447883606
val: 4 0.4531865119934082
val: 5 0.4489365518093109
val: 6 0.4481413662433624
val: 7 0.4605669379234314
val: 8 0.45949655771255493
val: 9 0.45123642683029175
val: 10 0.4592196047306061
val: 11 0.4536031186580658
val: 12 0.4543571472167969
val: 13 0.4543794095516205
val: 14 0.4629667401313782
val: 15 0.46957868337631226
val: 16 0.45693346858024597
val: 17 0.46156641840934753
val: 18 0.4663090109825134
val: 19 0.45615777373313904
val: 20 0.46693262457847595
val_Epoch:[ 64 ] val_loss: 0.4585520729422569 2022-06-30 21:07:59.820515
start training 2022-06-30 21:07:59.918521
Epoch:[ 65 0 ] loss: 0.43026959896087646 2022-06-30 21:08:14.246543
Epoch:[ 65 1 ] loss: 0.43207114934921265 2022-06-30 21:08:14.662399
Epoch:[ 65 2 ] loss: 0.43411150574684143 2022-06-30 21:08:15.074516
Epoch:[ 65 3 ] loss: 0.4305714964866638 2022-06-30 21:08:15.488159
Epoch:[ 65 4 ] loss: 0.43465638160705566 2022-06-30 21:08:15.902381
Epoch:[ 65 5 ] loss: 0.43520092964172363 2022-06-30 21:08:16.321500
Epoch:[ 65 6 ] loss: 0.43166178464889526 2022-06-30 21:08:16.740946
Epoch:[ 65 7 ] loss: 0.433628648519516 2022-06-30 21:08:17.155833
Epoch:[ 65 8 ] loss: 0.4321955144405365 2022-06-30 21:08:17.568979
Epoch:[ 65 9 ] loss: 0.43247175216674805 2022-06-30 21:08:17.988665
Epoch:[ 65 10 ] loss: 0.43148910999298096 2022-06-30 21:08:18.402435
Epoch:[ 65 11 ] loss: 0.43150052428245544 2022-06-30 21:08:18.815999
Epoch:[ 65 12 ] loss: 0.4307808578014374 2022-06-30 21:08:19.228274
Epoch:[ 65 13 ] loss: 0.427157461643219 2022-06-30 21:08:19.663728
Epoch:[ 65 14 ] loss: 0.43170857429504395 2022-06-30 21:08:20.079142
Epoch:[ 65 15 ] loss: 0.4302659332752228 2022-06-30 21:08:20.494786
Epoch:[ 65 16 ] loss: 0.4302830994129181 2022-06-30 21:08:26.125978
Epoch:[ 65 17 ] loss: 0.43211278319358826 2022-06-30 21:08:26.537346
Epoch:[ 65 18 ] loss: 0.43318814039230347 2022-06-30 21:08:26.957385
Epoch:[ 65 19 ] loss: 0.4343412220478058 2022-06-30 21:08:27.371507
Training_Epoch:[ 65 ] Training_loss: 0.43198332339525225 2022-06-30 21:08:27.372205
learning rate:  0.0013107200000000005
val: 1 0.4522506892681122
val: 2 0.44774460792541504
val: 3 0.45116618275642395
val: 4 0.46377357840538025
val: 5 0.4762780964374542
val: 6 0.44615262746810913
val: 7 0.45414265990257263
val: 8 0.44733163714408875
val: 9 0.46548181772232056
val: 10 0.46531546115875244
val: 11 0.45737355947494507
val: 12 0.44896596670150757
val: 13 0.462713360786438
val: 14 0.4562007784843445
val: 15 0.44923830032348633
val: 16 0.4671590328216553
val: 17 0.4580952823162079
val: 18 0.45372477173805237
val: 19 0.45338648557662964
val: 20 0.46334555745124817
val_Epoch:[ 65 ] val_loss: 0.4569920226931572 2022-06-30 21:08:30.717600
start training 2022-06-30 21:08:30.816610
Epoch:[ 66 0 ] loss: 0.4319537281990051 2022-06-30 21:08:44.561495
Epoch:[ 66 1 ] loss: 0.4274689555168152 2022-06-30 21:08:44.983184
Epoch:[ 66 2 ] loss: 0.42735135555267334 2022-06-30 21:08:45.403432
Epoch:[ 66 3 ] loss: 0.4309665262699127 2022-06-30 21:08:45.817786
Epoch:[ 66 4 ] loss: 0.42822879552841187 2022-06-30 21:08:46.231538
Epoch:[ 66 5 ] loss: 0.4303300082683563 2022-06-30 21:08:46.651578
Epoch:[ 66 6 ] loss: 0.4284905195236206 2022-06-30 21:08:47.064580
Epoch:[ 66 7 ] loss: 0.4320114850997925 2022-06-30 21:08:47.480997
Epoch:[ 66 8 ] loss: 0.42889928817749023 2022-06-30 21:08:47.897099
Epoch:[ 66 9 ] loss: 0.43040981888771057 2022-06-30 21:08:48.317557
Epoch:[ 66 10 ] loss: 0.42877620458602905 2022-06-30 21:08:48.730323
Epoch:[ 66 11 ] loss: 0.43017804622650146 2022-06-30 21:08:49.146417
Epoch:[ 66 12 ] loss: 0.42515459656715393 2022-06-30 21:08:49.559462
Epoch:[ 66 13 ] loss: 0.43101122975349426 2022-06-30 21:08:49.973417
Epoch:[ 66 14 ] loss: 0.43261826038360596 2022-06-30 21:08:50.390122
Epoch:[ 66 15 ] loss: 0.4285658299922943 2022-06-30 21:08:50.809043
Epoch:[ 66 16 ] loss: 0.4303724467754364 2022-06-30 21:08:56.359343
Epoch:[ 66 17 ] loss: 0.4299926459789276 2022-06-30 21:08:56.774245
Epoch:[ 66 18 ] loss: 0.4353407621383667 2022-06-30 21:08:57.196639
Epoch:[ 66 19 ] loss: 0.43312180042266846 2022-06-30 21:08:57.610697
Training_Epoch:[ 66 ] Training_loss: 0.43006211519241333 2022-06-30 21:08:57.611365
learning rate:  0.0013107200000000005
netparams have been saved once 66
val: 1 0.46154096722602844
val: 2 0.448821485042572
val: 3 0.44867268204689026
val: 4 0.457529753446579
val: 5 0.4679723381996155
val: 6 0.45126789808273315
val: 7 0.4545365273952484
val: 8 0.46135759353637695
val: 9 0.4503932297229767
val: 10 0.460153192281723
val: 11 0.4572196304798126
val: 12 0.459518700838089
val: 13 0.45426663756370544
val: 14 0.45674896240234375
val: 15 0.46261557936668396
val: 16 0.45281797647476196
val: 17 0.46946218609809875
val: 18 0.4505072236061096
val: 19 0.45642149448394775
val: 20 0.4626528024673462
val_Epoch:[ 66 ] val_loss: 0.4572238430380821 2022-06-30 21:09:00.950433
start training 2022-06-30 21:09:01.047568
Epoch:[ 67 0 ] loss: 0.4290884733200073 2022-06-30 21:09:15.580600
Epoch:[ 67 1 ] loss: 0.43019983172416687 2022-06-30 21:09:15.995938
Epoch:[ 67 2 ] loss: 0.43240004777908325 2022-06-30 21:09:16.411353
Epoch:[ 67 3 ] loss: 0.4308743476867676 2022-06-30 21:09:16.826585
Epoch:[ 67 4 ] loss: 0.4304828941822052 2022-06-30 21:09:17.239917
Epoch:[ 67 5 ] loss: 0.4270326495170593 2022-06-30 21:09:17.654111
Epoch:[ 67 6 ] loss: 0.4318750202655792 2022-06-30 21:09:18.072524
Epoch:[ 67 7 ] loss: 0.4287041425704956 2022-06-30 21:09:18.486438
Epoch:[ 67 8 ] loss: 0.43013763427734375 2022-06-30 21:09:18.902043
Epoch:[ 67 9 ] loss: 0.4290083348751068 2022-06-30 21:09:19.324085
Epoch:[ 67 10 ] loss: 0.43133050203323364 2022-06-30 21:09:19.743746
Epoch:[ 67 11 ] loss: 0.42851385474205017 2022-06-30 21:09:20.157414
Epoch:[ 67 12 ] loss: 0.4297870397567749 2022-06-30 21:09:20.587571
Epoch:[ 67 13 ] loss: 0.43321463465690613 2022-06-30 21:09:21.001028
Epoch:[ 67 14 ] loss: 0.4260120987892151 2022-06-30 21:09:21.419561
Epoch:[ 67 15 ] loss: 0.430440753698349 2022-06-30 21:09:21.840976
Epoch:[ 67 16 ] loss: 0.42759421467781067 2022-06-30 21:09:27.547422
Epoch:[ 67 17 ] loss: 0.4320255517959595 2022-06-30 21:09:27.962767
Epoch:[ 67 18 ] loss: 0.42974206805229187 2022-06-30 21:09:28.383944
Epoch:[ 67 19 ] loss: 0.4329042136669159 2022-06-30 21:09:28.799100
Training_Epoch:[ 67 ] Training_loss: 0.4300684154033661 2022-06-30 21:09:28.799893
learning rate:  0.0013107200000000005
val: 1 0.4441877603530884
val: 2 0.4479248821735382
val: 3 0.44401073455810547
val: 4 0.4565562307834625
val: 5 0.4607366621494293
val: 6 0.4607807993888855
val: 7 0.4613259434700012
val: 8 0.460440456867218
val: 9 0.45498859882354736
val: 10 0.4541339576244354
val: 11 0.44211265444755554
val: 12 0.4609275460243225
val: 13 0.4581807553768158
val: 14 0.4557023048400879
val: 15 0.45810404419898987
val: 16 0.4517795443534851
val: 17 0.45038625597953796
val: 18 0.45352017879486084
val: 19 0.45951446890830994
val: 20 0.4600166380405426
val_Epoch:[ 67 ] val_loss: 0.454766520857811 2022-06-30 21:09:32.181689
start training 2022-06-30 21:09:32.284101
Epoch:[ 68 0 ] loss: 0.42751607298851013 2022-06-30 21:09:46.298151
Epoch:[ 68 1 ] loss: 0.42824605107307434 2022-06-30 21:09:46.742525
Epoch:[ 68 2 ] loss: 0.42712149024009705 2022-06-30 21:09:47.232756
Epoch:[ 68 3 ] loss: 0.4288448095321655 2022-06-30 21:09:47.655366
Epoch:[ 68 4 ] loss: 0.4311233162879944 2022-06-30 21:09:48.072432
Epoch:[ 68 5 ] loss: 0.42784714698791504 2022-06-30 21:09:48.486724
Epoch:[ 68 6 ] loss: 0.4300748109817505 2022-06-30 21:09:48.907533
Epoch:[ 68 7 ] loss: 0.4287097454071045 2022-06-30 21:09:49.321701
Epoch:[ 68 8 ] loss: 0.42703694105148315 2022-06-30 21:09:49.734556
Epoch:[ 68 9 ] loss: 0.4245986342430115 2022-06-30 21:09:50.150542
Epoch:[ 68 10 ] loss: 0.42767348885536194 2022-06-30 21:09:50.571741
Epoch:[ 68 11 ] loss: 0.42682945728302 2022-06-30 21:09:50.988187
Epoch:[ 68 12 ] loss: 0.42891111969947815 2022-06-30 21:09:51.404095
Epoch:[ 68 13 ] loss: 0.4340124726295471 2022-06-30 21:09:51.818993
Epoch:[ 68 14 ] loss: 0.4296397566795349 2022-06-30 21:09:52.235073
Epoch:[ 68 15 ] loss: 0.42624664306640625 2022-06-30 21:09:52.649867
Epoch:[ 68 16 ] loss: 0.4299633502960205 2022-06-30 21:09:58.431179
Epoch:[ 68 17 ] loss: 0.43037179112434387 2022-06-30 21:09:58.847661
Epoch:[ 68 18 ] loss: 0.43119513988494873 2022-06-30 21:09:59.267400
Epoch:[ 68 19 ] loss: 0.43279168009757996 2022-06-30 21:09:59.682856
Training_Epoch:[ 68 ] Training_loss: 0.4289376959204674 2022-06-30 21:09:59.683655
learning rate:  0.0013107200000000005
netparams have been saved once 68
val: 1 0.4626178443431854
val: 2 0.44582152366638184
val: 3 0.44853436946868896
val: 4 0.4489944577217102
val: 5 0.4591658115386963
val: 6 0.46055999398231506
val: 7 0.4551438093185425
val: 8 0.46010175347328186
val: 9 0.45104917883872986
val: 10 0.4476582705974579
val: 11 0.45461520552635193
val: 12 0.45140016078948975
val: 13 0.4485088586807251
val: 14 0.45850855112075806
val: 15 0.46368351578712463
val: 16 0.4519795775413513
val: 17 0.4677380323410034
val: 18 0.4531896114349365
val: 19 0.45099112391471863
val: 20 0.4564652144908905
val_Epoch:[ 68 ] val_loss: 0.454836343228817 2022-06-30 21:10:03.207117
start training 2022-06-30 21:10:03.307588
Epoch:[ 69 0 ] loss: 0.42778608202934265 2022-06-30 21:10:17.228881
Epoch:[ 69 1 ] loss: 0.4264702796936035 2022-06-30 21:10:17.671097
Epoch:[ 69 2 ] loss: 0.4234243333339691 2022-06-30 21:10:18.084590
Epoch:[ 69 3 ] loss: 0.4272632598876953 2022-06-30 21:10:18.507311
Epoch:[ 69 4 ] loss: 0.4290425181388855 2022-06-30 21:10:18.924225
Epoch:[ 69 5 ] loss: 0.42993274331092834 2022-06-30 21:10:19.345943
Epoch:[ 69 6 ] loss: 0.4285251796245575 2022-06-30 21:10:19.787810
Epoch:[ 69 7 ] loss: 0.4317678213119507 2022-06-30 21:10:20.276111
Epoch:[ 69 8 ] loss: 0.4263755977153778 2022-06-30 21:10:20.691915
Epoch:[ 69 9 ] loss: 0.42667943239212036 2022-06-30 21:10:21.104370
Epoch:[ 69 10 ] loss: 0.427418977022171 2022-06-30 21:10:21.520874
Epoch:[ 69 11 ] loss: 0.4289476275444031 2022-06-30 21:10:21.936017
Epoch:[ 69 12 ] loss: 0.42699912190437317 2022-06-30 21:10:22.351160
Epoch:[ 69 13 ] loss: 0.42826682329177856 2022-06-30 21:10:22.771113
Epoch:[ 69 14 ] loss: 0.43193694949150085 2022-06-30 21:10:23.185211
Epoch:[ 69 15 ] loss: 0.4323715567588806 2022-06-30 21:10:23.600909
Epoch:[ 69 16 ] loss: 0.4307790696620941 2022-06-30 21:10:29.325314
Epoch:[ 69 17 ] loss: 0.43481355905532837 2022-06-30 21:10:29.742459
Epoch:[ 69 18 ] loss: 0.4297601580619812 2022-06-30 21:10:30.162049
Epoch:[ 69 19 ] loss: 0.42918962240219116 2022-06-30 21:10:30.580443
Training_Epoch:[ 69 ] Training_loss: 0.42888753563165666 2022-06-30 21:10:30.581143
learning rate:  0.0013107200000000005
val: 1 0.4489426910877228
val: 2 0.4538755416870117
val: 3 0.45480403304100037
val: 4 0.460462361574173
val: 5 0.4581089913845062
val: 6 0.4608188569545746
val: 7 0.4627348482608795
val: 8 0.4461592137813568
val: 9 0.45241451263427734
val: 10 0.4393882751464844
val: 11 0.4575636386871338
val: 12 0.44795945286750793
val: 13 0.4548623859882355
val: 14 0.4510885179042816
val: 15 0.46164271235466003
val: 16 0.45550161600112915
val: 17 0.45449015498161316
val: 18 0.46146655082702637
val: 19 0.4636532664299011
val: 20 0.45460259914398193
val_Epoch:[ 69 ] val_loss: 0.4550270110368729 2022-06-30 21:10:33.906087
start training 2022-06-30 21:10:34.008241
Epoch:[ 70 0 ] loss: 0.42843762040138245 2022-06-30 21:10:48.500619
Epoch:[ 70 1 ] loss: 0.4275098741054535 2022-06-30 21:10:48.914034
Epoch:[ 70 2 ] loss: 0.42971959710121155 2022-06-30 21:10:49.360708
Epoch:[ 70 3 ] loss: 0.4278589189052582 2022-06-30 21:10:49.839182
Epoch:[ 70 4 ] loss: 0.4271738529205322 2022-06-30 21:10:50.253883
Epoch:[ 70 5 ] loss: 0.42547228932380676 2022-06-30 21:10:50.670058
Epoch:[ 70 6 ] loss: 0.4329450726509094 2022-06-30 21:10:51.084479
Epoch:[ 70 7 ] loss: 0.42944836616516113 2022-06-30 21:10:51.499133
Epoch:[ 70 8 ] loss: 0.43197572231292725 2022-06-30 21:10:51.913043
Epoch:[ 70 9 ] loss: 0.4283016324043274 2022-06-30 21:10:52.331547
Epoch:[ 70 10 ] loss: 0.42837095260620117 2022-06-30 21:10:52.751461
Epoch:[ 70 11 ] loss: 0.42944613099098206 2022-06-30 21:10:53.174163
Epoch:[ 70 12 ] loss: 0.43441134691238403 2022-06-30 21:10:53.589265
Epoch:[ 70 13 ] loss: 0.4317783713340759 2022-06-30 21:10:54.004727
Epoch:[ 70 14 ] loss: 0.4268917143344879 2022-06-30 21:10:54.417687
Epoch:[ 70 15 ] loss: 0.4328610897064209 2022-06-30 21:10:54.838421
Epoch:[ 70 16 ] loss: 0.42707300186157227 2022-06-30 21:11:00.372650
Epoch:[ 70 17 ] loss: 0.4308032691478729 2022-06-30 21:11:00.785705
Epoch:[ 70 18 ] loss: 0.42805910110473633 2022-06-30 21:11:01.202200
Epoch:[ 70 19 ] loss: 0.42966392636299133 2022-06-30 21:11:01.616231
Training_Epoch:[ 70 ] Training_loss: 0.42941009253263474 2022-06-30 21:11:01.616986
learning rate:  0.0013107200000000005
netparams have been saved once 70
val: 1 0.46054425835609436
val: 2 0.4521012306213379
val: 3 0.46729645133018494
val: 4 0.46626338362693787
val: 5 0.45129382610321045
val: 6 0.45862528681755066
val: 7 0.46095359325408936
val: 8 0.45044592022895813
val: 9 0.4598942697048187
val: 10 0.4443109333515167
val: 11 0.4473588168621063
val: 12 0.4492831230163574
val: 13 0.463473916053772
val: 14 0.45339953899383545
val: 15 0.45349305868148804
val: 16 0.46710965037345886
val: 17 0.45892515778541565
val: 18 0.45467817783355713
val: 19 0.4597962200641632
val: 20 0.45204246044158936
val_Epoch:[ 70 ] val_loss: 0.4565644636750221 2022-06-30 21:11:05.015874
start training 2022-06-30 21:11:05.113327
Epoch:[ 71 0 ] loss: 0.4277878701686859 2022-06-30 21:11:19.278044
Epoch:[ 71 1 ] loss: 0.42819786071777344 2022-06-30 21:11:19.692416
Epoch:[ 71 2 ] loss: 0.42452120780944824 2022-06-30 21:11:20.113238
Epoch:[ 71 3 ] loss: 0.42504528164863586 2022-06-30 21:11:20.527437
Epoch:[ 71 4 ] loss: 0.4248737692832947 2022-06-30 21:11:20.941230
Epoch:[ 71 5 ] loss: 0.4235268235206604 2022-06-30 21:11:21.378857
Epoch:[ 71 6 ] loss: 0.426514208316803 2022-06-30 21:11:21.865800
Epoch:[ 71 7 ] loss: 0.42413797974586487 2022-06-30 21:11:22.284091
Epoch:[ 71 8 ] loss: 0.4288661777973175 2022-06-30 21:11:22.704300
Epoch:[ 71 9 ] loss: 0.43076053261756897 2022-06-30 21:11:23.118315
Epoch:[ 71 10 ] loss: 0.4278399646282196 2022-06-30 21:11:23.533119
Epoch:[ 71 11 ] loss: 0.42753905057907104 2022-06-30 21:11:23.954178
Epoch:[ 71 12 ] loss: 0.4276164770126343 2022-06-30 21:11:24.375589
Epoch:[ 71 13 ] loss: 0.42772549390792847 2022-06-30 21:11:24.792193
Epoch:[ 71 14 ] loss: 0.42663225531578064 2022-06-30 21:11:25.207555
Epoch:[ 71 15 ] loss: 0.4253098964691162 2022-06-30 21:11:25.623695
Epoch:[ 71 16 ] loss: 0.42719969153404236 2022-06-30 21:11:30.916729
Epoch:[ 71 17 ] loss: 0.4283846616744995 2022-06-30 21:11:31.330941
Epoch:[ 71 18 ] loss: 0.4266657829284668 2022-06-30 21:11:31.745248
Epoch:[ 71 19 ] loss: 0.42845261096954346 2022-06-30 21:11:32.161247
Training_Epoch:[ 71 ] Training_loss: 0.4268798798322678 2022-06-30 21:11:32.161865
learning rate:  0.0010485760000000005
val: 1 0.4443003535270691
val: 2 0.45678630471229553
val: 3 0.4559117555618286
val: 4 0.448565810918808
val: 5 0.4486464560031891
val: 6 0.45418447256088257
val: 7 0.4557858109474182
val: 8 0.4445948004722595
val: 9 0.44551560282707214
val: 10 0.4485732614994049
val: 11 0.4612433612346649
val: 12 0.45523303747177124
val: 13 0.4612976312637329
val: 14 0.4516129195690155
val: 15 0.4515956938266754
val: 16 0.4632803201675415
val: 17 0.4548354744911194
val: 18 0.4621534049510956
val: 19 0.45375916361808777
val: 20 0.44718337059020996
val_Epoch:[ 71 ] val_loss: 0.4532529503107071 2022-06-30 21:11:35.520317
start training 2022-06-30 21:11:35.618376
Epoch:[ 72 0 ] loss: 0.42500150203704834 2022-06-30 21:11:49.804768
Epoch:[ 72 1 ] loss: 0.4258277714252472 2022-06-30 21:11:50.226252
Epoch:[ 72 2 ] loss: 0.4243462383747101 2022-06-30 21:11:50.641429
Epoch:[ 72 3 ] loss: 0.4233860671520233 2022-06-30 21:11:51.058183
Epoch:[ 72 4 ] loss: 0.42203566431999207 2022-06-30 21:11:51.492102
Epoch:[ 72 5 ] loss: 0.42464274168014526 2022-06-30 21:11:51.974349
Epoch:[ 72 6 ] loss: 0.4263085126876831 2022-06-30 21:11:52.388967
Epoch:[ 72 7 ] loss: 0.42397770285606384 2022-06-30 21:11:52.805843
Epoch:[ 72 8 ] loss: 0.42391279339790344 2022-06-30 21:11:53.227148
Epoch:[ 72 9 ] loss: 0.42622146010398865 2022-06-30 21:11:53.642845
Epoch:[ 72 10 ] loss: 0.4230234622955322 2022-06-30 21:11:54.057969
Epoch:[ 72 11 ] loss: 0.42531028389930725 2022-06-30 21:11:54.473016
Epoch:[ 72 12 ] loss: 0.42316725850105286 2022-06-30 21:11:54.898738
Epoch:[ 72 13 ] loss: 0.42931604385375977 2022-06-30 21:11:55.321477
Epoch:[ 72 14 ] loss: 0.42401137948036194 2022-06-30 21:11:55.744328
Epoch:[ 72 15 ] loss: 0.4280507266521454 2022-06-30 21:11:56.173746
Epoch:[ 72 16 ] loss: 0.4268511235713959 2022-06-30 21:12:01.592119
Epoch:[ 72 17 ] loss: 0.4258703589439392 2022-06-30 21:12:02.008025
Epoch:[ 72 18 ] loss: 0.4253568649291992 2022-06-30 21:12:02.423166
Epoch:[ 72 19 ] loss: 0.42514199018478394 2022-06-30 21:12:02.843875
Training_Epoch:[ 72 ] Training_loss: 0.42508799731731417 2022-06-30 21:12:02.844587
learning rate:  0.0010485760000000005
netparams have been saved once 72
val: 1 0.46534448862075806
val: 2 0.4475520849227905
val: 3 0.465800404548645
val: 4 0.4519687592983246
val: 5 0.45894667506217957
val: 6 0.4544484615325928
val: 7 0.4653097689151764
val: 8 0.4622950553894043
val: 9 0.4588909149169922
val: 10 0.44724419713020325
val: 11 0.46154046058654785
val: 12 0.452634334564209
val: 13 0.4513678252696991
val: 14 0.4603065252304077
val: 15 0.45596617460250854
val: 16 0.4545442759990692
val: 17 0.4609821140766144
val: 18 0.4735882580280304
val: 19 0.46055516600608826
val: 20 0.4619506895542145
val_Epoch:[ 72 ] val_loss: 0.4585618317127228 2022-06-30 21:12:06.242450
start training 2022-06-30 21:12:06.339155
Epoch:[ 73 0 ] loss: 0.4232165515422821 2022-06-30 21:12:20.706368
Epoch:[ 73 1 ] loss: 0.42547544836997986 2022-06-30 21:12:21.130279
Epoch:[ 73 2 ] loss: 0.422133207321167 2022-06-30 21:12:21.610302
Epoch:[ 73 3 ] loss: 0.4221113920211792 2022-06-30 21:12:22.031793
Epoch:[ 73 4 ] loss: 0.4232063889503479 2022-06-30 21:12:22.447783
Epoch:[ 73 5 ] loss: 0.42384541034698486 2022-06-30 21:12:22.862711
Epoch:[ 73 6 ] loss: 0.4218560755252838 2022-06-30 21:12:23.294691
Epoch:[ 73 7 ] loss: 0.4238266944885254 2022-06-30 21:12:23.711540
Epoch:[ 73 8 ] loss: 0.42504289746284485 2022-06-30 21:12:24.128391
Epoch:[ 73 9 ] loss: 0.42330124974250793 2022-06-30 21:12:24.550449
Epoch:[ 73 10 ] loss: 0.42510509490966797 2022-06-30 21:12:24.972965
Epoch:[ 73 11 ] loss: 0.4255514442920685 2022-06-30 21:12:25.390875
Epoch:[ 73 12 ] loss: 0.42873069643974304 2022-06-30 21:12:25.805856
Epoch:[ 73 13 ] loss: 0.426786333322525 2022-06-30 21:12:26.220439
Epoch:[ 73 14 ] loss: 0.42446354031562805 2022-06-30 21:12:26.652329
Epoch:[ 73 15 ] loss: 0.42129844427108765 2022-06-30 21:12:27.075504
Epoch:[ 73 16 ] loss: 0.4281112253665924 2022-06-30 21:12:32.434809
Epoch:[ 73 17 ] loss: 0.426475465297699 2022-06-30 21:12:32.847325
Epoch:[ 73 18 ] loss: 0.4256400763988495 2022-06-30 21:12:33.262732
Epoch:[ 73 19 ] loss: 0.42701923847198486 2022-06-30 21:12:33.676993
Training_Epoch:[ 73 ] Training_loss: 0.42465984374284743 2022-06-30 21:12:33.677659
learning rate:  0.0010485760000000005
val: 1 0.4537223279476166
val: 2 0.45053690671920776
val: 3 0.46809113025665283
val: 4 0.46571552753448486
val: 5 0.4413565993309021
val: 6 0.46962687373161316
val: 7 0.4679856598377228
val: 8 0.4535244107246399
val: 9 0.4639602303504944
val: 10 0.448677659034729
val: 11 0.46037086844444275
val: 12 0.45846185088157654
val: 13 0.45855364203453064
val: 14 0.45510074496269226
val: 15 0.4507282078266144
val: 16 0.4654659628868103
val: 17 0.45423269271850586
val: 18 0.45380890369415283
val: 19 0.46884796023368835
val: 20 0.45156386494636536
val_Epoch:[ 73 ] val_loss: 0.45801660120487214 2022-06-30 21:12:36.984193
start training 2022-06-30 21:12:37.084123
Epoch:[ 74 0 ] loss: 0.4248445928096771 2022-06-30 21:12:51.364259
Epoch:[ 74 1 ] loss: 0.42682039737701416 2022-06-30 21:12:51.784641
Epoch:[ 74 2 ] loss: 0.42750805616378784 2022-06-30 21:12:52.275187
Epoch:[ 74 3 ] loss: 0.4253247082233429 2022-06-30 21:12:52.712904
Epoch:[ 74 4 ] loss: 0.4243139624595642 2022-06-30 21:12:53.134778
Epoch:[ 74 5 ] loss: 0.42568039894104004 2022-06-30 21:12:53.556227
Epoch:[ 74 6 ] loss: 0.423941969871521 2022-06-30 21:12:53.973164
Epoch:[ 74 7 ] loss: 0.42214661836624146 2022-06-30 21:12:54.389286
Epoch:[ 74 8 ] loss: 0.4257050156593323 2022-06-30 21:12:54.806915
Epoch:[ 74 9 ] loss: 0.4224916696548462 2022-06-30 21:12:55.229154
Epoch:[ 74 10 ] loss: 0.42458364367485046 2022-06-30 21:12:55.644470
Epoch:[ 74 11 ] loss: 0.4253702163696289 2022-06-30 21:12:56.074808
Epoch:[ 74 12 ] loss: 0.4247180223464966 2022-06-30 21:12:56.490942
Epoch:[ 74 13 ] loss: 0.42320072650909424 2022-06-30 21:12:56.911241
Epoch:[ 74 14 ] loss: 0.4263286590576172 2022-06-30 21:12:57.326216
Epoch:[ 74 15 ] loss: 0.4224242866039276 2022-06-30 21:12:57.744471
Epoch:[ 74 16 ] loss: 0.4283033311367035 2022-06-30 21:13:03.199048
Epoch:[ 74 17 ] loss: 0.4275552034378052 2022-06-30 21:13:03.613817
Epoch:[ 74 18 ] loss: 0.42818838357925415 2022-06-30 21:13:04.045529
Epoch:[ 74 19 ] loss: 0.42829808592796326 2022-06-30 21:13:04.460891
Training_Epoch:[ 74 ] Training_loss: 0.4253873974084854 2022-06-30 21:13:04.461737
learning rate:  0.0010485760000000005
netparams have been saved once 74
val: 1 0.463148832321167
val: 2 0.4673198163509369
val: 3 0.4614449441432953
val: 4 0.45945507287979126
val: 5 0.4777160882949829
val: 6 0.465159147977829
val: 7 0.4681727886199951
val: 8 0.44822442531585693
val: 9 0.46555793285369873
val: 10 0.46317240595817566
val: 11 0.4507347047328949
val: 12 0.4556844234466553
val: 13 0.4559687674045563
val: 14 0.4629710912704468
val: 15 0.4553063213825226
val: 16 0.4658775329589844
val: 17 0.45995646715164185
val: 18 0.4532879889011383
val: 19 0.47076618671417236
val: 20 0.47420379519462585
val_Epoch:[ 74 ] val_loss: 0.46220643669366834 2022-06-30 21:13:07.839615
start training 2022-06-30 21:13:07.934938
Epoch:[ 75 0 ] loss: 0.42889925837516785 2022-06-30 21:13:22.119854
Epoch:[ 75 1 ] loss: 0.42408129572868347 2022-06-30 21:13:22.540942
Epoch:[ 75 2 ] loss: 0.4256512224674225 2022-06-30 21:13:22.971276
Epoch:[ 75 3 ] loss: 0.42447134852409363 2022-06-30 21:13:23.454890
Epoch:[ 75 4 ] loss: 0.42321571707725525 2022-06-30 21:13:23.876194
Epoch:[ 75 5 ] loss: 0.42504534125328064 2022-06-30 21:13:24.306700
Epoch:[ 75 6 ] loss: 0.42479178309440613 2022-06-30 21:13:24.721358
Epoch:[ 75 7 ] loss: 0.4294244050979614 2022-06-30 21:13:25.137775
Epoch:[ 75 8 ] loss: 0.4225234389305115 2022-06-30 21:13:25.558465
Epoch:[ 75 9 ] loss: 0.4284968674182892 2022-06-30 21:13:25.976236
Epoch:[ 75 10 ] loss: 0.42502033710479736 2022-06-30 21:13:26.393256
Epoch:[ 75 11 ] loss: 0.42509081959724426 2022-06-30 21:13:26.816144
Epoch:[ 75 12 ] loss: 0.42432576417922974 2022-06-30 21:13:27.233521
Epoch:[ 75 13 ] loss: 0.42278048396110535 2022-06-30 21:13:27.653136
Epoch:[ 75 14 ] loss: 0.42378756403923035 2022-06-30 21:13:28.067592
Epoch:[ 75 15 ] loss: 0.42594051361083984 2022-06-30 21:13:28.481654
Epoch:[ 75 16 ] loss: 0.42440271377563477 2022-06-30 21:13:33.956875
Epoch:[ 75 17 ] loss: 0.42363762855529785 2022-06-30 21:13:34.609106
Epoch:[ 75 18 ] loss: 0.4256250560283661 2022-06-30 21:13:35.027696
Epoch:[ 75 19 ] loss: 0.425309419631958 2022-06-30 21:13:35.441648
Training_Epoch:[ 75 ] Training_loss: 0.42512604892253875 2022-06-30 21:13:35.442260
learning rate:  0.0010485760000000005
val: 1 0.45273956656455994
val: 2 0.44296473264694214
val: 3 0.4630994200706482
val: 4 0.4518281817436218
val: 5 0.45055773854255676
val: 6 0.44188234210014343
val: 7 0.4491264820098877
val: 8 0.45160338282585144
val: 9 0.46723484992980957
val: 10 0.4549981355667114
val: 11 0.4472438097000122
val: 12 0.4570581614971161
val: 13 0.44198188185691833
val: 14 0.4498666822910309
val: 15 0.4630509912967682
val: 16 0.46335339546203613
val: 17 0.4490566849708557
val: 18 0.45546042919158936
val: 19 0.4602338671684265
val: 20 0.45765799283981323
val_Epoch:[ 75 ] val_loss: 0.45354993641376495 2022-06-30 21:13:38.804898
start training 2022-06-30 21:13:38.903646
Epoch:[ 76 0 ] loss: 0.42123380303382874 2022-06-30 21:13:53.594831
Epoch:[ 76 1 ] loss: 0.4222675859928131 2022-06-30 21:13:54.009564
Epoch:[ 76 2 ] loss: 0.4240894615650177 2022-06-30 21:13:54.430205
Epoch:[ 76 3 ] loss: 0.42236649990081787 2022-06-30 21:13:54.858714
Epoch:[ 76 4 ] loss: 0.4221041202545166 2022-06-30 21:13:55.275552
Epoch:[ 76 5 ] loss: 0.42321541905403137 2022-06-30 21:13:55.697214
Epoch:[ 76 6 ] loss: 0.42202523350715637 2022-06-30 21:13:56.110822
Epoch:[ 76 7 ] loss: 0.4239720404148102 2022-06-30 21:13:56.532442
Epoch:[ 76 8 ] loss: 0.42237725853919983 2022-06-30 21:13:56.957755
Epoch:[ 76 9 ] loss: 0.42249366641044617 2022-06-30 21:13:57.377626
Epoch:[ 76 10 ] loss: 0.4217512309551239 2022-06-30 21:13:57.793585
Epoch:[ 76 11 ] loss: 0.42156559228897095 2022-06-30 21:13:58.223894
Epoch:[ 76 12 ] loss: 0.42420151829719543 2022-06-30 21:13:58.639425
Epoch:[ 76 13 ] loss: 0.4245435297489166 2022-06-30 21:13:59.052857
Epoch:[ 76 14 ] loss: 0.4231948256492615 2022-06-30 21:13:59.473096
Epoch:[ 76 15 ] loss: 0.4210205674171448 2022-06-30 21:13:59.887745
Epoch:[ 76 16 ] loss: 0.4230435788631439 2022-06-30 21:14:05.503021
Epoch:[ 76 17 ] loss: 0.4253307282924652 2022-06-30 21:14:05.918308
Epoch:[ 76 18 ] loss: 0.42146679759025574 2022-06-30 21:14:06.341853
Epoch:[ 76 19 ] loss: 0.4230581223964691 2022-06-30 21:14:06.758162
Training_Epoch:[ 76 ] Training_loss: 0.42276607900857927 2022-06-30 21:14:06.758813
learning rate:  0.0010485760000000005
netparams have been saved once 76
val: 1 0.4593890905380249
val: 2 0.4453957974910736
val: 3 0.4637962877750397
val: 4 0.4566251039505005
val: 5 0.44792404770851135
val: 6 0.45296433568000793
val: 7 0.44268569350242615
val: 8 0.4495537579059601
val: 9 0.4658607542514801
val: 10 0.4489956796169281
val: 11 0.44674399495124817
val: 12 0.4518156349658966
val: 13 0.46928831934928894
val: 14 0.4544646739959717
val: 15 0.4597163498401642
val: 16 0.4492766261100769
val: 17 0.4547657370567322
val: 18 0.45929449796676636
val: 19 0.46225428581237793
val: 20 0.45297324657440186
val_Epoch:[ 76 ] val_loss: 0.45468919575214384 2022-06-30 21:14:10.206397
start training 2022-06-30 21:14:10.312392
Epoch:[ 77 0 ] loss: 0.42067351937294006 2022-06-30 21:14:24.086223
Epoch:[ 77 1 ] loss: 0.4190666973590851 2022-06-30 21:14:25.019996
Epoch:[ 77 2 ] loss: 0.42229577898979187 2022-06-30 21:14:25.456803
Epoch:[ 77 3 ] loss: 0.41754719614982605 2022-06-30 21:14:25.943500
Epoch:[ 77 4 ] loss: 0.4202059507369995 2022-06-30 21:14:26.360137
Epoch:[ 77 5 ] loss: 0.4226267337799072 2022-06-30 21:14:26.783057
Epoch:[ 77 6 ] loss: 0.4225582182407379 2022-06-30 21:14:27.198716
Epoch:[ 77 7 ] loss: 0.4231816828250885 2022-06-30 21:14:27.613629
Epoch:[ 77 8 ] loss: 0.4243779480457306 2022-06-30 21:14:28.028543
Epoch:[ 77 9 ] loss: 0.4223315715789795 2022-06-30 21:14:28.448478
Epoch:[ 77 10 ] loss: 0.4221753180027008 2022-06-30 21:14:28.866818
Epoch:[ 77 11 ] loss: 0.4226433038711548 2022-06-30 21:14:29.283308
Epoch:[ 77 12 ] loss: 0.4223810136318207 2022-06-30 21:14:29.700138
Epoch:[ 77 13 ] loss: 0.42406854033470154 2022-06-30 21:14:30.115248
Epoch:[ 77 14 ] loss: 0.4237450361251831 2022-06-30 21:14:30.528192
Epoch:[ 77 15 ] loss: 0.4252294600009918 2022-06-30 21:14:30.949508
Epoch:[ 77 16 ] loss: 0.4268049895763397 2022-06-30 21:14:36.222509
Epoch:[ 77 17 ] loss: 0.42450329661369324 2022-06-30 21:14:37.132442
Epoch:[ 77 18 ] loss: 0.42703312635421753 2022-06-30 21:14:37.549354
Epoch:[ 77 19 ] loss: 0.4234384596347809 2022-06-30 21:14:37.969005
Training_Epoch:[ 77 ] Training_loss: 0.42284439206123353 2022-06-30 21:14:37.969654
learning rate:  0.0010485760000000005
val: 1 0.4589103162288666
val: 2 0.4624280333518982
val: 3 0.45510029792785645
val: 4 0.4486111104488373
val: 5 0.44976478815078735
val: 6 0.45897334814071655
val: 7 0.4435666501522064
val: 8 0.46655213832855225
val: 9 0.4536818563938141
val: 10 0.454014390707016
val: 11 0.45032668113708496
val: 12 0.452330619096756
val: 13 0.45299774408340454
val: 14 0.45930296182632446
val: 15 0.4592379927635193
val: 16 0.4566388428211212
val: 17 0.4550554156303406
val: 18 0.46999305486679077
val: 19 0.4646003246307373
val: 20 0.45834434032440186
val_Epoch:[ 77 ] val_loss: 0.4565215453505516 2022-06-30 21:14:41.294138
start training 2022-06-30 21:14:41.394749
Epoch:[ 78 0 ] loss: 0.4248671233654022 2022-06-30 21:14:55.663203
Epoch:[ 78 1 ] loss: 0.4206835627555847 2022-06-30 21:14:56.079734
Epoch:[ 78 2 ] loss: 0.4244125783443451 2022-06-30 21:14:56.497270
Epoch:[ 78 3 ] loss: 0.4230365753173828 2022-06-30 21:14:56.915630
Epoch:[ 78 4 ] loss: 0.42306333780288696 2022-06-30 21:14:57.335381
Epoch:[ 78 5 ] loss: 0.42046892642974854 2022-06-30 21:14:57.795410
Epoch:[ 78 6 ] loss: 0.425001859664917 2022-06-30 21:14:58.279611
Epoch:[ 78 7 ] loss: 0.42281219363212585 2022-06-30 21:14:58.705890
Epoch:[ 78 8 ] loss: 0.41825345158576965 2022-06-30 21:14:59.123244
Epoch:[ 78 9 ] loss: 0.4232243597507477 2022-06-30 21:14:59.540231
Epoch:[ 78 10 ] loss: 0.4192083179950714 2022-06-30 21:14:59.956242
Epoch:[ 78 11 ] loss: 0.4238951504230499 2022-06-30 21:15:00.378084
Epoch:[ 78 12 ] loss: 0.42232683300971985 2022-06-30 21:15:00.795091
Epoch:[ 78 13 ] loss: 0.42175212502479553 2022-06-30 21:15:01.213977
Epoch:[ 78 14 ] loss: 0.4259117543697357 2022-06-30 21:15:01.638343
Epoch:[ 78 15 ] loss: 0.4224550724029541 2022-06-30 21:15:02.054642
Epoch:[ 78 16 ] loss: 0.4221218228340149 2022-06-30 21:15:07.471372
Epoch:[ 78 17 ] loss: 0.4221847653388977 2022-06-30 21:15:07.887574
Epoch:[ 78 18 ] loss: 0.4221086800098419 2022-06-30 21:15:08.313442
Epoch:[ 78 19 ] loss: 0.42042219638824463 2022-06-30 21:15:08.730905
Training_Epoch:[ 78 ] Training_loss: 0.42241053432226183 2022-06-30 21:15:08.731731
learning rate:  0.0010485760000000005
netparams have been saved once 78
val: 1 0.45316338539123535
val: 2 0.4601548910140991
val: 3 0.45915839076042175
val: 4 0.4615229368209839
val: 5 0.44519996643066406
val: 6 0.4632275700569153
val: 7 0.46673890948295593
val: 8 0.4500892758369446
val: 9 0.45465388894081116
val: 10 0.44411739706993103
val: 11 0.4462169110774994
val: 12 0.44499096274375916
val: 13 0.459430456161499
val: 14 0.45895102620124817
val: 15 0.45831871032714844
val: 16 0.45295795798301697
val: 17 0.46657344698905945
val: 18 0.45017847418785095
val: 19 0.44799795746803284
val: 20 0.46446698904037476
val_Epoch:[ 78 ] val_loss: 0.4554054751992226 2022-06-30 21:15:12.160122
start training 2022-06-30 21:15:12.261056
Epoch:[ 79 0 ] loss: 0.4193718135356903 2022-06-30 21:15:26.322635
Epoch:[ 79 1 ] loss: 0.4204343557357788 2022-06-30 21:15:26.749453
Epoch:[ 79 2 ] loss: 0.4231683313846588 2022-06-30 21:15:27.165678
Epoch:[ 79 3 ] loss: 0.4173317551612854 2022-06-30 21:15:27.584247
Epoch:[ 79 4 ] loss: 0.4190623462200165 2022-06-30 21:15:28.003523
Epoch:[ 79 5 ] loss: 0.4219009280204773 2022-06-30 21:15:28.421606
Epoch:[ 79 6 ] loss: 0.4220908582210541 2022-06-30 21:15:28.837860
Epoch:[ 79 7 ] loss: 0.42156699299812317 2022-06-30 21:15:29.254151
Epoch:[ 79 8 ] loss: 0.4226667582988739 2022-06-30 21:15:29.668096
Epoch:[ 79 9 ] loss: 0.4215412735939026 2022-06-30 21:15:30.082701
Epoch:[ 79 10 ] loss: 0.4208340048789978 2022-06-30 21:15:30.513577
Epoch:[ 79 11 ] loss: 0.4196642339229584 2022-06-30 21:15:30.936478
Epoch:[ 79 12 ] loss: 0.4239901900291443 2022-06-30 21:15:31.355798
Epoch:[ 79 13 ] loss: 0.4194561839103699 2022-06-30 21:15:31.772173
Epoch:[ 79 14 ] loss: 0.42189058661460876 2022-06-30 21:15:32.198455
Epoch:[ 79 15 ] loss: 0.42282968759536743 2022-06-30 21:15:32.682445
Epoch:[ 79 16 ] loss: 0.4221852123737335 2022-06-30 21:15:38.116065
Epoch:[ 79 17 ] loss: 0.4235299527645111 2022-06-30 21:15:38.532668
Epoch:[ 79 18 ] loss: 0.42297878861427307 2022-06-30 21:15:39.012208
Epoch:[ 79 19 ] loss: 0.424752414226532 2022-06-30 21:15:39.441717
Training_Epoch:[ 79 ] Training_loss: 0.42156233340501786 2022-06-30 21:15:39.442414
learning rate:  0.0010485760000000005
val: 1 0.45386603474617004
val: 2 0.4511159360408783
val: 3 0.454774409532547
val: 4 0.46480441093444824
val: 5 0.4481876492500305
val: 6 0.4508891701698303
val: 7 0.45134902000427246
val: 8 0.46715104579925537
val: 9 0.45447489619255066
val: 10 0.46371522545814514
val: 11 0.45322689414024353
val: 12 0.4477565884590149
val: 13 0.45849254727363586
val: 14 0.4679044187068939
val: 15 0.451597660779953
val: 16 0.4471229314804077
val: 17 0.4486059248447418
val: 18 0.4578728675842285
val: 19 0.4488982856273651
val: 20 0.45240285992622375
val_Epoch:[ 79 ] val_loss: 0.4547104388475418 2022-06-30 21:15:42.846804
start training 2022-06-30 21:15:42.951627
Epoch:[ 80 0 ] loss: 0.4207838177680969 2022-06-30 21:15:56.888641
Epoch:[ 80 1 ] loss: 0.4191141128540039 2022-06-30 21:15:57.337631
Epoch:[ 80 2 ] loss: 0.42534905672073364 2022-06-30 21:15:57.754151
Epoch:[ 80 3 ] loss: 0.4187072217464447 2022-06-30 21:15:58.178238
Epoch:[ 80 4 ] loss: 0.41798335313796997 2022-06-30 21:15:58.592795
Epoch:[ 80 5 ] loss: 0.4213019609451294 2022-06-30 21:15:59.007406
Epoch:[ 80 6 ] loss: 0.41852959990501404 2022-06-30 21:15:59.421572
Epoch:[ 80 7 ] loss: 0.41965195536613464 2022-06-30 21:15:59.841413
Epoch:[ 80 8 ] loss: 0.42248785495758057 2022-06-30 21:16:00.262693
Epoch:[ 80 9 ] loss: 0.4190519154071808 2022-06-30 21:16:00.677889
Epoch:[ 80 10 ] loss: 0.4171167314052582 2022-06-30 21:16:01.102866
Epoch:[ 80 11 ] loss: 0.41895461082458496 2022-06-30 21:16:01.517619
Epoch:[ 80 12 ] loss: 0.4214738607406616 2022-06-30 21:16:01.930933
Epoch:[ 80 13 ] loss: 0.4192601144313812 2022-06-30 21:16:02.344450
Epoch:[ 80 14 ] loss: 0.4222268760204315 2022-06-30 21:16:02.769244
Epoch:[ 80 15 ] loss: 0.4197854697704315 2022-06-30 21:16:03.187470
Epoch:[ 80 16 ] loss: 0.4203380048274994 2022-06-30 21:16:08.769533
Epoch:[ 80 17 ] loss: 0.42154842615127563 2022-06-30 21:16:09.184110
Epoch:[ 80 18 ] loss: 0.42240920662879944 2022-06-30 21:16:09.601933
Epoch:[ 80 19 ] loss: 0.4213709235191345 2022-06-30 21:16:10.025141
Training_Epoch:[ 80 ] Training_loss: 0.4203722536563873 2022-06-30 21:16:10.025812
learning rate:  0.0010485760000000005
netparams have been saved once 80
val: 1 0.4520438611507416
val: 2 0.4551885426044464
val: 3 0.4615752398967743
val: 4 0.4480227530002594
val: 5 0.46084871888160706
val: 6 0.45904454588890076
val: 7 0.462092787027359
val: 8 0.4635091722011566
val: 9 0.4541313350200653
val: 10 0.47723156213760376
val: 11 0.44948747754096985
val: 12 0.4460257291793823
val: 13 0.45345282554626465
val: 14 0.45016634464263916
val: 15 0.4608541429042816
val: 16 0.4552139639854431
val: 17 0.4555736184120178
val: 18 0.4656599760055542
val: 19 0.4579979479312897
val: 20 0.45007073879241943
val_Epoch:[ 80 ] val_loss: 0.4569095641374588 2022-06-30 21:16:13.481898
start training 2022-06-30 21:16:13.584217
Epoch:[ 81 0 ] loss: 0.4191332459449768 2022-06-30 21:16:28.006540
Epoch:[ 81 1 ] loss: 0.4192783236503601 2022-06-30 21:16:28.423666
Epoch:[ 81 2 ] loss: 0.4190024435520172 2022-06-30 21:16:28.846017
Epoch:[ 81 3 ] loss: 0.4178258776664734 2022-06-30 21:16:29.268851
Epoch:[ 81 4 ] loss: 0.41771191358566284 2022-06-30 21:16:29.683760
Epoch:[ 81 5 ] loss: 0.4197772741317749 2022-06-30 21:16:30.107658
Epoch:[ 81 6 ] loss: 0.4147525429725647 2022-06-30 21:16:30.522108
Epoch:[ 81 7 ] loss: 0.420254111289978 2022-06-30 21:16:30.941058
Epoch:[ 81 8 ] loss: 0.4171229898929596 2022-06-30 21:16:31.361256
Epoch:[ 81 9 ] loss: 0.42027223110198975 2022-06-30 21:16:31.780424
Epoch:[ 81 10 ] loss: 0.41781172156333923 2022-06-30 21:16:32.200550
Epoch:[ 81 11 ] loss: 0.4190477430820465 2022-06-30 21:16:32.624887
Epoch:[ 81 12 ] loss: 0.418144166469574 2022-06-30 21:16:33.048149
Epoch:[ 81 13 ] loss: 0.41989797353744507 2022-06-30 21:16:33.462350
Epoch:[ 81 14 ] loss: 0.4146043062210083 2022-06-30 21:16:33.878424
Epoch:[ 81 15 ] loss: 0.4211864173412323 2022-06-30 21:16:34.298732
Epoch:[ 81 16 ] loss: 0.41681909561157227 2022-06-30 21:16:40.213388
Epoch:[ 81 17 ] loss: 0.4158093333244324 2022-06-30 21:16:40.631260
Epoch:[ 81 18 ] loss: 0.41998186707496643 2022-06-30 21:16:41.046486
Epoch:[ 81 19 ] loss: 0.41816529631614685 2022-06-30 21:16:41.464198
Training_Epoch:[ 81 ] Training_loss: 0.41832994371652604 2022-06-30 21:16:41.464882
learning rate:  0.0008388608000000005
val: 1 0.4663901627063751
val: 2 0.4524066746234894
val: 3 0.4527011215686798
val: 4 0.44598305225372314
val: 5 0.4608427584171295
val: 6 0.4570881426334381
val: 7 0.45870092511177063
val: 8 0.4585776627063751
val: 9 0.4539263844490051
val: 10 0.45665743947029114
val: 11 0.4522503614425659
val: 12 0.45781072974205017
val: 13 0.45495057106018066
val: 14 0.4579217731952667
val: 15 0.456306129693985
val: 16 0.4416006803512573
val: 17 0.45585206151008606
val: 18 0.46831783652305603
val: 19 0.458210289478302
val: 20 0.45186272263526917
val_Epoch:[ 81 ] val_loss: 0.45591787397861483 2022-06-30 21:16:44.942010
start training 2022-06-30 21:16:45.043510
Epoch:[ 82 0 ] loss: 0.4149176776409149 2022-06-30 21:16:59.663066
Epoch:[ 82 1 ] loss: 0.4165486693382263 2022-06-30 21:17:00.082602
Epoch:[ 82 2 ] loss: 0.4190172851085663 2022-06-30 21:17:00.505662
Epoch:[ 82 3 ] loss: 0.41405561566352844 2022-06-30 21:17:00.923047
Epoch:[ 82 4 ] loss: 0.4152022898197174 2022-06-30 21:17:01.337709
Epoch:[ 82 5 ] loss: 0.4180888831615448 2022-06-30 21:17:01.752671
Epoch:[ 82 6 ] loss: 0.4174962341785431 2022-06-30 21:17:02.167159
Epoch:[ 82 7 ] loss: 0.41681092977523804 2022-06-30 21:17:02.587794
Epoch:[ 82 8 ] loss: 0.4167126417160034 2022-06-30 21:17:03.001274
Epoch:[ 82 9 ] loss: 0.4158589243888855 2022-06-30 21:17:03.418247
Epoch:[ 82 10 ] loss: 0.4180552661418915 2022-06-30 21:17:03.836499
Epoch:[ 82 11 ] loss: 0.4180516302585602 2022-06-30 21:17:04.256223
Epoch:[ 82 12 ] loss: 0.41798487305641174 2022-06-30 21:17:04.669899
Epoch:[ 82 13 ] loss: 0.4214188754558563 2022-06-30 21:17:05.085943
Epoch:[ 82 14 ] loss: 0.41949087381362915 2022-06-30 21:17:05.507336
Epoch:[ 82 15 ] loss: 0.41577601432800293 2022-06-30 21:17:05.921972
Epoch:[ 82 16 ] loss: 0.42152464389801025 2022-06-30 21:17:11.034809
Epoch:[ 82 17 ] loss: 0.4194404184818268 2022-06-30 21:17:11.453772
Epoch:[ 82 18 ] loss: 0.4170183539390564 2022-06-30 21:17:11.871919
Epoch:[ 82 19 ] loss: 0.4171585440635681 2022-06-30 21:17:12.286773
Training_Epoch:[ 82 ] Training_loss: 0.4175314322113991 2022-06-30 21:17:12.287410
learning rate:  0.0008388608000000005
netparams have been saved once 82
val: 1 0.45010998845100403
val: 2 0.45964285731315613
val: 3 0.4713282585144043
val: 4 0.4555578827857971
val: 5 0.45830824971199036
val: 6 0.46249687671661377
val: 7 0.45130103826522827
val: 8 0.45850494503974915
val: 9 0.4585826098918915
val: 10 0.45582708716392517
val: 11 0.4574878513813019
val: 12 0.44132745265960693
val: 13 0.44483527541160583
val: 14 0.45104798674583435
val: 15 0.45825013518333435
val: 16 0.45357006788253784
val: 17 0.4664136469364166
val: 18 0.4556766748428345
val: 19 0.47324973344802856
val: 20 0.4504973888397217
val_Epoch:[ 82 ] val_loss: 0.4567008003592491 2022-06-30 21:17:15.736758
start training 2022-06-30 21:17:15.834980
Epoch:[ 83 0 ] loss: 0.41457483172416687 2022-06-30 21:17:30.273189
Epoch:[ 83 1 ] loss: 0.4195607304573059 2022-06-30 21:17:30.686935
Epoch:[ 83 2 ] loss: 0.4169224798679352 2022-06-30 21:17:31.105088
Epoch:[ 83 3 ] loss: 0.41683652997016907 2022-06-30 21:17:31.528267
Epoch:[ 83 4 ] loss: 0.4166194498538971 2022-06-30 21:17:31.944710
Epoch:[ 83 5 ] loss: 0.4168792963027954 2022-06-30 21:17:32.364629
Epoch:[ 83 6 ] loss: 0.41962018609046936 2022-06-30 21:17:32.778630
Epoch:[ 83 7 ] loss: 0.42027774453163147 2022-06-30 21:17:33.193775
Epoch:[ 83 8 ] loss: 0.41773995757102966 2022-06-30 21:17:33.612378
Epoch:[ 83 9 ] loss: 0.4191224277019501 2022-06-30 21:17:34.031922
Epoch:[ 83 10 ] loss: 0.41957998275756836 2022-06-30 21:17:34.453820
Epoch:[ 83 11 ] loss: 0.4187372028827667 2022-06-30 21:17:34.876186
Epoch:[ 83 12 ] loss: 0.4169999063014984 2022-06-30 21:17:35.291954
Epoch:[ 83 13 ] loss: 0.417521595954895 2022-06-30 21:17:35.706509
Epoch:[ 83 14 ] loss: 0.41779643297195435 2022-06-30 21:17:36.120403
Epoch:[ 83 15 ] loss: 0.417589008808136 2022-06-30 21:17:36.535591
Epoch:[ 83 16 ] loss: 0.4181194603443146 2022-06-30 21:17:42.086958
Epoch:[ 83 17 ] loss: 0.42009031772613525 2022-06-30 21:17:42.503143
Epoch:[ 83 18 ] loss: 0.41957029700279236 2022-06-30 21:17:42.920387
Epoch:[ 83 19 ] loss: 0.41860833764076233 2022-06-30 21:17:43.335926
Training_Epoch:[ 83 ] Training_loss: 0.41813830882310865 2022-06-30 21:17:43.336617
learning rate:  0.0008388608000000005
val: 1 0.4425213038921356
val: 2 0.4571782946586609
val: 3 0.45918941497802734
val: 4 0.4579917788505554
val: 5 0.45900633931159973
val: 6 0.4590557813644409
val: 7 0.4565245807170868
val: 8 0.4525521397590637
val: 9 0.449754923582077
val: 10 0.45821988582611084
val: 11 0.4333406090736389
val: 12 0.46087703108787537
val: 13 0.45882827043533325
val: 14 0.4523180425167084
val: 15 0.45456674695014954
val: 16 0.4704838693141937
val: 17 0.4571841061115265
val: 18 0.4487413167953491
val: 19 0.46212607622146606
val: 20 0.4576001763343811
val_Epoch:[ 83 ] val_loss: 0.455403034389019 2022-06-30 21:17:46.703550
start training 2022-06-30 21:17:46.800176
Epoch:[ 84 0 ] loss: 0.4177938401699066 2022-06-30 21:18:01.133850
Epoch:[ 84 1 ] loss: 0.4150630533695221 2022-06-30 21:18:01.547862
Epoch:[ 84 2 ] loss: 0.4173814356327057 2022-06-30 21:18:01.961407
Epoch:[ 84 3 ] loss: 0.41491296887397766 2022-06-30 21:18:02.381766
Epoch:[ 84 4 ] loss: 0.4177331328392029 2022-06-30 21:18:02.797708
Epoch:[ 84 5 ] loss: 0.4161401689052582 2022-06-30 21:18:03.213339
Epoch:[ 84 6 ] loss: 0.4172079563140869 2022-06-30 21:18:03.628044
Epoch:[ 84 7 ] loss: 0.41919437050819397 2022-06-30 21:18:04.051933
Epoch:[ 84 8 ] loss: 0.4163556694984436 2022-06-30 21:18:04.467328
Epoch:[ 84 9 ] loss: 0.4166313111782074 2022-06-30 21:18:04.881527
Epoch:[ 84 10 ] loss: 0.4187295436859131 2022-06-30 21:18:05.297746
Epoch:[ 84 11 ] loss: 0.41644278168678284 2022-06-30 21:18:05.720934
Epoch:[ 84 12 ] loss: 0.41756099462509155 2022-06-30 21:18:06.136509
Epoch:[ 84 13 ] loss: 0.4194581210613251 2022-06-30 21:18:06.557685
Epoch:[ 84 14 ] loss: 0.4158512055873871 2022-06-30 21:18:06.970509
Epoch:[ 84 15 ] loss: 0.4196700155735016 2022-06-30 21:18:07.385922
Epoch:[ 84 16 ] loss: 0.41454780101776123 2022-06-30 21:18:12.875085
Epoch:[ 84 17 ] loss: 0.41655275225639343 2022-06-30 21:18:13.288498
Epoch:[ 84 18 ] loss: 0.42068594694137573 2022-06-30 21:18:13.705371
Epoch:[ 84 19 ] loss: 0.4177232086658478 2022-06-30 21:18:14.120343
Training_Epoch:[ 84 ] Training_loss: 0.4172818139195442 2022-06-30 21:18:14.120989
learning rate:  0.0008388608000000005
netparams have been saved once 84
val: 1 0.4349396228790283
val: 2 0.44841280579566956
val: 3 0.4591163098812103
val: 4 0.4665730595588684
val: 5 0.4586012661457062
val: 6 0.45362335443496704
val: 7 0.4632093608379364
val: 8 0.47723445296287537
val: 9 0.4744655191898346
val: 10 0.475021094083786
val: 11 0.4653949439525604
val: 12 0.4570689797401428
val: 13 0.4444558322429657
val: 14 0.4579721987247467
val: 15 0.4644436240196228
val: 16 0.4674563705921173
val: 17 0.45525363087654114
val: 18 0.46534907817840576
val: 19 0.451891154050827
val: 20 0.4544191360473633
val_Epoch:[ 84 ] val_loss: 0.45974508970975875 2022-06-30 21:18:17.571706
start training 2022-06-30 21:18:17.668880
Epoch:[ 85 0 ] loss: 0.4177464544773102 2022-06-30 21:18:32.155756
Epoch:[ 85 1 ] loss: 0.41584935784339905 2022-06-30 21:18:32.575693
Epoch:[ 85 2 ] loss: 0.4163968861103058 2022-06-30 21:18:32.990528
Epoch:[ 85 3 ] loss: 0.41573628783226013 2022-06-30 21:18:33.404716
Epoch:[ 85 4 ] loss: 0.41706034541130066 2022-06-30 21:18:33.817026
Epoch:[ 85 5 ] loss: 0.419743150472641 2022-06-30 21:18:34.233131
Epoch:[ 85 6 ] loss: 0.41304466128349304 2022-06-30 21:18:34.648537
Epoch:[ 85 7 ] loss: 0.4181782603263855 2022-06-30 21:18:35.070472
Epoch:[ 85 8 ] loss: 0.41542914509773254 2022-06-30 21:18:35.483764
Epoch:[ 85 9 ] loss: 0.4178507924079895 2022-06-30 21:18:35.904099
Epoch:[ 85 10 ] loss: 0.41638535261154175 2022-06-30 21:18:36.316767
Epoch:[ 85 11 ] loss: 0.41870880126953125 2022-06-30 21:18:36.729994
Epoch:[ 85 12 ] loss: 0.41492775082588196 2022-06-30 21:18:37.145866
Epoch:[ 85 13 ] loss: 0.4155607521533966 2022-06-30 21:18:37.561082
Epoch:[ 85 14 ] loss: 0.41919589042663574 2022-06-30 21:18:37.982112
Epoch:[ 85 15 ] loss: 0.4185071587562561 2022-06-30 21:18:38.395665
Epoch:[ 85 16 ] loss: 0.41899728775024414 2022-06-30 21:18:43.749116
Epoch:[ 85 17 ] loss: 0.416093647480011 2022-06-30 21:18:44.164681
Epoch:[ 85 18 ] loss: 0.420299232006073 2022-06-30 21:18:44.584782
Epoch:[ 85 19 ] loss: 0.4163757562637329 2022-06-30 21:18:45.001972
Training_Epoch:[ 85 ] Training_loss: 0.4171043485403061 2022-06-30 21:18:45.002618
learning rate:  0.0008388608000000005
val: 1 0.4538502097129822
val: 2 0.46068528294563293
val: 3 0.4603756070137024
val: 4 0.453766793012619
val: 5 0.4519340991973877
val: 6 0.4603157043457031
val: 7 0.4517802298069
val: 8 0.4452923834323883
val: 9 0.440688818693161
val: 10 0.4524737298488617
val: 11 0.4511696696281433
val: 12 0.45460766553878784
val: 13 0.4670770466327667
val: 14 0.46025583148002625
val: 15 0.4596168100833893
val: 16 0.45045384764671326
val: 17 0.45715394616127014
val: 18 0.4637826085090637
val: 19 0.45860281586647034
val: 20 0.4549492299556732
val_Epoch:[ 85 ] val_loss: 0.4554416164755821 2022-06-30 21:18:48.370112
start training 2022-06-30 21:18:48.465787
Epoch:[ 86 0 ] loss: 0.41648751497268677 2022-06-30 21:19:02.629871
Epoch:[ 86 1 ] loss: 0.41704046726226807 2022-06-30 21:19:03.082956
Epoch:[ 86 2 ] loss: 0.4129132032394409 2022-06-30 21:19:03.503496
Epoch:[ 86 3 ] loss: 0.41575005650520325 2022-06-30 21:19:03.918732
Epoch:[ 86 4 ] loss: 0.41321149468421936 2022-06-30 21:19:04.340164
Epoch:[ 86 5 ] loss: 0.4160185754299164 2022-06-30 21:19:04.754588
Epoch:[ 86 6 ] loss: 0.4177907705307007 2022-06-30 21:19:05.173300
Epoch:[ 86 7 ] loss: 0.4136425256729126 2022-06-30 21:19:05.589205
Epoch:[ 86 8 ] loss: 0.4146093726158142 2022-06-30 21:19:06.004877
Epoch:[ 86 9 ] loss: 0.41475051641464233 2022-06-30 21:19:06.424655
Epoch:[ 86 10 ] loss: 0.41814500093460083 2022-06-30 21:19:06.839176
Epoch:[ 86 11 ] loss: 0.41370296478271484 2022-06-30 21:19:07.253958
Epoch:[ 86 12 ] loss: 0.41756853461265564 2022-06-30 21:19:07.673936
Epoch:[ 86 13 ] loss: 0.41561150550842285 2022-06-30 21:19:08.090063
Epoch:[ 86 14 ] loss: 0.41805341839790344 2022-06-30 21:19:08.506313
Epoch:[ 86 15 ] loss: 0.4161494970321655 2022-06-30 21:19:08.923679
Epoch:[ 86 16 ] loss: 0.41672009229660034 2022-06-30 21:19:14.320032
Epoch:[ 86 17 ] loss: 0.4145786166191101 2022-06-30 21:19:14.927029
Epoch:[ 86 18 ] loss: 0.41737765073776245 2022-06-30 21:19:15.342422
Epoch:[ 86 19 ] loss: 0.4144562780857086 2022-06-30 21:19:15.756922
Training_Epoch:[ 86 ] Training_loss: 0.41572890281677244 2022-06-30 21:19:15.757546
learning rate:  0.0008388608000000005
netparams have been saved once 86
val: 1 0.4808567464351654
val: 2 0.4591234624385834
val: 3 0.4480120539665222
val: 4 0.45012596249580383
val: 5 0.4720384180545807
val: 6 0.4695464074611664
val: 7 0.46364375948905945
val: 8 0.4604180157184601
val: 9 0.4714895486831665
val: 10 0.4634801149368286
val: 11 0.4671986699104309
val: 12 0.46742042899131775
val: 13 0.4527195692062378
val: 14 0.46041399240493774
val: 15 0.46042731404304504
val: 16 0.4554903507232666
val: 17 0.4560301601886749
val: 18 0.46510520577430725
val: 19 0.4467787742614746
val: 20 0.45300859212875366
val_Epoch:[ 86 ] val_loss: 0.46116637736558913 2022-06-30 21:19:19.098129
start training 2022-06-30 21:19:19.195189
Epoch:[ 87 0 ] loss: 0.4150749146938324 2022-06-30 21:19:33.581577
Epoch:[ 87 1 ] loss: 0.4115707278251648 2022-06-30 21:19:34.004215
Epoch:[ 87 2 ] loss: 0.41551876068115234 2022-06-30 21:19:34.419917
Epoch:[ 87 3 ] loss: 0.41514909267425537 2022-06-30 21:19:34.834626
Epoch:[ 87 4 ] loss: 0.4146198034286499 2022-06-30 21:19:35.249486
Epoch:[ 87 5 ] loss: 0.41279464960098267 2022-06-30 21:19:35.665080
Epoch:[ 87 6 ] loss: 0.41386061906814575 2022-06-30 21:19:36.078315
Epoch:[ 87 7 ] loss: 0.41804319620132446 2022-06-30 21:19:36.501627
Epoch:[ 87 8 ] loss: 0.4180600643157959 2022-06-30 21:19:36.923027
Epoch:[ 87 9 ] loss: 0.4175971448421478 2022-06-30 21:19:37.338478
Epoch:[ 87 10 ] loss: 0.41416051983833313 2022-06-30 21:19:37.754724
Epoch:[ 87 11 ] loss: 0.4144478440284729 2022-06-30 21:19:38.175715
Epoch:[ 87 12 ] loss: 0.4136745035648346 2022-06-30 21:19:38.590267
Epoch:[ 87 13 ] loss: 0.41545549035072327 2022-06-30 21:19:39.004951
Epoch:[ 87 14 ] loss: 0.41468673944473267 2022-06-30 21:19:39.420801
Epoch:[ 87 15 ] loss: 0.4157520830631256 2022-06-30 21:19:39.838320
Epoch:[ 87 16 ] loss: 0.41565439105033875 2022-06-30 21:19:45.110605
Epoch:[ 87 17 ] loss: 0.41493910551071167 2022-06-30 21:19:45.785405
Epoch:[ 87 18 ] loss: 0.41500693559646606 2022-06-30 21:19:46.201221
Epoch:[ 87 19 ] loss: 0.41676509380340576 2022-06-30 21:19:46.616206
Training_Epoch:[ 87 ] Training_loss: 0.4151415839791298 2022-06-30 21:19:46.616873
learning rate:  0.0008388608000000005
val: 1 0.46305522322654724
val: 2 0.4576455056667328
val: 3 0.45671188831329346
val: 4 0.46030718088150024
val: 5 0.4546419382095337
val: 6 0.4571363031864166
val: 7 0.45095181465148926
val: 8 0.4473871886730194
val: 9 0.45320335030555725
val: 10 0.46074163913726807
val: 11 0.4633433520793915
val: 12 0.4714307188987732
val: 13 0.4356033504009247
val: 14 0.4557317793369293
val: 15 0.4482095241546631
val: 16 0.468095988035202
val: 17 0.4453968107700348
val: 18 0.45509055256843567
val: 19 0.45397451519966125
val: 20 0.46365001797676086
val_Epoch:[ 87 ] val_loss: 0.4561154320836067 2022-06-30 21:19:49.961563
start training 2022-06-30 21:19:50.052843
Epoch:[ 88 0 ] loss: 0.4109555184841156 2022-06-30 21:20:04.059981
Epoch:[ 88 1 ] loss: 0.4129372835159302 2022-06-30 21:20:04.506793
Epoch:[ 88 2 ] loss: 0.41334661841392517 2022-06-30 21:20:04.929667
Epoch:[ 88 3 ] loss: 0.4130977392196655 2022-06-30 21:20:05.346278
Epoch:[ 88 4 ] loss: 0.41338589787483215 2022-06-30 21:20:05.759165
Epoch:[ 88 5 ] loss: 0.4148953855037689 2022-06-30 21:20:06.173306
Epoch:[ 88 6 ] loss: 0.4162294566631317 2022-06-30 21:20:06.589924
Epoch:[ 88 7 ] loss: 0.41464963555336 2022-06-30 21:20:07.005545
Epoch:[ 88 8 ] loss: 0.4152022898197174 2022-06-30 21:20:07.427385
Epoch:[ 88 9 ] loss: 0.4193873703479767 2022-06-30 21:20:07.843399
Epoch:[ 88 10 ] loss: 0.41631948947906494 2022-06-30 21:20:08.263630
Epoch:[ 88 11 ] loss: 0.41707339882850647 2022-06-30 21:20:08.678501
Epoch:[ 88 12 ] loss: 0.41475847363471985 2022-06-30 21:20:09.092771
Epoch:[ 88 13 ] loss: 0.4169519543647766 2022-06-30 21:20:09.509017
Epoch:[ 88 14 ] loss: 0.4158508777618408 2022-06-30 21:20:09.928529
Epoch:[ 88 15 ] loss: 0.4137784540653229 2022-06-30 21:20:10.345581
Epoch:[ 88 16 ] loss: 0.41624343395233154 2022-06-30 21:20:15.739384
Epoch:[ 88 17 ] loss: 0.4129737913608551 2022-06-30 21:20:16.337283
Epoch:[ 88 18 ] loss: 0.41737374663352966 2022-06-30 21:20:16.752525
Epoch:[ 88 19 ] loss: 0.41701868176460266 2022-06-30 21:20:17.167887
Training_Epoch:[ 88 ] Training_loss: 0.4151214748620987 2022-06-30 21:20:17.168577
learning rate:  0.0008388608000000005
netparams have been saved once 88
val: 1 0.4477234184741974
val: 2 0.4532228112220764
val: 3 0.459807813167572
val: 4 0.4664278030395508
val: 5 0.46018844842910767
val: 6 0.4553115963935852
val: 7 0.4525851607322693
val: 8 0.45523035526275635
val: 9 0.46424099802970886
val: 10 0.4612537920475006
val: 11 0.46070289611816406
val: 12 0.44827163219451904
val: 13 0.4562976062297821
val: 14 0.4528931677341461
val: 15 0.4476889967918396
val: 16 0.45945650339126587
val: 17 0.4568459093570709
val: 18 0.46134650707244873
val: 19 0.46402329206466675
val: 20 0.45464348793029785
val_Epoch:[ 88 ] val_loss: 0.45690810978412627 2022-06-30 21:20:20.569769
start training 2022-06-30 21:20:20.661718
Epoch:[ 89 0 ] loss: 0.4122315049171448 2022-06-30 21:20:34.656901
Epoch:[ 89 1 ] loss: 0.41374459862709045 2022-06-30 21:20:35.085082
Epoch:[ 89 2 ] loss: 0.4170285165309906 2022-06-30 21:20:35.501061
Epoch:[ 89 3 ] loss: 0.41326919198036194 2022-06-30 21:20:35.917502
Epoch:[ 89 4 ] loss: 0.41551563143730164 2022-06-30 21:20:36.332673
Epoch:[ 89 5 ] loss: 0.41728442907333374 2022-06-30 21:20:36.747742
Epoch:[ 89 6 ] loss: 0.4138278067111969 2022-06-30 21:20:37.162411
Epoch:[ 89 7 ] loss: 0.4118781089782715 2022-06-30 21:20:37.576903
Epoch:[ 89 8 ] loss: 0.4136262834072113 2022-06-30 21:20:37.990140
Epoch:[ 89 9 ] loss: 0.416868656873703 2022-06-30 21:20:38.407739
Epoch:[ 89 10 ] loss: 0.41285985708236694 2022-06-30 21:20:38.831651
Epoch:[ 89 11 ] loss: 0.41121965646743774 2022-06-30 21:20:39.251422
Epoch:[ 89 12 ] loss: 0.4166136682033539 2022-06-30 21:20:39.668126
Epoch:[ 89 13 ] loss: 0.4158557951450348 2022-06-30 21:20:40.090959
Epoch:[ 89 14 ] loss: 0.4167131781578064 2022-06-30 21:20:40.510399
Epoch:[ 89 15 ] loss: 0.4142568111419678 2022-06-30 21:20:40.925261
Epoch:[ 89 16 ] loss: 0.4167706370353699 2022-06-30 21:20:46.360411
Epoch:[ 89 17 ] loss: 0.41524603962898254 2022-06-30 21:20:46.776567
Epoch:[ 89 18 ] loss: 0.41705554723739624 2022-06-30 21:20:47.200942
Epoch:[ 89 19 ] loss: 0.41401994228363037 2022-06-30 21:20:47.630612
Training_Epoch:[ 89 ] Training_loss: 0.41479429304599763 2022-06-30 21:20:47.631268
learning rate:  0.0008388608000000005
val: 1 0.46869373321533203
val: 2 0.4498042166233063
val: 3 0.4618195593357086
val: 4 0.4553646147251129
val: 5 0.4535924196243286
val: 6 0.4459821581840515
val: 7 0.45121264457702637
val: 8 0.45687705278396606
val: 9 0.4516529142856598
val: 10 0.4464673101902008
val: 11 0.4481336772441864
val: 12 0.44658681750297546
val: 13 0.44906774163246155
val: 14 0.4656144678592682
val: 15 0.45564085245132446
val: 16 0.467248797416687
val: 17 0.45141473412513733
val: 18 0.45150747895240784
val: 19 0.46847057342529297
val: 20 0.46072444319725037
val_Epoch:[ 89 ] val_loss: 0.4552938103675842 2022-06-30 21:20:51.019604
start training 2022-06-30 21:20:51.114897
Epoch:[ 90 0 ] loss: 0.4128713607788086 2022-06-30 21:21:05.726416
Epoch:[ 90 1 ] loss: 0.41515234112739563 2022-06-30 21:21:06.149464
Epoch:[ 90 2 ] loss: 0.41450443863868713 2022-06-30 21:21:06.563500
Epoch:[ 90 3 ] loss: 0.41233015060424805 2022-06-30 21:21:06.980090
Epoch:[ 90 4 ] loss: 0.41637542843818665 2022-06-30 21:21:07.397123
Epoch:[ 90 5 ] loss: 0.41239845752716064 2022-06-30 21:21:07.815419
Epoch:[ 90 6 ] loss: 0.4115638732910156 2022-06-30 21:21:08.234977
Epoch:[ 90 7 ] loss: 0.41403496265411377 2022-06-30 21:21:08.650616
Epoch:[ 90 8 ] loss: 0.4148607850074768 2022-06-30 21:21:09.064591
Epoch:[ 90 9 ] loss: 0.41620370745658875 2022-06-30 21:21:09.481186
Epoch:[ 90 10 ] loss: 0.41464605927467346 2022-06-30 21:21:09.897686
Epoch:[ 90 11 ] loss: 0.41755926609039307 2022-06-30 21:21:10.318699
Epoch:[ 90 12 ] loss: 0.41698434948921204 2022-06-30 21:21:10.738250
Epoch:[ 90 13 ] loss: 0.41908547282218933 2022-06-30 21:21:11.223956
Epoch:[ 90 14 ] loss: 0.41144469380378723 2022-06-30 21:21:11.639200
Epoch:[ 90 15 ] loss: 0.4176371097564697 2022-06-30 21:21:12.053997
Epoch:[ 90 16 ] loss: 0.4149397909641266 2022-06-30 21:21:17.652341
Epoch:[ 90 17 ] loss: 0.41985952854156494 2022-06-30 21:21:18.084482
Epoch:[ 90 18 ] loss: 0.41288331151008606 2022-06-30 21:21:18.509718
Epoch:[ 90 19 ] loss: 0.41889533400535583 2022-06-30 21:21:18.926473
Training_Epoch:[ 90 ] Training_loss: 0.415211521089077 2022-06-30 21:21:18.927151
learning rate:  0.0008388608000000005
netparams have been saved once 90
val: 1 0.4541235864162445
val: 2 0.4568060040473938
val: 3 0.4502705931663513
val: 4 0.46670570969581604
val: 5 0.457444429397583
val: 6 0.45811402797698975
val: 7 0.4523320198059082
val: 8 0.43687549233436584
val: 9 0.448819637298584
val: 10 0.45316916704177856
val: 11 0.47122448682785034
val: 12 0.44896847009658813
val: 13 0.4584147036075592
val: 14 0.46475866436958313
val: 15 0.4614206552505493
val: 16 0.4456219971179962
val: 17 0.45329609513282776
val: 18 0.4553738534450531
val: 19 0.4524596929550171
val: 20 0.4495529234409332
val_Epoch:[ 90 ] val_loss: 0.4547876104712486 2022-06-30 21:21:22.351523
start training 2022-06-30 21:21:22.443795
Epoch:[ 91 0 ] loss: 0.41360989212989807 2022-06-30 21:21:36.384083
Epoch:[ 91 1 ] loss: 0.41358181834220886 2022-06-30 21:21:37.103831
Epoch:[ 91 2 ] loss: 0.41422784328460693 2022-06-30 21:21:37.516964
Epoch:[ 91 3 ] loss: 0.41218093037605286 2022-06-30 21:21:37.931255
Epoch:[ 91 4 ] loss: 0.4134812355041504 2022-06-30 21:21:38.347391
Epoch:[ 91 5 ] loss: 0.4125367999076843 2022-06-30 21:21:38.762914
Epoch:[ 91 6 ] loss: 0.41201886534690857 2022-06-30 21:21:39.184017
Epoch:[ 91 7 ] loss: 0.4114309251308441 2022-06-30 21:21:39.597868
Epoch:[ 91 8 ] loss: 0.4113006889820099 2022-06-30 21:21:40.013868
Epoch:[ 91 9 ] loss: 0.41387489438056946 2022-06-30 21:21:40.427454
Epoch:[ 91 10 ] loss: 0.4121394157409668 2022-06-30 21:21:40.840962
Epoch:[ 91 11 ] loss: 0.41521474719047546 2022-06-30 21:21:41.268074
Epoch:[ 91 12 ] loss: 0.41481658816337585 2022-06-30 21:21:41.750107
Epoch:[ 91 13 ] loss: 0.4107035994529724 2022-06-30 21:21:42.173069
Epoch:[ 91 14 ] loss: 0.41003021597862244 2022-06-30 21:21:42.591627
Epoch:[ 91 15 ] loss: 0.41274672746658325 2022-06-30 21:21:43.007177
Epoch:[ 91 16 ] loss: 0.4102073013782501 2022-06-30 21:21:48.770502
Epoch:[ 91 17 ] loss: 0.4119245111942291 2022-06-30 21:21:49.183689
Epoch:[ 91 18 ] loss: 0.4134672284126282 2022-06-30 21:21:49.607037
Epoch:[ 91 19 ] loss: 0.41341808438301086 2022-06-30 21:21:50.022591
Training_Epoch:[ 91 ] Training_loss: 0.4126456156373024 2022-06-30 21:21:50.023236
learning rate:  0.0006710886400000004
val: 1 0.4633200466632843
val: 2 0.45852965116500854
val: 3 0.46254608035087585
val: 4 0.4489993155002594
val: 5 0.45394641160964966
val: 6 0.46455511450767517
val: 7 0.45760923624038696
val: 8 0.45005589723587036
val: 9 0.4563605487346649
val: 10 0.4518011212348938
val: 11 0.4625217318534851
val: 12 0.4687974452972412
val: 13 0.4526849687099457
val: 14 0.4593138098716736
val: 15 0.46191513538360596
val: 16 0.45970839262008667
val: 17 0.4652283787727356
val: 18 0.455750048160553
val: 19 0.45793417096138
val: 20 0.4681524634361267
val_Epoch:[ 91 ] val_loss: 0.4589864984154701 2022-06-30 21:21:53.372865
start training 2022-06-30 21:21:53.467727
Epoch:[ 92 0 ] loss: 0.41094034910202026 2022-06-30 21:22:07.785660
Epoch:[ 92 1 ] loss: 0.4094163775444031 2022-06-30 21:22:08.199456
Epoch:[ 92 2 ] loss: 0.4107970595359802 2022-06-30 21:22:08.614692
Epoch:[ 92 3 ] loss: 0.40778765082359314 2022-06-30 21:22:09.035819
Epoch:[ 92 4 ] loss: 0.41181713342666626 2022-06-30 21:22:09.451870
Epoch:[ 92 5 ] loss: 0.41033220291137695 2022-06-30 21:22:09.874192
Epoch:[ 92 6 ] loss: 0.4080142378807068 2022-06-30 21:22:10.290106
Epoch:[ 92 7 ] loss: 0.4098454415798187 2022-06-30 21:22:10.715976
Epoch:[ 92 8 ] loss: 0.41231709718704224 2022-06-30 21:22:11.171318
Epoch:[ 92 9 ] loss: 0.4098988175392151 2022-06-30 21:22:11.638642
Epoch:[ 92 10 ] loss: 0.4102957844734192 2022-06-30 21:22:12.052106
Epoch:[ 92 11 ] loss: 0.41165146231651306 2022-06-30 21:22:12.467294
Epoch:[ 92 12 ] loss: 0.4141104817390442 2022-06-30 21:22:12.883201
Epoch:[ 92 13 ] loss: 0.4125354290008545 2022-06-30 21:22:13.299773
Epoch:[ 92 14 ] loss: 0.41333118081092834 2022-06-30 21:22:13.720802
Epoch:[ 92 15 ] loss: 0.4092639088630676 2022-06-30 21:22:14.136238
Epoch:[ 92 16 ] loss: 0.4104919731616974 2022-06-30 21:22:19.568923
Epoch:[ 92 17 ] loss: 0.4105885922908783 2022-06-30 21:22:19.982580
Epoch:[ 92 18 ] loss: 0.413310170173645 2022-06-30 21:22:20.396828
Epoch:[ 92 19 ] loss: 0.4110133647918701 2022-06-30 21:22:20.814130
Training_Epoch:[ 92 ] Training_loss: 0.41088793575763705 2022-06-30 21:22:20.814786
learning rate:  0.0006710886400000004
netparams have been saved once 92
val: 1 0.4629570543766022
val: 2 0.45261409878730774
val: 3 0.46415945887565613
val: 4 0.45225992798805237
val: 5 0.45766735076904297
val: 6 0.4664197266101837
val: 7 0.46691441535949707
val: 8 0.4520767629146576
val: 9 0.46733224391937256
val: 10 0.44596385955810547
val: 11 0.4442119300365448
val: 12 0.45619621872901917
val: 13 0.45451223850250244
val: 14 0.4486682713031769
val: 15 0.46071118116378784
val: 16 0.4436265230178833
val: 17 0.46139469742774963
val: 18 0.4545339345932007
val: 19 0.4594387114048004
val: 20 0.44735589623451233
val_Epoch:[ 92 ] val_loss: 0.45595072507858275 2022-06-30 21:22:24.207378
start training 2022-06-30 21:22:24.301878
Epoch:[ 93 0 ] loss: 0.40752044320106506 2022-06-30 21:22:38.028612
Epoch:[ 93 1 ] loss: 0.4086264669895172 2022-06-30 21:22:38.465554
Epoch:[ 93 2 ] loss: 0.4101296365261078 2022-06-30 21:22:38.909086
Epoch:[ 93 3 ] loss: 0.4107494354248047 2022-06-30 21:22:39.325148
Epoch:[ 93 4 ] loss: 0.41232386231422424 2022-06-30 21:22:39.741546
Epoch:[ 93 5 ] loss: 0.41259509325027466 2022-06-30 21:22:40.164659
Epoch:[ 93 6 ] loss: 0.4096139371395111 2022-06-30 21:22:40.579846
Epoch:[ 93 7 ] loss: 0.41127079725265503 2022-06-30 21:22:41.013265
Epoch:[ 93 8 ] loss: 0.40675604343414307 2022-06-30 21:22:41.496370
Epoch:[ 93 9 ] loss: 0.4094931483268738 2022-06-30 21:22:41.912674
Epoch:[ 93 10 ] loss: 0.4091281294822693 2022-06-30 21:22:42.326886
Epoch:[ 93 11 ] loss: 0.4106736481189728 2022-06-30 21:22:42.742003
Epoch:[ 93 12 ] loss: 0.4111710786819458 2022-06-30 21:22:43.155926
Epoch:[ 93 13 ] loss: 0.40989500284194946 2022-06-30 21:22:43.572684
Epoch:[ 93 14 ] loss: 0.4112609326839447 2022-06-30 21:22:43.988387
Epoch:[ 93 15 ] loss: 0.4120553731918335 2022-06-30 21:22:44.405275
Epoch:[ 93 16 ] loss: 0.41028159856796265 2022-06-30 21:22:49.720173
Epoch:[ 93 17 ] loss: 0.4090864956378937 2022-06-30 21:22:50.195557
Epoch:[ 93 18 ] loss: 0.4120591878890991 2022-06-30 21:22:50.611249
Epoch:[ 93 19 ] loss: 0.4114665687084198 2022-06-30 21:22:51.025264
Training_Epoch:[ 93 ] Training_loss: 0.4103078439831734 2022-06-30 21:22:51.025901
learning rate:  0.0006710886400000004
val: 1 0.4606555998325348
val: 2 0.457919716835022
val: 3 0.45042693614959717
val: 4 0.4614233672618866
val: 5 0.4528491795063019
val: 6 0.46851998567581177
val: 7 0.4526291787624359
val: 8 0.4571254849433899
val: 9 0.4568500518798828
val: 10 0.4587729275226593
val: 11 0.46024003624916077
val: 12 0.46354928612709045
val: 13 0.4566785395145416
val: 14 0.4561470150947571
val: 15 0.46088752150535583
val: 16 0.4642959535121918
val: 17 0.4605724811553955
val: 18 0.4496498107910156
val: 19 0.45677825808525085
val: 20 0.4577770531177521
val_Epoch:[ 93 ] val_loss: 0.4581874191761017 2022-06-30 21:22:54.384431
start training 2022-06-30 21:22:54.478255
Epoch:[ 94 0 ] loss: 0.4101932942867279 2022-06-30 21:23:07.951242
Epoch:[ 94 1 ] loss: 0.4094330072402954 2022-06-30 21:23:08.748111
Epoch:[ 94 2 ] loss: 0.40946581959724426 2022-06-30 21:23:09.162458
Epoch:[ 94 3 ] loss: 0.4096289873123169 2022-06-30 21:23:09.578241
Epoch:[ 94 4 ] loss: 0.4079624116420746 2022-06-30 21:23:09.994033
Epoch:[ 94 5 ] loss: 0.4105941653251648 2022-06-30 21:23:10.408734
Epoch:[ 94 6 ] loss: 0.40561187267303467 2022-06-30 21:23:10.867140
Epoch:[ 94 7 ] loss: 0.40945178270339966 2022-06-30 21:23:11.349014
Epoch:[ 94 8 ] loss: 0.4104742109775543 2022-06-30 21:23:11.766671
Epoch:[ 94 9 ] loss: 0.40951502323150635 2022-06-30 21:23:12.188809
Epoch:[ 94 10 ] loss: 0.41060683131217957 2022-06-30 21:23:12.609198
Epoch:[ 94 11 ] loss: 0.40888622403144836 2022-06-30 21:23:13.024928
Epoch:[ 94 12 ] loss: 0.410545289516449 2022-06-30 21:23:13.441105
Epoch:[ 94 13 ] loss: 0.40729179978370667 2022-06-30 21:23:13.862171
Epoch:[ 94 14 ] loss: 0.4085024297237396 2022-06-30 21:23:14.278924
Epoch:[ 94 15 ] loss: 0.41113990545272827 2022-06-30 21:23:14.694777
Epoch:[ 94 16 ] loss: 0.41064393520355225 2022-06-30 21:23:19.872227
Epoch:[ 94 17 ] loss: 0.4110352396965027 2022-06-30 21:23:20.585862
Epoch:[ 94 18 ] loss: 0.41627755761146545 2022-06-30 21:23:21.002744
Epoch:[ 94 19 ] loss: 0.40972211956977844 2022-06-30 21:23:21.417393
Training_Epoch:[ 94 ] Training_loss: 0.40984909534454345 2022-06-30 21:23:21.418129
learning rate:  0.0006710886400000004
netparams have been saved once 94
val: 1 0.4500255882740021
val: 2 0.4674501419067383
val: 3 0.45048394799232483
val: 4 0.45582711696624756
val: 5 0.4573880136013031
val: 6 0.4670948386192322
val: 7 0.47621774673461914
val: 8 0.46228480339050293
val: 9 0.46749258041381836
val: 10 0.45678213238716125
val: 11 0.45488685369491577
val: 12 0.4553290903568268
val: 13 0.46096158027648926
val: 14 0.44560760259628296
val: 15 0.46166157722473145
val: 16 0.4477308988571167
val: 17 0.4446586072444916
val: 18 0.4570060074329376
val: 19 0.4489234387874603
val: 20 0.4464632272720337
val_Epoch:[ 94 ] val_loss: 0.4567137897014618 2022-06-30 21:23:24.852789
start training 2022-06-30 21:23:24.950047
Epoch:[ 95 0 ] loss: 0.4106488823890686 2022-06-30 21:23:39.753122
Epoch:[ 95 1 ] loss: 0.4099881947040558 2022-06-30 21:23:40.175165
Epoch:[ 95 2 ] loss: 0.41096851229667664 2022-06-30 21:23:40.597629
Epoch:[ 95 3 ] loss: 0.41405948996543884 2022-06-30 21:23:41.019736
Epoch:[ 95 4 ] loss: 0.4090285897254944 2022-06-30 21:23:41.434018
Epoch:[ 95 5 ] loss: 0.41362935304641724 2022-06-30 21:23:41.870524
Epoch:[ 95 6 ] loss: 0.40824851393699646 2022-06-30 21:23:42.349834
Epoch:[ 95 7 ] loss: 0.40879085659980774 2022-06-30 21:23:42.764608
Epoch:[ 95 8 ] loss: 0.41069403290748596 2022-06-30 21:23:43.180821
Epoch:[ 95 9 ] loss: 0.4082081913948059 2022-06-30 21:23:43.596728
Epoch:[ 95 10 ] loss: 0.413604199886322 2022-06-30 21:23:44.011523
Epoch:[ 95 11 ] loss: 0.41148364543914795 2022-06-30 21:23:44.426380
Epoch:[ 95 12 ] loss: 0.4144369959831238 2022-06-30 21:23:44.845904
Epoch:[ 95 13 ] loss: 0.4097403883934021 2022-06-30 21:23:45.259450
Epoch:[ 95 14 ] loss: 0.4119064509868622 2022-06-30 21:23:45.672753
Epoch:[ 95 15 ] loss: 0.4078652262687683 2022-06-30 21:23:46.094619
Epoch:[ 95 16 ] loss: 0.4128676950931549 2022-06-30 21:23:51.688886
Epoch:[ 95 17 ] loss: 0.4121103286743164 2022-06-30 21:23:52.103099
Epoch:[ 95 18 ] loss: 0.4094545841217041 2022-06-30 21:23:52.517864
Epoch:[ 95 19 ] loss: 0.41520246863365173 2022-06-30 21:23:52.933175
Training_Epoch:[ 95 ] Training_loss: 0.41114683002233504 2022-06-30 21:23:52.933800
learning rate:  0.0006710886400000004
val: 1 0.4580520987510681
val: 2 0.46430617570877075
val: 3 0.4576834440231323
val: 4 0.45500653982162476
val: 5 0.4744972586631775
val: 6 0.4725274443626404
val: 7 0.46489977836608887
val: 8 0.4650166928768158
val: 9 0.4618527293205261
val: 10 0.45050767064094543
val: 11 0.4606318771839142
val: 12 0.451379656791687
val: 13 0.4661433696746826
val: 14 0.4576238691806793
val: 15 0.46597573161125183
val: 16 0.4660727083683014
val: 17 0.4707126021385193
val: 18 0.4591498076915741
val: 19 0.44746264815330505
val: 20 0.45865750312805176
val_Epoch:[ 95 ] val_loss: 0.4614079803228378 2022-06-30 21:23:56.306429
start training 2022-06-30 21:23:56.402199
Epoch:[ 96 0 ] loss: 0.4101541340351105 2022-06-30 21:24:10.344454
Epoch:[ 96 1 ] loss: 0.41141077876091003 2022-06-30 21:24:10.782733
Epoch:[ 96 2 ] loss: 0.4089062809944153 2022-06-30 21:24:11.204336
Epoch:[ 96 3 ] loss: 0.41207921504974365 2022-06-30 21:24:11.645631
Epoch:[ 96 4 ] loss: 0.40999436378479004 2022-06-30 21:24:12.128259
Epoch:[ 96 5 ] loss: 0.4072968363761902 2022-06-30 21:24:12.542425
Epoch:[ 96 6 ] loss: 0.409241646528244 2022-06-30 21:24:12.955586
Epoch:[ 96 7 ] loss: 0.41026362776756287 2022-06-30 21:24:13.370453
Epoch:[ 96 8 ] loss: 0.4079001247882843 2022-06-30 21:24:13.790165
Epoch:[ 96 9 ] loss: 0.40859031677246094 2022-06-30 21:24:14.206284
Epoch:[ 96 10 ] loss: 0.4096697270870209 2022-06-30 21:24:14.621469
Epoch:[ 96 11 ] loss: 0.4065828025341034 2022-06-30 21:24:15.037629
Epoch:[ 96 12 ] loss: 0.41208404302597046 2022-06-30 21:24:15.452434
Epoch:[ 96 13 ] loss: 0.410861611366272 2022-06-30 21:24:15.867082
Epoch:[ 96 14 ] loss: 0.41160961985588074 2022-06-30 21:24:16.288726
Epoch:[ 96 15 ] loss: 0.40934497117996216 2022-06-30 21:24:16.709846
Epoch:[ 96 16 ] loss: 0.4094030559062958 2022-06-30 21:24:21.990336
Epoch:[ 96 17 ] loss: 0.40948885679244995 2022-06-30 21:24:22.422108
Epoch:[ 96 18 ] loss: 0.4119342267513275 2022-06-30 21:24:22.843067
Epoch:[ 96 19 ] loss: 0.40824025869369507 2022-06-30 21:24:23.258661
Training_Epoch:[ 96 ] Training_loss: 0.4097528249025345 2022-06-30 21:24:23.259358
learning rate:  0.0006710886400000004
netparams have been saved once 96
val: 1 0.4650336503982544
val: 2 0.46089300513267517
val: 3 0.45523202419281006
val: 4 0.46903756260871887
val: 5 0.46515706181526184
val: 6 0.4704047739505768
val: 7 0.44892263412475586
val: 8 0.4442780911922455
val: 9 0.47591015696525574
val: 10 0.45089009404182434
val: 11 0.45221975445747375
val: 12 0.4624384045600891
val: 13 0.4502989947795868
val: 14 0.4536193609237671
val: 15 0.4585084319114685
val: 16 0.4691259562969208
val: 17 0.4520161747932434
val: 18 0.458967924118042
val: 19 0.46298539638519287
val: 20 0.4542591869831085
val_Epoch:[ 96 ] val_loss: 0.4590099319815636 2022-06-30 21:24:26.639699
start training 2022-06-30 21:24:26.737007
Epoch:[ 97 0 ] loss: 0.40830370783805847 2022-06-30 21:24:41.084960
Epoch:[ 97 1 ] loss: 0.40858909487724304 2022-06-30 21:24:41.505525
Epoch:[ 97 2 ] loss: 0.4109474718570709 2022-06-30 21:24:41.918409
Epoch:[ 97 3 ] loss: 0.41029685735702515 2022-06-30 21:24:42.335263
Epoch:[ 97 4 ] loss: 0.40710633993148804 2022-06-30 21:24:42.772176
Epoch:[ 97 5 ] loss: 0.4130829870700836 2022-06-30 21:24:43.255125
Epoch:[ 97 6 ] loss: 0.40854278206825256 2022-06-30 21:24:43.668321
Epoch:[ 97 7 ] loss: 0.40974369645118713 2022-06-30 21:24:44.090209
Epoch:[ 97 8 ] loss: 0.4082098603248596 2022-06-30 21:24:44.503781
Epoch:[ 97 9 ] loss: 0.40947720408439636 2022-06-30 21:24:44.917773
Epoch:[ 97 10 ] loss: 0.4110298454761505 2022-06-30 21:24:45.339401
Epoch:[ 97 11 ] loss: 0.40759482979774475 2022-06-30 21:24:45.753855
Epoch:[ 97 12 ] loss: 0.407970130443573 2022-06-30 21:24:46.169407
Epoch:[ 97 13 ] loss: 0.40857139229774475 2022-06-30 21:24:46.586951
Epoch:[ 97 14 ] loss: 0.41043388843536377 2022-06-30 21:24:47.006749
Epoch:[ 97 15 ] loss: 0.4094305634498596 2022-06-30 21:24:47.421991
Epoch:[ 97 16 ] loss: 0.40755176544189453 2022-06-30 21:24:52.521610
Epoch:[ 97 17 ] loss: 0.40596842765808105 2022-06-30 21:24:53.695834
Epoch:[ 97 18 ] loss: 0.4096689820289612 2022-06-30 21:24:54.113271
Epoch:[ 97 19 ] loss: 0.4090883731842041 2022-06-30 21:24:54.529854
Training_Epoch:[ 97 ] Training_loss: 0.40908041000366213 2022-06-30 21:24:54.530511
learning rate:  0.0006710886400000004
val: 1 0.4693845808506012
val: 2 0.4593563377857208
val: 3 0.467204749584198
val: 4 0.45325636863708496
val: 5 0.4543159008026123
val: 6 0.4616634249687195
val: 7 0.45505809783935547
val: 8 0.4512600302696228
val: 9 0.44038426876068115
val: 10 0.47166207432746887
val: 11 0.47040313482284546
val: 12 0.4500748813152313
val: 13 0.4598146378993988
val: 14 0.466348797082901
val: 15 0.4440455138683319
val: 16 0.44430074095726013
val: 17 0.47136345505714417
val: 18 0.4425028860569
val: 19 0.4693111181259155
val: 20 0.4558418393135071
val_Epoch:[ 97 ] val_loss: 0.457877641916275 2022-06-30 21:24:57.904543
start training 2022-06-30 21:24:58.000509
Epoch:[ 98 0 ] loss: 0.40595534443855286 2022-06-30 21:25:12.077167
Epoch:[ 98 1 ] loss: 0.40645068883895874 2022-06-30 21:25:12.495880
Epoch:[ 98 2 ] loss: 0.40886959433555603 2022-06-30 21:25:12.909833
Epoch:[ 98 3 ] loss: 0.4065925180912018 2022-06-30 21:25:13.365438
Epoch:[ 98 4 ] loss: 0.4072154462337494 2022-06-30 21:25:13.852786
Epoch:[ 98 5 ] loss: 0.4102347493171692 2022-06-30 21:25:14.269398
Epoch:[ 98 6 ] loss: 0.4083901643753052 2022-06-30 21:25:14.685924
Epoch:[ 98 7 ] loss: 0.40572991967201233 2022-06-30 21:25:15.101573
Epoch:[ 98 8 ] loss: 0.4071691334247589 2022-06-30 21:25:15.522709
Epoch:[ 98 9 ] loss: 0.40647417306900024 2022-06-30 21:25:15.936066
Epoch:[ 98 10 ] loss: 0.4115457534790039 2022-06-30 21:25:16.349842
Epoch:[ 98 11 ] loss: 0.4074663519859314 2022-06-30 21:25:16.773977
Epoch:[ 98 12 ] loss: 0.40948888659477234 2022-06-30 21:25:17.196401
Epoch:[ 98 13 ] loss: 0.4089212417602539 2022-06-30 21:25:17.611027
Epoch:[ 98 14 ] loss: 0.40998607873916626 2022-06-30 21:25:18.024634
Epoch:[ 98 15 ] loss: 0.40912875533103943 2022-06-30 21:25:18.440452
Epoch:[ 98 16 ] loss: 0.4092200994491577 2022-06-30 21:25:24.062592
Epoch:[ 98 17 ] loss: 0.4086957275867462 2022-06-30 21:25:24.476977
Epoch:[ 98 18 ] loss: 0.40983134508132935 2022-06-30 21:25:24.893795
Epoch:[ 98 19 ] loss: 0.40869489312171936 2022-06-30 21:25:25.309393
Training_Epoch:[ 98 ] Training_loss: 0.4083030432462692 2022-06-30 21:25:25.310123
learning rate:  0.0006710886400000004
netparams have been saved once 98
val: 1 0.4615888297557831
val: 2 0.46009361743927
val: 3 0.462471604347229
val: 4 0.4624640643596649
val: 5 0.46130889654159546
val: 6 0.4537409543991089
val: 7 0.4626907706260681
val: 8 0.4574185907840729
val: 9 0.4503229558467865
val: 10 0.46020519733428955
val: 11 0.4522535800933838
val: 12 0.44932371377944946
val: 13 0.456095427274704
val: 14 0.4596916139125824
val: 15 0.4427329897880554
val: 16 0.4542364180088043
val: 17 0.448343425989151
val: 18 0.4709007740020752
val: 19 0.4592388868331909
val: 20 0.43755972385406494
val_Epoch:[ 98 ] val_loss: 0.45613410174846647 2022-06-30 21:25:28.818149
start training 2022-06-30 21:25:28.916250
Epoch:[ 99 0 ] loss: 0.40769875049591064 2022-06-30 21:25:42.952931
Epoch:[ 99 1 ] loss: 0.40707579255104065 2022-06-30 21:25:43.391466
Epoch:[ 99 2 ] loss: 0.4067906439304352 2022-06-30 21:25:43.812055
Epoch:[ 99 3 ] loss: 0.4065563976764679 2022-06-30 21:25:44.248240
Epoch:[ 99 4 ] loss: 0.41001537442207336 2022-06-30 21:25:44.735850
Epoch:[ 99 5 ] loss: 0.4052141010761261 2022-06-30 21:25:45.152025
Epoch:[ 99 6 ] loss: 0.40926653146743774 2022-06-30 21:25:45.566532
Epoch:[ 99 7 ] loss: 0.4080561399459839 2022-06-30 21:25:45.983595
Epoch:[ 99 8 ] loss: 0.4071340262889862 2022-06-30 21:25:46.397177
Epoch:[ 99 9 ] loss: 0.4089811146259308 2022-06-30 21:25:46.811416
Epoch:[ 99 10 ] loss: 0.408221960067749 2022-06-30 21:25:47.226501
Epoch:[ 99 11 ] loss: 0.40776386857032776 2022-06-30 21:25:47.644498
Epoch:[ 99 12 ] loss: 0.41156771779060364 2022-06-30 21:25:48.060784
Epoch:[ 99 13 ] loss: 0.4072413742542267 2022-06-30 21:25:48.483672
Epoch:[ 99 14 ] loss: 0.41208383440971375 2022-06-30 21:25:48.905823
Epoch:[ 99 15 ] loss: 0.40623748302459717 2022-06-30 21:25:49.321394
Epoch:[ 99 16 ] loss: 0.4065104126930237 2022-06-30 21:25:55.061939
Epoch:[ 99 17 ] loss: 0.4095979928970337 2022-06-30 21:25:55.474738
Epoch:[ 99 18 ] loss: 0.41069531440734863 2022-06-30 21:25:55.896569
Epoch:[ 99 19 ] loss: 0.41096025705337524 2022-06-30 21:25:56.314276
Training_Epoch:[ 99 ] Training_loss: 0.4083834543824196 2022-06-30 21:25:56.314959
learning rate:  0.0006710886400000004
val: 1 0.47191348671913147
val: 2 0.4550781548023224
val: 3 0.4652974307537079
val: 4 0.4645857810974121
val: 5 0.4542572796344757
val: 6 0.464672327041626
val: 7 0.4719942808151245
val: 8 0.4566057026386261
val: 9 0.45315325260162354
val: 10 0.4567706882953644
val: 11 0.4607877731323242
val: 12 0.4560272991657257
val: 13 0.45738428831100464
val: 14 0.45879578590393066
val: 15 0.4575303792953491
val: 16 0.45675647258758545
val: 17 0.46315568685531616
val: 18 0.45621761679649353
val: 19 0.4525478780269623
val: 20 0.4597843289375305
val_Epoch:[ 99 ] val_loss: 0.45966579467058183 2022-06-30 21:25:59.669327
start training 2022-06-30 21:25:59.766699
Epoch:[ 100 0 ] loss: 0.407448947429657 2022-06-30 21:26:14.134324
Epoch:[ 100 1 ] loss: 0.40871506929397583 2022-06-30 21:26:14.556632
Epoch:[ 100 2 ] loss: 0.4104858636856079 2022-06-30 21:26:15.007378
Epoch:[ 100 3 ] loss: 0.4065783619880676 2022-06-30 21:26:15.489502
Epoch:[ 100 4 ] loss: 0.4072704613208771 2022-06-30 21:26:15.909173
Epoch:[ 100 5 ] loss: 0.4030897617340088 2022-06-30 21:26:16.323627
Epoch:[ 100 6 ] loss: 0.4074828326702118 2022-06-30 21:26:16.739526
Epoch:[ 100 7 ] loss: 0.40869468450546265 2022-06-30 21:26:17.161468
Epoch:[ 100 8 ] loss: 0.40628138184547424 2022-06-30 21:26:17.582392
Epoch:[ 100 9 ] loss: 0.4091956615447998 2022-06-30 21:26:17.998773
Epoch:[ 100 10 ] loss: 0.40779775381088257 2022-06-30 21:26:18.432610
Epoch:[ 100 11 ] loss: 0.40888574719429016 2022-06-30 21:26:18.849235
Epoch:[ 100 12 ] loss: 0.4086727797985077 2022-06-30 21:26:19.265257
Epoch:[ 100 13 ] loss: 0.4096314609050751 2022-06-30 21:26:19.682228
Epoch:[ 100 14 ] loss: 0.41029787063598633 2022-06-30 21:26:20.098520
Epoch:[ 100 15 ] loss: 0.40980345010757446 2022-06-30 21:26:20.514727
Epoch:[ 100 16 ] loss: 0.41008469462394714 2022-06-30 21:26:26.128541
Epoch:[ 100 17 ] loss: 0.41227400302886963 2022-06-30 21:26:26.545732
Epoch:[ 100 18 ] loss: 0.410380095243454 2022-06-30 21:26:26.963190
Epoch:[ 100 19 ] loss: 0.4081822335720062 2022-06-30 21:26:27.380281
Training_Epoch:[ 100 ] Training_loss: 0.4085626557469368 2022-06-30 21:26:27.381092
learning rate:  0.0006710886400000004
netparams have been saved once 100
val: 1 0.45274618268013
val: 2 0.4543077349662781
val: 3 0.456318199634552
val: 4 0.44568580389022827
val: 5 0.452260285615921
val: 6 0.4530123174190521
val: 7 0.4672260284423828
val: 8 0.45975634455680847
val: 9 0.46089640259742737
val: 10 0.4581018388271332
val: 11 0.45308035612106323
val: 12 0.46614643931388855
val: 13 0.4730297029018402
val: 14 0.47084295749664307
val: 15 0.46065184473991394
val: 16 0.4457530975341797
val: 17 0.45978304743766785
val: 18 0.4655380845069885
val: 19 0.46386414766311646
val: 20 0.45157167315483093
val_Epoch:[ 100 ] val_loss: 0.4585286244750023 2022-06-30 21:26:30.773918
start training 2022-06-30 21:26:30.873537
Epoch:[ 101 0 ] loss: 0.40553393959999084 2022-06-30 21:26:45.725477
Epoch:[ 101 1 ] loss: 0.40753981471061707 2022-06-30 21:26:46.145730
Epoch:[ 101 2 ] loss: 0.40757596492767334 2022-06-30 21:26:46.561894
Epoch:[ 101 3 ] loss: 0.40971797704696655 2022-06-30 21:26:46.977648
Epoch:[ 101 4 ] loss: 0.40657761693000793 2022-06-30 21:26:47.398672
Epoch:[ 101 5 ] loss: 0.4065503776073456 2022-06-30 21:26:47.884870
Epoch:[ 101 6 ] loss: 0.4053511619567871 2022-06-30 21:26:48.298454
Epoch:[ 101 7 ] loss: 0.40721726417541504 2022-06-30 21:26:48.715052
Epoch:[ 101 8 ] loss: 0.4038490056991577 2022-06-30 21:26:49.139156
Epoch:[ 101 9 ] loss: 0.4064367115497589 2022-06-30 21:26:49.554903
Epoch:[ 101 10 ] loss: 0.407174289226532 2022-06-30 21:26:49.968744
Epoch:[ 101 11 ] loss: 0.405862420797348 2022-06-30 21:26:50.389937
Epoch:[ 101 12 ] loss: 0.4047635793685913 2022-06-30 21:26:50.806009
Epoch:[ 101 13 ] loss: 0.405580997467041 2022-06-30 21:26:51.221612
Epoch:[ 101 14 ] loss: 0.4077971577644348 2022-06-30 21:26:51.639821
Epoch:[ 101 15 ] loss: 0.404745489358902 2022-06-30 21:26:52.060552
Epoch:[ 101 16 ] loss: 0.40644922852516174 2022-06-30 21:26:57.504064
Epoch:[ 101 17 ] loss: 0.4061254858970642 2022-06-30 21:26:57.920148
Epoch:[ 101 18 ] loss: 0.405534565448761 2022-06-30 21:26:58.350826
Epoch:[ 101 19 ] loss: 0.40604621171951294 2022-06-30 21:26:58.770185
Training_Epoch:[ 101 ] Training_loss: 0.40632146298885347 2022-06-30 21:26:58.770881
learning rate:  0.0005368709120000003
val: 1 0.4538661539554596
val: 2 0.4707484841346741
val: 3 0.4577469825744629
val: 4 0.4540543258190155
val: 5 0.4530376195907593
val: 6 0.4654414653778076
val: 7 0.45603466033935547
val: 8 0.460330605506897
val: 9 0.4494187831878662
val: 10 0.4598568379878998
val: 11 0.4539251923561096
val: 12 0.4544045329093933
val: 13 0.451752632856369
val: 14 0.4538278877735138
val: 15 0.4590741693973541
val: 16 0.45691269636154175
val: 17 0.45398813486099243
val: 18 0.4612891674041748
val: 19 0.46822389960289
val: 20 0.4597862958908081
val_Epoch:[ 101 ] val_loss: 0.45768602639436723 2022-06-30 21:27:02.148644
start training 2022-06-30 21:27:02.246759
Epoch:[ 102 0 ] loss: 0.4020499587059021 2022-06-30 21:27:16.032347
Epoch:[ 102 1 ] loss: 0.4056408405303955 2022-06-30 21:27:16.449267
Epoch:[ 102 2 ] loss: 0.4057348668575287 2022-06-30 21:27:16.915124
Epoch:[ 102 3 ] loss: 0.4048491418361664 2022-06-30 21:27:17.332923
Epoch:[ 102 4 ] loss: 0.4046728312969208 2022-06-30 21:27:17.749578
Epoch:[ 102 5 ] loss: 0.40682587027549744 2022-06-30 21:27:18.169979
Epoch:[ 102 6 ] loss: 0.40393102169036865 2022-06-30 21:27:18.587892
Epoch:[ 102 7 ] loss: 0.4059583246707916 2022-06-30 21:27:19.006396
Epoch:[ 102 8 ] loss: 0.4052003026008606 2022-06-30 21:27:19.425194
Epoch:[ 102 9 ] loss: 0.40516728162765503 2022-06-30 21:27:19.847186
Epoch:[ 102 10 ] loss: 0.4063624143600464 2022-06-30 21:27:20.334592
Epoch:[ 102 11 ] loss: 0.40497398376464844 2022-06-30 21:27:20.750563
Epoch:[ 102 12 ] loss: 0.40329957008361816 2022-06-30 21:27:21.165696
Epoch:[ 102 13 ] loss: 0.4062195122241974 2022-06-30 21:27:21.588340
Epoch:[ 102 14 ] loss: 0.4084447920322418 2022-06-30 21:27:22.003923
Epoch:[ 102 15 ] loss: 0.40435221791267395 2022-06-30 21:27:22.426362
Epoch:[ 102 16 ] loss: 0.40540212392807007 2022-06-30 21:27:27.805126
Epoch:[ 102 17 ] loss: 0.404689222574234 2022-06-30 21:27:28.238772
Epoch:[ 102 18 ] loss: 0.4037514328956604 2022-06-30 21:27:28.657679
Epoch:[ 102 19 ] loss: 0.40580248832702637 2022-06-30 21:27:29.074461
Training_Epoch:[ 102 ] Training_loss: 0.4051664099097252 2022-06-30 21:27:29.075186
learning rate:  0.0005368709120000003
netparams have been saved once 102
val: 1 0.45646679401397705
val: 2 0.4661889970302582
val: 3 0.4527197480201721
val: 4 0.44915899634361267
val: 5 0.4558156728744507
val: 6 0.4794515371322632
val: 7 0.45331576466560364
val: 8 0.45316699147224426
val: 9 0.4699183702468872
val: 10 0.4644189178943634
val: 11 0.4613950252532959
val: 12 0.46306854486465454
val: 13 0.44981759786605835
val: 14 0.4683864712715149
val: 15 0.4649300277233124
val: 16 0.4580353796482086
val: 17 0.46556195616722107
val: 18 0.45881959795951843
val: 19 0.4544571340084076
val: 20 0.45733848214149475
val_Epoch:[ 102 ] val_loss: 0.4601216003298759 2022-06-30 21:27:32.458442
start training 2022-06-30 21:27:32.560211
Epoch:[ 103 0 ] loss: 0.4055076241493225 2022-06-30 21:27:46.409946
Epoch:[ 103 1 ] loss: 0.40128615498542786 2022-06-30 21:27:46.857243
Epoch:[ 103 2 ] loss: 0.40460214018821716 2022-06-30 21:27:47.301787
Epoch:[ 103 3 ] loss: 0.40446460247039795 2022-06-30 21:27:47.717307
Epoch:[ 103 4 ] loss: 0.4046247601509094 2022-06-30 21:27:48.132943
Epoch:[ 103 5 ] loss: 0.40462589263916016 2022-06-30 21:27:48.557675
Epoch:[ 103 6 ] loss: 0.40511417388916016 2022-06-30 21:27:48.976246
Epoch:[ 103 7 ] loss: 0.40316662192344666 2022-06-30 21:27:49.397293
Epoch:[ 103 8 ] loss: 0.4040735363960266 2022-06-30 21:27:49.814234
Epoch:[ 103 9 ] loss: 0.4036725163459778 2022-06-30 21:27:50.230658
Epoch:[ 103 10 ] loss: 0.4039040207862854 2022-06-30 21:27:50.647458
Epoch:[ 103 11 ] loss: 0.402523010969162 2022-06-30 21:27:51.066900
Epoch:[ 103 12 ] loss: 0.4072573781013489 2022-06-30 21:27:51.483614
Epoch:[ 103 13 ] loss: 0.4057067334651947 2022-06-30 21:27:51.935829
Epoch:[ 103 14 ] loss: 0.40197134017944336 2022-06-30 21:27:52.415299
Epoch:[ 103 15 ] loss: 0.4056451618671417 2022-06-30 21:27:52.833325
Epoch:[ 103 16 ] loss: 0.4044113755226135 2022-06-30 21:27:58.223399
Epoch:[ 103 17 ] loss: 0.40474265813827515 2022-06-30 21:27:58.639038
Epoch:[ 103 18 ] loss: 0.4054516553878784 2022-06-30 21:27:59.071141
Epoch:[ 103 19 ] loss: 0.4037471413612366 2022-06-30 21:27:59.489699
Training_Epoch:[ 103 ] Training_loss: 0.4043249249458313 2022-06-30 21:27:59.490415
learning rate:  0.0005368709120000003
val: 1 0.457820862531662
val: 2 0.4680356979370117
val: 3 0.4452756643295288
val: 4 0.4602598547935486
val: 5 0.4584956169128418
val: 6 0.45760905742645264
val: 7 0.4648970663547516
val: 8 0.4752104580402374
val: 9 0.47040995955467224
val: 10 0.45278841257095337
val: 11 0.4676782488822937
val: 12 0.4634205996990204
val: 13 0.47630929946899414
val: 14 0.4609987139701843
val: 15 0.46342378854751587
val: 16 0.46179723739624023
val: 17 0.4757693409919739
val: 18 0.4606718122959137
val: 19 0.4515172839164734
val: 20 0.46219000220298767
val_Epoch:[ 103 ] val_loss: 0.4627289488911629 2022-06-30 21:28:02.854176
start training 2022-06-30 21:28:02.953155
Epoch:[ 104 0 ] loss: 0.40350770950317383 2022-06-30 21:28:17.691289
Epoch:[ 104 1 ] loss: 0.40194180607795715 2022-06-30 21:28:18.104726
Epoch:[ 104 2 ] loss: 0.40547505021095276 2022-06-30 21:28:18.517379
Epoch:[ 104 3 ] loss: 0.4033867120742798 2022-06-30 21:28:18.934571
Epoch:[ 104 4 ] loss: 0.40551427006721497 2022-06-30 21:28:19.351005
Epoch:[ 104 5 ] loss: 0.40298348665237427 2022-06-30 21:28:19.766234
Epoch:[ 104 6 ] loss: 0.4033900797367096 2022-06-30 21:28:20.186298
Epoch:[ 104 7 ] loss: 0.40502557158470154 2022-06-30 21:28:20.608269
Epoch:[ 104 8 ] loss: 0.4028525948524475 2022-06-30 21:28:21.028066
Epoch:[ 104 9 ] loss: 0.4022704064846039 2022-06-30 21:28:21.441252
Epoch:[ 104 10 ] loss: 0.403490275144577 2022-06-30 21:28:21.857434
Epoch:[ 104 11 ] loss: 0.4035396873950958 2022-06-30 21:28:22.272916
Epoch:[ 104 12 ] loss: 0.4060925543308258 2022-06-30 21:28:22.687458
Epoch:[ 104 13 ] loss: 0.40243932604789734 2022-06-30 21:28:23.107006
Epoch:[ 104 14 ] loss: 0.4041788578033447 2022-06-30 21:28:23.537955
Epoch:[ 104 15 ] loss: 0.4065946042537689 2022-06-30 21:28:24.018680
Epoch:[ 104 16 ] loss: 0.40537121891975403 2022-06-30 21:28:29.433233
Epoch:[ 104 17 ] loss: 0.4043309688568115 2022-06-30 21:28:29.860091
Epoch:[ 104 18 ] loss: 0.40357011556625366 2022-06-30 21:28:30.284977
Epoch:[ 104 19 ] loss: 0.4040522575378418 2022-06-30 21:28:30.701541
Training_Epoch:[ 104 ] Training_loss: 0.4040003776550293 2022-06-30 21:28:30.702252
learning rate:  0.0005368709120000003
netparams have been saved once 104
val: 1 0.4634595811367035
val: 2 0.4500400722026825
val: 3 0.4663238823413849
val: 4 0.46557530760765076
val: 5 0.4528602063655853
val: 6 0.4569431245326996
val: 7 0.47661638259887695
val: 8 0.46264323592185974
val: 9 0.4614275097846985
val: 10 0.45907488465309143
val: 11 0.45416051149368286
val: 12 0.45427176356315613
val: 13 0.46100836992263794
val: 14 0.4582785964012146
val: 15 0.4568549394607544
val: 16 0.4551767110824585
val: 17 0.47246769070625305
val: 18 0.45205816626548767
val: 19 0.4630221426486969
val: 20 0.4745301306247711
val_Epoch:[ 104 ] val_loss: 0.46083966046571734 2022-06-30 21:28:34.045258
start training 2022-06-30 21:28:34.142575
Epoch:[ 105 0 ] loss: 0.40152508020401 2022-06-30 21:28:48.147970
Epoch:[ 105 1 ] loss: 0.4059624671936035 2022-06-30 21:28:48.589458
Epoch:[ 105 2 ] loss: 0.4051903784275055 2022-06-30 21:28:49.003457
Epoch:[ 105 3 ] loss: 0.4038659334182739 2022-06-30 21:28:49.412976
Epoch:[ 105 4 ] loss: 0.40415364503860474 2022-06-30 21:28:49.829890
Epoch:[ 105 5 ] loss: 0.4042033851146698 2022-06-30 21:28:50.249485
Epoch:[ 105 6 ] loss: 0.4026692509651184 2022-06-30 21:28:50.659714
Epoch:[ 105 7 ] loss: 0.40430742502212524 2022-06-30 21:28:51.069485
Epoch:[ 105 8 ] loss: 0.4041811525821686 2022-06-30 21:28:51.487054
Epoch:[ 105 9 ] loss: 0.4058471620082855 2022-06-30 21:28:51.904593
Epoch:[ 105 10 ] loss: 0.4036170542240143 2022-06-30 21:28:52.319620
Epoch:[ 105 11 ] loss: 0.4038909077644348 2022-06-30 21:28:52.737417
Epoch:[ 105 12 ] loss: 0.40317094326019287 2022-06-30 21:28:53.149133
Epoch:[ 105 13 ] loss: 0.4048350155353546 2022-06-30 21:28:53.603593
Epoch:[ 105 14 ] loss: 0.4069685935974121 2022-06-30 21:28:54.089308
Epoch:[ 105 15 ] loss: 0.4046078622341156 2022-06-30 21:28:54.511499
Epoch:[ 105 16 ] loss: 0.4029463529586792 2022-06-30 21:28:59.902914
Epoch:[ 105 17 ] loss: 0.40391847491264343 2022-06-30 21:29:00.318238
Epoch:[ 105 18 ] loss: 0.40641477704048157 2022-06-30 21:29:00.735919
Epoch:[ 105 19 ] loss: 0.40381109714508057 2022-06-30 21:29:01.150342
Training_Epoch:[ 105 ] Training_loss: 0.4043043479323387 2022-06-30 21:29:01.151051
learning rate:  0.0005368709120000003
val: 1 0.4554184079170227
val: 2 0.46889597177505493
val: 3 0.46270400285720825
val: 4 0.45987406373023987
val: 5 0.4631904661655426
val: 6 0.4518417716026306
val: 7 0.44993501901626587
val: 8 0.4518813192844391
val: 9 0.455182820558548
val: 10 0.4669986963272095
val: 11 0.45537179708480835
val: 12 0.4644445776939392
val: 13 0.4758048355579376
val: 14 0.4530417025089264
val: 15 0.46222496032714844
val: 16 0.462992787361145
val: 17 0.44999754428863525
val: 18 0.4567166864871979
val: 19 0.45235204696655273
val: 20 0.46946898102760315
val_Epoch:[ 105 ] val_loss: 0.4594169229269028 2022-06-30 21:29:04.513944
start training 2022-06-30 21:29:04.609376
Epoch:[ 106 0 ] loss: 0.40258097648620605 2022-06-30 21:29:18.715990
Epoch:[ 106 1 ] loss: 0.4054829776287079 2022-06-30 21:29:19.189624
Epoch:[ 106 2 ] loss: 0.4062311351299286 2022-06-30 21:29:19.602721
Epoch:[ 106 3 ] loss: 0.404005229473114 2022-06-30 21:29:20.023612
Epoch:[ 106 4 ] loss: 0.4026561379432678 2022-06-30 21:29:20.437315
Epoch:[ 106 5 ] loss: 0.4051663279533386 2022-06-30 21:29:20.859299
Epoch:[ 106 6 ] loss: 0.4025730490684509 2022-06-30 21:29:21.274617
Epoch:[ 106 7 ] loss: 0.4032866060733795 2022-06-30 21:29:21.693341
Epoch:[ 106 8 ] loss: 0.4007657468318939 2022-06-30 21:29:22.106765
Epoch:[ 106 9 ] loss: 0.40384408831596375 2022-06-30 21:29:22.520474
Epoch:[ 106 10 ] loss: 0.40485242009162903 2022-06-30 21:29:22.933361
Epoch:[ 106 11 ] loss: 0.40543270111083984 2022-06-30 21:29:23.386639
Epoch:[ 106 12 ] loss: 0.40253937244415283 2022-06-30 21:29:23.870753
Epoch:[ 106 13 ] loss: 0.4034537672996521 2022-06-30 21:29:24.286489
Epoch:[ 106 14 ] loss: 0.40288910269737244 2022-06-30 21:29:24.700355
Epoch:[ 106 15 ] loss: 0.4058544635772705 2022-06-30 21:29:25.120615
Epoch:[ 106 16 ] loss: 0.4038892984390259 2022-06-30 21:29:30.446235
Epoch:[ 106 17 ] loss: 0.4016439616680145 2022-06-30 21:29:30.859368
Epoch:[ 106 18 ] loss: 0.405299574136734 2022-06-30 21:29:31.274206
Epoch:[ 106 19 ] loss: 0.40546849370002747 2022-06-30 21:29:31.691241
Training_Epoch:[ 106 ] Training_loss: 0.40389577150344846 2022-06-30 21:29:31.691918
learning rate:  0.0005368709120000003
netparams have been saved once 106
val: 1 0.48280441761016846
val: 2 0.4528135359287262
val: 3 0.4508936107158661
val: 4 0.4655953347682953
val: 5 0.48379433155059814
val: 6 0.4549354612827301
val: 7 0.4548812210559845
val: 8 0.466732382774353
val: 9 0.4574577510356903
val: 10 0.46700331568717957
val: 11 0.4491933286190033
val: 12 0.4726361334323883
val: 13 0.4625224173069
val: 14 0.4657754600048065
val: 15 0.4757455885410309
val: 16 0.4511564075946808
val: 17 0.45914578437805176
val: 18 0.4714078903198242
val: 19 0.459769070148468
val: 20 0.461363285779953
val_Epoch:[ 106 ] val_loss: 0.4632813364267349 2022-06-30 21:29:35.082499
start training 2022-06-30 21:29:35.179589
Epoch:[ 107 0 ] loss: 0.40310752391815186 2022-06-30 21:29:49.012003
Epoch:[ 107 1 ] loss: 0.4027664363384247 2022-06-30 21:29:49.698704
Epoch:[ 107 2 ] loss: 0.40413621068000793 2022-06-30 21:29:50.111955
Epoch:[ 107 3 ] loss: 0.4010213613510132 2022-06-30 21:29:50.536831
Epoch:[ 107 4 ] loss: 0.4036121666431427 2022-06-30 21:29:50.950579
Epoch:[ 107 5 ] loss: 0.4042515456676483 2022-06-30 21:29:51.364716
Epoch:[ 107 6 ] loss: 0.4055024981498718 2022-06-30 21:29:51.780040
Epoch:[ 107 7 ] loss: 0.4029540419578552 2022-06-30 21:29:52.196380
Epoch:[ 107 8 ] loss: 0.4031181335449219 2022-06-30 21:29:52.612855
Epoch:[ 107 9 ] loss: 0.40212854743003845 2022-06-30 21:29:53.052192
Epoch:[ 107 10 ] loss: 0.4025512933731079 2022-06-30 21:29:53.537459
Epoch:[ 107 11 ] loss: 0.4078233242034912 2022-06-30 21:29:53.953547
Epoch:[ 107 12 ] loss: 0.40346747636795044 2022-06-30 21:29:54.366364
Epoch:[ 107 13 ] loss: 0.4039911925792694 2022-06-30 21:29:54.788089
Epoch:[ 107 14 ] loss: 0.4026569128036499 2022-06-30 21:29:55.203257
Epoch:[ 107 15 ] loss: 0.405119925737381 2022-06-30 21:29:55.617941
Epoch:[ 107 16 ] loss: 0.4028208255767822 2022-06-30 21:30:00.733550
Epoch:[ 107 17 ] loss: 0.40536630153656006 2022-06-30 21:30:01.259156
Epoch:[ 107 18 ] loss: 0.4043206572532654 2022-06-30 21:30:01.674015
Epoch:[ 107 19 ] loss: 0.4057886600494385 2022-06-30 21:30:02.088247
Training_Epoch:[ 107 ] Training_loss: 0.4038252517580986 2022-06-30 21:30:02.088975
learning rate:  0.0005368709120000003
val: 1 0.46375107765197754
val: 2 0.44329121708869934
val: 3 0.46169140934944153
val: 4 0.4654916226863861
val: 5 0.4740840196609497
val: 6 0.45712244510650635
val: 7 0.45253071188926697
val: 8 0.45221996307373047
val: 9 0.4651225805282593
val: 10 0.45218217372894287
val: 11 0.4773937463760376
val: 12 0.46074730157852173
val: 13 0.45044955611228943
val: 14 0.4690757095813751
val: 15 0.46307966113090515
val: 16 0.4440181255340576
val: 17 0.4677847623825073
val: 18 0.45926567912101746
val: 19 0.4738139808177948
val: 20 0.45327386260032654
val_Epoch:[ 107 ] val_loss: 0.4603194802999496 2022-06-30 21:30:05.434215
start training 2022-06-30 21:30:05.531979
Epoch:[ 108 0 ] loss: 0.4003458321094513 2022-06-30 21:30:19.379766
Epoch:[ 108 1 ] loss: 0.4015195071697235 2022-06-30 21:30:19.825436
Epoch:[ 108 2 ] loss: 0.4042397141456604 2022-06-30 21:30:20.240496
Epoch:[ 108 3 ] loss: 0.40203478932380676 2022-06-30 21:30:20.654913
Epoch:[ 108 4 ] loss: 0.40237635374069214 2022-06-30 21:30:21.069823
Epoch:[ 108 5 ] loss: 0.4037652313709259 2022-06-30 21:30:21.489148
Epoch:[ 108 6 ] loss: 0.40019628405570984 2022-06-30 21:30:21.902364
Epoch:[ 108 7 ] loss: 0.4011940360069275 2022-06-30 21:30:22.324943
Epoch:[ 108 8 ] loss: 0.40204912424087524 2022-06-30 21:30:22.741611
Epoch:[ 108 9 ] loss: 0.4030613899230957 2022-06-30 21:30:23.156760
Epoch:[ 108 10 ] loss: 0.4030742049217224 2022-06-30 21:30:23.572727
Epoch:[ 108 11 ] loss: 0.40449798107147217 2022-06-30 21:30:23.992110
Epoch:[ 108 12 ] loss: 0.4025539457798004 2022-06-30 21:30:24.476983
Epoch:[ 108 13 ] loss: 0.4035646319389343 2022-06-30 21:30:24.896119
Epoch:[ 108 14 ] loss: 0.40140751004219055 2022-06-30 21:30:25.318403
Epoch:[ 108 15 ] loss: 0.4045649468898773 2022-06-30 21:30:25.735420
Epoch:[ 108 16 ] loss: 0.4039698839187622 2022-06-30 21:30:31.153169
Epoch:[ 108 17 ] loss: 0.4029422998428345 2022-06-30 21:30:31.688790
Epoch:[ 108 18 ] loss: 0.40357163548469543 2022-06-30 21:30:32.104180
Epoch:[ 108 19 ] loss: 0.40358975529670715 2022-06-30 21:30:32.518433
Training_Epoch:[ 108 ] Training_loss: 0.4027259528636932 2022-06-30 21:30:32.519108
learning rate:  0.0005368709120000003
netparams have been saved once 108
val: 1 0.4767822325229645
val: 2 0.4673933982849121
val: 3 0.46843910217285156
val: 4 0.4613821506500244
val: 5 0.46136316657066345
val: 6 0.4613268971443176
val: 7 0.44526565074920654
val: 8 0.4722074568271637
val: 9 0.46570920944213867
val: 10 0.4573552906513214
val: 11 0.4609961211681366
val: 12 0.45743075013160706
val: 13 0.4656390845775604
val: 14 0.46164849400520325
val: 15 0.474398136138916
val: 16 0.4631973206996918
val: 17 0.4610394239425659
val: 18 0.45999374985694885
val: 19 0.4587936997413635
val: 20 0.45132866501808167
val_Epoch:[ 108 ] val_loss: 0.46258450001478196 2022-06-30 21:30:35.913900
start training 2022-06-30 21:30:36.008056
Epoch:[ 109 0 ] loss: 0.402375727891922 2022-06-30 21:30:49.841952
Epoch:[ 109 1 ] loss: 0.401801735162735 2022-06-30 21:30:50.288353
Epoch:[ 109 2 ] loss: 0.4023120105266571 2022-06-30 21:30:50.703803
Epoch:[ 109 3 ] loss: 0.39967745542526245 2022-06-30 21:30:51.122997
Epoch:[ 109 4 ] loss: 0.4015158712863922 2022-06-30 21:30:51.539096
Epoch:[ 109 5 ] loss: 0.4009115695953369 2022-06-30 21:30:51.953128
Epoch:[ 109 6 ] loss: 0.4029027819633484 2022-06-30 21:30:52.367407
Epoch:[ 109 7 ] loss: 0.4020278751850128 2022-06-30 21:30:52.781618
Epoch:[ 109 8 ] loss: 0.4009755849838257 2022-06-30 21:30:53.203274
Epoch:[ 109 9 ] loss: 0.4016711413860321 2022-06-30 21:30:53.660689
Epoch:[ 109 10 ] loss: 0.3995545506477356 2022-06-30 21:30:54.142987
Epoch:[ 109 11 ] loss: 0.4035640358924866 2022-06-30 21:30:54.565252
Epoch:[ 109 12 ] loss: 0.40069401264190674 2022-06-30 21:30:54.980316
Epoch:[ 109 13 ] loss: 0.4019274115562439 2022-06-30 21:30:55.399693
Epoch:[ 109 14 ] loss: 0.4019411504268646 2022-06-30 21:30:55.812684
Epoch:[ 109 15 ] loss: 0.40320461988449097 2022-06-30 21:30:56.229878
Epoch:[ 109 16 ] loss: 0.4029807150363922 2022-06-30 21:31:01.558763
Epoch:[ 109 17 ] loss: 0.403338760137558 2022-06-30 21:31:01.973383
Epoch:[ 109 18 ] loss: 0.40464240312576294 2022-06-30 21:31:02.388157
Epoch:[ 109 19 ] loss: 0.40112853050231934 2022-06-30 21:31:02.803030
Training_Epoch:[ 109 ] Training_loss: 0.4019573971629143 2022-06-30 21:31:02.803739
learning rate:  0.0005368709120000003
val: 1 0.47337737679481506
val: 2 0.4556783437728882
val: 3 0.45503827929496765
val: 4 0.4673752188682556
val: 5 0.46275925636291504
val: 6 0.47229593992233276
val: 7 0.4562613368034363
val: 8 0.46673980355262756
val: 9 0.4374590218067169
val: 10 0.46601927280426025
val: 11 0.4629903733730316
val: 12 0.46874141693115234
val: 13 0.4695456624031067
val: 14 0.47007906436920166
val: 15 0.4472305178642273
val: 16 0.4615482985973358
val: 17 0.4600089490413666
val: 18 0.45826029777526855
val: 19 0.4695323407649994
val: 20 0.4619753956794739
val_Epoch:[ 109 ] val_loss: 0.46214580833911895 2022-06-30 21:31:06.093190
start training 2022-06-30 21:31:06.189605
Epoch:[ 110 0 ] loss: 0.4038282632827759 2022-06-30 21:31:20.847028
Epoch:[ 110 1 ] loss: 0.40083232522010803 2022-06-30 21:31:21.260372
Epoch:[ 110 2 ] loss: 0.39979371428489685 2022-06-30 21:31:21.675725
Epoch:[ 110 3 ] loss: 0.4031780958175659 2022-06-30 21:31:22.097303
Epoch:[ 110 4 ] loss: 0.4012526571750641 2022-06-30 21:31:22.514336
Epoch:[ 110 5 ] loss: 0.4022715389728546 2022-06-30 21:31:22.927917
Epoch:[ 110 6 ] loss: 0.4013445973396301 2022-06-30 21:31:23.357578
Epoch:[ 110 7 ] loss: 0.4009656608104706 2022-06-30 21:31:23.838257
Epoch:[ 110 8 ] loss: 0.4026586413383484 2022-06-30 21:31:24.253681
Epoch:[ 110 9 ] loss: 0.40335628390312195 2022-06-30 21:31:24.674926
Epoch:[ 110 10 ] loss: 0.40110453963279724 2022-06-30 21:31:25.090660
Epoch:[ 110 11 ] loss: 0.40454259514808655 2022-06-30 21:31:25.506944
Epoch:[ 110 12 ] loss: 0.4028589427471161 2022-06-30 21:31:25.925929
Epoch:[ 110 13 ] loss: 0.40370455384254456 2022-06-30 21:31:26.343019
Epoch:[ 110 14 ] loss: 0.404165655374527 2022-06-30 21:31:26.756516
Epoch:[ 110 15 ] loss: 0.4007555842399597 2022-06-30 21:31:27.170952
Epoch:[ 110 16 ] loss: 0.40243834257125854 2022-06-30 21:31:32.482122
Epoch:[ 110 17 ] loss: 0.4024660587310791 2022-06-30 21:31:32.897280
Epoch:[ 110 18 ] loss: 0.4033338129520416 2022-06-30 21:31:33.314135
Epoch:[ 110 19 ] loss: 0.40027451515197754 2022-06-30 21:31:33.727335
Training_Epoch:[ 110 ] Training_loss: 0.40225631892681124 2022-06-30 21:31:33.728050
learning rate:  0.0005368709120000003
netparams have been saved once 110
val: 1 0.46479448676109314
val: 2 0.4615268409252167
val: 3 0.46139946579933167
val: 4 0.45214030146598816
val: 5 0.44824880361557007
val: 6 0.46237531304359436
val: 7 0.4602394104003906
val: 8 0.4545532166957855
val: 9 0.46778175234794617
val: 10 0.4566985070705414
val: 11 0.46168825030326843
val: 12 0.44956544041633606
val: 13 0.4489343762397766
val: 14 0.4617142677307129
val: 15 0.4616493880748749
val: 16 0.47791528701782227
val: 17 0.45443859696388245
val: 18 0.4637688398361206
val: 19 0.4815996289253235
val: 20 0.45754167437553406
val_Epoch:[ 110 ] val_loss: 0.4604286924004555 2022-06-30 21:31:37.099754
start training 2022-06-30 21:31:37.197562
Epoch:[ 111 0 ] loss: 0.40268653631210327 2022-06-30 21:31:50.642235
Epoch:[ 111 1 ] loss: 0.4016239643096924 2022-06-30 21:31:51.697951
Epoch:[ 111 2 ] loss: 0.39969274401664734 2022-06-30 21:31:52.110498
Epoch:[ 111 3 ] loss: 0.4005841910839081 2022-06-30 21:31:52.526865
Epoch:[ 111 4 ] loss: 0.4009763300418854 2022-06-30 21:31:52.942925
Epoch:[ 111 5 ] loss: 0.3997268080711365 2022-06-30 21:31:53.356651
Epoch:[ 111 6 ] loss: 0.4017891585826874 2022-06-30 21:31:53.787439
Epoch:[ 111 7 ] loss: 0.3997941017150879 2022-06-30 21:31:54.271295
Epoch:[ 111 8 ] loss: 0.3995668292045593 2022-06-30 21:31:54.687271
Epoch:[ 111 9 ] loss: 0.40222659707069397 2022-06-30 21:31:55.106686
Epoch:[ 111 10 ] loss: 0.40379011631011963 2022-06-30 21:31:55.528501
Epoch:[ 111 11 ] loss: 0.4017305076122284 2022-06-30 21:31:55.943027
Epoch:[ 111 12 ] loss: 0.4012559950351715 2022-06-30 21:31:56.360139
Epoch:[ 111 13 ] loss: 0.4031279683113098 2022-06-30 21:31:56.779842
Epoch:[ 111 14 ] loss: 0.3995998203754425 2022-06-30 21:31:57.193120
Epoch:[ 111 15 ] loss: 0.40020573139190674 2022-06-30 21:31:57.607259
Epoch:[ 111 16 ] loss: 0.40134698152542114 2022-06-30 21:32:02.399098
Epoch:[ 111 17 ] loss: 0.3988690674304962 2022-06-30 21:32:03.597772
Epoch:[ 111 18 ] loss: 0.4013449251651764 2022-06-30 21:32:04.018051
Epoch:[ 111 19 ] loss: 0.4013788402080536 2022-06-30 21:32:04.435474
Training_Epoch:[ 111 ] Training_loss: 0.4010658606886864 2022-06-30 21:32:04.436176
learning rate:  0.0004294967296000003
val: 1 0.4597472548484802
val: 2 0.4624926745891571
val: 3 0.45135214924812317
val: 4 0.47300028800964355
val: 5 0.4668803811073303
val: 6 0.4539749026298523
val: 7 0.453173965215683
val: 8 0.46340978145599365
val: 9 0.4607497751712799
val: 10 0.4701493978500366
val: 11 0.470876544713974
val: 12 0.4759584069252014
val: 13 0.4592330753803253
val: 14 0.4647836983203888
val: 15 0.4720407724380493
val: 16 0.46345263719558716
val: 17 0.48012489080429077
val: 18 0.46515271067619324
val: 19 0.47299832105636597
val: 20 0.46354615688323975
val_Epoch:[ 111 ] val_loss: 0.46515488922595977 2022-06-30 21:32:07.814084
start training 2022-06-30 21:32:07.911088
Epoch:[ 112 0 ] loss: 0.39749792218208313 2022-06-30 21:32:21.842671
Epoch:[ 112 1 ] loss: 0.3981248140335083 2022-06-30 21:32:22.284275
Epoch:[ 112 2 ] loss: 0.397481769323349 2022-06-30 21:32:22.696600
Epoch:[ 112 3 ] loss: 0.3964467942714691 2022-06-30 21:32:23.116514
Epoch:[ 112 4 ] loss: 0.3977743983268738 2022-06-30 21:32:23.549589
Epoch:[ 112 5 ] loss: 0.4004560112953186 2022-06-30 21:32:24.030019
Epoch:[ 112 6 ] loss: 0.3960321545600891 2022-06-30 21:32:24.444460
Epoch:[ 112 7 ] loss: 0.40135303139686584 2022-06-30 21:32:24.865113
Epoch:[ 112 8 ] loss: 0.3991876542568207 2022-06-30 21:32:25.286672
Epoch:[ 112 9 ] loss: 0.3982849717140198 2022-06-30 21:32:25.699593
Epoch:[ 112 10 ] loss: 0.400166779756546 2022-06-30 21:32:26.113027
Epoch:[ 112 11 ] loss: 0.39819738268852234 2022-06-30 21:32:26.532052
Epoch:[ 112 12 ] loss: 0.398189514875412 2022-06-30 21:32:26.947866
Epoch:[ 112 13 ] loss: 0.401527464389801 2022-06-30 21:32:27.363248
Epoch:[ 112 14 ] loss: 0.39794209599494934 2022-06-30 21:32:27.779308
Epoch:[ 112 15 ] loss: 0.40017110109329224 2022-06-30 21:32:28.200464
Epoch:[ 112 16 ] loss: 0.4022239148616791 2022-06-30 21:32:33.415142
Epoch:[ 112 17 ] loss: 0.400325208902359 2022-06-30 21:32:33.827866
Epoch:[ 112 18 ] loss: 0.40284186601638794 2022-06-30 21:32:34.242515
Epoch:[ 112 19 ] loss: 0.40105000138282776 2022-06-30 21:32:34.657875
Training_Epoch:[ 112 ] Training_loss: 0.3992637425661087 2022-06-30 21:32:34.658551
learning rate:  0.0004294967296000003
netparams have been saved once 112
val: 1 0.46504876017570496
val: 2 0.4764484167098999
val: 3 0.472520112991333
val: 4 0.4736833870410919
val: 5 0.4623025357723236
val: 6 0.4629407525062561
val: 7 0.4668278098106384
val: 8 0.4463396668434143
val: 9 0.4585275948047638
val: 10 0.4593384265899658
val: 11 0.4733988344669342
val: 12 0.4830527901649475
val: 13 0.46796178817749023
val: 14 0.4673546850681305
val: 15 0.4661628007888794
val: 16 0.46404650807380676
val: 17 0.4781976044178009
val: 18 0.460475355386734
val: 19 0.463657408952713
val: 20 0.4678994119167328
val_Epoch:[ 112 ] val_loss: 0.46680923253297807 2022-06-30 21:32:38.129861
start training 2022-06-30 21:32:38.224626
Epoch:[ 113 0 ] loss: 0.39879003167152405 2022-06-30 21:32:52.219340
Epoch:[ 113 1 ] loss: 0.399006724357605 2022-06-30 21:32:52.660062
Epoch:[ 113 2 ] loss: 0.40043002367019653 2022-06-30 21:32:53.080159
Epoch:[ 113 3 ] loss: 0.39746037125587463 2022-06-30 21:32:53.494513
Epoch:[ 113 4 ] loss: 0.39867785573005676 2022-06-30 21:32:53.908215
Epoch:[ 113 5 ] loss: 0.39831408858299255 2022-06-30 21:32:54.324652
Epoch:[ 113 6 ] loss: 0.39575129747390747 2022-06-30 21:32:54.759326
Epoch:[ 113 7 ] loss: 0.3968014717102051 2022-06-30 21:32:55.244323
Epoch:[ 113 8 ] loss: 0.39889851212501526 2022-06-30 21:32:55.658324
Epoch:[ 113 9 ] loss: 0.39643847942352295 2022-06-30 21:32:56.078079
Epoch:[ 113 10 ] loss: 0.39817288517951965 2022-06-30 21:32:56.494269
Epoch:[ 113 11 ] loss: 0.398703932762146 2022-06-30 21:32:56.916071
Epoch:[ 113 12 ] loss: 0.4007534384727478 2022-06-30 21:32:57.332267
Epoch:[ 113 13 ] loss: 0.4000363349914551 2022-06-30 21:32:57.748272
Epoch:[ 113 14 ] loss: 0.39930564165115356 2022-06-30 21:32:58.163163
Epoch:[ 113 15 ] loss: 0.4001544713973999 2022-06-30 21:32:58.578376
Epoch:[ 113 16 ] loss: 0.3978709280490875 2022-06-30 21:33:03.836240
Epoch:[ 113 17 ] loss: 0.4027477502822876 2022-06-30 21:33:04.249423
Epoch:[ 113 18 ] loss: 0.3987974226474762 2022-06-30 21:33:04.664633
Epoch:[ 113 19 ] loss: 0.39923515915870667 2022-06-30 21:33:05.080551
Training_Epoch:[ 113 ] Training_loss: 0.398817341029644 2022-06-30 21:33:05.081223
learning rate:  0.0004294967296000003
val: 1 0.45397013425827026
val: 2 0.4717741012573242
val: 3 0.45767197012901306
val: 4 0.4697931110858917
val: 5 0.47165587544441223
val: 6 0.4539417326450348
val: 7 0.47035911679267883
val: 8 0.46657779812812805
val: 9 0.4558694660663605
val: 10 0.46884000301361084
val: 11 0.473001629114151
val: 12 0.46274441480636597
val: 13 0.45219680666923523
val: 14 0.45819833874702454
val: 15 0.45506298542022705
val: 16 0.4646081030368805
val: 17 0.46443551778793335
val: 18 0.46639180183410645
val: 19 0.4622727632522583
val: 20 0.468718558549881
val_Epoch:[ 113 ] val_loss: 0.4634042114019394 2022-06-30 21:33:08.395269
start training 2022-06-30 21:33:08.495479
Epoch:[ 114 0 ] loss: 0.39901044964790344 2022-06-30 21:33:23.209716
Epoch:[ 114 1 ] loss: 0.3993804156780243 2022-06-30 21:33:23.625569
Epoch:[ 114 2 ] loss: 0.39779967069625854 2022-06-30 21:33:24.039413
Epoch:[ 114 3 ] loss: 0.4001941680908203 2022-06-30 21:33:24.454027
Epoch:[ 114 4 ] loss: 0.3981676995754242 2022-06-30 21:33:24.870365
Epoch:[ 114 5 ] loss: 0.3976200222969055 2022-06-30 21:33:25.308375
Epoch:[ 114 6 ] loss: 0.39778485894203186 2022-06-30 21:33:25.796518
Epoch:[ 114 7 ] loss: 0.40007835626602173 2022-06-30 21:33:26.212178
Epoch:[ 114 8 ] loss: 0.39712759852409363 2022-06-30 21:33:26.639592
Epoch:[ 114 9 ] loss: 0.3992897868156433 2022-06-30 21:33:27.059988
Epoch:[ 114 10 ] loss: 0.3988344669342041 2022-06-30 21:33:27.475133
Epoch:[ 114 11 ] loss: 0.3998987376689911 2022-06-30 21:33:27.889230
Epoch:[ 114 12 ] loss: 0.39800432324409485 2022-06-30 21:33:28.307665
Epoch:[ 114 13 ] loss: 0.4016086757183075 2022-06-30 21:33:28.723202
Epoch:[ 114 14 ] loss: 0.3995327651500702 2022-06-30 21:33:29.139589
Epoch:[ 114 15 ] loss: 0.40002232789993286 2022-06-30 21:33:29.556576
Epoch:[ 114 16 ] loss: 0.4017716348171234 2022-06-30 21:33:34.592538
Epoch:[ 114 17 ] loss: 0.39776840806007385 2022-06-30 21:33:35.006702
Epoch:[ 114 18 ] loss: 0.3965164124965668 2022-06-30 21:33:35.423054
Epoch:[ 114 19 ] loss: 0.39707303047180176 2022-06-30 21:33:35.837736
Training_Epoch:[ 114 ] Training_loss: 0.39887419044971467 2022-06-30 21:33:35.838403
learning rate:  0.0004294967296000003
netparams have been saved once 114
val: 1 0.46013927459716797
val: 2 0.4633258879184723
val: 3 0.45416948199272156
val: 4 0.4564597010612488
val: 5 0.45425549149513245
val: 6 0.46236327290534973
val: 7 0.46298351883888245
val: 8 0.4683529734611511
val: 9 0.4640667736530304
val: 10 0.45697692036628723
val: 11 0.4673179090023041
val: 12 0.4665960371494293
val: 13 0.464365690946579
val: 14 0.44554582238197327
val: 15 0.4461607038974762
val: 16 0.4608011245727539
val: 17 0.4615684747695923
val: 18 0.4538547396659851
val: 19 0.4634144902229309
val: 20 0.4743306338787079
val_Epoch:[ 114 ] val_loss: 0.4603524461388588 2022-06-30 21:33:39.209254
start training 2022-06-30 21:33:39.309390
Epoch:[ 115 0 ] loss: 0.39834848046302795 2022-06-30 21:33:53.247449
Epoch:[ 115 1 ] loss: 0.39802709221839905 2022-06-30 21:33:53.687440
Epoch:[ 115 2 ] loss: 0.39893633127212524 2022-06-30 21:33:54.107999
Epoch:[ 115 3 ] loss: 0.3976317346096039 2022-06-30 21:33:54.532117
Epoch:[ 115 4 ] loss: 0.3982180058956146 2022-06-30 21:33:54.946713
Epoch:[ 115 5 ] loss: 0.39610934257507324 2022-06-30 21:33:55.360362
Epoch:[ 115 6 ] loss: 0.3978230655193329 2022-06-30 21:33:55.810584
Epoch:[ 115 7 ] loss: 0.399293452501297 2022-06-30 21:33:56.302705
Epoch:[ 115 8 ] loss: 0.3974027931690216 2022-06-30 21:33:56.725228
Epoch:[ 115 9 ] loss: 0.39822229743003845 2022-06-30 21:33:57.140053
Epoch:[ 115 10 ] loss: 0.3966318368911743 2022-06-30 21:33:57.554278
Epoch:[ 115 11 ] loss: 0.39850324392318726 2022-06-30 21:33:57.970957
Epoch:[ 115 12 ] loss: 0.40108704566955566 2022-06-30 21:33:58.384643
Epoch:[ 115 13 ] loss: 0.39975860714912415 2022-06-30 21:33:58.798018
Epoch:[ 115 14 ] loss: 0.4012487828731537 2022-06-30 21:33:59.213871
Epoch:[ 115 15 ] loss: 0.40009474754333496 2022-06-30 21:33:59.630164
Epoch:[ 115 16 ] loss: 0.3968553841114044 2022-06-30 21:34:04.771464
Epoch:[ 115 17 ] loss: 0.3985733389854431 2022-06-30 21:34:05.186952
Epoch:[ 115 18 ] loss: 0.3974721431732178 2022-06-30 21:34:05.603624
Epoch:[ 115 19 ] loss: 0.3990277051925659 2022-06-30 21:34:06.017839
Training_Epoch:[ 115 ] Training_loss: 0.39846327155828476 2022-06-30 21:34:06.018672
learning rate:  0.0004294967296000003
val: 1 0.4589484632015228
val: 2 0.48219597339630127
val: 3 0.47476208209991455
val: 4 0.4590166211128235
val: 5 0.44903725385665894
val: 6 0.45373374223709106
val: 7 0.4749442934989929
val: 8 0.47394320368766785
val: 9 0.4587496221065521
val: 10 0.4711260497570038
val: 11 0.4707869589328766
val: 12 0.46317383646965027
val: 13 0.4636690318584442
val: 14 0.4672521948814392
val: 15 0.480916827917099
val: 16 0.4711122214794159
val: 17 0.46473604440689087
val: 18 0.46156442165374756
val: 19 0.46031367778778076
val: 20 0.46773070096969604
val_Epoch:[ 115 ] val_loss: 0.46638566106557844 2022-06-30 21:34:09.410887
start training 2022-06-30 21:34:09.510295
Epoch:[ 116 0 ] loss: 0.39713892340660095 2022-06-30 21:34:24.240253
Epoch:[ 116 1 ] loss: 0.39907845854759216 2022-06-30 21:34:24.656692
Epoch:[ 116 2 ] loss: 0.39713290333747864 2022-06-30 21:34:25.081551
Epoch:[ 116 3 ] loss: 0.39670470356941223 2022-06-30 21:34:25.505043
Epoch:[ 116 4 ] loss: 0.39594578742980957 2022-06-30 21:34:25.925965
Epoch:[ 116 5 ] loss: 0.4002207815647125 2022-06-30 21:34:26.341380
Epoch:[ 116 6 ] loss: 0.39741387963294983 2022-06-30 21:34:26.754731
Epoch:[ 116 7 ] loss: 0.39666566252708435 2022-06-30 21:34:27.169361
Epoch:[ 116 8 ] loss: 0.4010103940963745 2022-06-30 21:34:27.595089
Epoch:[ 116 9 ] loss: 0.39674293994903564 2022-06-30 21:34:28.010498
Epoch:[ 116 10 ] loss: 0.39971017837524414 2022-06-30 21:34:28.466659
Epoch:[ 116 11 ] loss: 0.40197446942329407 2022-06-30 21:34:28.953473
Epoch:[ 116 12 ] loss: 0.39880627393722534 2022-06-30 21:34:29.368799
Epoch:[ 116 13 ] loss: 0.3993392884731293 2022-06-30 21:34:29.782792
Epoch:[ 116 14 ] loss: 0.3990979790687561 2022-06-30 21:34:30.196398
Epoch:[ 116 15 ] loss: 0.39797016978263855 2022-06-30 21:34:30.614138
Epoch:[ 116 16 ] loss: 0.39846575260162354 2022-06-30 21:34:35.897013
Epoch:[ 116 17 ] loss: 0.3997817933559418 2022-06-30 21:34:36.328108
Epoch:[ 116 18 ] loss: 0.3987189531326294 2022-06-30 21:34:36.743029
Epoch:[ 116 19 ] loss: 0.39699143171310425 2022-06-30 21:34:37.159097
Training_Epoch:[ 116 ] Training_loss: 0.39844553619623185 2022-06-30 21:34:37.159727
learning rate:  0.0004294967296000003
netparams have been saved once 116
val: 1 0.45350873470306396
val: 2 0.46828123927116394
val: 3 0.46768131852149963
val: 4 0.4814450442790985
val: 5 0.45958563685417175
val: 6 0.4568425714969635
val: 7 0.4725385010242462
val: 8 0.4607774615287781
val: 9 0.46771836280822754
val: 10 0.44861936569213867
val: 11 0.4565335512161255
val: 12 0.4832786023616791
val: 13 0.4555274248123169
val: 14 0.4670085310935974
val: 15 0.4623907208442688
val: 16 0.46906089782714844
val: 17 0.4615944027900696
val: 18 0.4643508195877075
val: 19 0.4597158133983612
val: 20 0.45342886447906494
val_Epoch:[ 116 ] val_loss: 0.46349439322948455 2022-06-30 21:34:40.540522
start training 2022-06-30 21:34:40.639227
Epoch:[ 117 0 ] loss: 0.3981417417526245 2022-06-30 21:34:54.316306
Epoch:[ 117 1 ] loss: 0.3947686553001404 2022-06-30 21:34:54.764955
Epoch:[ 117 2 ] loss: 0.39942529797554016 2022-06-30 21:34:55.203822
Epoch:[ 117 3 ] loss: 0.3985866904258728 2022-06-30 21:34:55.619616
Epoch:[ 117 4 ] loss: 0.39597755670547485 2022-06-30 21:34:56.034348
Epoch:[ 117 5 ] loss: 0.3984795808792114 2022-06-30 21:34:56.448457
Epoch:[ 117 6 ] loss: 0.39799875020980835 2022-06-30 21:34:56.871340
Epoch:[ 117 7 ] loss: 0.39955124258995056 2022-06-30 21:34:57.291420
Epoch:[ 117 8 ] loss: 0.3982328176498413 2022-06-30 21:34:57.704626
Epoch:[ 117 9 ] loss: 0.39893704652786255 2022-06-30 21:34:58.120074
Epoch:[ 117 10 ] loss: 0.3984901010990143 2022-06-30 21:34:58.536032
Epoch:[ 117 11 ] loss: 0.39897987246513367 2022-06-30 21:34:58.952779
Epoch:[ 117 12 ] loss: 0.39947015047073364 2022-06-30 21:34:59.366233
Epoch:[ 117 13 ] loss: 0.4006337523460388 2022-06-30 21:34:59.809326
Epoch:[ 117 14 ] loss: 0.39900052547454834 2022-06-30 21:35:00.296586
Epoch:[ 117 15 ] loss: 0.3995463252067566 2022-06-30 21:35:00.711403
Epoch:[ 117 16 ] loss: 0.39751458168029785 2022-06-30 21:35:06.191484
Epoch:[ 117 17 ] loss: 0.3995600640773773 2022-06-30 21:35:06.623446
Epoch:[ 117 18 ] loss: 0.3974452018737793 2022-06-30 21:35:07.038970
Epoch:[ 117 19 ] loss: 0.3971174657344818 2022-06-30 21:35:07.452840
Training_Epoch:[ 117 ] Training_loss: 0.3983928710222244 2022-06-30 21:35:07.453531
learning rate:  0.0004294967296000003
val: 1 0.4720354974269867
val: 2 0.46678516268730164
val: 3 0.4643750786781311
val: 4 0.46487104892730713
val: 5 0.4676504135131836
val: 6 0.4654448628425598
val: 7 0.43370911478996277
val: 8 0.48540568351745605
val: 9 0.45792338252067566
val: 10 0.45934560894966125
val: 11 0.4760030508041382
val: 12 0.4602072238922119
val: 13 0.4580288827419281
val: 14 0.473401814699173
val: 15 0.4469921886920929
val: 16 0.45790719985961914
val: 17 0.45859500765800476
val: 18 0.46138426661491394
val: 19 0.46753641963005066
val: 20 0.4554312825202942
val_Epoch:[ 117 ] val_loss: 0.46265165954828263 2022-06-30 21:35:10.926083
start training 2022-06-30 21:35:11.025089
Epoch:[ 118 0 ] loss: 0.3980571925640106 2022-06-30 21:35:25.398689
Epoch:[ 118 1 ] loss: 0.39789748191833496 2022-06-30 21:35:25.813800
Epoch:[ 118 2 ] loss: 0.39607924222946167 2022-06-30 21:35:26.227765
Epoch:[ 118 3 ] loss: 0.3986324071884155 2022-06-30 21:35:26.645488
Epoch:[ 118 4 ] loss: 0.3972384035587311 2022-06-30 21:35:27.067385
Epoch:[ 118 5 ] loss: 0.3960447907447815 2022-06-30 21:35:27.484480
Epoch:[ 118 6 ] loss: 0.3959595561027527 2022-06-30 21:35:27.899017
Epoch:[ 118 7 ] loss: 0.39645805954933167 2022-06-30 21:35:28.321496
Epoch:[ 118 8 ] loss: 0.3969818353652954 2022-06-30 21:35:28.743627
Epoch:[ 118 9 ] loss: 0.39863210916519165 2022-06-30 21:35:29.157405
Epoch:[ 118 10 ] loss: 0.39610087871551514 2022-06-30 21:35:29.573254
Epoch:[ 118 11 ] loss: 0.3981306850910187 2022-06-30 21:35:29.993749
Epoch:[ 118 12 ] loss: 0.395986407995224 2022-06-30 21:35:30.477284
Epoch:[ 118 13 ] loss: 0.39956188201904297 2022-06-30 21:35:30.897063
Epoch:[ 118 14 ] loss: 0.3970770537853241 2022-06-30 21:35:31.311069
Epoch:[ 118 15 ] loss: 0.3971589505672455 2022-06-30 21:35:31.731756
Epoch:[ 118 16 ] loss: 0.39797651767730713 2022-06-30 21:35:37.248428
Epoch:[ 118 17 ] loss: 0.39900466799736023 2022-06-30 21:35:37.662885
Epoch:[ 118 18 ] loss: 0.3962933123111725 2022-06-30 21:35:38.078746
Epoch:[ 118 19 ] loss: 0.40053248405456543 2022-06-30 21:35:38.493481
Training_Epoch:[ 118 ] Training_loss: 0.3974901959300041 2022-06-30 21:35:38.494176
learning rate:  0.0004294967296000003
netparams have been saved once 118
val: 1 0.45951592922210693
val: 2 0.4634247124195099
val: 3 0.4672365188598633
val: 4 0.4520415663719177
val: 5 0.45963796973228455
val: 6 0.4635874629020691
val: 7 0.45482465624809265
val: 8 0.4547901749610901
val: 9 0.4747030436992645
val: 10 0.45780280232429504
val: 11 0.4555720388889313
val: 12 0.4561799466609955
val: 13 0.4724455177783966
val: 14 0.4607422351837158
val: 15 0.4592200815677643
val: 16 0.4632355868816376
val: 17 0.4539047181606293
val: 18 0.4677563011646271
val: 19 0.45197439193725586
val: 20 0.4621133506298065
val_Epoch:[ 118 ] val_loss: 0.46053545027971265 2022-06-30 21:35:41.927775
start training 2022-06-30 21:35:42.027816
Epoch:[ 119 0 ] loss: 0.3979354202747345 2022-06-30 21:35:56.208575
Epoch:[ 119 1 ] loss: 0.39765140414237976 2022-06-30 21:35:56.623712
Epoch:[ 119 2 ] loss: 0.3996184766292572 2022-06-30 21:35:57.038018
Epoch:[ 119 3 ] loss: 0.3943113088607788 2022-06-30 21:35:57.452784
Epoch:[ 119 4 ] loss: 0.39667415618896484 2022-06-30 21:35:57.875163
Epoch:[ 119 5 ] loss: 0.3953027129173279 2022-06-30 21:35:58.292268
Epoch:[ 119 6 ] loss: 0.3982664942741394 2022-06-30 21:35:58.714313
Epoch:[ 119 7 ] loss: 0.3979392945766449 2022-06-30 21:35:59.136721
Epoch:[ 119 8 ] loss: 0.3964260518550873 2022-06-30 21:35:59.551704
Epoch:[ 119 9 ] loss: 0.3980019986629486 2022-06-30 21:35:59.964880
Epoch:[ 119 10 ] loss: 0.4001249074935913 2022-06-30 21:36:00.381530
Epoch:[ 119 11 ] loss: 0.397942453622818 2022-06-30 21:36:00.863392
Epoch:[ 119 12 ] loss: 0.3979467749595642 2022-06-30 21:36:01.286586
Epoch:[ 119 13 ] loss: 0.3976362347602844 2022-06-30 21:36:01.704053
Epoch:[ 119 14 ] loss: 0.3980439603328705 2022-06-30 21:36:02.118358
Epoch:[ 119 15 ] loss: 0.3961527645587921 2022-06-30 21:36:02.541043
Epoch:[ 119 16 ] loss: 0.3982919454574585 2022-06-30 21:36:07.712064
Epoch:[ 119 17 ] loss: 0.39836129546165466 2022-06-30 21:36:08.127292
Epoch:[ 119 18 ] loss: 0.40078169107437134 2022-06-30 21:36:08.544417
Epoch:[ 119 19 ] loss: 0.39748793840408325 2022-06-30 21:36:08.960607
Training_Epoch:[ 119 ] Training_loss: 0.3977448642253876 2022-06-30 21:36:08.961229
learning rate:  0.0004294967296000003
val: 1 0.459479421377182
val: 2 0.47106316685676575
val: 3 0.4559900462627411
val: 4 0.46047309041023254
val: 5 0.4557856023311615
val: 6 0.4597932994365692
val: 7 0.4699645936489105
val: 8 0.4730373024940491
val: 9 0.46521830558776855
val: 10 0.4746234714984894
val: 11 0.4712620973587036
val: 12 0.46218445897102356
val: 13 0.4731169641017914
val: 14 0.4554098844528198
val: 15 0.4562743604183197
val: 16 0.47807416319847107
val: 17 0.4563996195793152
val: 18 0.4711392819881439
val: 19 0.4660531282424927
val: 20 0.46077170968055725
val_Epoch:[ 119 ] val_loss: 0.46480569839477537 2022-06-30 21:36:12.323060
start training 2022-06-30 21:36:12.422596
Epoch:[ 120 0 ] loss: 0.39637991786003113 2022-06-30 21:36:26.366795
Epoch:[ 120 1 ] loss: 0.39639025926589966 2022-06-30 21:36:26.866275
Epoch:[ 120 2 ] loss: 0.396051287651062 2022-06-30 21:36:27.282068
Epoch:[ 120 3 ] loss: 0.40148869156837463 2022-06-30 21:36:27.701840
Epoch:[ 120 4 ] loss: 0.3968605101108551 2022-06-30 21:36:28.115382
Epoch:[ 120 5 ] loss: 0.39864352345466614 2022-06-30 21:36:28.531677
Epoch:[ 120 6 ] loss: 0.3973270058631897 2022-06-30 21:36:28.953792
Epoch:[ 120 7 ] loss: 0.39528921246528625 2022-06-30 21:36:29.373358
Epoch:[ 120 8 ] loss: 0.39663416147232056 2022-06-30 21:36:29.794628
Epoch:[ 120 9 ] loss: 0.39841121435165405 2022-06-30 21:36:30.209527
Epoch:[ 120 10 ] loss: 0.39848053455352783 2022-06-30 21:36:30.645684
Epoch:[ 120 11 ] loss: 0.3967157304286957 2022-06-30 21:36:31.136868
Epoch:[ 120 12 ] loss: 0.3988197445869446 2022-06-30 21:36:31.553444
Epoch:[ 120 13 ] loss: 0.39827919006347656 2022-06-30 21:36:31.970529
Epoch:[ 120 14 ] loss: 0.39807918667793274 2022-06-30 21:36:32.386004
Epoch:[ 120 15 ] loss: 0.3973664939403534 2022-06-30 21:36:32.801242
Epoch:[ 120 16 ] loss: 0.39752495288848877 2022-06-30 21:36:38.470537
Epoch:[ 120 17 ] loss: 0.3992955982685089 2022-06-30 21:36:38.884582
Epoch:[ 120 18 ] loss: 0.4020521640777588 2022-06-30 21:36:39.298934
Epoch:[ 120 19 ] loss: 0.3988398313522339 2022-06-30 21:36:39.718290
Training_Epoch:[ 120 ] Training_loss: 0.397946460545063 2022-06-30 21:36:39.719027
learning rate:  0.0004294967296000003
netparams have been saved once 120
val: 1 0.4625453054904938
val: 2 0.4631742537021637
val: 3 0.46062424778938293
val: 4 0.47664329409599304
val: 5 0.4778144657611847
val: 6 0.4573720693588257
val: 7 0.47683706879615784
val: 8 0.4724636375904083
val: 9 0.46148261427879333
val: 10 0.4706112742424011
val: 11 0.45550182461738586
val: 12 0.45969608426094055
val: 13 0.46412813663482666
val: 14 0.46909335255622864
val: 15 0.46459051966667175
val: 16 0.4615458548069
val: 17 0.46844282746315
val: 18 0.45667168498039246
val: 19 0.46700698137283325
val: 20 0.487486332654953
val_Epoch:[ 120 ] val_loss: 0.46668659150600433 2022-06-30 21:36:43.119508
start training 2022-06-30 21:36:43.216807
Epoch:[ 121 0 ] loss: 0.3953937590122223 2022-06-30 21:36:57.441541
Epoch:[ 121 1 ] loss: 0.3974824547767639 2022-06-30 21:36:57.857240
Epoch:[ 121 2 ] loss: 0.39958056807518005 2022-06-30 21:36:58.270868
Epoch:[ 121 3 ] loss: 0.3951200842857361 2022-06-30 21:36:58.692116
Epoch:[ 121 4 ] loss: 0.3983819782733917 2022-06-30 21:36:59.105114
Epoch:[ 121 5 ] loss: 0.3977234661579132 2022-06-30 21:36:59.518328
Epoch:[ 121 6 ] loss: 0.3951708972454071 2022-06-30 21:36:59.935552
Epoch:[ 121 7 ] loss: 0.39930233359336853 2022-06-30 21:37:00.357145
Epoch:[ 121 8 ] loss: 0.39622583985328674 2022-06-30 21:37:00.792354
Epoch:[ 121 9 ] loss: 0.39585721492767334 2022-06-30 21:37:01.272650
Epoch:[ 121 10 ] loss: 0.3945823907852173 2022-06-30 21:37:01.685951
Epoch:[ 121 11 ] loss: 0.3959467113018036 2022-06-30 21:37:02.100694
Epoch:[ 121 12 ] loss: 0.39605650305747986 2022-06-30 21:37:02.520313
Epoch:[ 121 13 ] loss: 0.39599549770355225 2022-06-30 21:37:02.936229
Epoch:[ 121 14 ] loss: 0.39583832025527954 2022-06-30 21:37:03.356677
Epoch:[ 121 15 ] loss: 0.39773985743522644 2022-06-30 21:37:03.779113
Epoch:[ 121 16 ] loss: 0.39772269129753113 2022-06-30 21:37:09.357586
Epoch:[ 121 17 ] loss: 0.3948507010936737 2022-06-30 21:37:09.771324
Epoch:[ 121 18 ] loss: 0.39640501141548157 2022-06-30 21:37:10.188470
Epoch:[ 121 19 ] loss: 0.39597654342651367 2022-06-30 21:37:10.602664
Training_Epoch:[ 121 ] Training_loss: 0.3965676411986351 2022-06-30 21:37:10.603512
learning rate:  0.00034359738368000027
val: 1 0.47052517533302307
val: 2 0.47638627886772156
val: 3 0.45430999994277954
val: 4 0.4686671197414398
val: 5 0.4658171534538269
val: 6 0.46401745080947876
val: 7 0.4678395688533783
val: 8 0.46359771490097046
val: 9 0.461954802274704
val: 10 0.45141613483428955
val: 11 0.4641854166984558
val: 12 0.463683158159256
val: 13 0.4637557566165924
val: 14 0.45900535583496094
val: 15 0.47525471448898315
val: 16 0.473292738199234
val: 17 0.45122402906417847
val: 18 0.478084921836853
val: 19 0.4658007025718689
val: 20 0.4653536379337311
val_Epoch:[ 121 ] val_loss: 0.4652085915207863 2022-06-30 21:37:13.965825
start training 2022-06-30 21:37:14.066932
Epoch:[ 122 0 ] loss: 0.39531201124191284 2022-06-30 21:37:27.756313
Epoch:[ 122 1 ] loss: 0.3932192921638489 2022-06-30 21:37:28.688394
Epoch:[ 122 2 ] loss: 0.3941552937030792 2022-06-30 21:37:29.102788
Epoch:[ 122 3 ] loss: 0.3946305215358734 2022-06-30 21:37:29.517400
Epoch:[ 122 4 ] loss: 0.3959862291812897 2022-06-30 21:37:29.932936
Epoch:[ 122 5 ] loss: 0.39354005455970764 2022-06-30 21:37:30.346480
Epoch:[ 122 6 ] loss: 0.39511772990226746 2022-06-30 21:37:30.761054
Epoch:[ 122 7 ] loss: 0.3942076861858368 2022-06-30 21:37:31.177073
Epoch:[ 122 8 ] loss: 0.39545387029647827 2022-06-30 21:37:31.592309
Epoch:[ 122 9 ] loss: 0.39646267890930176 2022-06-30 21:37:32.045827
Epoch:[ 122 10 ] loss: 0.3945901095867157 2022-06-30 21:37:32.521226
Epoch:[ 122 11 ] loss: 0.39783361554145813 2022-06-30 21:37:32.937454
Epoch:[ 122 12 ] loss: 0.39668723940849304 2022-06-30 21:37:33.350608
Epoch:[ 122 13 ] loss: 0.3983801603317261 2022-06-30 21:37:33.772031
Epoch:[ 122 14 ] loss: 0.3983326554298401 2022-06-30 21:37:34.194193
Epoch:[ 122 15 ] loss: 0.3981960713863373 2022-06-30 21:37:34.614812
Epoch:[ 122 16 ] loss: 0.3961002230644226 2022-06-30 21:37:39.742333
Epoch:[ 122 17 ] loss: 0.3937736749649048 2022-06-30 21:37:40.318045
Epoch:[ 122 18 ] loss: 0.3960644006729126 2022-06-30 21:37:40.732637
Epoch:[ 122 19 ] loss: 0.39469990134239197 2022-06-30 21:37:41.147880
Training_Epoch:[ 122 ] Training_loss: 0.39563717097043993 2022-06-30 21:37:41.148567
learning rate:  0.00034359738368000027
netparams have been saved once 122
val: 1 0.4701038897037506
val: 2 0.46709370613098145
val: 3 0.4631197154521942
val: 4 0.46620669960975647
val: 5 0.46405231952667236
val: 6 0.4577801525592804
val: 7 0.46448177099227905
val: 8 0.46175628900527954
val: 9 0.47268497943878174
val: 10 0.4681600034236908
val: 11 0.4629133939743042
val: 12 0.4702000021934509
val: 13 0.46070510149002075
val: 14 0.4732441008090973
val: 15 0.4690870940685272
val: 16 0.46403393149375916
val: 17 0.4700906276702881
val: 18 0.47166427969932556
val: 19 0.4649684429168701
val: 20 0.459538996219635
val_Epoch:[ 122 ] val_loss: 0.46609427481889726 2022-06-30 21:37:44.577199
start training 2022-06-30 21:37:44.677045
Epoch:[ 123 0 ] loss: 0.39784669876098633 2022-06-30 21:37:59.417966
Epoch:[ 123 1 ] loss: 0.39458298683166504 2022-06-30 21:37:59.836631
Epoch:[ 123 2 ] loss: 0.3947596549987793 2022-06-30 21:38:00.252697
Epoch:[ 123 3 ] loss: 0.3951743543148041 2022-06-30 21:38:00.669801
Epoch:[ 123 4 ] loss: 0.39491358399391174 2022-06-30 21:38:01.085497
Epoch:[ 123 5 ] loss: 0.3954887092113495 2022-06-30 21:38:01.500394
Epoch:[ 123 6 ] loss: 0.39354008436203003 2022-06-30 21:38:01.914084
Epoch:[ 123 7 ] loss: 0.3967837691307068 2022-06-30 21:38:02.328496
Epoch:[ 123 8 ] loss: 0.39453673362731934 2022-06-30 21:38:02.751025
Epoch:[ 123 9 ] loss: 0.39662647247314453 2022-06-30 21:38:03.166857
Epoch:[ 123 10 ] loss: 0.3966010510921478 2022-06-30 21:38:03.582971
Epoch:[ 123 11 ] loss: 0.39628684520721436 2022-06-30 21:38:04.052994
Epoch:[ 123 12 ] loss: 0.3934257924556732 2022-06-30 21:38:04.542272
Epoch:[ 123 13 ] loss: 0.39363592863082886 2022-06-30 21:38:04.974960
Epoch:[ 123 14 ] loss: 0.39486366510391235 2022-06-30 21:38:05.394818
Epoch:[ 123 15 ] loss: 0.39426541328430176 2022-06-30 21:38:05.822598
Epoch:[ 123 16 ] loss: 0.395555704832077 2022-06-30 21:38:11.412043
Epoch:[ 123 17 ] loss: 0.3982357382774353 2022-06-30 21:38:11.840791
Epoch:[ 123 18 ] loss: 0.3973045349121094 2022-06-30 21:38:12.284980
Epoch:[ 123 19 ] loss: 0.3966768980026245 2022-06-30 21:38:12.716230
Training_Epoch:[ 123 ] Training_loss: 0.39555523097515105 2022-06-30 21:38:12.717006
learning rate:  0.00034359738368000027
val: 1 0.4673532545566559
val: 2 0.4707140326499939
val: 3 0.4640054702758789
val: 4 0.45411795377731323
val: 5 0.4613804519176483
val: 6 0.4657021164894104
val: 7 0.4710000157356262
val: 8 0.46815958619117737
val: 9 0.4590141475200653
val: 10 0.45832523703575134
val: 11 0.4595988094806671
val: 12 0.4460262954235077
val: 13 0.46149685978889465
val: 14 0.4728178381919861
val: 15 0.46901601552963257
val: 16 0.4671870768070221
val: 17 0.46661376953125
val: 18 0.4679183065891266
val: 19 0.4615176022052765
val: 20 0.46320682764053345
val_Epoch:[ 123 ] val_loss: 0.46375858336687087 2022-06-30 21:38:16.139296
start training 2022-06-30 21:38:16.239237
Epoch:[ 124 0 ] loss: 0.3951002359390259 2022-06-30 21:38:30.787405
Epoch:[ 124 1 ] loss: 0.39388003945350647 2022-06-30 21:38:31.236087
Epoch:[ 124 2 ] loss: 0.39475348591804504 2022-06-30 21:38:31.651981
Epoch:[ 124 3 ] loss: 0.39354634284973145 2022-06-30 21:38:32.070263
Epoch:[ 124 4 ] loss: 0.3931524455547333 2022-06-30 21:38:32.493510
Epoch:[ 124 5 ] loss: 0.39525076746940613 2022-06-30 21:38:32.907913
Epoch:[ 124 6 ] loss: 0.3933314085006714 2022-06-30 21:38:33.321978
Epoch:[ 124 7 ] loss: 0.39436662197113037 2022-06-30 21:38:33.736782
Epoch:[ 124 8 ] loss: 0.39638227224349976 2022-06-30 21:38:34.152209
Epoch:[ 124 9 ] loss: 0.39633625745773315 2022-06-30 21:38:34.569488
Epoch:[ 124 10 ] loss: 0.3953883647918701 2022-06-30 21:38:34.985110
Epoch:[ 124 11 ] loss: 0.3951178789138794 2022-06-30 21:38:35.407123
Epoch:[ 124 12 ] loss: 0.3959600329399109 2022-06-30 21:38:35.824913
Epoch:[ 124 13 ] loss: 0.3959873914718628 2022-06-30 21:38:36.238938
Epoch:[ 124 14 ] loss: 0.39400362968444824 2022-06-30 21:38:36.657574
Epoch:[ 124 15 ] loss: 0.3963698446750641 2022-06-30 21:38:37.094469
Epoch:[ 124 16 ] loss: 0.39621222019195557 2022-06-30 21:38:42.158904
Epoch:[ 124 17 ] loss: 0.3973892629146576 2022-06-30 21:38:42.667849
Epoch:[ 124 18 ] loss: 0.3933618366718292 2022-06-30 21:38:43.086184
Epoch:[ 124 19 ] loss: 0.3975241482257843 2022-06-30 21:38:43.503764
Training_Epoch:[ 124 ] Training_loss: 0.39517072439193723 2022-06-30 21:38:43.504530
learning rate:  0.00034359738368000027
netparams have been saved once 124
val: 1 0.4612477719783783
val: 2 0.47127193212509155
val: 3 0.47148022055625916
val: 4 0.4646765887737274
val: 5 0.47406721115112305
val: 6 0.4576742947101593
val: 7 0.46666857600212097
val: 8 0.46479853987693787
val: 9 0.4554031491279602
val: 10 0.4614666998386383
val: 11 0.46365106105804443
val: 12 0.46597564220428467
val: 13 0.454228937625885
val: 14 0.4735614061355591
val: 15 0.4765472710132599
val: 16 0.46731507778167725
val: 17 0.46650412678718567
val: 18 0.4613770544528961
val: 19 0.45547744631767273
val: 20 0.47288042306900024
val_Epoch:[ 124 ] val_loss: 0.46531367152929304 2022-06-30 21:38:46.933205
start training 2022-06-30 21:38:47.035650
Epoch:[ 125 0 ] loss: 0.39472731947898865 2022-06-30 21:39:01.580712
Epoch:[ 125 1 ] loss: 0.39408645033836365 2022-06-30 21:39:02.002370
Epoch:[ 125 2 ] loss: 0.39803260564804077 2022-06-30 21:39:02.416954
Epoch:[ 125 3 ] loss: 0.39498084783554077 2022-06-30 21:39:02.836226
Epoch:[ 125 4 ] loss: 0.3959754407405853 2022-06-30 21:39:03.259509
Epoch:[ 125 5 ] loss: 0.39701950550079346 2022-06-30 21:39:03.679119
Epoch:[ 125 6 ] loss: 0.39267975091934204 2022-06-30 21:39:04.093762
Epoch:[ 125 7 ] loss: 0.39368173480033875 2022-06-30 21:39:04.509834
Epoch:[ 125 8 ] loss: 0.39562687277793884 2022-06-30 21:39:04.926522
Epoch:[ 125 9 ] loss: 0.3934107720851898 2022-06-30 21:39:05.341503
Epoch:[ 125 10 ] loss: 0.3945188522338867 2022-06-30 21:39:05.758218
Epoch:[ 125 11 ] loss: 0.39533761143684387 2022-06-30 21:39:06.174942
Epoch:[ 125 12 ] loss: 0.3960719704627991 2022-06-30 21:39:06.597560
Epoch:[ 125 13 ] loss: 0.3942006528377533 2022-06-30 21:39:07.014566
Epoch:[ 125 14 ] loss: 0.3938751220703125 2022-06-30 21:39:07.432041
Epoch:[ 125 15 ] loss: 0.39523327350616455 2022-06-30 21:39:07.847885
Epoch:[ 125 16 ] loss: 0.3938780426979065 2022-06-30 21:39:13.568559
Epoch:[ 125 17 ] loss: 0.39429759979248047 2022-06-30 21:39:13.984587
Epoch:[ 125 18 ] loss: 0.39371243119239807 2022-06-30 21:39:14.402276
Epoch:[ 125 19 ] loss: 0.39497140049934387 2022-06-30 21:39:14.819182
Training_Epoch:[ 125 ] Training_loss: 0.3948159128427505 2022-06-30 21:39:14.819875
learning rate:  0.00034359738368000027
val: 1 0.4622512459754944
val: 2 0.4611261487007141
val: 3 0.4726906716823578
val: 4 0.4863995909690857
val: 5 0.47077643871307373
val: 6 0.475610613822937
val: 7 0.45499011874198914
val: 8 0.48382842540740967
val: 9 0.4721418023109436
val: 10 0.4742751717567444
val: 11 0.4755612015724182
val: 12 0.4645005762577057
val: 13 0.4617220461368561
val: 14 0.4636845886707306
val: 15 0.4764612913131714
val: 16 0.48093217611312866
val: 17 0.4516196548938751
val: 18 0.47480180859565735
val: 19 0.4780723750591278
val: 20 0.46467795968055725
val_Epoch:[ 125 ] val_loss: 0.4703061953186989 2022-06-30 21:39:18.183894
start training 2022-06-30 21:39:18.285005
Epoch:[ 126 0 ] loss: 0.3931688666343689 2022-06-30 21:39:32.944107
Epoch:[ 126 1 ] loss: 0.3936927318572998 2022-06-30 21:39:33.378615
Epoch:[ 126 2 ] loss: 0.39212849736213684 2022-06-30 21:39:33.792407
Epoch:[ 126 3 ] loss: 0.3923555314540863 2022-06-30 21:39:34.208677
Epoch:[ 126 4 ] loss: 0.39590561389923096 2022-06-30 21:39:34.630482
Epoch:[ 126 5 ] loss: 0.3924466371536255 2022-06-30 21:39:35.052228
Epoch:[ 126 6 ] loss: 0.39440208673477173 2022-06-30 21:39:35.469635
Epoch:[ 126 7 ] loss: 0.39419662952423096 2022-06-30 21:39:35.885461
Epoch:[ 126 8 ] loss: 0.39405134320259094 2022-06-30 21:39:36.300033
Epoch:[ 126 9 ] loss: 0.3935169279575348 2022-06-30 21:39:36.713422
Epoch:[ 126 10 ] loss: 0.39370250701904297 2022-06-30 21:39:37.133252
Epoch:[ 126 11 ] loss: 0.39333659410476685 2022-06-30 21:39:37.549916
Epoch:[ 126 12 ] loss: 0.3955532908439636 2022-06-30 21:39:37.966923
Epoch:[ 126 13 ] loss: 0.3967401385307312 2022-06-30 21:39:38.388589
Epoch:[ 126 14 ] loss: 0.3946245610713959 2022-06-30 21:39:38.801315
Epoch:[ 126 15 ] loss: 0.3958873748779297 2022-06-30 21:39:39.224064
Epoch:[ 126 16 ] loss: 0.39315763115882874 2022-06-30 21:39:44.299588
Epoch:[ 126 17 ] loss: 0.3968106508255005 2022-06-30 21:39:44.713005
Epoch:[ 126 18 ] loss: 0.3971847891807556 2022-06-30 21:39:45.129607
Epoch:[ 126 19 ] loss: 0.39409780502319336 2022-06-30 21:39:45.544430
Training_Epoch:[ 126 ] Training_loss: 0.39434801042079926 2022-06-30 21:39:45.545080
learning rate:  0.00034359738368000027
netparams have been saved once 126
val: 1 0.4709196984767914
val: 2 0.47181808948516846
val: 3 0.4727690815925598
val: 4 0.4645482301712036
val: 5 0.4585813879966736
val: 6 0.4787087142467499
val: 7 0.4657604992389679
val: 8 0.4669901728630066
val: 9 0.4621274471282959
val: 10 0.4729096293449402
val: 11 0.4690304398536682
val: 12 0.4791128933429718
val: 13 0.4559517502784729
val: 14 0.45783981680870056
val: 15 0.47821393609046936
val: 16 0.4681614935398102
val: 17 0.4725967347621918
val: 18 0.46151503920555115
val: 19 0.4695449471473694
val: 20 0.4529515504837036
val_Epoch:[ 126 ] val_loss: 0.4675025776028633 2022-06-30 21:39:48.964206
start training 2022-06-30 21:39:49.068238
Epoch:[ 127 0 ] loss: 0.39465075731277466 2022-06-30 21:40:03.334205
Epoch:[ 127 1 ] loss: 0.3952997326850891 2022-06-30 21:40:03.760044
Epoch:[ 127 2 ] loss: 0.3955489993095398 2022-06-30 21:40:04.183788
Epoch:[ 127 3 ] loss: 0.3943992853164673 2022-06-30 21:40:04.605767
Epoch:[ 127 4 ] loss: 0.39426422119140625 2022-06-30 21:40:05.026627
Epoch:[ 127 5 ] loss: 0.39200374484062195 2022-06-30 21:40:05.448556
Epoch:[ 127 6 ] loss: 0.3937472403049469 2022-06-30 21:40:05.876686
Epoch:[ 127 7 ] loss: 0.3944902718067169 2022-06-30 21:40:06.300133
Epoch:[ 127 8 ] loss: 0.3934442400932312 2022-06-30 21:40:06.720721
Epoch:[ 127 9 ] loss: 0.3939567804336548 2022-06-30 21:40:07.141147
Epoch:[ 127 10 ] loss: 0.3939826786518097 2022-06-30 21:40:07.560522
Epoch:[ 127 11 ] loss: 0.3937855064868927 2022-06-30 21:40:07.987675
Epoch:[ 127 12 ] loss: 0.3930312395095825 2022-06-30 21:40:08.409022
Epoch:[ 127 13 ] loss: 0.39391055703163147 2022-06-30 21:40:08.833958
Epoch:[ 127 14 ] loss: 0.39528486132621765 2022-06-30 21:40:09.260968
Epoch:[ 127 15 ] loss: 0.3925364911556244 2022-06-30 21:40:09.688398
Epoch:[ 127 16 ] loss: 0.39346054196357727 2022-06-30 21:40:14.794656
Epoch:[ 127 17 ] loss: 0.3948580324649811 2022-06-30 21:40:15.213909
Epoch:[ 127 18 ] loss: 0.39583322405815125 2022-06-30 21:40:15.640641
Epoch:[ 127 19 ] loss: 0.397143691778183 2022-06-30 21:40:16.059772
Training_Epoch:[ 127 ] Training_loss: 0.394281604886055 2022-06-30 21:40:16.060529
learning rate:  0.00034359738368000027
val: 1 0.4680229127407074
val: 2 0.4776454567909241
val: 3 0.4553375244140625
val: 4 0.4682541787624359
val: 5 0.4618544280529022
val: 6 0.483542799949646
val: 7 0.46892809867858887
val: 8 0.48189032077789307
val: 9 0.46806585788726807
val: 10 0.47808969020843506
val: 11 0.46720370650291443
val: 12 0.4743192791938782
val: 13 0.462276428937912
val: 14 0.46260666847229004
val: 15 0.45825183391571045
val: 16 0.46747735142707825
val: 17 0.4804343581199646
val: 18 0.47854089736938477
val: 19 0.47784629464149475
val: 20 0.48198115825653076
val_Epoch:[ 127 ] val_loss: 0.47112846225500105 2022-06-30 21:40:19.345449
start training 2022-06-30 21:40:19.441688
Epoch:[ 128 0 ] loss: 0.39378851652145386 2022-06-30 21:40:33.941729
Epoch:[ 128 1 ] loss: 0.3944651484489441 2022-06-30 21:40:34.360247
Epoch:[ 128 2 ] loss: 0.3944277763366699 2022-06-30 21:40:34.787387
Epoch:[ 128 3 ] loss: 0.3910999596118927 2022-06-30 21:40:35.205570
Epoch:[ 128 4 ] loss: 0.39610999822616577 2022-06-30 21:40:35.622087
Epoch:[ 128 5 ] loss: 0.39398249983787537 2022-06-30 21:40:36.040036
Epoch:[ 128 6 ] loss: 0.3936671316623688 2022-06-30 21:40:36.459264
Epoch:[ 128 7 ] loss: 0.3944825828075409 2022-06-30 21:40:36.885259
Epoch:[ 128 8 ] loss: 0.39364346861839294 2022-06-30 21:40:37.304344
Epoch:[ 128 9 ] loss: 0.39477384090423584 2022-06-30 21:40:37.720244
Epoch:[ 128 10 ] loss: 0.39287659525871277 2022-06-30 21:40:38.136169
Epoch:[ 128 11 ] loss: 0.3950560390949249 2022-06-30 21:40:38.560858
Epoch:[ 128 12 ] loss: 0.3935711085796356 2022-06-30 21:40:38.983876
Epoch:[ 128 13 ] loss: 0.39579716324806213 2022-06-30 21:40:39.402469
Epoch:[ 128 14 ] loss: 0.3945404291152954 2022-06-30 21:40:39.820135
Epoch:[ 128 15 ] loss: 0.3949177861213684 2022-06-30 21:40:40.238917
Epoch:[ 128 16 ] loss: 0.3938889801502228 2022-06-30 21:40:45.710087
Epoch:[ 128 17 ] loss: 0.3930269181728363 2022-06-30 21:40:46.128059
Epoch:[ 128 18 ] loss: 0.3934375047683716 2022-06-30 21:40:46.547625
Epoch:[ 128 19 ] loss: 0.39647436141967773 2022-06-30 21:40:46.977035
Training_Epoch:[ 128 ] Training_loss: 0.3942013904452324 2022-06-30 21:40:46.977710
learning rate:  0.00034359738368000027
netparams have been saved once 128
val: 1 0.47297412157058716
val: 2 0.45924314856529236
val: 3 0.47321924567222595
val: 4 0.47437402606010437
val: 5 0.47579678893089294
val: 6 0.4692786931991577
val: 7 0.4635860323905945
val: 8 0.4508262872695923
val: 9 0.46301430463790894
val: 10 0.4595925807952881
val: 11 0.4797182083129883
val: 12 0.4623483121395111
val: 13 0.4654264450073242
val: 14 0.4673549234867096
val: 15 0.4688534438610077
val: 16 0.46598827838897705
val: 17 0.47347596287727356
val: 18 0.46738824248313904
val: 19 0.46360906958580017
val: 20 0.46734708547592163
val_Epoch:[ 128 ] val_loss: 0.46717076003551483 2022-06-30 21:40:50.425888
start training 2022-06-30 21:40:50.525723
Epoch:[ 129 0 ] loss: 0.39184990525245667 2022-06-30 21:41:04.816195
Epoch:[ 129 1 ] loss: 0.393929123878479 2022-06-30 21:41:05.233640
Epoch:[ 129 2 ] loss: 0.39277738332748413 2022-06-30 21:41:05.656100
Epoch:[ 129 3 ] loss: 0.39426445960998535 2022-06-30 21:41:06.073317
Epoch:[ 129 4 ] loss: 0.39379337430000305 2022-06-30 21:41:06.489812
Epoch:[ 129 5 ] loss: 0.39259210228919983 2022-06-30 21:41:06.908044
Epoch:[ 129 6 ] loss: 0.39272621273994446 2022-06-30 21:41:07.324479
Epoch:[ 129 7 ] loss: 0.3913726806640625 2022-06-30 21:41:07.743201
Epoch:[ 129 8 ] loss: 0.393298864364624 2022-06-30 21:41:08.160796
Epoch:[ 129 9 ] loss: 0.3956197500228882 2022-06-30 21:41:08.584381
Epoch:[ 129 10 ] loss: 0.39347559213638306 2022-06-30 21:41:09.000546
Epoch:[ 129 11 ] loss: 0.394685298204422 2022-06-30 21:41:09.422467
Epoch:[ 129 12 ] loss: 0.3937751352787018 2022-06-30 21:41:09.838368
Epoch:[ 129 13 ] loss: 0.3945222496986389 2022-06-30 21:41:10.254626
Epoch:[ 129 14 ] loss: 0.39165550470352173 2022-06-30 21:41:10.678958
Epoch:[ 129 15 ] loss: 0.3941405713558197 2022-06-30 21:41:11.111438
Epoch:[ 129 16 ] loss: 0.3931427597999573 2022-06-30 21:41:16.255926
Epoch:[ 129 17 ] loss: 0.3945639133453369 2022-06-30 21:41:16.744430
Epoch:[ 129 18 ] loss: 0.39515992999076843 2022-06-30 21:41:17.162802
Epoch:[ 129 19 ] loss: 0.3936012089252472 2022-06-30 21:41:17.591773
Training_Epoch:[ 129 ] Training_loss: 0.3935473009943962 2022-06-30 21:41:17.592450
learning rate:  0.00034359738368000027
val: 1 0.47245869040489197
val: 2 0.4562138319015503
val: 3 0.4709986448287964
val: 4 0.46575337648391724
val: 5 0.4671698808670044
val: 6 0.4742124378681183
val: 7 0.46361324191093445
val: 8 0.4696962237358093
val: 9 0.47173619270324707
val: 10 0.4616415202617645
val: 11 0.4670523405075073
val: 12 0.46273258328437805
val: 13 0.46881285309791565
val: 14 0.4572603106498718
val: 15 0.45688214898109436
val: 16 0.4611532986164093
val: 17 0.46148961782455444
val: 18 0.47678816318511963
val: 19 0.46237292885780334
val: 20 0.4774218201637268
val_Epoch:[ 129 ] val_loss: 0.4662730053067207 2022-06-30 21:41:21.025552
start training 2022-06-30 21:41:21.125381
Epoch:[ 130 0 ] loss: 0.3944297730922699 2022-06-30 21:41:35.813711
Epoch:[ 130 1 ] loss: 0.39367353916168213 2022-06-30 21:41:36.239765
Epoch:[ 130 2 ] loss: 0.3922673761844635 2022-06-30 21:41:36.660975
Epoch:[ 130 3 ] loss: 0.39179280400276184 2022-06-30 21:41:37.083112
Epoch:[ 130 4 ] loss: 0.3942928910255432 2022-06-30 21:41:37.501993
Epoch:[ 130 5 ] loss: 0.3922651708126068 2022-06-30 21:41:37.920941
Epoch:[ 130 6 ] loss: 0.3939199149608612 2022-06-30 21:41:38.348585
Epoch:[ 130 7 ] loss: 0.39246994256973267 2022-06-30 21:41:38.768743
Epoch:[ 130 8 ] loss: 0.3930324614048004 2022-06-30 21:41:39.189779
Epoch:[ 130 9 ] loss: 0.3966178596019745 2022-06-30 21:41:39.615523
Epoch:[ 130 10 ] loss: 0.3935811221599579 2022-06-30 21:41:40.035100
Epoch:[ 130 11 ] loss: 0.3923299014568329 2022-06-30 21:41:40.455855
Epoch:[ 130 12 ] loss: 0.3941940665245056 2022-06-30 21:41:40.876013
Epoch:[ 130 13 ] loss: 0.39328140020370483 2022-06-30 21:41:41.299776
Epoch:[ 130 14 ] loss: 0.39399388432502747 2022-06-30 21:41:41.717693
Epoch:[ 130 15 ] loss: 0.3940739333629608 2022-06-30 21:41:42.139528
Epoch:[ 130 16 ] loss: 0.39316609501838684 2022-06-30 21:41:47.522062
Epoch:[ 130 17 ] loss: 0.3949844241142273 2022-06-30 21:41:47.942327
Epoch:[ 130 18 ] loss: 0.3947451710700989 2022-06-30 21:41:48.364861
Epoch:[ 130 19 ] loss: 0.39519184827804565 2022-06-30 21:41:48.783482
Training_Epoch:[ 130 ] Training_loss: 0.3937151789665222 2022-06-30 21:41:48.784115
learning rate:  0.00034359738368000027
netparams have been saved once 130
val: 1 0.48232781887054443
val: 2 0.47572454810142517
val: 3 0.47310513257980347
val: 4 0.4765884280204773
val: 5 0.4774474501609802
val: 6 0.4567151665687561
val: 7 0.4661439061164856
val: 8 0.4621928930282593
val: 9 0.4639371335506439
val: 10 0.4760226011276245
val: 11 0.47471603751182556
val: 12 0.4757557511329651
val: 13 0.46952518820762634
val: 14 0.47095105051994324
val: 15 0.4616014063358307
val: 16 0.45711076259613037
val: 17 0.47467419505119324
val: 18 0.4783903956413269
val: 19 0.4616881012916565
val: 20 0.4613340198993683
val_Epoch:[ 130 ] val_loss: 0.4697975993156433 2022-06-30 21:41:52.275305
start training 2022-06-30 21:41:52.374568
Epoch:[ 131 0 ] loss: 0.39530980587005615 2022-06-30 21:42:06.795412
Epoch:[ 131 1 ] loss: 0.39155614376068115 2022-06-30 21:42:07.216417
Epoch:[ 131 2 ] loss: 0.3927977383136749 2022-06-30 21:42:07.639422
Epoch:[ 131 3 ] loss: 0.3921468257904053 2022-06-30 21:42:08.062689
Epoch:[ 131 4 ] loss: 0.39342594146728516 2022-06-30 21:42:08.485063
Epoch:[ 131 5 ] loss: 0.39510440826416016 2022-06-30 21:42:08.906524
Epoch:[ 131 6 ] loss: 0.3923354148864746 2022-06-30 21:42:09.328266
Epoch:[ 131 7 ] loss: 0.3921780288219452 2022-06-30 21:42:09.750229
Epoch:[ 131 8 ] loss: 0.3903545141220093 2022-06-30 21:42:10.170504
Epoch:[ 131 9 ] loss: 0.3928419351577759 2022-06-30 21:42:10.599374
Epoch:[ 131 10 ] loss: 0.39334920048713684 2022-06-30 21:42:11.028305
Epoch:[ 131 11 ] loss: 0.39141738414764404 2022-06-30 21:42:11.455666
Epoch:[ 131 12 ] loss: 0.39002639055252075 2022-06-30 21:42:11.882452
Epoch:[ 131 13 ] loss: 0.39436399936676025 2022-06-30 21:42:12.309974
Epoch:[ 131 14 ] loss: 0.3895623981952667 2022-06-30 21:42:12.733263
Epoch:[ 131 15 ] loss: 0.39347827434539795 2022-06-30 21:42:13.155088
Epoch:[ 131 16 ] loss: 0.39169278740882874 2022-06-30 21:42:18.274068
Epoch:[ 131 17 ] loss: 0.39218518137931824 2022-06-30 21:42:18.696235
Epoch:[ 131 18 ] loss: 0.39408084750175476 2022-06-30 21:42:19.122089
Epoch:[ 131 19 ] loss: 0.39529484510421753 2022-06-30 21:42:19.544320
Training_Epoch:[ 131 ] Training_loss: 0.3926751032471657 2022-06-30 21:42:19.544948
learning rate:  0.00027487790694400024
val: 1 0.48352861404418945
val: 2 0.4689936637878418
val: 3 0.4749673008918762
val: 4 0.4668598771095276
val: 5 0.47355353832244873
val: 6 0.46154266595840454
val: 7 0.46681272983551025
val: 8 0.4614688456058502
val: 9 0.47660207748413086
val: 10 0.46633416414260864
val: 11 0.46579501032829285
val: 12 0.4546705484390259
val: 13 0.4616820514202118
val: 14 0.4623395502567291
val: 15 0.4650020897388458
val: 16 0.4723229706287384
val: 17 0.464499294757843
val: 18 0.4478588402271271
val: 19 0.47927534580230713
val: 20 0.4744700789451599
val_Epoch:[ 131 ] val_loss: 0.46742896288633345 2022-06-30 21:42:22.900538
start training 2022-06-30 21:42:22.997760
Epoch:[ 132 0 ] loss: 0.3938327729701996 2022-06-30 21:42:37.133709
Epoch:[ 132 1 ] loss: 0.39046207070350647 2022-06-30 21:42:37.556624
Epoch:[ 132 2 ] loss: 0.3891206383705139 2022-06-30 21:42:37.983724
Epoch:[ 132 3 ] loss: 0.390908807516098 2022-06-30 21:42:38.408416
Epoch:[ 132 4 ] loss: 0.393547385931015 2022-06-30 21:42:38.832803
Epoch:[ 132 5 ] loss: 0.39242416620254517 2022-06-30 21:42:39.255082
Epoch:[ 132 6 ] loss: 0.3923591077327728 2022-06-30 21:42:39.675755
Epoch:[ 132 7 ] loss: 0.39156946539878845 2022-06-30 21:42:40.098517
Epoch:[ 132 8 ] loss: 0.3904314637184143 2022-06-30 21:42:40.526080
Epoch:[ 132 9 ] loss: 0.392880916595459 2022-06-30 21:42:40.952899
Epoch:[ 132 10 ] loss: 0.39119216799736023 2022-06-30 21:42:41.376752
Epoch:[ 132 11 ] loss: 0.3941284418106079 2022-06-30 21:42:41.799789
Epoch:[ 132 12 ] loss: 0.3925894498825073 2022-06-30 21:42:42.229532
Epoch:[ 132 13 ] loss: 0.39185968041419983 2022-06-30 21:42:42.652789
Epoch:[ 132 14 ] loss: 0.391433984041214 2022-06-30 21:42:43.074298
Epoch:[ 132 15 ] loss: 0.39410653710365295 2022-06-30 21:42:43.496281
Epoch:[ 132 16 ] loss: 0.3947147727012634 2022-06-30 21:42:48.609603
Epoch:[ 132 17 ] loss: 0.39157918095588684 2022-06-30 21:42:49.033261
Epoch:[ 132 18 ] loss: 0.39423105120658875 2022-06-30 21:42:49.460662
Epoch:[ 132 19 ] loss: 0.3925267457962036 2022-06-30 21:42:49.884768
Training_Epoch:[ 132 ] Training_loss: 0.3922949403524399 2022-06-30 21:42:49.885460
learning rate:  0.00027487790694400024
netparams have been saved once 132
val: 1 0.46585285663604736
val: 2 0.47880229353904724
val: 3 0.46948421001434326
val: 4 0.46498820185661316
val: 5 0.46984681487083435
val: 6 0.4620859920978546
val: 7 0.4501142203807831
val: 8 0.46614399552345276
val: 9 0.4604726731777191
val: 10 0.4601902663707733
val: 11 0.4598637819290161
val: 12 0.469356894493103
val: 13 0.4633125364780426
val: 14 0.4719657599925995
val: 15 0.46433308720588684
val: 16 0.47511494159698486
val: 17 0.472249299287796
val: 18 0.4725814461708069
val: 19 0.46281009912490845
val: 20 0.4703001379966736
val_Epoch:[ 132 ] val_loss: 0.4664934754371643 2022-06-30 21:42:53.331155
start training 2022-06-30 21:42:53.429967
Epoch:[ 133 0 ] loss: 0.39118441939353943 2022-06-30 21:43:07.934661
Epoch:[ 133 1 ] loss: 0.3892630636692047 2022-06-30 21:43:08.357601
Epoch:[ 133 2 ] loss: 0.3917294442653656 2022-06-30 21:43:08.784478
Epoch:[ 133 3 ] loss: 0.391262024641037 2022-06-30 21:43:09.213267
Epoch:[ 133 4 ] loss: 0.39084067940711975 2022-06-30 21:43:09.643855
Epoch:[ 133 5 ] loss: 0.3912138044834137 2022-06-30 21:43:10.074236
Epoch:[ 133 6 ] loss: 0.3931386172771454 2022-06-30 21:43:10.496524
Epoch:[ 133 7 ] loss: 0.38918536901474 2022-06-30 21:43:10.919742
Epoch:[ 133 8 ] loss: 0.39150306582450867 2022-06-30 21:43:11.341154
Epoch:[ 133 9 ] loss: 0.39203333854675293 2022-06-30 21:43:11.763320
Epoch:[ 133 10 ] loss: 0.39177167415618896 2022-06-30 21:43:12.185114
Epoch:[ 133 11 ] loss: 0.3911227583885193 2022-06-30 21:43:12.609747
Epoch:[ 133 12 ] loss: 0.39055824279785156 2022-06-30 21:43:13.033418
Epoch:[ 133 13 ] loss: 0.3911671042442322 2022-06-30 21:43:13.456194
Epoch:[ 133 14 ] loss: 0.3912246525287628 2022-06-30 21:43:13.913354
Epoch:[ 133 15 ] loss: 0.3945856988430023 2022-06-30 21:43:14.403814
Epoch:[ 133 16 ] loss: 0.3930882513523102 2022-06-30 21:43:19.325950
Epoch:[ 133 17 ] loss: 0.39169955253601074 2022-06-30 21:43:19.746940
Epoch:[ 133 18 ] loss: 0.39603787660598755 2022-06-30 21:43:20.180485
Epoch:[ 133 19 ] loss: 0.390103280544281 2022-06-30 21:43:20.607169
Training_Epoch:[ 133 ] Training_loss: 0.3916356459259987 2022-06-30 21:43:20.607861
learning rate:  0.00027487790694400024
val: 1 0.463778018951416
val: 2 0.45784950256347656
val: 3 0.4764556884765625
val: 4 0.47877395153045654
val: 5 0.47149983048439026
val: 6 0.4685044586658478
val: 7 0.4703248143196106
val: 8 0.4602755010128021
val: 9 0.46775302290916443
val: 10 0.457546591758728
val: 11 0.473322331905365
val: 12 0.45144331455230713
val: 13 0.46793127059936523
val: 14 0.47137710452079773
val: 15 0.4542413353919983
val: 16 0.46030834317207336
val: 17 0.4680755138397217
val: 18 0.45956698060035706
val: 19 0.46154698729515076
val: 20 0.47959110140800476
val_Epoch:[ 133 ] val_loss: 0.4660082831978798 2022-06-30 21:43:23.969503
start training 2022-06-30 21:43:24.067159
Epoch:[ 134 0 ] loss: 0.39109018445014954 2022-06-30 21:43:38.715319
Epoch:[ 134 1 ] loss: 0.3901662528514862 2022-06-30 21:43:39.135635
Epoch:[ 134 2 ] loss: 0.3912786543369293 2022-06-30 21:43:39.557681
Epoch:[ 134 3 ] loss: 0.3915891647338867 2022-06-30 21:43:39.980021
Epoch:[ 134 4 ] loss: 0.3915407657623291 2022-06-30 21:43:40.405113
Epoch:[ 134 5 ] loss: 0.39046043157577515 2022-06-30 21:43:40.832564
Epoch:[ 134 6 ] loss: 0.39124053716659546 2022-06-30 21:43:41.260857
Epoch:[ 134 7 ] loss: 0.38902759552001953 2022-06-30 21:43:41.687013
Epoch:[ 134 8 ] loss: 0.39103788137435913 2022-06-30 21:43:42.108831
Epoch:[ 134 9 ] loss: 0.3921891152858734 2022-06-30 21:43:42.530979
Epoch:[ 134 10 ] loss: 0.38856786489486694 2022-06-30 21:43:42.951571
Epoch:[ 134 11 ] loss: 0.3892441391944885 2022-06-30 21:43:43.374660
Epoch:[ 134 12 ] loss: 0.3901022970676422 2022-06-30 21:43:43.803133
Epoch:[ 134 13 ] loss: 0.3929344117641449 2022-06-30 21:43:44.236025
Epoch:[ 134 14 ] loss: 0.3918551206588745 2022-06-30 21:43:44.662639
Epoch:[ 134 15 ] loss: 0.39097025990486145 2022-06-30 21:43:45.084063
Epoch:[ 134 16 ] loss: 0.3934202194213867 2022-06-30 21:43:50.707224
Epoch:[ 134 17 ] loss: 0.39168232679367065 2022-06-30 21:43:51.129528
Epoch:[ 134 18 ] loss: 0.3912111222743988 2022-06-30 21:43:51.555155
Epoch:[ 134 19 ] loss: 0.39339500665664673 2022-06-30 21:43:51.979911
Training_Epoch:[ 134 ] Training_loss: 0.39115016758441923 2022-06-30 21:43:51.980586
learning rate:  0.00027487790694400024
netparams have been saved once 134
val: 1 0.4687555730342865
val: 2 0.4632001519203186
val: 3 0.4715282917022705
val: 4 0.4731931984424591
val: 5 0.4670139253139496
val: 6 0.47581809759140015
val: 7 0.47142115235328674
val: 8 0.46126505732536316
val: 9 0.47614312171936035
val: 10 0.48229342699050903
val: 11 0.47188201546669006
val: 12 0.47305017709732056
val: 13 0.46539735794067383
val: 14 0.4826914966106415
val: 15 0.46317794919013977
val: 16 0.46709343791007996
val: 17 0.46956226229667664
val: 18 0.47511032223701477
val: 19 0.45889219641685486
val: 20 0.46762028336524963
val_Epoch:[ 134 ] val_loss: 0.47025547474622725 2022-06-30 21:43:55.378090
start training 2022-06-30 21:43:55.478213
Epoch:[ 135 0 ] loss: 0.3909389078617096 2022-06-30 21:44:09.940644
Epoch:[ 135 1 ] loss: 0.3905241787433624 2022-06-30 21:44:10.360442
Epoch:[ 135 2 ] loss: 0.39285731315612793 2022-06-30 21:44:10.778351
Epoch:[ 135 3 ] loss: 0.39031359553337097 2022-06-30 21:44:11.200988
Epoch:[ 135 4 ] loss: 0.39227864146232605 2022-06-30 21:44:11.618825
Epoch:[ 135 5 ] loss: 0.39140400290489197 2022-06-30 21:44:12.042736
Epoch:[ 135 6 ] loss: 0.3918183743953705 2022-06-30 21:44:12.471176
Epoch:[ 135 7 ] loss: 0.3912191092967987 2022-06-30 21:44:12.891730
Epoch:[ 135 8 ] loss: 0.3899441063404083 2022-06-30 21:44:13.310807
Epoch:[ 135 9 ] loss: 0.3917292356491089 2022-06-30 21:44:13.728277
Epoch:[ 135 10 ] loss: 0.3908780813217163 2022-06-30 21:44:14.146417
Epoch:[ 135 11 ] loss: 0.39480891823768616 2022-06-30 21:44:14.566841
Epoch:[ 135 12 ] loss: 0.3923874795436859 2022-06-30 21:44:14.985366
Epoch:[ 135 13 ] loss: 0.389615535736084 2022-06-30 21:44:15.411111
Epoch:[ 135 14 ] loss: 0.38974228501319885 2022-06-30 21:44:15.837449
Epoch:[ 135 15 ] loss: 0.3901422917842865 2022-06-30 21:44:16.264968
Epoch:[ 135 16 ] loss: 0.391180157661438 2022-06-30 21:44:21.237754
Epoch:[ 135 17 ] loss: 0.39047473669052124 2022-06-30 21:44:21.656454
Epoch:[ 135 18 ] loss: 0.3912326693534851 2022-06-30 21:44:22.076858
Epoch:[ 135 19 ] loss: 0.3952658772468567 2022-06-30 21:44:22.506917
Training_Epoch:[ 135 ] Training_loss: 0.3914377748966217 2022-06-30 21:44:22.507585
learning rate:  0.00027487790694400024
val: 1 0.4837757349014282
val: 2 0.47307515144348145
val: 3 0.46468353271484375
val: 4 0.4537220299243927
val: 5 0.44702741503715515
val: 6 0.4559797942638397
val: 7 0.4685515761375427
val: 8 0.47593313455581665
val: 9 0.46070367097854614
val: 10 0.4729502201080322
val: 11 0.4646357595920563
val: 12 0.46197178959846497
val: 13 0.47123026847839355
val: 14 0.47584739327430725
val: 15 0.47194594144821167
val: 16 0.45868274569511414
val: 17 0.47208768129348755
val: 18 0.46808895468711853
val: 19 0.45248743891716003
val: 20 0.47289565205574036
val_Epoch:[ 135 ] val_loss: 0.46631379425525665 2022-06-30 21:44:25.893514
start training 2022-06-30 21:44:25.994717
Epoch:[ 136 0 ] loss: 0.38940858840942383 2022-06-30 21:44:40.544422
Epoch:[ 136 1 ] loss: 0.3887460231781006 2022-06-30 21:44:40.970219
Epoch:[ 136 2 ] loss: 0.39022567868232727 2022-06-30 21:44:41.388222
Epoch:[ 136 3 ] loss: 0.39246687293052673 2022-06-30 21:44:41.807580
Epoch:[ 136 4 ] loss: 0.39174315333366394 2022-06-30 21:44:42.225876
Epoch:[ 136 5 ] loss: 0.3904688060283661 2022-06-30 21:44:42.649869
Epoch:[ 136 6 ] loss: 0.38996022939682007 2022-06-30 21:44:43.067575
Epoch:[ 136 7 ] loss: 0.3918651044368744 2022-06-30 21:44:43.494880
Epoch:[ 136 8 ] loss: 0.3887932598590851 2022-06-30 21:44:43.914437
Epoch:[ 136 9 ] loss: 0.3916369676589966 2022-06-30 21:44:44.333069
Epoch:[ 136 10 ] loss: 0.3904051184654236 2022-06-30 21:44:44.750844
Epoch:[ 136 11 ] loss: 0.3920782208442688 2022-06-30 21:44:45.177278
Epoch:[ 136 12 ] loss: 0.39227426052093506 2022-06-30 21:44:45.595242
Epoch:[ 136 13 ] loss: 0.39305052161216736 2022-06-30 21:44:46.031531
Epoch:[ 136 14 ] loss: 0.39133408665657043 2022-06-30 21:44:46.520747
Epoch:[ 136 15 ] loss: 0.39109134674072266 2022-06-30 21:44:46.939644
Epoch:[ 136 16 ] loss: 0.39307549595832825 2022-06-30 21:44:51.732073
Epoch:[ 136 17 ] loss: 0.3943188786506653 2022-06-30 21:44:52.150578
Epoch:[ 136 18 ] loss: 0.3930763900279999 2022-06-30 21:44:52.578373
Epoch:[ 136 19 ] loss: 0.3940325081348419 2022-06-30 21:44:53.000831
Training_Epoch:[ 136 ] Training_loss: 0.3915025755763054 2022-06-30 21:44:53.001467
learning rate:  0.00027487790694400024
netparams have been saved once 136
val: 1 0.4737478494644165
val: 2 0.4563935697078705
val: 3 0.4652126133441925
val: 4 0.4752635061740875
val: 5 0.4747866094112396
val: 6 0.4601884186267853
val: 7 0.46004942059516907
val: 8 0.46556568145751953
val: 9 0.4614483118057251
val: 10 0.4547750949859619
val: 11 0.4580974280834198
val: 12 0.44814497232437134
val: 13 0.4781439006328583
val: 14 0.45728397369384766
val: 15 0.48476341366767883
val: 16 0.4629397988319397
val: 17 0.4909067153930664
val: 18 0.4699290990829468
val: 19 0.4629559814929962
val: 20 0.4725192189216614
val_Epoch:[ 136 ] val_loss: 0.4666557788848877 2022-06-30 21:44:56.414199
start training 2022-06-30 21:44:56.512615
Epoch:[ 137 0 ] loss: 0.39153406023979187 2022-06-30 21:45:11.120957
Epoch:[ 137 1 ] loss: 0.3911205232143402 2022-06-30 21:45:11.545109
Epoch:[ 137 2 ] loss: 0.3902265727519989 2022-06-30 21:45:11.964503
Epoch:[ 137 3 ] loss: 0.3921082019805908 2022-06-30 21:45:12.389753
Epoch:[ 137 4 ] loss: 0.38977277278900146 2022-06-30 21:45:12.806341
Epoch:[ 137 5 ] loss: 0.394386351108551 2022-06-30 21:45:13.223672
Epoch:[ 137 6 ] loss: 0.3911471664905548 2022-06-30 21:45:13.639721
Epoch:[ 137 7 ] loss: 0.39308133721351624 2022-06-30 21:45:14.057618
Epoch:[ 137 8 ] loss: 0.39114463329315186 2022-06-30 21:45:14.476571
Epoch:[ 137 9 ] loss: 0.39147570729255676 2022-06-30 21:45:14.902009
Epoch:[ 137 10 ] loss: 0.3900429308414459 2022-06-30 21:45:15.319772
Epoch:[ 137 11 ] loss: 0.39293673634529114 2022-06-30 21:45:15.781068
Epoch:[ 137 12 ] loss: 0.3909478783607483 2022-06-30 21:45:16.261470
Epoch:[ 137 13 ] loss: 0.3919960558414459 2022-06-30 21:45:16.678119
Epoch:[ 137 14 ] loss: 0.39174580574035645 2022-06-30 21:45:17.095110
Epoch:[ 137 15 ] loss: 0.3910411298274994 2022-06-30 21:45:17.515057
Epoch:[ 137 16 ] loss: 0.39079639315605164 2022-06-30 21:45:22.494964
Epoch:[ 137 17 ] loss: 0.38961610198020935 2022-06-30 21:45:22.914895
Epoch:[ 137 18 ] loss: 0.3907470405101776 2022-06-30 21:45:23.333584
Epoch:[ 137 19 ] loss: 0.3915703594684601 2022-06-30 21:45:23.751968
Training_Epoch:[ 137 ] Training_loss: 0.391371887922287 2022-06-30 21:45:23.752692
learning rate:  0.00027487790694400024
val: 1 0.4566093683242798
val: 2 0.4751022756099701
val: 3 0.46438655257225037
val: 4 0.47582337260246277
val: 5 0.4624336063861847
val: 6 0.4612376093864441
val: 7 0.46621444821357727
val: 8 0.4588848054409027
val: 9 0.47593358159065247
val: 10 0.47833451628685
val: 11 0.4711744487285614
val: 12 0.4531671106815338
val: 13 0.4618029296398163
val: 14 0.4740903675556183
val: 15 0.46722978353500366
val: 16 0.46850571036338806
val: 17 0.469289094209671
val: 18 0.4742196202278137
val: 19 0.471345454454422
val: 20 0.4699249267578125
val_Epoch:[ 137 ] val_loss: 0.46778547912836077 2022-06-30 21:45:27.052361
start training 2022-06-30 21:45:27.153507
Epoch:[ 138 0 ] loss: 0.3906753659248352 2022-06-30 21:45:41.286502
Epoch:[ 138 1 ] loss: 0.39249730110168457 2022-06-30 21:45:41.809011
Epoch:[ 138 2 ] loss: 0.39152348041534424 2022-06-30 21:45:42.228480
Epoch:[ 138 3 ] loss: 0.39214953780174255 2022-06-30 21:45:42.647270
Epoch:[ 138 4 ] loss: 0.389835000038147 2022-06-30 21:45:43.065520
Epoch:[ 138 5 ] loss: 0.3886769115924835 2022-06-30 21:45:43.489928
Epoch:[ 138 6 ] loss: 0.39164191484451294 2022-06-30 21:45:43.906949
Epoch:[ 138 7 ] loss: 0.3909810781478882 2022-06-30 21:45:44.324411
Epoch:[ 138 8 ] loss: 0.39039933681488037 2022-06-30 21:45:44.747181
Epoch:[ 138 9 ] loss: 0.389858603477478 2022-06-30 21:45:45.166991
Epoch:[ 138 10 ] loss: 0.3896229565143585 2022-06-30 21:45:45.594752
Epoch:[ 138 11 ] loss: 0.39156416058540344 2022-06-30 21:45:46.081798
Epoch:[ 138 12 ] loss: 0.38976216316223145 2022-06-30 21:45:46.507283
Epoch:[ 138 13 ] loss: 0.391537070274353 2022-06-30 21:45:46.923893
Epoch:[ 138 14 ] loss: 0.3898545503616333 2022-06-30 21:45:47.342808
Epoch:[ 138 15 ] loss: 0.38853487372398376 2022-06-30 21:45:47.760600
Epoch:[ 138 16 ] loss: 0.39084288477897644 2022-06-30 21:45:52.782740
Epoch:[ 138 17 ] loss: 0.39218223094940186 2022-06-30 21:45:53.210339
Epoch:[ 138 18 ] loss: 0.3892368674278259 2022-06-30 21:45:53.632422
Epoch:[ 138 19 ] loss: 0.39286449551582336 2022-06-30 21:45:54.050150
Training_Epoch:[ 138 ] Training_loss: 0.3907120391726494 2022-06-30 21:45:54.050779
learning rate:  0.00027487790694400024
netparams have been saved once 138
val: 1 0.46839845180511475
val: 2 0.46212688088417053
val: 3 0.47672802209854126
val: 4 0.47035762667655945
val: 5 0.47273656725883484
val: 6 0.4666076600551605
val: 7 0.4842998683452606
val: 8 0.46769681572914124
val: 9 0.4601961374282837
val: 10 0.47503167390823364
val: 11 0.49062344431877136
val: 12 0.4657762944698334
val: 13 0.46737590432167053
val: 14 0.4747164845466614
val: 15 0.477599561214447
val: 16 0.46772074699401855
val: 17 0.46220076084136963
val: 18 0.46589502692222595
val: 19 0.47260692715644836
val: 20 0.460659384727478
val_Epoch:[ 138 ] val_loss: 0.4704677119851112 2022-06-30 21:45:57.436174
start training 2022-06-30 21:45:57.543720
Epoch:[ 139 0 ] loss: 0.38799527287483215 2022-06-30 21:46:12.204589
Epoch:[ 139 1 ] loss: 0.38937515020370483 2022-06-30 21:46:12.628244
Epoch:[ 139 2 ] loss: 0.39385876059532166 2022-06-30 21:46:13.051452
Epoch:[ 139 3 ] loss: 0.38912463188171387 2022-06-30 21:46:13.471836
Epoch:[ 139 4 ] loss: 0.39184489846229553 2022-06-30 21:46:13.890846
Epoch:[ 139 5 ] loss: 0.39213523268699646 2022-06-30 21:46:14.309848
Epoch:[ 139 6 ] loss: 0.3925793766975403 2022-06-30 21:46:14.736026
Epoch:[ 139 7 ] loss: 0.38977810740470886 2022-06-30 21:46:15.162052
Epoch:[ 139 8 ] loss: 0.39181143045425415 2022-06-30 21:46:15.578974
Epoch:[ 139 9 ] loss: 0.3898674249649048 2022-06-30 21:46:15.996378
Epoch:[ 139 10 ] loss: 0.3909391760826111 2022-06-30 21:46:16.415869
Epoch:[ 139 11 ] loss: 0.3933992385864258 2022-06-30 21:46:16.837882
Epoch:[ 139 12 ] loss: 0.39469075202941895 2022-06-30 21:46:17.320526
Epoch:[ 139 13 ] loss: 0.3900177478790283 2022-06-30 21:46:17.739020
Epoch:[ 139 14 ] loss: 0.39076974987983704 2022-06-30 21:46:18.155893
Epoch:[ 139 15 ] loss: 0.3911467492580414 2022-06-30 21:46:18.572556
Epoch:[ 139 16 ] loss: 0.39056000113487244 2022-06-30 21:46:23.819714
Epoch:[ 139 17 ] loss: 0.390608012676239 2022-06-30 21:46:24.239151
Epoch:[ 139 18 ] loss: 0.39005884528160095 2022-06-30 21:46:24.677796
Epoch:[ 139 19 ] loss: 0.3925546407699585 2022-06-30 21:46:25.098998
Training_Epoch:[ 139 ] Training_loss: 0.3911557599902153 2022-06-30 21:46:25.099694
learning rate:  0.00027487790694400024
val: 1 0.4716189205646515
val: 2 0.46725893020629883
val: 3 0.4569789171218872
val: 4 0.4573478400707245
val: 5 0.4713485538959503
val: 6 0.4768235683441162
val: 7 0.47093307971954346
val: 8 0.4570951461791992
val: 9 0.47121378779411316
val: 10 0.4669135510921478
val: 11 0.4654483497142792
val: 12 0.4706483483314514
val: 13 0.4706151783466339
val: 14 0.46586257219314575
val: 15 0.463410347700119
val: 16 0.4759041965007782
val: 17 0.48207515478134155
val: 18 0.47549623250961304
val: 19 0.46933314204216003
val: 20 0.4729033410549164
val_Epoch:[ 139 ] val_loss: 0.4689614579081535 2022-06-30 21:46:28.484748
start training 2022-06-30 21:46:28.585765
Epoch:[ 140 0 ] loss: 0.390314519405365 2022-06-30 21:46:43.237369
Epoch:[ 140 1 ] loss: 0.3883485198020935 2022-06-30 21:46:43.653983
Epoch:[ 140 2 ] loss: 0.3913799524307251 2022-06-30 21:46:44.069609
Epoch:[ 140 3 ] loss: 0.3936799168586731 2022-06-30 21:46:44.486432
Epoch:[ 140 4 ] loss: 0.3889012634754181 2022-06-30 21:46:44.911454
Epoch:[ 140 5 ] loss: 0.3901797831058502 2022-06-30 21:46:45.329740
Epoch:[ 140 6 ] loss: 0.39009660482406616 2022-06-30 21:46:45.749018
Epoch:[ 140 7 ] loss: 0.3906596004962921 2022-06-30 21:46:46.174501
Epoch:[ 140 8 ] loss: 0.3889492154121399 2022-06-30 21:46:46.597368
Epoch:[ 140 9 ] loss: 0.3911588191986084 2022-06-30 21:46:47.015769
Epoch:[ 140 10 ] loss: 0.3898893892765045 2022-06-30 21:46:47.433873
Epoch:[ 140 11 ] loss: 0.3912317454814911 2022-06-30 21:46:47.853201
Epoch:[ 140 12 ] loss: 0.3923265039920807 2022-06-30 21:46:48.271964
Epoch:[ 140 13 ] loss: 0.3903147876262665 2022-06-30 21:46:48.697050
Epoch:[ 140 14 ] loss: 0.3932461440563202 2022-06-30 21:46:49.113200
Epoch:[ 140 15 ] loss: 0.39012396335601807 2022-06-30 21:46:49.534532
Epoch:[ 140 16 ] loss: 0.3914426267147064 2022-06-30 21:46:54.695269
Epoch:[ 140 17 ] loss: 0.3900296688079834 2022-06-30 21:46:55.109367
Epoch:[ 140 18 ] loss: 0.38921812176704407 2022-06-30 21:46:55.535721
Epoch:[ 140 19 ] loss: 0.39070093631744385 2022-06-30 21:46:55.966884
Training_Epoch:[ 140 ] Training_loss: 0.3906096041202545 2022-06-30 21:46:55.967541
learning rate:  0.00027487790694400024
netparams have been saved once 140
val: 1 0.47567710280418396
val: 2 0.46692991256713867
val: 3 0.4768649935722351
val: 4 0.46466609835624695
val: 5 0.4616587162017822
val: 6 0.4732159674167633
val: 7 0.4721672832965851
val: 8 0.46149060130119324
val: 9 0.4600066542625427
val: 10 0.47418612241744995
val: 11 0.47044309973716736
val: 12 0.46960097551345825
val: 13 0.4608497619628906
val: 14 0.47887298464775085
val: 15 0.4634944796562195
val: 16 0.47544053196907043
val: 17 0.4860232472419739
val: 18 0.47560301423072815
val: 19 0.47604209184646606
val: 20 0.46212854981422424
val_Epoch:[ 140 ] val_loss: 0.47026810944080355 2022-06-30 21:46:59.357719
start training 2022-06-30 21:46:59.457765
Epoch:[ 141 0 ] loss: 0.3879569172859192 2022-06-30 21:47:14.004603
Epoch:[ 141 1 ] loss: 0.38970738649368286 2022-06-30 21:47:14.427862
Epoch:[ 141 2 ] loss: 0.38900622725486755 2022-06-30 21:47:14.849987
Epoch:[ 141 3 ] loss: 0.392534464597702 2022-06-30 21:47:15.267173
Epoch:[ 141 4 ] loss: 0.39181452989578247 2022-06-30 21:47:15.690469
Epoch:[ 141 5 ] loss: 0.3887386620044708 2022-06-30 21:47:16.109523
Epoch:[ 141 6 ] loss: 0.390190064907074 2022-06-30 21:47:16.527163
Epoch:[ 141 7 ] loss: 0.38965773582458496 2022-06-30 21:47:16.947966
Epoch:[ 141 8 ] loss: 0.38926735520362854 2022-06-30 21:47:17.365335
Epoch:[ 141 9 ] loss: 0.38971444964408875 2022-06-30 21:47:17.789086
Epoch:[ 141 10 ] loss: 0.3897082805633545 2022-06-30 21:47:18.204971
Epoch:[ 141 11 ] loss: 0.388506680727005 2022-06-30 21:47:18.622463
Epoch:[ 141 12 ] loss: 0.39021360874176025 2022-06-30 21:47:19.041046
Epoch:[ 141 13 ] loss: 0.38935360312461853 2022-06-30 21:47:19.459822
Epoch:[ 141 14 ] loss: 0.3907875418663025 2022-06-30 21:47:19.881360
Epoch:[ 141 15 ] loss: 0.3888351321220398 2022-06-30 21:47:20.366888
Epoch:[ 141 16 ] loss: 0.3900991380214691 2022-06-30 21:47:25.677272
Epoch:[ 141 17 ] loss: 0.3894720673561096 2022-06-30 21:47:26.094507
Epoch:[ 141 18 ] loss: 0.3904061019420624 2022-06-30 21:47:26.520391
Epoch:[ 141 19 ] loss: 0.3889061212539673 2022-06-30 21:47:26.939369
Training_Epoch:[ 141 ] Training_loss: 0.3897438034415245 2022-06-30 21:47:26.940058
learning rate:  0.0002199023255552002
val: 1 0.47579383850097656
val: 2 0.48187801241874695
val: 3 0.4658384323120117
val: 4 0.4667704999446869
val: 5 0.4765498638153076
val: 6 0.4605439603328705
val: 7 0.4639884829521179
val: 8 0.4610980749130249
val: 9 0.4727417230606079
val: 10 0.4714447855949402
val: 11 0.46233272552490234
val: 12 0.4727838933467865
val: 13 0.4672744870185852
val: 14 0.47160273790359497
val: 15 0.47628459334373474
val: 16 0.4665352702140808
val: 17 0.48053786158561707
val: 18 0.47407805919647217
val: 19 0.46691441535949707
val: 20 0.46969613432884216
val_Epoch:[ 141 ] val_loss: 0.4702343925833702 2022-06-30 21:47:30.262684
start training 2022-06-30 21:47:30.360890
Epoch:[ 142 0 ] loss: 0.3873172700405121 2022-06-30 21:47:44.688535
Epoch:[ 142 1 ] loss: 0.38861504197120667 2022-06-30 21:47:45.114378
Epoch:[ 142 2 ] loss: 0.38803184032440186 2022-06-30 21:47:45.533853
Epoch:[ 142 3 ] loss: 0.38794535398483276 2022-06-30 21:47:45.952424
Epoch:[ 142 4 ] loss: 0.38908621668815613 2022-06-30 21:47:46.369671
Epoch:[ 142 5 ] loss: 0.3896782398223877 2022-06-30 21:47:46.787182
Epoch:[ 142 6 ] loss: 0.38950115442276 2022-06-30 21:47:47.205261
Epoch:[ 142 7 ] loss: 0.388693630695343 2022-06-30 21:47:47.633327
Epoch:[ 142 8 ] loss: 0.387210875749588 2022-06-30 21:47:48.057639
Epoch:[ 142 9 ] loss: 0.3878076374530792 2022-06-30 21:47:48.480986
Epoch:[ 142 10 ] loss: 0.39156287908554077 2022-06-30 21:47:48.897453
Epoch:[ 142 11 ] loss: 0.3903499245643616 2022-06-30 21:47:49.317221
Epoch:[ 142 12 ] loss: 0.39272603392601013 2022-06-30 21:47:49.734569
Epoch:[ 142 13 ] loss: 0.3874567449092865 2022-06-30 21:47:50.197622
Epoch:[ 142 14 ] loss: 0.38768237829208374 2022-06-30 21:47:50.683042
Epoch:[ 142 15 ] loss: 0.3901709020137787 2022-06-30 21:47:51.101887
Epoch:[ 142 16 ] loss: 0.38889768719673157 2022-06-30 21:47:56.674301
Epoch:[ 142 17 ] loss: 0.39020606875419617 2022-06-30 21:47:57.092463
Epoch:[ 142 18 ] loss: 0.3879441022872925 2022-06-30 21:47:57.525312
Epoch:[ 142 19 ] loss: 0.3897764980792999 2022-06-30 21:47:57.945281
Training_Epoch:[ 142 ] Training_loss: 0.38903302401304246 2022-06-30 21:47:57.945970
learning rate:  0.0002199023255552002
netparams have been saved once 142
val: 1 0.47671547532081604
val: 2 0.4659772515296936
val: 3 0.4614260792732239
val: 4 0.4721298813819885
val: 5 0.461942195892334
val: 6 0.4693240523338318
val: 7 0.4725467264652252
val: 8 0.4744352400302887
val: 9 0.4738805890083313
val: 10 0.47358331084251404
val: 11 0.47619232535362244
val: 12 0.46511560678482056
val: 13 0.47362518310546875
val: 14 0.484511137008667
val: 15 0.46007096767425537
val: 16 0.47257715463638306
val: 17 0.48163077235221863
val: 18 0.47968924045562744
val: 19 0.45810481905937195
val: 20 0.46932053565979004
val_Epoch:[ 142 ] val_loss: 0.4711399272084236 2022-06-30 21:48:01.299912
start training 2022-06-30 21:48:01.398362
Epoch:[ 143 0 ] loss: 0.388557493686676 2022-06-30 21:48:16.326989
Epoch:[ 143 1 ] loss: 0.38803625106811523 2022-06-30 21:48:16.748357
Epoch:[ 143 2 ] loss: 0.38941627740859985 2022-06-30 21:48:17.170118
Epoch:[ 143 3 ] loss: 0.388008713722229 2022-06-30 21:48:17.590470
Epoch:[ 143 4 ] loss: 0.38847631216049194 2022-06-30 21:48:18.010910
Epoch:[ 143 5 ] loss: 0.38844501972198486 2022-06-30 21:48:18.431981
Epoch:[ 143 6 ] loss: 0.38820409774780273 2022-06-30 21:48:18.856267
Epoch:[ 143 7 ] loss: 0.3877544701099396 2022-06-30 21:48:19.284108
Epoch:[ 143 8 ] loss: 0.3895586431026459 2022-06-30 21:48:19.705033
Epoch:[ 143 9 ] loss: 0.38834479451179504 2022-06-30 21:48:20.127351
Epoch:[ 143 10 ] loss: 0.3898765444755554 2022-06-30 21:48:20.547613
Epoch:[ 143 11 ] loss: 0.38924670219421387 2022-06-30 21:48:21.034397
Epoch:[ 143 12 ] loss: 0.38865548372268677 2022-06-30 21:48:21.459863
Epoch:[ 143 13 ] loss: 0.3899567723274231 2022-06-30 21:48:21.884213
Epoch:[ 143 14 ] loss: 0.39138951897621155 2022-06-30 21:48:22.303715
Epoch:[ 143 15 ] loss: 0.39078885316848755 2022-06-30 21:48:22.733774
Epoch:[ 143 16 ] loss: 0.3891397714614868 2022-06-30 21:48:27.786412
Epoch:[ 143 17 ] loss: 0.3901200294494629 2022-06-30 21:48:28.203358
Epoch:[ 143 18 ] loss: 0.3878076672554016 2022-06-30 21:48:28.621297
Epoch:[ 143 19 ] loss: 0.3883730471134186 2022-06-30 21:48:29.037729
Training_Epoch:[ 143 ] Training_loss: 0.38900782316923144 2022-06-30 21:48:29.038411
learning rate:  0.0002199023255552002
val: 1 0.47184520959854126
val: 2 0.48307088017463684
val: 3 0.48271602392196655
val: 4 0.47079819440841675
val: 5 0.46300190687179565
val: 6 0.4562940001487732
val: 7 0.45831260085105896
val: 8 0.45874807238578796
val: 9 0.4645232856273651
val: 10 0.4603549838066101
val: 11 0.4736221432685852
val: 12 0.4786869287490845
val: 13 0.47675296664237976
val: 14 0.46664661169052124
val: 15 0.4730268120765686
val: 16 0.4773918688297272
val: 17 0.4570567309856415
val: 18 0.4683210849761963
val: 19 0.48660561442375183
val: 20 0.4766446053981781
val_Epoch:[ 143 ] val_loss: 0.4702210262417793 2022-06-30 21:48:32.436610
start training 2022-06-30 21:48:32.535918
Epoch:[ 144 0 ] loss: 0.3874775469303131 2022-06-30 21:48:46.588988
Epoch:[ 144 1 ] loss: 0.38871511816978455 2022-06-30 21:48:47.248884
Epoch:[ 144 2 ] loss: 0.38947778940200806 2022-06-30 21:48:47.668367
Epoch:[ 144 3 ] loss: 0.38552987575531006 2022-06-30 21:48:48.087962
Epoch:[ 144 4 ] loss: 0.3896620273590088 2022-06-30 21:48:48.504038
Epoch:[ 144 5 ] loss: 0.3867407739162445 2022-06-30 21:48:48.926937
Epoch:[ 144 6 ] loss: 0.3881804049015045 2022-06-30 21:48:49.343623
Epoch:[ 144 7 ] loss: 0.390036404132843 2022-06-30 21:48:49.766195
Epoch:[ 144 8 ] loss: 0.38960376381874084 2022-06-30 21:48:50.185517
Epoch:[ 144 9 ] loss: 0.3886953890323639 2022-06-30 21:48:50.609862
Epoch:[ 144 10 ] loss: 0.38946205377578735 2022-06-30 21:48:51.067618
Epoch:[ 144 11 ] loss: 0.38942623138427734 2022-06-30 21:48:51.552503
Epoch:[ 144 12 ] loss: 0.38651958107948303 2022-06-30 21:48:51.973594
Epoch:[ 144 13 ] loss: 0.39089542627334595 2022-06-30 21:48:52.395898
Epoch:[ 144 14 ] loss: 0.3887501358985901 2022-06-30 21:48:52.811666
Epoch:[ 144 15 ] loss: 0.3890591859817505 2022-06-30 21:48:53.232252
Epoch:[ 144 16 ] loss: 0.3890271484851837 2022-06-30 21:48:58.045455
Epoch:[ 144 17 ] loss: 0.38765770196914673 2022-06-30 21:48:58.678343
Epoch:[ 144 18 ] loss: 0.39144226908683777 2022-06-30 21:48:59.100594
Epoch:[ 144 19 ] loss: 0.38793638348579407 2022-06-30 21:48:59.519975
Training_Epoch:[ 144 ] Training_loss: 0.3887147605419159 2022-06-30 21:48:59.520569
learning rate:  0.0002199023255552002
netparams have been saved once 144
val: 1 0.4667573869228363
val: 2 0.47793295979499817
val: 3 0.45886221528053284
val: 4 0.4700409770011902
val: 5 0.47722959518432617
val: 6 0.46530163288116455
val: 7 0.458063542842865
val: 8 0.4675021171569824
val: 9 0.4725108742713928
val: 10 0.48636093735694885
val: 11 0.4766532778739929
val: 12 0.4599275588989258
val: 13 0.4875372052192688
val: 14 0.478631854057312
val: 15 0.47592130303382874
val: 16 0.47622036933898926
val: 17 0.47033312916755676
val: 18 0.45356252789497375
val: 19 0.47712305188179016
val: 20 0.4763467609882355
val_Epoch:[ 144 ] val_loss: 0.47164096385240556 2022-06-30 21:49:02.842610
start training 2022-06-30 21:49:02.942712
Epoch:[ 145 0 ] loss: 0.3902425765991211 2022-06-30 21:49:16.774847
Epoch:[ 145 1 ] loss: 0.38722723722457886 2022-06-30 21:49:17.956772
Epoch:[ 145 2 ] loss: 0.3873470425605774 2022-06-30 21:49:18.377734
Epoch:[ 145 3 ] loss: 0.388491690158844 2022-06-30 21:49:18.803270
Epoch:[ 145 4 ] loss: 0.38620972633361816 2022-06-30 21:49:19.227026
Epoch:[ 145 5 ] loss: 0.3869800269603729 2022-06-30 21:49:19.648465
Epoch:[ 145 6 ] loss: 0.38872280716896057 2022-06-30 21:49:20.072655
Epoch:[ 145 7 ] loss: 0.3879682421684265 2022-06-30 21:49:20.492861
Epoch:[ 145 8 ] loss: 0.38672691583633423 2022-06-30 21:49:20.913887
Epoch:[ 145 9 ] loss: 0.3897936940193176 2022-06-30 21:49:21.334243
Epoch:[ 145 10 ] loss: 0.389152854681015 2022-06-30 21:49:21.758656
Epoch:[ 145 11 ] loss: 0.38901421427726746 2022-06-30 21:49:22.185752
Epoch:[ 145 12 ] loss: 0.39064472913742065 2022-06-30 21:49:22.629863
Epoch:[ 145 13 ] loss: 0.39113637804985046 2022-06-30 21:49:23.115828
Epoch:[ 145 14 ] loss: 0.3902038633823395 2022-06-30 21:49:23.535930
Epoch:[ 145 15 ] loss: 0.3890572190284729 2022-06-30 21:49:23.954876
Epoch:[ 145 16 ] loss: 0.3886626958847046 2022-06-30 21:49:28.702082
Epoch:[ 145 17 ] loss: 0.3862161636352539 2022-06-30 21:49:29.913730
Epoch:[ 145 18 ] loss: 0.39054402709007263 2022-06-30 21:49:30.342065
Epoch:[ 145 19 ] loss: 0.39298397302627563 2022-06-30 21:49:30.768508
Training_Epoch:[ 145 ] Training_loss: 0.3888663038611412 2022-06-30 21:49:30.769304
learning rate:  0.0002199023255552002
val: 1 0.4751245081424713
val: 2 0.45722270011901855
val: 3 0.4878416359424591
val: 4 0.48138144612312317
val: 5 0.47589531540870667
val: 6 0.4647306799888611
val: 7 0.4746045768260956
val: 8 0.4733496308326721
val: 9 0.4737010598182678
val: 10 0.47427281737327576
val: 11 0.47655797004699707
val: 12 0.47372865676879883
val: 13 0.4740757942199707
val: 14 0.4749008119106293
val: 15 0.4896225929260254
val: 16 0.4567643702030182
val: 17 0.4606664478778839
val: 18 0.47297435998916626
val: 19 0.46131762862205505
val: 20 0.4719363749027252
val_Epoch:[ 145 ] val_loss: 0.47253346890211106 2022-06-30 21:49:34.178316
start training 2022-06-30 21:49:34.278804
Epoch:[ 146 0 ] loss: 0.389818012714386 2022-06-30 21:49:48.526509
Epoch:[ 146 1 ] loss: 0.3891902565956116 2022-06-30 21:49:48.967919
Epoch:[ 146 2 ] loss: 0.3871358335018158 2022-06-30 21:49:49.389943
Epoch:[ 146 3 ] loss: 0.38594701886177063 2022-06-30 21:49:49.809392
Epoch:[ 146 4 ] loss: 0.3872493803501129 2022-06-30 21:49:50.253202
Epoch:[ 146 5 ] loss: 0.38927629590034485 2022-06-30 21:49:50.677307
Epoch:[ 146 6 ] loss: 0.3897362947463989 2022-06-30 21:49:51.105311
Epoch:[ 146 7 ] loss: 0.3897789716720581 2022-06-30 21:49:51.527004
Epoch:[ 146 8 ] loss: 0.3871060907840729 2022-06-30 21:49:51.943856
Epoch:[ 146 9 ] loss: 0.3874029517173767 2022-06-30 21:49:52.362928
Epoch:[ 146 10 ] loss: 0.38769209384918213 2022-06-30 21:49:52.784667
Epoch:[ 146 11 ] loss: 0.38955140113830566 2022-06-30 21:49:53.212035
Epoch:[ 146 12 ] loss: 0.3874068856239319 2022-06-30 21:49:53.635932
Epoch:[ 146 13 ] loss: 0.38893601298332214 2022-06-30 21:49:54.059260
Epoch:[ 146 14 ] loss: 0.3910977244377136 2022-06-30 21:49:54.478836
Epoch:[ 146 15 ] loss: 0.38809940218925476 2022-06-30 21:49:54.895905
Epoch:[ 146 16 ] loss: 0.3902476727962494 2022-06-30 21:49:59.912338
Epoch:[ 146 17 ] loss: 0.3875294625759125 2022-06-30 21:50:00.332869
Epoch:[ 146 18 ] loss: 0.3896448016166687 2022-06-30 21:50:00.755028
Epoch:[ 146 19 ] loss: 0.38981521129608154 2022-06-30 21:50:01.177967
Training_Epoch:[ 146 ] Training_loss: 0.38863308876752856 2022-06-30 21:50:01.178770
learning rate:  0.0002199023255552002
netparams have been saved once 146
val: 1 0.45836684107780457
val: 2 0.4790048897266388
val: 3 0.47627174854278564
val: 4 0.47199317812919617
val: 5 0.4682331383228302
val: 6 0.46156659722328186
val: 7 0.46718183159828186
val: 8 0.4663807451725006
val: 9 0.45904412865638733
val: 10 0.4674893319606781
val: 11 0.4786725342273712
val: 12 0.4791468679904938
val: 13 0.45074591040611267
val: 14 0.4723204970359802
val: 15 0.48029381036758423
val: 16 0.47223976254463196
val: 17 0.47391608357429504
val: 18 0.46098554134368896
val: 19 0.4716285169124603
val: 20 0.47445181012153625
val_Epoch:[ 146 ] val_loss: 0.46949668824672697 2022-06-30 21:50:04.583069
start training 2022-06-30 21:50:04.683609
Epoch:[ 147 0 ] loss: 0.387727826833725 2022-06-30 21:50:19.718453
Epoch:[ 147 1 ] loss: 0.3874867260456085 2022-06-30 21:50:20.142649
Epoch:[ 147 2 ] loss: 0.38855496048927307 2022-06-30 21:50:20.561595
Epoch:[ 147 3 ] loss: 0.3901563882827759 2022-06-30 21:50:20.979436
Epoch:[ 147 4 ] loss: 0.38645875453948975 2022-06-30 21:50:21.399508
Epoch:[ 147 5 ] loss: 0.3878168761730194 2022-06-30 21:50:21.842943
Epoch:[ 147 6 ] loss: 0.38696128129959106 2022-06-30 21:50:22.268619
Epoch:[ 147 7 ] loss: 0.3883455991744995 2022-06-30 21:50:22.692686
Epoch:[ 147 8 ] loss: 0.3869898021221161 2022-06-30 21:50:23.110744
Epoch:[ 147 9 ] loss: 0.3890310823917389 2022-06-30 21:50:23.527677
Epoch:[ 147 10 ] loss: 0.3864017128944397 2022-06-30 21:50:23.950153
Epoch:[ 147 11 ] loss: 0.3884449601173401 2022-06-30 21:50:24.370324
Epoch:[ 147 12 ] loss: 0.38939476013183594 2022-06-30 21:50:24.790679
Epoch:[ 147 13 ] loss: 0.38951948285102844 2022-06-30 21:50:25.210590
Epoch:[ 147 14 ] loss: 0.38964226841926575 2022-06-30 21:50:25.636918
Epoch:[ 147 15 ] loss: 0.3903038799762726 2022-06-30 21:50:26.056991
Epoch:[ 147 16 ] loss: 0.38783466815948486 2022-06-30 21:50:31.152888
Epoch:[ 147 17 ] loss: 0.3890910744667053 2022-06-30 21:50:31.573652
Epoch:[ 147 18 ] loss: 0.39003023505210876 2022-06-30 21:50:32.001763
Epoch:[ 147 19 ] loss: 0.3899708390235901 2022-06-30 21:50:32.421061
Training_Epoch:[ 147 ] Training_loss: 0.3885081589221954 2022-06-30 21:50:32.421872
learning rate:  0.0002199023255552002
val: 1 0.4675101935863495
val: 2 0.47530436515808105
val: 3 0.4699714481830597
val: 4 0.46983540058135986
val: 5 0.4919554591178894
val: 6 0.46563392877578735
val: 7 0.49034953117370605
val: 8 0.48027148842811584
val: 9 0.4797309339046478
val: 10 0.4533534348011017
val: 11 0.459908127784729
val: 12 0.4702073633670807
val: 13 0.4688475728034973
val: 14 0.4546518921852112
val: 15 0.47061872482299805
val: 16 0.4824437201023102
val: 17 0.469744473695755
val: 18 0.48591452836990356
val: 19 0.4600755274295807
val: 20 0.46887344121932983
val_Epoch:[ 147 ] val_loss: 0.47176007777452467 2022-06-30 21:50:35.821733
start training 2022-06-30 21:50:35.921057
Epoch:[ 148 0 ] loss: 0.3855237066745758 2022-06-30 21:50:50.211762
Epoch:[ 148 1 ] loss: 0.3863578736782074 2022-06-30 21:50:50.670405
Epoch:[ 148 2 ] loss: 0.3895498514175415 2022-06-30 21:50:51.117836
Epoch:[ 148 3 ] loss: 0.39014238119125366 2022-06-30 21:50:51.558386
Epoch:[ 148 4 ] loss: 0.38892224431037903 2022-06-30 21:50:51.993936
Epoch:[ 148 5 ] loss: 0.38767218589782715 2022-06-30 21:50:52.427503
Epoch:[ 148 6 ] loss: 0.3910340666770935 2022-06-30 21:50:52.862762
Epoch:[ 148 7 ] loss: 0.3915289640426636 2022-06-30 21:50:53.300777
Epoch:[ 148 8 ] loss: 0.38737282156944275 2022-06-30 21:50:53.735229
Epoch:[ 148 9 ] loss: 0.3897826373577118 2022-06-30 21:50:54.171192
Epoch:[ 148 10 ] loss: 0.38629257678985596 2022-06-30 21:50:54.602789
Epoch:[ 148 11 ] loss: 0.3863106667995453 2022-06-30 21:50:55.035023
Epoch:[ 148 12 ] loss: 0.39044877886772156 2022-06-30 21:50:55.467801
Epoch:[ 148 13 ] loss: 0.3880704343318939 2022-06-30 21:50:55.899988
Epoch:[ 148 14 ] loss: 0.38909822702407837 2022-06-30 21:50:56.332870
Epoch:[ 148 15 ] loss: 0.3875073194503784 2022-06-30 21:50:56.764637
Epoch:[ 148 16 ] loss: 0.3880259394645691 2022-06-30 21:51:01.892292
Epoch:[ 148 17 ] loss: 0.3887510895729065 2022-06-30 21:51:02.320108
Epoch:[ 148 18 ] loss: 0.388937383890152 2022-06-30 21:51:02.752613
Epoch:[ 148 19 ] loss: 0.3870423436164856 2022-06-30 21:51:03.181584
Training_Epoch:[ 148 ] Training_loss: 0.38841857463121415 2022-06-30 21:51:03.182227
learning rate:  0.0002199023255552002
netparams have been saved once 148
val: 1 0.47244563698768616
val: 2 0.4721965491771698
val: 3 0.4775063395500183
val: 4 0.46674108505249023
val: 5 0.46655458211898804
val: 6 0.47537967562675476
val: 7 0.47676992416381836
val: 8 0.45649173855781555
val: 9 0.4675901234149933
val: 10 0.46383917331695557
val: 11 0.4724403917789459
val: 12 0.46076440811157227
val: 13 0.4723639488220215
val: 14 0.4766191840171814
val: 15 0.4861103296279907
val: 16 0.4788113832473755
val: 17 0.479850709438324
val: 18 0.45720040798187256
val: 19 0.46017253398895264
val: 20 0.4766615331172943
val_Epoch:[ 148 ] val_loss: 0.47082548290491105 2022-06-30 21:51:06.580119
start training 2022-06-30 21:51:06.682078
Epoch:[ 149 0 ] loss: 0.38730332255363464 2022-06-30 21:51:21.304569
Epoch:[ 149 1 ] loss: 0.3878075182437897 2022-06-30 21:51:21.735064
Epoch:[ 149 2 ] loss: 0.388853520154953 2022-06-30 21:51:22.166576
Epoch:[ 149 3 ] loss: 0.38835409283638 2022-06-30 21:51:22.593774
Epoch:[ 149 4 ] loss: 0.38491788506507874 2022-06-30 21:51:23.019730
Epoch:[ 149 5 ] loss: 0.3883102536201477 2022-06-30 21:51:23.451720
Epoch:[ 149 6 ] loss: 0.38782042264938354 2022-06-30 21:51:23.880027
Epoch:[ 149 7 ] loss: 0.3878419101238251 2022-06-30 21:51:24.308248
Epoch:[ 149 8 ] loss: 0.38644418120384216 2022-06-30 21:51:24.743971
Epoch:[ 149 9 ] loss: 0.38897520303726196 2022-06-30 21:51:25.170766
Epoch:[ 149 10 ] loss: 0.3901195824146271 2022-06-30 21:51:25.598549
Epoch:[ 149 11 ] loss: 0.3870038092136383 2022-06-30 21:51:26.031298
Epoch:[ 149 12 ] loss: 0.3881663680076599 2022-06-30 21:51:26.457403
Epoch:[ 149 13 ] loss: 0.3908306956291199 2022-06-30 21:51:26.891987
Epoch:[ 149 14 ] loss: 0.39059150218963623 2022-06-30 21:51:27.321040
Epoch:[ 149 15 ] loss: 0.39070045948028564 2022-06-30 21:51:27.749901
Epoch:[ 149 16 ] loss: 0.38914987444877625 2022-06-30 21:51:33.422006
Epoch:[ 149 17 ] loss: 0.3862019181251526 2022-06-30 21:51:33.848416
Epoch:[ 149 18 ] loss: 0.38864225149154663 2022-06-30 21:51:34.282253
Epoch:[ 149 19 ] loss: 0.39068594574928284 2022-06-30 21:51:34.709049
Training_Epoch:[ 149 ] Training_loss: 0.3884360358119011 2022-06-30 21:51:34.709914
learning rate:  0.0002199023255552002
val: 1 0.4755963087081909
val: 2 0.4764731824398041
val: 3 0.4776698052883148
val: 4 0.47749951481819153
val: 5 0.4725906252861023
val: 6 0.4730485677719116
val: 7 0.46617797017097473
val: 8 0.45369279384613037
val: 9 0.47800981998443604
val: 10 0.4700424373149872
val: 11 0.4789332449436188
val: 12 0.47118455171585083
val: 13 0.47946664690971375
val: 14 0.4720437228679657
val: 15 0.47717100381851196
val: 16 0.46255525946617126
val: 17 0.45904454588890076
val: 18 0.46869704127311707
val: 19 0.47621169686317444
val: 20 0.4564187526702881
val_Epoch:[ 149 ] val_loss: 0.4711263746023178 2022-06-30 21:51:38.019026
start training 2022-06-30 21:51:38.119011
Epoch:[ 150 0 ] loss: 0.3897917866706848 2022-06-30 21:51:52.478336
Epoch:[ 150 1 ] loss: 0.3868372440338135 2022-06-30 21:51:52.912247
Epoch:[ 150 2 ] loss: 0.3889460861682892 2022-06-30 21:51:53.339259
Epoch:[ 150 3 ] loss: 0.3876270353794098 2022-06-30 21:51:53.766299
Epoch:[ 150 4 ] loss: 0.3905593454837799 2022-06-30 21:51:54.193979
Epoch:[ 150 5 ] loss: 0.38829129934310913 2022-06-30 21:51:54.620788
Epoch:[ 150 6 ] loss: 0.38905787467956543 2022-06-30 21:51:55.046138
Epoch:[ 150 7 ] loss: 0.3887341618537903 2022-06-30 21:51:55.476053
Epoch:[ 150 8 ] loss: 0.3871367275714874 2022-06-30 21:51:55.910356
Epoch:[ 150 9 ] loss: 0.386570006608963 2022-06-30 21:51:56.337969
Epoch:[ 150 10 ] loss: 0.38585543632507324 2022-06-30 21:51:56.764028
Epoch:[ 150 11 ] loss: 0.38815367221832275 2022-06-30 21:51:57.192840
Epoch:[ 150 12 ] loss: 0.39042165875434875 2022-06-30 21:51:57.620240
Epoch:[ 150 13 ] loss: 0.38872796297073364 2022-06-30 21:51:58.047675
Epoch:[ 150 14 ] loss: 0.387394517660141 2022-06-30 21:51:58.481298
Epoch:[ 150 15 ] loss: 0.38638052344322205 2022-06-30 21:51:58.915545
Epoch:[ 150 16 ] loss: 0.3877083361148834 2022-06-30 21:52:04.028140
Epoch:[ 150 17 ] loss: 0.3899923861026764 2022-06-30 21:52:04.452772
Epoch:[ 150 18 ] loss: 0.38669970631599426 2022-06-30 21:52:04.884309
Epoch:[ 150 19 ] loss: 0.3880513310432434 2022-06-30 21:52:05.310117
Training_Epoch:[ 150 ] Training_loss: 0.38814685493707657 2022-06-30 21:52:05.310744
learning rate:  0.0002199023255552002
netparams have been saved once 150
val: 1 0.46664658188819885
val: 2 0.4845793545246124
val: 3 0.4741020202636719
val: 4 0.4820023477077484
val: 5 0.45806947350502014
val: 6 0.4632365107536316
val: 7 0.46484464406967163
val: 8 0.4784272015094757
val: 9 0.47863349318504333
val: 10 0.4770236015319824
val: 11 0.48399409651756287
val: 12 0.4682702124118805
val: 13 0.48017242550849915
val: 14 0.4589235782623291
val: 15 0.464152991771698
val: 16 0.4711807668209076
val: 17 0.4564953148365021
val: 18 0.46971189975738525
val: 19 0.4805602431297302
val: 20 0.47551512718200684
val_Epoch:[ 150 ] val_loss: 0.4718270942568779 2022-06-30 21:52:08.691247
start training 2022-06-30 21:52:08.790371
Epoch:[ 151 0 ] loss: 0.3866676092147827 2022-06-30 21:52:23.429858
Epoch:[ 151 1 ] loss: 0.38919225335121155 2022-06-30 21:52:23.858252
Epoch:[ 151 2 ] loss: 0.38756996393203735 2022-06-30 21:52:24.287608
Epoch:[ 151 3 ] loss: 0.3879341781139374 2022-06-30 21:52:24.716885
Epoch:[ 151 4 ] loss: 0.386849582195282 2022-06-30 21:52:25.144432
Epoch:[ 151 5 ] loss: 0.38766616582870483 2022-06-30 21:52:25.571469
Epoch:[ 151 6 ] loss: 0.38735702633857727 2022-06-30 21:52:26.006111
Epoch:[ 151 7 ] loss: 0.387525349855423 2022-06-30 21:52:26.439318
Epoch:[ 151 8 ] loss: 0.3861500024795532 2022-06-30 21:52:26.874365
Epoch:[ 151 9 ] loss: 0.3883896768093109 2022-06-30 21:52:27.304210
Epoch:[ 151 10 ] loss: 0.3844800293445587 2022-06-30 21:52:27.732956
Epoch:[ 151 11 ] loss: 0.3883489668369293 2022-06-30 21:52:28.167798
Epoch:[ 151 12 ] loss: 0.38749244809150696 2022-06-30 21:52:28.596716
Epoch:[ 151 13 ] loss: 0.388426810503006 2022-06-30 21:52:29.022753
Epoch:[ 151 14 ] loss: 0.38866493105888367 2022-06-30 21:52:29.449491
Epoch:[ 151 15 ] loss: 0.3854053020477295 2022-06-30 21:52:29.883373
Epoch:[ 151 16 ] loss: 0.3878873288631439 2022-06-30 21:52:35.130887
Epoch:[ 151 17 ] loss: 0.3857240080833435 2022-06-30 21:52:35.558534
Epoch:[ 151 18 ] loss: 0.38913798332214355 2022-06-30 21:52:35.988130
Epoch:[ 151 19 ] loss: 0.3856906294822693 2022-06-30 21:52:36.415296
Training_Epoch:[ 151 ] Training_loss: 0.3873280122876167 2022-06-30 21:52:36.416084
learning rate:  0.00017592186044416018
val: 1 0.47580984234809875
val: 2 0.468294233083725
val: 3 0.48641642928123474
val: 4 0.4707508385181427
val: 5 0.47656944394111633
val: 6 0.4749292731285095
val: 7 0.46838974952697754
val: 8 0.46695637702941895
val: 9 0.480018675327301
val: 10 0.4600681960582733
val: 11 0.48467332124710083
val: 12 0.4668155908584595
val: 13 0.48322489857673645
val: 14 0.48427537083625793
val: 15 0.4594351053237915
val: 16 0.4633356034755707
val: 17 0.4638013243675232
val: 18 0.45735639333724976
val: 19 0.4646904468536377
val: 20 0.4666995704174042
val_Epoch:[ 151 ] val_loss: 0.47112553417682645 2022-06-30 21:52:39.750737
start training 2022-06-30 21:52:39.849318
Epoch:[ 152 0 ] loss: 0.38751116394996643 2022-06-30 21:52:53.809750
Epoch:[ 152 1 ] loss: 0.38537612557411194 2022-06-30 21:52:54.253281
Epoch:[ 152 2 ] loss: 0.38764870166778564 2022-06-30 21:52:54.674250
Epoch:[ 152 3 ] loss: 0.3863980174064636 2022-06-30 21:52:55.100567
Epoch:[ 152 4 ] loss: 0.38702109456062317 2022-06-30 21:52:55.520451
Epoch:[ 152 5 ] loss: 0.3879198133945465 2022-06-30 21:52:55.939415
Epoch:[ 152 6 ] loss: 0.38585972785949707 2022-06-30 21:52:56.365309
Epoch:[ 152 7 ] loss: 0.38576552271842957 2022-06-30 21:52:56.790763
Epoch:[ 152 8 ] loss: 0.3870880901813507 2022-06-30 21:52:57.209516
Epoch:[ 152 9 ] loss: 0.3872276246547699 2022-06-30 21:52:57.630620
Epoch:[ 152 10 ] loss: 0.3880805969238281 2022-06-30 21:52:58.051118
Epoch:[ 152 11 ] loss: 0.3885596990585327 2022-06-30 21:52:58.473320
Epoch:[ 152 12 ] loss: 0.3870460093021393 2022-06-30 21:52:58.898653
Epoch:[ 152 13 ] loss: 0.38645660877227783 2022-06-30 21:52:59.319062
Epoch:[ 152 14 ] loss: 0.38531625270843506 2022-06-30 21:52:59.737779
Epoch:[ 152 15 ] loss: 0.38529664278030396 2022-06-30 21:53:00.157295
Epoch:[ 152 16 ] loss: 0.38831254839897156 2022-06-30 21:53:05.693252
Epoch:[ 152 17 ] loss: 0.3846770226955414 2022-06-30 21:53:06.114240
Epoch:[ 152 18 ] loss: 0.3872215151786804 2022-06-30 21:53:06.544681
Epoch:[ 152 19 ] loss: 0.3860616683959961 2022-06-30 21:53:06.963918
Training_Epoch:[ 152 ] Training_loss: 0.38674222230911254 2022-06-30 21:53:06.964581
learning rate:  0.00017592186044416018
netparams have been saved once 152
val: 1 0.4691118597984314
val: 2 0.46977514028549194
val: 3 0.47306153178215027
val: 4 0.46483880281448364
val: 5 0.4918851852416992
val: 6 0.45928969979286194
val: 7 0.4741813540458679
val: 8 0.47322314977645874
val: 9 0.46776527166366577
val: 10 0.46344417333602905
val: 11 0.4610642194747925
val: 12 0.4894002676010132
val: 13 0.4839823246002197
val: 14 0.4739173948764801
val: 15 0.48603305220603943
val: 16 0.4722940921783447
val: 17 0.47097986936569214
val: 18 0.4759296774864197
val: 19 0.47541841864585876
val: 20 0.47426605224609375
val_Epoch:[ 152 ] val_loss: 0.4734930768609047 2022-06-30 21:53:10.314252
start training 2022-06-30 21:53:10.413352
Epoch:[ 153 0 ] loss: 0.38541340827941895 2022-06-30 21:53:24.032821
Epoch:[ 153 1 ] loss: 0.38522398471832275 2022-06-30 21:53:25.018008
Epoch:[ 153 2 ] loss: 0.3855450749397278 2022-06-30 21:53:25.443073
Epoch:[ 153 3 ] loss: 0.3868412375450134 2022-06-30 21:53:25.865623
Epoch:[ 153 4 ] loss: 0.38599199056625366 2022-06-30 21:53:26.287786
Epoch:[ 153 5 ] loss: 0.3866901993751526 2022-06-30 21:53:26.713455
Epoch:[ 153 6 ] loss: 0.3886115550994873 2022-06-30 21:53:27.133234
Epoch:[ 153 7 ] loss: 0.3866020739078522 2022-06-30 21:53:27.560093
Epoch:[ 153 8 ] loss: 0.3872409164905548 2022-06-30 21:53:27.980616
Epoch:[ 153 9 ] loss: 0.38823333382606506 2022-06-30 21:53:28.399982
Epoch:[ 153 10 ] loss: 0.3858717679977417 2022-06-30 21:53:28.822118
Epoch:[ 153 11 ] loss: 0.38792935013771057 2022-06-30 21:53:29.250187
Epoch:[ 153 12 ] loss: 0.38390836119651794 2022-06-30 21:53:29.671575
Epoch:[ 153 13 ] loss: 0.38563570380210876 2022-06-30 21:53:30.090496
Epoch:[ 153 14 ] loss: 0.3867168724536896 2022-06-30 21:53:30.510394
Epoch:[ 153 15 ] loss: 0.3867770731449127 2022-06-30 21:53:30.932078
Epoch:[ 153 16 ] loss: 0.38588500022888184 2022-06-30 21:53:35.833902
Epoch:[ 153 17 ] loss: 0.3866269290447235 2022-06-30 21:53:36.934886
Epoch:[ 153 18 ] loss: 0.38868793845176697 2022-06-30 21:53:37.358694
Epoch:[ 153 19 ] loss: 0.3868837058544159 2022-06-30 21:53:37.782375
Training_Epoch:[ 153 ] Training_loss: 0.3865658238530159 2022-06-30 21:53:37.783038
learning rate:  0.00017592186044416018
val: 1 0.4609898030757904
val: 2 0.4705599844455719
val: 3 0.4779879152774811
val: 4 0.4692341983318329
val: 5 0.47001996636390686
val: 6 0.4675811231136322
val: 7 0.4792930781841278
val: 8 0.475030779838562
val: 9 0.4814594089984894
val: 10 0.4546966850757599
val: 11 0.4794783592224121
val: 12 0.45141950249671936
val: 13 0.47927960753440857
val: 14 0.4764470160007477
val: 15 0.4785332679748535
val: 16 0.46347638964653015
val: 17 0.4702417850494385
val: 18 0.46288836002349854
val: 19 0.4815019369125366
val: 20 0.46940648555755615
val_Epoch:[ 153 ] val_loss: 0.4709762826561928 2022-06-30 21:53:41.123664
start training 2022-06-30 21:53:41.227719
Epoch:[ 154 0 ] loss: 0.387606680393219 2022-06-30 21:53:55.905749
Epoch:[ 154 1 ] loss: 0.386020302772522 2022-06-30 21:53:56.325248
Epoch:[ 154 2 ] loss: 0.3865693509578705 2022-06-30 21:53:56.749525
Epoch:[ 154 3 ] loss: 0.3857882022857666 2022-06-30 21:53:57.174406
Epoch:[ 154 4 ] loss: 0.3872884213924408 2022-06-30 21:53:57.601823
Epoch:[ 154 5 ] loss: 0.38539427518844604 2022-06-30 21:53:58.028521
Epoch:[ 154 6 ] loss: 0.3844727575778961 2022-06-30 21:53:58.447216
Epoch:[ 154 7 ] loss: 0.3858678340911865 2022-06-30 21:53:58.866929
Epoch:[ 154 8 ] loss: 0.3865063488483429 2022-06-30 21:53:59.286012
Epoch:[ 154 9 ] loss: 0.38680508732795715 2022-06-30 21:53:59.704644
Epoch:[ 154 10 ] loss: 0.3865087032318115 2022-06-30 21:54:00.122544
Epoch:[ 154 11 ] loss: 0.3885217308998108 2022-06-30 21:54:00.544433
Epoch:[ 154 12 ] loss: 0.38827142119407654 2022-06-30 21:54:00.965532
Epoch:[ 154 13 ] loss: 0.38562217354774475 2022-06-30 21:54:01.385642
Epoch:[ 154 14 ] loss: 0.38543248176574707 2022-06-30 21:54:01.804253
Epoch:[ 154 15 ] loss: 0.38847455382347107 2022-06-30 21:54:02.224143
Epoch:[ 154 16 ] loss: 0.38676440715789795 2022-06-30 21:54:07.705703
Epoch:[ 154 17 ] loss: 0.38651856780052185 2022-06-30 21:54:08.123723
Epoch:[ 154 18 ] loss: 0.3883109986782074 2022-06-30 21:54:08.546383
Epoch:[ 154 19 ] loss: 0.3863673508167267 2022-06-30 21:54:08.967608
Training_Epoch:[ 154 ] Training_loss: 0.38665558248758314 2022-06-30 21:54:08.968231
learning rate:  0.00017592186044416018
netparams have been saved once 154
val: 1 0.46827617287635803
val: 2 0.4739314317703247
val: 3 0.4624205231666565
val: 4 0.4803021550178528
val: 5 0.47324085235595703
val: 6 0.47653645277023315
val: 7 0.46933433413505554
val: 8 0.46148884296417236
val: 9 0.47504934668540955
val: 10 0.4893782436847687
val: 11 0.4669620096683502
val: 12 0.4688653349876404
val: 13 0.4696124494075775
val: 14 0.478964626789093
val: 15 0.4730915427207947
val: 16 0.4811064898967743
val: 17 0.48848652839660645
val: 18 0.47313305735588074
val: 19 0.48543044924736023
val: 20 0.47066888213157654
val_Epoch:[ 154 ] val_loss: 0.47431398630142213 2022-06-30 21:54:12.390789
start training 2022-06-30 21:54:12.493011
Epoch:[ 155 0 ] loss: 0.38493862748146057 2022-06-30 21:54:26.800853
Epoch:[ 155 1 ] loss: 0.3865854740142822 2022-06-30 21:54:27.214862
Epoch:[ 155 2 ] loss: 0.38279038667678833 2022-06-30 21:54:27.634147
Epoch:[ 155 3 ] loss: 0.38743194937705994 2022-06-30 21:54:28.056946
Epoch:[ 155 4 ] loss: 0.3867952525615692 2022-06-30 21:54:28.469708
Epoch:[ 155 5 ] loss: 0.3865342140197754 2022-06-30 21:54:28.886302
Epoch:[ 155 6 ] loss: 0.38771823048591614 2022-06-30 21:54:29.305458
Epoch:[ 155 7 ] loss: 0.38816702365875244 2022-06-30 21:54:29.721977
Epoch:[ 155 8 ] loss: 0.3868914246559143 2022-06-30 21:54:30.141933
Epoch:[ 155 9 ] loss: 0.3859196603298187 2022-06-30 21:54:30.556426
Epoch:[ 155 10 ] loss: 0.3858223557472229 2022-06-30 21:54:30.970223
Epoch:[ 155 11 ] loss: 0.38568931818008423 2022-06-30 21:54:31.384799
Epoch:[ 155 12 ] loss: 0.38591304421424866 2022-06-30 21:54:31.801803
Epoch:[ 155 13 ] loss: 0.3854887783527374 2022-06-30 21:54:32.217371
Epoch:[ 155 14 ] loss: 0.38716843724250793 2022-06-30 21:54:32.640723
Epoch:[ 155 15 ] loss: 0.3871816396713257 2022-06-30 21:54:33.055386
Epoch:[ 155 16 ] loss: 0.38341936469078064 2022-06-30 21:54:38.345707
Epoch:[ 155 17 ] loss: 0.3862241804599762 2022-06-30 21:54:38.759445
Epoch:[ 155 18 ] loss: 0.3873525559902191 2022-06-30 21:54:39.179798
Epoch:[ 155 19 ] loss: 0.3875315189361572 2022-06-30 21:54:39.596879
Training_Epoch:[ 155 ] Training_loss: 0.3862781718373299 2022-06-30 21:54:39.597683
learning rate:  0.00017592186044416018
val: 1 0.4639332592487335
val: 2 0.4699867367744446
val: 3 0.45701417326927185
val: 4 0.4552666246891022
val: 5 0.4678705036640167
val: 6 0.47749197483062744
val: 7 0.4761955142021179
val: 8 0.48534685373306274
val: 9 0.4712636470794678
val: 10 0.4818379580974579
val: 11 0.49380090832710266
val: 12 0.47100627422332764
val: 13 0.4728724956512451
val: 14 0.46508416533470154
val: 15 0.48890426754951477
val: 16 0.48184677958488464
val: 17 0.4690816104412079
val: 18 0.4766835868358612
val: 19 0.46526235342025757
val: 20 0.48815786838531494
val_Epoch:[ 155 ] val_loss: 0.473945377767086 2022-06-30 21:54:42.940092
start training 2022-06-30 21:54:43.043462
Epoch:[ 156 0 ] loss: 0.38877683877944946 2022-06-30 21:54:57.136915
Epoch:[ 156 1 ] loss: 0.3848177194595337 2022-06-30 21:54:57.713398
Epoch:[ 156 2 ] loss: 0.387692928314209 2022-06-30 21:54:58.127369
Epoch:[ 156 3 ] loss: 0.3873079717159271 2022-06-30 21:54:58.542427
Epoch:[ 156 4 ] loss: 0.388550728559494 2022-06-30 21:54:58.961400
Epoch:[ 156 5 ] loss: 0.3858702778816223 2022-06-30 21:54:59.374226
Epoch:[ 156 6 ] loss: 0.3847498595714569 2022-06-30 21:54:59.789402
Epoch:[ 156 7 ] loss: 0.3849450349807739 2022-06-30 21:55:00.205892
Epoch:[ 156 8 ] loss: 0.3859512507915497 2022-06-30 21:55:00.626934
Epoch:[ 156 9 ] loss: 0.3876021206378937 2022-06-30 21:55:01.046044
Epoch:[ 156 10 ] loss: 0.3846728503704071 2022-06-30 21:55:01.460478
Epoch:[ 156 11 ] loss: 0.38746851682662964 2022-06-30 21:55:01.874969
Epoch:[ 156 12 ] loss: 0.3834146559238434 2022-06-30 21:55:02.293662
Epoch:[ 156 13 ] loss: 0.38374215364456177 2022-06-30 21:55:02.709757
Epoch:[ 156 14 ] loss: 0.3850378096103668 2022-06-30 21:55:03.125735
Epoch:[ 156 15 ] loss: 0.3863348066806793 2022-06-30 21:55:03.544881
Epoch:[ 156 16 ] loss: 0.38686680793762207 2022-06-30 21:55:08.549059
Epoch:[ 156 17 ] loss: 0.386544406414032 2022-06-30 21:55:09.301411
Epoch:[ 156 18 ] loss: 0.38825616240501404 2022-06-30 21:55:09.716827
Epoch:[ 156 19 ] loss: 0.38800838589668274 2022-06-30 21:55:10.131932
Training_Epoch:[ 156 ] Training_loss: 0.38633056432008744 2022-06-30 21:55:10.132602
learning rate:  0.00017592186044416018
netparams have been saved once 156
val: 1 0.4742545485496521
val: 2 0.468461275100708
val: 3 0.4722706377506256
val: 4 0.4721750020980835
val: 5 0.4701279103755951
val: 6 0.4797411561012268
val: 7 0.4839637279510498
val: 8 0.4835965037345886
val: 9 0.468626469373703
val: 10 0.48033809661865234
val: 11 0.47351282835006714
val: 12 0.48760688304901123
val: 13 0.4675390124320984
val: 14 0.4717867374420166
val: 15 0.4766142666339874
val: 16 0.4709804058074951
val: 17 0.47515496611595154
val: 18 0.4695208966732025
val: 19 0.47848188877105713
val: 20 0.4685460925102234
val_Epoch:[ 156 ] val_loss: 0.4746649652719498 2022-06-30 21:55:13.565824
start training 2022-06-30 21:55:13.665817
Epoch:[ 157 0 ] loss: 0.38548141717910767 2022-06-30 21:55:28.173921
Epoch:[ 157 1 ] loss: 0.3866199851036072 2022-06-30 21:55:28.596194
Epoch:[ 157 2 ] loss: 0.38670259714126587 2022-06-30 21:55:29.011909
Epoch:[ 157 3 ] loss: 0.38820186257362366 2022-06-30 21:55:29.426691
Epoch:[ 157 4 ] loss: 0.38522806763648987 2022-06-30 21:55:29.842029
Epoch:[ 157 5 ] loss: 0.38620710372924805 2022-06-30 21:55:30.261833
Epoch:[ 157 6 ] loss: 0.3845707178115845 2022-06-30 21:55:30.676138
Epoch:[ 157 7 ] loss: 0.38327378034591675 2022-06-30 21:55:31.092909
Epoch:[ 157 8 ] loss: 0.386911541223526 2022-06-30 21:55:31.508922
Epoch:[ 157 9 ] loss: 0.3872886300086975 2022-06-30 21:55:31.925620
Epoch:[ 157 10 ] loss: 0.38794752955436707 2022-06-30 21:55:32.347583
Epoch:[ 157 11 ] loss: 0.3876775801181793 2022-06-30 21:55:32.762734
Epoch:[ 157 12 ] loss: 0.3872317373752594 2022-06-30 21:55:33.182201
Epoch:[ 157 13 ] loss: 0.38747063279151917 2022-06-30 21:55:33.595583
Epoch:[ 157 14 ] loss: 0.38685211539268494 2022-06-30 21:55:34.010881
Epoch:[ 157 15 ] loss: 0.38707444071769714 2022-06-30 21:55:34.426029
Epoch:[ 157 16 ] loss: 0.38566499948501587 2022-06-30 21:55:39.775783
Epoch:[ 157 17 ] loss: 0.38637077808380127 2022-06-30 21:55:40.190956
Epoch:[ 157 18 ] loss: 0.3868529498577118 2022-06-30 21:55:40.613408
Epoch:[ 157 19 ] loss: 0.3866526186466217 2022-06-30 21:55:41.026268
Training_Epoch:[ 157 ] Training_loss: 0.38651405423879626 2022-06-30 21:55:41.027120
learning rate:  0.00017592186044416018
val: 1 0.47450724244117737
val: 2 0.4698231518268585
val: 3 0.47044727206230164
val: 4 0.4850340485572815
val: 5 0.46568363904953003
val: 6 0.4664975106716156
val: 7 0.46662744879722595
val: 8 0.47634896636009216
val: 9 0.4832919239997864
val: 10 0.47042426466941833
val: 11 0.4738660156726837
val: 12 0.4703480005264282
val: 13 0.4777584671974182
val: 14 0.4622117578983307
val: 15 0.4797825813293457
val: 16 0.4752952456474304
val: 17 0.4876866042613983
val: 18 0.48160886764526367
val: 19 0.4749554693698883
val: 20 0.4778657853603363
val_Epoch:[ 157 ] val_loss: 0.4745032131671906 2022-06-30 21:55:44.417354
start training 2022-06-30 21:55:44.518447
Epoch:[ 158 0 ] loss: 0.38603833317756653 2022-06-30 21:55:58.179984
Epoch:[ 158 1 ] loss: 0.3838209807872772 2022-06-30 21:55:58.749036
Epoch:[ 158 2 ] loss: 0.388258159160614 2022-06-30 21:55:59.188219
Epoch:[ 158 3 ] loss: 0.3880103826522827 2022-06-30 21:55:59.607206
Epoch:[ 158 4 ] loss: 0.3847835063934326 2022-06-30 21:56:00.025228
Epoch:[ 158 5 ] loss: 0.384396493434906 2022-06-30 21:56:00.438571
Epoch:[ 158 6 ] loss: 0.3836868703365326 2022-06-30 21:56:00.851471
Epoch:[ 158 7 ] loss: 0.38725417852401733 2022-06-30 21:56:01.265270
Epoch:[ 158 8 ] loss: 0.38342171907424927 2022-06-30 21:56:01.683842
Epoch:[ 158 9 ] loss: 0.3872857093811035 2022-06-30 21:56:02.098737
Epoch:[ 158 10 ] loss: 0.3875182867050171 2022-06-30 21:56:02.521409
Epoch:[ 158 11 ] loss: 0.38532209396362305 2022-06-30 21:56:02.937468
Epoch:[ 158 12 ] loss: 0.3855145573616028 2022-06-30 21:56:03.352115
Epoch:[ 158 13 ] loss: 0.3884999454021454 2022-06-30 21:56:03.770986
Epoch:[ 158 14 ] loss: 0.38794854283332825 2022-06-30 21:56:04.183268
Epoch:[ 158 15 ] loss: 0.38739264011383057 2022-06-30 21:56:04.599794
Epoch:[ 158 16 ] loss: 0.38801974058151245 2022-06-30 21:56:09.940069
Epoch:[ 158 17 ] loss: 0.3877728283405304 2022-06-30 21:56:10.356747
Epoch:[ 158 18 ] loss: 0.38821086287498474 2022-06-30 21:56:10.778425
Epoch:[ 158 19 ] loss: 0.3858043849468231 2022-06-30 21:56:11.193703
Training_Epoch:[ 158 ] Training_loss: 0.386448010802269 2022-06-30 21:56:11.194378
learning rate:  0.00017592186044416018
netparams have been saved once 158
val: 1 0.48147597908973694
val: 2 0.4635154604911804
val: 3 0.4878537058830261
val: 4 0.473214715719223
val: 5 0.46464675664901733
val: 6 0.4715278148651123
val: 7 0.47357648611068726
val: 8 0.4556393027305603
val: 9 0.46789148449897766
val: 10 0.47149452567100525
val: 11 0.46711018681526184
val: 12 0.47937577962875366
val: 13 0.45823773741722107
val: 14 0.48318353295326233
val: 15 0.47372403740882874
val: 16 0.4795713722705841
val: 17 0.47146353125572205
val: 18 0.47484010457992554
val: 19 0.4821068346500397
val: 20 0.46387019753456116
val_Epoch:[ 158 ] val_loss: 0.47221597731113435 2022-06-30 21:56:14.685075
start training 2022-06-30 21:56:14.786838
Epoch:[ 159 0 ] loss: 0.3863537907600403 2022-06-30 21:56:28.494532
Epoch:[ 159 1 ] loss: 0.38560739159584045 2022-06-30 21:56:28.945625
Epoch:[ 159 2 ] loss: 0.38593703508377075 2022-06-30 21:56:29.396976
Epoch:[ 159 3 ] loss: 0.3853473663330078 2022-06-30 21:56:29.812999
Epoch:[ 159 4 ] loss: 0.38499438762664795 2022-06-30 21:56:30.227708
Epoch:[ 159 5 ] loss: 0.3871927559375763 2022-06-30 21:56:30.642353
Epoch:[ 159 6 ] loss: 0.38595494627952576 2022-06-30 21:56:31.056992
Epoch:[ 159 7 ] loss: 0.388909250497818 2022-06-30 21:56:31.472423
Epoch:[ 159 8 ] loss: 0.3875190317630768 2022-06-30 21:56:31.892847
Epoch:[ 159 9 ] loss: 0.3871050179004669 2022-06-30 21:56:32.309795
Epoch:[ 159 10 ] loss: 0.3855367600917816 2022-06-30 21:56:32.726293
Epoch:[ 159 11 ] loss: 0.38583531975746155 2022-06-30 21:56:33.143586
Epoch:[ 159 12 ] loss: 0.3850005567073822 2022-06-30 21:56:33.564078
Epoch:[ 159 13 ] loss: 0.38842132687568665 2022-06-30 21:56:33.979453
Epoch:[ 159 14 ] loss: 0.3849891126155853 2022-06-30 21:56:34.402077
Epoch:[ 159 15 ] loss: 0.3875761032104492 2022-06-30 21:56:34.816450
Epoch:[ 159 16 ] loss: 0.38512083888053894 2022-06-30 21:56:40.206718
Epoch:[ 159 17 ] loss: 0.3883790373802185 2022-06-30 21:56:40.622769
Epoch:[ 159 18 ] loss: 0.38741087913513184 2022-06-30 21:56:41.040579
Epoch:[ 159 19 ] loss: 0.38828086853027344 2022-06-30 21:56:41.455987
Training_Epoch:[ 159 ] Training_loss: 0.386573588848114 2022-06-30 21:56:41.456753
learning rate:  0.00017592186044416018
val: 1 0.46317246556282043
val: 2 0.48066583275794983
val: 3 0.465309739112854
val: 4 0.4719374179840088
val: 5 0.4911188781261444
val: 6 0.4765125811100006
val: 7 0.49590232968330383
val: 8 0.4800085425376892
val: 9 0.4671727120876312
val: 10 0.46490320563316345
val: 11 0.47073936462402344
val: 12 0.4703650176525116
val: 13 0.46201109886169434
val: 14 0.47347745299339294
val: 15 0.4726819396018982
val: 16 0.46800488233566284
val: 17 0.4654479920864105
val: 18 0.47118356823921204
val: 19 0.49374252557754517
val: 20 0.4761695861816406
val_Epoch:[ 159 ] val_loss: 0.4740263566374779 2022-06-30 21:56:44.807123
start training 2022-06-30 21:56:44.910205
Epoch:[ 160 0 ] loss: 0.38481810688972473 2022-06-30 21:56:59.331455
Epoch:[ 160 1 ] loss: 0.3857435882091522 2022-06-30 21:56:59.750982
Epoch:[ 160 2 ] loss: 0.38560009002685547 2022-06-30 21:57:00.163611
Epoch:[ 160 3 ] loss: 0.38750070333480835 2022-06-30 21:57:00.579327
Epoch:[ 160 4 ] loss: 0.38938799500465393 2022-06-30 21:57:00.995041
Epoch:[ 160 5 ] loss: 0.3867165446281433 2022-06-30 21:57:01.409205
Epoch:[ 160 6 ] loss: 0.3854563236236572 2022-06-30 21:57:01.822511
Epoch:[ 160 7 ] loss: 0.3851964771747589 2022-06-30 21:57:02.243435
Epoch:[ 160 8 ] loss: 0.38900935649871826 2022-06-30 21:57:02.659412
Epoch:[ 160 9 ] loss: 0.38681966066360474 2022-06-30 21:57:03.072220
Epoch:[ 160 10 ] loss: 0.3854408860206604 2022-06-30 21:57:03.488746
Epoch:[ 160 11 ] loss: 0.3862512707710266 2022-06-30 21:57:03.904473
Epoch:[ 160 12 ] loss: 0.38683152198791504 2022-06-30 21:57:04.324555
Epoch:[ 160 13 ] loss: 0.3872072696685791 2022-06-30 21:57:04.744724
Epoch:[ 160 14 ] loss: 0.3875528573989868 2022-06-30 21:57:05.159944
Epoch:[ 160 15 ] loss: 0.38977187871932983 2022-06-30 21:57:05.574532
Epoch:[ 160 16 ] loss: 0.3866911828517914 2022-06-30 21:57:10.890436
Epoch:[ 160 17 ] loss: 0.38762134313583374 2022-06-30 21:57:11.305899
Epoch:[ 160 18 ] loss: 0.38732048869132996 2022-06-30 21:57:11.723011
Epoch:[ 160 19 ] loss: 0.386231392621994 2022-06-30 21:57:12.139811
Training_Epoch:[ 160 ] Training_loss: 0.3868584468960762 2022-06-30 21:57:12.140454
learning rate:  0.00017592186044416018
netparams have been saved once 160
val: 1 0.49209585785865784
val: 2 0.4698113799095154
val: 3 0.4738524258136749
val: 4 0.4784347414970398
val: 5 0.4828258156776428
val: 6 0.46040037274360657
val: 7 0.4769386649131775
val: 8 0.47042521834373474
val: 9 0.46396562457084656
val: 10 0.4689396321773529
val: 11 0.4804113805294037
val: 12 0.48997440934181213
val: 13 0.4715181887149811
val: 14 0.4675354063510895
val: 15 0.4603121280670166
val: 16 0.468999445438385
val: 17 0.4759782552719116
val: 18 0.46611595153808594
val: 19 0.46950462460517883
val: 20 0.453376442193985
val_Epoch:[ 160 ] val_loss: 0.4720707982778549 2022-06-30 21:57:15.498414
start training 2022-06-30 21:57:15.602690
Epoch:[ 161 0 ] loss: 0.3845672011375427 2022-06-30 21:57:29.851627
Epoch:[ 161 1 ] loss: 0.38713034987449646 2022-06-30 21:57:30.272384
Epoch:[ 161 2 ] loss: 0.3866075575351715 2022-06-30 21:57:30.684697
Epoch:[ 161 3 ] loss: 0.38490065932273865 2022-06-30 21:57:31.104937
Epoch:[ 161 4 ] loss: 0.3851310610771179 2022-06-30 21:57:31.526833
Epoch:[ 161 5 ] loss: 0.3828596770763397 2022-06-30 21:57:31.948079
Epoch:[ 161 6 ] loss: 0.3861927390098572 2022-06-30 21:57:32.362568
Epoch:[ 161 7 ] loss: 0.3841440975666046 2022-06-30 21:57:32.776692
Epoch:[ 161 8 ] loss: 0.3853137791156769 2022-06-30 21:57:33.190680
Epoch:[ 161 9 ] loss: 0.3842691481113434 2022-06-30 21:57:33.604607
Epoch:[ 161 10 ] loss: 0.3852596580982208 2022-06-30 21:57:34.017746
Epoch:[ 161 11 ] loss: 0.3870944082736969 2022-06-30 21:57:34.433778
Epoch:[ 161 12 ] loss: 0.384881854057312 2022-06-30 21:57:34.856104
Epoch:[ 161 13 ] loss: 0.38504859805107117 2022-06-30 21:57:35.271216
Epoch:[ 161 14 ] loss: 0.3857613503932953 2022-06-30 21:57:35.685656
Epoch:[ 161 15 ] loss: 0.3851237893104553 2022-06-30 21:57:36.101824
Epoch:[ 161 16 ] loss: 0.3837594985961914 2022-06-30 21:57:41.245510
Epoch:[ 161 17 ] loss: 0.38852497935295105 2022-06-30 21:57:42.058441
Epoch:[ 161 18 ] loss: 0.38738077878952026 2022-06-30 21:57:42.474577
Epoch:[ 161 19 ] loss: 0.38418686389923096 2022-06-30 21:57:42.889852
Training_Epoch:[ 161 ] Training_loss: 0.3854069024324417 2022-06-30 21:57:42.890657
learning rate:  0.00014073748835532815
val: 1 0.47466611862182617
val: 2 0.4759742021560669
val: 3 0.4671684205532074
val: 4 0.4683435559272766
val: 5 0.4714428782463074
val: 6 0.4807213842868805
val: 7 0.47865045070648193
val: 8 0.4842498302459717
val: 9 0.48021572828292847
val: 10 0.4868549108505249
val: 11 0.47385790944099426
val: 12 0.4843238294124603
val: 13 0.4751075804233551
val: 14 0.45569512248039246
val: 15 0.466474711894989
val: 16 0.4716242551803589
val: 17 0.49236637353897095
val: 18 0.47629788517951965
val: 19 0.4730982780456543
val: 20 0.48134109377861023
val_Epoch:[ 161 ] val_loss: 0.4759237259626389 2022-06-30 21:57:46.324131
start training 2022-06-30 21:57:46.425061
Epoch:[ 162 0 ] loss: 0.3839416801929474 2022-06-30 21:58:01.179462
Epoch:[ 162 1 ] loss: 0.38562658429145813 2022-06-30 21:58:01.599614
Epoch:[ 162 2 ] loss: 0.3850678503513336 2022-06-30 21:58:02.013803
Epoch:[ 162 3 ] loss: 0.38521867990493774 2022-06-30 21:58:02.427753
Epoch:[ 162 4 ] loss: 0.3848833739757538 2022-06-30 21:58:02.840888
Epoch:[ 162 5 ] loss: 0.3819616138935089 2022-06-30 21:58:03.256627
Epoch:[ 162 6 ] loss: 0.38448768854141235 2022-06-30 21:58:03.672447
Epoch:[ 162 7 ] loss: 0.3831752836704254 2022-06-30 21:58:04.088649
Epoch:[ 162 8 ] loss: 0.38696128129959106 2022-06-30 21:58:04.502830
Epoch:[ 162 9 ] loss: 0.38469499349594116 2022-06-30 21:58:04.917586
Epoch:[ 162 10 ] loss: 0.3872889280319214 2022-06-30 21:58:05.336483
Epoch:[ 162 11 ] loss: 0.3852047026157379 2022-06-30 21:58:05.750629
Epoch:[ 162 12 ] loss: 0.38541457056999207 2022-06-30 21:58:06.172929
Epoch:[ 162 13 ] loss: 0.38587912917137146 2022-06-30 21:58:06.589083
Epoch:[ 162 14 ] loss: 0.3853413164615631 2022-06-30 21:58:07.009755
Epoch:[ 162 15 ] loss: 0.3864615559577942 2022-06-30 21:58:07.425078
Epoch:[ 162 16 ] loss: 0.38387829065322876 2022-06-30 21:58:12.560060
Epoch:[ 162 17 ] loss: 0.38583672046661377 2022-06-30 21:58:12.975944
Epoch:[ 162 18 ] loss: 0.3855631649494171 2022-06-30 21:58:13.390108
Epoch:[ 162 19 ] loss: 0.3857845962047577 2022-06-30 21:58:13.806093
Training_Epoch:[ 162 ] Training_loss: 0.38513360023498533 2022-06-30 21:58:13.806724
learning rate:  0.00014073748835532815
netparams have been saved once 162
val: 1 0.47057369351387024
val: 2 0.48390084505081177
val: 3 0.47085899114608765
val: 4 0.46530681848526
val: 5 0.48284122347831726
val: 6 0.47195538878440857
val: 7 0.4728665351867676
val: 8 0.4714527428150177
val: 9 0.47377535700798035
val: 10 0.4817473590373993
val: 11 0.4859582185745239
val: 12 0.4774026572704315
val: 13 0.4739786684513092
val: 14 0.4682954251766205
val: 15 0.4628210663795471
val: 16 0.47239577770233154
val: 17 0.474700391292572
val: 18 0.48195287585258484
val: 19 0.4720815420150757
val: 20 0.4801701009273529
val_Epoch:[ 162 ] val_loss: 0.47475178390741346 2022-06-30 21:58:17.168170
start training 2022-06-30 21:58:17.268044
Epoch:[ 163 0 ] loss: 0.3829488754272461 2022-06-30 21:58:31.901189
Epoch:[ 163 1 ] loss: 0.38496729731559753 2022-06-30 21:58:32.316142
Epoch:[ 163 2 ] loss: 0.38590627908706665 2022-06-30 21:58:32.728655
Epoch:[ 163 3 ] loss: 0.3841409981250763 2022-06-30 21:58:33.144706
Epoch:[ 163 4 ] loss: 0.3868284821510315 2022-06-30 21:58:33.557594
Epoch:[ 163 5 ] loss: 0.38332995772361755 2022-06-30 21:58:33.975706
Epoch:[ 163 6 ] loss: 0.3842296600341797 2022-06-30 21:58:34.396990
Epoch:[ 163 7 ] loss: 0.38465654850006104 2022-06-30 21:58:34.811769
Epoch:[ 163 8 ] loss: 0.3862367272377014 2022-06-30 21:58:35.226008
Epoch:[ 163 9 ] loss: 0.38436776399612427 2022-06-30 21:58:35.647391
Epoch:[ 163 10 ] loss: 0.38427814841270447 2022-06-30 21:58:36.067050
Epoch:[ 163 11 ] loss: 0.3851478397846222 2022-06-30 21:58:36.480605
Epoch:[ 163 12 ] loss: 0.3841090798377991 2022-06-30 21:58:36.892788
Epoch:[ 163 13 ] loss: 0.387927383184433 2022-06-30 21:58:37.314391
Epoch:[ 163 14 ] loss: 0.38471719622612 2022-06-30 21:58:37.728889
Epoch:[ 163 15 ] loss: 0.38450509309768677 2022-06-30 21:58:38.145713
Epoch:[ 163 16 ] loss: 0.38404572010040283 2022-06-30 21:58:43.651880
Epoch:[ 163 17 ] loss: 0.38696104288101196 2022-06-30 21:58:44.063811
Epoch:[ 163 18 ] loss: 0.385903537273407 2022-06-30 21:58:44.479521
Epoch:[ 163 19 ] loss: 0.38405129313468933 2022-06-30 21:58:44.893887
Training_Epoch:[ 163 ] Training_loss: 0.38496294617652893 2022-06-30 21:58:44.894581
learning rate:  0.00014073748835532815
val: 1 0.4615169167518616
val: 2 0.4680675268173218
val: 3 0.46396806836128235
val: 4 0.4813574552536011
val: 5 0.4850074052810669
val: 6 0.47660669684410095
val: 7 0.48993822932243347
val: 8 0.48058176040649414
val: 9 0.4704959988594055
val: 10 0.4857136309146881
val: 11 0.4730550944805145
val: 12 0.46616482734680176
val: 13 0.4794253706932068
val: 14 0.4774033725261688
val: 15 0.4720798134803772
val: 16 0.4829420745372772
val: 17 0.47308576107025146
val: 18 0.4670761227607727
val: 19 0.4782702326774597
val: 20 0.4800962507724762
val_Epoch:[ 163 ] val_loss: 0.47564263045787813 2022-06-30 21:58:48.257463
start training 2022-06-30 21:58:48.360517
Epoch:[ 164 0 ] loss: 0.3844730257987976 2022-06-30 21:59:02.489802
Epoch:[ 164 1 ] loss: 0.38443222641944885 2022-06-30 21:59:02.924896
Epoch:[ 164 2 ] loss: 0.3859211802482605 2022-06-30 21:59:03.338249
Epoch:[ 164 3 ] loss: 0.3857503831386566 2022-06-30 21:59:03.751633
Epoch:[ 164 4 ] loss: 0.38442251086235046 2022-06-30 21:59:04.172821
Epoch:[ 164 5 ] loss: 0.3862054944038391 2022-06-30 21:59:04.592226
Epoch:[ 164 6 ] loss: 0.38355112075805664 2022-06-30 21:59:05.005344
Epoch:[ 164 7 ] loss: 0.38678088784217834 2022-06-30 21:59:05.422604
Epoch:[ 164 8 ] loss: 0.382906049489975 2022-06-30 21:59:05.843900
Epoch:[ 164 9 ] loss: 0.3848969042301178 2022-06-30 21:59:06.257935
Epoch:[ 164 10 ] loss: 0.38583317399024963 2022-06-30 21:59:06.670738
Epoch:[ 164 11 ] loss: 0.3849189877510071 2022-06-30 21:59:07.092090
Epoch:[ 164 12 ] loss: 0.3834872841835022 2022-06-30 21:59:07.505915
Epoch:[ 164 13 ] loss: 0.38539937138557434 2022-06-30 21:59:07.918815
Epoch:[ 164 14 ] loss: 0.3865368962287903 2022-06-30 21:59:08.333699
Epoch:[ 164 15 ] loss: 0.3825613260269165 2022-06-30 21:59:08.747986
Epoch:[ 164 16 ] loss: 0.38446831703186035 2022-06-30 21:59:14.002314
Epoch:[ 164 17 ] loss: 0.3865368664264679 2022-06-30 21:59:14.439785
Epoch:[ 164 18 ] loss: 0.383073091506958 2022-06-30 21:59:14.854733
Epoch:[ 164 19 ] loss: 0.38448989391326904 2022-06-30 21:59:15.269997
Training_Epoch:[ 164 ] Training_loss: 0.38483224958181383 2022-06-30 21:59:15.270830
learning rate:  0.00014073748835532815
netparams have been saved once 164
val: 1 0.4760403037071228
val: 2 0.47916775941848755
val: 3 0.4706602394580841
val: 4 0.4814731478691101
val: 5 0.47056204080581665
val: 6 0.4784436821937561
val: 7 0.47527697682380676
val: 8 0.46983712911605835
val: 9 0.4752826988697052
val: 10 0.48460832238197327
val: 11 0.4665946960449219
val: 12 0.4776190519332886
val: 13 0.48524028062820435
val: 14 0.4690401256084442
val: 15 0.4702080488204956
val: 16 0.4840291142463684
val: 17 0.4627494215965271
val: 18 0.4704776704311371
val: 19 0.47833263874053955
val: 20 0.48371368646621704
val_Epoch:[ 164 ] val_loss: 0.4754678517580032 2022-06-30 21:59:18.708404
start training 2022-06-30 21:59:18.811260
Epoch:[ 165 0 ] loss: 0.3851918876171112 2022-06-30 21:59:32.484776
Epoch:[ 165 1 ] loss: 0.3840373754501343 2022-06-30 21:59:32.911012
Epoch:[ 165 2 ] loss: 0.3821370601654053 2022-06-30 21:59:33.348594
Epoch:[ 165 3 ] loss: 0.38291648030281067 2022-06-30 21:59:33.764491
Epoch:[ 165 4 ] loss: 0.38664373755455017 2022-06-30 21:59:34.183333
Epoch:[ 165 5 ] loss: 0.38336384296417236 2022-06-30 21:59:34.597676
Epoch:[ 165 6 ] loss: 0.3851136565208435 2022-06-30 21:59:35.011481
Epoch:[ 165 7 ] loss: 0.38305696845054626 2022-06-30 21:59:35.432354
Epoch:[ 165 8 ] loss: 0.38376033306121826 2022-06-30 21:59:35.848527
Epoch:[ 165 9 ] loss: 0.38527533411979675 2022-06-30 21:59:36.264648
Epoch:[ 165 10 ] loss: 0.3856698274612427 2022-06-30 21:59:36.678846
Epoch:[ 165 11 ] loss: 0.38243818283081055 2022-06-30 21:59:37.094316
Epoch:[ 165 12 ] loss: 0.3840692341327667 2022-06-30 21:59:37.508642
Epoch:[ 165 13 ] loss: 0.38738664984703064 2022-06-30 21:59:37.930532
Epoch:[ 165 14 ] loss: 0.38580846786499023 2022-06-30 21:59:38.343557
Epoch:[ 165 15 ] loss: 0.38648954033851624 2022-06-30 21:59:38.760467
Epoch:[ 165 16 ] loss: 0.3847159743309021 2022-06-30 21:59:44.263111
Epoch:[ 165 17 ] loss: 0.3859182298183441 2022-06-30 21:59:44.679403
Epoch:[ 165 18 ] loss: 0.38828417658805847 2022-06-30 21:59:45.094511
Epoch:[ 165 19 ] loss: 0.38520312309265137 2022-06-30 21:59:45.509363
Training_Epoch:[ 165 ] Training_loss: 0.3848740041255951 2022-06-30 21:59:45.510050
learning rate:  0.00014073748835532815
val: 1 0.4844244718551636
val: 2 0.47906431555747986
val: 3 0.4791004955768585
val: 4 0.4697668254375458
val: 5 0.46124887466430664
val: 6 0.47884616255760193
val: 7 0.4860788881778717
val: 8 0.4775412082672119
val: 9 0.46831801533699036
val: 10 0.48025038838386536
val: 11 0.48210859298706055
val: 12 0.4872090518474579
val: 13 0.46222880482673645
val: 14 0.46469902992248535
val: 15 0.4618890583515167
val: 16 0.46560701727867126
val: 17 0.46551400423049927
val: 18 0.49019870162010193
val: 19 0.4622862637042999
val: 20 0.4763713479042053
val_Epoch:[ 165 ] val_loss: 0.47413757592439654 2022-06-30 21:59:48.883585
start training 2022-06-30 21:59:48.983477
Epoch:[ 166 0 ] loss: 0.38504937291145325 2022-06-30 22:00:03.600285
Epoch:[ 166 1 ] loss: 0.38425952196121216 2022-06-30 22:00:04.013320
Epoch:[ 166 2 ] loss: 0.38411611318588257 2022-06-30 22:00:04.428460
Epoch:[ 166 3 ] loss: 0.38549643754959106 2022-06-30 22:00:04.844240
Epoch:[ 166 4 ] loss: 0.3848429024219513 2022-06-30 22:00:05.267317
Epoch:[ 166 5 ] loss: 0.38416218757629395 2022-06-30 22:00:05.686798
Epoch:[ 166 6 ] loss: 0.3860474228858948 2022-06-30 22:00:06.100395
Epoch:[ 166 7 ] loss: 0.38555997610092163 2022-06-30 22:00:06.514752
Epoch:[ 166 8 ] loss: 0.38596251606941223 2022-06-30 22:00:06.928719
Epoch:[ 166 9 ] loss: 0.3859352469444275 2022-06-30 22:00:07.345620
Epoch:[ 166 10 ] loss: 0.3854309320449829 2022-06-30 22:00:07.760323
Epoch:[ 166 11 ] loss: 0.38401082158088684 2022-06-30 22:00:08.183333
Epoch:[ 166 12 ] loss: 0.38489067554473877 2022-06-30 22:00:08.605357
Epoch:[ 166 13 ] loss: 0.3842957317829132 2022-06-30 22:00:09.026190
Epoch:[ 166 14 ] loss: 0.3844662308692932 2022-06-30 22:00:09.439250
Epoch:[ 166 15 ] loss: 0.38533756136894226 2022-06-30 22:00:09.857476
Epoch:[ 166 16 ] loss: 0.38491764664649963 2022-06-30 22:00:15.502452
Epoch:[ 166 17 ] loss: 0.38330286741256714 2022-06-30 22:00:15.917690
Epoch:[ 166 18 ] loss: 0.3855677545070648 2022-06-30 22:00:16.332437
Epoch:[ 166 19 ] loss: 0.3844166100025177 2022-06-30 22:00:16.745925
Training_Epoch:[ 166 ] Training_loss: 0.38490342646837233 2022-06-30 22:00:16.746571
learning rate:  0.00014073748835532815
netparams have been saved once 166
val: 1 0.481955885887146
val: 2 0.4724670350551605
val: 3 0.4721646010875702
val: 4 0.4628314971923828
val: 5 0.4713819921016693
val: 6 0.4802095592021942
val: 7 0.4666244387626648
val: 8 0.4773170053958893
val: 9 0.4840555191040039
val: 10 0.47486743330955505
val: 11 0.4760793447494507
val: 12 0.4750182628631592
val: 13 0.46683040261268616
val: 14 0.4808477461338043
val: 15 0.4830772578716278
val: 16 0.4762403070926666
val: 17 0.46004992723464966
val: 18 0.48464301228523254
val: 19 0.48302704095840454
val: 20 0.4774465262889862
val_Epoch:[ 166 ] val_loss: 0.4753567397594452 2022-06-30 22:00:20.140589
start training 2022-06-30 22:00:20.237141
Epoch:[ 167 0 ] loss: 0.38374242186546326 2022-06-30 22:00:34.506429
Epoch:[ 167 1 ] loss: 0.3841928541660309 2022-06-30 22:00:34.950564
Epoch:[ 167 2 ] loss: 0.3859742283821106 2022-06-30 22:00:35.366233
Epoch:[ 167 3 ] loss: 0.3866632282733917 2022-06-30 22:00:35.781814
Epoch:[ 167 4 ] loss: 0.38553503155708313 2022-06-30 22:00:36.197702
Epoch:[ 167 5 ] loss: 0.3830564022064209 2022-06-30 22:00:36.618041
Epoch:[ 167 6 ] loss: 0.383889377117157 2022-06-30 22:00:37.033403
Epoch:[ 167 7 ] loss: 0.38514894247055054 2022-06-30 22:00:37.453937
Epoch:[ 167 8 ] loss: 0.38541486859321594 2022-06-30 22:00:37.867601
Epoch:[ 167 9 ] loss: 0.38520511984825134 2022-06-30 22:00:38.282565
Epoch:[ 167 10 ] loss: 0.38353607058525085 2022-06-30 22:00:38.702960
Epoch:[ 167 11 ] loss: 0.3862835764884949 2022-06-30 22:00:39.123142
Epoch:[ 167 12 ] loss: 0.38268205523490906 2022-06-30 22:00:39.540896
Epoch:[ 167 13 ] loss: 0.38475388288497925 2022-06-30 22:00:39.961164
Epoch:[ 167 14 ] loss: 0.3837842643260956 2022-06-30 22:00:40.376298
Epoch:[ 167 15 ] loss: 0.384047269821167 2022-06-30 22:00:40.798714
Epoch:[ 167 16 ] loss: 0.3859536647796631 2022-06-30 22:00:46.093564
Epoch:[ 167 17 ] loss: 0.3850182890892029 2022-06-30 22:00:46.509287
Epoch:[ 167 18 ] loss: 0.3840863108634949 2022-06-30 22:00:46.926105
Epoch:[ 167 19 ] loss: 0.3858773112297058 2022-06-30 22:00:47.345816
Training_Epoch:[ 167 ] Training_loss: 0.3847422584891319 2022-06-30 22:00:47.346549
learning rate:  0.00014073748835532815
val: 1 0.46359339356422424
val: 2 0.4839484691619873
val: 3 0.474223256111145
val: 4 0.4581729471683502
val: 5 0.4788225591182709
val: 6 0.4769282341003418
val: 7 0.46801134943962097
val: 8 0.47639134526252747
val: 9 0.47336292266845703
val: 10 0.4821031391620636
val: 11 0.4772109091281891
val: 12 0.46222296357154846
val: 13 0.47668376564979553
val: 14 0.48132285475730896
val: 15 0.477229505777359
val: 16 0.48411309719085693
val: 17 0.4701049029827118
val: 18 0.48545369505882263
val: 19 0.47392579913139343
val: 20 0.4584991931915283
val_Epoch:[ 167 ] val_loss: 0.47411621510982516 2022-06-30 22:00:50.716029
start training 2022-06-30 22:00:50.815142
Epoch:[ 168 0 ] loss: 0.38596054911613464 2022-06-30 22:01:05.376062
Epoch:[ 168 1 ] loss: 0.3838344216346741 2022-06-30 22:01:05.798084
Epoch:[ 168 2 ] loss: 0.3849269151687622 2022-06-30 22:01:06.214302
Epoch:[ 168 3 ] loss: 0.38440239429473877 2022-06-30 22:01:06.630962
Epoch:[ 168 4 ] loss: 0.383225679397583 2022-06-30 22:01:07.047383
Epoch:[ 168 5 ] loss: 0.3828999102115631 2022-06-30 22:01:07.465191
Epoch:[ 168 6 ] loss: 0.3851763904094696 2022-06-30 22:01:07.881884
Epoch:[ 168 7 ] loss: 0.3844452500343323 2022-06-30 22:01:08.307690
Epoch:[ 168 8 ] loss: 0.3862621486186981 2022-06-30 22:01:08.727225
Epoch:[ 168 9 ] loss: 0.38546016812324524 2022-06-30 22:01:09.147781
Epoch:[ 168 10 ] loss: 0.3853183686733246 2022-06-30 22:01:09.569057
Epoch:[ 168 11 ] loss: 0.38470855355262756 2022-06-30 22:01:09.989624
Epoch:[ 168 12 ] loss: 0.3843919336795807 2022-06-30 22:01:10.412314
Epoch:[ 168 13 ] loss: 0.386352002620697 2022-06-30 22:01:10.828605
Epoch:[ 168 14 ] loss: 0.3836863338947296 2022-06-30 22:01:11.243650
Epoch:[ 168 15 ] loss: 0.38353872299194336 2022-06-30 22:01:11.668154
Epoch:[ 168 16 ] loss: 0.3843640089035034 2022-06-30 22:01:17.016299
Epoch:[ 168 17 ] loss: 0.38688814640045166 2022-06-30 22:01:17.437980
Epoch:[ 168 18 ] loss: 0.3862868547439575 2022-06-30 22:01:17.855516
Epoch:[ 168 19 ] loss: 0.3849829435348511 2022-06-30 22:01:18.272338
Training_Epoch:[ 168 ] Training_loss: 0.3848555848002434 2022-06-30 22:01:18.273160
learning rate:  0.00014073748835532815
netparams have been saved once 168
val: 1 0.47280052304267883
val: 2 0.47901326417922974
val: 3 0.47825300693511963
val: 4 0.446850448846817
val: 5 0.4662831425666809
val: 6 0.4531577527523041
val: 7 0.4739775061607361
val: 8 0.47435590624809265
val: 9 0.4842401444911957
val: 10 0.4991156756877899
val: 11 0.4731960594654083
val: 12 0.47653403878211975
val: 13 0.47200483083724976
val: 14 0.48937636613845825
val: 15 0.4836263358592987
val: 16 0.4863877594470978
val: 17 0.47175249457359314
val: 18 0.49126505851745605
val: 19 0.4670542776584625
val: 20 0.4802013039588928
val_Epoch:[ 168 ] val_loss: 0.4759722948074341 2022-06-30 22:01:21.753052
start training 2022-06-30 22:01:21.857647
Epoch:[ 169 0 ] loss: 0.38574111461639404 2022-06-30 22:01:35.690207
Epoch:[ 169 1 ] loss: 0.385736882686615 2022-06-30 22:01:36.417369
Epoch:[ 169 2 ] loss: 0.38282862305641174 2022-06-30 22:01:36.835999
Epoch:[ 169 3 ] loss: 0.3853169083595276 2022-06-30 22:01:37.252540
Epoch:[ 169 4 ] loss: 0.3837980329990387 2022-06-30 22:01:37.666204
Epoch:[ 169 5 ] loss: 0.3836008310317993 2022-06-30 22:01:38.088272
Epoch:[ 169 6 ] loss: 0.38382819294929504 2022-06-30 22:01:38.512981
Epoch:[ 169 7 ] loss: 0.38755369186401367 2022-06-30 22:01:38.932256
Epoch:[ 169 8 ] loss: 0.38208794593811035 2022-06-30 22:01:39.350547
Epoch:[ 169 9 ] loss: 0.38636818528175354 2022-06-30 22:01:39.765871
Epoch:[ 169 10 ] loss: 0.38620564341545105 2022-06-30 22:01:40.180544
Epoch:[ 169 11 ] loss: 0.38381630182266235 2022-06-30 22:01:40.595564
Epoch:[ 169 12 ] loss: 0.38444584608078003 2022-06-30 22:01:41.012237
Epoch:[ 169 13 ] loss: 0.3855098485946655 2022-06-30 22:01:41.435511
Epoch:[ 169 14 ] loss: 0.38705432415008545 2022-06-30 22:01:41.856467
Epoch:[ 169 15 ] loss: 0.383823037147522 2022-06-30 22:01:42.272167
Epoch:[ 169 16 ] loss: 0.3831644356250763 2022-06-30 22:01:47.298548
Epoch:[ 169 17 ] loss: 0.3841157853603363 2022-06-30 22:01:48.327907
Epoch:[ 169 18 ] loss: 0.385904461145401 2022-06-30 22:01:48.763016
Epoch:[ 169 19 ] loss: 0.38372617959976196 2022-06-30 22:01:49.199021
Training_Epoch:[ 169 ] Training_loss: 0.384731313586235 2022-06-30 22:01:49.199792
learning rate:  0.00014073748835532815
val: 1 0.4597163796424866
val: 2 0.4885987937450409
val: 3 0.4731813371181488
val: 4 0.4783581495285034
val: 5 0.46701541543006897
val: 6 0.47778043150901794
val: 7 0.47281867265701294
val: 8 0.4786190986633301
val: 9 0.4730558395385742
val: 10 0.4759136736392975
val: 11 0.4642839729785919
val: 12 0.47615382075309753
val: 13 0.470559298992157
val: 14 0.4739205837249756
val: 15 0.47264888882637024
val: 16 0.48254677653312683
val: 17 0.4725729525089264
val: 18 0.4884742498397827
val: 19 0.4694894850254059
val: 20 0.4779432713985443
val_Epoch:[ 169 ] val_loss: 0.474682554602623 2022-06-30 22:01:52.625990
start training 2022-06-30 22:01:52.728155
Epoch:[ 170 0 ] loss: 0.3832620084285736 2022-06-30 22:02:07.766177
Epoch:[ 170 1 ] loss: 0.3830863833427429 2022-06-30 22:02:08.193027
Epoch:[ 170 2 ] loss: 0.3845561146736145 2022-06-30 22:02:08.609189
Epoch:[ 170 3 ] loss: 0.3839952349662781 2022-06-30 22:02:09.036705
Epoch:[ 170 4 ] loss: 0.3837752938270569 2022-06-30 22:02:09.457293
Epoch:[ 170 5 ] loss: 0.38417768478393555 2022-06-30 22:02:09.873678
Epoch:[ 170 6 ] loss: 0.3836536109447479 2022-06-30 22:02:10.289253
Epoch:[ 170 7 ] loss: 0.3838888704776764 2022-06-30 22:02:10.705263
Epoch:[ 170 8 ] loss: 0.3847910463809967 2022-06-30 22:02:11.130581
Epoch:[ 170 9 ] loss: 0.3838155269622803 2022-06-30 22:02:11.563173
Epoch:[ 170 10 ] loss: 0.38580945134162903 2022-06-30 22:02:11.995379
Epoch:[ 170 11 ] loss: 0.385652631521225 2022-06-30 22:02:12.412345
Epoch:[ 170 12 ] loss: 0.383836567401886 2022-06-30 22:02:12.845312
Epoch:[ 170 13 ] loss: 0.383171021938324 2022-06-30 22:02:13.271730
Epoch:[ 170 14 ] loss: 0.3853757679462433 2022-06-30 22:02:13.692844
Epoch:[ 170 15 ] loss: 0.38593414425849915 2022-06-30 22:02:14.109154
Epoch:[ 170 16 ] loss: 0.3872334361076355 2022-06-30 22:02:19.572272
Epoch:[ 170 17 ] loss: 0.3852043151855469 2022-06-30 22:02:19.993826
Epoch:[ 170 18 ] loss: 0.3877074122428894 2022-06-30 22:02:20.428376
Epoch:[ 170 19 ] loss: 0.3855368494987488 2022-06-30 22:02:20.852093
Training_Epoch:[ 170 ] Training_loss: 0.3847231686115265 2022-06-30 22:02:20.852857
learning rate:  0.00014073748835532815
netparams have been saved once 170
val: 1 0.48830491304397583
val: 2 0.47694718837738037
val: 3 0.4778817892074585
val: 4 0.4702487289905548
val: 5 0.4722049832344055
val: 6 0.46156126260757446
val: 7 0.4685356318950653
val: 8 0.470331609249115
val: 9 0.4699845314025879
val: 10 0.4838986396789551
val: 11 0.48082345724105835
val: 12 0.48416218161582947
val: 13 0.47491636872291565
val: 14 0.46747511625289917
val: 15 0.48451942205429077
val: 16 0.48894307017326355
val: 17 0.47011443972587585
val: 18 0.47116121649742126
val: 19 0.47065553069114685
val: 20 0.4773222804069519
val_Epoch:[ 170 ] val_loss: 0.47549961805343627 2022-06-30 22:02:24.350319
start training 2022-06-30 22:02:24.459460
Epoch:[ 171 0 ] loss: 0.3852524161338806 2022-06-30 22:02:38.171194
Epoch:[ 171 1 ] loss: 0.38519906997680664 2022-06-30 22:02:38.640282
Epoch:[ 171 2 ] loss: 0.38487935066223145 2022-06-30 22:02:39.079467
Epoch:[ 171 3 ] loss: 0.3856041729450226 2022-06-30 22:02:39.496252
Epoch:[ 171 4 ] loss: 0.3853952884674072 2022-06-30 22:02:39.905418
Epoch:[ 171 5 ] loss: 0.38127633929252625 2022-06-30 22:02:40.322330
Epoch:[ 171 6 ] loss: 0.38580331206321716 2022-06-30 22:02:40.735811
Epoch:[ 171 7 ] loss: 0.3840276300907135 2022-06-30 22:02:41.152216
Epoch:[ 171 8 ] loss: 0.38326361775398254 2022-06-30 22:02:41.566594
Epoch:[ 171 9 ] loss: 0.38597482442855835 2022-06-30 22:02:41.981270
Epoch:[ 171 10 ] loss: 0.38497915863990784 2022-06-30 22:02:42.393772
Epoch:[ 171 11 ] loss: 0.3845237195491791 2022-06-30 22:02:42.809210
Epoch:[ 171 12 ] loss: 0.38333743810653687 2022-06-30 22:02:43.229686
Epoch:[ 171 13 ] loss: 0.3834257423877716 2022-06-30 22:02:43.642380
Epoch:[ 171 14 ] loss: 0.3840416371822357 2022-06-30 22:02:44.068804
Epoch:[ 171 15 ] loss: 0.38582107424736023 2022-06-30 22:02:44.484473
Epoch:[ 171 16 ] loss: 0.38517722487449646 2022-06-30 22:02:49.989002
Epoch:[ 171 17 ] loss: 0.3854684829711914 2022-06-30 22:02:50.402195
Epoch:[ 171 18 ] loss: 0.384594589471817 2022-06-30 22:02:50.826803
Epoch:[ 171 19 ] loss: 0.3846290409564972 2022-06-30 22:02:51.242536
Training_Epoch:[ 171 ] Training_loss: 0.384633706510067 2022-06-30 22:02:51.243305
learning rate:  0.00011258999068426252
val: 1 0.47524189949035645
val: 2 0.4829849600791931
val: 3 0.4640156030654907
val: 4 0.4780777096748352
val: 5 0.4758313298225403
val: 6 0.47875669598579407
val: 7 0.46863001585006714
val: 8 0.4709497094154358
val: 9 0.4737462103366852
val: 10 0.4685397148132324
val: 11 0.4683195650577545
val: 12 0.4840996563434601
val: 13 0.47237905859947205
val: 14 0.4794166684150696
val: 15 0.4816984534263611
val: 16 0.4815363585948944
val: 17 0.471291184425354
val: 18 0.47027382254600525
val: 19 0.47549962997436523
val: 20 0.4657524824142456
val_Epoch:[ 171 ] val_loss: 0.4743520364165306 2022-06-30 22:02:54.641218
start training 2022-06-30 22:02:54.743079
Epoch:[ 172 0 ] loss: 0.3861545920372009 2022-06-30 22:03:09.303865
Epoch:[ 172 1 ] loss: 0.3827914893627167 2022-06-30 22:03:09.718734
Epoch:[ 172 2 ] loss: 0.386382132768631 2022-06-30 22:03:10.134701
Epoch:[ 172 3 ] loss: 0.38232600688934326 2022-06-30 22:03:10.552819
Epoch:[ 172 4 ] loss: 0.3841429352760315 2022-06-30 22:03:10.965572
Epoch:[ 172 5 ] loss: 0.38240742683410645 2022-06-30 22:03:11.380529
Epoch:[ 172 6 ] loss: 0.38400596380233765 2022-06-30 22:03:11.800427
Epoch:[ 172 7 ] loss: 0.3861127197742462 2022-06-30 22:03:12.216824
Epoch:[ 172 8 ] loss: 0.3855428695678711 2022-06-30 22:03:12.632199
Epoch:[ 172 9 ] loss: 0.3837624788284302 2022-06-30 22:03:13.047064
Epoch:[ 172 10 ] loss: 0.38487163186073303 2022-06-30 22:03:13.461621
Epoch:[ 172 11 ] loss: 0.38619014620780945 2022-06-30 22:03:13.876377
Epoch:[ 172 12 ] loss: 0.3851866126060486 2022-06-30 22:03:14.295387
Epoch:[ 172 13 ] loss: 0.384918212890625 2022-06-30 22:03:14.714437
Epoch:[ 172 14 ] loss: 0.3817625045776367 2022-06-30 22:03:15.133315
Epoch:[ 172 15 ] loss: 0.38449421525001526 2022-06-30 22:03:15.549993
Epoch:[ 172 16 ] loss: 0.3829648196697235 2022-06-30 22:03:20.941868
Epoch:[ 172 17 ] loss: 0.3817286789417267 2022-06-30 22:03:21.356510
Epoch:[ 172 18 ] loss: 0.3824906051158905 2022-06-30 22:03:21.771775
Epoch:[ 172 19 ] loss: 0.38458308577537537 2022-06-30 22:03:22.186446
Training_Epoch:[ 172 ] Training_loss: 0.38414095640182494 2022-06-30 22:03:22.187067
learning rate:  0.00011258999068426252
netparams have been saved once 172
val: 1 0.4770072102546692
val: 2 0.4857563376426697
val: 3 0.4799768924713135
val: 4 0.48051324486732483
val: 5 0.46868032217025757
val: 6 0.473715603351593
val: 7 0.4670414626598358
val: 8 0.4855301082134247
val: 9 0.48582974076271057
val: 10 0.4733083248138428
val: 11 0.4743631184101105
val: 12 0.45898008346557617
val: 13 0.47319653630256653
val: 14 0.4643020033836365
val: 15 0.47176453471183777
val: 16 0.48010414838790894
val: 17 0.464882493019104
val: 18 0.473486989736557
val: 19 0.49158382415771484
val: 20 0.48471054434776306
val_Epoch:[ 172 ] val_loss: 0.4757366761565208 2022-06-30 22:03:25.595275
start training 2022-06-30 22:03:25.692827
Epoch:[ 173 0 ] loss: 0.3841199278831482 2022-06-30 22:03:39.821069
Epoch:[ 173 1 ] loss: 0.3833928108215332 2022-06-30 22:03:40.298824
Epoch:[ 173 2 ] loss: 0.3830006420612335 2022-06-30 22:03:40.714128
Epoch:[ 173 3 ] loss: 0.3838476240634918 2022-06-30 22:03:41.128788
Epoch:[ 173 4 ] loss: 0.38362887501716614 2022-06-30 22:03:41.544275
Epoch:[ 173 5 ] loss: 0.3827767074108124 2022-06-30 22:03:41.958297
Epoch:[ 173 6 ] loss: 0.38320592045783997 2022-06-30 22:03:42.372632
Epoch:[ 173 7 ] loss: 0.38277459144592285 2022-06-30 22:03:42.795523
Epoch:[ 173 8 ] loss: 0.3850484788417816 2022-06-30 22:03:43.215325
Epoch:[ 173 9 ] loss: 0.3824653923511505 2022-06-30 22:03:43.631465
Epoch:[ 173 10 ] loss: 0.38490933179855347 2022-06-30 22:03:44.051948
Epoch:[ 173 11 ] loss: 0.38605156540870667 2022-06-30 22:03:44.474817
Epoch:[ 173 12 ] loss: 0.385554701089859 2022-06-30 22:03:44.888875
Epoch:[ 173 13 ] loss: 0.38283103704452515 2022-06-30 22:03:45.303499
Epoch:[ 173 14 ] loss: 0.38259047269821167 2022-06-30 22:03:45.717396
Epoch:[ 173 15 ] loss: 0.3845268487930298 2022-06-30 22:03:46.134837
Epoch:[ 173 16 ] loss: 0.3839542865753174 2022-06-30 22:03:51.701080
Epoch:[ 173 17 ] loss: 0.3852022886276245 2022-06-30 22:03:52.251174
Epoch:[ 173 18 ] loss: 0.3846512734889984 2022-06-30 22:03:52.667167
Epoch:[ 173 19 ] loss: 0.3819102942943573 2022-06-30 22:03:53.082492
Training_Epoch:[ 173 ] Training_loss: 0.38382215350866317 2022-06-30 22:03:53.083217
learning rate:  0.00011258999068426252
val: 1 0.46747952699661255
val: 2 0.48765695095062256
val: 3 0.4683986008167267
val: 4 0.4782167375087738
val: 5 0.4711452126502991
val: 6 0.4627242684364319
val: 7 0.4704253673553467
val: 8 0.48841777443885803
val: 9 0.4822269380092621
val: 10 0.46676167845726013
val: 11 0.4795067608356476
val: 12 0.491904616355896
val: 13 0.4699418842792511
val: 14 0.46379202604293823
val: 15 0.4854482114315033
val: 16 0.4744212329387665
val: 17 0.4884222149848938
val: 18 0.48160412907600403
val: 19 0.47319263219833374
val: 20 0.4699077010154724
val_Epoch:[ 173 ] val_loss: 0.476079723238945 2022-06-30 22:03:56.461426
start training 2022-06-30 22:03:56.562880
Epoch:[ 174 0 ] loss: 0.38139230012893677 2022-06-30 22:04:10.796427
Epoch:[ 174 1 ] loss: 0.38432180881500244 2022-06-30 22:04:11.215646
Epoch:[ 174 2 ] loss: 0.3854907155036926 2022-06-30 22:04:11.628409
Epoch:[ 174 3 ] loss: 0.3850134015083313 2022-06-30 22:04:12.051581
Epoch:[ 174 4 ] loss: 0.38339853286743164 2022-06-30 22:04:12.469046
Epoch:[ 174 5 ] loss: 0.3848051428794861 2022-06-30 22:04:12.884651
Epoch:[ 174 6 ] loss: 0.3846360743045807 2022-06-30 22:04:13.297758
Epoch:[ 174 7 ] loss: 0.381646990776062 2022-06-30 22:04:13.719461
Epoch:[ 174 8 ] loss: 0.383674293756485 2022-06-30 22:04:14.133734
Epoch:[ 174 9 ] loss: 0.38202619552612305 2022-06-30 22:04:14.549334
Epoch:[ 174 10 ] loss: 0.3838669955730438 2022-06-30 22:04:14.970810
Epoch:[ 174 11 ] loss: 0.38256993889808655 2022-06-30 22:04:15.393524
Epoch:[ 174 12 ] loss: 0.3849399983882904 2022-06-30 22:04:15.808797
Epoch:[ 174 13 ] loss: 0.38506871461868286 2022-06-30 22:04:16.229754
Epoch:[ 174 14 ] loss: 0.38299453258514404 2022-06-30 22:04:16.645306
Epoch:[ 174 15 ] loss: 0.382639616727829 2022-06-30 22:04:17.059171
Epoch:[ 174 16 ] loss: 0.38332730531692505 2022-06-30 22:04:22.428680
Epoch:[ 174 17 ] loss: 0.3846622705459595 2022-06-30 22:04:22.845320
Epoch:[ 174 18 ] loss: 0.38480237126350403 2022-06-30 22:04:23.262798
Epoch:[ 174 19 ] loss: 0.3814658224582672 2022-06-30 22:04:23.681260
Training_Epoch:[ 174 ] Training_loss: 0.3836371511220932 2022-06-30 22:04:23.682188
learning rate:  0.00011258999068426252
netparams have been saved once 174
val: 1 0.47279059886932373
val: 2 0.4814876317977905
val: 3 0.47497886419296265
val: 4 0.4770294427871704
val: 5 0.48174768686294556
val: 6 0.4615658223628998
val: 7 0.48536527156829834
val: 8 0.47708791494369507
val: 9 0.47592735290527344
val: 10 0.4525696337223053
val: 11 0.4809151589870453
val: 12 0.4658684730529785
val: 13 0.467151939868927
val: 14 0.4728899598121643
val: 15 0.47341567277908325
val: 16 0.4585413336753845
val: 17 0.4743517339229584
val: 18 0.4877534508705139
val: 19 0.48781314492225647
val: 20 0.4787420928478241
val_Epoch:[ 174 ] val_loss: 0.47439965903759 2022-06-30 22:04:27.096289
start training 2022-06-30 22:04:27.197557
Epoch:[ 175 0 ] loss: 0.38181644678115845 2022-06-30 22:04:40.806710
Epoch:[ 175 1 ] loss: 0.3829840123653412 2022-06-30 22:04:41.247739
Epoch:[ 175 2 ] loss: 0.3838450312614441 2022-06-30 22:04:41.680518
Epoch:[ 175 3 ] loss: 0.3841443359851837 2022-06-30 22:04:42.101224
Epoch:[ 175 4 ] loss: 0.3816329836845398 2022-06-30 22:04:42.518351
Epoch:[ 175 5 ] loss: 0.38506442308425903 2022-06-30 22:04:42.934444
Epoch:[ 175 6 ] loss: 0.3844108283519745 2022-06-30 22:04:43.349482
Epoch:[ 175 7 ] loss: 0.3824065327644348 2022-06-30 22:04:43.764958
Epoch:[ 175 8 ] loss: 0.3840528130531311 2022-06-30 22:04:44.183936
Epoch:[ 175 9 ] loss: 0.3843333423137665 2022-06-30 22:04:44.596263
Epoch:[ 175 10 ] loss: 0.38541415333747864 2022-06-30 22:04:45.009420
Epoch:[ 175 11 ] loss: 0.383870929479599 2022-06-30 22:04:45.432853
Epoch:[ 175 12 ] loss: 0.38438355922698975 2022-06-30 22:04:45.848614
Epoch:[ 175 13 ] loss: 0.38481807708740234 2022-06-30 22:04:46.265047
Epoch:[ 175 14 ] loss: 0.38311702013015747 2022-06-30 22:04:46.678637
Epoch:[ 175 15 ] loss: 0.38340458273887634 2022-06-30 22:04:47.094425
Epoch:[ 175 16 ] loss: 0.38404762744903564 2022-06-30 22:04:53.136643
Epoch:[ 175 17 ] loss: 0.38401445746421814 2022-06-30 22:04:53.551652
Epoch:[ 175 18 ] loss: 0.38355764746665955 2022-06-30 22:04:53.968887
Epoch:[ 175 19 ] loss: 0.38315820693969727 2022-06-30 22:04:54.384869
Training_Epoch:[ 175 ] Training_loss: 0.38372385054826735 2022-06-30 22:04:54.385605
learning rate:  0.00011258999068426252
val: 1 0.4688057601451874
val: 2 0.47222238779067993
val: 3 0.4771822988986969
val: 4 0.4850179851055145
val: 5 0.4695815145969391
val: 6 0.4726223945617676
val: 7 0.4831414520740509
val: 8 0.4877694845199585
val: 9 0.47772273421287537
val: 10 0.4817158281803131
val: 11 0.4726915955543518
val: 12 0.4918798804283142
val: 13 0.48106423020362854
val: 14 0.4706292152404785
val: 15 0.47493934631347656
val: 16 0.4699464738368988
val: 17 0.4772869050502777
val: 18 0.48493269085884094
val: 19 0.4612673223018646
val: 20 0.4658041000366211
val_Epoch:[ 175 ] val_loss: 0.4763111799955368 2022-06-30 22:04:57.734479
start training 2022-06-30 22:04:57.833398
Epoch:[ 176 0 ] loss: 0.38323891162872314 2022-06-30 22:05:12.364812
Epoch:[ 176 1 ] loss: 0.3831779658794403 2022-06-30 22:05:12.778282
Epoch:[ 176 2 ] loss: 0.3841190040111542 2022-06-30 22:05:13.192131
Epoch:[ 176 3 ] loss: 0.38284218311309814 2022-06-30 22:05:13.606609
Epoch:[ 176 4 ] loss: 0.383855938911438 2022-06-30 22:05:14.019497
Epoch:[ 176 5 ] loss: 0.384091854095459 2022-06-30 22:05:14.435419
Epoch:[ 176 6 ] loss: 0.3833250403404236 2022-06-30 22:05:14.851056
Epoch:[ 176 7 ] loss: 0.3841831088066101 2022-06-30 22:05:15.267754
Epoch:[ 176 8 ] loss: 0.3837837278842926 2022-06-30 22:05:15.681877
Epoch:[ 176 9 ] loss: 0.38236188888549805 2022-06-30 22:05:16.101742
Epoch:[ 176 10 ] loss: 0.3831831216812134 2022-06-30 22:05:16.521874
Epoch:[ 176 11 ] loss: 0.3821980059146881 2022-06-30 22:05:16.935855
Epoch:[ 176 12 ] loss: 0.38516655564308167 2022-06-30 22:05:17.358699
Epoch:[ 176 13 ] loss: 0.38280147314071655 2022-06-30 22:05:17.774720
Epoch:[ 176 14 ] loss: 0.3841803967952728 2022-06-30 22:05:18.189289
Epoch:[ 176 15 ] loss: 0.38528499007225037 2022-06-30 22:05:18.610526
Epoch:[ 176 16 ] loss: 0.38522738218307495 2022-06-30 22:05:24.208196
Epoch:[ 176 17 ] loss: 0.38294461369514465 2022-06-30 22:05:24.620914
Epoch:[ 176 18 ] loss: 0.3846607208251953 2022-06-30 22:05:25.043219
Epoch:[ 176 19 ] loss: 0.38432446122169495 2022-06-30 22:05:25.459430
Training_Epoch:[ 176 ] Training_loss: 0.3837475672364235 2022-06-30 22:05:25.460082
learning rate:  0.00011258999068426252
netparams have been saved once 176
val: 1 0.47056421637535095
val: 2 0.4791393280029297
val: 3 0.4821367561817169
val: 4 0.45982232689857483
val: 5 0.4751722514629364
val: 6 0.4770873785018921
val: 7 0.4733365476131439
val: 8 0.47974157333374023
val: 9 0.4689486622810364
val: 10 0.4734557271003723
val: 11 0.4796922504901886
val: 12 0.4710368514060974
val: 13 0.48480045795440674
val: 14 0.4878198802471161
val: 15 0.4768190085887909
val: 16 0.4913659393787384
val: 17 0.4607228934764862
val: 18 0.47371333837509155
val: 19 0.48289164900779724
val: 20 0.48464253544807434
val_Epoch:[ 176 ] val_loss: 0.4766454786062241 2022-06-30 22:05:28.920780
start training 2022-06-30 22:05:29.018681
Epoch:[ 177 0 ] loss: 0.38394901156425476 2022-06-30 22:05:43.084155
Epoch:[ 177 1 ] loss: 0.3844071924686432 2022-06-30 22:05:43.668432
Epoch:[ 177 2 ] loss: 0.38384637236595154 2022-06-30 22:05:44.087862
Epoch:[ 177 3 ] loss: 0.3851203918457031 2022-06-30 22:05:44.503998
Epoch:[ 177 4 ] loss: 0.3816267251968384 2022-06-30 22:05:44.917373
Epoch:[ 177 5 ] loss: 0.38412684202194214 2022-06-30 22:05:45.331235
Epoch:[ 177 6 ] loss: 0.38225337862968445 2022-06-30 22:05:45.752180
Epoch:[ 177 7 ] loss: 0.38381892442703247 2022-06-30 22:05:46.167825
Epoch:[ 177 8 ] loss: 0.38316527009010315 2022-06-30 22:05:46.584780
Epoch:[ 177 9 ] loss: 0.38354143500328064 2022-06-30 22:05:46.998274
Epoch:[ 177 10 ] loss: 0.38346970081329346 2022-06-30 22:05:47.413728
Epoch:[ 177 11 ] loss: 0.3842029571533203 2022-06-30 22:05:47.828442
Epoch:[ 177 12 ] loss: 0.38415369391441345 2022-06-30 22:05:48.241183
Epoch:[ 177 13 ] loss: 0.38587242364883423 2022-06-30 22:05:48.657076
Epoch:[ 177 14 ] loss: 0.38325321674346924 2022-06-30 22:05:49.078665
Epoch:[ 177 15 ] loss: 0.38408783078193665 2022-06-30 22:05:49.500134
Epoch:[ 177 16 ] loss: 0.3797219395637512 2022-06-30 22:05:55.016147
Epoch:[ 177 17 ] loss: 0.38309746980667114 2022-06-30 22:05:55.430569
Epoch:[ 177 18 ] loss: 0.38215962052345276 2022-06-30 22:05:55.844112
Epoch:[ 177 19 ] loss: 0.38275420665740967 2022-06-30 22:05:56.257755
Training_Epoch:[ 177 ] Training_loss: 0.3834314301609993 2022-06-30 22:05:56.258445
learning rate:  0.00011258999068426252
val: 1 0.474195659160614
val: 2 0.47072064876556396
val: 3 0.4798656404018402
val: 4 0.4774901270866394
val: 5 0.47539079189300537
val: 6 0.47761815786361694
val: 7 0.46227994561195374
val: 8 0.4811088442802429
val: 9 0.4701381027698517
val: 10 0.4921676218509674
val: 11 0.45961064100265503
val: 12 0.47095757722854614
val: 13 0.4634895622730255
val: 14 0.47515761852264404
val: 15 0.47611284255981445
val: 16 0.4740619361400604
val: 17 0.47524791955947876
val: 18 0.48244577646255493
val: 19 0.475436806678772
val: 20 0.48285049200057983
val_Epoch:[ 177 ] val_loss: 0.47481733560562134 2022-06-30 22:05:59.633687
start training 2022-06-30 22:05:59.734142
Epoch:[ 178 0 ] loss: 0.38109713792800903 2022-06-30 22:06:13.755541
Epoch:[ 178 1 ] loss: 0.38258591294288635 2022-06-30 22:06:14.171009
Epoch:[ 178 2 ] loss: 0.38327789306640625 2022-06-30 22:06:14.585524
Epoch:[ 178 3 ] loss: 0.3840433359146118 2022-06-30 22:06:15.000740
Epoch:[ 178 4 ] loss: 0.3835096061229706 2022-06-30 22:06:15.421308
Epoch:[ 178 5 ] loss: 0.3835660219192505 2022-06-30 22:06:15.835170
Epoch:[ 178 6 ] loss: 0.3828020989894867 2022-06-30 22:06:16.248371
Epoch:[ 178 7 ] loss: 0.38142573833465576 2022-06-30 22:06:16.664994
Epoch:[ 178 8 ] loss: 0.38473594188690186 2022-06-30 22:06:17.080621
Epoch:[ 178 9 ] loss: 0.384744256734848 2022-06-30 22:06:17.495567
Epoch:[ 178 10 ] loss: 0.38594990968704224 2022-06-30 22:06:17.916073
Epoch:[ 178 11 ] loss: 0.38219282031059265 2022-06-30 22:06:18.331997
Epoch:[ 178 12 ] loss: 0.383907288312912 2022-06-30 22:06:18.754571
Epoch:[ 178 13 ] loss: 0.38251668214797974 2022-06-30 22:06:19.169443
Epoch:[ 178 14 ] loss: 0.38251805305480957 2022-06-30 22:06:19.591136
Epoch:[ 178 15 ] loss: 0.3838692903518677 2022-06-30 22:06:20.007001
Epoch:[ 178 16 ] loss: 0.3844396770000458 2022-06-30 22:06:25.262762
Epoch:[ 178 17 ] loss: 0.3823789954185486 2022-06-30 22:06:25.676558
Epoch:[ 178 18 ] loss: 0.3841184973716736 2022-06-30 22:06:26.281937
Epoch:[ 178 19 ] loss: 0.3840341567993164 2022-06-30 22:06:26.698192
Training_Epoch:[ 178 ] Training_loss: 0.38338566571474075 2022-06-30 22:06:26.698875
learning rate:  0.00011258999068426252
netparams have been saved once 178
val: 1 0.4799174666404724
val: 2 0.47893959283828735
val: 3 0.48238882422447205
val: 4 0.4640536308288574
val: 5 0.47070804238319397
val: 6 0.46265071630477905
val: 7 0.4847039580345154
val: 8 0.46162641048431396
val: 9 0.4740689992904663
val: 10 0.49046841263771057
val: 11 0.4701431691646576
val: 12 0.46672701835632324
val: 13 0.4772353768348694
val: 14 0.4818413257598877
val: 15 0.47561347484588623
val: 16 0.4798599183559418
val: 17 0.4951178729534149
val: 18 0.4677542448043823
val: 19 0.4757573902606964
val: 20 0.4847447872161865
val_Epoch:[ 178 ] val_loss: 0.4762160316109657 2022-06-30 22:06:30.094642
start training 2022-06-30 22:06:30.193563
Epoch:[ 179 0 ] loss: 0.3820403516292572 2022-06-30 22:06:44.154671
Epoch:[ 179 1 ] loss: 0.38324904441833496 2022-06-30 22:06:44.598640
Epoch:[ 179 2 ] loss: 0.3841592073440552 2022-06-30 22:06:45.020065
Epoch:[ 179 3 ] loss: 0.38248586654663086 2022-06-30 22:06:45.439082
Epoch:[ 179 4 ] loss: 0.38335323333740234 2022-06-30 22:06:45.852357
Epoch:[ 179 5 ] loss: 0.38219454884529114 2022-06-30 22:06:46.275891
Epoch:[ 179 6 ] loss: 0.3828214704990387 2022-06-30 22:06:46.689516
Epoch:[ 179 7 ] loss: 0.3827592432498932 2022-06-30 22:06:47.109971
Epoch:[ 179 8 ] loss: 0.38511818647384644 2022-06-30 22:06:47.525245
Epoch:[ 179 9 ] loss: 0.38274750113487244 2022-06-30 22:06:47.940350
Epoch:[ 179 10 ] loss: 0.3828256130218506 2022-06-30 22:06:48.360827
Epoch:[ 179 11 ] loss: 0.38016214966773987 2022-06-30 22:06:48.774957
Epoch:[ 179 12 ] loss: 0.38407090306282043 2022-06-30 22:06:49.190833
Epoch:[ 179 13 ] loss: 0.38370102643966675 2022-06-30 22:06:49.604381
Epoch:[ 179 14 ] loss: 0.38279637694358826 2022-06-30 22:06:50.017253
Epoch:[ 179 15 ] loss: 0.38151341676712036 2022-06-30 22:06:50.433522
Epoch:[ 179 16 ] loss: 0.38408198952674866 2022-06-30 22:06:55.745173
Epoch:[ 179 17 ] loss: 0.38347548246383667 2022-06-30 22:06:56.159379
Epoch:[ 179 18 ] loss: 0.3857903778553009 2022-06-30 22:06:56.579717
Epoch:[ 179 19 ] loss: 0.38699108362197876 2022-06-30 22:06:56.994491
Training_Epoch:[ 179 ] Training_loss: 0.3833168536424637 2022-06-30 22:06:56.995172
learning rate:  0.00011258999068426252
val: 1 0.46620169281959534
val: 2 0.4801481068134308
val: 3 0.48018115758895874
val: 4 0.4879249632358551
val: 5 0.47557592391967773
val: 6 0.4729989171028137
val: 7 0.4953772723674774
val: 8 0.47544655203819275
val: 9 0.4536992609500885
val: 10 0.48707085847854614
val: 11 0.46751323342323303
val: 12 0.49066027998924255
val: 13 0.473984032869339
val: 14 0.485853910446167
val: 15 0.48976799845695496
val: 16 0.47602319717407227
val: 17 0.46637848019599915
val: 18 0.473445862531662
val: 19 0.44844698905944824
val: 20 0.47280165553092957
val_Epoch:[ 179 ] val_loss: 0.4759750172495842 2022-06-30 22:07:00.337616
start training 2022-06-30 22:07:00.436221
Epoch:[ 180 0 ] loss: 0.3835495710372925 2022-06-30 22:07:14.963822
Epoch:[ 180 1 ] loss: 0.3824997842311859 2022-06-30 22:07:15.376842
Epoch:[ 180 2 ] loss: 0.38302767276763916 2022-06-30 22:07:15.793226
Epoch:[ 180 3 ] loss: 0.38215580582618713 2022-06-30 22:07:16.209743
Epoch:[ 180 4 ] loss: 0.38084876537323 2022-06-30 22:07:16.633759
Epoch:[ 180 5 ] loss: 0.382536917924881 2022-06-30 22:07:17.047801
Epoch:[ 180 6 ] loss: 0.38299480080604553 2022-06-30 22:07:17.462265
Epoch:[ 180 7 ] loss: 0.3814909756183624 2022-06-30 22:07:17.884869
Epoch:[ 180 8 ] loss: 0.3843420147895813 2022-06-30 22:07:18.303694
Epoch:[ 180 9 ] loss: 0.3853268325328827 2022-06-30 22:07:18.720117
Epoch:[ 180 10 ] loss: 0.3827977776527405 2022-06-30 22:07:19.136039
Epoch:[ 180 11 ] loss: 0.3804074823856354 2022-06-30 22:07:19.553730
Epoch:[ 180 12 ] loss: 0.3842465579509735 2022-06-30 22:07:19.968410
Epoch:[ 180 13 ] loss: 0.3841339349746704 2022-06-30 22:07:20.383688
Epoch:[ 180 14 ] loss: 0.3811802268028259 2022-06-30 22:07:20.803758
Epoch:[ 180 15 ] loss: 0.3826039731502533 2022-06-30 22:07:21.218021
Epoch:[ 180 16 ] loss: 0.38477790355682373 2022-06-30 22:07:26.667381
Epoch:[ 180 17 ] loss: 0.3857300579547882 2022-06-30 22:07:27.082727
Epoch:[ 180 18 ] loss: 0.38438135385513306 2022-06-30 22:07:27.500531
Epoch:[ 180 19 ] loss: 0.3826369047164917 2022-06-30 22:07:27.915437
Training_Epoch:[ 180 ] Training_loss: 0.38308346569538115 2022-06-30 22:07:27.916087
learning rate:  0.00011258999068426252
netparams have been saved once 180
val: 1 0.4805923402309418
val: 2 0.4689261317253113
val: 3 0.4680405557155609
val: 4 0.4818423092365265
val: 5 0.4634419083595276
val: 6 0.4823342561721802
val: 7 0.4704383313655853
val: 8 0.47772055864334106
val: 9 0.47054165601730347
val: 10 0.4657594859600067
val: 11 0.4858607351779938
val: 12 0.4723132848739624
val: 13 0.4764883816242218
val: 14 0.4694235920906067
val: 15 0.47404944896698
val: 16 0.4692938029766083
val: 17 0.4923575222492218
val: 18 0.4878992438316345
val: 19 0.47923004627227783
val: 20 0.4934292733669281
val_Epoch:[ 180 ] val_loss: 0.476499143242836 2022-06-30 22:07:31.317673
start training 2022-06-30 22:07:31.417814
Epoch:[ 181 0 ] loss: 0.3825634717941284 2022-06-30 22:07:45.053097
Epoch:[ 181 1 ] loss: 0.38291916251182556 2022-06-30 22:07:45.500281
Epoch:[ 181 2 ] loss: 0.38217630982398987 2022-06-30 22:07:46.065130
Epoch:[ 181 3 ] loss: 0.3826359808444977 2022-06-30 22:07:46.480968
Epoch:[ 181 4 ] loss: 0.3834556043148041 2022-06-30 22:07:46.897030
Epoch:[ 181 5 ] loss: 0.38241106271743774 2022-06-30 22:07:47.314788
Epoch:[ 181 6 ] loss: 0.38361427187919617 2022-06-30 22:07:47.728186
Epoch:[ 181 7 ] loss: 0.38449347019195557 2022-06-30 22:07:48.143598
Epoch:[ 181 8 ] loss: 0.38288140296936035 2022-06-30 22:07:48.565909
Epoch:[ 181 9 ] loss: 0.3832908570766449 2022-06-30 22:07:48.979250
Epoch:[ 181 10 ] loss: 0.38311728835105896 2022-06-30 22:07:49.393825
Epoch:[ 181 11 ] loss: 0.38410550355911255 2022-06-30 22:07:49.809358
Epoch:[ 181 12 ] loss: 0.38101208209991455 2022-06-30 22:07:50.225434
Epoch:[ 181 13 ] loss: 0.3837653398513794 2022-06-30 22:07:50.638234
Epoch:[ 181 14 ] loss: 0.3820139467716217 2022-06-30 22:07:51.056678
Epoch:[ 181 15 ] loss: 0.3834333121776581 2022-06-30 22:07:51.472852
Epoch:[ 181 16 ] loss: 0.38455769419670105 2022-06-30 22:07:56.855667
Epoch:[ 181 17 ] loss: 0.38079503178596497 2022-06-30 22:07:57.271474
Epoch:[ 181 18 ] loss: 0.38216570019721985 2022-06-30 22:07:57.945850
Epoch:[ 181 19 ] loss: 0.3815728724002838 2022-06-30 22:07:58.361273
Training_Epoch:[ 181 ] Training_loss: 0.38284901827573775 2022-06-30 22:07:58.362119
learning rate:  9.007199254741002e-05
val: 1 0.4663039445877075
val: 2 0.47177019715309143
val: 3 0.4747527539730072
val: 4 0.4905347526073456
val: 5 0.46976298093795776
val: 6 0.48174411058425903
val: 7 0.47493961453437805
val: 8 0.469516396522522
val: 9 0.4760093092918396
val: 10 0.47095179557800293
val: 11 0.47478097677230835
val: 12 0.46499499678611755
val: 13 0.47551679611206055
val: 14 0.4901222586631775
val: 15 0.4673042595386505
val: 16 0.4773099422454834
val: 17 0.484955757856369
val: 18 0.4604863226413727
val: 19 0.4800664186477661
val: 20 0.4908551871776581
val_Epoch:[ 181 ] val_loss: 0.47563393861055375 2022-06-30 22:08:01.720806
start training 2022-06-30 22:08:01.819411
Epoch:[ 182 0 ] loss: 0.38365283608436584 2022-06-30 22:08:15.920103
Epoch:[ 182 1 ] loss: 0.38377076387405396 2022-06-30 22:08:16.350981
Epoch:[ 182 2 ] loss: 0.3833659291267395 2022-06-30 22:08:16.763582
Epoch:[ 182 3 ] loss: 0.3819703459739685 2022-06-30 22:08:17.183561
Epoch:[ 182 4 ] loss: 0.382279634475708 2022-06-30 22:08:17.598727
Epoch:[ 182 5 ] loss: 0.38097551465034485 2022-06-30 22:08:18.014898
Epoch:[ 182 6 ] loss: 0.38193610310554504 2022-06-30 22:08:18.429834
Epoch:[ 182 7 ] loss: 0.3817828595638275 2022-06-30 22:08:18.844934
Epoch:[ 182 8 ] loss: 0.3822747468948364 2022-06-30 22:08:19.258794
Epoch:[ 182 9 ] loss: 0.3817357122898102 2022-06-30 22:08:19.671892
Epoch:[ 182 10 ] loss: 0.38265910744667053 2022-06-30 22:08:20.084826
Epoch:[ 182 11 ] loss: 0.3818509876728058 2022-06-30 22:08:20.506344
Epoch:[ 182 12 ] loss: 0.38326382637023926 2022-06-30 22:08:20.922200
Epoch:[ 182 13 ] loss: 0.38413283228874207 2022-06-30 22:08:21.337106
Epoch:[ 182 14 ] loss: 0.38123783469200134 2022-06-30 22:08:21.756614
Epoch:[ 182 15 ] loss: 0.38394293189048767 2022-06-30 22:08:22.178398
Epoch:[ 182 16 ] loss: 0.3843362629413605 2022-06-30 22:08:27.325797
Epoch:[ 182 17 ] loss: 0.38276809453964233 2022-06-30 22:08:27.913015
Epoch:[ 182 18 ] loss: 0.3825646638870239 2022-06-30 22:08:28.327629
Epoch:[ 182 19 ] loss: 0.38293829560279846 2022-06-30 22:08:28.744552
Training_Epoch:[ 182 ] Training_loss: 0.3826719641685486 2022-06-30 22:08:28.745153
learning rate:  9.007199254741002e-05
netparams have been saved once 182
val: 1 0.4841616749763489
val: 2 0.46886077523231506
val: 3 0.46803489327430725
val: 4 0.4796909689903259
val: 5 0.4779662787914276
val: 6 0.475504994392395
val: 7 0.47621679306030273
val: 8 0.4759666323661804
val: 9 0.487846314907074
val: 10 0.48104044795036316
val: 11 0.4862379729747772
val: 12 0.48425906896591187
val: 13 0.4844076633453369
val: 14 0.4812348484992981
val: 15 0.4676397442817688
val: 16 0.48021286725997925
val: 17 0.46109795570373535
val: 18 0.46306848526000977
val: 19 0.4833971858024597
val: 20 0.4650972783565521
val_Epoch:[ 182 ] val_loss: 0.47659714221954347 2022-06-30 22:08:32.128254
start training 2022-06-30 22:08:32.225498
Epoch:[ 183 0 ] loss: 0.3834312856197357 2022-06-30 22:08:46.132350
Epoch:[ 183 1 ] loss: 0.3826392889022827 2022-06-30 22:08:46.656723
Epoch:[ 183 2 ] loss: 0.3828376531600952 2022-06-30 22:08:47.076916
Epoch:[ 183 3 ] loss: 0.38302212953567505 2022-06-30 22:08:47.494845
Epoch:[ 183 4 ] loss: 0.3830536901950836 2022-06-30 22:08:47.908971
Epoch:[ 183 5 ] loss: 0.38346895575523376 2022-06-30 22:08:48.331385
Epoch:[ 183 6 ] loss: 0.38284820318222046 2022-06-30 22:08:48.750720
Epoch:[ 183 7 ] loss: 0.38250166177749634 2022-06-30 22:08:49.166749
Epoch:[ 183 8 ] loss: 0.38196760416030884 2022-06-30 22:08:49.580874
Epoch:[ 183 9 ] loss: 0.3824861943721771 2022-06-30 22:08:49.996031
Epoch:[ 183 10 ] loss: 0.3798886239528656 2022-06-30 22:08:50.409170
Epoch:[ 183 11 ] loss: 0.3817899525165558 2022-06-30 22:08:50.824095
Epoch:[ 183 12 ] loss: 0.3838377594947815 2022-06-30 22:08:51.246149
Epoch:[ 183 13 ] loss: 0.38158977031707764 2022-06-30 22:08:51.663108
Epoch:[ 183 14 ] loss: 0.38327234983444214 2022-06-30 22:08:52.079528
Epoch:[ 183 15 ] loss: 0.3837463855743408 2022-06-30 22:08:52.495078
Epoch:[ 183 16 ] loss: 0.38337287306785583 2022-06-30 22:08:58.280822
Epoch:[ 183 17 ] loss: 0.38330331444740295 2022-06-30 22:08:58.696821
Epoch:[ 183 18 ] loss: 0.38280344009399414 2022-06-30 22:08:59.111718
Epoch:[ 183 19 ] loss: 0.38300174474716187 2022-06-30 22:08:59.529007
Training_Epoch:[ 183 ] Training_loss: 0.3827431440353394 2022-06-30 22:08:59.529868
learning rate:  9.007199254741002e-05
val: 1 0.46301984786987305
val: 2 0.4592166543006897
val: 3 0.4817483723163605
val: 4 0.4987761676311493
val: 5 0.4843931496143341
val: 6 0.47172996401786804
val: 7 0.4729357659816742
val: 8 0.4714854955673218
val: 9 0.4773499369621277
val: 10 0.48541101813316345
val: 11 0.48228198289871216
val: 12 0.46740689873695374
val: 13 0.4743891656398773
val: 14 0.48588240146636963
val: 15 0.4849648177623749
val: 16 0.46057838201522827
val: 17 0.4700811207294464
val: 18 0.4846520721912384
val: 19 0.4949650764465332
val: 20 0.4746277630329132
val_Epoch:[ 183 ] val_loss: 0.47729480266571045 2022-06-30 22:09:02.951729
start training 2022-06-30 22:09:03.053392
Epoch:[ 184 0 ] loss: 0.3823915421962738 2022-06-30 22:09:17.448061
Epoch:[ 184 1 ] loss: 0.38310936093330383 2022-06-30 22:09:17.865141
Epoch:[ 184 2 ] loss: 0.38420844078063965 2022-06-30 22:09:18.279638
Epoch:[ 184 3 ] loss: 0.3841552436351776 2022-06-30 22:09:18.696761
Epoch:[ 184 4 ] loss: 0.38170817494392395 2022-06-30 22:09:19.113486
Epoch:[ 184 5 ] loss: 0.38199737668037415 2022-06-30 22:09:19.533658
Epoch:[ 184 6 ] loss: 0.38209354877471924 2022-06-30 22:09:19.949658
Epoch:[ 184 7 ] loss: 0.3805597722530365 2022-06-30 22:09:20.370551
Epoch:[ 184 8 ] loss: 0.38082411885261536 2022-06-30 22:09:20.784620
Epoch:[ 184 9 ] loss: 0.3824424743652344 2022-06-30 22:09:21.198344
Epoch:[ 184 10 ] loss: 0.38045167922973633 2022-06-30 22:09:21.618989
Epoch:[ 184 11 ] loss: 0.38145607709884644 2022-06-30 22:09:22.033757
Epoch:[ 184 12 ] loss: 0.38274282217025757 2022-06-30 22:09:22.449942
Epoch:[ 184 13 ] loss: 0.383388489484787 2022-06-30 22:09:22.865723
Epoch:[ 184 14 ] loss: 0.3838443458080292 2022-06-30 22:09:23.287356
Epoch:[ 184 15 ] loss: 0.3831440806388855 2022-06-30 22:09:23.710284
Epoch:[ 184 16 ] loss: 0.38137781620025635 2022-06-30 22:09:28.784857
Epoch:[ 184 17 ] loss: 0.3822709321975708 2022-06-30 22:09:29.201844
Epoch:[ 184 18 ] loss: 0.3847172260284424 2022-06-30 22:09:29.618265
Epoch:[ 184 19 ] loss: 0.38204318284988403 2022-06-30 22:09:30.033404
Training_Epoch:[ 184 ] Training_loss: 0.3824463352560997 2022-06-30 22:09:30.034074
learning rate:  9.007199254741002e-05
netparams have been saved once 184
val: 1 0.48863485455513
val: 2 0.4746546447277069
val: 3 0.47068479657173157
val: 4 0.4729814827442169
val: 5 0.48288494348526
val: 6 0.4661724269390106
val: 7 0.4638504981994629
val: 8 0.47791624069213867
val: 9 0.477064847946167
val: 10 0.4744202792644501
val: 11 0.4755654036998749
val: 12 0.490057110786438
val: 13 0.4908848702907562
val: 14 0.4746723175048828
val: 15 0.4802456200122833
val: 16 0.4954661726951599
val: 17 0.46921736001968384
val: 18 0.4688951075077057
val: 19 0.4746171236038208
val: 20 0.4814297556877136
val_Epoch:[ 184 ] val_loss: 0.47751579284667967 2022-06-30 22:09:33.375035
start training 2022-06-30 22:09:33.473253
Epoch:[ 185 0 ] loss: 0.3829614222049713 2022-06-30 22:09:47.235550
Epoch:[ 185 1 ] loss: 0.38317063450813293 2022-06-30 22:09:47.677861
Epoch:[ 185 2 ] loss: 0.3799421787261963 2022-06-30 22:09:48.106528
Epoch:[ 185 3 ] loss: 0.38253673911094666 2022-06-30 22:09:48.527284
Epoch:[ 185 4 ] loss: 0.3838690519332886 2022-06-30 22:09:48.942147
Epoch:[ 185 5 ] loss: 0.38264867663383484 2022-06-30 22:09:49.354809
Epoch:[ 185 6 ] loss: 0.3798235058784485 2022-06-30 22:09:49.768119
Epoch:[ 185 7 ] loss: 0.3823554813861847 2022-06-30 22:09:50.184297
Epoch:[ 185 8 ] loss: 0.38410553336143494 2022-06-30 22:09:50.600315
Epoch:[ 185 9 ] loss: 0.3810444474220276 2022-06-30 22:09:51.021109
Epoch:[ 185 10 ] loss: 0.3826487958431244 2022-06-30 22:09:51.440782
Epoch:[ 185 11 ] loss: 0.38202938437461853 2022-06-30 22:09:51.856325
Epoch:[ 185 12 ] loss: 0.38334861397743225 2022-06-30 22:09:52.269583
Epoch:[ 185 13 ] loss: 0.38501134514808655 2022-06-30 22:09:52.682771
Epoch:[ 185 14 ] loss: 0.3827398717403412 2022-06-30 22:09:53.099134
Epoch:[ 185 15 ] loss: 0.38234376907348633 2022-06-30 22:09:53.513404
Epoch:[ 185 16 ] loss: 0.3819349706172943 2022-06-30 22:09:58.876004
Epoch:[ 185 17 ] loss: 0.38184332847595215 2022-06-30 22:09:59.290081
Epoch:[ 185 18 ] loss: 0.38132745027542114 2022-06-30 22:09:59.710544
Epoch:[ 185 19 ] loss: 0.38405677676200867 2022-06-30 22:10:00.124443
Training_Epoch:[ 185 ] Training_loss: 0.3824870988726616 2022-06-30 22:10:00.125074
learning rate:  9.007199254741002e-05
val: 1 0.46844255924224854
val: 2 0.46858254075050354
val: 3 0.48504385352134705
val: 4 0.4824891686439514
val: 5 0.48449549078941345
val: 6 0.46985119581222534
val: 7 0.4844749867916107
val: 8 0.4783341586589813
val: 9 0.47233399748802185
val: 10 0.48314666748046875
val: 11 0.4843885898590088
val: 12 0.47922423481941223
val: 13 0.4705709218978882
val: 14 0.4795171916484833
val: 15 0.4786428213119507
val: 16 0.47301143407821655
val: 17 0.4702705442905426
val: 18 0.469412237405777
val: 19 0.46488359570503235
val: 20 0.48289239406585693
val_Epoch:[ 185 ] val_loss: 0.476500429213047 2022-06-30 22:10:03.417063
start training 2022-06-30 22:10:03.518772
Epoch:[ 186 0 ] loss: 0.3812839388847351 2022-06-30 22:10:18.002509
Epoch:[ 186 1 ] loss: 0.3828316032886505 2022-06-30 22:10:18.423986
Epoch:[ 186 2 ] loss: 0.3792511522769928 2022-06-30 22:10:18.846290
Epoch:[ 186 3 ] loss: 0.38245144486427307 2022-06-30 22:10:19.265285
Epoch:[ 186 4 ] loss: 0.3831307291984558 2022-06-30 22:10:19.678690
Epoch:[ 186 5 ] loss: 0.3826901912689209 2022-06-30 22:10:20.093788
Epoch:[ 186 6 ] loss: 0.3823547065258026 2022-06-30 22:10:20.507293
Epoch:[ 186 7 ] loss: 0.3839927017688751 2022-06-30 22:10:20.920919
Epoch:[ 186 8 ] loss: 0.38412797451019287 2022-06-30 22:10:21.336664
Epoch:[ 186 9 ] loss: 0.38189616799354553 2022-06-30 22:10:21.752187
Epoch:[ 186 10 ] loss: 0.3826078474521637 2022-06-30 22:10:22.165340
Epoch:[ 186 11 ] loss: 0.3825569152832031 2022-06-30 22:10:22.580276
Epoch:[ 186 12 ] loss: 0.3818129599094391 2022-06-30 22:10:23.001177
Epoch:[ 186 13 ] loss: 0.38234782218933105 2022-06-30 22:10:23.423236
Epoch:[ 186 14 ] loss: 0.38297852873802185 2022-06-30 22:10:23.836406
Epoch:[ 186 15 ] loss: 0.3842025399208069 2022-06-30 22:10:24.252376
Epoch:[ 186 16 ] loss: 0.3823881447315216 2022-06-30 22:10:29.685992
Epoch:[ 186 17 ] loss: 0.3838348984718323 2022-06-30 22:10:30.100894
Epoch:[ 186 18 ] loss: 0.380854994058609 2022-06-30 22:10:30.665132
Epoch:[ 186 19 ] loss: 0.38305792212486267 2022-06-30 22:10:31.080147
Training_Epoch:[ 186 ] Training_loss: 0.38253265917301177 2022-06-30 22:10:31.080847
learning rate:  9.007199254741002e-05
netparams have been saved once 186
val: 1 0.486829936504364
val: 2 0.48087185621261597
val: 3 0.4731261134147644
val: 4 0.46819108724594116
val: 5 0.4728129208087921
val: 6 0.4915652275085449
val: 7 0.4728291928768158
val: 8 0.4845992922782898
val: 9 0.4790877401828766
val: 10 0.47895893454551697
val: 11 0.47316035628318787
val: 12 0.47910168766975403
val: 13 0.47848567366600037
val: 14 0.4661390781402588
val: 15 0.46903395652770996
val: 16 0.4843127131462097
val: 17 0.48404133319854736
val: 18 0.4808495044708252
val: 19 0.4848329424858093
val: 20 0.4664910137653351
val_Epoch:[ 186 ] val_loss: 0.47776602804660795 2022-06-30 22:10:34.624129
start training 2022-06-30 22:10:34.722466
Epoch:[ 187 0 ] loss: 0.3807300627231598 2022-06-30 22:10:48.809670
Epoch:[ 187 1 ] loss: 0.380618155002594 2022-06-30 22:10:49.243886
Epoch:[ 187 2 ] loss: 0.3814425468444824 2022-06-30 22:10:49.659454
Epoch:[ 187 3 ] loss: 0.3826914131641388 2022-06-30 22:10:50.073876
Epoch:[ 187 4 ] loss: 0.38156747817993164 2022-06-30 22:10:50.494181
Epoch:[ 187 5 ] loss: 0.3828490674495697 2022-06-30 22:10:50.906635
Epoch:[ 187 6 ] loss: 0.3820105493068695 2022-06-30 22:10:51.320376
Epoch:[ 187 7 ] loss: 0.38352224230766296 2022-06-30 22:10:51.734224
Epoch:[ 187 8 ] loss: 0.38183116912841797 2022-06-30 22:10:52.148042
Epoch:[ 187 9 ] loss: 0.3830488324165344 2022-06-30 22:10:52.562420
Epoch:[ 187 10 ] loss: 0.3831908404827118 2022-06-30 22:10:52.978321
Epoch:[ 187 11 ] loss: 0.3816995322704315 2022-06-30 22:10:53.397170
Epoch:[ 187 12 ] loss: 0.3825218379497528 2022-06-30 22:10:53.817946
Epoch:[ 187 13 ] loss: 0.38277745246887207 2022-06-30 22:10:54.231386
Epoch:[ 187 14 ] loss: 0.3829106092453003 2022-06-30 22:10:54.650603
Epoch:[ 187 15 ] loss: 0.3827553391456604 2022-06-30 22:10:55.070713
Epoch:[ 187 16 ] loss: 0.38243114948272705 2022-06-30 22:11:00.330630
Epoch:[ 187 17 ] loss: 0.38407957553863525 2022-06-30 22:11:00.752237
Epoch:[ 187 18 ] loss: 0.3842018246650696 2022-06-30 22:11:01.169451
Epoch:[ 187 19 ] loss: 0.3836894929409027 2022-06-30 22:11:01.584033
Training_Epoch:[ 187 ] Training_loss: 0.38252845853567125 2022-06-30 22:11:01.584710
learning rate:  9.007199254741002e-05
val: 1 0.4637930691242218
val: 2 0.48465844988822937
val: 3 0.46571487188339233
val: 4 0.4837163984775543
val: 5 0.4840986728668213
val: 6 0.4932805597782135
val: 7 0.4878334403038025
val: 8 0.4763442575931549
val: 9 0.48550963401794434
val: 10 0.4790915846824646
val: 11 0.48567646741867065
val: 12 0.46480995416641235
val: 13 0.4705698788166046
val: 14 0.4777992069721222
val: 15 0.47197237610816956
val: 16 0.46830064058303833
val: 17 0.47051161527633667
val: 18 0.49054020643234253
val: 19 0.4771445691585541
val: 20 0.4706806242465973
val_Epoch:[ 187 ] val_loss: 0.47760232388973234 2022-06-30 22:11:04.969635
start training 2022-06-30 22:11:05.069542
Epoch:[ 188 0 ] loss: 0.3819229304790497 2022-06-30 22:11:19.295431
Epoch:[ 188 1 ] loss: 0.38287588953971863 2022-06-30 22:11:19.720289
Epoch:[ 188 2 ] loss: 0.38212457299232483 2022-06-30 22:11:20.133320
Epoch:[ 188 3 ] loss: 0.38103052973747253 2022-06-30 22:11:20.550351
Epoch:[ 188 4 ] loss: 0.38118281960487366 2022-06-30 22:11:20.967219
Epoch:[ 188 5 ] loss: 0.38190972805023193 2022-06-30 22:11:21.382156
Epoch:[ 188 6 ] loss: 0.38167107105255127 2022-06-30 22:11:21.795965
Epoch:[ 188 7 ] loss: 0.3832796812057495 2022-06-30 22:11:22.211474
Epoch:[ 188 8 ] loss: 0.3832060992717743 2022-06-30 22:11:22.631262
Epoch:[ 188 9 ] loss: 0.3835751414299011 2022-06-30 22:11:23.044871
Epoch:[ 188 10 ] loss: 0.38356485962867737 2022-06-30 22:11:23.467501
Epoch:[ 188 11 ] loss: 0.38262856006622314 2022-06-30 22:11:23.883457
Epoch:[ 188 12 ] loss: 0.3845809996128082 2022-06-30 22:11:24.298588
Epoch:[ 188 13 ] loss: 0.38029614090919495 2022-06-30 22:11:24.720809
Epoch:[ 188 14 ] loss: 0.38078880310058594 2022-06-30 22:11:25.134406
Epoch:[ 188 15 ] loss: 0.3809514045715332 2022-06-30 22:11:25.548367
Epoch:[ 188 16 ] loss: 0.3816487193107605 2022-06-30 22:11:30.675582
Epoch:[ 188 17 ] loss: 0.38213369250297546 2022-06-30 22:11:31.568845
Epoch:[ 188 18 ] loss: 0.3826737701892853 2022-06-30 22:11:31.986615
Epoch:[ 188 19 ] loss: 0.3827095925807953 2022-06-30 22:11:32.405405
Training_Epoch:[ 188 ] Training_loss: 0.38223775029182433 2022-06-30 22:11:32.406075
learning rate:  9.007199254741002e-05
netparams have been saved once 188
val: 1 0.48072612285614014
val: 2 0.49407610297203064
val: 3 0.4806636571884155
val: 4 0.4685887098312378
val: 5 0.4881839454174042
val: 6 0.4820185601711273
val: 7 0.4768214821815491
val: 8 0.48811882734298706
val: 9 0.4683646261692047
val: 10 0.46181344985961914
val: 11 0.49733850359916687
val: 12 0.47315582633018494
val: 13 0.4748830497264862
val: 14 0.474131315946579
val: 15 0.4864015281200409
val: 16 0.47596222162246704
val: 17 0.46721065044403076
val: 18 0.4640145003795624
val: 19 0.4702289402484894
val: 20 0.4757550060749054
val_Epoch:[ 188 ] val_loss: 0.4774228513240814 2022-06-30 22:11:35.812908
start training 2022-06-30 22:11:35.913589
Epoch:[ 189 0 ] loss: 0.3841826021671295 2022-06-30 22:11:49.772202
Epoch:[ 189 1 ] loss: 0.38264986872673035 2022-06-30 22:11:50.277047
Epoch:[ 189 2 ] loss: 0.3814513385295868 2022-06-30 22:11:50.689913
Epoch:[ 189 3 ] loss: 0.3819314241409302 2022-06-30 22:11:51.106067
Epoch:[ 189 4 ] loss: 0.38270801305770874 2022-06-30 22:11:51.522072
Epoch:[ 189 5 ] loss: 0.38288193941116333 2022-06-30 22:11:51.943441
Epoch:[ 189 6 ] loss: 0.38403528928756714 2022-06-30 22:11:52.358066
Epoch:[ 189 7 ] loss: 0.3802967071533203 2022-06-30 22:11:52.773401
Epoch:[ 189 8 ] loss: 0.38016238808631897 2022-06-30 22:11:53.187068
Epoch:[ 189 9 ] loss: 0.3835969567298889 2022-06-30 22:11:53.608215
Epoch:[ 189 10 ] loss: 0.38026928901672363 2022-06-30 22:11:54.024996
Epoch:[ 189 11 ] loss: 0.38149285316467285 2022-06-30 22:11:54.441744
Epoch:[ 189 12 ] loss: 0.3821229636669159 2022-06-30 22:11:54.857518
Epoch:[ 189 13 ] loss: 0.38230445981025696 2022-06-30 22:11:55.280035
Epoch:[ 189 14 ] loss: 0.3837525248527527 2022-06-30 22:11:55.699356
Epoch:[ 189 15 ] loss: 0.3814083933830261 2022-06-30 22:11:56.130275
Epoch:[ 189 16 ] loss: 0.3824247717857361 2022-06-30 22:12:01.376749
Epoch:[ 189 17 ] loss: 0.38504093885421753 2022-06-30 22:12:02.092284
Epoch:[ 189 18 ] loss: 0.38202208280563354 2022-06-30 22:12:02.510353
Epoch:[ 189 19 ] loss: 0.3813367486000061 2022-06-30 22:12:02.929366
Training_Epoch:[ 189 ] Training_loss: 0.3823035776615143 2022-06-30 22:12:02.930076
learning rate:  9.007199254741002e-05
val: 1 0.4894193112850189
val: 2 0.48122748732566833
val: 3 0.46515849232673645
val: 4 0.47341951727867126
val: 5 0.48404553532600403
val: 6 0.4765266180038452
val: 7 0.47942227125167847
val: 8 0.48678454756736755
val: 9 0.4704034924507141
val: 10 0.49039551615715027
val: 11 0.4712503254413605
val: 12 0.48223942518234253
val: 13 0.4791540801525116
val: 14 0.4792807698249817
val: 15 0.47027522325515747
val: 16 0.48023608326911926
val: 17 0.4742395281791687
val: 18 0.4695740044116974
val: 19 0.4654594361782074
val: 20 0.4771445393562317
val_Epoch:[ 189 ] val_loss: 0.47728281021118163 2022-06-30 22:12:06.293505
start training 2022-06-30 22:12:06.397390
Epoch:[ 190 0 ] loss: 0.3835136294364929 2022-06-30 22:12:21.450639
Epoch:[ 190 1 ] loss: 0.3823922872543335 2022-06-30 22:12:21.865887
Epoch:[ 190 2 ] loss: 0.38121575117111206 2022-06-30 22:12:22.281127
Epoch:[ 190 3 ] loss: 0.3807007372379303 2022-06-30 22:12:22.696242
Epoch:[ 190 4 ] loss: 0.3798842430114746 2022-06-30 22:12:23.113526
Epoch:[ 190 5 ] loss: 0.3802855312824249 2022-06-30 22:12:23.532553
Epoch:[ 190 6 ] loss: 0.38045257329940796 2022-06-30 22:12:23.952603
Epoch:[ 190 7 ] loss: 0.3809877932071686 2022-06-30 22:12:24.378810
Epoch:[ 190 8 ] loss: 0.3816026747226715 2022-06-30 22:12:24.797241
Epoch:[ 190 9 ] loss: 0.38055935502052307 2022-06-30 22:12:25.215820
Epoch:[ 190 10 ] loss: 0.3835793137550354 2022-06-30 22:12:25.646592
Epoch:[ 190 11 ] loss: 0.3828749358654022 2022-06-30 22:12:26.063126
Epoch:[ 190 12 ] loss: 0.383220374584198 2022-06-30 22:12:26.483066
Epoch:[ 190 13 ] loss: 0.38074418902397156 2022-06-30 22:12:26.905256
Epoch:[ 190 14 ] loss: 0.38601386547088623 2022-06-30 22:12:27.328299
Epoch:[ 190 15 ] loss: 0.38366755843162537 2022-06-30 22:12:27.749528
Epoch:[ 190 16 ] loss: 0.38223958015441895 2022-06-30 22:12:33.738559
Epoch:[ 190 17 ] loss: 0.38408350944519043 2022-06-30 22:12:34.163058
Epoch:[ 190 18 ] loss: 0.38195157051086426 2022-06-30 22:12:34.599482
Epoch:[ 190 19 ] loss: 0.3819950222969055 2022-06-30 22:12:35.035738
Training_Epoch:[ 190 ] Training_loss: 0.3820982247591019 2022-06-30 22:12:35.036561
learning rate:  9.007199254741002e-05
netparams have been saved once 190
val: 1 0.48408418893814087
val: 2 0.46312785148620605
val: 3 0.47446495294570923
val: 4 0.49145373702049255
val: 5 0.47289931774139404
val: 6 0.4877340793609619
val: 7 0.47834405303001404
val: 8 0.46931129693984985
val: 9 0.47369757294654846
val: 10 0.47347939014434814
val: 11 0.4844559133052826
val: 12 0.47627466917037964
val: 13 0.4662925899028778
val: 14 0.47633421421051025
val: 15 0.4755059778690338
val: 16 0.46605443954467773
val: 17 0.4879583418369293
val: 18 0.4979679584503174
val: 19 0.47022518515586853
val: 20 0.4860594868659973
val_Epoch:[ 190 ] val_loss: 0.47778626084327697 2022-06-30 22:12:38.503879
start training 2022-06-30 22:12:38.602860
Epoch:[ 191 0 ] loss: 0.38144898414611816 2022-06-30 22:12:53.206408
Epoch:[ 191 1 ] loss: 0.3804461359977722 2022-06-30 22:12:53.630528
Epoch:[ 191 2 ] loss: 0.38230881094932556 2022-06-30 22:12:54.052488
Epoch:[ 191 3 ] loss: 0.3793550729751587 2022-06-30 22:12:54.472380
Epoch:[ 191 4 ] loss: 0.38201794028282166 2022-06-30 22:12:54.887300
Epoch:[ 191 5 ] loss: 0.3806256949901581 2022-06-30 22:12:55.300982
Epoch:[ 191 6 ] loss: 0.38239893317222595 2022-06-30 22:12:55.716907
Epoch:[ 191 7 ] loss: 0.381340891122818 2022-06-30 22:12:56.131230
Epoch:[ 191 8 ] loss: 0.38119325041770935 2022-06-30 22:12:56.551341
Epoch:[ 191 9 ] loss: 0.3821047246456146 2022-06-30 22:12:56.974090
Epoch:[ 191 10 ] loss: 0.38352566957473755 2022-06-30 22:12:57.389170
Epoch:[ 191 11 ] loss: 0.38202789425849915 2022-06-30 22:12:57.804210
Epoch:[ 191 12 ] loss: 0.3822251856327057 2022-06-30 22:12:58.218307
Epoch:[ 191 13 ] loss: 0.38204213976860046 2022-06-30 22:12:58.640439
Epoch:[ 191 14 ] loss: 0.38242077827453613 2022-06-30 22:12:59.059137
Epoch:[ 191 15 ] loss: 0.38150614500045776 2022-06-30 22:12:59.478622
Epoch:[ 191 16 ] loss: 0.3827465772628784 2022-06-30 22:13:04.818950
Epoch:[ 191 17 ] loss: 0.38235780596733093 2022-06-30 22:13:05.544422
Epoch:[ 191 18 ] loss: 0.38240480422973633 2022-06-30 22:13:05.980040
Epoch:[ 191 19 ] loss: 0.38247811794281006 2022-06-30 22:13:06.414359
Training_Epoch:[ 191 ] Training_loss: 0.3818487778306007 2022-06-30 22:13:06.415065
learning rate:  7.205759403792802e-05
val: 1 0.4752742350101471
val: 2 0.48236361145973206
val: 3 0.47542139887809753
val: 4 0.4895906150341034
val: 5 0.47309502959251404
val: 6 0.4690086543560028
val: 7 0.47870901226997375
val: 8 0.48561447858810425
val: 9 0.4820675849914551
val: 10 0.48367390036582947
val: 11 0.4835417568683624
val: 12 0.4813407063484192
val: 13 0.47939735651016235
val: 14 0.46819230914115906
val: 15 0.4844726622104645
val: 16 0.4950132668018341
val: 17 0.4646993577480316
val: 18 0.4747847318649292
val: 19 0.4813425838947296
val: 20 0.45923230051994324
val_Epoch:[ 191 ] val_loss: 0.47834177762269975 2022-06-30 22:13:09.794882
start training 2022-06-30 22:13:09.901078
Epoch:[ 192 0 ] loss: 0.38178586959838867 2022-06-30 22:13:24.062059
Epoch:[ 192 1 ] loss: 0.3855847716331482 2022-06-30 22:13:24.744494
Epoch:[ 192 2 ] loss: 0.38194170594215393 2022-06-30 22:13:25.165356
Epoch:[ 192 3 ] loss: 0.38022997975349426 2022-06-30 22:13:25.582016
Epoch:[ 192 4 ] loss: 0.38237470388412476 2022-06-30 22:13:25.998030
Epoch:[ 192 5 ] loss: 0.38329991698265076 2022-06-30 22:13:26.414324
Epoch:[ 192 6 ] loss: 0.38223859667778015 2022-06-30 22:13:26.830171
Epoch:[ 192 7 ] loss: 0.381151407957077 2022-06-30 22:13:27.255259
Epoch:[ 192 8 ] loss: 0.38039812445640564 2022-06-30 22:13:27.674176
Epoch:[ 192 9 ] loss: 0.3813883364200592 2022-06-30 22:13:28.089259
Epoch:[ 192 10 ] loss: 0.3820939064025879 2022-06-30 22:13:28.503212
Epoch:[ 192 11 ] loss: 0.38004323840141296 2022-06-30 22:13:28.918996
Epoch:[ 192 12 ] loss: 0.3831034004688263 2022-06-30 22:13:29.339926
Epoch:[ 192 13 ] loss: 0.38270941376686096 2022-06-30 22:13:29.760578
Epoch:[ 192 14 ] loss: 0.38098928332328796 2022-06-30 22:13:30.177498
Epoch:[ 192 15 ] loss: 0.3819248676300049 2022-06-30 22:13:30.594099
Epoch:[ 192 16 ] loss: 0.3792644739151001 2022-06-30 22:13:36.211283
Epoch:[ 192 17 ] loss: 0.380603551864624 2022-06-30 22:13:36.639837
Epoch:[ 192 18 ] loss: 0.38161352276802063 2022-06-30 22:13:37.077021
Epoch:[ 192 19 ] loss: 0.3830016255378723 2022-06-30 22:13:37.503163
Training_Epoch:[ 192 ] Training_loss: 0.381787034869194 2022-06-30 22:13:37.503971
learning rate:  7.205759403792802e-05
netparams have been saved once 192
val: 1 0.47192054986953735
val: 2 0.4798831045627594
val: 3 0.48647448420524597
val: 4 0.4766991138458252
val: 5 0.4672577977180481
val: 6 0.49339064955711365
val: 7 0.4616265296936035
val: 8 0.475577712059021
val: 9 0.47398412227630615
val: 10 0.49105697870254517
val: 11 0.47981730103492737
val: 12 0.4732421338558197
val: 13 0.47843262553215027
val: 14 0.48037245869636536
val: 15 0.4744280278682709
val: 16 0.49152353405952454
val: 17 0.4682253301143646
val: 18 0.4959222674369812
val: 19 0.4702048599720001
val: 20 0.470949649810791
val_Epoch:[ 192 ] val_loss: 0.47804946154356004 2022-06-30 22:13:40.971419
start training 2022-06-30 22:13:41.081680
Epoch:[ 193 0 ] loss: 0.38183268904685974 2022-06-30 22:13:55.619505
Epoch:[ 193 1 ] loss: 0.3834342062473297 2022-06-30 22:13:56.044881
Epoch:[ 193 2 ] loss: 0.3831291198730469 2022-06-30 22:13:56.461016
Epoch:[ 193 3 ] loss: 0.3809150159358978 2022-06-30 22:13:56.876785
Epoch:[ 193 4 ] loss: 0.38208624720573425 2022-06-30 22:13:57.289048
Epoch:[ 193 5 ] loss: 0.3805149793624878 2022-06-30 22:13:57.702608
Epoch:[ 193 6 ] loss: 0.3817620575428009 2022-06-30 22:13:58.122239
Epoch:[ 193 7 ] loss: 0.3826294541358948 2022-06-30 22:13:58.543281
Epoch:[ 193 8 ] loss: 0.3823190927505493 2022-06-30 22:13:58.965286
Epoch:[ 193 9 ] loss: 0.3802872598171234 2022-06-30 22:13:59.381074
Epoch:[ 193 10 ] loss: 0.38021305203437805 2022-06-30 22:13:59.795176
Epoch:[ 193 11 ] loss: 0.37994736433029175 2022-06-30 22:14:00.211993
Epoch:[ 193 12 ] loss: 0.383080393075943 2022-06-30 22:14:00.626807
Epoch:[ 193 13 ] loss: 0.38304585218429565 2022-06-30 22:14:01.039896
Epoch:[ 193 14 ] loss: 0.38067591190338135 2022-06-30 22:14:01.457912
Epoch:[ 193 15 ] loss: 0.38227295875549316 2022-06-30 22:14:01.880497
Epoch:[ 193 16 ] loss: 0.38239648938179016 2022-06-30 22:14:07.455601
Epoch:[ 193 17 ] loss: 0.3830031752586365 2022-06-30 22:14:07.870435
Epoch:[ 193 18 ] loss: 0.3797588050365448 2022-06-30 22:14:08.284213
Epoch:[ 193 19 ] loss: 0.3829342722892761 2022-06-30 22:14:08.702861
Training_Epoch:[ 193 ] Training_loss: 0.38181191980838775 2022-06-30 22:14:08.703491
learning rate:  7.205759403792802e-05
val: 1 0.4670233726501465
val: 2 0.46859219670295715
val: 3 0.4778992533683777
val: 4 0.47194135189056396
val: 5 0.4764019846916199
val: 6 0.4826602041721344
val: 7 0.4844776391983032
val: 8 0.4703679084777832
val: 9 0.4845304787158966
val: 10 0.47810104489326477
val: 11 0.4750001132488251
val: 12 0.4852020740509033
val: 13 0.48544561862945557
val: 14 0.4849396049976349
val: 15 0.4844588041305542
val: 16 0.4742169678211212
val: 17 0.4742748737335205
val: 18 0.48381510376930237
val: 19 0.47613492608070374
val: 20 0.4765053391456604
val_Epoch:[ 193 ] val_loss: 0.47809944301843643 2022-06-30 22:14:12.057178
start training 2022-06-30 22:14:12.159713
Epoch:[ 194 0 ] loss: 0.3808497190475464 2022-06-30 22:14:25.750492
Epoch:[ 194 1 ] loss: 0.38275158405303955 2022-06-30 22:14:26.506361
Epoch:[ 194 2 ] loss: 0.3811369240283966 2022-06-30 22:14:26.929824
Epoch:[ 194 3 ] loss: 0.3805195093154907 2022-06-30 22:14:27.351122
Epoch:[ 194 4 ] loss: 0.38325268030166626 2022-06-30 22:14:27.767033
Epoch:[ 194 5 ] loss: 0.3812074363231659 2022-06-30 22:14:28.181988
Epoch:[ 194 6 ] loss: 0.38118988275527954 2022-06-30 22:14:28.604252
Epoch:[ 194 7 ] loss: 0.3834500312805176 2022-06-30 22:14:29.025986
Epoch:[ 194 8 ] loss: 0.38256537914276123 2022-06-30 22:14:29.437511
Epoch:[ 194 9 ] loss: 0.3831358253955841 2022-06-30 22:14:29.854316
Epoch:[ 194 10 ] loss: 0.3806506395339966 2022-06-30 22:14:30.270871
Epoch:[ 194 11 ] loss: 0.38320115208625793 2022-06-30 22:14:30.688018
Epoch:[ 194 12 ] loss: 0.3802451491355896 2022-06-30 22:14:31.118855
Epoch:[ 194 13 ] loss: 0.37901580333709717 2022-06-30 22:14:31.533148
Epoch:[ 194 14 ] loss: 0.38198286294937134 2022-06-30 22:14:31.949466
Epoch:[ 194 15 ] loss: 0.38199490308761597 2022-06-30 22:14:32.365781
Epoch:[ 194 16 ] loss: 0.38052690029144287 2022-06-30 22:14:38.144810
Epoch:[ 194 17 ] loss: 0.3817194700241089 2022-06-30 22:14:38.562259
Epoch:[ 194 18 ] loss: 0.3808008134365082 2022-06-30 22:14:38.978622
Epoch:[ 194 19 ] loss: 0.38339826464653015 2022-06-30 22:14:39.393965
Training_Epoch:[ 194 ] Training_loss: 0.3816797465085983 2022-06-30 22:14:39.394569
learning rate:  7.205759403792802e-05
netparams have been saved once 194
val: 1 0.4849124252796173
val: 2 0.46540117263793945
val: 3 0.4795365631580353
val: 4 0.47452372312545776
val: 5 0.5018225312232971
val: 6 0.4714573621749878
val: 7 0.4765116274356842
val: 8 0.4660134017467499
val: 9 0.4844261407852173
val: 10 0.47779199481010437
val: 11 0.4971526563167572
val: 12 0.4731021225452423
val: 13 0.4871613383293152
val: 14 0.47567734122276306
val: 15 0.48370805382728577
val: 16 0.467126727104187
val: 17 0.4697917103767395
val: 18 0.47985970973968506
val: 19 0.47324028611183167
val: 20 0.47564512491226196
val_Epoch:[ 194 ] val_loss: 0.47824310064315795 2022-06-30 22:14:42.784675
start training 2022-06-30 22:14:42.885697
Epoch:[ 195 0 ] loss: 0.3824746310710907 2022-06-30 22:14:57.001857
Epoch:[ 195 1 ] loss: 0.38206154108047485 2022-06-30 22:14:57.441974
Epoch:[ 195 2 ] loss: 0.3812410831451416 2022-06-30 22:14:57.863824
Epoch:[ 195 3 ] loss: 0.38202667236328125 2022-06-30 22:14:58.281371
Epoch:[ 195 4 ] loss: 0.3818442225456238 2022-06-30 22:14:58.698545
Epoch:[ 195 5 ] loss: 0.38383743166923523 2022-06-30 22:14:59.113686
Epoch:[ 195 6 ] loss: 0.38332995772361755 2022-06-30 22:14:59.534454
Epoch:[ 195 7 ] loss: 0.383468896150589 2022-06-30 22:14:59.951257
Epoch:[ 195 8 ] loss: 0.3818560242652893 2022-06-30 22:15:00.365143
Epoch:[ 195 9 ] loss: 0.38240912556648254 2022-06-30 22:15:00.785301
Epoch:[ 195 10 ] loss: 0.38354042172431946 2022-06-30 22:15:01.201983
Epoch:[ 195 11 ] loss: 0.381602942943573 2022-06-30 22:15:01.617296
Epoch:[ 195 12 ] loss: 0.38123226165771484 2022-06-30 22:15:02.034957
Epoch:[ 195 13 ] loss: 0.3813353180885315 2022-06-30 22:15:02.455375
Epoch:[ 195 14 ] loss: 0.3828882873058319 2022-06-30 22:15:02.868564
Epoch:[ 195 15 ] loss: 0.38172343373298645 2022-06-30 22:15:03.282247
Epoch:[ 195 16 ] loss: 0.3788652718067169 2022-06-30 22:15:08.647087
Epoch:[ 195 17 ] loss: 0.3822554051876068 2022-06-30 22:15:09.064342
Epoch:[ 195 18 ] loss: 0.3793812394142151 2022-06-30 22:15:09.481688
Epoch:[ 195 19 ] loss: 0.3779067099094391 2022-06-30 22:15:09.898007
Training_Epoch:[ 195 ] Training_loss: 0.38176404386758805 2022-06-30 22:15:09.898849
learning rate:  7.205759403792802e-05
val: 1 0.4596503973007202
val: 2 0.4970252513885498
val: 3 0.48606958985328674
val: 4 0.4761126637458801
val: 5 0.4734255075454712
val: 6 0.4759880304336548
val: 7 0.4781424403190613
val: 8 0.47252583503723145
val: 9 0.47989198565483093
val: 10 0.46798059344291687
val: 11 0.4724136292934418
val: 12 0.4942971467971802
val: 13 0.4745902717113495
val: 14 0.4727126955986023
val: 15 0.48903223872184753
val: 16 0.4610185921192169
val: 17 0.48232302069664
val: 18 0.47815802693367004
val: 19 0.4899715185165405
val: 20 0.47895243763923645
val_Epoch:[ 195 ] val_loss: 0.47801409363746644 2022-06-30 22:15:13.301163
start training 2022-06-30 22:15:13.401228
Epoch:[ 196 0 ] loss: 0.3810341954231262 2022-06-30 22:15:27.536707
Epoch:[ 196 1 ] loss: 0.3824925720691681 2022-06-30 22:15:27.974586
Epoch:[ 196 2 ] loss: 0.38377198576927185 2022-06-30 22:15:28.391414
Epoch:[ 196 3 ] loss: 0.38418447971343994 2022-06-30 22:15:28.806029
Epoch:[ 196 4 ] loss: 0.38019347190856934 2022-06-30 22:15:29.228275
Epoch:[ 196 5 ] loss: 0.3814849257469177 2022-06-30 22:15:29.644561
Epoch:[ 196 6 ] loss: 0.38239309191703796 2022-06-30 22:15:30.061912
Epoch:[ 196 7 ] loss: 0.38062816858291626 2022-06-30 22:15:30.484902
Epoch:[ 196 8 ] loss: 0.38176003098487854 2022-06-30 22:15:30.899748
Epoch:[ 196 9 ] loss: 0.38058045506477356 2022-06-30 22:15:31.313682
Epoch:[ 196 10 ] loss: 0.3792625665664673 2022-06-30 22:15:31.726388
Epoch:[ 196 11 ] loss: 0.38268452882766724 2022-06-30 22:15:32.142922
Epoch:[ 196 12 ] loss: 0.38434097170829773 2022-06-30 22:15:32.559996
Epoch:[ 196 13 ] loss: 0.38272154331207275 2022-06-30 22:15:32.981420
Epoch:[ 196 14 ] loss: 0.38316142559051514 2022-06-30 22:15:33.402120
Epoch:[ 196 15 ] loss: 0.3802417814731598 2022-06-30 22:15:33.818765
Epoch:[ 196 16 ] loss: 0.3797754943370819 2022-06-30 22:15:39.416466
Epoch:[ 196 17 ] loss: 0.38184311985969543 2022-06-30 22:15:39.832019
Epoch:[ 196 18 ] loss: 0.38139939308166504 2022-06-30 22:15:40.250508
Epoch:[ 196 19 ] loss: 0.3809109628200531 2022-06-30 22:15:40.667786
Training_Epoch:[ 196 ] Training_loss: 0.3817432582378387 2022-06-30 22:15:40.668593
learning rate:  7.205759403792802e-05
netparams have been saved once 196
val: 1 0.48759597539901733
val: 2 0.47139406204223633
val: 3 0.4767853915691376
val: 4 0.4899871349334717
val: 5 0.4770409166812897
val: 6 0.48909902572631836
val: 7 0.4710947275161743
val: 8 0.481483519077301
val: 9 0.46864134073257446
val: 10 0.4636935889720917
val: 11 0.4840521216392517
val: 12 0.4785005748271942
val: 13 0.4762292206287384
val: 14 0.48179998993873596
val: 15 0.4676099121570587
val: 16 0.46835213899612427
val: 17 0.4792516529560089
val: 18 0.4781917631626129
val: 19 0.4860956370830536
val: 20 0.4710524380207062
val_Epoch:[ 196 ] val_loss: 0.47739755660295485 2022-06-30 22:15:44.141262
start training 2022-06-30 22:15:44.241287
Epoch:[ 197 0 ] loss: 0.38086625933647156 2022-06-30 22:15:57.843738
Epoch:[ 197 1 ] loss: 0.3806609809398651 2022-06-30 22:15:58.886808
Epoch:[ 197 2 ] loss: 0.3803938925266266 2022-06-30 22:15:59.317307
Epoch:[ 197 3 ] loss: 0.38099968433380127 2022-06-30 22:15:59.738317
Epoch:[ 197 4 ] loss: 0.3825243413448334 2022-06-30 22:16:00.152110
Epoch:[ 197 5 ] loss: 0.3822319507598877 2022-06-30 22:16:00.568078
Epoch:[ 197 6 ] loss: 0.3818783462047577 2022-06-30 22:16:00.982995
Epoch:[ 197 7 ] loss: 0.38338229060173035 2022-06-30 22:16:01.408052
Epoch:[ 197 8 ] loss: 0.37975171208381653 2022-06-30 22:16:01.823637
Epoch:[ 197 9 ] loss: 0.381621390581131 2022-06-30 22:16:02.238343
Epoch:[ 197 10 ] loss: 0.3811284005641937 2022-06-30 22:16:02.652322
Epoch:[ 197 11 ] loss: 0.381193608045578 2022-06-30 22:16:03.067356
Epoch:[ 197 12 ] loss: 0.38003525137901306 2022-06-30 22:16:03.489874
Epoch:[ 197 13 ] loss: 0.3830467462539673 2022-06-30 22:16:03.905978
Epoch:[ 197 14 ] loss: 0.38409602642059326 2022-06-30 22:16:04.321529
Epoch:[ 197 15 ] loss: 0.38214075565338135 2022-06-30 22:16:04.743180
Epoch:[ 197 16 ] loss: 0.38139915466308594 2022-06-30 22:16:09.455210
Epoch:[ 197 17 ] loss: 0.38088151812553406 2022-06-30 22:16:10.249818
Epoch:[ 197 18 ] loss: 0.3820914030075073 2022-06-30 22:16:10.663686
Epoch:[ 197 19 ] loss: 0.38263803720474243 2022-06-30 22:16:11.079906
Training_Epoch:[ 197 ] Training_loss: 0.3816480875015259 2022-06-30 22:16:11.080548
learning rate:  7.205759403792802e-05
val: 1 0.4769704043865204
val: 2 0.4794803261756897
val: 3 0.46641525626182556
val: 4 0.48163101077079773
val: 5 0.48786941170692444
val: 6 0.47447165846824646
val: 7 0.4698857069015503
val: 8 0.4760521948337555
val: 9 0.48309311270713806
val: 10 0.47864845395088196
val: 11 0.4876209497451782
val: 12 0.49103257060050964
val: 13 0.4709097445011139
val: 14 0.47051456570625305
val: 15 0.4769909977912903
val: 16 0.47822606563568115
val: 17 0.4802744388580322
val: 18 0.47237876057624817
val: 19 0.48095622658729553
val: 20 0.4755729138851166
val_Epoch:[ 197 ] val_loss: 0.47794973850250244 2022-06-30 22:16:14.416889
start training 2022-06-30 22:16:14.518090
Epoch:[ 198 0 ] loss: 0.38238006830215454 2022-06-30 22:16:28.513258
Epoch:[ 198 1 ] loss: 0.3804883360862732 2022-06-30 22:16:28.951056
Epoch:[ 198 2 ] loss: 0.3811986744403839 2022-06-30 22:16:29.365109
Epoch:[ 198 3 ] loss: 0.380140483379364 2022-06-30 22:16:29.781899
Epoch:[ 198 4 ] loss: 0.3813346326351166 2022-06-30 22:16:30.210986
Epoch:[ 198 5 ] loss: 0.3795699179172516 2022-06-30 22:16:30.627186
Epoch:[ 198 6 ] loss: 0.38113248348236084 2022-06-30 22:16:31.043818
Epoch:[ 198 7 ] loss: 0.3835977017879486 2022-06-30 22:16:31.460118
Epoch:[ 198 8 ] loss: 0.38227593898773193 2022-06-30 22:16:31.881962
Epoch:[ 198 9 ] loss: 0.38069894909858704 2022-06-30 22:16:32.297007
Epoch:[ 198 10 ] loss: 0.3832564055919647 2022-06-30 22:16:32.712291
Epoch:[ 198 11 ] loss: 0.3798069357872009 2022-06-30 22:16:33.130067
Epoch:[ 198 12 ] loss: 0.38099488615989685 2022-06-30 22:16:33.545085
Epoch:[ 198 13 ] loss: 0.38089075684547424 2022-06-30 22:16:33.967196
Epoch:[ 198 14 ] loss: 0.3828359544277191 2022-06-30 22:16:34.392343
Epoch:[ 198 15 ] loss: 0.38380908966064453 2022-06-30 22:16:34.815185
Epoch:[ 198 16 ] loss: 0.3832384943962097 2022-06-30 22:16:40.909156
Epoch:[ 198 17 ] loss: 0.38247475028038025 2022-06-30 22:16:41.325086
Epoch:[ 198 18 ] loss: 0.38121089339256287 2022-06-30 22:16:41.746063
Epoch:[ 198 19 ] loss: 0.381421834230423 2022-06-30 22:16:42.161722
Training_Epoch:[ 198 ] Training_loss: 0.3816378593444824 2022-06-30 22:16:42.162515
learning rate:  7.205759403792802e-05
netparams have been saved once 198
val: 1 0.48237377405166626
val: 2 0.47809725999832153
val: 3 0.4731544852256775
val: 4 0.47306597232818604
val: 5 0.48097583651542664
val: 6 0.4759684205055237
val: 7 0.47237688302993774
val: 8 0.4809459447860718
val: 9 0.4641619324684143
val: 10 0.47270241379737854
val: 11 0.48461073637008667
val: 12 0.4787788689136505
val: 13 0.4697386920452118
val: 14 0.4927571713924408
val: 15 0.4788161814212799
val: 16 0.4761148691177368
val: 17 0.4855620861053467
val: 18 0.4655269384384155
val: 19 0.48627951741218567
val: 20 0.48533180356025696
val_Epoch:[ 198 ] val_loss: 0.4778669893741608 2022-06-30 22:16:45.651100
start training 2022-06-30 22:16:45.754018
Epoch:[ 199 0 ] loss: 0.3809939920902252 2022-06-30 22:16:59.398699
Epoch:[ 199 1 ] loss: 0.38452526926994324 2022-06-30 22:16:59.827063
Epoch:[ 199 2 ] loss: 0.3804875314235687 2022-06-30 22:17:00.260200
Epoch:[ 199 3 ] loss: 0.38126182556152344 2022-06-30 22:17:00.692644
Epoch:[ 199 4 ] loss: 0.38044506311416626 2022-06-30 22:17:01.107486
Epoch:[ 199 5 ] loss: 0.3812973201274872 2022-06-30 22:17:01.531271
Epoch:[ 199 6 ] loss: 0.38361507654190063 2022-06-30 22:17:01.944949
Epoch:[ 199 7 ] loss: 0.3835967779159546 2022-06-30 22:17:02.368581
Epoch:[ 199 8 ] loss: 0.38170191645622253 2022-06-30 22:17:02.785639
Epoch:[ 199 9 ] loss: 0.3796297013759613 2022-06-30 22:17:03.201395
Epoch:[ 199 10 ] loss: 0.3821524977684021 2022-06-30 22:17:03.622829
Epoch:[ 199 11 ] loss: 0.3803618848323822 2022-06-30 22:17:04.038429
Epoch:[ 199 12 ] loss: 0.3821500837802887 2022-06-30 22:17:04.452887
Epoch:[ 199 13 ] loss: 0.3786182999610901 2022-06-30 22:17:04.866929
Epoch:[ 199 14 ] loss: 0.38267290592193604 2022-06-30 22:17:05.284087
Epoch:[ 199 15 ] loss: 0.37911278009414673 2022-06-30 22:17:05.703630
Epoch:[ 199 16 ] loss: 0.3794369697570801 2022-06-30 22:17:11.188136
Epoch:[ 199 17 ] loss: 0.3824901282787323 2022-06-30 22:17:11.604919
Epoch:[ 199 18 ] loss: 0.38238489627838135 2022-06-30 22:17:12.020516
Epoch:[ 199 19 ] loss: 0.3829256594181061 2022-06-30 22:17:12.435745
Training_Epoch:[ 199 ] Training_loss: 0.38149302899837495 2022-06-30 22:17:12.436470
learning rate:  7.205759403792802e-05
val: 1 0.48064637184143066
val: 2 0.46897199749946594
val: 3 0.4811132550239563
val: 4 0.4869295358657837
val: 5 0.4773704707622528
val: 6 0.46667298674583435
val: 7 0.4728739261627197
val: 8 0.49110668897628784
val: 9 0.4772241413593292
val: 10 0.4656233489513397
val: 11 0.48387831449508667
val: 12 0.49231186509132385
val: 13 0.4739707112312317
val: 14 0.4824294149875641
val: 15 0.4737984538078308
val: 16 0.4634283185005188
val: 17 0.48292276263237
val: 18 0.4854776859283447
val: 19 0.4781813323497772
val: 20 0.4640101194381714
val_Epoch:[ 199 ] val_loss: 0.477447085082531 2022-06-30 22:17:15.831778
start training 2022-06-30 22:17:15.935475
Epoch:[ 200 0 ] loss: 0.38001886010169983 2022-06-30 22:17:30.101323
Epoch:[ 200 1 ] loss: 0.3822891414165497 2022-06-30 22:17:30.628327
Epoch:[ 200 2 ] loss: 0.38116389513015747 2022-06-30 22:17:31.050591
Epoch:[ 200 3 ] loss: 0.3832385838031769 2022-06-30 22:17:31.481532
Epoch:[ 200 4 ] loss: 0.3836715519428253 2022-06-30 22:17:31.896134
Epoch:[ 200 5 ] loss: 0.38158273696899414 2022-06-30 22:17:32.310743
Epoch:[ 200 6 ] loss: 0.3809942603111267 2022-06-30 22:17:32.724412
Epoch:[ 200 7 ] loss: 0.3802323639392853 2022-06-30 22:17:33.139848
Epoch:[ 200 8 ] loss: 0.3810449242591858 2022-06-30 22:17:33.556439
Epoch:[ 200 9 ] loss: 0.3789893090724945 2022-06-30 22:17:33.975685
Epoch:[ 200 10 ] loss: 0.3819236755371094 2022-06-30 22:17:34.390814
Epoch:[ 200 11 ] loss: 0.3827686905860901 2022-06-30 22:17:34.813085
Epoch:[ 200 12 ] loss: 0.38178038597106934 2022-06-30 22:17:35.229403
Epoch:[ 200 13 ] loss: 0.38265764713287354 2022-06-30 22:17:35.650837
Epoch:[ 200 14 ] loss: 0.3794601261615753 2022-06-30 22:17:36.064408
Epoch:[ 200 15 ] loss: 0.38086792826652527 2022-06-30 22:17:36.481786
Epoch:[ 200 16 ] loss: 0.3828032910823822 2022-06-30 22:17:42.289858
Epoch:[ 200 17 ] loss: 0.3801167905330658 2022-06-30 22:17:42.706060
Epoch:[ 200 18 ] loss: 0.38201647996902466 2022-06-30 22:17:43.123930
Epoch:[ 200 19 ] loss: 0.38328173756599426 2022-06-30 22:17:43.541998
Training_Epoch:[ 200 ] Training_loss: 0.38154511898756027 2022-06-30 22:17:43.542734
learning rate:  7.205759403792802e-05
netparams have been saved once 200
val: 1 0.47694694995880127
val: 2 0.48681652545928955
val: 3 0.4845890998840332
val: 4 0.47063565254211426
val: 5 0.4901508390903473
val: 6 0.473832368850708
val: 7 0.4709128439426422
val: 8 0.49118557572364807
val: 9 0.48999321460723877
val: 10 0.46664074063301086
val: 11 0.46511635184288025
val: 12 0.4731453061103821
val: 13 0.46940892934799194
val: 14 0.47143104672431946
val: 15 0.48862767219543457
val: 16 0.48163121938705444
val: 17 0.47887101769447327
val: 18 0.4754880666732788
val: 19 0.4693855941295624
val: 20 0.48575976490974426
val_Epoch:[ 200 ] val_loss: 0.47802843898534775 2022-06-30 22:17:46.942437
start training 2022-06-30 22:17:47.043208
Epoch:[ 201 0 ] loss: 0.38171276450157166 2022-06-30 22:18:01.881883
Epoch:[ 201 1 ] loss: 0.37986063957214355 2022-06-30 22:18:02.303006
Epoch:[ 201 2 ] loss: 0.3828594982624054 2022-06-30 22:18:02.726186
Epoch:[ 201 3 ] loss: 0.38165944814682007 2022-06-30 22:18:03.150382
Epoch:[ 201 4 ] loss: 0.3815695643424988 2022-06-30 22:18:03.575009
Epoch:[ 201 5 ] loss: 0.3816272020339966 2022-06-30 22:18:03.996235
Epoch:[ 201 6 ] loss: 0.3829212486743927 2022-06-30 22:18:04.424681
Epoch:[ 201 7 ] loss: 0.3806140124797821 2022-06-30 22:18:04.851447
Epoch:[ 201 8 ] loss: 0.380042165517807 2022-06-30 22:18:05.269984
Epoch:[ 201 9 ] loss: 0.3805311620235443 2022-06-30 22:18:05.699994
Epoch:[ 201 10 ] loss: 0.38248714804649353 2022-06-30 22:18:06.121848
Epoch:[ 201 11 ] loss: 0.3805134892463684 2022-06-30 22:18:06.546770
Epoch:[ 201 12 ] loss: 0.3840872347354889 2022-06-30 22:18:06.968712
Epoch:[ 201 13 ] loss: 0.3803049623966217 2022-06-30 22:18:07.393699
Epoch:[ 201 14 ] loss: 0.3801155984401703 2022-06-30 22:18:07.812479
Epoch:[ 201 15 ] loss: 0.3808153569698334 2022-06-30 22:18:08.238466
Epoch:[ 201 16 ] loss: 0.3812192976474762 2022-06-30 22:18:13.198581
Epoch:[ 201 17 ] loss: 0.3821515142917633 2022-06-30 22:18:13.622594
Epoch:[ 201 18 ] loss: 0.38055336475372314 2022-06-30 22:18:14.055052
Epoch:[ 201 19 ] loss: 0.3818834722042084 2022-06-30 22:18:14.474974
Training_Epoch:[ 201 ] Training_loss: 0.3813764572143555 2022-06-30 22:18:14.476013
learning rate:  5.764607523034242e-05
val: 1 0.46628451347351074
val: 2 0.49160099029541016
val: 3 0.48553499579429626
val: 4 0.48452988266944885
val: 5 0.473551869392395
val: 6 0.4770428538322449
val: 7 0.4846349358558655
val: 8 0.47445881366729736
val: 9 0.48923569917678833
val: 10 0.48299357295036316
val: 11 0.4821130633354187
val: 12 0.47503462433815
val: 13 0.4761836528778076
val: 14 0.4710557460784912
val: 15 0.4705851078033447
val: 16 0.4735168218612671
val: 17 0.4711439609527588
val: 18 0.48131656646728516
val: 19 0.4798820912837982
val: 20 0.47107407450675964
val_Epoch:[ 201 ] val_loss: 0.47808869183063507 2022-06-30 22:18:17.858635
start training 2022-06-30 22:18:17.962473
Epoch:[ 202 0 ] loss: 0.3841814696788788 2022-06-30 22:18:32.304419
Epoch:[ 202 1 ] loss: 0.3806849420070648 2022-06-30 22:18:32.895839
Epoch:[ 202 2 ] loss: 0.38235005736351013 2022-06-30 22:18:33.314011
Epoch:[ 202 3 ] loss: 0.3810531198978424 2022-06-30 22:18:33.735016
Epoch:[ 202 4 ] loss: 0.3814070522785187 2022-06-30 22:18:34.156075
Epoch:[ 202 5 ] loss: 0.381734699010849 2022-06-30 22:18:34.576829
Epoch:[ 202 6 ] loss: 0.3803223967552185 2022-06-30 22:18:34.995077
Epoch:[ 202 7 ] loss: 0.3800022602081299 2022-06-30 22:18:35.413992
Epoch:[ 202 8 ] loss: 0.381618469953537 2022-06-30 22:18:35.833525
Epoch:[ 202 9 ] loss: 0.37969207763671875 2022-06-30 22:18:36.258382
Epoch:[ 202 10 ] loss: 0.37913408875465393 2022-06-30 22:18:36.682781
Epoch:[ 202 11 ] loss: 0.37858718633651733 2022-06-30 22:18:37.109900
Epoch:[ 202 12 ] loss: 0.3797037601470947 2022-06-30 22:18:37.535685
Epoch:[ 202 13 ] loss: 0.38239994645118713 2022-06-30 22:18:37.955232
Epoch:[ 202 14 ] loss: 0.3829107880592346 2022-06-30 22:18:38.380286
Epoch:[ 202 15 ] loss: 0.3800855875015259 2022-06-30 22:18:38.804757
Epoch:[ 202 16 ] loss: 0.3824673295021057 2022-06-30 22:18:44.098722
Epoch:[ 202 17 ] loss: 0.3806658089160919 2022-06-30 22:18:44.596989
Epoch:[ 202 18 ] loss: 0.3842984139919281 2022-06-30 22:18:45.019894
Epoch:[ 202 19 ] loss: 0.38100743293762207 2022-06-30 22:18:45.440554
Training_Epoch:[ 202 ] Training_loss: 0.38121534436941146 2022-06-30 22:18:45.441208
learning rate:  5.764607523034242e-05
netparams have been saved once 202
val: 1 0.464112251996994
val: 2 0.4662078320980072
val: 3 0.4758386015892029
val: 4 0.49000245332717896
val: 5 0.47546377778053284
val: 6 0.4758163094520569
val: 7 0.4894351661205292
val: 8 0.48721814155578613
val: 9 0.4820137917995453
val: 10 0.4830080568790436
val: 11 0.47366786003112793
val: 12 0.47864603996276855
val: 13 0.48244258761405945
val: 14 0.4865947961807251
val: 15 0.4736167788505554
val: 16 0.47516173124313354
val: 17 0.47291630506515503
val: 18 0.47773653268814087
val: 19 0.48124489188194275
val: 20 0.4861985445022583
val_Epoch:[ 202 ] val_loss: 0.4788671225309372 2022-06-30 22:18:48.863377
start training 2022-06-30 22:18:48.965450
Epoch:[ 203 0 ] loss: 0.3817562460899353 2022-06-30 22:19:03.692629
Epoch:[ 203 1 ] loss: 0.37990400195121765 2022-06-30 22:19:04.111397
Epoch:[ 203 2 ] loss: 0.38088130950927734 2022-06-30 22:19:04.534951
Epoch:[ 203 3 ] loss: 0.3804960250854492 2022-06-30 22:19:04.954729
Epoch:[ 203 4 ] loss: 0.38264840841293335 2022-06-30 22:19:05.374960
Epoch:[ 203 5 ] loss: 0.3814198970794678 2022-06-30 22:19:05.796170
Epoch:[ 203 6 ] loss: 0.3818809390068054 2022-06-30 22:19:06.226828
Epoch:[ 203 7 ] loss: 0.3817002773284912 2022-06-30 22:19:06.647124
Epoch:[ 203 8 ] loss: 0.38277414441108704 2022-06-30 22:19:07.071946
Epoch:[ 203 9 ] loss: 0.38005173206329346 2022-06-30 22:19:07.496888
Epoch:[ 203 10 ] loss: 0.3816302418708801 2022-06-30 22:19:07.915254
Epoch:[ 203 11 ] loss: 0.38105738162994385 2022-06-30 22:19:08.341381
Epoch:[ 203 12 ] loss: 0.37933841347694397 2022-06-30 22:19:08.762040
Epoch:[ 203 13 ] loss: 0.38217467069625854 2022-06-30 22:19:09.183771
Epoch:[ 203 14 ] loss: 0.3826523721218109 2022-06-30 22:19:09.602422
Epoch:[ 203 15 ] loss: 0.38129013776779175 2022-06-30 22:19:10.028657
Epoch:[ 203 16 ] loss: 0.3816307783126831 2022-06-30 22:19:15.626845
Epoch:[ 203 17 ] loss: 0.38189375400543213 2022-06-30 22:19:16.044287
Epoch:[ 203 18 ] loss: 0.3803356885910034 2022-06-30 22:19:16.466855
Epoch:[ 203 19 ] loss: 0.38156500458717346 2022-06-30 22:19:16.887047
Training_Epoch:[ 203 ] Training_loss: 0.38135407119989395 2022-06-30 22:19:16.887767
learning rate:  5.764607523034242e-05
val: 1 0.4886570870876312
val: 2 0.4634445607662201
val: 3 0.48444923758506775
val: 4 0.47069019079208374
val: 5 0.47927379608154297
val: 6 0.47040030360221863
val: 7 0.47750338912010193
val: 8 0.4838469624519348
val: 9 0.4691832661628723
val: 10 0.4669466018676758
val: 11 0.48769694566726685
val: 12 0.4869234263896942
val: 13 0.47381487488746643
val: 14 0.47034674882888794
val: 15 0.4844116270542145
val: 16 0.4822894334793091
val: 17 0.471275269985199
val: 18 0.4856448173522949
val: 19 0.4830373227596283
val: 20 0.48486876487731934
val_Epoch:[ 203 ] val_loss: 0.4782352313399315 2022-06-30 22:19:20.377832
start training 2022-06-30 22:19:20.479988
Epoch:[ 204 0 ] loss: 0.3808231055736542 2022-06-30 22:19:34.808994
Epoch:[ 204 1 ] loss: 0.38237524032592773 2022-06-30 22:19:35.254141
Epoch:[ 204 2 ] loss: 0.3809293508529663 2022-06-30 22:19:35.674623
Epoch:[ 204 3 ] loss: 0.3815461993217468 2022-06-30 22:19:36.094190
Epoch:[ 204 4 ] loss: 0.3801715075969696 2022-06-30 22:19:36.527367
Epoch:[ 204 5 ] loss: 0.3818291127681732 2022-06-30 22:19:36.953751
Epoch:[ 204 6 ] loss: 0.38012826442718506 2022-06-30 22:19:37.374825
Epoch:[ 204 7 ] loss: 0.38057941198349 2022-06-30 22:19:37.801047
Epoch:[ 204 8 ] loss: 0.3787945508956909 2022-06-30 22:19:38.220116
Epoch:[ 204 9 ] loss: 0.38203734159469604 2022-06-30 22:19:38.643449
Epoch:[ 204 10 ] loss: 0.3810490369796753 2022-06-30 22:19:39.061373
Epoch:[ 204 11 ] loss: 0.38153335452079773 2022-06-30 22:19:39.486474
Epoch:[ 204 12 ] loss: 0.3828718662261963 2022-06-30 22:19:39.907194
Epoch:[ 204 13 ] loss: 0.3822769522666931 2022-06-30 22:19:40.328782
Epoch:[ 204 14 ] loss: 0.3808456361293793 2022-06-30 22:19:40.748262
Epoch:[ 204 15 ] loss: 0.3816815912723541 2022-06-30 22:19:41.168296
Epoch:[ 204 16 ] loss: 0.38076743483543396 2022-06-30 22:19:46.614646
Epoch:[ 204 17 ] loss: 0.3812939524650574 2022-06-30 22:19:47.035740
Epoch:[ 204 18 ] loss: 0.38130539655685425 2022-06-30 22:19:47.456158
Epoch:[ 204 19 ] loss: 0.3808800280094147 2022-06-30 22:19:47.879094
Training_Epoch:[ 204 ] Training_loss: 0.3811859667301178 2022-06-30 22:19:47.879803
learning rate:  5.764607523034242e-05
netparams have been saved once 204
val: 1 0.4874996542930603
val: 2 0.4794307053089142
val: 3 0.4764326214790344
val: 4 0.4901248514652252
val: 5 0.4836046099662781
val: 6 0.4787653684616089
val: 7 0.4755605161190033
val: 8 0.4698141813278198
val: 9 0.48547112941741943
val: 10 0.479871541261673
val: 11 0.47590890526771545
val: 12 0.474136084318161
val: 13 0.4834839701652527
val: 14 0.4704033136367798
val: 15 0.4615529179573059
val: 16 0.46824562549591064
val: 17 0.4772958755493164
val: 18 0.4828018546104431
val: 19 0.4727849066257477
val: 20 0.491137832403183
val_Epoch:[ 204 ] val_loss: 0.4782163232564926 2022-06-30 22:19:51.285660
start training 2022-06-30 22:19:51.391912
Epoch:[ 205 0 ] loss: 0.3816838264465332 2022-06-30 22:20:06.018925
Epoch:[ 205 1 ] loss: 0.3820512890815735 2022-06-30 22:20:06.455724
Epoch:[ 205 2 ] loss: 0.3804160952568054 2022-06-30 22:20:06.880840
Epoch:[ 205 3 ] loss: 0.3796199858188629 2022-06-30 22:20:07.299561
Epoch:[ 205 4 ] loss: 0.381641685962677 2022-06-30 22:20:07.716820
Epoch:[ 205 5 ] loss: 0.38065236806869507 2022-06-30 22:20:08.134828
Epoch:[ 205 6 ] loss: 0.3817637264728546 2022-06-30 22:20:08.560611
Epoch:[ 205 7 ] loss: 0.38058018684387207 2022-06-30 22:20:08.983403
Epoch:[ 205 8 ] loss: 0.38202279806137085 2022-06-30 22:20:09.404834
Epoch:[ 205 9 ] loss: 0.3812764585018158 2022-06-30 22:20:09.822846
Epoch:[ 205 10 ] loss: 0.3828151226043701 2022-06-30 22:20:10.244217
Epoch:[ 205 11 ] loss: 0.38236263394355774 2022-06-30 22:20:10.668219
Epoch:[ 205 12 ] loss: 0.37974610924720764 2022-06-30 22:20:11.085806
Epoch:[ 205 13 ] loss: 0.3795287311077118 2022-06-30 22:20:11.514849
Epoch:[ 205 14 ] loss: 0.3814951777458191 2022-06-30 22:20:11.935922
Epoch:[ 205 15 ] loss: 0.38031914830207825 2022-06-30 22:20:12.356417
Epoch:[ 205 16 ] loss: 0.3810916841030121 2022-06-30 22:20:17.913080
Epoch:[ 205 17 ] loss: 0.3807297945022583 2022-06-30 22:20:18.331917
Epoch:[ 205 18 ] loss: 0.38173535466194153 2022-06-30 22:20:18.760481
Epoch:[ 205 19 ] loss: 0.38289833068847656 2022-06-30 22:20:19.181132
Training_Epoch:[ 205 ] Training_loss: 0.3812215253710747 2022-06-30 22:20:19.181779
learning rate:  5.764607523034242e-05
val: 1 0.48670637607574463
val: 2 0.48591557145118713
val: 3 0.46611663699150085
val: 4 0.4619339108467102
val: 5 0.4759746491909027
val: 6 0.4821297824382782
val: 7 0.4632834792137146
val: 8 0.48129987716674805
val: 9 0.4780876636505127
val: 10 0.47746461629867554
val: 11 0.48111897706985474
val: 12 0.4908265769481659
val: 13 0.48085319995880127
val: 14 0.4745183289051056
val: 15 0.47923946380615234
val: 16 0.48189523816108704
val: 17 0.48391756415367126
val: 18 0.4822952151298523
val: 19 0.492984801530838
val: 20 0.4800381660461426
val_Epoch:[ 205 ] val_loss: 0.4793300047516823 2022-06-30 22:20:22.490087
start training 2022-06-30 22:20:22.591461
Epoch:[ 206 0 ] loss: 0.3789674937725067 2022-06-30 22:20:36.710806
Epoch:[ 206 1 ] loss: 0.3818346858024597 2022-06-30 22:20:37.320902
Epoch:[ 206 2 ] loss: 0.3819035589694977 2022-06-30 22:20:37.742666
Epoch:[ 206 3 ] loss: 0.38038042187690735 2022-06-30 22:20:38.162700
Epoch:[ 206 4 ] loss: 0.37911733984947205 2022-06-30 22:20:38.581232
Epoch:[ 206 5 ] loss: 0.37923359870910645 2022-06-30 22:20:39.000135
Epoch:[ 206 6 ] loss: 0.38056811690330505 2022-06-30 22:20:39.417658
Epoch:[ 206 7 ] loss: 0.38206374645233154 2022-06-30 22:20:39.838735
Epoch:[ 206 8 ] loss: 0.3808083236217499 2022-06-30 22:20:40.259727
Epoch:[ 206 9 ] loss: 0.38006657361984253 2022-06-30 22:20:40.681397
Epoch:[ 206 10 ] loss: 0.38268598914146423 2022-06-30 22:20:41.106137
Epoch:[ 206 11 ] loss: 0.38165056705474854 2022-06-30 22:20:41.524850
Epoch:[ 206 12 ] loss: 0.3816240131855011 2022-06-30 22:20:41.944685
Epoch:[ 206 13 ] loss: 0.3809996545314789 2022-06-30 22:20:42.368071
Epoch:[ 206 14 ] loss: 0.38209959864616394 2022-06-30 22:20:42.792947
Epoch:[ 206 15 ] loss: 0.38188955187797546 2022-06-30 22:20:43.214271
Epoch:[ 206 16 ] loss: 0.38277652859687805 2022-06-30 22:20:48.556235
Epoch:[ 206 17 ] loss: 0.3822554051876068 2022-06-30 22:20:48.977645
Epoch:[ 206 18 ] loss: 0.38058653473854065 2022-06-30 22:20:49.398844
Epoch:[ 206 19 ] loss: 0.3823898732662201 2022-06-30 22:20:49.817229
Training_Epoch:[ 206 ] Training_loss: 0.3811950787901878 2022-06-30 22:20:49.818025
learning rate:  5.764607523034242e-05
netparams have been saved once 206
val: 1 0.4730740785598755
val: 2 0.47420525550842285
val: 3 0.4803560674190521
val: 4 0.4878781735897064
val: 5 0.4750291109085083
val: 6 0.4729419946670532
val: 7 0.48666438460350037
val: 8 0.4661213457584381
val: 9 0.47140181064605713
val: 10 0.4818277955055237
val: 11 0.4801989197731018
val: 12 0.486103355884552
val: 13 0.4812370538711548
val: 14 0.4877956807613373
val: 15 0.4760483205318451
val: 16 0.4789620339870453
val: 17 0.47343260049819946
val: 18 0.4857091009616852
val: 19 0.4931904077529907
val: 20 0.46510806679725647
val_Epoch:[ 206 ] val_loss: 0.4788642778992653 2022-06-30 22:20:53.224537
start training 2022-06-30 22:20:53.320908
Epoch:[ 207 0 ] loss: 0.3827649652957916 2022-06-30 22:21:06.947616
Epoch:[ 207 1 ] loss: 0.38307198882102966 2022-06-30 22:21:07.628279
Epoch:[ 207 2 ] loss: 0.38211268186569214 2022-06-30 22:21:08.054620
Epoch:[ 207 3 ] loss: 0.3804115056991577 2022-06-30 22:21:08.486469
Epoch:[ 207 4 ] loss: 0.3808571398258209 2022-06-30 22:21:08.903400
Epoch:[ 207 5 ] loss: 0.37945371866226196 2022-06-30 22:21:09.319778
Epoch:[ 207 6 ] loss: 0.38031381368637085 2022-06-30 22:21:09.739295
Epoch:[ 207 7 ] loss: 0.38140538334846497 2022-06-30 22:21:10.163527
Epoch:[ 207 8 ] loss: 0.37956947088241577 2022-06-30 22:21:10.582520
Epoch:[ 207 9 ] loss: 0.38076406717300415 2022-06-30 22:21:11.002919
Epoch:[ 207 10 ] loss: 0.3812914788722992 2022-06-30 22:21:11.420053
Epoch:[ 207 11 ] loss: 0.38262394070625305 2022-06-30 22:21:11.843874
Epoch:[ 207 12 ] loss: 0.38010719418525696 2022-06-30 22:21:12.261284
Epoch:[ 207 13 ] loss: 0.3813314437866211 2022-06-30 22:21:12.680684
Epoch:[ 207 14 ] loss: 0.3809818625450134 2022-06-30 22:21:13.099197
Epoch:[ 207 15 ] loss: 0.38075780868530273 2022-06-30 22:21:13.524258
Epoch:[ 207 16 ] loss: 0.3817480802536011 2022-06-30 22:21:18.755720
Epoch:[ 207 17 ] loss: 0.3804299831390381 2022-06-30 22:21:19.175989
Epoch:[ 207 18 ] loss: 0.37979647517204285 2022-06-30 22:21:19.598899
Epoch:[ 207 19 ] loss: 0.3826022744178772 2022-06-30 22:21:20.019548
Training_Epoch:[ 207 ] Training_loss: 0.38111976385116575 2022-06-30 22:21:20.020312
learning rate:  5.764607523034242e-05
val: 1 0.4816567003726959
val: 2 0.46063679456710815
val: 3 0.49010568857192993
val: 4 0.4797007143497467
val: 5 0.47908392548561096
val: 6 0.4810844957828522
val: 7 0.4861609637737274
val: 8 0.4766347408294678
val: 9 0.4921380281448364
val: 10 0.4642625153064728
val: 11 0.48062431812286377
val: 12 0.48629841208457947
val: 13 0.460035502910614
val: 14 0.48190516233444214
val: 15 0.4808318018913269
val: 16 0.4734584093093872
val: 17 0.48948344588279724
val: 18 0.4780202805995941
val: 19 0.45134732127189636
val: 20 0.4851623475551605
val_Epoch:[ 207 ] val_loss: 0.4779315784573555 2022-06-30 22:21:23.435666
start training 2022-06-30 22:21:23.534395
Epoch:[ 208 0 ] loss: 0.3811269998550415 2022-06-30 22:21:37.933531
Epoch:[ 208 1 ] loss: 0.38137248158454895 2022-06-30 22:21:38.379085
Epoch:[ 208 2 ] loss: 0.3808000981807709 2022-06-30 22:21:38.800552
Epoch:[ 208 3 ] loss: 0.381345272064209 2022-06-30 22:21:39.221097
Epoch:[ 208 4 ] loss: 0.38178709149360657 2022-06-30 22:21:39.641280
Epoch:[ 208 5 ] loss: 0.3802570104598999 2022-06-30 22:21:40.060129
Epoch:[ 208 6 ] loss: 0.3818790316581726 2022-06-30 22:21:40.485793
Epoch:[ 208 7 ] loss: 0.3812805414199829 2022-06-30 22:21:40.904432
Epoch:[ 208 8 ] loss: 0.3803273141384125 2022-06-30 22:21:41.342286
Epoch:[ 208 9 ] loss: 0.38019153475761414 2022-06-30 22:21:41.763874
Epoch:[ 208 10 ] loss: 0.38279518485069275 2022-06-30 22:21:42.183307
Epoch:[ 208 11 ] loss: 0.3815349042415619 2022-06-30 22:21:42.604640
Epoch:[ 208 12 ] loss: 0.37892407178878784 2022-06-30 22:21:43.032649
Epoch:[ 208 13 ] loss: 0.3832896649837494 2022-06-30 22:21:43.457102
Epoch:[ 208 14 ] loss: 0.3803959786891937 2022-06-30 22:21:43.875377
Epoch:[ 208 15 ] loss: 0.3817206025123596 2022-06-30 22:21:44.296257
Epoch:[ 208 16 ] loss: 0.3786812722682953 2022-06-30 22:21:49.976496
Epoch:[ 208 17 ] loss: 0.3825916051864624 2022-06-30 22:21:50.396585
Epoch:[ 208 18 ] loss: 0.37988924980163574 2022-06-30 22:21:50.823967
Epoch:[ 208 19 ] loss: 0.3807418644428253 2022-06-30 22:21:51.243036
Training_Epoch:[ 208 ] Training_loss: 0.38104658871889113 2022-06-30 22:21:51.243845
learning rate:  5.764607523034242e-05
netparams have been saved once 208
val: 1 0.47632288932800293
val: 2 0.46826475858688354
val: 3 0.4900195896625519
val: 4 0.4689820110797882
val: 5 0.46885669231414795
val: 6 0.4838431477546692
val: 7 0.46883562207221985
val: 8 0.4701402187347412
val: 9 0.48168104887008667
val: 10 0.4803825616836548
val: 11 0.47808220982551575
val: 12 0.47940847277641296
val: 13 0.46921178698539734
val: 14 0.4875212013721466
val: 15 0.47785335779190063
val: 16 0.4832569360733032
val: 17 0.4890219569206238
val: 18 0.4756194055080414
val: 19 0.47831711173057556
val: 20 0.4893324375152588
val_Epoch:[ 208 ] val_loss: 0.4782476708292961 2022-06-30 22:21:54.656955
start training 2022-06-30 22:21:54.753434
Epoch:[ 209 0 ] loss: 0.380023717880249 2022-06-30 22:22:09.120081
Epoch:[ 209 1 ] loss: 0.38210785388946533 2022-06-30 22:22:09.546413
Epoch:[ 209 2 ] loss: 0.37985607981681824 2022-06-30 22:22:09.963480
Epoch:[ 209 3 ] loss: 0.37965261936187744 2022-06-30 22:22:10.390135
Epoch:[ 209 4 ] loss: 0.3819270133972168 2022-06-30 22:22:10.810866
Epoch:[ 209 5 ] loss: 0.3821800947189331 2022-06-30 22:22:11.230442
Epoch:[ 209 6 ] loss: 0.38043662905693054 2022-06-30 22:22:11.655412
Epoch:[ 209 7 ] loss: 0.37997564673423767 2022-06-30 22:22:12.075327
Epoch:[ 209 8 ] loss: 0.3818937838077545 2022-06-30 22:22:12.493958
Epoch:[ 209 9 ] loss: 0.38328027725219727 2022-06-30 22:22:12.910499
Epoch:[ 209 10 ] loss: 0.38049936294555664 2022-06-30 22:22:13.331189
Epoch:[ 209 11 ] loss: 0.3814142644405365 2022-06-30 22:22:13.754748
Epoch:[ 209 12 ] loss: 0.38239139318466187 2022-06-30 22:22:14.189190
Epoch:[ 209 13 ] loss: 0.38129693269729614 2022-06-30 22:22:14.613582
Epoch:[ 209 14 ] loss: 0.379102885723114 2022-06-30 22:22:15.033009
Epoch:[ 209 15 ] loss: 0.38087743520736694 2022-06-30 22:22:15.459797
Epoch:[ 209 16 ] loss: 0.38130757212638855 2022-06-30 22:22:20.656741
Epoch:[ 209 17 ] loss: 0.3806599974632263 2022-06-30 22:22:21.077299
Epoch:[ 209 18 ] loss: 0.38208580017089844 2022-06-30 22:22:21.499540
Epoch:[ 209 19 ] loss: 0.3804260492324829 2022-06-30 22:22:21.923358
Training_Epoch:[ 209 ] Training_loss: 0.3810697704553604 2022-06-30 22:22:21.924152
learning rate:  5.764607523034242e-05
val: 1 0.4884655475616455
val: 2 0.48268431425094604
val: 3 0.47732338309288025
val: 4 0.48052603006362915
val: 5 0.469169557094574
val: 6 0.483335018157959
val: 7 0.4838675558567047
val: 8 0.4781676232814789
val: 9 0.47248396277427673
val: 10 0.48120632767677307
val: 11 0.48434144258499146
val: 12 0.46672412753105164
val: 13 0.4776328206062317
val: 14 0.4842519462108612
val: 15 0.46516406536102295
val: 16 0.48054203391075134
val: 17 0.47177717089653015
val: 18 0.4887600541114807
val: 19 0.47547659277915955
val: 20 0.48563119769096375
val_Epoch:[ 209 ] val_loss: 0.4788765385746956 2022-06-30 22:22:25.297464
start training 2022-06-30 22:22:25.395486
Epoch:[ 210 0 ] loss: 0.3789014518260956 2022-06-30 22:22:40.334086
Epoch:[ 210 1 ] loss: 0.38224923610687256 2022-06-30 22:22:40.789568
Epoch:[ 210 2 ] loss: 0.38369220495224 2022-06-30 22:22:41.279556
Epoch:[ 210 3 ] loss: 0.3825870752334595 2022-06-30 22:22:41.698368
Epoch:[ 210 4 ] loss: 0.38076335191726685 2022-06-30 22:22:42.118706
Epoch:[ 210 5 ] loss: 0.38007983565330505 2022-06-30 22:22:42.540125
Epoch:[ 210 6 ] loss: 0.38059625029563904 2022-06-30 22:22:42.962022
Epoch:[ 210 7 ] loss: 0.38075482845306396 2022-06-30 22:22:43.387092
Epoch:[ 210 8 ] loss: 0.37924817204475403 2022-06-30 22:22:43.806729
Epoch:[ 210 9 ] loss: 0.38110366463661194 2022-06-30 22:22:44.224666
Epoch:[ 210 10 ] loss: 0.3815106749534607 2022-06-30 22:22:44.642581
Epoch:[ 210 11 ] loss: 0.3838425874710083 2022-06-30 22:22:45.064175
Epoch:[ 210 12 ] loss: 0.3782614767551422 2022-06-30 22:22:45.490355
Epoch:[ 210 13 ] loss: 0.3794967830181122 2022-06-30 22:22:45.909259
Epoch:[ 210 14 ] loss: 0.3812835216522217 2022-06-30 22:22:46.332023
Epoch:[ 210 15 ] loss: 0.3809797465801239 2022-06-30 22:22:46.751481
Epoch:[ 210 16 ] loss: 0.3818269968032837 2022-06-30 22:22:52.021365
Epoch:[ 210 17 ] loss: 0.3822009265422821 2022-06-30 22:22:52.439771
Epoch:[ 210 18 ] loss: 0.380412220954895 2022-06-30 22:22:52.862785
Epoch:[ 210 19 ] loss: 0.3818313181400299 2022-06-30 22:22:53.283111
Training_Epoch:[ 210 ] Training_loss: 0.3810811161994934 2022-06-30 22:22:53.283994
learning rate:  5.764607523034242e-05
netparams have been saved once 210
val: 1 0.48200830817222595
val: 2 0.4819490909576416
val: 3 0.4697319269180298
val: 4 0.4813094437122345
val: 5 0.4725382328033447
val: 6 0.4913190007209778
val: 7 0.46495041251182556
val: 8 0.47289466857910156
val: 9 0.4878734052181244
val: 10 0.48077601194381714
val: 11 0.485617995262146
val: 12 0.48352351784706116
val: 13 0.4788082540035248
val: 14 0.47704607248306274
val: 15 0.47452405095100403
val: 16 0.4692564904689789
val: 17 0.48520246148109436
val: 18 0.4737005829811096
val: 19 0.48145467042922974
val: 20 0.467053085565567
val_Epoch:[ 210 ] val_loss: 0.4780768841505051 2022-06-30 22:22:56.736617
start training 2022-06-30 22:22:56.834476
Epoch:[ 211 0 ] loss: 0.3821899890899658 2022-06-30 22:23:11.491924
Epoch:[ 211 1 ] loss: 0.3824104368686676 2022-06-30 22:23:11.914511
Epoch:[ 211 2 ] loss: 0.3810662627220154 2022-06-30 22:23:12.328083
Epoch:[ 211 3 ] loss: 0.3816054165363312 2022-06-30 22:23:12.752352
Epoch:[ 211 4 ] loss: 0.3800257444381714 2022-06-30 22:23:13.239161
Epoch:[ 211 5 ] loss: 0.38117140531539917 2022-06-30 22:23:13.661682
Epoch:[ 211 6 ] loss: 0.3788134455680847 2022-06-30 22:23:14.077739
Epoch:[ 211 7 ] loss: 0.37910744547843933 2022-06-30 22:23:14.494094
Epoch:[ 211 8 ] loss: 0.3820129930973053 2022-06-30 22:23:14.907890
Epoch:[ 211 9 ] loss: 0.3803865909576416 2022-06-30 22:23:15.320533
Epoch:[ 211 10 ] loss: 0.37973031401634216 2022-06-30 22:23:15.733789
Epoch:[ 211 11 ] loss: 0.3798835277557373 2022-06-30 22:23:16.148107
Epoch:[ 211 12 ] loss: 0.38193634152412415 2022-06-30 22:23:16.570043
Epoch:[ 211 13 ] loss: 0.3836791217327118 2022-06-30 22:23:16.985813
Epoch:[ 211 14 ] loss: 0.38124918937683105 2022-06-30 22:23:17.400249
Epoch:[ 211 15 ] loss: 0.37973126769065857 2022-06-30 22:23:17.820653
Epoch:[ 211 16 ] loss: 0.3826371729373932 2022-06-30 22:23:23.325742
Epoch:[ 211 17 ] loss: 0.37888675928115845 2022-06-30 22:23:23.739504
Epoch:[ 211 18 ] loss: 0.38166263699531555 2022-06-30 22:23:24.161815
Epoch:[ 211 19 ] loss: 0.3793633282184601 2022-06-30 22:23:24.581261
Training_Epoch:[ 211 ] Training_loss: 0.3808774694800377 2022-06-30 22:23:24.582160
learning rate:  4.611686018427394e-05
val: 1 0.4790891110897064
val: 2 0.47830846905708313
val: 3 0.48648062348365784
val: 4 0.4824114441871643
val: 5 0.48150965571403503
val: 6 0.481098473072052
val: 7 0.4643423855304718
val: 8 0.47049665451049805
val: 9 0.4828583598136902
val: 10 0.47840675711631775
val: 11 0.4654262065887451
val: 12 0.47199416160583496
val: 13 0.4751148521900177
val: 14 0.49558019638061523
val: 15 0.47652414441108704
val: 16 0.4879707098007202
val: 17 0.48610031604766846
val: 18 0.4840241074562073
val: 19 0.47613805532455444
val: 20 0.464038610458374
val_Epoch:[ 211 ] val_loss: 0.47839566469192507 2022-06-30 22:23:28.041016
start training 2022-06-30 22:23:28.141714
Epoch:[ 212 0 ] loss: 0.38112372159957886 2022-06-30 22:23:43.192217
Epoch:[ 212 1 ] loss: 0.3817206025123596 2022-06-30 22:23:43.609395
Epoch:[ 212 2 ] loss: 0.3784084916114807 2022-06-30 22:23:44.026594
Epoch:[ 212 3 ] loss: 0.3802320063114166 2022-06-30 22:23:44.451476
Epoch:[ 212 4 ] loss: 0.37949103116989136 2022-06-30 22:23:44.939955
Epoch:[ 212 5 ] loss: 0.3796781003475189 2022-06-30 22:23:45.363999
Epoch:[ 212 6 ] loss: 0.38059863448143005 2022-06-30 22:23:45.783071
Epoch:[ 212 7 ] loss: 0.3822208344936371 2022-06-30 22:23:46.199089
Epoch:[ 212 8 ] loss: 0.38295692205429077 2022-06-30 22:23:46.620037
Epoch:[ 212 9 ] loss: 0.38061875104904175 2022-06-30 22:23:47.040939
Epoch:[ 212 10 ] loss: 0.382754385471344 2022-06-30 22:23:47.458466
Epoch:[ 212 11 ] loss: 0.3806951642036438 2022-06-30 22:23:47.874110
Epoch:[ 212 12 ] loss: 0.37921270728111267 2022-06-30 22:23:48.287744
Epoch:[ 212 13 ] loss: 0.3813028335571289 2022-06-30 22:23:48.704311
Epoch:[ 212 14 ] loss: 0.37998807430267334 2022-06-30 22:23:49.122497
Epoch:[ 212 15 ] loss: 0.380251407623291 2022-06-30 22:23:49.542087
Epoch:[ 212 16 ] loss: 0.38041767477989197 2022-06-30 22:23:54.727517
Epoch:[ 212 17 ] loss: 0.38013821840286255 2022-06-30 22:23:55.146188
Epoch:[ 212 18 ] loss: 0.3820221722126007 2022-06-30 22:23:55.567927
Epoch:[ 212 19 ] loss: 0.3795514702796936 2022-06-30 22:23:55.982626
Training_Epoch:[ 212 ] Training_loss: 0.3806691601872444 2022-06-30 22:23:55.983275
learning rate:  4.611686018427394e-05
netparams have been saved once 212
val: 1 0.4672105610370636
val: 2 0.4788534343242645
val: 3 0.4740771949291229
val: 4 0.4701814651489258
val: 5 0.4835202395915985
val: 6 0.4775131642818451
val: 7 0.47691023349761963
val: 8 0.46331262588500977
val: 9 0.49590444564819336
val: 10 0.4831981360912323
val: 11 0.4876866638660431
val: 12 0.4811761677265167
val: 13 0.4639224112033844
val: 14 0.4891996383666992
val: 15 0.48114636540412903
val: 16 0.48704031109809875
val: 17 0.4807620942592621
val: 18 0.4824496805667877
val: 19 0.4665689468383789
val: 20 0.4783150255680084
val_Epoch:[ 212 ] val_loss: 0.4784474402666092 2022-06-30 22:23:59.422591
start training 2022-06-30 22:23:59.519784
Epoch:[ 213 0 ] loss: 0.38169506192207336 2022-06-30 22:24:13.997795
Epoch:[ 213 1 ] loss: 0.38065752387046814 2022-06-30 22:24:14.443377
Epoch:[ 213 2 ] loss: 0.3808174431324005 2022-06-30 22:24:14.864465
Epoch:[ 213 3 ] loss: 0.3813190758228302 2022-06-30 22:24:15.282754
Epoch:[ 213 4 ] loss: 0.3816772699356079 2022-06-30 22:24:15.722555
Epoch:[ 213 5 ] loss: 0.3821488916873932 2022-06-30 22:24:16.143977
Epoch:[ 213 6 ] loss: 0.3772819936275482 2022-06-30 22:24:16.618184
Epoch:[ 213 7 ] loss: 0.37945812940597534 2022-06-30 22:24:17.101742
Epoch:[ 213 8 ] loss: 0.38030263781547546 2022-06-30 22:24:17.535013
Epoch:[ 213 9 ] loss: 0.38189271092414856 2022-06-30 22:24:17.952324
Epoch:[ 213 10 ] loss: 0.3783845007419586 2022-06-30 22:24:18.396077
Epoch:[ 213 11 ] loss: 0.38031286001205444 2022-06-30 22:24:18.813640
Epoch:[ 213 12 ] loss: 0.3801395893096924 2022-06-30 22:24:19.257958
Epoch:[ 213 13 ] loss: 0.3805219233036041 2022-06-30 22:24:19.706212
Epoch:[ 213 14 ] loss: 0.38071897625923157 2022-06-30 22:24:20.148743
Epoch:[ 213 15 ] loss: 0.380092978477478 2022-06-30 22:24:20.569269
Epoch:[ 213 16 ] loss: 0.38097840547561646 2022-06-30 22:24:25.857376
Epoch:[ 213 17 ] loss: 0.3808729946613312 2022-06-30 22:24:26.289075
Epoch:[ 213 18 ] loss: 0.3820428252220154 2022-06-30 22:24:26.727625
Epoch:[ 213 19 ] loss: 0.38092732429504395 2022-06-30 22:24:27.151710
Training_Epoch:[ 213 ] Training_loss: 0.38061215579509733 2022-06-30 22:24:27.152477
learning rate:  4.611686018427394e-05
val: 1 0.47672951221466064
val: 2 0.4779694974422455
val: 3 0.4706360995769501
val: 4 0.47592321038246155
val: 5 0.4781293272972107
val: 6 0.4743625521659851
val: 7 0.49011608958244324
val: 8 0.4686681926250458
val: 9 0.48827511072158813
val: 10 0.4755155146121979
val: 11 0.48431092500686646
val: 12 0.47862645983695984
val: 13 0.47496500611305237
val: 14 0.487702339887619
val: 15 0.4799972176551819
val: 16 0.4824303686618805
val: 17 0.46268948912620544
val: 18 0.4882771670818329
val: 19 0.4869835078716278
val: 20 0.47039103507995605
val_Epoch:[ 213 ] val_loss: 0.47863493114709854 2022-06-30 22:24:30.510651
start training 2022-06-30 22:24:30.608567
Epoch:[ 214 0 ] loss: 0.3800157308578491 2022-06-30 22:24:44.766546
Epoch:[ 214 1 ] loss: 0.38055336475372314 2022-06-30 22:24:45.196137
Epoch:[ 214 2 ] loss: 0.38083937764167786 2022-06-30 22:24:45.620435
Epoch:[ 214 3 ] loss: 0.38124778866767883 2022-06-30 22:24:46.036804
Epoch:[ 214 4 ] loss: 0.38063502311706543 2022-06-30 22:24:46.450025
Epoch:[ 214 5 ] loss: 0.38117215037345886 2022-06-30 22:24:46.863611
Epoch:[ 214 6 ] loss: 0.37917670607566833 2022-06-30 22:24:47.277033
Epoch:[ 214 7 ] loss: 0.3798990845680237 2022-06-30 22:24:47.693824
Epoch:[ 214 8 ] loss: 0.3804243505001068 2022-06-30 22:24:48.109864
Epoch:[ 214 9 ] loss: 0.3797972798347473 2022-06-30 22:24:48.524927
Epoch:[ 214 10 ] loss: 0.38026440143585205 2022-06-30 22:24:48.965371
Epoch:[ 214 11 ] loss: 0.3792417645454407 2022-06-30 22:24:49.387371
Epoch:[ 214 12 ] loss: 0.38337424397468567 2022-06-30 22:24:49.874539
Epoch:[ 214 13 ] loss: 0.38119587302207947 2022-06-30 22:24:50.380790
Epoch:[ 214 14 ] loss: 0.38039007782936096 2022-06-30 22:24:50.803065
Epoch:[ 214 15 ] loss: 0.37993863224983215 2022-06-30 22:24:51.228220
Epoch:[ 214 16 ] loss: 0.38123831152915955 2022-06-30 22:24:56.544742
Epoch:[ 214 17 ] loss: 0.382986843585968 2022-06-30 22:24:57.002814
Epoch:[ 214 18 ] loss: 0.37811633944511414 2022-06-30 22:24:57.486428
Epoch:[ 214 19 ] loss: 0.3804361820220947 2022-06-30 22:24:57.917655
Training_Epoch:[ 214 ] Training_loss: 0.38054717630147933 2022-06-30 22:24:57.918506
learning rate:  4.611686018427394e-05
netparams have been saved once 214
val: 1 0.4794050455093384
val: 2 0.4906424880027771
val: 3 0.4695790708065033
val: 4 0.46829596161842346
val: 5 0.4674451947212219
val: 6 0.47365695238113403
val: 7 0.46806544065475464
val: 8 0.4893464148044586
val: 9 0.48825663328170776
val: 10 0.47263583540916443
val: 11 0.48619481921195984
val: 12 0.47683843970298767
val: 13 0.47918227314949036
val: 14 0.4731766879558563
val: 15 0.49507957696914673
val: 16 0.4685325026512146
val: 17 0.49083271622657776
val: 18 0.49470099806785583
val: 19 0.4673602879047394
val: 20 0.46622559428215027
val_Epoch:[ 214 ] val_loss: 0.4782726466655731 2022-06-30 22:25:01.394082
start training 2022-06-30 22:25:01.490858
Epoch:[ 215 0 ] loss: 0.3802398145198822 2022-06-30 22:25:15.860123
Epoch:[ 215 1 ] loss: 0.3822981119155884 2022-06-30 22:25:16.289902
Epoch:[ 215 2 ] loss: 0.37966421246528625 2022-06-30 22:25:16.705681
Epoch:[ 215 3 ] loss: 0.38030919432640076 2022-06-30 22:25:17.121135
Epoch:[ 215 4 ] loss: 0.3801589012145996 2022-06-30 22:25:17.535298
Epoch:[ 215 5 ] loss: 0.37957584857940674 2022-06-30 22:25:17.950399
Epoch:[ 215 6 ] loss: 0.3779436945915222 2022-06-30 22:25:18.371665
Epoch:[ 215 7 ] loss: 0.3808760643005371 2022-06-30 22:25:18.783836
Epoch:[ 215 8 ] loss: 0.3796524107456207 2022-06-30 22:25:19.197094
Epoch:[ 215 9 ] loss: 0.381399929523468 2022-06-30 22:25:19.618008
Epoch:[ 215 10 ] loss: 0.3806115388870239 2022-06-30 22:25:20.033841
Epoch:[ 215 11 ] loss: 0.38004401326179504 2022-06-30 22:25:20.449809
Epoch:[ 215 12 ] loss: 0.38233625888824463 2022-06-30 22:25:20.869302
Epoch:[ 215 13 ] loss: 0.3798424303531647 2022-06-30 22:25:21.283405
Epoch:[ 215 14 ] loss: 0.38149556517601013 2022-06-30 22:25:21.702093
Epoch:[ 215 15 ] loss: 0.3815634846687317 2022-06-30 22:25:22.116808
Epoch:[ 215 16 ] loss: 0.3803357481956482 2022-06-30 22:25:27.769625
Epoch:[ 215 17 ] loss: 0.38208603858947754 2022-06-30 22:25:28.185980
Epoch:[ 215 18 ] loss: 0.3805149495601654 2022-06-30 22:25:28.601299
Epoch:[ 215 19 ] loss: 0.3809901177883148 2022-06-30 22:25:29.016349
Training_Epoch:[ 215 ] Training_loss: 0.3805969163775444 2022-06-30 22:25:29.017119
learning rate:  4.611686018427394e-05
val: 1 0.4582775831222534
val: 2 0.4892445206642151
val: 3 0.4735344648361206
val: 4 0.4800146520137787
val: 5 0.4823698103427887
val: 6 0.4771602153778076
val: 7 0.46967244148254395
val: 8 0.4818783402442932
val: 9 0.46976298093795776
val: 10 0.4822404980659485
val: 11 0.4802016019821167
val: 12 0.4912054240703583
val: 13 0.48943307995796204
val: 14 0.4710613489151001
val: 15 0.4862370491027832
val: 16 0.4801959991455078
val: 17 0.47962209582328796
val: 18 0.4861304759979248
val: 19 0.46269139647483826
val: 20 0.4747321307659149
val_Epoch:[ 215 ] val_loss: 0.4782833054661751 2022-06-30 22:25:32.391276
start training 2022-06-30 22:25:32.489101
Epoch:[ 216 0 ] loss: 0.37966158986091614 2022-06-30 22:25:46.841906
Epoch:[ 216 1 ] loss: 0.38121557235717773 2022-06-30 22:25:47.277343
Epoch:[ 216 2 ] loss: 0.3780456781387329 2022-06-30 22:25:47.690598
Epoch:[ 216 3 ] loss: 0.3813609480857849 2022-06-30 22:25:48.107655
Epoch:[ 216 4 ] loss: 0.38048550486564636 2022-06-30 22:25:48.523266
Epoch:[ 216 5 ] loss: 0.37974995374679565 2022-06-30 22:25:48.944091
Epoch:[ 216 6 ] loss: 0.3809302747249603 2022-06-30 22:25:49.364126
Epoch:[ 216 7 ] loss: 0.3828069269657135 2022-06-30 22:25:49.780615
Epoch:[ 216 8 ] loss: 0.3812136650085449 2022-06-30 22:25:50.194766
Epoch:[ 216 9 ] loss: 0.3784484565258026 2022-06-30 22:25:50.608018
Epoch:[ 216 10 ] loss: 0.37967532873153687 2022-06-30 22:25:51.029298
Epoch:[ 216 11 ] loss: 0.38095033168792725 2022-06-30 22:25:51.451145
Epoch:[ 216 12 ] loss: 0.3812538683414459 2022-06-30 22:25:51.864878
Epoch:[ 216 13 ] loss: 0.38017964363098145 2022-06-30 22:25:52.279369
Epoch:[ 216 14 ] loss: 0.3816204369068146 2022-06-30 22:25:52.692687
Epoch:[ 216 15 ] loss: 0.38262805342674255 2022-06-30 22:25:53.113229
Epoch:[ 216 16 ] loss: 0.3821788728237152 2022-06-30 22:25:58.303025
Epoch:[ 216 17 ] loss: 0.3813709616661072 2022-06-30 22:25:58.717732
Epoch:[ 216 18 ] loss: 0.38176754117012024 2022-06-30 22:25:59.134186
Epoch:[ 216 19 ] loss: 0.37719017267227173 2022-06-30 22:25:59.549089
Training_Epoch:[ 216 ] Training_loss: 0.3806366890668869 2022-06-30 22:25:59.549778
learning rate:  4.611686018427394e-05
netparams have been saved once 216
val: 1 0.48738640546798706
val: 2 0.48685190081596375
val: 3 0.49141770601272583
val: 4 0.4749543368816376
val: 5 0.4827076196670532
val: 6 0.4704234302043915
val: 7 0.4689384698867798
val: 8 0.4735732674598694
val: 9 0.481923907995224
val: 10 0.47062239050865173
val: 11 0.48447293043136597
val: 12 0.4853857755661011
val: 13 0.4898332953453064
val: 14 0.48991894721984863
val: 15 0.48214003443717957
val: 16 0.474337100982666
val: 17 0.4637991786003113
val: 18 0.4731990098953247
val: 19 0.4802461564540863
val: 20 0.4741627275943756
val_Epoch:[ 216 ] val_loss: 0.47931472957134247 2022-06-30 22:26:02.926815
start training 2022-06-30 22:26:03.023222
Epoch:[ 217 0 ] loss: 0.38035744428634644 2022-06-30 22:26:17.217747
Epoch:[ 217 1 ] loss: 0.3796761631965637 2022-06-30 22:26:17.637225
Epoch:[ 217 2 ] loss: 0.38245218992233276 2022-06-30 22:26:18.052765
Epoch:[ 217 3 ] loss: 0.380401074886322 2022-06-30 22:26:18.475996
Epoch:[ 217 4 ] loss: 0.3817887008190155 2022-06-30 22:26:18.890733
Epoch:[ 217 5 ] loss: 0.3778378367424011 2022-06-30 22:26:19.306143
Epoch:[ 217 6 ] loss: 0.3809577226638794 2022-06-30 22:26:19.728961
Epoch:[ 217 7 ] loss: 0.381172776222229 2022-06-30 22:26:20.143094
Epoch:[ 217 8 ] loss: 0.380439430475235 2022-06-30 22:26:20.562042
Epoch:[ 217 9 ] loss: 0.3802986443042755 2022-06-30 22:26:20.976132
Epoch:[ 217 10 ] loss: 0.381886750459671 2022-06-30 22:26:21.389210
Epoch:[ 217 11 ] loss: 0.37908074259757996 2022-06-30 22:26:21.804255
Epoch:[ 217 12 ] loss: 0.38039153814315796 2022-06-30 22:26:22.220740
Epoch:[ 217 13 ] loss: 0.37937551736831665 2022-06-30 22:26:22.643408
Epoch:[ 217 14 ] loss: 0.38204553723335266 2022-06-30 22:26:23.057985
Epoch:[ 217 15 ] loss: 0.3804767429828644 2022-06-30 22:26:23.472930
Epoch:[ 217 16 ] loss: 0.37928542494773865 2022-06-30 22:26:28.774348
Epoch:[ 217 17 ] loss: 0.37983331084251404 2022-06-30 22:26:29.187459
Epoch:[ 217 18 ] loss: 0.38127920031547546 2022-06-30 22:26:29.604329
Epoch:[ 217 19 ] loss: 0.38027840852737427 2022-06-30 22:26:30.020234
Training_Epoch:[ 217 ] Training_loss: 0.3804657578468323 2022-06-30 22:26:30.020935
learning rate:  4.611686018427394e-05
val: 1 0.4799047112464905
val: 2 0.4769437611103058
val: 3 0.474128782749176
val: 4 0.4946417808532715
val: 5 0.4854832589626312
val: 6 0.47927021980285645
val: 7 0.4838739037513733
val: 8 0.4569496810436249
val: 9 0.46671226620674133
val: 10 0.49680083990097046
val: 11 0.4633282423019409
val: 12 0.4800306558609009
val: 13 0.47401162981987
val: 14 0.4828530550003052
val: 15 0.4769708812236786
val: 16 0.47781088948249817
val: 17 0.49610137939453125
val: 18 0.473375529050827
val: 19 0.47570744156837463
val: 20 0.49149081110954285
val_Epoch:[ 217 ] val_loss: 0.47931948602199553 2022-06-30 22:26:33.402560
start training 2022-06-30 22:26:33.498059
Epoch:[ 218 0 ] loss: 0.3801652789115906 2022-06-30 22:26:48.101568
Epoch:[ 218 1 ] loss: 0.3804197311401367 2022-06-30 22:26:48.514831
Epoch:[ 218 2 ] loss: 0.3811459243297577 2022-06-30 22:26:48.929373
Epoch:[ 218 3 ] loss: 0.37987545132637024 2022-06-30 22:26:49.342988
Epoch:[ 218 4 ] loss: 0.38242441415786743 2022-06-30 22:26:49.756256
Epoch:[ 218 5 ] loss: 0.37930747866630554 2022-06-30 22:26:50.173488
Epoch:[ 218 6 ] loss: 0.3799172043800354 2022-06-30 22:26:50.595565
Epoch:[ 218 7 ] loss: 0.380696177482605 2022-06-30 22:26:51.017809
Epoch:[ 218 8 ] loss: 0.37941232323646545 2022-06-30 22:26:51.431390
Epoch:[ 218 9 ] loss: 0.37916019558906555 2022-06-30 22:26:51.844144
Epoch:[ 218 10 ] loss: 0.37878626585006714 2022-06-30 22:26:52.264949
Epoch:[ 218 11 ] loss: 0.38122230768203735 2022-06-30 22:26:52.680073
Epoch:[ 218 12 ] loss: 0.38249969482421875 2022-06-30 22:26:53.095834
Epoch:[ 218 13 ] loss: 0.3813225030899048 2022-06-30 22:26:53.517982
Epoch:[ 218 14 ] loss: 0.38124871253967285 2022-06-30 22:26:53.934457
Epoch:[ 218 15 ] loss: 0.3789388835430145 2022-06-30 22:26:54.351232
Epoch:[ 218 16 ] loss: 0.3812359571456909 2022-06-30 22:26:59.596088
Epoch:[ 218 17 ] loss: 0.3796049952507019 2022-06-30 22:27:00.008340
Epoch:[ 218 18 ] loss: 0.3801765441894531 2022-06-30 22:27:00.427662
Epoch:[ 218 19 ] loss: 0.37991049885749817 2022-06-30 22:27:00.850066
Training_Epoch:[ 218 ] Training_loss: 0.38037352710962297 2022-06-30 22:27:00.850752
learning rate:  4.611686018427394e-05
netparams have been saved once 218
val: 1 0.4751388132572174
val: 2 0.48248419165611267
val: 3 0.4808399975299835
val: 4 0.4808656573295593
val: 5 0.4715603291988373
val: 6 0.4709203243255615
val: 7 0.47936928272247314
val: 8 0.4811286926269531
val: 9 0.4883492887020111
val: 10 0.4806482493877411
val: 11 0.47982320189476013
val: 12 0.47285985946655273
val: 13 0.4864945113658905
val: 14 0.4796716272830963
val: 15 0.47946697473526
val: 16 0.4899556040763855
val: 17 0.4836407005786896
val: 18 0.47298580408096313
val: 19 0.47617247700691223
val: 20 0.48099446296691895
val_Epoch:[ 218 ] val_loss: 0.479668502509594 2022-06-30 22:27:04.312531
start training 2022-06-30 22:27:04.409449
Epoch:[ 219 0 ] loss: 0.37987902760505676 2022-06-30 22:27:19.037624
Epoch:[ 219 1 ] loss: 0.3790241777896881 2022-06-30 22:27:19.460177
Epoch:[ 219 2 ] loss: 0.3782634735107422 2022-06-30 22:27:19.873631
Epoch:[ 219 3 ] loss: 0.3795112073421478 2022-06-30 22:27:20.289341
Epoch:[ 219 4 ] loss: 0.3815931975841522 2022-06-30 22:27:20.702765
Epoch:[ 219 5 ] loss: 0.3780873715877533 2022-06-30 22:27:21.122325
Epoch:[ 219 6 ] loss: 0.37793052196502686 2022-06-30 22:27:21.538815
Epoch:[ 219 7 ] loss: 0.38090336322784424 2022-06-30 22:27:21.955248
Epoch:[ 219 8 ] loss: 0.3821246027946472 2022-06-30 22:27:22.368906
Epoch:[ 219 9 ] loss: 0.38221627473831177 2022-06-30 22:27:22.781740
Epoch:[ 219 10 ] loss: 0.3800874352455139 2022-06-30 22:27:23.201836
Epoch:[ 219 11 ] loss: 0.3812292814254761 2022-06-30 22:27:23.616440
Epoch:[ 219 12 ] loss: 0.380799800157547 2022-06-30 22:27:24.030393
Epoch:[ 219 13 ] loss: 0.381952166557312 2022-06-30 22:27:24.446955
Epoch:[ 219 14 ] loss: 0.38245880603790283 2022-06-30 22:27:24.868893
Epoch:[ 219 15 ] loss: 0.38117408752441406 2022-06-30 22:27:25.288085
Epoch:[ 219 16 ] loss: 0.383477121591568 2022-06-30 22:27:30.709555
Epoch:[ 219 17 ] loss: 0.3774773180484772 2022-06-30 22:27:31.124335
Epoch:[ 219 18 ] loss: 0.37928664684295654 2022-06-30 22:27:31.537979
Epoch:[ 219 19 ] loss: 0.3807327449321747 2022-06-30 22:27:31.952080
Training_Epoch:[ 219 ] Training_loss: 0.3804104313254356 2022-06-30 22:27:31.952812
learning rate:  4.611686018427394e-05
val: 1 0.47775983810424805
val: 2 0.4733322560787201
val: 3 0.4821586608886719
val: 4 0.48720043897628784
val: 5 0.48718035221099854
val: 6 0.48143520951271057
val: 7 0.490662157535553
val: 8 0.46709001064300537
val: 9 0.4833543002605438
val: 10 0.47106680274009705
val: 11 0.48179638385772705
val: 12 0.4764881134033203
val: 13 0.4681943953037262
val: 14 0.468762069940567
val: 15 0.4698292911052704
val: 16 0.4775698781013489
val: 17 0.49582287669181824
val: 18 0.4817633330821991
val: 19 0.47971275448799133
val: 20 0.4847564995288849
val_Epoch:[ 219 ] val_loss: 0.4792967811226845 2022-06-30 22:27:35.298919
start training 2022-06-30 22:27:35.414611
Epoch:[ 220 0 ] loss: 0.380936861038208 2022-06-30 22:27:49.796772
Epoch:[ 220 1 ] loss: 0.3801996111869812 2022-06-30 22:27:50.242192
Epoch:[ 220 2 ] loss: 0.38259202241897583 2022-06-30 22:27:50.656831
Epoch:[ 220 3 ] loss: 0.38102200627326965 2022-06-30 22:27:51.072133
Epoch:[ 220 4 ] loss: 0.38012564182281494 2022-06-30 22:27:51.492919
Epoch:[ 220 5 ] loss: 0.3810544013977051 2022-06-30 22:27:51.906899
Epoch:[ 220 6 ] loss: 0.3800925314426422 2022-06-30 22:27:52.320015
Epoch:[ 220 7 ] loss: 0.3799033761024475 2022-06-30 22:27:52.736578
Epoch:[ 220 8 ] loss: 0.38137087225914 2022-06-30 22:27:53.151808
Epoch:[ 220 9 ] loss: 0.3794119358062744 2022-06-30 22:27:53.569203
Epoch:[ 220 10 ] loss: 0.3803800642490387 2022-06-30 22:27:53.989624
Epoch:[ 220 11 ] loss: 0.38117408752441406 2022-06-30 22:27:54.407437
Epoch:[ 220 12 ] loss: 0.3810117244720459 2022-06-30 22:27:54.820934
Epoch:[ 220 13 ] loss: 0.379847913980484 2022-06-30 22:27:55.241189
Epoch:[ 220 14 ] loss: 0.3787231147289276 2022-06-30 22:27:55.663275
Epoch:[ 220 15 ] loss: 0.37977662682533264 2022-06-30 22:27:56.077950
Epoch:[ 220 16 ] loss: 0.38009321689605713 2022-06-30 22:28:01.492492
Epoch:[ 220 17 ] loss: 0.37954968214035034 2022-06-30 22:28:01.920845
Epoch:[ 220 18 ] loss: 0.3822113573551178 2022-06-30 22:28:02.336356
Epoch:[ 220 19 ] loss: 0.38090282678604126 2022-06-30 22:28:02.753485
Training_Epoch:[ 220 ] Training_loss: 0.3805189937353134 2022-06-30 22:28:02.754163
learning rate:  4.611686018427394e-05
netparams have been saved once 220
val: 1 0.47386646270751953
val: 2 0.4692184329032898
val: 3 0.48075082898139954
val: 4 0.4852028787136078
val: 5 0.4797976613044739
val: 6 0.4769735336303711
val: 7 0.4802044928073883
val: 8 0.467382550239563
val: 9 0.4764992594718933
val: 10 0.47981083393096924
val: 11 0.48051655292510986
val: 12 0.4735908806324005
val: 13 0.4666731655597687
val: 14 0.48561978340148926
val: 15 0.4993447959423065
val: 16 0.4679919481277466
val: 17 0.4769758880138397
val: 18 0.46837836503982544
val: 19 0.5049616098403931
val: 20 0.48297810554504395
val_Epoch:[ 220 ] val_loss: 0.47883690148591995 2022-06-30 22:28:06.162181
start training 2022-06-30 22:28:06.260877
Epoch:[ 221 0 ] loss: 0.3801842927932739 2022-06-30 22:28:20.351989
Epoch:[ 221 1 ] loss: 0.3821049928665161 2022-06-30 22:28:20.790066
Epoch:[ 221 2 ] loss: 0.38184285163879395 2022-06-30 22:28:21.206710
Epoch:[ 221 3 ] loss: 0.3827434182167053 2022-06-30 22:28:21.629701
Epoch:[ 221 4 ] loss: 0.38268575072288513 2022-06-30 22:28:22.042985
Epoch:[ 221 5 ] loss: 0.3801679015159607 2022-06-30 22:28:22.464456
Epoch:[ 221 6 ] loss: 0.37882208824157715 2022-06-30 22:28:22.877897
Epoch:[ 221 7 ] loss: 0.38005295395851135 2022-06-30 22:28:23.292067
Epoch:[ 221 8 ] loss: 0.3798561990261078 2022-06-30 22:28:23.708222
Epoch:[ 221 9 ] loss: 0.3783407211303711 2022-06-30 22:28:24.123536
Epoch:[ 221 10 ] loss: 0.37994152307510376 2022-06-30 22:28:24.544016
Epoch:[ 221 11 ] loss: 0.380654513835907 2022-06-30 22:28:24.961778
Epoch:[ 221 12 ] loss: 0.38088884949684143 2022-06-30 22:28:25.376873
Epoch:[ 221 13 ] loss: 0.3793119192123413 2022-06-30 22:28:25.797385
Epoch:[ 221 14 ] loss: 0.3802986443042755 2022-06-30 22:28:26.212348
Epoch:[ 221 15 ] loss: 0.37974271178245544 2022-06-30 22:28:26.627989
Epoch:[ 221 16 ] loss: 0.3778199851512909 2022-06-30 22:28:31.971648
Epoch:[ 221 17 ] loss: 0.380434513092041 2022-06-30 22:28:32.385964
Epoch:[ 221 18 ] loss: 0.380206823348999 2022-06-30 22:28:32.800870
Epoch:[ 221 19 ] loss: 0.381221741437912 2022-06-30 22:28:33.215856
Training_Epoch:[ 221 ] Training_loss: 0.3803661197423935 2022-06-30 22:28:33.216633
learning rate:  3.6893488147419155e-05
val: 1 0.47703078389167786
val: 2 0.48654720187187195
val: 3 0.46634355187416077
val: 4 0.4838481843471527
val: 5 0.4947519600391388
val: 6 0.4797264635562897
val: 7 0.4792477488517761
val: 8 0.4726540148258209
val: 9 0.4812855124473572
val: 10 0.4817078709602356
val: 11 0.487671822309494
val: 12 0.4740576148033142
val: 13 0.48322364687919617
val: 14 0.4715379476547241
val: 15 0.4788646996021271
val: 16 0.4746443033218384
val: 17 0.468051940202713
val: 18 0.47560766339302063
val: 19 0.49028927087783813
val: 20 0.4731537997722626
val_Epoch:[ 221 ] val_loss: 0.4790123000741005 2022-06-30 22:28:36.643370
start training 2022-06-30 22:28:36.756774
Epoch:[ 222 0 ] loss: 0.3820328116416931 2022-06-30 22:28:51.155379
Epoch:[ 222 1 ] loss: 0.38038215041160583 2022-06-30 22:28:51.595854
Epoch:[ 222 2 ] loss: 0.3789856731891632 2022-06-30 22:28:52.017809
Epoch:[ 222 3 ] loss: 0.37875717878341675 2022-06-30 22:28:52.433983
Epoch:[ 222 4 ] loss: 0.38078591227531433 2022-06-30 22:28:52.848735
Epoch:[ 222 5 ] loss: 0.38206690549850464 2022-06-30 22:28:53.262854
Epoch:[ 222 6 ] loss: 0.3799613416194916 2022-06-30 22:28:53.680454
Epoch:[ 222 7 ] loss: 0.3805224299430847 2022-06-30 22:28:54.094961
Epoch:[ 222 8 ] loss: 0.3789663314819336 2022-06-30 22:28:54.513627
Epoch:[ 222 9 ] loss: 0.3791123330593109 2022-06-30 22:28:54.935882
Epoch:[ 222 10 ] loss: 0.3796955645084381 2022-06-30 22:28:55.352158
Epoch:[ 222 11 ] loss: 0.3807165324687958 2022-06-30 22:28:55.775070
Epoch:[ 222 12 ] loss: 0.3784344792366028 2022-06-30 22:28:56.187515
Epoch:[ 222 13 ] loss: 0.3802739083766937 2022-06-30 22:28:56.600669
Epoch:[ 222 14 ] loss: 0.3810768723487854 2022-06-30 22:28:57.015947
Epoch:[ 222 15 ] loss: 0.38024210929870605 2022-06-30 22:28:57.430430
Epoch:[ 222 16 ] loss: 0.37904679775238037 2022-06-30 22:29:03.026251
Epoch:[ 222 17 ] loss: 0.3800618052482605 2022-06-30 22:29:03.442165
Epoch:[ 222 18 ] loss: 0.3821541368961334 2022-06-30 22:29:03.953831
Epoch:[ 222 19 ] loss: 0.38052284717559814 2022-06-30 22:29:04.367694
Training_Epoch:[ 222 ] Training_loss: 0.38018990606069564 2022-06-30 22:29:04.368460
learning rate:  3.6893488147419155e-05
netparams have been saved once 222
val: 1 0.47586196660995483
val: 2 0.47596150636672974
val: 3 0.47752392292022705
val: 4 0.4909825921058655
val: 5 0.4666445255279541
val: 6 0.47432783246040344
val: 7 0.4766084849834442
val: 8 0.4703710377216339
val: 9 0.462929904460907
val: 10 0.4763590693473816
val: 11 0.4826711416244507
val: 12 0.48384982347488403
val: 13 0.4751766622066498
val: 14 0.48329004645347595
val: 15 0.4699213206768036
val: 16 0.4769531488418579
val: 17 0.49484744668006897
val: 18 0.49072179198265076
val: 19 0.4928301274776459
val: 20 0.49249884486198425
val_Epoch:[ 222 ] val_loss: 0.4795165598392487 2022-06-30 22:29:07.782834
start training 2022-06-30 22:29:07.878812
Epoch:[ 223 0 ] loss: 0.3816452622413635 2022-06-30 22:29:22.535091
Epoch:[ 223 1 ] loss: 0.38036662340164185 2022-06-30 22:29:22.948922
Epoch:[ 223 2 ] loss: 0.3807954490184784 2022-06-30 22:29:23.368640
Epoch:[ 223 3 ] loss: 0.38057175278663635 2022-06-30 22:29:23.785398
Epoch:[ 223 4 ] loss: 0.3802078068256378 2022-06-30 22:29:24.202014
Epoch:[ 223 5 ] loss: 0.3785719573497772 2022-06-30 22:29:24.617522
Epoch:[ 223 6 ] loss: 0.379787415266037 2022-06-30 22:29:25.030236
Epoch:[ 223 7 ] loss: 0.37905022501945496 2022-06-30 22:29:25.446217
Epoch:[ 223 8 ] loss: 0.3806394934654236 2022-06-30 22:29:25.859513
Epoch:[ 223 9 ] loss: 0.379461407661438 2022-06-30 22:29:26.281545
Epoch:[ 223 10 ] loss: 0.38070014119148254 2022-06-30 22:29:26.697670
Epoch:[ 223 11 ] loss: 0.3804216682910919 2022-06-30 22:29:27.113739
Epoch:[ 223 12 ] loss: 0.3803367018699646 2022-06-30 22:29:27.528562
Epoch:[ 223 13 ] loss: 0.37982869148254395 2022-06-30 22:29:27.950569
Epoch:[ 223 14 ] loss: 0.3818124234676361 2022-06-30 22:29:28.363613
Epoch:[ 223 15 ] loss: 0.38072705268859863 2022-06-30 22:29:28.781863
Epoch:[ 223 16 ] loss: 0.37850213050842285 2022-06-30 22:29:33.902112
Epoch:[ 223 17 ] loss: 0.3808225393295288 2022-06-30 22:29:34.317253
Epoch:[ 223 18 ] loss: 0.38025134801864624 2022-06-30 22:29:34.739065
Epoch:[ 223 19 ] loss: 0.3800920248031616 2022-06-30 22:29:35.154538
Training_Epoch:[ 223 ] Training_loss: 0.3802296057343483 2022-06-30 22:29:35.155193
learning rate:  3.6893488147419155e-05
val: 1 0.4797269105911255
val: 2 0.48006492853164673
val: 3 0.48978450894355774
val: 4 0.4733887314796448
val: 5 0.48749274015426636
val: 6 0.4807592034339905
val: 7 0.47681960463523865
val: 8 0.47440266609191895
val: 9 0.47422996163368225
val: 10 0.484304279088974
val: 11 0.4810713827610016
val: 12 0.4655681848526001
val: 13 0.4748900234699249
val: 14 0.48251667618751526
val: 15 0.4769279956817627
val: 16 0.47905099391937256
val: 17 0.47920650243759155
val: 18 0.46990570425987244
val: 19 0.48438385128974915
val: 20 0.48634061217308044
val_Epoch:[ 223 ] val_loss: 0.4790417730808258 2022-06-30 22:29:38.508877
start training 2022-06-30 22:29:38.621220
Epoch:[ 224 0 ] loss: 0.37884068489074707 2022-06-30 22:29:52.862213
Epoch:[ 224 1 ] loss: 0.3801135718822479 2022-06-30 22:29:53.303916
Epoch:[ 224 2 ] loss: 0.37945279479026794 2022-06-30 22:29:53.716917
Epoch:[ 224 3 ] loss: 0.38147085905075073 2022-06-30 22:29:54.130868
Epoch:[ 224 4 ] loss: 0.380563348531723 2022-06-30 22:29:54.546608
Epoch:[ 224 5 ] loss: 0.3795918822288513 2022-06-30 22:29:54.962837
Epoch:[ 224 6 ] loss: 0.37971431016921997 2022-06-30 22:29:55.378080
Epoch:[ 224 7 ] loss: 0.3814184069633484 2022-06-30 22:29:55.793934
Epoch:[ 224 8 ] loss: 0.3783947825431824 2022-06-30 22:29:56.215104
Epoch:[ 224 9 ] loss: 0.380872905254364 2022-06-30 22:29:56.628280
Epoch:[ 224 10 ] loss: 0.3793841004371643 2022-06-30 22:29:57.043549
Epoch:[ 224 11 ] loss: 0.379594087600708 2022-06-30 22:29:57.460199
Epoch:[ 224 12 ] loss: 0.3819854259490967 2022-06-30 22:29:57.882790
Epoch:[ 224 13 ] loss: 0.3783712089061737 2022-06-30 22:29:58.303352
Epoch:[ 224 14 ] loss: 0.37835946679115295 2022-06-30 22:29:58.723196
Epoch:[ 224 15 ] loss: 0.3823108971118927 2022-06-30 22:29:59.138973
Epoch:[ 224 16 ] loss: 0.38086241483688354 2022-06-30 22:30:04.519505
Epoch:[ 224 17 ] loss: 0.3813133239746094 2022-06-30 22:30:04.932967
Epoch:[ 224 18 ] loss: 0.380339115858078 2022-06-30 22:30:05.349773
Epoch:[ 224 19 ] loss: 0.3797942101955414 2022-06-30 22:30:05.776776
Training_Epoch:[ 224 ] Training_loss: 0.38013738989830015 2022-06-30 22:30:05.777427
learning rate:  3.6893488147419155e-05
netparams have been saved once 224
val: 1 0.48406335711479187
val: 2 0.4801398813724518
val: 3 0.47217103838920593
val: 4 0.48675230145454407
val: 5 0.4779036343097687
val: 6 0.4942034184932709
val: 7 0.4876543879508972
val: 8 0.4872177541255951
val: 9 0.48131218552589417
val: 10 0.4780072271823883
val: 11 0.4615590274333954
val: 12 0.47841134667396545
val: 13 0.47897326946258545
val: 14 0.47581857442855835
val: 15 0.481544554233551
val: 16 0.48797744512557983
val: 17 0.4731794595718384
val: 18 0.4774205684661865
val: 19 0.4724618196487427
val: 20 0.47221627831459045
val_Epoch:[ 224 ] val_loss: 0.4794493764638901 2022-06-30 22:30:09.187387
start training 2022-06-30 22:30:09.283722
Epoch:[ 225 0 ] loss: 0.38077402114868164 2022-06-30 22:30:23.735021
Epoch:[ 225 1 ] loss: 0.37960365414619446 2022-06-30 22:30:24.154532
Epoch:[ 225 2 ] loss: 0.38004955649375916 2022-06-30 22:30:24.569892
Epoch:[ 225 3 ] loss: 0.38052064180374146 2022-06-30 22:30:24.983810
Epoch:[ 225 4 ] loss: 0.38253018260002136 2022-06-30 22:30:25.397979
Epoch:[ 225 5 ] loss: 0.3795888125896454 2022-06-30 22:30:25.813948
Epoch:[ 225 6 ] loss: 0.3812422454357147 2022-06-30 22:30:26.232805
Epoch:[ 225 7 ] loss: 0.3811994194984436 2022-06-30 22:30:26.648396
Epoch:[ 225 8 ] loss: 0.3799467384815216 2022-06-30 22:30:27.063604
Epoch:[ 225 9 ] loss: 0.3793860077857971 2022-06-30 22:30:27.486653
Epoch:[ 225 10 ] loss: 0.3797919452190399 2022-06-30 22:30:27.900455
Epoch:[ 225 11 ] loss: 0.38170352578163147 2022-06-30 22:30:28.315817
Epoch:[ 225 12 ] loss: 0.37900954484939575 2022-06-30 22:30:28.732666
Epoch:[ 225 13 ] loss: 0.37983983755111694 2022-06-30 22:30:29.155633
Epoch:[ 225 14 ] loss: 0.3790097236633301 2022-06-30 22:30:29.578207
Epoch:[ 225 15 ] loss: 0.38162821531295776 2022-06-30 22:30:30.033888
Epoch:[ 225 16 ] loss: 0.3789880871772766 2022-06-30 22:30:35.284509
Epoch:[ 225 17 ] loss: 0.38033196330070496 2022-06-30 22:30:35.698692
Epoch:[ 225 18 ] loss: 0.38052335381507874 2022-06-30 22:30:36.126922
Epoch:[ 225 19 ] loss: 0.3800841271877289 2022-06-30 22:30:36.545569
Training_Epoch:[ 225 ] Training_loss: 0.3802875801920891 2022-06-30 22:30:36.546239
learning rate:  3.6893488147419155e-05
val: 1 0.47591260075569153
val: 2 0.46461036801338196
val: 3 0.48784640431404114
val: 4 0.4625602066516876
val: 5 0.47415855526924133
val: 6 0.4873020648956299
val: 7 0.4805440902709961
val: 8 0.4833434522151947
val: 9 0.481075257062912
val: 10 0.4850672483444214
val: 11 0.4628804922103882
val: 12 0.48281872272491455
val: 13 0.47414159774780273
val: 14 0.4787618815898895
val: 15 0.4791713356971741
val: 16 0.4773159623146057
val: 17 0.4847167134284973
val: 18 0.4871353805065155
val: 19 0.499342143535614
val: 20 0.47825196385383606
val_Epoch:[ 225 ] val_loss: 0.4793478220701218 2022-06-30 22:30:39.989698
start training 2022-06-30 22:30:40.105346
Epoch:[ 226 0 ] loss: 0.37810808420181274 2022-06-30 22:30:54.537301
Epoch:[ 226 1 ] loss: 0.3814397156238556 2022-06-30 22:30:54.951189
Epoch:[ 226 2 ] loss: 0.378606915473938 2022-06-30 22:30:55.364490
Epoch:[ 226 3 ] loss: 0.37887924909591675 2022-06-30 22:30:55.780532
Epoch:[ 226 4 ] loss: 0.37966427206993103 2022-06-30 22:30:56.194071
Epoch:[ 226 5 ] loss: 0.3801737129688263 2022-06-30 22:30:56.614067
Epoch:[ 226 6 ] loss: 0.38045212626457214 2022-06-30 22:30:57.030295
Epoch:[ 226 7 ] loss: 0.37991634011268616 2022-06-30 22:30:57.446353
Epoch:[ 226 8 ] loss: 0.3790636956691742 2022-06-30 22:30:57.867891
Epoch:[ 226 9 ] loss: 0.3810774087905884 2022-06-30 22:30:58.283672
Epoch:[ 226 10 ] loss: 0.37930598855018616 2022-06-30 22:30:58.697909
Epoch:[ 226 11 ] loss: 0.3802514374256134 2022-06-30 22:30:59.112204
Epoch:[ 226 12 ] loss: 0.3805397152900696 2022-06-30 22:30:59.531701
Epoch:[ 226 13 ] loss: 0.3796471953392029 2022-06-30 22:30:59.953719
Epoch:[ 226 14 ] loss: 0.38133370876312256 2022-06-30 22:31:00.374613
Epoch:[ 226 15 ] loss: 0.3808714747428894 2022-06-30 22:31:00.791088
Epoch:[ 226 16 ] loss: 0.38027533888816833 2022-06-30 22:31:05.860512
Epoch:[ 226 17 ] loss: 0.38351190090179443 2022-06-30 22:31:06.274995
Epoch:[ 226 18 ] loss: 0.37962016463279724 2022-06-30 22:31:06.688587
Epoch:[ 226 19 ] loss: 0.380829393863678 2022-06-30 22:31:07.104803
Training_Epoch:[ 226 ] Training_loss: 0.38017839193344116 2022-06-30 22:31:07.105584
learning rate:  3.6893488147419155e-05
netparams have been saved once 226
val: 1 0.48791009187698364
val: 2 0.4764229953289032
val: 3 0.488431453704834
val: 4 0.46882644295692444
val: 5 0.4838305711746216
val: 6 0.47342944145202637
val: 7 0.4777398705482483
val: 8 0.4689326882362366
val: 9 0.4746198058128357
val: 10 0.4762129783630371
val: 11 0.4937567114830017
val: 12 0.46361956000328064
val: 13 0.4774111211299896
val: 14 0.4892931282520294
val: 15 0.4809206426143646
val: 16 0.48462802171707153
val: 17 0.4782729148864746
val: 18 0.4829808175563812
val: 19 0.48465579748153687
val: 20 0.4795980453491211
val_Epoch:[ 226 ] val_loss: 0.4795746549963951 2022-06-30 22:31:10.567027
start training 2022-06-30 22:31:10.665727
Epoch:[ 227 0 ] loss: 0.37945833802223206 2022-06-30 22:31:24.649587
Epoch:[ 227 1 ] loss: 0.379413366317749 2022-06-30 22:31:25.088732
Epoch:[ 227 2 ] loss: 0.38048994541168213 2022-06-30 22:31:25.511653
Epoch:[ 227 3 ] loss: 0.3804265260696411 2022-06-30 22:31:25.926685
Epoch:[ 227 4 ] loss: 0.38120317459106445 2022-06-30 22:31:26.341184
Epoch:[ 227 5 ] loss: 0.3798937499523163 2022-06-30 22:31:26.760971
Epoch:[ 227 6 ] loss: 0.3819942772388458 2022-06-30 22:31:27.173794
Epoch:[ 227 7 ] loss: 0.3788553476333618 2022-06-30 22:31:27.597294
Epoch:[ 227 8 ] loss: 0.3808857202529907 2022-06-30 22:31:28.013830
Epoch:[ 227 9 ] loss: 0.37945497035980225 2022-06-30 22:31:28.428457
Epoch:[ 227 10 ] loss: 0.3780921697616577 2022-06-30 22:31:28.849039
Epoch:[ 227 11 ] loss: 0.38070523738861084 2022-06-30 22:31:29.265273
Epoch:[ 227 12 ] loss: 0.3814091682434082 2022-06-30 22:31:29.681160
Epoch:[ 227 13 ] loss: 0.3798055946826935 2022-06-30 22:31:30.095355
Epoch:[ 227 14 ] loss: 0.3791654109954834 2022-06-30 22:31:30.511482
Epoch:[ 227 15 ] loss: 0.38105395436286926 2022-06-30 22:31:30.927801
Epoch:[ 227 16 ] loss: 0.37884411215782166 2022-06-30 22:31:36.366605
Epoch:[ 227 17 ] loss: 0.3800733685493469 2022-06-30 22:31:36.780185
Epoch:[ 227 18 ] loss: 0.3827461004257202 2022-06-30 22:31:37.201570
Epoch:[ 227 19 ] loss: 0.37822267413139343 2022-06-30 22:31:37.617048
Training_Epoch:[ 227 ] Training_loss: 0.38010966032743454 2022-06-30 22:31:37.617677
learning rate:  3.6893488147419155e-05
val: 1 0.47658222913742065
val: 2 0.47797074913978577
val: 3 0.47922483086586
val: 4 0.48195919394493103
val: 5 0.49053964018821716
val: 6 0.48762187361717224
val: 7 0.4799557626247406
val: 8 0.48029109835624695
val: 9 0.48484906554222107
val: 10 0.48772868514060974
val: 11 0.4754137694835663
val: 12 0.4654141664505005
val: 13 0.4863494038581848
val: 14 0.4743811786174774
val: 15 0.47938209772109985
val: 16 0.4758937954902649
val: 17 0.4756506681442261
val: 18 0.47628289461135864
val: 19 0.4778299629688263
val: 20 0.4826008081436157
val_Epoch:[ 227 ] val_loss: 0.4797960937023163 2022-06-30 22:31:40.967123
start training 2022-06-30 22:31:41.081124
Epoch:[ 228 0 ] loss: 0.3813851475715637 2022-06-30 22:31:55.573738
Epoch:[ 228 1 ] loss: 0.3816346824169159 2022-06-30 22:31:56.014516
Epoch:[ 228 2 ] loss: 0.3809974789619446 2022-06-30 22:31:56.431209
Epoch:[ 228 3 ] loss: 0.38304603099823 2022-06-30 22:31:56.848451
Epoch:[ 228 4 ] loss: 0.3785039186477661 2022-06-30 22:31:57.267893
Epoch:[ 228 5 ] loss: 0.37751978635787964 2022-06-30 22:31:57.687930
Epoch:[ 228 6 ] loss: 0.37793663144111633 2022-06-30 22:31:58.102354
Epoch:[ 228 7 ] loss: 0.381399005651474 2022-06-30 22:31:58.517586
Epoch:[ 228 8 ] loss: 0.378501832485199 2022-06-30 22:31:58.935897
Epoch:[ 228 9 ] loss: 0.38117730617523193 2022-06-30 22:31:59.351269
Epoch:[ 228 10 ] loss: 0.3801578879356384 2022-06-30 22:31:59.766795
Epoch:[ 228 11 ] loss: 0.38134336471557617 2022-06-30 22:32:00.188274
Epoch:[ 228 12 ] loss: 0.37864935398101807 2022-06-30 22:32:00.603018
Epoch:[ 228 13 ] loss: 0.38147133588790894 2022-06-30 22:32:01.023268
Epoch:[ 228 14 ] loss: 0.37996551394462585 2022-06-30 22:32:01.438675
Epoch:[ 228 15 ] loss: 0.3799419701099396 2022-06-30 22:32:01.855771
Epoch:[ 228 16 ] loss: 0.3799968361854553 2022-06-30 22:32:06.975469
Epoch:[ 228 17 ] loss: 0.3811458647251129 2022-06-30 22:32:07.452990
Epoch:[ 228 18 ] loss: 0.3792673647403717 2022-06-30 22:32:07.867775
Epoch:[ 228 19 ] loss: 0.3787482678890228 2022-06-30 22:32:08.282663
Training_Epoch:[ 228 ] Training_loss: 0.38013947904109957 2022-06-30 22:32:08.283391
learning rate:  3.6893488147419155e-05
netparams have been saved once 228
val: 1 0.4767065942287445
val: 2 0.4917541444301605
val: 3 0.4775117337703705
val: 4 0.48137396574020386
val: 5 0.47551849484443665
val: 6 0.47709721326828003
val: 7 0.46545690298080444
val: 8 0.47465965151786804
val: 9 0.47916725277900696
val: 10 0.4811636805534363
val: 11 0.48391494154930115
val: 12 0.4861656129360199
val: 13 0.4948420226573944
val: 14 0.4664546847343445
val: 15 0.4911404550075531
val: 16 0.4758395254611969
val: 17 0.48416903614997864
val: 18 0.476881742477417
val: 19 0.47501280903816223
val: 20 0.47635334730148315
val_Epoch:[ 228 ] val_loss: 0.47955919057130814 2022-06-30 22:32:11.693582
start training 2022-06-30 22:32:11.789895
Epoch:[ 229 0 ] loss: 0.3805485963821411 2022-06-30 22:32:26.034315
Epoch:[ 229 1 ] loss: 0.38190895318984985 2022-06-30 22:32:26.447411
Epoch:[ 229 2 ] loss: 0.3793449103832245 2022-06-30 22:32:26.862897
Epoch:[ 229 3 ] loss: 0.3815274238586426 2022-06-30 22:32:27.277926
Epoch:[ 229 4 ] loss: 0.3775796890258789 2022-06-30 22:32:27.699609
Epoch:[ 229 5 ] loss: 0.3786129951477051 2022-06-30 22:32:28.113493
Epoch:[ 229 6 ] loss: 0.3821585476398468 2022-06-30 22:32:28.535900
Epoch:[ 229 7 ] loss: 0.3807355463504791 2022-06-30 22:32:28.950686
Epoch:[ 229 8 ] loss: 0.37995681166648865 2022-06-30 22:32:29.364814
Epoch:[ 229 9 ] loss: 0.3803676962852478 2022-06-30 22:32:29.786135
Epoch:[ 229 10 ] loss: 0.3782675862312317 2022-06-30 22:32:30.202104
Epoch:[ 229 11 ] loss: 0.3808002173900604 2022-06-30 22:32:30.624342
Epoch:[ 229 12 ] loss: 0.377872496843338 2022-06-30 22:32:31.037935
Epoch:[ 229 13 ] loss: 0.3810577392578125 2022-06-30 22:32:31.452199
Epoch:[ 229 14 ] loss: 0.37885838747024536 2022-06-30 22:32:31.871478
Epoch:[ 229 15 ] loss: 0.3804314434528351 2022-06-30 22:32:32.286141
Epoch:[ 229 16 ] loss: 0.3802282512187958 2022-06-30 22:32:37.810068
Epoch:[ 229 17 ] loss: 0.3806748390197754 2022-06-30 22:32:38.225745
Epoch:[ 229 18 ] loss: 0.3806721568107605 2022-06-30 22:32:38.640644
Epoch:[ 229 19 ] loss: 0.37889760732650757 2022-06-30 22:32:39.055536
Training_Epoch:[ 229 ] Training_loss: 0.3800250947475433 2022-06-30 22:32:39.056242
learning rate:  3.6893488147419155e-05
val: 1 0.4916795790195465
val: 2 0.46961307525634766
val: 3 0.4846642315387726
val: 4 0.48465782403945923
val: 5 0.4818849265575409
val: 6 0.4827851951122284
val: 7 0.4575015902519226
val: 8 0.46848323941230774
val: 9 0.4882679879665375
val: 10 0.4931858479976654
val: 11 0.4883038401603699
val: 12 0.48037976026535034
val: 13 0.46776846051216125
val: 14 0.47299957275390625
val: 15 0.47364529967308044
val: 16 0.4770953357219696
val: 17 0.48800021409988403
val: 18 0.48952391743659973
val: 19 0.47332534193992615
val: 20 0.4816169738769531
val_Epoch:[ 229 ] val_loss: 0.47976911067962646 2022-06-30 22:32:42.394032
start training 2022-06-30 22:32:42.506233
Epoch:[ 230 0 ] loss: 0.38074132800102234 2022-06-30 22:32:57.092859
Epoch:[ 230 1 ] loss: 0.3818870186805725 2022-06-30 22:32:57.506025
Epoch:[ 230 2 ] loss: 0.3775656521320343 2022-06-30 22:32:57.919741
Epoch:[ 230 3 ] loss: 0.3797942101955414 2022-06-30 22:32:58.341091
Epoch:[ 230 4 ] loss: 0.3809138834476471 2022-06-30 22:32:58.762050
Epoch:[ 230 5 ] loss: 0.37993311882019043 2022-06-30 22:32:59.176792
Epoch:[ 230 6 ] loss: 0.38082078099250793 2022-06-30 22:32:59.590720
Epoch:[ 230 7 ] loss: 0.37743961811065674 2022-06-30 22:33:00.010892
Epoch:[ 230 8 ] loss: 0.3798832893371582 2022-06-30 22:33:00.425062
Epoch:[ 230 9 ] loss: 0.3796764016151428 2022-06-30 22:33:00.844385
Epoch:[ 230 10 ] loss: 0.37816086411476135 2022-06-30 22:33:01.262025
Epoch:[ 230 11 ] loss: 0.3815244734287262 2022-06-30 22:33:01.677307
Epoch:[ 230 12 ] loss: 0.37897953391075134 2022-06-30 22:33:02.092321
Epoch:[ 230 13 ] loss: 0.3795177638530731 2022-06-30 22:33:02.509813
Epoch:[ 230 14 ] loss: 0.3810026943683624 2022-06-30 22:33:02.924400
Epoch:[ 230 15 ] loss: 0.3799148201942444 2022-06-30 22:33:03.338931
Epoch:[ 230 16 ] loss: 0.38033464550971985 2022-06-30 22:33:08.645392
Epoch:[ 230 17 ] loss: 0.37994006276130676 2022-06-30 22:33:09.059975
Epoch:[ 230 18 ] loss: 0.3805600106716156 2022-06-30 22:33:09.477363
Epoch:[ 230 19 ] loss: 0.3811900317668915 2022-06-30 22:33:09.896020
Training_Epoch:[ 230 ] Training_loss: 0.3799890100955963 2022-06-30 22:33:09.896725
learning rate:  3.6893488147419155e-05
netparams have been saved once 230
val: 1 0.459517240524292
val: 2 0.4657258689403534
val: 3 0.46877872943878174
val: 4 0.47117552161216736
val: 5 0.476508766412735
val: 6 0.47102221846580505
val: 7 0.47547852993011475
val: 8 0.4679133892059326
val: 9 0.4715996980667114
val: 10 0.4795238971710205
val: 11 0.4911348521709442
val: 12 0.49298909306526184
val: 13 0.48829546570777893
val: 14 0.4868699014186859
val: 15 0.4850485622882843
val: 16 0.48880520462989807
val: 17 0.5003399848937988
val: 18 0.47791722416877747
val: 19 0.4922572672367096
val: 20 0.48423686623573303
val_Epoch:[ 230 ] val_loss: 0.4797569140791893 2022-06-30 22:33:13.314460
start training 2022-06-30 22:33:13.412167
Epoch:[ 231 0 ] loss: 0.3789747357368469 2022-06-30 22:33:28.181997
Epoch:[ 231 1 ] loss: 0.37907731533050537 2022-06-30 22:33:28.596223
Epoch:[ 231 2 ] loss: 0.3816758692264557 2022-06-30 22:33:29.009979
Epoch:[ 231 3 ] loss: 0.37951013445854187 2022-06-30 22:33:29.424947
Epoch:[ 231 4 ] loss: 0.377472847700119 2022-06-30 22:33:29.841333
Epoch:[ 231 5 ] loss: 0.37939611077308655 2022-06-30 22:33:30.263563
Epoch:[ 231 6 ] loss: 0.3797678053379059 2022-06-30 22:33:30.686302
Epoch:[ 231 7 ] loss: 0.3806982636451721 2022-06-30 22:33:31.106364
Epoch:[ 231 8 ] loss: 0.38032031059265137 2022-06-30 22:33:31.521257
Epoch:[ 231 9 ] loss: 0.38027337193489075 2022-06-30 22:33:31.935974
Epoch:[ 231 10 ] loss: 0.3789736032485962 2022-06-30 22:33:32.348619
Epoch:[ 231 11 ] loss: 0.37958428263664246 2022-06-30 22:33:32.765845
Epoch:[ 231 12 ] loss: 0.3798104226589203 2022-06-30 22:33:33.181497
Epoch:[ 231 13 ] loss: 0.38098669052124023 2022-06-30 22:33:33.598637
Epoch:[ 231 14 ] loss: 0.3799467384815216 2022-06-30 22:33:34.017595
Epoch:[ 231 15 ] loss: 0.3799748718738556 2022-06-30 22:33:34.432390
Epoch:[ 231 16 ] loss: 0.38048917055130005 2022-06-30 22:33:39.701224
Epoch:[ 231 17 ] loss: 0.38020583987236023 2022-06-30 22:33:40.185396
Epoch:[ 231 18 ] loss: 0.37897801399230957 2022-06-30 22:33:40.603645
Epoch:[ 231 19 ] loss: 0.3810117542743683 2022-06-30 22:33:41.018858
Training_Epoch:[ 231 ] Training_loss: 0.3798564076423645 2022-06-30 22:33:41.019556
learning rate:  2.9514790517935324e-05
val: 1 0.4797661304473877
val: 2 0.48572105169296265
val: 3 0.4923476278781891
val: 4 0.4703314006328583
val: 5 0.48044678568840027
val: 6 0.4753971993923187
val: 7 0.4666314721107483
val: 8 0.4688062369823456
val: 9 0.4855745732784271
val: 10 0.48530080914497375
val: 11 0.4813010096549988
val: 12 0.4860110580921173
val: 13 0.484981507062912
val: 14 0.47995510697364807
val: 15 0.4751970171928406
val: 16 0.4807867109775543
val: 17 0.4781060814857483
val: 18 0.476316899061203
val: 19 0.47869548201560974
val: 20 0.4793764054775238
val_Epoch:[ 231 ] val_loss: 0.47955252826213834 2022-06-30 22:33:44.487480
start training 2022-06-30 22:33:44.598781
Epoch:[ 232 0 ] loss: 0.38009488582611084 2022-06-30 22:33:59.302533
Epoch:[ 232 1 ] loss: 0.3796958029270172 2022-06-30 22:33:59.716351
Epoch:[ 232 2 ] loss: 0.38050827383995056 2022-06-30 22:34:00.136840
Epoch:[ 232 3 ] loss: 0.3792541027069092 2022-06-30 22:34:00.557272
Epoch:[ 232 4 ] loss: 0.3794967532157898 2022-06-30 22:34:00.971410
Epoch:[ 232 5 ] loss: 0.37939515709877014 2022-06-30 22:34:01.388207
Epoch:[ 232 6 ] loss: 0.3802074193954468 2022-06-30 22:34:01.804142
Epoch:[ 232 7 ] loss: 0.37916243076324463 2022-06-30 22:34:02.220321
Epoch:[ 232 8 ] loss: 0.38034871220588684 2022-06-30 22:34:02.636064
Epoch:[ 232 9 ] loss: 0.3786640167236328 2022-06-30 22:34:03.055784
Epoch:[ 232 10 ] loss: 0.3809807598590851 2022-06-30 22:34:03.468983
Epoch:[ 232 11 ] loss: 0.38108986616134644 2022-06-30 22:34:03.886535
Epoch:[ 232 12 ] loss: 0.3801096975803375 2022-06-30 22:34:04.301751
Epoch:[ 232 13 ] loss: 0.38055649399757385 2022-06-30 22:34:04.717344
Epoch:[ 232 14 ] loss: 0.37933769822120667 2022-06-30 22:34:05.137093
Epoch:[ 232 15 ] loss: 0.38079193234443665 2022-06-30 22:34:05.552481
Epoch:[ 232 16 ] loss: 0.38092923164367676 2022-06-30 22:34:10.489124
Epoch:[ 232 17 ] loss: 0.3801434338092804 2022-06-30 22:34:10.920810
Epoch:[ 232 18 ] loss: 0.37965887784957886 2022-06-30 22:34:11.334578
Epoch:[ 232 19 ] loss: 0.378994345664978 2022-06-30 22:34:11.751213
Training_Epoch:[ 232 ] Training_loss: 0.37997099459171296 2022-06-30 22:34:11.752017
learning rate:  2.9514790517935324e-05
netparams have been saved once 232
val: 1 0.49163323640823364
val: 2 0.47925952076911926
val: 3 0.4854671359062195
val: 4 0.47941333055496216
val: 5 0.4728407859802246
val: 6 0.4836256206035614
val: 7 0.4820232093334198
val: 8 0.48276039958000183
val: 9 0.473000168800354
val: 10 0.4733210802078247
val: 11 0.46287891268730164
val: 12 0.48475193977355957
val: 13 0.48231980204582214
val: 14 0.47128674387931824
val: 15 0.47022953629493713
val: 16 0.4805835485458374
val: 17 0.4794786274433136
val: 18 0.48426440358161926
val: 19 0.4966358244419098
val: 20 0.471462219953537
val_Epoch:[ 232 ] val_loss: 0.47936180233955383 2022-06-30 22:34:15.183464
start training 2022-06-30 22:34:15.277271
Epoch:[ 233 0 ] loss: 0.3784872889518738 2022-06-30 22:34:29.678026
Epoch:[ 233 1 ] loss: 0.3830013871192932 2022-06-30 22:34:30.099337
Epoch:[ 233 2 ] loss: 0.3779977262020111 2022-06-30 22:34:30.513259
Epoch:[ 233 3 ] loss: 0.38128745555877686 2022-06-30 22:34:30.930038
Epoch:[ 233 4 ] loss: 0.3803057372570038 2022-06-30 22:34:31.344343
Epoch:[ 233 5 ] loss: 0.3775278329849243 2022-06-30 22:34:31.758504
Epoch:[ 233 6 ] loss: 0.3810977041721344 2022-06-30 22:34:32.183838
Epoch:[ 233 7 ] loss: 0.3808012306690216 2022-06-30 22:34:32.598859
Epoch:[ 233 8 ] loss: 0.37963446974754333 2022-06-30 22:34:33.019175
Epoch:[ 233 9 ] loss: 0.3806892931461334 2022-06-30 22:34:33.438761
Epoch:[ 233 10 ] loss: 0.3799946904182434 2022-06-30 22:34:33.852599
Epoch:[ 233 11 ] loss: 0.37794187664985657 2022-06-30 22:34:34.268866
Epoch:[ 233 12 ] loss: 0.3812439739704132 2022-06-30 22:34:34.683567
Epoch:[ 233 13 ] loss: 0.3789210319519043 2022-06-30 22:34:35.099385
Epoch:[ 233 14 ] loss: 0.3793717324733734 2022-06-30 22:34:35.521603
Epoch:[ 233 15 ] loss: 0.3782613277435303 2022-06-30 22:34:35.937313
Epoch:[ 233 16 ] loss: 0.38085228204727173 2022-06-30 22:34:40.933974
Epoch:[ 233 17 ] loss: 0.38048437237739563 2022-06-30 22:34:41.347844
Epoch:[ 233 18 ] loss: 0.3793259263038635 2022-06-30 22:34:41.767402
Epoch:[ 233 19 ] loss: 0.3796732723712921 2022-06-30 22:34:42.181727
Training_Epoch:[ 233 ] Training_loss: 0.379845030605793 2022-06-30 22:34:42.182566
learning rate:  2.9514790517935324e-05
val: 1 0.48169222474098206
val: 2 0.5014156699180603
val: 3 0.4774249196052551
val: 4 0.5031586289405823
val: 5 0.47931981086730957
val: 6 0.48447808623313904
val: 7 0.47656601667404175
val: 8 0.4735133945941925
val: 9 0.4872184097766876
val: 10 0.47081029415130615
val: 11 0.4760179817676544
val: 12 0.49830231070518494
val: 13 0.46437984704971313
val: 14 0.4681568443775177
val: 15 0.4649345278739929
val: 16 0.48130640387535095
val: 17 0.4764336347579956
val: 18 0.48128601908683777
val: 19 0.46752265095710754
val: 20 0.4861086905002594
val_Epoch:[ 233 ] val_loss: 0.48000231832265855 2022-06-30 22:34:45.554477
start training 2022-06-30 22:34:45.665839
Epoch:[ 234 0 ] loss: 0.3776136636734009 2022-06-30 22:35:00.063982
Epoch:[ 234 1 ] loss: 0.38022580742836 2022-06-30 22:35:00.483104
Epoch:[ 234 2 ] loss: 0.3814789354801178 2022-06-30 22:35:00.928797
Epoch:[ 234 3 ] loss: 0.3797069489955902 2022-06-30 22:35:01.344883
Epoch:[ 234 4 ] loss: 0.3809535503387451 2022-06-30 22:35:01.761825
Epoch:[ 234 5 ] loss: 0.37937217950820923 2022-06-30 22:35:02.176399
Epoch:[ 234 6 ] loss: 0.37849152088165283 2022-06-30 22:35:02.589571
Epoch:[ 234 7 ] loss: 0.3795797526836395 2022-06-30 22:35:03.006324
Epoch:[ 234 8 ] loss: 0.3802686929702759 2022-06-30 22:35:03.431257
Epoch:[ 234 9 ] loss: 0.3797456920146942 2022-06-30 22:35:03.851433
Epoch:[ 234 10 ] loss: 0.3787751793861389 2022-06-30 22:35:04.264758
Epoch:[ 234 11 ] loss: 0.38252896070480347 2022-06-30 22:35:04.680053
Epoch:[ 234 12 ] loss: 0.379594087600708 2022-06-30 22:35:05.095810
Epoch:[ 234 13 ] loss: 0.3795452117919922 2022-06-30 22:35:05.515017
Epoch:[ 234 14 ] loss: 0.38047006726264954 2022-06-30 22:35:05.930070
Epoch:[ 234 15 ] loss: 0.3793627619743347 2022-06-30 22:35:06.356756
Epoch:[ 234 16 ] loss: 0.37825867533683777 2022-06-30 22:35:12.171826
Epoch:[ 234 17 ] loss: 0.38160619139671326 2022-06-30 22:35:12.586538
Epoch:[ 234 18 ] loss: 0.3788428008556366 2022-06-30 22:35:13.010285
Epoch:[ 234 19 ] loss: 0.37943193316459656 2022-06-30 22:35:13.440700
Training_Epoch:[ 234 ] Training_loss: 0.37979263067245483 2022-06-30 22:35:13.441357
learning rate:  2.9514790517935324e-05
netparams have been saved once 234
val: 1 0.47453081607818604
val: 2 0.4857683479785919
val: 3 0.4837891161441803
val: 4 0.4875747859477997
val: 5 0.47265511751174927
val: 6 0.47354209423065186
val: 7 0.48445770144462585
val: 8 0.4895859956741333
val: 9 0.4801652133464813
val: 10 0.4851107597351074
val: 11 0.4846703112125397
val: 12 0.47437572479248047
val: 13 0.47114989161491394
val: 14 0.4740438163280487
val: 15 0.4780779480934143
val: 16 0.47742125391960144
val: 17 0.4773699641227722
val: 18 0.48607638478279114
val: 19 0.47995832562446594
val: 20 0.47913846373558044
val_Epoch:[ 234 ] val_loss: 0.4799731016159058 2022-06-30 22:35:16.966571
start training 2022-06-30 22:35:17.071619
Epoch:[ 235 0 ] loss: 0.38057634234428406 2022-06-30 22:35:31.955072
Epoch:[ 235 1 ] loss: 0.3797766864299774 2022-06-30 22:35:32.371878
Epoch:[ 235 2 ] loss: 0.3794349133968353 2022-06-30 22:35:32.796935
Epoch:[ 235 3 ] loss: 0.3813405930995941 2022-06-30 22:35:33.216775
Epoch:[ 235 4 ] loss: 0.3804461658000946 2022-06-30 22:35:33.633516
Epoch:[ 235 5 ] loss: 0.37984463572502136 2022-06-30 22:35:34.051040
Epoch:[ 235 6 ] loss: 0.37790554761886597 2022-06-30 22:35:34.467860
Epoch:[ 235 7 ] loss: 0.3779789209365845 2022-06-30 22:35:34.891517
Epoch:[ 235 8 ] loss: 0.37875545024871826 2022-06-30 22:35:35.308296
Epoch:[ 235 9 ] loss: 0.37769171595573425 2022-06-30 22:35:35.724057
Epoch:[ 235 10 ] loss: 0.37863120436668396 2022-06-30 22:35:36.139569
Epoch:[ 235 11 ] loss: 0.3806380033493042 2022-06-30 22:35:36.561491
Epoch:[ 235 12 ] loss: 0.37905338406562805 2022-06-30 22:35:36.979273
Epoch:[ 235 13 ] loss: 0.3805996775627136 2022-06-30 22:35:37.393225
Epoch:[ 235 14 ] loss: 0.38024789094924927 2022-06-30 22:35:37.815252
Epoch:[ 235 15 ] loss: 0.3803718090057373 2022-06-30 22:35:38.231874
Epoch:[ 235 16 ] loss: 0.38036254048347473 2022-06-30 22:35:43.593237
Epoch:[ 235 17 ] loss: 0.38055410981178284 2022-06-30 22:35:44.007466
Epoch:[ 235 18 ] loss: 0.38098135590553284 2022-06-30 22:35:44.422648
Epoch:[ 235 19 ] loss: 0.3800564408302307 2022-06-30 22:35:44.836872
Training_Epoch:[ 235 ] Training_loss: 0.37976236939430236 2022-06-30 22:35:44.837703
learning rate:  2.9514790517935324e-05
val: 1 0.49368035793304443
val: 2 0.48253390192985535
val: 3 0.48910948634147644
val: 4 0.4636102020740509
val: 5 0.4840530753135681
val: 6 0.4802494943141937
val: 7 0.4878367781639099
val: 8 0.48246994614601135
val: 9 0.4633992314338684
val: 10 0.49204596877098083
val: 11 0.4748539924621582
val: 12 0.47440624237060547
val: 13 0.4638463854789734
val: 14 0.4699417054653168
val: 15 0.49430280923843384
val: 16 0.47652482986450195
val: 17 0.484574556350708
val: 18 0.47376394271850586
val: 19 0.46598851680755615
val: 20 0.5025451183319092
val_Epoch:[ 235 ] val_loss: 0.4799868270754814 2022-06-30 22:35:48.288650
start training 2022-06-30 22:35:48.387571
Epoch:[ 236 0 ] loss: 0.3791978657245636 2022-06-30 22:36:02.948087
Epoch:[ 236 1 ] loss: 0.3773731589317322 2022-06-30 22:36:03.401870
Epoch:[ 236 2 ] loss: 0.3799651861190796 2022-06-30 22:36:03.838342
Epoch:[ 236 3 ] loss: 0.37972328066825867 2022-06-30 22:36:04.254260
Epoch:[ 236 4 ] loss: 0.3801298439502716 2022-06-30 22:36:04.684703
Epoch:[ 236 5 ] loss: 0.3801599442958832 2022-06-30 22:36:05.099560
Epoch:[ 236 6 ] loss: 0.37833306193351746 2022-06-30 22:36:05.513130
Epoch:[ 236 7 ] loss: 0.38115087151527405 2022-06-30 22:36:05.936413
Epoch:[ 236 8 ] loss: 0.38004282116889954 2022-06-30 22:36:06.351686
Epoch:[ 236 9 ] loss: 0.3797832727432251 2022-06-30 22:36:06.766853
Epoch:[ 236 10 ] loss: 0.379705011844635 2022-06-30 22:36:07.188041
Epoch:[ 236 11 ] loss: 0.3789871037006378 2022-06-30 22:36:07.606738
Epoch:[ 236 12 ] loss: 0.37827619910240173 2022-06-30 22:36:08.019676
Epoch:[ 236 13 ] loss: 0.3806439936161041 2022-06-30 22:36:08.433877
Epoch:[ 236 14 ] loss: 0.37915706634521484 2022-06-30 22:36:08.848361
Epoch:[ 236 15 ] loss: 0.38126808404922485 2022-06-30 22:36:09.269922
Epoch:[ 236 16 ] loss: 0.3801441490650177 2022-06-30 22:36:14.911198
Epoch:[ 236 17 ] loss: 0.3799038529396057 2022-06-30 22:36:15.336669
Epoch:[ 236 18 ] loss: 0.37939155101776123 2022-06-30 22:36:15.784204
Epoch:[ 236 19 ] loss: 0.3817633092403412 2022-06-30 22:36:16.200962
Training_Epoch:[ 236 ] Training_loss: 0.37975498139858244 2022-06-30 22:36:16.201747
learning rate:  2.9514790517935324e-05
netparams have been saved once 236
val: 1 0.48009705543518066
val: 2 0.49477124214172363
val: 3 0.47568753361701965
val: 4 0.4828779399394989
val: 5 0.48464202880859375
val: 6 0.4789860248565674
val: 7 0.48284223675727844
val: 8 0.47001978754997253
val: 9 0.4766560196876526
val: 10 0.47786375880241394
val: 11 0.4786188304424286
val: 12 0.46803179383277893
val: 13 0.4948943257331848
val: 14 0.48289772868156433
val: 15 0.4730265736579895
val: 16 0.4867328405380249
val: 17 0.4723385274410248
val: 18 0.4859008491039276
val: 19 0.476571649312973
val: 20 0.47352170944213867
val_Epoch:[ 236 ] val_loss: 0.47984892278909685 2022-06-30 22:36:19.604567
start training 2022-06-30 22:36:19.702111
Epoch:[ 237 0 ] loss: 0.38110846281051636 2022-06-30 22:36:34.416586
Epoch:[ 237 1 ] loss: 0.38035571575164795 2022-06-30 22:36:34.831105
Epoch:[ 237 2 ] loss: 0.38082563877105713 2022-06-30 22:36:35.244472
Epoch:[ 237 3 ] loss: 0.37946486473083496 2022-06-30 22:36:35.673140
Epoch:[ 237 4 ] loss: 0.38070017099380493 2022-06-30 22:36:36.095943
Epoch:[ 237 5 ] loss: 0.3806973099708557 2022-06-30 22:36:36.512156
Epoch:[ 237 6 ] loss: 0.38053178787231445 2022-06-30 22:36:36.925505
Epoch:[ 237 7 ] loss: 0.379080206155777 2022-06-30 22:36:37.342135
Epoch:[ 237 8 ] loss: 0.37940526008605957 2022-06-30 22:36:37.755058
Epoch:[ 237 9 ] loss: 0.382839173078537 2022-06-30 22:36:38.170654
Epoch:[ 237 10 ] loss: 0.37984898686408997 2022-06-30 22:36:38.590937
Epoch:[ 237 11 ] loss: 0.379109263420105 2022-06-30 22:36:39.011420
Epoch:[ 237 12 ] loss: 0.3783756196498871 2022-06-30 22:36:39.432182
Epoch:[ 237 13 ] loss: 0.37866806983947754 2022-06-30 22:36:39.855043
Epoch:[ 237 14 ] loss: 0.38065457344055176 2022-06-30 22:36:40.270080
Epoch:[ 237 15 ] loss: 0.37743768095970154 2022-06-30 22:36:40.689066
Epoch:[ 237 16 ] loss: 0.3787487745285034 2022-06-30 22:36:46.165803
Epoch:[ 237 17 ] loss: 0.3789037764072418 2022-06-30 22:36:46.580819
Epoch:[ 237 18 ] loss: 0.380066454410553 2022-06-30 22:36:47.013152
Epoch:[ 237 19 ] loss: 0.3788873851299286 2022-06-30 22:36:47.430290
Training_Epoch:[ 237 ] Training_loss: 0.3797854587435722 2022-06-30 22:36:47.430987
learning rate:  2.9514790517935324e-05
val: 1 0.48610350489616394
val: 2 0.4856995642185211
val: 3 0.4793945848941803
val: 4 0.4798510670661926
val: 5 0.49696481227874756
val: 6 0.47679010033607483
val: 7 0.48247140645980835
val: 8 0.47620925307273865
val: 9 0.4769173860549927
val: 10 0.46558862924575806
val: 11 0.49653348326683044
val: 12 0.49034395813941956
val: 13 0.4768672287464142
val: 14 0.4719892144203186
val: 15 0.4786126911640167
val: 16 0.4793311655521393
val: 17 0.4742448031902313
val: 18 0.47434476017951965
val: 19 0.4772472679615021
val: 20 0.4679777920246124
val_Epoch:[ 237 ] val_loss: 0.4796741336584091 2022-06-30 22:36:50.835659
start training 2022-06-30 22:36:50.934342
Epoch:[ 238 0 ] loss: 0.37938085198402405 2022-06-30 22:37:04.690457
Epoch:[ 238 1 ] loss: 0.37743717432022095 2022-06-30 22:37:05.838391
Epoch:[ 238 2 ] loss: 0.3776615858078003 2022-06-30 22:37:06.258578
Epoch:[ 238 3 ] loss: 0.37670081853866577 2022-06-30 22:37:06.687839
Epoch:[ 238 4 ] loss: 0.38103434443473816 2022-06-30 22:37:07.104378
Epoch:[ 238 5 ] loss: 0.3793146014213562 2022-06-30 22:37:07.520842
Epoch:[ 238 6 ] loss: 0.37810078263282776 2022-06-30 22:37:07.935525
Epoch:[ 238 7 ] loss: 0.3804638981819153 2022-06-30 22:37:08.363360
Epoch:[ 238 8 ] loss: 0.3793450593948364 2022-06-30 22:37:08.777867
Epoch:[ 238 9 ] loss: 0.38441240787506104 2022-06-30 22:37:09.191237
Epoch:[ 238 10 ] loss: 0.38048461079597473 2022-06-30 22:37:09.608907
Epoch:[ 238 11 ] loss: 0.3800133764743805 2022-06-30 22:37:10.031781
Epoch:[ 238 12 ] loss: 0.3799085021018982 2022-06-30 22:37:10.447593
Epoch:[ 238 13 ] loss: 0.3808787167072296 2022-06-30 22:37:10.883029
Epoch:[ 238 14 ] loss: 0.38108131289482117 2022-06-30 22:37:11.304589
Epoch:[ 238 15 ] loss: 0.3789735436439514 2022-06-30 22:37:11.726840
Epoch:[ 238 16 ] loss: 0.3790135085582733 2022-06-30 22:37:17.001478
Epoch:[ 238 17 ] loss: 0.38201701641082764 2022-06-30 22:37:17.426345
Epoch:[ 238 18 ] loss: 0.3798612356185913 2022-06-30 22:37:17.842928
Epoch:[ 238 19 ] loss: 0.37768685817718506 2022-06-30 22:37:18.258078
Training_Epoch:[ 238 ] Training_loss: 0.37968851029872897 2022-06-30 22:37:18.258900
learning rate:  2.9514790517935324e-05
netparams have been saved once 238
val: 1 0.47396397590637207
val: 2 0.4958309829235077
val: 3 0.4779762923717499
val: 4 0.4829264283180237
val: 5 0.4795196056365967
val: 6 0.47838902473449707
val: 7 0.478613942861557
val: 8 0.5002153515815735
val: 9 0.49010762572288513
val: 10 0.48684749007225037
val: 11 0.4846212565898895
val: 12 0.4894600212574005
val: 13 0.4748995900154114
val: 14 0.48350900411605835
val: 15 0.4865734577178955
val: 16 0.4786151349544525
val: 17 0.4681735038757324
val: 18 0.4659154713153839
val: 19 0.4746224582195282
val: 20 0.46546876430511475
val_Epoch:[ 238 ] val_loss: 0.48081246912479403 2022-06-30 22:37:21.650219
start training 2022-06-30 22:37:21.749086
Epoch:[ 239 0 ] loss: 0.37969356775283813 2022-06-30 22:37:36.289474
Epoch:[ 239 1 ] loss: 0.3792358934879303 2022-06-30 22:37:36.732823
Epoch:[ 239 2 ] loss: 0.3795192539691925 2022-06-30 22:37:37.146615
Epoch:[ 239 3 ] loss: 0.37858670949935913 2022-06-30 22:37:37.562038
Epoch:[ 239 4 ] loss: 0.38047462701797485 2022-06-30 22:37:37.975221
Epoch:[ 239 5 ] loss: 0.3818055987358093 2022-06-30 22:37:38.391110
Epoch:[ 239 6 ] loss: 0.38016438484191895 2022-06-30 22:37:38.805395
Epoch:[ 239 7 ] loss: 0.3797359764575958 2022-06-30 22:37:39.223741
Epoch:[ 239 8 ] loss: 0.3798379898071289 2022-06-30 22:37:39.636859
Epoch:[ 239 9 ] loss: 0.37927284836769104 2022-06-30 22:37:40.056656
Epoch:[ 239 10 ] loss: 0.38091978430747986 2022-06-30 22:37:40.476152
Epoch:[ 239 11 ] loss: 0.3780389726161957 2022-06-30 22:37:40.890041
Epoch:[ 239 12 ] loss: 0.37939581274986267 2022-06-30 22:37:41.321223
Epoch:[ 239 13 ] loss: 0.380534827709198 2022-06-30 22:37:41.743049
Epoch:[ 239 14 ] loss: 0.3794754147529602 2022-06-30 22:37:42.157073
Epoch:[ 239 15 ] loss: 0.3803112804889679 2022-06-30 22:37:42.577750
Epoch:[ 239 16 ] loss: 0.37886765599250793 2022-06-30 22:37:47.675732
Epoch:[ 239 17 ] loss: 0.3779717981815338 2022-06-30 22:37:48.088722
Epoch:[ 239 18 ] loss: 0.37942302227020264 2022-06-30 22:37:48.503077
Epoch:[ 239 19 ] loss: 0.38067930936813354 2022-06-30 22:37:48.918818
Training_Epoch:[ 239 ] Training_loss: 0.37969723641872405 2022-06-30 22:37:48.919566
learning rate:  2.9514790517935324e-05
val: 1 0.4744109809398651
val: 2 0.48771998286247253
val: 3 0.48449599742889404
val: 4 0.48626551032066345
val: 5 0.48583272099494934
val: 6 0.48030993342399597
val: 7 0.47487038373947144
val: 8 0.4920961260795593
val: 9 0.48632001876831055
val: 10 0.48421716690063477
val: 11 0.4689483344554901
val: 12 0.4688129425048828
val: 13 0.48620137572288513
val: 14 0.4867301285266876
val: 15 0.47487735748291016
val: 16 0.47886815667152405
val: 17 0.47076210379600525
val: 18 0.4695858061313629
val: 19 0.47123387455940247
val: 20 0.47754836082458496
val_Epoch:[ 239 ] val_loss: 0.4795053631067276 2022-06-30 22:37:52.289344
start training 2022-06-30 22:37:52.395796
Epoch:[ 240 0 ] loss: 0.37974321842193604 2022-06-30 22:38:06.511261
Epoch:[ 240 1 ] loss: 0.38100573420524597 2022-06-30 22:38:06.960254
Epoch:[ 240 2 ] loss: 0.38110870122909546 2022-06-30 22:38:07.373579
Epoch:[ 240 3 ] loss: 0.3802095651626587 2022-06-30 22:38:07.788843
Epoch:[ 240 4 ] loss: 0.3812008202075958 2022-06-30 22:38:08.204256
Epoch:[ 240 5 ] loss: 0.37904998660087585 2022-06-30 22:38:08.635005
Epoch:[ 240 6 ] loss: 0.37963637709617615 2022-06-30 22:38:09.050645
Epoch:[ 240 7 ] loss: 0.38155031204223633 2022-06-30 22:38:09.467474
Epoch:[ 240 8 ] loss: 0.3799625337123871 2022-06-30 22:38:09.883672
Epoch:[ 240 9 ] loss: 0.3797376751899719 2022-06-30 22:38:10.303730
Epoch:[ 240 10 ] loss: 0.377151757478714 2022-06-30 22:38:10.718194
Epoch:[ 240 11 ] loss: 0.3788808286190033 2022-06-30 22:38:11.141116
Epoch:[ 240 12 ] loss: 0.3801679313182831 2022-06-30 22:38:11.560047
Epoch:[ 240 13 ] loss: 0.37977349758148193 2022-06-30 22:38:11.981737
Epoch:[ 240 14 ] loss: 0.3789633512496948 2022-06-30 22:38:12.397370
Epoch:[ 240 15 ] loss: 0.3776973485946655 2022-06-30 22:38:12.814141
Epoch:[ 240 16 ] loss: 0.3780769109725952 2022-06-30 22:38:18.569816
Epoch:[ 240 17 ] loss: 0.38204532861709595 2022-06-30 22:38:18.983069
Epoch:[ 240 18 ] loss: 0.37956157326698303 2022-06-30 22:38:19.399124
Epoch:[ 240 19 ] loss: 0.37857547402381897 2022-06-30 22:38:19.813510
Training_Epoch:[ 240 ] Training_loss: 0.3797049462795258 2022-06-30 22:38:19.814135
learning rate:  2.9514790517935324e-05
netparams have been saved once 240
val: 1 0.47737765312194824
val: 2 0.4779549539089203
val: 3 0.48284024000167847
val: 4 0.4715549945831299
val: 5 0.4811188876628876
val: 6 0.465475857257843
val: 7 0.4801363945007324
val: 8 0.4900219440460205
val: 9 0.4921295642852783
val: 10 0.476092666387558
val: 11 0.48555243015289307
val: 12 0.4766266942024231
val: 13 0.49467504024505615
val: 14 0.46760833263397217
val: 15 0.4648308753967285
val: 16 0.4880109429359436
val: 17 0.48031070828437805
val: 18 0.4786321818828583
val: 19 0.47498759627342224
val: 20 0.4798024594783783
val_Epoch:[ 240 ] val_loss: 0.4792870208621025 2022-06-30 22:38:23.186820
start training 2022-06-30 22:38:23.284357
Epoch:[ 241 0 ] loss: 0.3808739185333252 2022-06-30 22:38:37.961070
Epoch:[ 241 1 ] loss: 0.381035715341568 2022-06-30 22:38:38.378196
Epoch:[ 241 2 ] loss: 0.37885019183158875 2022-06-30 22:38:38.802387
Epoch:[ 241 3 ] loss: 0.3776296079158783 2022-06-30 22:38:39.218384
Epoch:[ 241 4 ] loss: 0.3787599205970764 2022-06-30 22:38:39.633526
Epoch:[ 241 5 ] loss: 0.37928229570388794 2022-06-30 22:38:40.054370
Epoch:[ 241 6 ] loss: 0.3784809708595276 2022-06-30 22:38:40.474020
Epoch:[ 241 7 ] loss: 0.3804054260253906 2022-06-30 22:38:40.892141
Epoch:[ 241 8 ] loss: 0.37887609004974365 2022-06-30 22:38:41.309162
Epoch:[ 241 9 ] loss: 0.3846266567707062 2022-06-30 22:38:41.724546
Epoch:[ 241 10 ] loss: 0.3797726035118103 2022-06-30 22:38:42.145049
Epoch:[ 241 11 ] loss: 0.38004106283187866 2022-06-30 22:38:42.561670
Epoch:[ 241 12 ] loss: 0.37962666153907776 2022-06-30 22:38:42.982182
Epoch:[ 241 13 ] loss: 0.3784189522266388 2022-06-30 22:38:43.396901
Epoch:[ 241 14 ] loss: 0.3797665536403656 2022-06-30 22:38:43.818737
Epoch:[ 241 15 ] loss: 0.38176462054252625 2022-06-30 22:38:44.235357
Epoch:[ 241 16 ] loss: 0.3822610080242157 2022-06-30 22:38:49.424350
Epoch:[ 241 17 ] loss: 0.3773456811904907 2022-06-30 22:38:49.844785
Epoch:[ 241 18 ] loss: 0.37647855281829834 2022-06-30 22:38:50.268370
Epoch:[ 241 19 ] loss: 0.37902727723121643 2022-06-30 22:38:50.685710
Training_Epoch:[ 241 ] Training_loss: 0.3796661883592606 2022-06-30 22:38:50.686532
learning rate:  2.361183241434826e-05
val: 1 0.4955063760280609
val: 2 0.47652697563171387
val: 3 0.480858713388443
val: 4 0.4929194748401642
val: 5 0.48104652762413025
val: 6 0.47646641731262207
val: 7 0.4809379577636719
val: 8 0.47082260251045227
val: 9 0.47350171208381653
val: 10 0.4832514524459839
val: 11 0.47895732522010803
val: 12 0.49180924892425537
val: 13 0.4814571440219879
val: 14 0.46828126907348633
val: 15 0.47663822770118713
val: 16 0.4655110538005829
val: 17 0.46725592017173767
val: 18 0.4792807102203369
val: 19 0.4879781901836395
val: 20 0.4816130995750427
val_Epoch:[ 241 ] val_loss: 0.47953101992607117 2022-06-30 22:38:54.180554
start training 2022-06-30 22:38:54.278007
Epoch:[ 242 0 ] loss: 0.37930595874786377 2022-06-30 22:39:08.665866
Epoch:[ 242 1 ] loss: 0.38221848011016846 2022-06-30 22:39:09.108297
Epoch:[ 242 2 ] loss: 0.37982696294784546 2022-06-30 22:39:09.524894
Epoch:[ 242 3 ] loss: 0.37772589921951294 2022-06-30 22:39:09.940515
Epoch:[ 242 4 ] loss: 0.37826454639434814 2022-06-30 22:39:10.357601
Epoch:[ 242 5 ] loss: 0.37719911336898804 2022-06-30 22:39:10.772857
Epoch:[ 242 6 ] loss: 0.37756842374801636 2022-06-30 22:39:11.195636
Epoch:[ 242 7 ] loss: 0.3795457184314728 2022-06-30 22:39:11.611017
Epoch:[ 242 8 ] loss: 0.3797116279602051 2022-06-30 22:39:12.027240
Epoch:[ 242 9 ] loss: 0.3813983201980591 2022-06-30 22:39:12.450144
Epoch:[ 242 10 ] loss: 0.378720760345459 2022-06-30 22:39:12.863750
Epoch:[ 242 11 ] loss: 0.37958621978759766 2022-06-30 22:39:13.287274
Epoch:[ 242 12 ] loss: 0.3787582218647003 2022-06-30 22:39:13.700871
Epoch:[ 242 13 ] loss: 0.3805234730243683 2022-06-30 22:39:14.121470
Epoch:[ 242 14 ] loss: 0.37976551055908203 2022-06-30 22:39:14.534711
Epoch:[ 242 15 ] loss: 0.379527747631073 2022-06-30 22:39:14.951100
Epoch:[ 242 16 ] loss: 0.38178765773773193 2022-06-30 22:39:20.545192
Epoch:[ 242 17 ] loss: 0.3795117735862732 2022-06-30 22:39:20.961566
Epoch:[ 242 18 ] loss: 0.38082584738731384 2022-06-30 22:39:21.376050
Epoch:[ 242 19 ] loss: 0.3809394836425781 2022-06-30 22:39:21.791099
Training_Epoch:[ 242 ] Training_loss: 0.3796355873346329 2022-06-30 22:39:21.792108
learning rate:  2.361183241434826e-05
netparams have been saved once 242
val: 1 0.4732626676559448
val: 2 0.49292442202568054
val: 3 0.47276571393013
val: 4 0.49962833523750305
val: 5 0.47933241724967957
val: 6 0.46444880962371826
val: 7 0.47671493887901306
val: 8 0.4757845401763916
val: 9 0.4838038980960846
val: 10 0.46778377890586853
val: 11 0.47994041442871094
val: 12 0.4992789030075073
val: 13 0.5037132501602173
val: 14 0.4725523889064789
val: 15 0.4766724109649658
val: 16 0.47000831365585327
val: 17 0.47691991925239563
val: 18 0.4839543104171753
val: 19 0.4789128005504608
val: 20 0.47032561898231506
val_Epoch:[ 242 ] val_loss: 0.47993639260530474 2022-06-30 22:39:25.148542
start training 2022-06-30 22:39:25.247483
Epoch:[ 243 0 ] loss: 0.3820244371891022 2022-06-30 22:39:39.667248
Epoch:[ 243 1 ] loss: 0.37975990772247314 2022-06-30 22:39:40.080324
Epoch:[ 243 2 ] loss: 0.3805503845214844 2022-06-30 22:39:40.502553
Epoch:[ 243 3 ] loss: 0.3795899450778961 2022-06-30 22:39:40.918725
Epoch:[ 243 4 ] loss: 0.37978675961494446 2022-06-30 22:39:41.333972
Epoch:[ 243 5 ] loss: 0.3796203136444092 2022-06-30 22:39:41.748296
Epoch:[ 243 6 ] loss: 0.3800359070301056 2022-06-30 22:39:42.168727
Epoch:[ 243 7 ] loss: 0.37765419483184814 2022-06-30 22:39:42.589010
Epoch:[ 243 8 ] loss: 0.3795972466468811 2022-06-30 22:39:43.002109
Epoch:[ 243 9 ] loss: 0.3783155679702759 2022-06-30 22:39:43.418122
Epoch:[ 243 10 ] loss: 0.37873297929763794 2022-06-30 22:39:43.833871
Epoch:[ 243 11 ] loss: 0.37758561968803406 2022-06-30 22:39:44.251133
Epoch:[ 243 12 ] loss: 0.37856054306030273 2022-06-30 22:39:44.671271
Epoch:[ 243 13 ] loss: 0.3817847967147827 2022-06-30 22:39:45.085791
Epoch:[ 243 14 ] loss: 0.37992027401924133 2022-06-30 22:39:45.501568
Epoch:[ 243 15 ] loss: 0.37858501076698303 2022-06-30 22:39:45.916210
Epoch:[ 243 16 ] loss: 0.37990903854370117 2022-06-30 22:39:51.326082
Epoch:[ 243 17 ] loss: 0.37963205575942993 2022-06-30 22:39:51.740667
Epoch:[ 243 18 ] loss: 0.3800409436225891 2022-06-30 22:39:52.155238
Epoch:[ 243 19 ] loss: 0.37889209389686584 2022-06-30 22:39:52.569975
Training_Epoch:[ 243 ] Training_loss: 0.3795289009809494 2022-06-30 22:39:52.570713
learning rate:  2.361183241434826e-05
val: 1 0.4871203601360321
val: 2 0.47137731313705444
val: 3 0.4908858835697174
val: 4 0.48125675320625305
val: 5 0.46513083577156067
val: 6 0.47808292508125305
val: 7 0.48368576169013977
val: 8 0.48281291127204895
val: 9 0.4868219494819641
val: 10 0.4757777750492096
val: 11 0.48210108280181885
val: 12 0.4645519256591797
val: 13 0.4818470776081085
val: 14 0.47380849719047546
val: 15 0.47544774413108826
val: 16 0.48025041818618774
val: 17 0.4726674556732178
val: 18 0.4890483319759369
val: 19 0.4831978976726532
val: 20 0.49401387572288513
val_Epoch:[ 243 ] val_loss: 0.47999433875083924 2022-06-30 22:39:55.869835
start training 2022-06-30 22:39:55.972171
Epoch:[ 244 0 ] loss: 0.378696084022522 2022-06-30 22:40:09.745558
Epoch:[ 244 1 ] loss: 0.38038548827171326 2022-06-30 22:40:10.590035
Epoch:[ 244 2 ] loss: 0.37994515895843506 2022-06-30 22:40:11.002540
Epoch:[ 244 3 ] loss: 0.3814200162887573 2022-06-30 22:40:11.424584
Epoch:[ 244 4 ] loss: 0.3798937201499939 2022-06-30 22:40:11.839319
Epoch:[ 244 5 ] loss: 0.37814822793006897 2022-06-30 22:40:12.260288
Epoch:[ 244 6 ] loss: 0.37901005148887634 2022-06-30 22:40:12.672571
Epoch:[ 244 7 ] loss: 0.3823546767234802 2022-06-30 22:40:13.087835
Epoch:[ 244 8 ] loss: 0.3811432719230652 2022-06-30 22:40:13.501373
Epoch:[ 244 9 ] loss: 0.37898188829421997 2022-06-30 22:40:13.915147
Epoch:[ 244 10 ] loss: 0.3816526234149933 2022-06-30 22:40:14.331022
Epoch:[ 244 11 ] loss: 0.37898388504981995 2022-06-30 22:40:14.747038
Epoch:[ 244 12 ] loss: 0.3808269500732422 2022-06-30 22:40:15.167020
Epoch:[ 244 13 ] loss: 0.3786092698574066 2022-06-30 22:40:15.580316
Epoch:[ 244 14 ] loss: 0.37822407484054565 2022-06-30 22:40:15.995811
Epoch:[ 244 15 ] loss: 0.37783393263816833 2022-06-30 22:40:16.415492
Epoch:[ 244 16 ] loss: 0.3808002471923828 2022-06-30 22:40:21.475747
Epoch:[ 244 17 ] loss: 0.38040825724601746 2022-06-30 22:40:21.987326
Epoch:[ 244 18 ] loss: 0.37702658772468567 2022-06-30 22:40:22.409670
Epoch:[ 244 19 ] loss: 0.3798442780971527 2022-06-30 22:40:22.825868
Training_Epoch:[ 244 ] Training_loss: 0.37970943450927735 2022-06-30 22:40:22.826634
learning rate:  2.361183241434826e-05
netparams have been saved once 244
val: 1 0.47481051087379456
val: 2 0.4794110357761383
val: 3 0.4744371473789215
val: 4 0.48672720789909363
val: 5 0.48034021258354187
val: 6 0.4787454903125763
val: 7 0.48611506819725037
val: 8 0.4728037118911743
val: 9 0.47804635763168335
val: 10 0.47956758737564087
val: 11 0.4791743755340576
val: 12 0.4713302254676819
val: 13 0.4837929904460907
val: 14 0.48985573649406433
val: 15 0.4865431487560272
val: 16 0.46883878111839294
val: 17 0.478604257106781
val: 18 0.47007688879966736
val: 19 0.48944151401519775
val: 20 0.4832100570201874
val_Epoch:[ 244 ] val_loss: 0.47959361523389815 2022-06-30 22:40:26.212860
start training 2022-06-30 22:40:26.311330
Epoch:[ 245 0 ] loss: 0.37953847646713257 2022-06-30 22:40:40.231485
Epoch:[ 245 1 ] loss: 0.37876883149147034 2022-06-30 22:40:40.980051
Epoch:[ 245 2 ] loss: 0.3793516755104065 2022-06-30 22:40:41.393073
Epoch:[ 245 3 ] loss: 0.38075077533721924 2022-06-30 22:40:41.807847
Epoch:[ 245 4 ] loss: 0.3774964213371277 2022-06-30 22:40:42.223726
Epoch:[ 245 5 ] loss: 0.38181689381599426 2022-06-30 22:40:42.639237
Epoch:[ 245 6 ] loss: 0.3816032409667969 2022-06-30 22:40:43.060820
Epoch:[ 245 7 ] loss: 0.37758517265319824 2022-06-30 22:40:43.476038
Epoch:[ 245 8 ] loss: 0.37948429584503174 2022-06-30 22:40:43.890600
Epoch:[ 245 9 ] loss: 0.37842634320259094 2022-06-30 22:40:44.305118
Epoch:[ 245 10 ] loss: 0.3793417811393738 2022-06-30 22:40:44.724580
Epoch:[ 245 11 ] loss: 0.3792274594306946 2022-06-30 22:40:45.146343
Epoch:[ 245 12 ] loss: 0.38061606884002686 2022-06-30 22:40:45.561929
Epoch:[ 245 13 ] loss: 0.37872314453125 2022-06-30 22:40:45.977744
Epoch:[ 245 14 ] loss: 0.38066962361335754 2022-06-30 22:40:46.391741
Epoch:[ 245 15 ] loss: 0.3799613118171692 2022-06-30 22:40:46.807170
Epoch:[ 245 16 ] loss: 0.37987449765205383 2022-06-30 22:40:52.404565
Epoch:[ 245 17 ] loss: 0.3806152641773224 2022-06-30 22:40:52.817518
Epoch:[ 245 18 ] loss: 0.3808901309967041 2022-06-30 22:40:53.234160
Epoch:[ 245 19 ] loss: 0.37835195660591125 2022-06-30 22:40:53.651062
Training_Epoch:[ 245 ] Training_loss: 0.3796546682715416 2022-06-30 22:40:53.651823
learning rate:  2.361183241434826e-05
val: 1 0.4806405305862427
val: 2 0.4871986508369446
val: 3 0.4846686124801636
val: 4 0.495342880487442
val: 5 0.4972647726535797
val: 6 0.4817233681678772
val: 7 0.4752746820449829
val: 8 0.4624023735523224
val: 9 0.48187655210494995
val: 10 0.4806104600429535
val: 11 0.4771829843521118
val: 12 0.4840134382247925
val: 13 0.4972907304763794
val: 14 0.4889388382434845
val: 15 0.4690205156803131
val: 16 0.45969218015670776
val: 17 0.4621189832687378
val: 18 0.47637611627578735
val: 19 0.47216349840164185
val: 20 0.4925384819507599
val_Epoch:[ 245 ] val_loss: 0.4803169324994087 2022-06-30 22:40:57.110649
start training 2022-06-30 22:40:57.207016
Epoch:[ 246 0 ] loss: 0.37828028202056885 2022-06-30 22:41:11.495844
Epoch:[ 246 1 ] loss: 0.38028714060783386 2022-06-30 22:41:11.915846
Epoch:[ 246 2 ] loss: 0.38082292675971985 2022-06-30 22:41:12.330907
Epoch:[ 246 3 ] loss: 0.38066014647483826 2022-06-30 22:41:12.747290
Epoch:[ 246 4 ] loss: 0.3791181147098541 2022-06-30 22:41:13.160727
Epoch:[ 246 5 ] loss: 0.3792777955532074 2022-06-30 22:41:13.575967
Epoch:[ 246 6 ] loss: 0.378734827041626 2022-06-30 22:41:14.001830
Epoch:[ 246 7 ] loss: 0.3789610266685486 2022-06-30 22:41:14.418094
Epoch:[ 246 8 ] loss: 0.3799345791339874 2022-06-30 22:41:14.838103
Epoch:[ 246 9 ] loss: 0.3783798813819885 2022-06-30 22:41:15.258446
Epoch:[ 246 10 ] loss: 0.3782610595226288 2022-06-30 22:41:15.674269
Epoch:[ 246 11 ] loss: 0.3793726861476898 2022-06-30 22:41:16.089815
Epoch:[ 246 12 ] loss: 0.3798635005950928 2022-06-30 22:41:16.505810
Epoch:[ 246 13 ] loss: 0.3800866901874542 2022-06-30 22:41:16.927087
Epoch:[ 246 14 ] loss: 0.380817174911499 2022-06-30 22:41:17.341454
Epoch:[ 246 15 ] loss: 0.3802746832370758 2022-06-30 22:41:17.756405
Epoch:[ 246 16 ] loss: 0.3790421187877655 2022-06-30 22:41:23.322421
Epoch:[ 246 17 ] loss: 0.38093698024749756 2022-06-30 22:41:23.735619
Epoch:[ 246 18 ] loss: 0.3791557252407074 2022-06-30 22:41:24.149566
Epoch:[ 246 19 ] loss: 0.3796166479587555 2022-06-30 22:41:24.566002
Training_Epoch:[ 246 ] Training_loss: 0.37959419935941696 2022-06-30 22:41:24.566674
learning rate:  2.361183241434826e-05
netparams have been saved once 246
val: 1 0.4732784032821655
val: 2 0.4821769893169403
val: 3 0.4672222137451172
val: 4 0.4793142080307007
val: 5 0.4839419424533844
val: 6 0.4818743169307709
val: 7 0.4766242206096649
val: 8 0.47788816690444946
val: 9 0.48993703722953796
val: 10 0.4787973463535309
val: 11 0.47587934136390686
val: 12 0.47326189279556274
val: 13 0.48122429847717285
val: 14 0.4965757727622986
val: 15 0.4705139100551605
val: 16 0.4950583577156067
val: 17 0.4696010649204254
val: 18 0.4769216477870941
val: 19 0.48245105147361755
val: 20 0.4845997393131256
val_Epoch:[ 246 ] val_loss: 0.4798570960760117 2022-06-30 22:41:27.976483
start training 2022-06-30 22:41:28.073462
Epoch:[ 247 0 ] loss: 0.3792661726474762 2022-06-30 22:41:42.528194
Epoch:[ 247 1 ] loss: 0.37851032614707947 2022-06-30 22:41:42.941868
Epoch:[ 247 2 ] loss: 0.3814820945262909 2022-06-30 22:41:43.360808
Epoch:[ 247 3 ] loss: 0.3785410523414612 2022-06-30 22:41:43.775874
Epoch:[ 247 4 ] loss: 0.37856829166412354 2022-06-30 22:41:44.188911
Epoch:[ 247 5 ] loss: 0.3787171244621277 2022-06-30 22:41:44.601950
Epoch:[ 247 6 ] loss: 0.38012081384658813 2022-06-30 22:41:45.017431
Epoch:[ 247 7 ] loss: 0.38053324818611145 2022-06-30 22:41:45.438621
Epoch:[ 247 8 ] loss: 0.38000184297561646 2022-06-30 22:41:45.853460
Epoch:[ 247 9 ] loss: 0.38037940859794617 2022-06-30 22:41:46.267514
Epoch:[ 247 10 ] loss: 0.3775307238101959 2022-06-30 22:41:46.681007
Epoch:[ 247 11 ] loss: 0.37992337346076965 2022-06-30 22:41:47.101573
Epoch:[ 247 12 ] loss: 0.38032519817352295 2022-06-30 22:41:47.514711
Epoch:[ 247 13 ] loss: 0.3793294131755829 2022-06-30 22:41:47.930714
Epoch:[ 247 14 ] loss: 0.37896275520324707 2022-06-30 22:41:48.352542
Epoch:[ 247 15 ] loss: 0.38229742646217346 2022-06-30 22:41:48.768734
Epoch:[ 247 16 ] loss: 0.3795236051082611 2022-06-30 22:41:54.055532
Epoch:[ 247 17 ] loss: 0.3805868625640869 2022-06-30 22:41:54.469308
Epoch:[ 247 18 ] loss: 0.3794470727443695 2022-06-30 22:41:54.885298
Epoch:[ 247 19 ] loss: 0.3788571357727051 2022-06-30 22:41:55.299246
Training_Epoch:[ 247 ] Training_loss: 0.37964519709348676 2022-06-30 22:41:55.299992
learning rate:  2.361183241434826e-05
val: 1 0.48888710141181946
val: 2 0.47835448384284973
val: 3 0.4964372217655182
val: 4 0.48551857471466064
val: 5 0.48897233605384827
val: 6 0.4746614396572113
val: 7 0.4986012578010559
val: 8 0.4780225157737732
val: 9 0.4576345682144165
val: 10 0.4761682450771332
val: 11 0.4757002294063568
val: 12 0.48715654015541077
val: 13 0.48639845848083496
val: 14 0.4985175132751465
val: 15 0.4792537987232208
val: 16 0.45878681540489197
val: 17 0.4751364290714264
val: 18 0.4742615818977356
val: 19 0.4621427655220032
val: 20 0.47339755296707153
val_Epoch:[ 247 ] val_loss: 0.47970047146081923 2022-06-30 22:41:58.668556
start training 2022-06-30 22:41:58.765174
Epoch:[ 248 0 ] loss: 0.3817042112350464 2022-06-30 22:42:13.321777
Epoch:[ 248 1 ] loss: 0.3802773654460907 2022-06-30 22:42:13.743612
Epoch:[ 248 2 ] loss: 0.3781859576702118 2022-06-30 22:42:14.160755
Epoch:[ 248 3 ] loss: 0.3787458539009094 2022-06-30 22:42:14.575693
Epoch:[ 248 4 ] loss: 0.3787684738636017 2022-06-30 22:42:14.989857
Epoch:[ 248 5 ] loss: 0.37906885147094727 2022-06-30 22:42:15.409561
Epoch:[ 248 6 ] loss: 0.37884587049484253 2022-06-30 22:42:15.822448
Epoch:[ 248 7 ] loss: 0.3799218237400055 2022-06-30 22:42:16.239927
Epoch:[ 248 8 ] loss: 0.38139209151268005 2022-06-30 22:42:16.656599
Epoch:[ 248 9 ] loss: 0.38010936975479126 2022-06-30 22:42:17.074270
Epoch:[ 248 10 ] loss: 0.38013413548469543 2022-06-30 22:42:17.488664
Epoch:[ 248 11 ] loss: 0.3814113438129425 2022-06-30 22:42:17.910704
Epoch:[ 248 12 ] loss: 0.3795056939125061 2022-06-30 22:42:18.333785
Epoch:[ 248 13 ] loss: 0.38030806183815 2022-06-30 22:42:18.748409
Epoch:[ 248 14 ] loss: 0.37843057513237 2022-06-30 22:42:19.163998
Epoch:[ 248 15 ] loss: 0.37894168496131897 2022-06-30 22:42:19.579977
Epoch:[ 248 16 ] loss: 0.3784845769405365 2022-06-30 22:42:24.782232
Epoch:[ 248 17 ] loss: 0.3802809715270996 2022-06-30 22:42:25.196057
Epoch:[ 248 18 ] loss: 0.37970319390296936 2022-06-30 22:42:25.611534
Epoch:[ 248 19 ] loss: 0.37718287110328674 2022-06-30 22:42:26.026220
Training_Epoch:[ 248 ] Training_loss: 0.3795701488852501 2022-06-30 22:42:26.026935
learning rate:  2.361183241434826e-05
netparams have been saved once 248
val: 1 0.48158448934555054
val: 2 0.4773182272911072
val: 3 0.48095253109931946
val: 4 0.4791320264339447
val: 5 0.466326504945755
val: 6 0.4832037091255188
val: 7 0.4775509238243103
val: 8 0.47359365224838257
val: 9 0.48876336216926575
val: 10 0.48462966084480286
val: 11 0.49022024869918823
val: 12 0.4835200011730194
val: 13 0.47573593258857727
val: 14 0.4916672706604004
val: 15 0.4742286205291748
val: 16 0.4705697000026703
val: 17 0.4749360978603363
val: 18 0.47838500142097473
val: 19 0.4861656427383423
val: 20 0.48299774527549744
val_Epoch:[ 248 ] val_loss: 0.4800740674138069 2022-06-30 22:42:29.457932
start training 2022-06-30 22:42:29.554876
Epoch:[ 249 0 ] loss: 0.38253846764564514 2022-06-30 22:42:43.754369
Epoch:[ 249 1 ] loss: 0.38174229860305786 2022-06-30 22:42:44.170775
Epoch:[ 249 2 ] loss: 0.3769523501396179 2022-06-30 22:42:44.586775
Epoch:[ 249 3 ] loss: 0.37966686487197876 2022-06-30 22:42:45.002815
Epoch:[ 249 4 ] loss: 0.38014793395996094 2022-06-30 22:42:45.424425
Epoch:[ 249 5 ] loss: 0.379141241312027 2022-06-30 22:42:45.843602
Epoch:[ 249 6 ] loss: 0.37852731347084045 2022-06-30 22:42:46.259026
Epoch:[ 249 7 ] loss: 0.3783339560031891 2022-06-30 22:42:46.674246
Epoch:[ 249 8 ] loss: 0.3794732391834259 2022-06-30 22:42:47.090415
Epoch:[ 249 9 ] loss: 0.38060837984085083 2022-06-30 22:42:47.512380
Epoch:[ 249 10 ] loss: 0.37999024987220764 2022-06-30 22:42:47.932641
Epoch:[ 249 11 ] loss: 0.38034382462501526 2022-06-30 22:42:48.346912
Epoch:[ 249 12 ] loss: 0.3801746666431427 2022-06-30 22:42:48.761129
Epoch:[ 249 13 ] loss: 0.3777128756046295 2022-06-30 22:42:49.174341
Epoch:[ 249 14 ] loss: 0.3783799707889557 2022-06-30 22:42:49.586985
Epoch:[ 249 15 ] loss: 0.37861886620521545 2022-06-30 22:42:50.010236
Epoch:[ 249 16 ] loss: 0.378366082906723 2022-06-30 22:42:55.437186
Epoch:[ 249 17 ] loss: 0.3794260323047638 2022-06-30 22:42:55.852881
Epoch:[ 249 18 ] loss: 0.3795701563358307 2022-06-30 22:42:56.266844
Epoch:[ 249 19 ] loss: 0.37956634163856506 2022-06-30 22:42:56.682826
Training_Epoch:[ 249 ] Training_loss: 0.3794640555977821 2022-06-30 22:42:56.683611
learning rate:  2.361183241434826e-05
val: 1 0.4811157286167145
val: 2 0.47965237498283386
val: 3 0.4868685305118561
val: 4 0.4904111921787262
val: 5 0.47727543115615845
val: 6 0.4842587113380432
val: 7 0.4714628756046295
val: 8 0.4724304974079132
val: 9 0.47482386231422424
val: 10 0.4814295768737793
val: 11 0.48762014508247375
val: 12 0.4773370027542114
val: 13 0.4711858630180359
val: 14 0.47411707043647766
val: 15 0.48534446954727173
val: 16 0.4778890013694763
val: 17 0.4777469038963318
val: 18 0.49702882766723633
val: 19 0.47731032967567444
val: 20 0.4706096649169922
val_Epoch:[ 249 ] val_loss: 0.479795902967453 2022-06-30 22:43:00.105013
start training 2022-06-30 22:43:00.201373
Epoch:[ 250 0 ] loss: 0.3797125518321991 2022-06-30 22:43:14.698857
Epoch:[ 250 1 ] loss: 0.37805384397506714 2022-06-30 22:43:15.114958
Epoch:[ 250 2 ] loss: 0.3793453872203827 2022-06-30 22:43:15.537047
Epoch:[ 250 3 ] loss: 0.38166719675064087 2022-06-30 22:43:15.952748
Epoch:[ 250 4 ] loss: 0.3790707290172577 2022-06-30 22:43:16.373354
Epoch:[ 250 5 ] loss: 0.38060685992240906 2022-06-30 22:43:16.787272
Epoch:[ 250 6 ] loss: 0.37812185287475586 2022-06-30 22:43:17.202266
Epoch:[ 250 7 ] loss: 0.3803887665271759 2022-06-30 22:43:17.637772
Epoch:[ 250 8 ] loss: 0.3796579837799072 2022-06-30 22:43:18.050856
Epoch:[ 250 9 ] loss: 0.38089215755462646 2022-06-30 22:43:18.466409
Epoch:[ 250 10 ] loss: 0.3807447850704193 2022-06-30 22:43:18.881998
Epoch:[ 250 11 ] loss: 0.38181808590888977 2022-06-30 22:43:19.305722
Epoch:[ 250 12 ] loss: 0.37731659412384033 2022-06-30 22:43:19.718861
Epoch:[ 250 13 ] loss: 0.3765612542629242 2022-06-30 22:43:20.133991
Epoch:[ 250 14 ] loss: 0.37905189394950867 2022-06-30 22:43:20.547355
Epoch:[ 250 15 ] loss: 0.3797157406806946 2022-06-30 22:43:20.962343
Epoch:[ 250 16 ] loss: 0.37868553400039673 2022-06-30 22:43:26.262400
Epoch:[ 250 17 ] loss: 0.37918683886528015 2022-06-30 22:43:26.677224
Epoch:[ 250 18 ] loss: 0.38161134719848633 2022-06-30 22:43:27.093523
Epoch:[ 250 19 ] loss: 0.3764561116695404 2022-06-30 22:43:27.508654
Training_Epoch:[ 250 ] Training_loss: 0.37943327575922015 2022-06-30 22:43:27.509469
learning rate:  2.361183241434826e-05
netparams have been saved once 250
val: 1 0.47469601035118103
val: 2 0.4796670377254486
val: 3 0.47424617409706116
val: 4 0.4899577498435974
val: 5 0.48462092876434326
val: 6 0.4709603190422058
val: 7 0.48841172456741333
val: 8 0.47149422764778137
val: 9 0.47552964091300964
val: 10 0.4873601794242859
val: 11 0.477189302444458
val: 12 0.47594162821769714
val: 13 0.4821152985095978
val: 14 0.49088922142982483
val: 15 0.47235190868377686
val: 16 0.4853661060333252
val: 17 0.4880795478820801
val: 18 0.4792884290218353
val: 19 0.4799588620662689
val: 20 0.48089730739593506
val_Epoch:[ 250 ] val_loss: 0.4804510802030563 2022-06-30 22:43:30.901435
