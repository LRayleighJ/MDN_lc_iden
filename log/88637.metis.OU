GPU: True
80
start training 2022-08-11 23:58:16.438375
Epoch:[ 1 0 ] loss: 0.6855705380439758 2022-08-11 23:58:35.209572
Epoch:[ 1 1 ] loss: 0.6920546293258667 2022-08-11 23:58:35.719846
Epoch:[ 1 2 ] loss: 0.677180290222168 2022-08-11 23:58:36.151220
Epoch:[ 1 3 ] loss: 0.6713637709617615 2022-08-11 23:58:36.581568
Epoch:[ 1 4 ] loss: 0.6639096736907959 2022-08-11 23:58:37.001550
Epoch:[ 1 5 ] loss: 0.6554094552993774 2022-08-11 23:58:37.426302
Epoch:[ 1 6 ] loss: 0.6484724283218384 2022-08-11 23:58:37.851459
Epoch:[ 1 7 ] loss: 0.6410248875617981 2022-08-11 23:58:38.278331
Epoch:[ 1 8 ] loss: 0.6354547142982483 2022-08-11 23:58:38.695729
Epoch:[ 1 9 ] loss: 0.6300684809684753 2022-08-11 23:58:39.115242
Epoch:[ 1 10 ] loss: 0.6236073970794678 2022-08-11 23:58:39.538149
Epoch:[ 1 11 ] loss: 0.6190853714942932 2022-08-11 23:58:39.961672
Epoch:[ 1 12 ] loss: 0.6139056086540222 2022-08-11 23:58:40.384096
Epoch:[ 1 13 ] loss: 0.6082311868667603 2022-08-11 23:58:40.809605
Epoch:[ 1 14 ] loss: 0.6057125329971313 2022-08-11 23:58:41.232563
Epoch:[ 1 15 ] loss: 0.6042935252189636 2022-08-11 23:58:41.652430
Epoch:[ 1 16 ] loss: 0.5990384221076965 2022-08-11 23:58:42.319025
Epoch:[ 1 17 ] loss: 0.5955731272697449 2022-08-11 23:58:42.749499
Epoch:[ 1 18 ] loss: 0.5927671790122986 2022-08-11 23:58:43.175541
Epoch:[ 1 19 ] loss: 0.5876749157905579 2022-08-11 23:58:43.599080
Training_Epoch:[ 1 ] Training_loss: 0.6325199067592621 2022-08-11 23:58:43.599762
learning rate:  0.004
val: 1 0.647761881351471
val: 2 0.6457104086875916
val: 3 0.6458526849746704
val: 4 0.6491440534591675
val: 5 0.6435931921005249
val: 6 0.6472455263137817
val: 7 0.6457707285881042
val: 8 0.6438828706741333
val: 9 0.6448686718940735
val: 10 0.6462111473083496
val: 11 0.6445991396903992
val: 12 0.6468261480331421
val: 13 0.6433209180831909
val: 14 0.6480069160461426
val: 15 0.6492007374763489
val: 16 0.6440645456314087
val: 17 0.6477097272872925
val: 18 0.6446839570999146
val: 19 0.6444531083106995
val: 20 0.6485823392868042
val_Epoch:[ 1 ] val_loss: 0.6460744351148605 2022-08-11 23:58:47.130100
start training 2022-08-11 23:58:47.236894
Epoch:[ 2 0 ] loss: 0.5854353904724121 2022-08-11 23:59:02.175185
Epoch:[ 2 1 ] loss: 0.5822833180427551 2022-08-11 23:59:02.602166
Epoch:[ 2 2 ] loss: 0.5810837745666504 2022-08-11 23:59:03.027087
Epoch:[ 2 3 ] loss: 0.5769598484039307 2022-08-11 23:59:03.446150
Epoch:[ 2 4 ] loss: 0.5784854888916016 2022-08-11 23:59:03.861224
Epoch:[ 2 5 ] loss: 0.5756500959396362 2022-08-11 23:59:04.279595
Epoch:[ 2 6 ] loss: 0.5731768608093262 2022-08-11 23:59:04.707222
Epoch:[ 2 7 ] loss: 0.5707300305366516 2022-08-11 23:59:05.134796
Epoch:[ 2 8 ] loss: 0.5701813697814941 2022-08-11 23:59:05.560893
Epoch:[ 2 9 ] loss: 0.5676703453063965 2022-08-11 23:59:05.981537
Epoch:[ 2 10 ] loss: 0.5641341209411621 2022-08-11 23:59:06.405295
Epoch:[ 2 11 ] loss: 0.5638890266418457 2022-08-11 23:59:06.833937
Epoch:[ 2 12 ] loss: 0.5638211369514465 2022-08-11 23:59:07.266565
Epoch:[ 2 13 ] loss: 0.568767249584198 2022-08-11 23:59:07.690722
Epoch:[ 2 14 ] loss: 0.5653544664382935 2022-08-11 23:59:08.111672
Epoch:[ 2 15 ] loss: 0.5620726943016052 2022-08-11 23:59:08.536744
Epoch:[ 2 16 ] loss: 0.5607365369796753 2022-08-11 23:59:13.817068
Epoch:[ 2 17 ] loss: 0.5612860321998596 2022-08-11 23:59:14.239730
Epoch:[ 2 18 ] loss: 0.5559137463569641 2022-08-11 23:59:14.661865
Epoch:[ 2 19 ] loss: 0.5542821288108826 2022-08-11 23:59:15.086472
Training_Epoch:[ 2 ] Training_loss: 0.5690956830978393 2022-08-11 23:59:15.087139
learning rate:  0.004
val: 1 0.5573429465293884
val: 2 0.5511789321899414
val: 3 0.5516051054000854
val: 4 0.547469437122345
val: 5 0.5457267165184021
val: 6 0.5467408895492554
val: 7 0.5552446246147156
val: 8 0.5522537231445312
val: 9 0.5459132194519043
val: 10 0.55254065990448
val: 11 0.5538698434829712
val: 12 0.5502368211746216
val: 13 0.5508193373680115
val: 14 0.5548229813575745
val: 15 0.5513848066329956
val: 16 0.5532471537590027
val: 17 0.5523978471755981
val: 18 0.5536699295043945
val: 19 0.5516283512115479
val: 20 0.5465404987335205
val_Epoch:[ 2 ] val_loss: 0.5512316912412644 2022-08-11 23:59:18.744524
start training 2022-08-11 23:59:18.843108
Epoch:[ 3 0 ] loss: 0.5516506433486938 2022-08-11 23:59:33.312136
Epoch:[ 3 1 ] loss: 0.5510876774787903 2022-08-11 23:59:33.734004
Epoch:[ 3 2 ] loss: 0.5502433180809021 2022-08-11 23:59:34.157455
Epoch:[ 3 3 ] loss: 0.5490947961807251 2022-08-11 23:59:34.574895
Epoch:[ 3 4 ] loss: 0.546497642993927 2022-08-11 23:59:35.002456
Epoch:[ 3 5 ] loss: 0.5477766394615173 2022-08-11 23:59:35.417021
Epoch:[ 3 6 ] loss: 0.5455650091171265 2022-08-11 23:59:35.837934
Epoch:[ 3 7 ] loss: 0.5445870161056519 2022-08-11 23:59:36.263423
Epoch:[ 3 8 ] loss: 0.544989824295044 2022-08-11 23:59:36.696321
Epoch:[ 3 9 ] loss: 0.5433737635612488 2022-08-11 23:59:37.117129
Epoch:[ 3 10 ] loss: 0.5418970584869385 2022-08-11 23:59:37.541920
Epoch:[ 3 11 ] loss: 0.5394226312637329 2022-08-11 23:59:37.964516
Epoch:[ 3 12 ] loss: 0.5363724231719971 2022-08-11 23:59:38.393979
Epoch:[ 3 13 ] loss: 0.537093460559845 2022-08-11 23:59:38.816974
Epoch:[ 3 14 ] loss: 0.5400711297988892 2022-08-11 23:59:39.242875
Epoch:[ 3 15 ] loss: 0.5396206974983215 2022-08-11 23:59:39.668577
Epoch:[ 3 16 ] loss: 0.5392867922782898 2022-08-11 23:59:45.019925
Epoch:[ 3 17 ] loss: 0.5365535616874695 2022-08-11 23:59:45.440935
Epoch:[ 3 18 ] loss: 0.5348432660102844 2022-08-11 23:59:45.866540
Epoch:[ 3 19 ] loss: 0.5329495072364807 2022-08-11 23:59:46.283369
Training_Epoch:[ 3 ] Training_loss: 0.5426488429307937 2022-08-11 23:59:46.284022
learning rate:  0.004
val: 1 0.5568767189979553
val: 2 0.5695081353187561
val: 3 0.5596453547477722
val: 4 0.5674397349357605
val: 5 0.5655965805053711
val: 6 0.5607714056968689
val: 7 0.5637479424476624
val: 8 0.5586174130439758
val: 9 0.56025630235672
val: 10 0.5648275017738342
val: 11 0.5574842095375061
val: 12 0.5620701909065247
val: 13 0.5685491561889648
val: 14 0.5754281282424927
val: 15 0.5621011257171631
val: 16 0.5633344650268555
val: 17 0.5610353946685791
val: 18 0.5594483017921448
val: 19 0.5656222701072693
val: 20 0.5643068552017212
val_Epoch:[ 3 ] val_loss: 0.5633333593606948 2022-08-11 23:59:49.835192
start training 2022-08-11 23:59:49.939084
Epoch:[ 4 0 ] loss: 0.5336596965789795 2022-08-12 00:00:04.377438
Epoch:[ 4 1 ] loss: 0.5334950089454651 2022-08-12 00:00:04.810135
Epoch:[ 4 2 ] loss: 0.5334877967834473 2022-08-12 00:00:05.235825
Epoch:[ 4 3 ] loss: 0.5327023863792419 2022-08-12 00:00:05.659328
Epoch:[ 4 4 ] loss: 0.5317342281341553 2022-08-12 00:00:06.084052
Epoch:[ 4 5 ] loss: 0.5324012637138367 2022-08-12 00:00:06.502741
Epoch:[ 4 6 ] loss: 0.533897876739502 2022-08-12 00:00:06.926016
Epoch:[ 4 7 ] loss: 0.5326498746871948 2022-08-12 00:00:07.350479
Epoch:[ 4 8 ] loss: 0.5303816199302673 2022-08-12 00:00:07.776119
Epoch:[ 4 9 ] loss: 0.529466986656189 2022-08-12 00:00:08.196682
Epoch:[ 4 10 ] loss: 0.5309896469116211 2022-08-12 00:00:08.612894
Epoch:[ 4 11 ] loss: 0.5305864214897156 2022-08-12 00:00:09.033175
Epoch:[ 4 12 ] loss: 0.5278839468955994 2022-08-12 00:00:09.463213
Epoch:[ 4 13 ] loss: 0.5275603532791138 2022-08-12 00:00:09.881968
Epoch:[ 4 14 ] loss: 0.5270576477050781 2022-08-12 00:00:10.301885
Epoch:[ 4 15 ] loss: 0.5305617451667786 2022-08-12 00:00:10.729448
Epoch:[ 4 16 ] loss: 0.5298638343811035 2022-08-12 00:00:16.150743
Epoch:[ 4 17 ] loss: 0.5264372229576111 2022-08-12 00:00:16.568338
Epoch:[ 4 18 ] loss: 0.528182864189148 2022-08-12 00:00:16.984299
Epoch:[ 4 19 ] loss: 0.5263713002204895 2022-08-12 00:00:17.408805
Training_Epoch:[ 4 ] Training_loss: 0.5304685860872269 2022-08-12 00:00:17.409449
learning rate:  0.004
val: 1 0.7398727536201477
val: 2 0.7314349412918091
val: 3 0.7350096702575684
val: 4 0.7331078052520752
val: 5 0.7314924001693726
val: 6 0.7274008393287659
val: 7 0.7239257097244263
val: 8 0.7451411485671997
val: 9 0.7422835826873779
val: 10 0.7402707934379578
val: 11 0.7359165549278259
val: 12 0.7372702360153198
val: 13 0.7351839542388916
val: 14 0.7347962260246277
val: 15 0.7322272658348083
val: 16 0.7209711670875549
val: 17 0.7260512113571167
val: 18 0.7336591482162476
val: 19 0.7325518727302551
val: 20 0.7267419099807739
val_Epoch:[ 4 ] val_loss: 0.7332654595375061 2022-08-12 00:00:20.962148
start training 2022-08-12 00:00:21.067630
Epoch:[ 5 0 ] loss: 0.530079185962677 2022-08-12 00:00:35.744222
Epoch:[ 5 1 ] loss: 0.5288758277893066 2022-08-12 00:00:36.161235
Epoch:[ 5 2 ] loss: 0.5286316871643066 2022-08-12 00:00:36.585437
Epoch:[ 5 3 ] loss: 0.5274578928947449 2022-08-12 00:00:37.017358
Epoch:[ 5 4 ] loss: 0.5249406099319458 2022-08-12 00:00:37.442239
Epoch:[ 5 5 ] loss: 0.5255690217018127 2022-08-12 00:00:37.865439
Epoch:[ 5 6 ] loss: 0.5290659070014954 2022-08-12 00:00:38.287077
Epoch:[ 5 7 ] loss: 0.5266673564910889 2022-08-12 00:00:38.710631
Epoch:[ 5 8 ] loss: 0.5269252061843872 2022-08-12 00:00:39.135207
Epoch:[ 5 9 ] loss: 0.5249843001365662 2022-08-12 00:00:39.556218
Epoch:[ 5 10 ] loss: 0.5264813303947449 2022-08-12 00:00:39.980052
Epoch:[ 5 11 ] loss: 0.5230148434638977 2022-08-12 00:00:40.409975
Epoch:[ 5 12 ] loss: 0.5200486183166504 2022-08-12 00:00:40.827463
Epoch:[ 5 13 ] loss: 0.5204038023948669 2022-08-12 00:00:41.239598
Epoch:[ 5 14 ] loss: 0.5227863192558289 2022-08-12 00:00:41.663477
Epoch:[ 5 15 ] loss: 0.5237562656402588 2022-08-12 00:00:42.093924
Epoch:[ 5 16 ] loss: 0.521197497844696 2022-08-12 00:00:47.637057
Epoch:[ 5 17 ] loss: 0.5222047567367554 2022-08-12 00:00:48.057408
Epoch:[ 5 18 ] loss: 0.5233626365661621 2022-08-12 00:00:48.482423
Epoch:[ 5 19 ] loss: 0.5199387669563293 2022-08-12 00:00:48.898234
Training_Epoch:[ 5 ] Training_loss: 0.5248195916414261 2022-08-12 00:00:48.898872
learning rate:  0.004
val: 1 0.804224967956543
val: 2 0.796451210975647
val: 3 0.8034940361976624
val: 4 0.7933513522148132
val: 5 0.7996701002120972
val: 6 0.7994629740715027
val: 7 0.7976912260055542
val: 8 0.8030393123626709
val: 9 0.808561384677887
val: 10 0.8150853514671326
val: 11 0.7898986339569092
val: 12 0.8027229905128479
val: 13 0.8012513518333435
val: 14 0.8150258660316467
val: 15 0.7950195670127869
val: 16 0.8059306144714355
val: 17 0.8068026304244995
val: 18 0.7975630164146423
val: 19 0.7958570718765259
val: 20 0.8009662628173828
val_Epoch:[ 5 ] val_loss: 0.8016034960746765 2022-08-12 00:00:52.471985
start training 2022-08-12 00:00:52.573719
Epoch:[ 6 0 ] loss: 0.5208756327629089 2022-08-12 00:01:07.243995
Epoch:[ 6 1 ] loss: 0.5197197198867798 2022-08-12 00:01:07.668907
Epoch:[ 6 2 ] loss: 0.5202687978744507 2022-08-12 00:01:08.091195
Epoch:[ 6 3 ] loss: 0.5186102390289307 2022-08-12 00:01:08.515158
Epoch:[ 6 4 ] loss: 0.5191442370414734 2022-08-12 00:01:08.944747
Epoch:[ 6 5 ] loss: 0.5166094899177551 2022-08-12 00:01:09.368251
Epoch:[ 6 6 ] loss: 0.5182607769966125 2022-08-12 00:01:09.781024
Epoch:[ 6 7 ] loss: 0.5184599161148071 2022-08-12 00:01:10.203096
Epoch:[ 6 8 ] loss: 0.515812337398529 2022-08-12 00:01:10.628119
Epoch:[ 6 9 ] loss: 0.5153170228004456 2022-08-12 00:01:11.047570
Epoch:[ 6 10 ] loss: 0.5128625631332397 2022-08-12 00:01:11.470028
Epoch:[ 6 11 ] loss: 0.5147238969802856 2022-08-12 00:01:11.895575
Epoch:[ 6 12 ] loss: 0.5142883062362671 2022-08-12 00:01:12.328136
Epoch:[ 6 13 ] loss: 0.5107495784759521 2022-08-12 00:01:12.755203
Epoch:[ 6 14 ] loss: 0.5099842548370361 2022-08-12 00:01:13.176903
Epoch:[ 6 15 ] loss: 0.5129269957542419 2022-08-12 00:01:13.600374
Epoch:[ 6 16 ] loss: 0.5119332671165466 2022-08-12 00:01:19.082082
Epoch:[ 6 17 ] loss: 0.5229730010032654 2022-08-12 00:01:19.503096
Epoch:[ 6 18 ] loss: 0.520689070224762 2022-08-12 00:01:19.934984
Epoch:[ 6 19 ] loss: 0.5241440534591675 2022-08-12 00:01:20.359554
Training_Epoch:[ 6 ] Training_loss: 0.5169176578521728 2022-08-12 00:01:20.360244
learning rate:  0.004
val: 1 0.6529850959777832
val: 2 0.6531540751457214
val: 3 0.6557263731956482
val: 4 0.6409575343132019
val: 5 0.6520455479621887
val: 6 0.6540713906288147
val: 7 0.645435094833374
val: 8 0.6507465243339539
val: 9 0.6450547575950623
val: 10 0.6584459543228149
val: 11 0.6427345871925354
val: 12 0.6604782938957214
val: 13 0.6393302083015442
val: 14 0.6542033553123474
val: 15 0.6611400842666626
val: 16 0.6534464359283447
val: 17 0.6623164415359497
val: 18 0.6417658925056458
val: 19 0.6459072232246399
val: 20 0.6493488550186157
val_Epoch:[ 6 ] val_loss: 0.6509646862745285 2022-08-12 00:01:23.948930
start training 2022-08-12 00:01:24.047519
Epoch:[ 7 0 ] loss: 0.5247280597686768 2022-08-12 00:01:38.921546
Epoch:[ 7 1 ] loss: 0.5200194716453552 2022-08-12 00:01:39.349501
Epoch:[ 7 2 ] loss: 0.5194278359413147 2022-08-12 00:01:39.778361
Epoch:[ 7 3 ] loss: 0.516038179397583 2022-08-12 00:01:40.201491
Epoch:[ 7 4 ] loss: 0.5154480338096619 2022-08-12 00:01:40.626261
Epoch:[ 7 5 ] loss: 0.5130711793899536 2022-08-12 00:01:41.051997
Epoch:[ 7 6 ] loss: 0.5175865888595581 2022-08-12 00:01:41.476437
Epoch:[ 7 7 ] loss: 0.5211723446846008 2022-08-12 00:01:41.895501
Epoch:[ 7 8 ] loss: 0.5157414674758911 2022-08-12 00:01:42.311789
Epoch:[ 7 9 ] loss: 0.5151859521865845 2022-08-12 00:01:42.734918
Epoch:[ 7 10 ] loss: 0.514443576335907 2022-08-12 00:01:43.157346
Epoch:[ 7 11 ] loss: 0.5138460993766785 2022-08-12 00:01:43.582108
Epoch:[ 7 12 ] loss: 0.5062078833580017 2022-08-12 00:01:44.005626
Epoch:[ 7 13 ] loss: 0.5089854001998901 2022-08-12 00:01:44.427680
Epoch:[ 7 14 ] loss: 0.5098111033439636 2022-08-12 00:01:44.848772
Epoch:[ 7 15 ] loss: 0.509041428565979 2022-08-12 00:01:45.271241
Epoch:[ 7 16 ] loss: 0.5074167251586914 2022-08-12 00:01:50.642622
Epoch:[ 7 17 ] loss: 0.5048657059669495 2022-08-12 00:01:51.057119
Epoch:[ 7 18 ] loss: 0.5039922595024109 2022-08-12 00:01:51.485067
Epoch:[ 7 19 ] loss: 0.5043132305145264 2022-08-12 00:01:51.912574
Training_Epoch:[ 7 ] Training_loss: 0.5130671262741089 2022-08-12 00:01:51.913299
learning rate:  0.004
val: 1 0.7790424823760986
val: 2 0.7880937457084656
val: 3 0.7896151542663574
val: 4 0.7717673182487488
val: 5 0.7898625135421753
val: 6 0.7830240726470947
val: 7 0.787192702293396
val: 8 0.7834592461585999
val: 9 0.7853359580039978
val: 10 0.7777403593063354
val: 11 0.7813069820404053
val: 12 0.7857726812362671
val: 13 0.7937318086624146
val: 14 0.7759220600128174
val: 15 0.7735826969146729
val: 16 0.7708408236503601
val: 17 0.7831780314445496
val: 18 0.7800928354263306
val: 19 0.7897521257400513
val: 20 0.7865675687789917
val_Epoch:[ 7 ] val_loss: 0.7827940583229065 2022-08-12 00:01:55.497097
start training 2022-08-12 00:01:55.599330
Epoch:[ 8 0 ] loss: 0.5027401447296143 2022-08-12 00:02:10.073449
Epoch:[ 8 1 ] loss: 0.5002291202545166 2022-08-12 00:02:10.505682
Epoch:[ 8 2 ] loss: 0.5013483762741089 2022-08-12 00:02:10.923795
Epoch:[ 8 3 ] loss: 0.5025123953819275 2022-08-12 00:02:11.354015
Epoch:[ 8 4 ] loss: 0.5087608695030212 2022-08-12 00:02:11.776847
Epoch:[ 8 5 ] loss: 0.5051136016845703 2022-08-12 00:02:12.199646
Epoch:[ 8 6 ] loss: 0.5047687292098999 2022-08-12 00:02:12.622158
Epoch:[ 8 7 ] loss: 0.5053203105926514 2022-08-12 00:02:13.047127
Epoch:[ 8 8 ] loss: 0.5029582381248474 2022-08-12 00:02:13.476874
Epoch:[ 8 9 ] loss: 0.5021910071372986 2022-08-12 00:02:13.898281
Epoch:[ 8 10 ] loss: 0.49805155396461487 2022-08-12 00:02:14.324642
Epoch:[ 8 11 ] loss: 0.49789154529571533 2022-08-12 00:02:14.746682
Epoch:[ 8 12 ] loss: 0.4993501603603363 2022-08-12 00:02:15.172652
Epoch:[ 8 13 ] loss: 0.4983751177787781 2022-08-12 00:02:15.596667
Epoch:[ 8 14 ] loss: 0.4964536428451538 2022-08-12 00:02:16.022269
Epoch:[ 8 15 ] loss: 0.49456986784935 2022-08-12 00:02:16.444704
Epoch:[ 8 16 ] loss: 0.4927244484424591 2022-08-12 00:02:22.015662
Epoch:[ 8 17 ] loss: 0.49700015783309937 2022-08-12 00:02:22.438142
Epoch:[ 8 18 ] loss: 0.4947560131549835 2022-08-12 00:02:22.861155
Epoch:[ 8 19 ] loss: 0.4911743700504303 2022-08-12 00:02:23.283259
Training_Epoch:[ 8 ] Training_loss: 0.4998144835233688 2022-08-12 00:02:23.283935
learning rate:  0.004
val: 1 0.7462170124053955
val: 2 0.7618324756622314
val: 3 0.7457252144813538
val: 4 0.7571876049041748
val: 5 0.7702497243881226
val: 6 0.757719874382019
val: 7 0.7687790393829346
val: 8 0.7615902423858643
val: 9 0.7609884142875671
val: 10 0.7426523566246033
val: 11 0.7380763292312622
val: 12 0.7531939744949341
val: 13 0.7590328454971313
val: 14 0.7637407183647156
val: 15 0.747002124786377
val: 16 0.7548255920410156
val: 17 0.7518152594566345
val: 18 0.7512890696525574
val: 19 0.755177915096283
val: 20 0.7630648016929626
val_Epoch:[ 8 ] val_loss: 0.755508029460907 2022-08-12 00:02:26.867983
start training 2022-08-12 00:02:26.973883
Epoch:[ 9 0 ] loss: 0.5047771334648132 2022-08-12 00:02:40.908508
Epoch:[ 9 1 ] loss: 0.520369291305542 2022-08-12 00:02:41.820350
Epoch:[ 9 2 ] loss: 0.512843132019043 2022-08-12 00:02:42.238621
Epoch:[ 9 3 ] loss: 0.5134141445159912 2022-08-12 00:02:42.660794
Epoch:[ 9 4 ] loss: 0.513640284538269 2022-08-12 00:02:43.084976
Epoch:[ 9 5 ] loss: 0.5121628046035767 2022-08-12 00:02:43.509392
Epoch:[ 9 6 ] loss: 0.5045071244239807 2022-08-12 00:02:43.933820
Epoch:[ 9 7 ] loss: 0.5051873326301575 2022-08-12 00:02:44.358677
Epoch:[ 9 8 ] loss: 0.5034226179122925 2022-08-12 00:02:44.786126
Epoch:[ 9 9 ] loss: 0.5044922232627869 2022-08-12 00:02:45.202355
Epoch:[ 9 10 ] loss: 0.5017433166503906 2022-08-12 00:02:45.622298
Epoch:[ 9 11 ] loss: 0.4993271231651306 2022-08-12 00:02:46.050937
Epoch:[ 9 12 ] loss: 0.5024024844169617 2022-08-12 00:02:46.481461
Epoch:[ 9 13 ] loss: 0.49887314438819885 2022-08-12 00:02:46.902979
Epoch:[ 9 14 ] loss: 0.4947682321071625 2022-08-12 00:02:47.319534
Epoch:[ 9 15 ] loss: 0.494480162858963 2022-08-12 00:02:47.745218
Epoch:[ 9 16 ] loss: 0.4949146509170532 2022-08-12 00:02:53.147695
Epoch:[ 9 17 ] loss: 0.4896409809589386 2022-08-12 00:02:53.565080
Epoch:[ 9 18 ] loss: 0.49032753705978394 2022-08-12 00:02:53.991063
Epoch:[ 9 19 ] loss: 0.48761770129203796 2022-08-12 00:02:54.416242
Training_Epoch:[ 9 ] Training_loss: 0.5024455711245537 2022-08-12 00:02:54.416921
learning rate:  0.004
val: 1 0.6222256422042847
val: 2 0.6315174102783203
val: 3 0.6167730093002319
val: 4 0.6116491556167603
val: 5 0.6182654500007629
val: 6 0.6176339387893677
val: 7 0.6131627559661865
val: 8 0.6056222915649414
val: 9 0.6207754611968994
val: 10 0.6185570955276489
val: 11 0.6100519299507141
val: 12 0.6134698390960693
val: 13 0.6122954487800598
val: 14 0.6079800724983215
val: 15 0.6144452095031738
val: 16 0.6243170499801636
val: 17 0.6122719049453735
val: 18 0.6197006106376648
val: 19 0.6088609099388123
val: 20 0.6174855828285217
val_Epoch:[ 9 ] val_loss: 0.6158530384302139 2022-08-12 00:02:57.956265
start training 2022-08-12 00:02:58.063432
Epoch:[ 10 0 ] loss: 0.49285006523132324 2022-08-12 00:03:12.751995
Epoch:[ 10 1 ] loss: 0.4853096306324005 2022-08-12 00:03:13.174611
Epoch:[ 10 2 ] loss: 0.48832249641418457 2022-08-12 00:03:13.595915
Epoch:[ 10 3 ] loss: 0.49630919098854065 2022-08-12 00:03:14.028295
Epoch:[ 10 4 ] loss: 0.49247416853904724 2022-08-12 00:03:14.452531
Epoch:[ 10 5 ] loss: 0.48887899518013 2022-08-12 00:03:14.874270
Epoch:[ 10 6 ] loss: 0.4889625310897827 2022-08-12 00:03:15.297021
Epoch:[ 10 7 ] loss: 0.489846795797348 2022-08-12 00:03:15.721463
Epoch:[ 10 8 ] loss: 0.48493367433547974 2022-08-12 00:03:16.146225
Epoch:[ 10 9 ] loss: 0.48543423414230347 2022-08-12 00:03:16.572065
Epoch:[ 10 10 ] loss: 0.4835416078567505 2022-08-12 00:03:16.998563
Epoch:[ 10 11 ] loss: 0.4861227571964264 2022-08-12 00:03:17.419070
Epoch:[ 10 12 ] loss: 0.4827093780040741 2022-08-12 00:03:17.832748
Epoch:[ 10 13 ] loss: 0.484828919172287 2022-08-12 00:03:18.251085
Epoch:[ 10 14 ] loss: 0.4844570457935333 2022-08-12 00:03:18.677209
Epoch:[ 10 15 ] loss: 0.4825129508972168 2022-08-12 00:03:19.106388
Epoch:[ 10 16 ] loss: 0.48170825839042664 2022-08-12 00:03:24.403976
Epoch:[ 10 17 ] loss: 0.4828058183193207 2022-08-12 00:03:24.822805
Epoch:[ 10 18 ] loss: 0.48149874806404114 2022-08-12 00:03:25.252750
Epoch:[ 10 19 ] loss: 0.4812210500240326 2022-08-12 00:03:25.674433
Training_Epoch:[ 10 ] Training_loss: 0.48623641580343246 2022-08-12 00:03:25.675111
learning rate:  0.004
netparams have been saved once 10
val: 1 0.57358318567276
val: 2 0.5872436761856079
val: 3 0.5778795480728149
val: 4 0.5894184112548828
val: 5 0.5896032452583313
val: 6 0.5785402059555054
val: 7 0.578407883644104
val: 8 0.5890787243843079
val: 9 0.5822021961212158
val: 10 0.5716654658317566
val: 11 0.5813038349151611
val: 12 0.5825318098068237
val: 13 0.5746291875839233
val: 14 0.5781518816947937
val: 15 0.5723432898521423
val: 16 0.576210081577301
val: 17 0.5850646495819092
val: 18 0.5863020420074463
val: 19 0.5750154256820679
val: 20 0.5886296629905701
val_Epoch:[ 10 ] val_loss: 0.5808902204036712 2022-08-12 00:03:29.340141
start training 2022-08-12 00:03:29.439102
Epoch:[ 11 0 ] loss: 0.4807112514972687 2022-08-12 00:03:43.649472
Epoch:[ 11 1 ] loss: 0.4782830774784088 2022-08-12 00:03:44.080246
Epoch:[ 11 2 ] loss: 0.47927865386009216 2022-08-12 00:03:44.520997
Epoch:[ 11 3 ] loss: 0.4772026836872101 2022-08-12 00:03:44.946270
Epoch:[ 11 4 ] loss: 0.4790564179420471 2022-08-12 00:03:45.370788
Epoch:[ 11 5 ] loss: 0.47735896706581116 2022-08-12 00:03:45.793427
Epoch:[ 11 6 ] loss: 0.47642385959625244 2022-08-12 00:03:46.216308
Epoch:[ 11 7 ] loss: 0.47665223479270935 2022-08-12 00:03:46.633974
Epoch:[ 11 8 ] loss: 0.4781339466571808 2022-08-12 00:03:47.059442
Epoch:[ 11 9 ] loss: 0.4778870940208435 2022-08-12 00:03:47.485970
Epoch:[ 11 10 ] loss: 0.4777958393096924 2022-08-12 00:03:47.906455
Epoch:[ 11 11 ] loss: 0.4767146706581116 2022-08-12 00:03:48.324618
Epoch:[ 11 12 ] loss: 0.4779762029647827 2022-08-12 00:03:48.749159
Epoch:[ 11 13 ] loss: 0.4801449179649353 2022-08-12 00:03:49.174604
Epoch:[ 11 14 ] loss: 0.4760081470012665 2022-08-12 00:03:49.598582
Epoch:[ 11 15 ] loss: 0.47480320930480957 2022-08-12 00:03:50.022673
Epoch:[ 11 16 ] loss: 0.4762440323829651 2022-08-12 00:03:55.835757
Epoch:[ 11 17 ] loss: 0.476662814617157 2022-08-12 00:03:56.254081
Epoch:[ 11 18 ] loss: 0.4724614918231964 2022-08-12 00:03:56.681327
Epoch:[ 11 19 ] loss: 0.4734589755535126 2022-08-12 00:03:57.103821
Training_Epoch:[ 11 ] Training_loss: 0.47716292440891267 2022-08-12 00:03:57.104454
learning rate:  0.0034
val: 1 0.5039793252944946
val: 2 0.5000631809234619
val: 3 0.5108533501625061
val: 4 0.5043134689331055
val: 5 0.5076056718826294
val: 6 0.5031141042709351
val: 7 0.5032067894935608
val: 8 0.5004310607910156
val: 9 0.5010388493537903
val: 10 0.5025936961174011
val: 11 0.4957300126552582
val: 12 0.5053249597549438
val: 13 0.5049408078193665
val: 14 0.49897316098213196
val: 15 0.49859848618507385
val: 16 0.4939534068107605
val: 17 0.49736639857292175
val: 18 0.5061011910438538
val: 19 0.5063635110855103
val: 20 0.5085269212722778
val_Epoch:[ 11 ] val_loss: 0.5026539176702499 2022-08-12 00:04:00.674736
start training 2022-08-12 00:04:00.773555
Epoch:[ 12 0 ] loss: 0.47277161478996277 2022-08-12 00:04:14.626391
Epoch:[ 12 1 ] loss: 0.469711571931839 2022-08-12 00:04:15.680083
Epoch:[ 12 2 ] loss: 0.4677298069000244 2022-08-12 00:04:16.112761
Epoch:[ 12 3 ] loss: 0.4698362350463867 2022-08-12 00:04:16.532897
Epoch:[ 12 4 ] loss: 0.47161969542503357 2022-08-12 00:04:16.958771
Epoch:[ 12 5 ] loss: 0.46995770931243896 2022-08-12 00:04:17.382064
Epoch:[ 12 6 ] loss: 0.47165805101394653 2022-08-12 00:04:17.806052
Epoch:[ 12 7 ] loss: 0.46932467818260193 2022-08-12 00:04:18.228989
Epoch:[ 12 8 ] loss: 0.4696022570133209 2022-08-12 00:04:18.649913
Epoch:[ 12 9 ] loss: 0.4689655601978302 2022-08-12 00:04:19.068863
Epoch:[ 12 10 ] loss: 0.4668595492839813 2022-08-12 00:04:19.494941
Epoch:[ 12 11 ] loss: 0.4679754376411438 2022-08-12 00:04:19.920908
Epoch:[ 12 12 ] loss: 0.46407395601272583 2022-08-12 00:04:20.342672
Epoch:[ 12 13 ] loss: 0.4699920415878296 2022-08-12 00:04:20.759310
Epoch:[ 12 14 ] loss: 0.46776556968688965 2022-08-12 00:04:21.185294
Epoch:[ 12 15 ] loss: 0.46839439868927 2022-08-12 00:04:21.610360
Epoch:[ 12 16 ] loss: 0.46456167101860046 2022-08-12 00:04:27.121349
Epoch:[ 12 17 ] loss: 0.46833959221839905 2022-08-12 00:04:27.544947
Epoch:[ 12 18 ] loss: 0.46440237760543823 2022-08-12 00:04:27.970874
Epoch:[ 12 19 ] loss: 0.4633971154689789 2022-08-12 00:04:28.394508
Training_Epoch:[ 12 ] Training_loss: 0.46834694445133207 2022-08-12 00:04:28.395216
learning rate:  0.0034
val: 1 0.49344944953918457
val: 2 0.49850913882255554
val: 3 0.4932311177253723
val: 4 0.488621324300766
val: 5 0.4963974058628082
val: 6 0.490106463432312
val: 7 0.4950767755508423
val: 8 0.494172066450119
val: 9 0.5011574029922485
val: 10 0.5062773823738098
val: 11 0.49356889724731445
val: 12 0.49780553579330444
val: 13 0.495868980884552
val: 14 0.5003527998924255
val: 15 0.49578121304512024
val: 16 0.49198126792907715
val: 17 0.49199149012565613
val: 18 0.4948888123035431
val: 19 0.4986828863620758
val: 20 0.4987373352050781
val_Epoch:[ 12 ] val_loss: 0.4958328872919083 2022-08-12 00:04:32.011000
start training 2022-08-12 00:04:32.111144
Epoch:[ 13 0 ] loss: 0.4628041088581085 2022-08-12 00:04:46.187048
Epoch:[ 13 1 ] loss: 0.46233630180358887 2022-08-12 00:04:47.060545
Epoch:[ 13 2 ] loss: 0.46154502034187317 2022-08-12 00:04:47.472929
Epoch:[ 13 3 ] loss: 0.46110230684280396 2022-08-12 00:04:47.897709
Epoch:[ 13 4 ] loss: 0.4643598794937134 2022-08-12 00:04:48.329424
Epoch:[ 13 5 ] loss: 0.46077761054039 2022-08-12 00:04:48.752717
Epoch:[ 13 6 ] loss: 0.4581298530101776 2022-08-12 00:04:49.167229
Epoch:[ 13 7 ] loss: 0.46153223514556885 2022-08-12 00:04:49.592580
Epoch:[ 13 8 ] loss: 0.4592808187007904 2022-08-12 00:04:50.023915
Epoch:[ 13 9 ] loss: 0.46085697412490845 2022-08-12 00:04:50.447622
Epoch:[ 13 10 ] loss: 0.4701007604598999 2022-08-12 00:04:50.868452
Epoch:[ 13 11 ] loss: 0.4711971580982208 2022-08-12 00:04:51.293109
Epoch:[ 13 12 ] loss: 0.46754759550094604 2022-08-12 00:04:51.716584
Epoch:[ 13 13 ] loss: 0.46899643540382385 2022-08-12 00:04:52.139639
Epoch:[ 13 14 ] loss: 0.47098368406295776 2022-08-12 00:04:52.565568
Epoch:[ 13 15 ] loss: 0.4767901301383972 2022-08-12 00:04:52.990763
Epoch:[ 13 16 ] loss: 0.47541293501853943 2022-08-12 00:04:58.084321
Epoch:[ 13 17 ] loss: 0.46898460388183594 2022-08-12 00:04:58.508812
Epoch:[ 13 18 ] loss: 0.47254419326782227 2022-08-12 00:04:58.937055
Epoch:[ 13 19 ] loss: 0.4685133397579193 2022-08-12 00:04:59.360974
Training_Epoch:[ 13 ] Training_loss: 0.4661897972226143 2022-08-12 00:04:59.361655
learning rate:  0.0034
val: 1 0.5014153122901917
val: 2 0.5046653747558594
val: 3 0.5062656402587891
val: 4 0.5130437016487122
val: 5 0.5081280469894409
val: 6 0.5105137228965759
val: 7 0.5084127187728882
val: 8 0.4962354898452759
val: 9 0.5022525191307068
val: 10 0.5056011080741882
val: 11 0.49775055050849915
val: 12 0.5119515657424927
val: 13 0.5080640316009521
val: 14 0.5103968381881714
val: 15 0.5117337703704834
val: 16 0.4982626736164093
val: 17 0.5208219885826111
val: 18 0.5072878003120422
val: 19 0.5048076510429382
val: 20 0.5120667815208435
val_Epoch:[ 13 ] val_loss: 0.5069838643074036 2022-08-12 00:05:02.924466
start training 2022-08-12 00:05:03.027678
Epoch:[ 14 0 ] loss: 0.46489644050598145 2022-08-12 00:05:17.227443
Epoch:[ 14 1 ] loss: 0.4617637097835541 2022-08-12 00:05:17.711564
Epoch:[ 14 2 ] loss: 0.46252384781837463 2022-08-12 00:05:18.135496
Epoch:[ 14 3 ] loss: 0.46199777722358704 2022-08-12 00:05:18.559124
Epoch:[ 14 4 ] loss: 0.4601859450340271 2022-08-12 00:05:18.984002
Epoch:[ 14 5 ] loss: 0.4590713381767273 2022-08-12 00:05:19.404173
Epoch:[ 14 6 ] loss: 0.4613525867462158 2022-08-12 00:05:19.818053
Epoch:[ 14 7 ] loss: 0.45864447951316833 2022-08-12 00:05:20.237901
Epoch:[ 14 8 ] loss: 0.45979323983192444 2022-08-12 00:05:20.666852
Epoch:[ 14 9 ] loss: 0.4596719741821289 2022-08-12 00:05:21.088425
Epoch:[ 14 10 ] loss: 0.45853328704833984 2022-08-12 00:05:21.506502
Epoch:[ 14 11 ] loss: 0.45551109313964844 2022-08-12 00:05:21.926425
Epoch:[ 14 12 ] loss: 0.4573831856250763 2022-08-12 00:05:22.353279
Epoch:[ 14 13 ] loss: 0.45477095246315 2022-08-12 00:05:22.780321
Epoch:[ 14 14 ] loss: 0.4557300806045532 2022-08-12 00:05:23.203773
Epoch:[ 14 15 ] loss: 0.4571932554244995 2022-08-12 00:05:23.637886
Epoch:[ 14 16 ] loss: 0.45689865946769714 2022-08-12 00:05:29.230533
Epoch:[ 14 17 ] loss: 0.4574585258960724 2022-08-12 00:05:29.656840
Epoch:[ 14 18 ] loss: 0.45688939094543457 2022-08-12 00:05:30.083948
Epoch:[ 14 19 ] loss: 0.4573730528354645 2022-08-12 00:05:30.505511
Training_Epoch:[ 14 ] Training_loss: 0.45888214111328124 2022-08-12 00:05:30.506182
learning rate:  0.0034
val: 1 0.4846293032169342
val: 2 0.4808129370212555
val: 3 0.4776858389377594
val: 4 0.4778306782245636
val: 5 0.4864060580730438
val: 6 0.4855825901031494
val: 7 0.4781697988510132
val: 8 0.48602965474128723
val: 9 0.483223557472229
val: 10 0.4836832582950592
val: 11 0.4830881655216217
val: 12 0.4766104221343994
val: 13 0.48923978209495544
val: 14 0.4841618835926056
val: 15 0.4839685261249542
val: 16 0.48587748408317566
val: 17 0.4810931980609894
val: 18 0.48163923621177673
val: 19 0.4835340678691864
val: 20 0.4832833409309387
val_Epoch:[ 14 ] val_loss: 0.4828274890780449 2022-08-12 00:05:34.142239
start training 2022-08-12 00:05:34.247869
Epoch:[ 15 0 ] loss: 0.45403575897216797 2022-08-12 00:05:49.103222
Epoch:[ 15 1 ] loss: 0.45913931727409363 2022-08-12 00:05:49.525651
Epoch:[ 15 2 ] loss: 0.45559659600257874 2022-08-12 00:05:49.943836
Epoch:[ 15 3 ] loss: 0.4540867805480957 2022-08-12 00:05:50.364880
Epoch:[ 15 4 ] loss: 0.4548979699611664 2022-08-12 00:05:50.792900
Epoch:[ 15 5 ] loss: 0.4511095881462097 2022-08-12 00:05:51.219728
Epoch:[ 15 6 ] loss: 0.4518474042415619 2022-08-12 00:05:51.639314
Epoch:[ 15 7 ] loss: 0.4509541392326355 2022-08-12 00:05:52.059911
Epoch:[ 15 8 ] loss: 0.45048752427101135 2022-08-12 00:05:52.486234
Epoch:[ 15 9 ] loss: 0.44905775785446167 2022-08-12 00:05:52.910450
Epoch:[ 15 10 ] loss: 0.44947171211242676 2022-08-12 00:05:53.332750
Epoch:[ 15 11 ] loss: 0.4492478370666504 2022-08-12 00:05:53.755220
Epoch:[ 15 12 ] loss: 0.4511103630065918 2022-08-12 00:05:54.179813
Epoch:[ 15 13 ] loss: 0.44998836517333984 2022-08-12 00:05:54.602492
Epoch:[ 15 14 ] loss: 0.454346239566803 2022-08-12 00:05:55.015953
Epoch:[ 15 15 ] loss: 0.45123279094696045 2022-08-12 00:05:55.439945
Epoch:[ 15 16 ] loss: 0.4499444365501404 2022-08-12 00:06:00.837833
Epoch:[ 15 17 ] loss: 0.44814780354499817 2022-08-12 00:06:01.250698
Epoch:[ 15 18 ] loss: 0.44918906688690186 2022-08-12 00:06:01.668750
Epoch:[ 15 19 ] loss: 0.4503392279148102 2022-08-12 00:06:02.092392
Training_Epoch:[ 15 ] Training_loss: 0.45171153396368025 2022-08-12 00:06:02.093115
learning rate:  0.0034
val: 1 0.4588397443294525
val: 2 0.449410080909729
val: 3 0.4521647095680237
val: 4 0.45381036400794983
val: 5 0.4525913596153259
val: 6 0.45271387696266174
val: 7 0.4536365866661072
val: 8 0.4474230706691742
val: 9 0.45385757088661194
val: 10 0.4638831913471222
val: 11 0.4475008547306061
val: 12 0.45483696460723877
val: 13 0.45013582706451416
val: 14 0.4477826654911041
val: 15 0.44876232743263245
val: 16 0.457671195268631
val: 17 0.45297375321388245
val: 18 0.45694631338119507
val: 19 0.45427608489990234
val: 20 0.4490690529346466
val_Epoch:[ 15 ] val_loss: 0.4529142796993256 2022-08-12 00:06:05.703185
start training 2022-08-12 00:06:05.805390
Epoch:[ 16 0 ] loss: 0.4472767114639282 2022-08-12 00:06:19.943368
Epoch:[ 16 1 ] loss: 0.4463919401168823 2022-08-12 00:06:20.399305
Epoch:[ 16 2 ] loss: 0.447397917509079 2022-08-12 00:06:20.824159
Epoch:[ 16 3 ] loss: 0.447556734085083 2022-08-12 00:06:21.247801
Epoch:[ 16 4 ] loss: 0.4516919255256653 2022-08-12 00:06:21.671140
Epoch:[ 16 5 ] loss: 0.4490649700164795 2022-08-12 00:06:22.094444
Epoch:[ 16 6 ] loss: 0.44934675097465515 2022-08-12 00:06:22.522568
Epoch:[ 16 7 ] loss: 0.4470505118370056 2022-08-12 00:06:22.942971
Epoch:[ 16 8 ] loss: 0.4429630637168884 2022-08-12 00:06:23.359729
Epoch:[ 16 9 ] loss: 0.4457884132862091 2022-08-12 00:06:23.779166
Epoch:[ 16 10 ] loss: 0.4451090097427368 2022-08-12 00:06:24.208226
Epoch:[ 16 11 ] loss: 0.4457699954509735 2022-08-12 00:06:24.628819
Epoch:[ 16 12 ] loss: 0.44688042998313904 2022-08-12 00:06:25.049358
Epoch:[ 16 13 ] loss: 0.4446229636669159 2022-08-12 00:06:25.471211
Epoch:[ 16 14 ] loss: 0.4451576769351959 2022-08-12 00:06:25.904523
Epoch:[ 16 15 ] loss: 0.44325941801071167 2022-08-12 00:06:26.329861
Epoch:[ 16 16 ] loss: 0.44374755024909973 2022-08-12 00:06:32.310832
Epoch:[ 16 17 ] loss: 0.44948941469192505 2022-08-12 00:06:32.735012
Epoch:[ 16 18 ] loss: 0.46028193831443787 2022-08-12 00:06:33.154010
Epoch:[ 16 19 ] loss: 0.4518163800239563 2022-08-12 00:06:33.576320
Training_Epoch:[ 16 ] Training_loss: 0.44753318578004836 2022-08-12 00:06:33.577014
learning rate:  0.0034
val: 1 0.520519495010376
val: 2 0.5271021127700806
val: 3 0.5318121910095215
val: 4 0.5101193189620972
val: 5 0.5198418498039246
val: 6 0.526757538318634
val: 7 0.5350387692451477
val: 8 0.5432314276695251
val: 9 0.5182992219924927
val: 10 0.5178918242454529
val: 11 0.5278505682945251
val: 12 0.5182637572288513
val: 13 0.5246548056602478
val: 14 0.5290328860282898
val: 15 0.5164430737495422
val: 16 0.5264776349067688
val: 17 0.525317370891571
val: 18 0.5270262956619263
val: 19 0.5260849595069885
val: 20 0.5264098048210144
val_Epoch:[ 16 ] val_loss: 0.5249087452888489 2022-08-12 00:06:37.204278
start training 2022-08-12 00:06:37.309783
Epoch:[ 17 0 ] loss: 0.45430848002433777 2022-08-12 00:06:52.336312
Epoch:[ 17 1 ] loss: 0.45957478880882263 2022-08-12 00:06:52.757565
Epoch:[ 17 2 ] loss: 0.44989970326423645 2022-08-12 00:06:53.181803
Epoch:[ 17 3 ] loss: 0.4528670907020569 2022-08-12 00:06:53.609417
Epoch:[ 17 4 ] loss: 0.44704437255859375 2022-08-12 00:06:54.030433
Epoch:[ 17 5 ] loss: 0.4561205208301544 2022-08-12 00:06:54.455352
Epoch:[ 17 6 ] loss: 0.4515414535999298 2022-08-12 00:06:54.880729
Epoch:[ 17 7 ] loss: 0.4512999951839447 2022-08-12 00:06:55.303349
Epoch:[ 17 8 ] loss: 0.44605860114097595 2022-08-12 00:06:55.720181
Epoch:[ 17 9 ] loss: 0.4514789879322052 2022-08-12 00:06:56.138273
Epoch:[ 17 10 ] loss: 0.4480155408382416 2022-08-12 00:06:56.563393
Epoch:[ 17 11 ] loss: 0.4473487436771393 2022-08-12 00:06:56.986321
Epoch:[ 17 12 ] loss: 0.44726404547691345 2022-08-12 00:06:57.408633
Epoch:[ 17 13 ] loss: 0.44690999388694763 2022-08-12 00:06:57.830508
Epoch:[ 17 14 ] loss: 0.44718167185783386 2022-08-12 00:06:58.257625
Epoch:[ 17 15 ] loss: 0.4473004639148712 2022-08-12 00:06:58.689212
Epoch:[ 17 16 ] loss: 0.444748193025589 2022-08-12 00:07:04.465545
Epoch:[ 17 17 ] loss: 0.4479949474334717 2022-08-12 00:07:04.891803
Epoch:[ 17 18 ] loss: 0.44319018721580505 2022-08-12 00:07:05.323572
Epoch:[ 17 19 ] loss: 0.44260233640670776 2022-08-12 00:07:05.743819
Training_Epoch:[ 17 ] Training_loss: 0.4491375058889389 2022-08-12 00:07:05.744560
learning rate:  0.0034
val: 1 0.45883142948150635
val: 2 0.45089879631996155
val: 3 0.4566398561000824
val: 4 0.44045519828796387
val: 5 0.4606633484363556
val: 6 0.4574858844280243
val: 7 0.4488278925418854
val: 8 0.4554501175880432
val: 9 0.44789478182792664
val: 10 0.45993444323539734
val: 11 0.44850966334342957
val: 12 0.4559440612792969
val: 13 0.4507603943347931
val: 14 0.447993665933609
val: 15 0.4481227993965149
val: 16 0.4477684795856476
val: 17 0.4508034288883209
val: 18 0.449177622795105
val: 19 0.4488617479801178
val: 20 0.4397653639316559
val_Epoch:[ 17 ] val_loss: 0.45123944878578187 2022-08-12 00:07:09.350198
start training 2022-08-12 00:07:09.457088
Epoch:[ 18 0 ] loss: 0.4455859363079071 2022-08-12 00:07:24.383891
Epoch:[ 18 1 ] loss: 0.4423750638961792 2022-08-12 00:07:24.804654
Epoch:[ 18 2 ] loss: 0.4419119358062744 2022-08-12 00:07:25.230977
Epoch:[ 18 3 ] loss: 0.43961143493652344 2022-08-12 00:07:25.651087
Epoch:[ 18 4 ] loss: 0.4370127320289612 2022-08-12 00:07:26.071408
Epoch:[ 18 5 ] loss: 0.44001761078834534 2022-08-12 00:07:26.498330
Epoch:[ 18 6 ] loss: 0.4395105838775635 2022-08-12 00:07:26.925019
Epoch:[ 18 7 ] loss: 0.44111520051956177 2022-08-12 00:07:27.349948
Epoch:[ 18 8 ] loss: 0.4397697448730469 2022-08-12 00:07:27.771832
Epoch:[ 18 9 ] loss: 0.4375658929347992 2022-08-12 00:07:28.195622
Epoch:[ 18 10 ] loss: 0.43874695897102356 2022-08-12 00:07:28.620457
Epoch:[ 18 11 ] loss: 0.43983420729637146 2022-08-12 00:07:29.041604
Epoch:[ 18 12 ] loss: 0.44064095616340637 2022-08-12 00:07:29.466900
Epoch:[ 18 13 ] loss: 0.44311171770095825 2022-08-12 00:07:29.893024
Epoch:[ 18 14 ] loss: 0.44102805852890015 2022-08-12 00:07:30.313736
Epoch:[ 18 15 ] loss: 0.4362832307815552 2022-08-12 00:07:30.735206
Epoch:[ 18 16 ] loss: 0.440273255109787 2022-08-12 00:07:36.046631
Epoch:[ 18 17 ] loss: 0.4395848512649536 2022-08-12 00:07:36.471572
Epoch:[ 18 18 ] loss: 0.43262261152267456 2022-08-12 00:07:36.891294
Epoch:[ 18 19 ] loss: 0.43735232949256897 2022-08-12 00:07:37.304230
Training_Epoch:[ 18 ] Training_loss: 0.43969771564006804 2022-08-12 00:07:37.304935
learning rate:  0.0034
val: 1 0.43834128975868225
val: 2 0.4388546347618103
val: 3 0.4449932873249054
val: 4 0.44244593381881714
val: 5 0.4419291913509369
val: 6 0.438393235206604
val: 7 0.4461388885974884
val: 8 0.4337126314640045
val: 9 0.4426250159740448
val: 10 0.43929243087768555
val: 11 0.4439118802547455
val: 12 0.43663638830184937
val: 13 0.4376513957977295
val: 14 0.4402405619621277
val: 15 0.43694278597831726
val: 16 0.4362681806087494
val: 17 0.4336498975753784
val: 18 0.44649648666381836
val: 19 0.44532322883605957
val: 20 0.4474232792854309
val_Epoch:[ 18 ] val_loss: 0.4405635312199593 2022-08-12 00:07:40.862279
start training 2022-08-12 00:07:40.969387
Epoch:[ 19 0 ] loss: 0.434872567653656 2022-08-12 00:07:55.786292
Epoch:[ 19 1 ] loss: 0.4347730278968811 2022-08-12 00:07:56.207994
Epoch:[ 19 2 ] loss: 0.4373551905155182 2022-08-12 00:07:56.631067
Epoch:[ 19 3 ] loss: 0.43881887197494507 2022-08-12 00:07:57.045349
Epoch:[ 19 4 ] loss: 0.434844970703125 2022-08-12 00:07:57.470759
Epoch:[ 19 5 ] loss: 0.43776196241378784 2022-08-12 00:07:57.897001
Epoch:[ 19 6 ] loss: 0.4368920624256134 2022-08-12 00:07:58.317669
Epoch:[ 19 7 ] loss: 0.43709850311279297 2022-08-12 00:07:58.733690
Epoch:[ 19 8 ] loss: 0.4404720962047577 2022-08-12 00:07:59.158196
Epoch:[ 19 9 ] loss: 0.4380558431148529 2022-08-12 00:07:59.590526
Epoch:[ 19 10 ] loss: 0.4393500089645386 2022-08-12 00:08:00.015350
Epoch:[ 19 11 ] loss: 0.4366343319416046 2022-08-12 00:08:00.439153
Epoch:[ 19 12 ] loss: 0.43728089332580566 2022-08-12 00:08:00.862927
Epoch:[ 19 13 ] loss: 0.43773120641708374 2022-08-12 00:08:01.290457
Epoch:[ 19 14 ] loss: 0.43288448452949524 2022-08-12 00:08:01.715302
Epoch:[ 19 15 ] loss: 0.4364483058452606 2022-08-12 00:08:02.133871
Epoch:[ 19 16 ] loss: 0.4381566643714905 2022-08-12 00:08:07.455006
Epoch:[ 19 17 ] loss: 0.43229204416275024 2022-08-12 00:08:07.876171
Epoch:[ 19 18 ] loss: 0.43460533022880554 2022-08-12 00:08:08.301837
Epoch:[ 19 19 ] loss: 0.43072250485420227 2022-08-12 00:08:08.728230
Training_Epoch:[ 19 ] Training_loss: 0.43635254353284836 2022-08-12 00:08:08.728907
learning rate:  0.0034
val: 1 0.4610457420349121
val: 2 0.45842862129211426
val: 3 0.4627382755279541
val: 4 0.45582130551338196
val: 5 0.4603419303894043
val: 6 0.4553748667240143
val: 7 0.4577196538448334
val: 8 0.45663201808929443
val: 9 0.45032769441604614
val: 10 0.4598182141780853
val: 11 0.4599269926548004
val: 12 0.4547480344772339
val: 13 0.4588013291358948
val: 14 0.45449143648147583
val: 15 0.445413202047348
val: 16 0.4589114189147949
val: 17 0.4540826976299286
val: 18 0.4605480432510376
val: 19 0.4538014233112335
val: 20 0.4528995454311371
val_Epoch:[ 19 ] val_loss: 0.45659362226724626 2022-08-12 00:08:12.269796
start training 2022-08-12 00:08:12.373206
Epoch:[ 20 0 ] loss: 0.4308251440525055 2022-08-12 00:08:27.245711
Epoch:[ 20 1 ] loss: 0.43717849254608154 2022-08-12 00:08:27.669228
Epoch:[ 20 2 ] loss: 0.43584132194519043 2022-08-12 00:08:28.095614
Epoch:[ 20 3 ] loss: 0.4334326982498169 2022-08-12 00:08:28.515826
Epoch:[ 20 4 ] loss: 0.43349164724349976 2022-08-12 00:08:28.940486
Epoch:[ 20 5 ] loss: 0.43384912610054016 2022-08-12 00:08:29.365985
Epoch:[ 20 6 ] loss: 0.43662410974502563 2022-08-12 00:08:29.792623
Epoch:[ 20 7 ] loss: 0.43530789017677307 2022-08-12 00:08:30.215309
Epoch:[ 20 8 ] loss: 0.4299221336841583 2022-08-12 00:08:30.638478
Epoch:[ 20 9 ] loss: 0.43756553530693054 2022-08-12 00:08:31.063894
Epoch:[ 20 10 ] loss: 0.43938735127449036 2022-08-12 00:08:31.483266
Epoch:[ 20 11 ] loss: 0.4356870949268341 2022-08-12 00:08:31.902831
Epoch:[ 20 12 ] loss: 0.44141432642936707 2022-08-12 00:08:32.327301
Epoch:[ 20 13 ] loss: 0.4357726275920868 2022-08-12 00:08:32.762029
Epoch:[ 20 14 ] loss: 0.437030166387558 2022-08-12 00:08:33.181622
Epoch:[ 20 15 ] loss: 0.43493399024009705 2022-08-12 00:08:33.596313
Epoch:[ 20 16 ] loss: 0.4383855164051056 2022-08-12 00:08:38.973535
Epoch:[ 20 17 ] loss: 0.4388416111469269 2022-08-12 00:08:39.396735
Epoch:[ 20 18 ] loss: 0.43589723110198975 2022-08-12 00:08:39.817273
Epoch:[ 20 19 ] loss: 0.43683555722236633 2022-08-12 00:08:40.237014
Training_Epoch:[ 20 ] Training_loss: 0.4359111785888672 2022-08-12 00:08:40.237687
learning rate:  0.0034
netparams have been saved once 20
val: 1 0.5238035917282104
val: 2 0.5087886452674866
val: 3 0.5114181041717529
val: 4 0.5134696960449219
val: 5 0.5124923586845398
val: 6 0.5178009271621704
val: 7 0.5178565382957458
val: 8 0.5121505856513977
val: 9 0.5053227543830872
val: 10 0.5193069577217102
val: 11 0.5162224769592285
val: 12 0.5089429616928101
val: 13 0.5186936259269714
val: 14 0.514103889465332
val: 15 0.5131901502609253
val: 16 0.505084216594696
val: 17 0.5152958631515503
val: 18 0.5146139860153198
val: 19 0.5114778280258179
val: 20 0.5140832662582397
val_Epoch:[ 20 ] val_loss: 0.5137059211730957 2022-08-12 00:08:43.893901
start training 2022-08-12 00:08:44.002177
Epoch:[ 21 0 ] loss: 0.434312641620636 2022-08-12 00:08:58.092586
Epoch:[ 21 1 ] loss: 0.4325072169303894 2022-08-12 00:08:58.772400
Epoch:[ 21 2 ] loss: 0.4302956163883209 2022-08-12 00:08:59.188762
Epoch:[ 21 3 ] loss: 0.43312475085258484 2022-08-12 00:08:59.610212
Epoch:[ 21 4 ] loss: 0.432794988155365 2022-08-12 00:09:00.032558
Epoch:[ 21 5 ] loss: 0.43193280696868896 2022-08-12 00:09:00.456101
Epoch:[ 21 6 ] loss: 0.434069961309433 2022-08-12 00:09:00.878513
Epoch:[ 21 7 ] loss: 0.4289547801017761 2022-08-12 00:09:01.300702
Epoch:[ 21 8 ] loss: 0.4322906732559204 2022-08-12 00:09:01.719469
Epoch:[ 21 9 ] loss: 0.42957526445388794 2022-08-12 00:09:02.134801
Epoch:[ 21 10 ] loss: 0.42888006567955017 2022-08-12 00:09:02.559239
Epoch:[ 21 11 ] loss: 0.42995452880859375 2022-08-12 00:09:02.985455
Epoch:[ 21 12 ] loss: 0.4287937581539154 2022-08-12 00:09:03.413869
Epoch:[ 21 13 ] loss: 0.4270074963569641 2022-08-12 00:09:03.835862
Epoch:[ 21 14 ] loss: 0.4265759587287903 2022-08-12 00:09:04.259588
Epoch:[ 21 15 ] loss: 0.4304092228412628 2022-08-12 00:09:04.677450
Epoch:[ 21 16 ] loss: 0.42588043212890625 2022-08-12 00:09:10.063167
Epoch:[ 21 17 ] loss: 0.42838069796562195 2022-08-12 00:09:10.484798
Epoch:[ 21 18 ] loss: 0.42884138226509094 2022-08-12 00:09:10.905655
Epoch:[ 21 19 ] loss: 0.4275759160518646 2022-08-12 00:09:11.449606
Training_Epoch:[ 21 ] Training_loss: 0.43010790795087817 2022-08-12 00:09:11.450334
learning rate:  0.0028899999999999998
val: 1 0.4272558391094208
val: 2 0.4354696273803711
val: 3 0.43338534235954285
val: 4 0.42970719933509827
val: 5 0.43538376688957214
val: 6 0.4341972768306732
val: 7 0.4340445399284363
val: 8 0.4328564703464508
val: 9 0.43153753876686096
val: 10 0.4364778697490692
val: 11 0.4247240424156189
val: 12 0.43010973930358887
val: 13 0.43015745282173157
val: 14 0.4299142360687256
val: 15 0.4367797374725342
val: 16 0.4333491623401642
val: 17 0.4293696880340576
val: 18 0.437582790851593
val: 19 0.4439948797225952
val: 20 0.43633338809013367
val_Epoch:[ 21 ] val_loss: 0.4331315293908119 2022-08-12 00:09:15.018029
start training 2022-08-12 00:09:15.126306
Epoch:[ 22 0 ] loss: 0.4260287880897522 2022-08-12 00:09:29.916941
Epoch:[ 22 1 ] loss: 0.4295068085193634 2022-08-12 00:09:30.337657
Epoch:[ 22 2 ] loss: 0.4236595928668976 2022-08-12 00:09:30.763063
Epoch:[ 22 3 ] loss: 0.42708781361579895 2022-08-12 00:09:31.186666
Epoch:[ 22 4 ] loss: 0.4296015202999115 2022-08-12 00:09:31.609237
Epoch:[ 22 5 ] loss: 0.4261191785335541 2022-08-12 00:09:32.033244
Epoch:[ 22 6 ] loss: 0.4299415946006775 2022-08-12 00:09:32.457608
Epoch:[ 22 7 ] loss: 0.42486560344696045 2022-08-12 00:09:32.870744
Epoch:[ 22 8 ] loss: 0.4283665716648102 2022-08-12 00:09:33.295042
Epoch:[ 22 9 ] loss: 0.42828404903411865 2022-08-12 00:09:33.718288
Epoch:[ 22 10 ] loss: 0.4239237606525421 2022-08-12 00:09:34.139590
Epoch:[ 22 11 ] loss: 0.4261098802089691 2022-08-12 00:09:34.552539
Epoch:[ 22 12 ] loss: 0.4256080090999603 2022-08-12 00:09:34.983841
Epoch:[ 22 13 ] loss: 0.42543545365333557 2022-08-12 00:09:35.413073
Epoch:[ 22 14 ] loss: 0.42637741565704346 2022-08-12 00:09:35.837385
Epoch:[ 22 15 ] loss: 0.42710939049720764 2022-08-12 00:09:36.264233
Epoch:[ 22 16 ] loss: 0.42477262020111084 2022-08-12 00:09:41.305713
Epoch:[ 22 17 ] loss: 0.4246366322040558 2022-08-12 00:09:41.732399
Epoch:[ 22 18 ] loss: 0.42456457018852234 2022-08-12 00:09:42.157927
Epoch:[ 22 19 ] loss: 0.4271060526371002 2022-08-12 00:09:42.579574
Training_Epoch:[ 22 ] Training_loss: 0.4264552652835846 2022-08-12 00:09:42.580324
learning rate:  0.0028899999999999998
val: 1 0.43335163593292236
val: 2 0.43785738945007324
val: 3 0.4331637918949127
val: 4 0.43172356486320496
val: 5 0.4319861829280853
val: 6 0.4338292181491852
val: 7 0.4308464229106903
val: 8 0.43159839510917664
val: 9 0.437134712934494
val: 10 0.4341271221637726
val: 11 0.4320744574069977
val: 12 0.43446996808052063
val: 13 0.42973899841308594
val: 14 0.43840229511260986
val: 15 0.43036556243896484
val: 16 0.4335762858390808
val: 17 0.4384666383266449
val: 18 0.4451223313808441
val: 19 0.43625929951667786
val: 20 0.4298786222934723
val_Epoch:[ 22 ] val_loss: 0.4341986447572708 2022-08-12 00:09:46.208688
start training 2022-08-12 00:09:46.308835
Epoch:[ 23 0 ] loss: 0.4271259009838104 2022-08-12 00:10:00.872772
Epoch:[ 23 1 ] loss: 0.4242355525493622 2022-08-12 00:10:01.284504
Epoch:[ 23 2 ] loss: 0.429107666015625 2022-08-12 00:10:01.707697
Epoch:[ 23 3 ] loss: 0.42468276619911194 2022-08-12 00:10:02.137077
Epoch:[ 23 4 ] loss: 0.4276992082595825 2022-08-12 00:10:02.555843
Epoch:[ 23 5 ] loss: 0.42562416195869446 2022-08-12 00:10:02.969922
Epoch:[ 23 6 ] loss: 0.426408976316452 2022-08-12 00:10:03.395887
Epoch:[ 23 7 ] loss: 0.4249357283115387 2022-08-12 00:10:03.823314
Epoch:[ 23 8 ] loss: 0.42482998967170715 2022-08-12 00:10:04.249223
Epoch:[ 23 9 ] loss: 0.42500361800193787 2022-08-12 00:10:04.669264
Epoch:[ 23 10 ] loss: 0.4247532784938812 2022-08-12 00:10:05.092877
Epoch:[ 23 11 ] loss: 0.4252959191799164 2022-08-12 00:10:05.515674
Epoch:[ 23 12 ] loss: 0.42207884788513184 2022-08-12 00:10:05.939021
Epoch:[ 23 13 ] loss: 0.4222778379917145 2022-08-12 00:10:06.365517
Epoch:[ 23 14 ] loss: 0.4248306155204773 2022-08-12 00:10:06.797324
Epoch:[ 23 15 ] loss: 0.4252537488937378 2022-08-12 00:10:07.220536
Epoch:[ 23 16 ] loss: 0.4277818500995636 2022-08-12 00:10:12.759291
Epoch:[ 23 17 ] loss: 0.421810120344162 2022-08-12 00:10:13.182537
Epoch:[ 23 18 ] loss: 0.42319589853286743 2022-08-12 00:10:13.604496
Epoch:[ 23 19 ] loss: 0.42176932096481323 2022-08-12 00:10:14.019777
Training_Epoch:[ 23 ] Training_loss: 0.4249350503087044 2022-08-12 00:10:14.020489
learning rate:  0.0028899999999999998
val: 1 0.44212403893470764
val: 2 0.44413620233535767
val: 3 0.4412263035774231
val: 4 0.45317283272743225
val: 5 0.44057217240333557
val: 6 0.4516213834285736
val: 7 0.4441465437412262
val: 8 0.4397711455821991
val: 9 0.4409068524837494
val: 10 0.44674837589263916
val: 11 0.44995933771133423
val: 12 0.44076547026634216
val: 13 0.4456477761268616
val: 14 0.4420181214809418
val: 15 0.44662100076675415
val: 16 0.4436890184879303
val: 17 0.444307804107666
val: 18 0.44940364360809326
val: 19 0.4489673972129822
val: 20 0.4459126591682434
val_Epoch:[ 23 ] val_loss: 0.4450859040021896 2022-08-12 00:10:17.599663
start training 2022-08-12 00:10:17.704714
Epoch:[ 24 0 ] loss: 0.42009830474853516 2022-08-12 00:10:32.522175
Epoch:[ 24 1 ] loss: 0.4241762161254883 2022-08-12 00:10:32.952293
Epoch:[ 24 2 ] loss: 0.42115017771720886 2022-08-12 00:10:33.375476
Epoch:[ 24 3 ] loss: 0.4248417615890503 2022-08-12 00:10:33.787223
Epoch:[ 24 4 ] loss: 0.42243844270706177 2022-08-12 00:10:34.209404
Epoch:[ 24 5 ] loss: 0.4221079349517822 2022-08-12 00:10:34.637230
Epoch:[ 24 6 ] loss: 0.424402117729187 2022-08-12 00:10:35.056613
Epoch:[ 24 7 ] loss: 0.42058080434799194 2022-08-12 00:10:35.472896
Epoch:[ 24 8 ] loss: 0.4191216230392456 2022-08-12 00:10:35.899606
Epoch:[ 24 9 ] loss: 0.4248102605342865 2022-08-12 00:10:36.325749
Epoch:[ 24 10 ] loss: 0.42311373353004456 2022-08-12 00:10:36.757299
Epoch:[ 24 11 ] loss: 0.4235117733478546 2022-08-12 00:10:37.177170
Epoch:[ 24 12 ] loss: 0.4212265610694885 2022-08-12 00:10:37.601050
Epoch:[ 24 13 ] loss: 0.4206664264202118 2022-08-12 00:10:38.018669
Epoch:[ 24 14 ] loss: 0.4220017194747925 2022-08-12 00:10:38.445429
Epoch:[ 24 15 ] loss: 0.4225938618183136 2022-08-12 00:10:38.871830
Epoch:[ 24 16 ] loss: 0.4205312430858612 2022-08-12 00:10:44.242126
Epoch:[ 24 17 ] loss: 0.42254748940467834 2022-08-12 00:10:44.665522
Epoch:[ 24 18 ] loss: 0.4215628504753113 2022-08-12 00:10:45.088357
Epoch:[ 24 19 ] loss: 0.42338165640830994 2022-08-12 00:10:45.511553
Training_Epoch:[ 24 ] Training_loss: 0.4222432479262352 2022-08-12 00:10:45.512257
learning rate:  0.0028899999999999998
val: 1 0.44105035066604614
val: 2 0.4408268928527832
val: 3 0.4326249659061432
val: 4 0.43420711159706116
val: 5 0.4421072006225586
val: 6 0.43571439385414124
val: 7 0.442261278629303
val: 8 0.43182533979415894
val: 9 0.4385869801044464
val: 10 0.44079890847206116
val: 11 0.4343453645706177
val: 12 0.4375835955142975
val: 13 0.43235713243484497
val: 14 0.43044453859329224
val: 15 0.4325568974018097
val: 16 0.437885582447052
val: 17 0.4286644458770752
val: 18 0.4297640025615692
val: 19 0.4360525906085968
val: 20 0.43321365118026733
val_Epoch:[ 24 ] val_loss: 0.4356435611844063 2022-08-12 00:10:49.056233
start training 2022-08-12 00:10:49.155053
Epoch:[ 25 0 ] loss: 0.42093732953071594 2022-08-12 00:11:03.215390
Epoch:[ 25 1 ] loss: 0.42063960433006287 2022-08-12 00:11:03.654215
Epoch:[ 25 2 ] loss: 0.422087699174881 2022-08-12 00:11:04.082431
Epoch:[ 25 3 ] loss: 0.4269217252731323 2022-08-12 00:11:04.505902
Epoch:[ 25 4 ] loss: 0.4386347532272339 2022-08-12 00:11:04.919954
Epoch:[ 25 5 ] loss: 0.42764297127723694 2022-08-12 00:11:05.344317
Epoch:[ 25 6 ] loss: 0.43152573704719543 2022-08-12 00:11:05.771021
Epoch:[ 25 7 ] loss: 0.4285670816898346 2022-08-12 00:11:06.193408
Epoch:[ 25 8 ] loss: 0.42882341146469116 2022-08-12 00:11:06.615201
Epoch:[ 25 9 ] loss: 0.4250340759754181 2022-08-12 00:11:07.040239
Epoch:[ 25 10 ] loss: 0.4237845242023468 2022-08-12 00:11:07.463330
Epoch:[ 25 11 ] loss: 0.42939040064811707 2022-08-12 00:11:07.887296
Epoch:[ 25 12 ] loss: 0.42497551441192627 2022-08-12 00:11:08.312669
Epoch:[ 25 13 ] loss: 0.4247993528842926 2022-08-12 00:11:08.737377
Epoch:[ 25 14 ] loss: 0.4225941002368927 2022-08-12 00:11:09.156251
Epoch:[ 25 15 ] loss: 0.4262772798538208 2022-08-12 00:11:09.573775
Epoch:[ 25 16 ] loss: 0.42527246475219727 2022-08-12 00:11:15.006884
Epoch:[ 25 17 ] loss: 0.42405954003334045 2022-08-12 00:11:15.448598
Epoch:[ 25 18 ] loss: 0.4226793348789215 2022-08-12 00:11:15.871083
Epoch:[ 25 19 ] loss: 0.42402416467666626 2022-08-12 00:11:16.283198
Training_Epoch:[ 25 ] Training_loss: 0.4259335532784462 2022-08-12 00:11:16.283902
learning rate:  0.0028899999999999998
val: 1 0.44011399149894714
val: 2 0.4394044280052185
val: 3 0.4474560618400574
val: 4 0.44638004899024963
val: 5 0.4371567964553833
val: 6 0.4383186101913452
val: 7 0.44279608130455017
val: 8 0.4396001100540161
val: 9 0.439897745847702
val: 10 0.43851181864738464
val: 11 0.45067790150642395
val: 12 0.43927842378616333
val: 13 0.44543027877807617
val: 14 0.4537293612957001
val: 15 0.43952006101608276
val: 16 0.4444434344768524
val: 17 0.4382772445678711
val: 18 0.457161545753479
val: 19 0.4429165720939636
val: 20 0.4413362443447113
val_Epoch:[ 25 ] val_loss: 0.4431203380227089 2022-08-12 00:11:19.897481
start training 2022-08-12 00:11:20.001319
Epoch:[ 26 0 ] loss: 0.42044302821159363 2022-08-12 00:11:34.667587
Epoch:[ 26 1 ] loss: 0.4202238619327545 2022-08-12 00:11:35.095790
Epoch:[ 26 2 ] loss: 0.4206455647945404 2022-08-12 00:11:35.512542
Epoch:[ 26 3 ] loss: 0.42005398869514465 2022-08-12 00:11:35.933855
Epoch:[ 26 4 ] loss: 0.4169537127017975 2022-08-12 00:11:36.365612
Epoch:[ 26 5 ] loss: 0.42156311869621277 2022-08-12 00:11:36.790807
Epoch:[ 26 6 ] loss: 0.42090141773223877 2022-08-12 00:11:37.213448
Epoch:[ 26 7 ] loss: 0.42259663343429565 2022-08-12 00:11:37.640584
Epoch:[ 26 8 ] loss: 0.41918453574180603 2022-08-12 00:11:38.064257
Epoch:[ 26 9 ] loss: 0.4192163050174713 2022-08-12 00:11:38.490520
Epoch:[ 26 10 ] loss: 0.41840213537216187 2022-08-12 00:11:38.910784
Epoch:[ 26 11 ] loss: 0.41812705993652344 2022-08-12 00:11:39.337063
Epoch:[ 26 12 ] loss: 0.41856908798217773 2022-08-12 00:11:39.761451
Epoch:[ 26 13 ] loss: 0.41879144310951233 2022-08-12 00:11:40.190484
Epoch:[ 26 14 ] loss: 0.42166969180107117 2022-08-12 00:11:40.613028
Epoch:[ 26 15 ] loss: 0.42272257804870605 2022-08-12 00:11:41.036463
Epoch:[ 26 16 ] loss: 0.4235672056674957 2022-08-12 00:11:46.081833
Epoch:[ 26 17 ] loss: 0.41992050409317017 2022-08-12 00:11:46.505595
Epoch:[ 26 18 ] loss: 0.42030322551727295 2022-08-12 00:11:46.931818
Epoch:[ 26 19 ] loss: 0.42279261350631714 2022-08-12 00:11:47.351197
Training_Epoch:[ 26 ] Training_loss: 0.42033238559961317 2022-08-12 00:11:47.351894
learning rate:  0.0028899999999999998
val: 1 0.4357229173183441
val: 2 0.41775012016296387
val: 3 0.4248715043067932
val: 4 0.426589697599411
val: 5 0.42810407280921936
val: 6 0.4225221276283264
val: 7 0.4219154417514801
val: 8 0.4286629259586334
val: 9 0.42459285259246826
val: 10 0.42700400948524475
val: 11 0.42470282316207886
val: 12 0.43197375535964966
val: 13 0.42344164848327637
val: 14 0.42190682888031006
val: 15 0.42803114652633667
val: 16 0.4247771203517914
val: 17 0.4250986874103546
val: 18 0.4308471977710724
val: 19 0.42749640345573425
val: 20 0.4295799136161804
val_Epoch:[ 26 ] val_loss: 0.42627955973148346 2022-08-12 00:11:50.908655
start training 2022-08-12 00:11:51.011318
Epoch:[ 27 0 ] loss: 0.42040470242500305 2022-08-12 00:12:05.552920
Epoch:[ 27 1 ] loss: 0.4195327162742615 2022-08-12 00:12:05.972849
Epoch:[ 27 2 ] loss: 0.41803839802742004 2022-08-12 00:12:06.394790
Epoch:[ 27 3 ] loss: 0.41687190532684326 2022-08-12 00:12:06.821889
Epoch:[ 27 4 ] loss: 0.4207698404788971 2022-08-12 00:12:07.248554
Epoch:[ 27 5 ] loss: 0.41680991649627686 2022-08-12 00:12:07.671698
Epoch:[ 27 6 ] loss: 0.4167524576187134 2022-08-12 00:12:08.093850
Epoch:[ 27 7 ] loss: 0.4210754930973053 2022-08-12 00:12:08.515051
Epoch:[ 27 8 ] loss: 0.41622376441955566 2022-08-12 00:12:08.938938
Epoch:[ 27 9 ] loss: 0.41644445061683655 2022-08-12 00:12:09.356693
Epoch:[ 27 10 ] loss: 0.4162134528160095 2022-08-12 00:12:09.782977
Epoch:[ 27 11 ] loss: 0.41399699449539185 2022-08-12 00:12:10.201721
Epoch:[ 27 12 ] loss: 0.4131348133087158 2022-08-12 00:12:10.616397
Epoch:[ 27 13 ] loss: 0.41690462827682495 2022-08-12 00:12:11.035226
Epoch:[ 27 14 ] loss: 0.4164592921733856 2022-08-12 00:12:11.457877
Epoch:[ 27 15 ] loss: 0.41574618220329285 2022-08-12 00:12:11.883548
Epoch:[ 27 16 ] loss: 0.4134739637374878 2022-08-12 00:12:17.388620
Epoch:[ 27 17 ] loss: 0.4158381223678589 2022-08-12 00:12:17.814239
Epoch:[ 27 18 ] loss: 0.41432154178619385 2022-08-12 00:12:18.240239
Epoch:[ 27 19 ] loss: 0.413051575422287 2022-08-12 00:12:18.656995
Training_Epoch:[ 27 ] Training_loss: 0.41660321056842803 2022-08-12 00:12:18.657705
learning rate:  0.0028899999999999998
val: 1 0.41729915142059326
val: 2 0.41760075092315674
val: 3 0.42534971237182617
val: 4 0.42356884479522705
val: 5 0.41433367133140564
val: 6 0.4210355579853058
val: 7 0.4156205654144287
val: 8 0.4227312505245209
val: 9 0.418326735496521
val: 10 0.4224579930305481
val: 11 0.4210013449192047
val: 12 0.42305925488471985
val: 13 0.42379289865493774
val: 14 0.4157852232456207
val: 15 0.4178709089756012
val: 16 0.4210686981678009
val: 17 0.4164556860923767
val: 18 0.4190286099910736
val: 19 0.42366722226142883
val: 20 0.4252925515174866
val_Epoch:[ 27 ] val_loss: 0.4202673316001892 2022-08-12 00:12:22.252808
start training 2022-08-12 00:12:22.356820
Epoch:[ 28 0 ] loss: 0.4128703474998474 2022-08-12 00:12:36.990380
Epoch:[ 28 1 ] loss: 0.4144381284713745 2022-08-12 00:12:37.415509
Epoch:[ 28 2 ] loss: 0.41573503613471985 2022-08-12 00:12:37.835529
Epoch:[ 28 3 ] loss: 0.4140234887599945 2022-08-12 00:12:38.254729
Epoch:[ 28 4 ] loss: 0.41462501883506775 2022-08-12 00:12:38.677657
Epoch:[ 28 5 ] loss: 0.4142860174179077 2022-08-12 00:12:39.105365
Epoch:[ 28 6 ] loss: 0.4134685695171356 2022-08-12 00:12:39.533573
Epoch:[ 28 7 ] loss: 0.4129369854927063 2022-08-12 00:12:39.953723
Epoch:[ 28 8 ] loss: 0.4154036343097687 2022-08-12 00:12:40.377673
Epoch:[ 28 9 ] loss: 0.41421031951904297 2022-08-12 00:12:40.800644
Epoch:[ 28 10 ] loss: 0.41586071252822876 2022-08-12 00:12:41.226796
Epoch:[ 28 11 ] loss: 0.4170047640800476 2022-08-12 00:12:41.658633
Epoch:[ 28 12 ] loss: 0.41626182198524475 2022-08-12 00:12:42.086743
Epoch:[ 28 13 ] loss: 0.41544681787490845 2022-08-12 00:12:42.506567
Epoch:[ 28 14 ] loss: 0.4175046384334564 2022-08-12 00:12:42.923906
Epoch:[ 28 15 ] loss: 0.4129442274570465 2022-08-12 00:12:43.342702
Epoch:[ 28 16 ] loss: 0.4150751233100891 2022-08-12 00:12:48.495968
Epoch:[ 28 17 ] loss: 0.4161251485347748 2022-08-12 00:12:48.911508
Epoch:[ 28 18 ] loss: 0.4155848026275635 2022-08-12 00:12:49.338775
Epoch:[ 28 19 ] loss: 0.41475510597229004 2022-08-12 00:12:49.762141
Training_Epoch:[ 28 ] Training_loss: 0.4149280354380608 2022-08-12 00:12:49.762812
learning rate:  0.0028899999999999998
val: 1 0.41641879081726074
val: 2 0.41424402594566345
val: 3 0.4152546226978302
val: 4 0.4209997057914734
val: 5 0.4169856309890747
val: 6 0.42006155848503113
val: 7 0.41778913140296936
val: 8 0.4200628101825714
val: 9 0.41297662258148193
val: 10 0.41019925475120544
val: 11 0.41770294308662415
val: 12 0.4170869290828705
val: 13 0.4206438660621643
val: 14 0.4193262755870819
val: 15 0.4171295166015625
val: 16 0.4157565236091614
val: 17 0.41822072863578796
val: 18 0.4168161451816559
val: 19 0.41903501749038696
val: 20 0.41085049510002136
val_Epoch:[ 28 ] val_loss: 0.41687802970409393 2022-08-12 00:12:53.340616
start training 2022-08-12 00:12:53.442076
Epoch:[ 29 0 ] loss: 0.4108619689941406 2022-08-12 00:13:07.741332
Epoch:[ 29 1 ] loss: 0.41578027606010437 2022-08-12 00:13:08.469012
Epoch:[ 29 2 ] loss: 0.41429203748703003 2022-08-12 00:13:08.892137
Epoch:[ 29 3 ] loss: 0.4111059606075287 2022-08-12 00:13:09.315121
Epoch:[ 29 4 ] loss: 0.41621482372283936 2022-08-12 00:13:09.735753
Epoch:[ 29 5 ] loss: 0.41235852241516113 2022-08-12 00:13:10.161677
Epoch:[ 29 6 ] loss: 0.4152437746524811 2022-08-12 00:13:10.589567
Epoch:[ 29 7 ] loss: 0.4209882616996765 2022-08-12 00:13:11.010726
Epoch:[ 29 8 ] loss: 0.4134596884250641 2022-08-12 00:13:11.429958
Epoch:[ 29 9 ] loss: 0.4156785011291504 2022-08-12 00:13:11.847186
Epoch:[ 29 10 ] loss: 0.41568201780319214 2022-08-12 00:13:12.272480
Epoch:[ 29 11 ] loss: 0.4149080514907837 2022-08-12 00:13:12.695183
Epoch:[ 29 12 ] loss: 0.41704756021499634 2022-08-12 00:13:13.113886
Epoch:[ 29 13 ] loss: 0.4166858196258545 2022-08-12 00:13:13.538094
Epoch:[ 29 14 ] loss: 0.41343703866004944 2022-08-12 00:13:13.964852
Epoch:[ 29 15 ] loss: 0.4180808961391449 2022-08-12 00:13:14.391851
Epoch:[ 29 16 ] loss: 0.41443318128585815 2022-08-12 00:13:19.757370
Epoch:[ 29 17 ] loss: 0.41485831141471863 2022-08-12 00:13:20.177185
Epoch:[ 29 18 ] loss: 0.41613245010375977 2022-08-12 00:13:20.602958
Epoch:[ 29 19 ] loss: 0.4140036404132843 2022-08-12 00:13:21.027481
Training_Epoch:[ 29 ] Training_loss: 0.4150626391172409 2022-08-12 00:13:21.028139
learning rate:  0.0028899999999999998
val: 1 0.4120890498161316
val: 2 0.4151766896247864
val: 3 0.41657450795173645
val: 4 0.417956680059433
val: 5 0.41802290081977844
val: 6 0.41516396403312683
val: 7 0.42025700211524963
val: 8 0.4221689999103546
val: 9 0.4126982092857361
val: 10 0.42497536540031433
val: 11 0.4202250838279724
val: 12 0.4160076379776001
val: 13 0.41691237688064575
val: 14 0.4203294515609741
val: 15 0.41456374526023865
val: 16 0.42006799578666687
val: 17 0.42843130230903625
val: 18 0.4120209515094757
val: 19 0.414640337228775
val: 20 0.41884148120880127
val_Epoch:[ 29 ] val_loss: 0.4178561866283417 2022-08-12 00:13:24.607377
start training 2022-08-12 00:13:24.710529
Epoch:[ 30 0 ] loss: 0.41203540563583374 2022-08-12 00:13:39.067515
Epoch:[ 30 1 ] loss: 0.4105680584907532 2022-08-12 00:13:39.506545
Epoch:[ 30 2 ] loss: 0.4116553068161011 2022-08-12 00:13:39.933090
Epoch:[ 30 3 ] loss: 0.4127352833747864 2022-08-12 00:13:40.355582
Epoch:[ 30 4 ] loss: 0.41100597381591797 2022-08-12 00:13:40.777224
Epoch:[ 30 5 ] loss: 0.41198140382766724 2022-08-12 00:13:41.201255
Epoch:[ 30 6 ] loss: 0.40889790654182434 2022-08-12 00:13:41.623445
Epoch:[ 30 7 ] loss: 0.4119531214237213 2022-08-12 00:13:42.048467
Epoch:[ 30 8 ] loss: 0.4141576886177063 2022-08-12 00:13:42.480783
Epoch:[ 30 9 ] loss: 0.4133669137954712 2022-08-12 00:13:42.907275
Epoch:[ 30 10 ] loss: 0.41726115345954895 2022-08-12 00:13:43.337095
Epoch:[ 30 11 ] loss: 0.4159495234489441 2022-08-12 00:13:43.763108
Epoch:[ 30 12 ] loss: 0.4236254096031189 2022-08-12 00:13:44.183545
Epoch:[ 30 13 ] loss: 0.41812023520469666 2022-08-12 00:13:44.609770
Epoch:[ 30 14 ] loss: 0.41804468631744385 2022-08-12 00:13:45.034864
Epoch:[ 30 15 ] loss: 0.4197801351547241 2022-08-12 00:13:45.458539
Epoch:[ 30 16 ] loss: 0.4157344400882721 2022-08-12 00:13:50.768877
Epoch:[ 30 17 ] loss: 0.4175970256328583 2022-08-12 00:13:51.191696
Epoch:[ 30 18 ] loss: 0.4156099855899811 2022-08-12 00:13:51.624442
Epoch:[ 30 19 ] loss: 0.41567108035087585 2022-08-12 00:13:52.048087
Training_Epoch:[ 30 ] Training_loss: 0.4147875368595123 2022-08-12 00:13:52.048800
learning rate:  0.0028899999999999998
netparams have been saved once 30
val: 1 0.4296393096446991
val: 2 0.4267030954360962
val: 3 0.42410168051719666
val: 4 0.4233234226703644
val: 5 0.42658472061157227
val: 6 0.42393577098846436
val: 7 0.4292537271976471
val: 8 0.41940435767173767
val: 9 0.4252605736255646
val: 10 0.4224552810192108
val: 11 0.42435964941978455
val: 12 0.42481499910354614
val: 13 0.4215221405029297
val: 14 0.4211212694644928
val: 15 0.42661190032958984
val: 16 0.4245153069496155
val: 17 0.4216814339160919
val: 18 0.4240979552268982
val: 19 0.4215051829814911
val: 20 0.4232601523399353
val_Epoch:[ 30 ] val_loss: 0.4242075964808464 2022-08-12 00:13:55.682327
start training 2022-08-12 00:13:55.786974
Epoch:[ 31 0 ] loss: 0.41649365425109863 2022-08-12 00:14:10.133592
Epoch:[ 31 1 ] loss: 0.4124397933483124 2022-08-12 00:14:10.575098
Epoch:[ 31 2 ] loss: 0.4142746031284332 2022-08-12 00:14:11.004488
Epoch:[ 31 3 ] loss: 0.41281354427337646 2022-08-12 00:14:11.426869
Epoch:[ 31 4 ] loss: 0.4131760597229004 2022-08-12 00:14:11.845496
Epoch:[ 31 5 ] loss: 0.415034681558609 2022-08-12 00:14:12.266902
Epoch:[ 31 6 ] loss: 0.41193053126335144 2022-08-12 00:14:12.677022
Epoch:[ 31 7 ] loss: 0.4101932942867279 2022-08-12 00:14:13.102504
Epoch:[ 31 8 ] loss: 0.40908169746398926 2022-08-12 00:14:13.533199
Epoch:[ 31 9 ] loss: 0.40999212861061096 2022-08-12 00:14:13.953627
Epoch:[ 31 10 ] loss: 0.4125581979751587 2022-08-12 00:14:14.365310
Epoch:[ 31 11 ] loss: 0.4088720381259918 2022-08-12 00:14:14.788609
Epoch:[ 31 12 ] loss: 0.40894126892089844 2022-08-12 00:14:15.215478
Epoch:[ 31 13 ] loss: 0.40844106674194336 2022-08-12 00:14:15.638503
Epoch:[ 31 14 ] loss: 0.4080781936645508 2022-08-12 00:14:16.059888
Epoch:[ 31 15 ] loss: 0.41022270917892456 2022-08-12 00:14:16.483255
Epoch:[ 31 16 ] loss: 0.4088992476463318 2022-08-12 00:14:21.804492
Epoch:[ 31 17 ] loss: 0.4088844060897827 2022-08-12 00:14:22.221772
Epoch:[ 31 18 ] loss: 0.40747004747390747 2022-08-12 00:14:22.644861
Epoch:[ 31 19 ] loss: 0.4076676368713379 2022-08-12 00:14:23.066217
Training_Epoch:[ 31 ] Training_loss: 0.41077324002981186 2022-08-12 00:14:23.066888
learning rate:  0.0024565
val: 1 0.41224828362464905
val: 2 0.4201524257659912
val: 3 0.4128095805644989
val: 4 0.41198599338531494
val: 5 0.41979503631591797
val: 6 0.4169718623161316
val: 7 0.410663902759552
val: 8 0.41595739126205444
val: 9 0.41086673736572266
val: 10 0.4070000946521759
val: 11 0.41484689712524414
val: 12 0.4158353805541992
val: 13 0.4179801344871521
val: 14 0.40383949875831604
val: 15 0.40874332189559937
val: 16 0.4076331555843353
val: 17 0.40720584988594055
val: 18 0.4118027091026306
val: 19 0.4158053994178772
val: 20 0.4124448895454407
val_Epoch:[ 31 ] val_loss: 0.4127294272184372 2022-08-12 00:14:26.628519
start training 2022-08-12 00:14:26.732153
Epoch:[ 32 0 ] loss: 0.4053189754486084 2022-08-12 00:14:41.508404
Epoch:[ 32 1 ] loss: 0.40485021471977234 2022-08-12 00:14:42.019682
Epoch:[ 32 2 ] loss: 0.4088881313800812 2022-08-12 00:14:42.442798
Epoch:[ 32 3 ] loss: 0.40676605701446533 2022-08-12 00:14:42.859290
Epoch:[ 32 4 ] loss: 0.4104578197002411 2022-08-12 00:14:43.287098
Epoch:[ 32 5 ] loss: 0.4076874554157257 2022-08-12 00:14:43.710864
Epoch:[ 32 6 ] loss: 0.40670332312583923 2022-08-12 00:14:44.138188
Epoch:[ 32 7 ] loss: 0.408381849527359 2022-08-12 00:14:44.559830
Epoch:[ 32 8 ] loss: 0.4083899259567261 2022-08-12 00:14:44.987723
Epoch:[ 32 9 ] loss: 0.4083278477191925 2022-08-12 00:14:45.411666
Epoch:[ 32 10 ] loss: 0.4054509401321411 2022-08-12 00:14:45.836651
Epoch:[ 32 11 ] loss: 0.40824076533317566 2022-08-12 00:14:46.259580
Epoch:[ 32 12 ] loss: 0.4084603786468506 2022-08-12 00:14:46.683564
Epoch:[ 32 13 ] loss: 0.4066780209541321 2022-08-12 00:14:47.101337
Epoch:[ 32 14 ] loss: 0.41030004620552063 2022-08-12 00:14:47.516894
Epoch:[ 32 15 ] loss: 0.4067936837673187 2022-08-12 00:14:47.940152
Epoch:[ 32 16 ] loss: 0.405849814414978 2022-08-12 00:14:53.323379
Epoch:[ 32 17 ] loss: 0.4051060378551483 2022-08-12 00:14:54.323801
Epoch:[ 32 18 ] loss: 0.4051470458507538 2022-08-12 00:14:54.754095
Epoch:[ 32 19 ] loss: 0.405685156583786 2022-08-12 00:14:55.176462
Training_Epoch:[ 32 ] Training_loss: 0.4071741744875908 2022-08-12 00:14:55.177181
learning rate:  0.0024565
val: 1 0.41299566626548767
val: 2 0.4090758264064789
val: 3 0.40722426772117615
val: 4 0.411617636680603
val: 5 0.4060853123664856
val: 6 0.4122661054134369
val: 7 0.40880537033081055
val: 8 0.4086430072784424
val: 9 0.40605756640434265
val: 10 0.4054480791091919
val: 11 0.40708523988723755
val: 12 0.4074363708496094
val: 13 0.4050133526325226
val: 14 0.40438276529312134
val: 15 0.4060955047607422
val: 16 0.41360118985176086
val: 17 0.40493243932724
val: 18 0.41812315583229065
val: 19 0.41118401288986206
val: 20 0.4124729037284851
val_Epoch:[ 32 ] val_loss: 0.4089272886514664 2022-08-12 00:14:58.804080
start training 2022-08-12 00:14:58.908722
Epoch:[ 33 0 ] loss: 0.40173202753067017 2022-08-12 00:15:13.483593
Epoch:[ 33 1 ] loss: 0.40557846426963806 2022-08-12 00:15:13.903806
Epoch:[ 33 2 ] loss: 0.4049126207828522 2022-08-12 00:15:14.333647
Epoch:[ 33 3 ] loss: 0.4041244685649872 2022-08-12 00:15:14.759874
Epoch:[ 33 4 ] loss: 0.40625235438346863 2022-08-12 00:15:15.176817
Epoch:[ 33 5 ] loss: 0.40234237909317017 2022-08-12 00:15:15.599228
Epoch:[ 33 6 ] loss: 0.40504342317581177 2022-08-12 00:15:16.022410
Epoch:[ 33 7 ] loss: 0.40445634722709656 2022-08-12 00:15:16.447879
Epoch:[ 33 8 ] loss: 0.40417519211769104 2022-08-12 00:15:16.866925
Epoch:[ 33 9 ] loss: 0.403671532869339 2022-08-12 00:15:17.290009
Epoch:[ 33 10 ] loss: 0.40338701009750366 2022-08-12 00:15:17.712144
Epoch:[ 33 11 ] loss: 0.404881089925766 2022-08-12 00:15:18.136206
Epoch:[ 33 12 ] loss: 0.40377840399742126 2022-08-12 00:15:18.561488
Epoch:[ 33 13 ] loss: 0.40596601366996765 2022-08-12 00:15:18.988458
Epoch:[ 33 14 ] loss: 0.4041922092437744 2022-08-12 00:15:19.421761
Epoch:[ 33 15 ] loss: 0.4051530957221985 2022-08-12 00:15:19.834491
Epoch:[ 33 16 ] loss: 0.40785205364227295 2022-08-12 00:15:25.374810
Epoch:[ 33 17 ] loss: 0.41301429271698 2022-08-12 00:15:25.794492
Epoch:[ 33 18 ] loss: 0.40483444929122925 2022-08-12 00:15:26.221734
Epoch:[ 33 19 ] loss: 0.40912628173828125 2022-08-12 00:15:26.637275
Training_Epoch:[ 33 ] Training_loss: 0.40522368550300597 2022-08-12 00:15:26.637934
learning rate:  0.0024565
val: 1 0.4100906252861023
val: 2 0.41298922896385193
val: 3 0.4100591838359833
val: 4 0.4084912836551666
val: 5 0.405391663312912
val: 6 0.4140511453151703
val: 7 0.4152836203575134
val: 8 0.4070511758327484
val: 9 0.4083098769187927
val: 10 0.4159482717514038
val: 11 0.40713244676589966
val: 12 0.41496023535728455
val: 13 0.4059944450855255
val: 14 0.40669122338294983
val: 15 0.4095025062561035
val: 16 0.41242143511772156
val: 17 0.41622453927993774
val: 18 0.41127368807792664
val: 19 0.41211017966270447
val: 20 0.409936785697937
val_Epoch:[ 33 ] val_loss: 0.41069567799568174 2022-08-12 00:15:30.195240
start training 2022-08-12 00:15:30.296913
Epoch:[ 34 0 ] loss: 0.40494203567504883 2022-08-12 00:15:44.536043
Epoch:[ 34 1 ] loss: 0.40543681383132935 2022-08-12 00:15:44.975270
Epoch:[ 34 2 ] loss: 0.40561673045158386 2022-08-12 00:15:45.396723
Epoch:[ 34 3 ] loss: 0.40362632274627686 2022-08-12 00:15:45.822595
Epoch:[ 34 4 ] loss: 0.4065871834754944 2022-08-12 00:15:46.249108
Epoch:[ 34 5 ] loss: 0.405074805021286 2022-08-12 00:15:46.674120
Epoch:[ 34 6 ] loss: 0.40735432505607605 2022-08-12 00:15:47.099024
Epoch:[ 34 7 ] loss: 0.4090104401111603 2022-08-12 00:15:47.523725
Epoch:[ 34 8 ] loss: 0.4077131748199463 2022-08-12 00:15:47.943194
Epoch:[ 34 9 ] loss: 0.40635380148887634 2022-08-12 00:15:48.360584
Epoch:[ 34 10 ] loss: 0.40832823514938354 2022-08-12 00:15:48.781527
Epoch:[ 34 11 ] loss: 0.4077695906162262 2022-08-12 00:15:49.211197
Epoch:[ 34 12 ] loss: 0.4059288799762726 2022-08-12 00:15:49.631138
Epoch:[ 34 13 ] loss: 0.4085202217102051 2022-08-12 00:15:50.053333
Epoch:[ 34 14 ] loss: 0.40539780259132385 2022-08-12 00:15:50.475069
Epoch:[ 34 15 ] loss: 0.40541622042655945 2022-08-12 00:15:50.901202
Epoch:[ 34 16 ] loss: 0.40511763095855713 2022-08-12 00:15:56.636342
Epoch:[ 34 17 ] loss: 0.4067862331867218 2022-08-12 00:15:57.061936
Epoch:[ 34 18 ] loss: 0.407111257314682 2022-08-12 00:15:57.488421
Epoch:[ 34 19 ] loss: 0.4053765833377838 2022-08-12 00:15:57.915512
Training_Epoch:[ 34 ] Training_loss: 0.4063734143972397 2022-08-12 00:15:57.916224
learning rate:  0.0024565
val: 1 0.424327552318573
val: 2 0.4167276620864868
val: 3 0.4229421317577362
val: 4 0.41708049178123474
val: 5 0.4130040109157562
val: 6 0.41688698530197144
val: 7 0.42523813247680664
val: 8 0.4209001660346985
val: 9 0.420225590467453
val: 10 0.4208216667175293
val: 11 0.4204839766025543
val: 12 0.41770315170288086
val: 13 0.4253484606742859
val: 14 0.42301636934280396
val: 15 0.42690375447273254
val: 16 0.42572423815727234
val: 17 0.41631168127059937
val: 18 0.42416509985923767
val: 19 0.421695351600647
val: 20 0.41791948676109314
val_Epoch:[ 34 ] val_loss: 0.42087129801511763 2022-08-12 00:16:01.466982
start training 2022-08-12 00:16:01.571270
Epoch:[ 35 0 ] loss: 0.40877312421798706 2022-08-12 00:16:15.241963
Epoch:[ 35 1 ] loss: 0.4076305329799652 2022-08-12 00:16:16.097243
Epoch:[ 35 2 ] loss: 0.41218316555023193 2022-08-12 00:16:16.519250
Epoch:[ 35 3 ] loss: 0.4080067574977875 2022-08-12 00:16:16.943134
Epoch:[ 35 4 ] loss: 0.40772178769111633 2022-08-12 00:16:17.368961
Epoch:[ 35 5 ] loss: 0.40709441900253296 2022-08-12 00:16:17.791836
Epoch:[ 35 6 ] loss: 0.4096156358718872 2022-08-12 00:16:18.217760
Epoch:[ 35 7 ] loss: 0.40834876894950867 2022-08-12 00:16:18.639156
Epoch:[ 35 8 ] loss: 0.4075184166431427 2022-08-12 00:16:19.064275
Epoch:[ 35 9 ] loss: 0.40821096301078796 2022-08-12 00:16:19.488879
Epoch:[ 35 10 ] loss: 0.405985951423645 2022-08-12 00:16:19.911072
Epoch:[ 35 11 ] loss: 0.4075833559036255 2022-08-12 00:16:20.337662
Epoch:[ 35 12 ] loss: 0.40290120244026184 2022-08-12 00:16:20.752676
Epoch:[ 35 13 ] loss: 0.40561750531196594 2022-08-12 00:16:21.172511
Epoch:[ 35 14 ] loss: 0.40703192353248596 2022-08-12 00:16:21.606576
Epoch:[ 35 15 ] loss: 0.40380963683128357 2022-08-12 00:16:22.028806
Epoch:[ 35 16 ] loss: 0.4046953022480011 2022-08-12 00:16:27.720418
Epoch:[ 35 17 ] loss: 0.4020121991634369 2022-08-12 00:16:28.142646
Epoch:[ 35 18 ] loss: 0.40381139516830444 2022-08-12 00:16:28.576380
Epoch:[ 35 19 ] loss: 0.4032621383666992 2022-08-12 00:16:29.002711
Training_Epoch:[ 35 ] Training_loss: 0.40659070909023287 2022-08-12 00:16:29.003463
learning rate:  0.0024565
val: 1 0.4170721173286438
val: 2 0.41238027811050415
val: 3 0.408412903547287
val: 4 0.4114077389240265
val: 5 0.4089762270450592
val: 6 0.4072578549385071
val: 7 0.4096750020980835
val: 8 0.41573721170425415
val: 9 0.4099520742893219
val: 10 0.41188105940818787
val: 11 0.4103398025035858
val: 12 0.4085341691970825
val: 13 0.41135382652282715
val: 14 0.41029536724090576
val: 15 0.40903812646865845
val: 16 0.41067469120025635
val: 17 0.4137941300868988
val: 18 0.4088209569454193
val: 19 0.4133904278278351
val: 20 0.41000404953956604
val_Epoch:[ 35 ] val_loss: 0.4109499007463455 2022-08-12 00:16:32.554855
start training 2022-08-12 00:16:32.664496
Epoch:[ 36 0 ] loss: 0.40047213435173035 2022-08-12 00:16:46.699745
Epoch:[ 36 1 ] loss: 0.39985066652297974 2022-08-12 00:16:47.489209
Epoch:[ 36 2 ] loss: 0.40502652525901794 2022-08-12 00:16:47.915983
Epoch:[ 36 3 ] loss: 0.40171122550964355 2022-08-12 00:16:48.341363
Epoch:[ 36 4 ] loss: 0.4008380174636841 2022-08-12 00:16:48.767138
Epoch:[ 36 5 ] loss: 0.4024306833744049 2022-08-12 00:16:49.183571
Epoch:[ 36 6 ] loss: 0.4022389054298401 2022-08-12 00:16:49.604975
Epoch:[ 36 7 ] loss: 0.4038683772087097 2022-08-12 00:16:50.031082
Epoch:[ 36 8 ] loss: 0.4016471803188324 2022-08-12 00:16:50.454828
Epoch:[ 36 9 ] loss: 0.4041231870651245 2022-08-12 00:16:50.870220
Epoch:[ 36 10 ] loss: 0.4073568284511566 2022-08-12 00:16:51.292158
Epoch:[ 36 11 ] loss: 0.40525877475738525 2022-08-12 00:16:51.717683
Epoch:[ 36 12 ] loss: 0.4051024913787842 2022-08-12 00:16:52.143544
Epoch:[ 36 13 ] loss: 0.408113956451416 2022-08-12 00:16:52.561846
Epoch:[ 36 14 ] loss: 0.40561339259147644 2022-08-12 00:16:52.987796
Epoch:[ 36 15 ] loss: 0.4030259847640991 2022-08-12 00:16:53.409541
Epoch:[ 36 16 ] loss: 0.40274977684020996 2022-08-12 00:16:59.007339
Epoch:[ 36 17 ] loss: 0.40579953789711 2022-08-12 00:16:59.681452
Epoch:[ 36 18 ] loss: 0.4041794240474701 2022-08-12 00:17:00.103629
Epoch:[ 36 19 ] loss: 0.40451711416244507 2022-08-12 00:17:00.529621
Training_Epoch:[ 36 ] Training_loss: 0.403696209192276 2022-08-12 00:17:00.530328
learning rate:  0.0024565
val: 1 0.4112336039543152
val: 2 0.4058786928653717
val: 3 0.40796253085136414
val: 4 0.4069528579711914
val: 5 0.41646474599838257
val: 6 0.41295623779296875
val: 7 0.4061700105667114
val: 8 0.4082215130329132
val: 9 0.41206860542297363
val: 10 0.4110630452632904
val: 11 0.4076947271823883
val: 12 0.4012123942375183
val: 13 0.4194812476634979
val: 14 0.4075049161911011
val: 15 0.39845365285873413
val: 16 0.40409255027770996
val: 17 0.4018639624118805
val: 18 0.40507620573043823
val: 19 0.3997602164745331
val: 20 0.41001707315444946
val_Epoch:[ 36 ] val_loss: 0.40770643949508667 2022-08-12 00:17:04.085625
start training 2022-08-12 00:17:04.189794
Epoch:[ 37 0 ] loss: 0.40264230966567993 2022-08-12 00:17:18.832751
Epoch:[ 37 1 ] loss: 0.40226075053215027 2022-08-12 00:17:19.252524
Epoch:[ 37 2 ] loss: 0.4016188681125641 2022-08-12 00:17:19.669363
Epoch:[ 37 3 ] loss: 0.39982888102531433 2022-08-12 00:17:20.094085
Epoch:[ 37 4 ] loss: 0.40067097544670105 2022-08-12 00:17:20.525868
Epoch:[ 37 5 ] loss: 0.40201103687286377 2022-08-12 00:17:20.953158
Epoch:[ 37 6 ] loss: 0.4000778794288635 2022-08-12 00:17:21.375870
Epoch:[ 37 7 ] loss: 0.3987715542316437 2022-08-12 00:17:21.799913
Epoch:[ 37 8 ] loss: 0.3999345600605011 2022-08-12 00:17:22.217635
Epoch:[ 37 9 ] loss: 0.3993403911590576 2022-08-12 00:17:22.642832
Epoch:[ 37 10 ] loss: 0.4000656306743622 2022-08-12 00:17:23.065865
Epoch:[ 37 11 ] loss: 0.4006563723087311 2022-08-12 00:17:23.491499
Epoch:[ 37 12 ] loss: 0.4001643657684326 2022-08-12 00:17:23.907531
Epoch:[ 37 13 ] loss: 0.40048012137413025 2022-08-12 00:17:24.324712
Epoch:[ 37 14 ] loss: 0.40272095799446106 2022-08-12 00:17:24.748236
Epoch:[ 37 15 ] loss: 0.40609315037727356 2022-08-12 00:17:25.174353
Epoch:[ 37 16 ] loss: 0.40245112776756287 2022-08-12 00:17:30.555134
Epoch:[ 37 17 ] loss: 0.4030950367450714 2022-08-12 00:17:30.969568
Epoch:[ 37 18 ] loss: 0.40729647874832153 2022-08-12 00:17:31.400110
Epoch:[ 37 19 ] loss: 0.4042130410671234 2022-08-12 00:17:31.823979
Training_Epoch:[ 37 ] Training_loss: 0.40171967446804047 2022-08-12 00:17:31.824699
learning rate:  0.0024565
val: 1 0.43364566564559937
val: 2 0.4182814955711365
val: 3 0.4220292568206787
val: 4 0.4213731288909912
val: 5 0.4250107705593109
val: 6 0.4214014410972595
val: 7 0.43263131380081177
val: 8 0.4244355857372284
val: 9 0.43295761942863464
val: 10 0.4250392019748688
val: 11 0.4211735427379608
val: 12 0.4198435842990875
val: 13 0.42344221472740173
val: 14 0.4218648374080658
val: 15 0.42576882243156433
val: 16 0.4251982271671295
val: 17 0.4320487678050995
val: 18 0.42302072048187256
val: 19 0.423470675945282
val: 20 0.42091163992881775
val_Epoch:[ 37 ] val_loss: 0.4246774256229401 2022-08-12 00:17:35.383630
start training 2022-08-12 00:17:35.489895
Epoch:[ 38 0 ] loss: 0.4069450795650482 2022-08-12 00:17:50.157061
Epoch:[ 38 1 ] loss: 0.4073813557624817 2022-08-12 00:17:50.575186
Epoch:[ 38 2 ] loss: 0.401901513338089 2022-08-12 00:17:51.000272
Epoch:[ 38 3 ] loss: 0.40631288290023804 2022-08-12 00:17:51.423664
Epoch:[ 38 4 ] loss: 0.40522047877311707 2022-08-12 00:17:51.840824
Epoch:[ 38 5 ] loss: 0.4071198105812073 2022-08-12 00:17:52.262957
Epoch:[ 38 6 ] loss: 0.4041859805583954 2022-08-12 00:17:52.688981
Epoch:[ 38 7 ] loss: 0.40464603900909424 2022-08-12 00:17:53.115700
Epoch:[ 38 8 ] loss: 0.40315356850624084 2022-08-12 00:17:53.535017
Epoch:[ 38 9 ] loss: 0.4033377766609192 2022-08-12 00:17:53.958688
Epoch:[ 38 10 ] loss: 0.4019773006439209 2022-08-12 00:17:54.379890
Epoch:[ 38 11 ] loss: 0.40100160241127014 2022-08-12 00:17:54.805978
Epoch:[ 38 12 ] loss: 0.4012882709503174 2022-08-12 00:17:55.229200
Epoch:[ 38 13 ] loss: 0.39897000789642334 2022-08-12 00:17:55.657436
Epoch:[ 38 14 ] loss: 0.4002462923526764 2022-08-12 00:17:56.082912
Epoch:[ 38 15 ] loss: 0.4006325602531433 2022-08-12 00:17:56.506222
Epoch:[ 38 16 ] loss: 0.4012545645236969 2022-08-12 00:18:02.126072
Epoch:[ 38 17 ] loss: 0.4014745354652405 2022-08-12 00:18:02.550424
Epoch:[ 38 18 ] loss: 0.4012362062931061 2022-08-12 00:18:02.968343
Epoch:[ 38 19 ] loss: 0.3991316258907318 2022-08-12 00:18:03.381516
Training_Epoch:[ 38 ] Training_loss: 0.4028708726167679 2022-08-12 00:18:03.382154
learning rate:  0.0024565
val: 1 0.4058617651462555
val: 2 0.4089873731136322
val: 3 0.40740177035331726
val: 4 0.4120527505874634
val: 5 0.40782666206359863
val: 6 0.41020482778549194
val: 7 0.41271039843559265
val: 8 0.409982293844223
val: 9 0.4088503122329712
val: 10 0.4089091420173645
val: 11 0.4109077751636505
val: 12 0.40101101994514465
val: 13 0.3984896242618561
val: 14 0.41053250432014465
val: 15 0.40380921959877014
val: 16 0.41162553429603577
val: 17 0.40640807151794434
val: 18 0.4044576585292816
val: 19 0.4139512777328491
val: 20 0.4073874354362488
val_Epoch:[ 38 ] val_loss: 0.4080683708190918 2022-08-12 00:18:07.023048
start training 2022-08-12 00:18:07.129389
Epoch:[ 39 0 ] loss: 0.40297001600265503 2022-08-12 00:18:21.439186
Epoch:[ 39 1 ] loss: 0.40010130405426025 2022-08-12 00:18:21.862844
Epoch:[ 39 2 ] loss: 0.39748144149780273 2022-08-12 00:18:22.283986
Epoch:[ 39 3 ] loss: 0.4007033109664917 2022-08-12 00:18:22.708802
Epoch:[ 39 4 ] loss: 0.4068899154663086 2022-08-12 00:18:23.130670
Epoch:[ 39 5 ] loss: 0.40466368198394775 2022-08-12 00:18:23.551799
Epoch:[ 39 6 ] loss: 0.39896970987319946 2022-08-12 00:18:23.977078
Epoch:[ 39 7 ] loss: 0.4021579623222351 2022-08-12 00:18:24.401904
Epoch:[ 39 8 ] loss: 0.4007192850112915 2022-08-12 00:18:24.823950
Epoch:[ 39 9 ] loss: 0.40170589089393616 2022-08-12 00:18:25.238284
Epoch:[ 39 10 ] loss: 0.40346482396125793 2022-08-12 00:18:25.664318
Epoch:[ 39 11 ] loss: 0.4032202661037445 2022-08-12 00:18:26.094952
Epoch:[ 39 12 ] loss: 0.4021400213241577 2022-08-12 00:18:26.516934
Epoch:[ 39 13 ] loss: 0.4009515047073364 2022-08-12 00:18:26.938052
Epoch:[ 39 14 ] loss: 0.40167394280433655 2022-08-12 00:18:27.358846
Epoch:[ 39 15 ] loss: 0.40036317706108093 2022-08-12 00:18:27.785505
Epoch:[ 39 16 ] loss: 0.39993810653686523 2022-08-12 00:18:33.495863
Epoch:[ 39 17 ] loss: 0.39961862564086914 2022-08-12 00:18:33.917371
Epoch:[ 39 18 ] loss: 0.3999152183532715 2022-08-12 00:18:34.343920
Epoch:[ 39 19 ] loss: 0.3988398313522339 2022-08-12 00:18:34.768714
Training_Epoch:[ 39 ] Training_loss: 0.4013244017958641 2022-08-12 00:18:34.769376
learning rate:  0.0024565
val: 1 0.41096267104148865
val: 2 0.4029843807220459
val: 3 0.4027629792690277
val: 4 0.4123162031173706
val: 5 0.399916410446167
val: 6 0.40830180048942566
val: 7 0.402710884809494
val: 8 0.40518882870674133
val: 9 0.40610814094543457
val: 10 0.3975681662559509
val: 11 0.4110257625579834
val: 12 0.4133773744106293
val: 13 0.4146276116371155
val: 14 0.4083499312400818
val: 15 0.40498074889183044
val: 16 0.4186389744281769
val: 17 0.3993220925331116
val: 18 0.403276264667511
val: 19 0.4026147127151489
val: 20 0.4040027856826782
val_Epoch:[ 39 ] val_loss: 0.40645183622837067 2022-08-12 00:18:38.380981
start training 2022-08-12 00:18:38.488507
Epoch:[ 40 0 ] loss: 0.4000694155693054 2022-08-12 00:18:53.466200
Epoch:[ 40 1 ] loss: 0.3974354863166809 2022-08-12 00:18:53.889571
Epoch:[ 40 2 ] loss: 0.3975462019443512 2022-08-12 00:18:54.315178
Epoch:[ 40 3 ] loss: 0.39976391196250916 2022-08-12 00:18:54.736337
Epoch:[ 40 4 ] loss: 0.39770108461380005 2022-08-12 00:18:55.162079
Epoch:[ 40 5 ] loss: 0.3972810208797455 2022-08-12 00:18:55.585819
Epoch:[ 40 6 ] loss: 0.3998399078845978 2022-08-12 00:18:56.010034
Epoch:[ 40 7 ] loss: 0.39718905091285706 2022-08-12 00:18:56.440195
Epoch:[ 40 8 ] loss: 0.39928826689720154 2022-08-12 00:18:56.864343
Epoch:[ 40 9 ] loss: 0.39597606658935547 2022-08-12 00:18:57.285470
Epoch:[ 40 10 ] loss: 0.39928320050239563 2022-08-12 00:18:57.700848
Epoch:[ 40 11 ] loss: 0.3985619843006134 2022-08-12 00:18:58.125399
Epoch:[ 40 12 ] loss: 0.39714938402175903 2022-08-12 00:18:58.555088
Epoch:[ 40 13 ] loss: 0.39790406823158264 2022-08-12 00:18:58.977753
Epoch:[ 40 14 ] loss: 0.3972231447696686 2022-08-12 00:18:59.400251
Epoch:[ 40 15 ] loss: 0.39986923336982727 2022-08-12 00:18:59.820912
Epoch:[ 40 16 ] loss: 0.3975754380226135 2022-08-12 00:19:05.305631
Epoch:[ 40 17 ] loss: 0.39845380187034607 2022-08-12 00:19:05.721588
Epoch:[ 40 18 ] loss: 0.39794501662254333 2022-08-12 00:19:06.144700
Epoch:[ 40 19 ] loss: 0.4014909267425537 2022-08-12 00:19:06.566617
Training_Epoch:[ 40 ] Training_loss: 0.3983773306012154 2022-08-12 00:19:06.567293
learning rate:  0.0024565
netparams have been saved once 40
val: 1 0.4081670939922333
val: 2 0.4147225618362427
val: 3 0.41414323449134827
val: 4 0.4174668490886688
val: 5 0.41636666655540466
val: 6 0.4076840281486511
val: 7 0.40787962079048157
val: 8 0.4149409532546997
val: 9 0.4117063283920288
val: 10 0.41505512595176697
val: 11 0.4060100018978119
val: 12 0.41040241718292236
val: 13 0.4102511405944824
val: 14 0.4066855013370514
val: 15 0.41333550214767456
val: 16 0.4140297472476959
val: 17 0.40794873237609863
val: 18 0.4126550555229187
val: 19 0.41223570704460144
val: 20 0.4107365310192108
val_Epoch:[ 40 ] val_loss: 0.4116211399435997 2022-08-12 00:19:10.186231
start training 2022-08-12 00:19:10.303813
Epoch:[ 41 0 ] loss: 0.39679351449012756 2022-08-12 00:19:24.428361
Epoch:[ 41 1 ] loss: 0.39766091108322144 2022-08-12 00:19:25.201434
Epoch:[ 41 2 ] loss: 0.3963928520679474 2022-08-12 00:19:25.624148
Epoch:[ 41 3 ] loss: 0.3969958424568176 2022-08-12 00:19:26.046734
Epoch:[ 41 4 ] loss: 0.39459797739982605 2022-08-12 00:19:26.460005
Epoch:[ 41 5 ] loss: 0.3991282880306244 2022-08-12 00:19:26.889576
Epoch:[ 41 6 ] loss: 0.39568662643432617 2022-08-12 00:19:27.314946
Epoch:[ 41 7 ] loss: 0.3962017595767975 2022-08-12 00:19:27.735292
Epoch:[ 41 8 ] loss: 0.3950650691986084 2022-08-12 00:19:28.151518
Epoch:[ 41 9 ] loss: 0.3965403735637665 2022-08-12 00:19:28.576524
Epoch:[ 41 10 ] loss: 0.39582470059394836 2022-08-12 00:19:29.003736
Epoch:[ 41 11 ] loss: 0.3972461223602295 2022-08-12 00:19:29.429473
Epoch:[ 41 12 ] loss: 0.39739903807640076 2022-08-12 00:19:29.852533
Epoch:[ 41 13 ] loss: 0.39451080560684204 2022-08-12 00:19:30.275018
Epoch:[ 41 14 ] loss: 0.3962475061416626 2022-08-12 00:19:30.696056
Epoch:[ 41 15 ] loss: 0.39895784854888916 2022-08-12 00:19:31.120701
Epoch:[ 41 16 ] loss: 0.39905139803886414 2022-08-12 00:19:36.546290
Epoch:[ 41 17 ] loss: 0.3957773745059967 2022-08-12 00:19:36.970476
Epoch:[ 41 18 ] loss: 0.3974328637123108 2022-08-12 00:19:37.403102
Epoch:[ 41 19 ] loss: 0.39655402302742004 2022-08-12 00:19:37.828929
Training_Epoch:[ 41 ] Training_loss: 0.3967032447457314 2022-08-12 00:19:37.829640
learning rate:  0.002088025
val: 1 0.3980875015258789
val: 2 0.403511106967926
val: 3 0.40044519305229187
val: 4 0.39558500051498413
val: 5 0.4018150269985199
val: 6 0.40352940559387207
val: 7 0.40517985820770264
val: 8 0.41112321615219116
val: 9 0.399112731218338
val: 10 0.4033110439777374
val: 11 0.3996875584125519
val: 12 0.4041418135166168
val: 13 0.4005366265773773
val: 14 0.39756399393081665
val: 15 0.40575119853019714
val: 16 0.3999768793582916
val: 17 0.3939961791038513
val: 18 0.4014219343662262
val: 19 0.40267202258110046
val: 20 0.40384867787361145
val_Epoch:[ 41 ] val_loss: 0.40156484842300416 2022-08-12 00:19:41.429359
start training 2022-08-12 00:19:41.534235
Epoch:[ 42 0 ] loss: 0.3936798572540283 2022-08-12 00:19:55.544262
Epoch:[ 42 1 ] loss: 0.3963131308555603 2022-08-12 00:19:56.264444
Epoch:[ 42 2 ] loss: 0.39469224214553833 2022-08-12 00:19:56.681507
Epoch:[ 42 3 ] loss: 0.3948441743850708 2022-08-12 00:19:57.109726
Epoch:[ 42 4 ] loss: 0.39565667510032654 2022-08-12 00:19:57.534978
Epoch:[ 42 5 ] loss: 0.3980104923248291 2022-08-12 00:19:57.962287
Epoch:[ 42 6 ] loss: 0.39561736583709717 2022-08-12 00:19:58.382070
Epoch:[ 42 7 ] loss: 0.39818713068962097 2022-08-12 00:19:58.798823
Epoch:[ 42 8 ] loss: 0.3980737328529358 2022-08-12 00:19:59.218230
Epoch:[ 42 9 ] loss: 0.39860302209854126 2022-08-12 00:19:59.643025
Epoch:[ 42 10 ] loss: 0.39588600397109985 2022-08-12 00:20:00.058809
Epoch:[ 42 11 ] loss: 0.3965102732181549 2022-08-12 00:20:00.478617
Epoch:[ 42 12 ] loss: 0.39647001028060913 2022-08-12 00:20:00.902841
Epoch:[ 42 13 ] loss: 0.39596831798553467 2022-08-12 00:20:01.327384
Epoch:[ 42 14 ] loss: 0.39485377073287964 2022-08-12 00:20:01.747437
Epoch:[ 42 15 ] loss: 0.3947986960411072 2022-08-12 00:20:02.168787
Epoch:[ 42 16 ] loss: 0.3978179097175598 2022-08-12 00:20:07.545304
Epoch:[ 42 17 ] loss: 0.3968828022480011 2022-08-12 00:20:07.958131
Epoch:[ 42 18 ] loss: 0.39800113439559937 2022-08-12 00:20:08.391035
Epoch:[ 42 19 ] loss: 0.398433655500412 2022-08-12 00:20:08.816295
Training_Epoch:[ 42 ] Training_loss: 0.39646501988172533 2022-08-12 00:20:08.817038
learning rate:  0.002088025
val: 1 0.41169580817222595
val: 2 0.41157767176628113
val: 3 0.4101119935512543
val: 4 0.40271705389022827
val: 5 0.4127064049243927
val: 6 0.41278669238090515
val: 7 0.4054795503616333
val: 8 0.4044326841831207
val: 9 0.39579907059669495
val: 10 0.4116557538509369
val: 11 0.4095814824104309
val: 12 0.4066968858242035
val: 13 0.41582658886909485
val: 14 0.4183040261268616
val: 15 0.40350833535194397
val: 16 0.4124843180179596
val: 17 0.40533003211021423
val: 18 0.40656405687332153
val: 19 0.41068992018699646
val: 20 0.407243013381958
val_Epoch:[ 42 ] val_loss: 0.4087595671415329 2022-08-12 00:20:12.389388
start training 2022-08-12 00:20:12.491146
Epoch:[ 43 0 ] loss: 0.3966115713119507 2022-08-12 00:20:27.564098
Epoch:[ 43 1 ] loss: 0.3953108787536621 2022-08-12 00:20:27.989457
Epoch:[ 43 2 ] loss: 0.3952437937259674 2022-08-12 00:20:28.412838
Epoch:[ 43 3 ] loss: 0.39783790707588196 2022-08-12 00:20:28.830414
Epoch:[ 43 4 ] loss: 0.39531469345092773 2022-08-12 00:20:29.252371
Epoch:[ 43 5 ] loss: 0.3945618271827698 2022-08-12 00:20:29.681136
Epoch:[ 43 6 ] loss: 0.3941304683685303 2022-08-12 00:20:30.108624
Epoch:[ 43 7 ] loss: 0.3972550630569458 2022-08-12 00:20:30.527597
Epoch:[ 43 8 ] loss: 0.39625999331474304 2022-08-12 00:20:30.949787
Epoch:[ 43 9 ] loss: 0.3947872817516327 2022-08-12 00:20:31.371980
Epoch:[ 43 10 ] loss: 0.3966622054576874 2022-08-12 00:20:31.803290
Epoch:[ 43 11 ] loss: 0.39663827419281006 2022-08-12 00:20:32.224193
Epoch:[ 43 12 ] loss: 0.3962252736091614 2022-08-12 00:20:32.650078
Epoch:[ 43 13 ] loss: 0.3946761190891266 2022-08-12 00:20:33.073950
Epoch:[ 43 14 ] loss: 0.39875268936157227 2022-08-12 00:20:33.495171
Epoch:[ 43 15 ] loss: 0.396930456161499 2022-08-12 00:20:33.908615
Epoch:[ 43 16 ] loss: 0.3964052200317383 2022-08-12 00:20:39.156694
Epoch:[ 43 17 ] loss: 0.3983912765979767 2022-08-12 00:20:39.577029
Epoch:[ 43 18 ] loss: 0.3978078365325928 2022-08-12 00:20:40.004843
Epoch:[ 43 19 ] loss: 0.39522841572761536 2022-08-12 00:20:40.418673
Training_Epoch:[ 43 ] Training_loss: 0.39625156223773955 2022-08-12 00:20:40.419414
learning rate:  0.002088025
val: 1 0.4036731719970703
val: 2 0.3998502790927887
val: 3 0.40814271569252014
val: 4 0.4120669662952423
val: 5 0.4024951756000519
val: 6 0.40672963857650757
val: 7 0.40768900513648987
val: 8 0.4043600857257843
val: 9 0.405780553817749
val: 10 0.4024743437767029
val: 11 0.4021030068397522
val: 12 0.40897977352142334
val: 13 0.41246291995048523
val: 14 0.4038958251476288
val: 15 0.40679070353507996
val: 16 0.4063166081905365
val: 17 0.40423837304115295
val: 18 0.40246838331222534
val: 19 0.4056982398033142
val: 20 0.40444180369377136
val_Epoch:[ 43 ] val_loss: 0.40553287863731385 2022-08-12 00:20:43.969359
start training 2022-08-12 00:20:44.069788
Epoch:[ 44 0 ] loss: 0.39586353302001953 2022-08-12 00:20:57.979327
Epoch:[ 44 1 ] loss: 0.3939671516418457 2022-08-12 00:20:58.556945
Epoch:[ 44 2 ] loss: 0.3948823809623718 2022-08-12 00:20:58.995087
Epoch:[ 44 3 ] loss: 0.3963063955307007 2022-08-12 00:20:59.417577
Epoch:[ 44 4 ] loss: 0.39212602376937866 2022-08-12 00:20:59.842394
Epoch:[ 44 5 ] loss: 0.3945199251174927 2022-08-12 00:21:00.266800
Epoch:[ 44 6 ] loss: 0.3934818506240845 2022-08-12 00:21:00.693268
Epoch:[ 44 7 ] loss: 0.3958238661289215 2022-08-12 00:21:01.114900
Epoch:[ 44 8 ] loss: 0.394801527261734 2022-08-12 00:21:01.539835
Epoch:[ 44 9 ] loss: 0.3939794600009918 2022-08-12 00:21:01.956022
Epoch:[ 44 10 ] loss: 0.3966597616672516 2022-08-12 00:21:02.369464
Epoch:[ 44 11 ] loss: 0.39618587493896484 2022-08-12 00:21:02.793023
Epoch:[ 44 12 ] loss: 0.3960888087749481 2022-08-12 00:21:03.222785
Epoch:[ 44 13 ] loss: 0.39542627334594727 2022-08-12 00:21:03.643851
Epoch:[ 44 14 ] loss: 0.394212931394577 2022-08-12 00:21:04.060051
Epoch:[ 44 15 ] loss: 0.395736962556839 2022-08-12 00:21:04.489557
Epoch:[ 44 16 ] loss: 0.3965282738208771 2022-08-12 00:21:10.267946
Epoch:[ 44 17 ] loss: 0.39546239376068115 2022-08-12 00:21:10.683082
Epoch:[ 44 18 ] loss: 0.3984069526195526 2022-08-12 00:21:11.108155
Epoch:[ 44 19 ] loss: 0.39317286014556885 2022-08-12 00:21:11.532403
Training_Epoch:[ 44 ] Training_loss: 0.39518166035413743 2022-08-12 00:21:11.533155
learning rate:  0.002088025
val: 1 0.41065534949302673
val: 2 0.4059307873249054
val: 3 0.40646523237228394
val: 4 0.40147829055786133
val: 5 0.4014246165752411
val: 6 0.40471914410591125
val: 7 0.4043959081172943
val: 8 0.40220633149147034
val: 9 0.4099249243736267
val: 10 0.4082677662372589
val: 11 0.41050970554351807
val: 12 0.3990579843521118
val: 13 0.403057724237442
val: 14 0.4066111743450165
val: 15 0.40381479263305664
val: 16 0.40710464119911194
val: 17 0.4107433259487152
val: 18 0.4134686291217804
val: 19 0.4090571403503418
val: 20 0.41248804330825806
val_Epoch:[ 44 ] val_loss: 0.40656907558441163 2022-08-12 00:21:15.123104
start training 2022-08-12 00:21:15.221912
Epoch:[ 45 0 ] loss: 0.3965021073818207 2022-08-12 00:21:29.294734
Epoch:[ 45 1 ] loss: 0.39509516954421997 2022-08-12 00:21:29.746641
Epoch:[ 45 2 ] loss: 0.3934711813926697 2022-08-12 00:21:30.189724
Epoch:[ 45 3 ] loss: 0.39381706714630127 2022-08-12 00:21:30.614351
Epoch:[ 45 4 ] loss: 0.39572444558143616 2022-08-12 00:21:31.039419
Epoch:[ 45 5 ] loss: 0.39580830931663513 2022-08-12 00:21:31.459910
Epoch:[ 45 6 ] loss: 0.3941033184528351 2022-08-12 00:21:31.883151
Epoch:[ 45 7 ] loss: 0.3939407169818878 2022-08-12 00:21:32.308432
Epoch:[ 45 8 ] loss: 0.3954619765281677 2022-08-12 00:21:32.741079
Epoch:[ 45 9 ] loss: 0.3945925533771515 2022-08-12 00:21:33.164197
Epoch:[ 45 10 ] loss: 0.39531344175338745 2022-08-12 00:21:33.586335
Epoch:[ 45 11 ] loss: 0.39453354477882385 2022-08-12 00:21:34.011461
Epoch:[ 45 12 ] loss: 0.3948863446712494 2022-08-12 00:21:34.427670
Epoch:[ 45 13 ] loss: 0.3967418074607849 2022-08-12 00:21:34.840234
Epoch:[ 45 14 ] loss: 0.39438849687576294 2022-08-12 00:21:35.264483
Epoch:[ 45 15 ] loss: 0.39316824078559875 2022-08-12 00:21:35.696212
Epoch:[ 45 16 ] loss: 0.39541664719581604 2022-08-12 00:21:41.438926
Epoch:[ 45 17 ] loss: 0.39280346035957336 2022-08-12 00:21:41.862101
Epoch:[ 45 18 ] loss: 0.39363983273506165 2022-08-12 00:21:42.288147
Epoch:[ 45 19 ] loss: 0.39466699957847595 2022-08-12 00:21:42.706852
Training_Epoch:[ 45 ] Training_loss: 0.39470378309488297 2022-08-12 00:21:42.707571
learning rate:  0.002088025
val: 1 0.4060468077659607
val: 2 0.39946889877319336
val: 3 0.4034181237220764
val: 4 0.4029971659183502
val: 5 0.402823269367218
val: 6 0.39465534687042236
val: 7 0.396027147769928
val: 8 0.4043649733066559
val: 9 0.39720314741134644
val: 10 0.3988758325576782
val: 11 0.40549570322036743
val: 12 0.4007003903388977
val: 13 0.403533935546875
val: 14 0.40409591794013977
val: 15 0.41520601511001587
val: 16 0.39936214685440063
val: 17 0.40355074405670166
val: 18 0.397645503282547
val: 19 0.4020637571811676
val: 20 0.39898809790611267
val_Epoch:[ 45 ] val_loss: 0.40182614624500274 2022-08-12 00:21:46.378186
start training 2022-08-12 00:21:46.485181
Epoch:[ 46 0 ] loss: 0.39299747347831726 2022-08-12 00:22:00.898966
Epoch:[ 46 1 ] loss: 0.39248591661453247 2022-08-12 00:22:01.326058
Epoch:[ 46 2 ] loss: 0.39425909519195557 2022-08-12 00:22:01.748230
Epoch:[ 46 3 ] loss: 0.394402414560318 2022-08-12 00:22:02.172378
Epoch:[ 46 4 ] loss: 0.39275991916656494 2022-08-12 00:22:02.596657
Epoch:[ 46 5 ] loss: 0.39337292313575745 2022-08-12 00:22:03.016990
Epoch:[ 46 6 ] loss: 0.39628714323043823 2022-08-12 00:22:03.430687
Epoch:[ 46 7 ] loss: 0.3997320830821991 2022-08-12 00:22:03.853785
Epoch:[ 46 8 ] loss: 0.39761948585510254 2022-08-12 00:22:04.280755
Epoch:[ 46 9 ] loss: 0.3970198631286621 2022-08-12 00:22:04.701292
Epoch:[ 46 10 ] loss: 0.39723944664001465 2022-08-12 00:22:05.117030
Epoch:[ 46 11 ] loss: 0.3961501121520996 2022-08-12 00:22:05.542058
Epoch:[ 46 12 ] loss: 0.39468875527381897 2022-08-12 00:22:05.968016
Epoch:[ 46 13 ] loss: 0.39575666189193726 2022-08-12 00:22:06.391783
Epoch:[ 46 14 ] loss: 0.39765721559524536 2022-08-12 00:22:06.817905
Epoch:[ 46 15 ] loss: 0.39213865995407104 2022-08-12 00:22:07.241601
Epoch:[ 46 16 ] loss: 0.3971371650695801 2022-08-12 00:22:13.015322
Epoch:[ 46 17 ] loss: 0.39302802085876465 2022-08-12 00:22:13.439064
Epoch:[ 46 18 ] loss: 0.39669352769851685 2022-08-12 00:22:13.858213
Epoch:[ 46 19 ] loss: 0.39480826258659363 2022-08-12 00:22:14.281897
Training_Epoch:[ 46 ] Training_loss: 0.3953117072582245 2022-08-12 00:22:14.282649
learning rate:  0.002088025
val: 1 0.39947399497032166
val: 2 0.40377750992774963
val: 3 0.40285724401474
val: 4 0.40324416756629944
val: 5 0.4065876603126526
val: 6 0.40248411893844604
val: 7 0.40491268038749695
val: 8 0.40208375453948975
val: 9 0.40402814745903015
val: 10 0.40158477425575256
val: 11 0.4010845422744751
val: 12 0.4076997935771942
val: 13 0.4065665006637573
val: 14 0.3972921073436737
val: 15 0.40057075023651123
val: 16 0.40248820185661316
val: 17 0.401932030916214
val: 18 0.4039987623691559
val: 19 0.40440648794174194
val: 20 0.4059826731681824
val_Epoch:[ 46 ] val_loss: 0.4031527951359749 2022-08-12 00:22:17.829028
start training 2022-08-12 00:22:17.932724
Epoch:[ 47 0 ] loss: 0.3949372172355652 2022-08-12 00:22:32.641135
Epoch:[ 47 1 ] loss: 0.39477965235710144 2022-08-12 00:22:33.058665
Epoch:[ 47 2 ] loss: 0.39393094182014465 2022-08-12 00:22:33.485170
Epoch:[ 47 3 ] loss: 0.39278846979141235 2022-08-12 00:22:33.910126
Epoch:[ 47 4 ] loss: 0.3921191990375519 2022-08-12 00:22:34.330329
Epoch:[ 47 5 ] loss: 0.39486512541770935 2022-08-12 00:22:34.751249
Epoch:[ 47 6 ] loss: 0.39296385645866394 2022-08-12 00:22:35.177869
Epoch:[ 47 7 ] loss: 0.393913596868515 2022-08-12 00:22:35.604043
Epoch:[ 47 8 ] loss: 0.39538922905921936 2022-08-12 00:22:36.022984
Epoch:[ 47 9 ] loss: 0.393750935792923 2022-08-12 00:22:36.448630
Epoch:[ 47 10 ] loss: 0.39279231429100037 2022-08-12 00:22:36.872557
Epoch:[ 47 11 ] loss: 0.39483270049095154 2022-08-12 00:22:37.301480
Epoch:[ 47 12 ] loss: 0.39379656314849854 2022-08-12 00:22:37.725746
Epoch:[ 47 13 ] loss: 0.3945589065551758 2022-08-12 00:22:38.149252
Epoch:[ 47 14 ] loss: 0.39509260654449463 2022-08-12 00:22:38.573009
Epoch:[ 47 15 ] loss: 0.3937506079673767 2022-08-12 00:22:38.994258
Epoch:[ 47 16 ] loss: 0.39417359232902527 2022-08-12 00:22:44.572997
Epoch:[ 47 17 ] loss: 0.3949042856693268 2022-08-12 00:22:45.005167
Epoch:[ 47 18 ] loss: 0.3934670686721802 2022-08-12 00:22:45.431204
Epoch:[ 47 19 ] loss: 0.39407879114151 2022-08-12 00:22:45.846376
Training_Epoch:[ 47 ] Training_loss: 0.3940442830324173 2022-08-12 00:22:45.847036
learning rate:  0.002088025
val: 1 0.3987986743450165
val: 2 0.40251049399375916
val: 3 0.396302193403244
val: 4 0.40240293741226196
val: 5 0.39750662446022034
val: 6 0.40588635206222534
val: 7 0.4031135141849518
val: 8 0.40299180150032043
val: 9 0.3978143632411957
val: 10 0.4058576226234436
val: 11 0.40234217047691345
val: 12 0.3957380950450897
val: 13 0.4021417498588562
val: 14 0.39867520332336426
val: 15 0.40038472414016724
val: 16 0.4047492742538452
val: 17 0.40034228563308716
val: 18 0.400788277387619
val: 19 0.4024542570114136
val: 20 0.4032745957374573
val_Epoch:[ 47 ] val_loss: 0.4012037605047226 2022-08-12 00:22:49.470877
start training 2022-08-12 00:22:49.571483
Epoch:[ 48 0 ] loss: 0.3904339373111725 2022-08-12 00:23:03.852955
Epoch:[ 48 1 ] loss: 0.39548739790916443 2022-08-12 00:23:04.321185
Epoch:[ 48 2 ] loss: 0.39374837279319763 2022-08-12 00:23:04.740421
Epoch:[ 48 3 ] loss: 0.39250677824020386 2022-08-12 00:23:05.166105
Epoch:[ 48 4 ] loss: 0.39248308539390564 2022-08-12 00:23:05.591208
Epoch:[ 48 5 ] loss: 0.3952070474624634 2022-08-12 00:23:06.015675
Epoch:[ 48 6 ] loss: 0.3960692882537842 2022-08-12 00:23:06.440437
Epoch:[ 48 7 ] loss: 0.39626723527908325 2022-08-12 00:23:06.865789
Epoch:[ 48 8 ] loss: 0.39330974221229553 2022-08-12 00:23:07.286661
Epoch:[ 48 9 ] loss: 0.3949339687824249 2022-08-12 00:23:07.702314
Epoch:[ 48 10 ] loss: 0.3926628530025482 2022-08-12 00:23:08.124158
Epoch:[ 48 11 ] loss: 0.39134958386421204 2022-08-12 00:23:08.555068
Epoch:[ 48 12 ] loss: 0.39259228110313416 2022-08-12 00:23:08.981993
Epoch:[ 48 13 ] loss: 0.39171603322029114 2022-08-12 00:23:09.403639
Epoch:[ 48 14 ] loss: 0.3905813694000244 2022-08-12 00:23:09.824590
Epoch:[ 48 15 ] loss: 0.39255303144454956 2022-08-12 00:23:10.249171
Epoch:[ 48 16 ] loss: 0.39333176612854004 2022-08-12 00:23:15.520448
Epoch:[ 48 17 ] loss: 0.3935958445072174 2022-08-12 00:23:16.968565
Epoch:[ 48 18 ] loss: 0.39280229806900024 2022-08-12 00:23:17.400953
Epoch:[ 48 19 ] loss: 0.3935821056365967 2022-08-12 00:23:17.823795
Training_Epoch:[ 48 ] Training_loss: 0.39326070100069044 2022-08-12 00:23:17.824504
learning rate:  0.002088025
val: 1 0.40263307094573975
val: 2 0.4029678702354431
val: 3 0.40652674436569214
val: 4 0.4075045585632324
val: 5 0.4082110524177551
val: 6 0.4090113639831543
val: 7 0.41124171018600464
val: 8 0.40857967734336853
val: 9 0.4045774042606354
val: 10 0.4101603627204895
val: 11 0.40638604760169983
val: 12 0.4078558087348938
val: 13 0.40894466638565063
val: 14 0.40955862402915955
val: 15 0.40703168511390686
val: 16 0.4082566499710083
val: 17 0.40371978282928467
val: 18 0.40602239966392517
val: 19 0.40755560994148254
val: 20 0.41320204734802246
val_Epoch:[ 48 ] val_loss: 0.4074973568320274 2022-08-12 00:23:21.483343
start training 2022-08-12 00:23:21.586127
Epoch:[ 49 0 ] loss: 0.3921126425266266 2022-08-12 00:23:36.529063
Epoch:[ 49 1 ] loss: 0.3910742402076721 2022-08-12 00:23:36.953390
Epoch:[ 49 2 ] loss: 0.3914218246936798 2022-08-12 00:23:37.368542
Epoch:[ 49 3 ] loss: 0.39121049642562866 2022-08-12 00:23:37.790735
Epoch:[ 49 4 ] loss: 0.3905036747455597 2022-08-12 00:23:38.214849
Epoch:[ 49 5 ] loss: 0.3909156322479248 2022-08-12 00:23:38.640112
Epoch:[ 49 6 ] loss: 0.392550528049469 2022-08-12 00:23:39.065047
Epoch:[ 49 7 ] loss: 0.38945087790489197 2022-08-12 00:23:39.489913
Epoch:[ 49 8 ] loss: 0.3914082944393158 2022-08-12 00:23:39.918068
Epoch:[ 49 9 ] loss: 0.3916928768157959 2022-08-12 00:23:40.334407
Epoch:[ 49 10 ] loss: 0.39054808020591736 2022-08-12 00:23:40.751138
Epoch:[ 49 11 ] loss: 0.3919615149497986 2022-08-12 00:23:41.176022
Epoch:[ 49 12 ] loss: 0.39170727133750916 2022-08-12 00:23:41.600285
Epoch:[ 49 13 ] loss: 0.39060497283935547 2022-08-12 00:23:42.018914
Epoch:[ 49 14 ] loss: 0.39209580421447754 2022-08-12 00:23:42.440769
Epoch:[ 49 15 ] loss: 0.3930244445800781 2022-08-12 00:23:42.866116
Epoch:[ 49 16 ] loss: 0.3893318772315979 2022-08-12 00:23:48.450376
Epoch:[ 49 17 ] loss: 0.39479559659957886 2022-08-12 00:23:48.871476
Epoch:[ 49 18 ] loss: 0.39298468828201294 2022-08-12 00:23:49.301115
Epoch:[ 49 19 ] loss: 0.39328813552856445 2022-08-12 00:23:49.716120
Training_Epoch:[ 49 ] Training_loss: 0.39163417369127274 2022-08-12 00:23:49.716794
learning rate:  0.002088025
val: 1 0.4097784757614136
val: 2 0.39916324615478516
val: 3 0.40134701132774353
val: 4 0.4043920040130615
val: 5 0.40063196420669556
val: 6 0.40303757786750793
val: 7 0.403878778219223
val: 8 0.40944796800613403
val: 9 0.3981764018535614
val: 10 0.40366554260253906
val: 11 0.4008413553237915
val: 12 0.4000365138053894
val: 13 0.4043830633163452
val: 14 0.3988988697528839
val: 15 0.40202948451042175
val: 16 0.39894941449165344
val: 17 0.4090920686721802
val: 18 0.40311017632484436
val: 19 0.3934210240840912
val: 20 0.40338215231895447
val_Epoch:[ 49 ] val_loss: 0.402383154630661 2022-08-12 00:23:53.339879
start training 2022-08-12 00:23:53.436407
Epoch:[ 50 0 ] loss: 0.39234182238578796 2022-08-12 00:24:08.100491
Epoch:[ 50 1 ] loss: 0.39615780115127563 2022-08-12 00:24:08.529994
Epoch:[ 50 2 ] loss: 0.39075157046318054 2022-08-12 00:24:08.944079
Epoch:[ 50 3 ] loss: 0.3961103856563568 2022-08-12 00:24:09.364815
Epoch:[ 50 4 ] loss: 0.3934854567050934 2022-08-12 00:24:09.793344
Epoch:[ 50 5 ] loss: 0.3927931487560272 2022-08-12 00:24:10.219776
Epoch:[ 50 6 ] loss: 0.39491456747055054 2022-08-12 00:24:10.648416
Epoch:[ 50 7 ] loss: 0.39277154207229614 2022-08-12 00:24:11.068710
Epoch:[ 50 8 ] loss: 0.39150992035865784 2022-08-12 00:24:11.492756
Epoch:[ 50 9 ] loss: 0.3918531537055969 2022-08-12 00:24:11.918404
Epoch:[ 50 10 ] loss: 0.38970068097114563 2022-08-12 00:24:12.345302
Epoch:[ 50 11 ] loss: 0.3912237882614136 2022-08-12 00:24:12.770555
Epoch:[ 50 12 ] loss: 0.3918203115463257 2022-08-12 00:24:13.191098
Epoch:[ 50 13 ] loss: 0.3906804323196411 2022-08-12 00:24:13.616906
Epoch:[ 50 14 ] loss: 0.39225468039512634 2022-08-12 00:24:14.039307
Epoch:[ 50 15 ] loss: 0.38999682664871216 2022-08-12 00:24:14.462623
Epoch:[ 50 16 ] loss: 0.39189690351486206 2022-08-12 00:24:19.719278
Epoch:[ 50 17 ] loss: 0.39217662811279297 2022-08-12 00:24:20.143604
Epoch:[ 50 18 ] loss: 0.39213594794273376 2022-08-12 00:24:20.564910
Epoch:[ 50 19 ] loss: 0.3908281624317169 2022-08-12 00:24:20.988903
Training_Epoch:[ 50 ] Training_loss: 0.3922701865434647 2022-08-12 00:24:20.989571
learning rate:  0.002088025
netparams have been saved once 50
val: 1 0.4053572416305542
val: 2 0.4071463942527771
val: 3 0.407867431640625
val: 4 0.39773377776145935
val: 5 0.4080677330493927
val: 6 0.4081284999847412
val: 7 0.4100160598754883
val: 8 0.4114087224006653
val: 9 0.4020110070705414
val: 10 0.41256269812583923
val: 11 0.40615516901016235
val: 12 0.4070854187011719
val: 13 0.40616729855537415
val: 14 0.40782299637794495
val: 15 0.4048522114753723
val: 16 0.4096294641494751
val: 17 0.4039812386035919
val: 18 0.40390902757644653
val: 19 0.3995434641838074
val: 20 0.40866324305534363
val_Epoch:[ 50 ] val_loss: 0.4064054548740387 2022-08-12 00:24:24.618713
start training 2022-08-12 00:24:24.715293
Epoch:[ 51 0 ] loss: 0.3924468159675598 2022-08-12 00:24:38.767396
Epoch:[ 51 1 ] loss: 0.3925716280937195 2022-08-12 00:24:39.352026
Epoch:[ 51 2 ] loss: 0.3875122666358948 2022-08-12 00:24:39.778104
Epoch:[ 51 3 ] loss: 0.3929947018623352 2022-08-12 00:24:40.203688
Epoch:[ 51 4 ] loss: 0.38908708095550537 2022-08-12 00:24:40.624207
Epoch:[ 51 5 ] loss: 0.3895915448665619 2022-08-12 00:24:41.043868
Epoch:[ 51 6 ] loss: 0.38924747705459595 2022-08-12 00:24:41.468343
Epoch:[ 51 7 ] loss: 0.38976359367370605 2022-08-12 00:24:41.890607
Epoch:[ 51 8 ] loss: 0.3919138014316559 2022-08-12 00:24:42.319612
Epoch:[ 51 9 ] loss: 0.38822808861732483 2022-08-12 00:24:42.744788
Epoch:[ 51 10 ] loss: 0.38862305879592896 2022-08-12 00:24:43.170163
Epoch:[ 51 11 ] loss: 0.3883998394012451 2022-08-12 00:24:43.590773
Epoch:[ 51 12 ] loss: 0.39011457562446594 2022-08-12 00:24:44.003505
Epoch:[ 51 13 ] loss: 0.3875553011894226 2022-08-12 00:24:44.422973
Epoch:[ 51 14 ] loss: 0.38912537693977356 2022-08-12 00:24:44.852707
Epoch:[ 51 15 ] loss: 0.38790008425712585 2022-08-12 00:24:45.275302
Epoch:[ 51 16 ] loss: 0.38957810401916504 2022-08-12 00:24:50.846233
Epoch:[ 51 17 ] loss: 0.3893476724624634 2022-08-12 00:24:51.271138
Epoch:[ 51 18 ] loss: 0.38930371403694153 2022-08-12 00:24:51.695875
Epoch:[ 51 19 ] loss: 0.38767218589782715 2022-08-12 00:24:52.112054
Training_Epoch:[ 51 ] Training_loss: 0.3895488455891609 2022-08-12 00:24:52.112796
learning rate:  0.0017748212499999999
val: 1 0.4079116880893707
val: 2 0.3993823826313019
val: 3 0.3981967866420746
val: 4 0.4005082845687866
val: 5 0.4127008616924286
val: 6 0.4024204909801483
val: 7 0.3955458998680115
val: 8 0.40024644136428833
val: 9 0.3956385552883148
val: 10 0.40073317289352417
val: 11 0.3961844742298126
val: 12 0.3988659381866455
val: 13 0.40058979392051697
val: 14 0.4045746624469757
val: 15 0.4002363979816437
val: 16 0.40581682324409485
val: 17 0.39918893575668335
val: 18 0.40376535058021545
val: 19 0.39725252985954285
val: 20 0.4027314782142639
val_Epoch:[ 51 ] val_loss: 0.4011245474219322 2022-08-12 00:24:55.725419
start training 2022-08-12 00:24:55.822000
Epoch:[ 52 0 ] loss: 0.38738125562667847 2022-08-12 00:25:10.214235
Epoch:[ 52 1 ] loss: 0.388197660446167 2022-08-12 00:25:10.660829
Epoch:[ 52 2 ] loss: 0.3896702527999878 2022-08-12 00:25:11.089423
Epoch:[ 52 3 ] loss: 0.3907477855682373 2022-08-12 00:25:11.507494
Epoch:[ 52 4 ] loss: 0.3930840790271759 2022-08-12 00:25:11.924786
Epoch:[ 52 5 ] loss: 0.39034387469291687 2022-08-12 00:25:12.350227
Epoch:[ 52 6 ] loss: 0.38993602991104126 2022-08-12 00:25:12.775784
Epoch:[ 52 7 ] loss: 0.3905094563961029 2022-08-12 00:25:13.202731
Epoch:[ 52 8 ] loss: 0.39015933871269226 2022-08-12 00:25:13.626814
Epoch:[ 52 9 ] loss: 0.3907533288002014 2022-08-12 00:25:14.051232
Epoch:[ 52 10 ] loss: 0.3916427791118622 2022-08-12 00:25:14.475681
Epoch:[ 52 11 ] loss: 0.38972073793411255 2022-08-12 00:25:14.900286
Epoch:[ 52 12 ] loss: 0.39183109998703003 2022-08-12 00:25:15.320996
Epoch:[ 52 13 ] loss: 0.39066675305366516 2022-08-12 00:25:15.745858
Epoch:[ 52 14 ] loss: 0.3909628391265869 2022-08-12 00:25:16.172343
Epoch:[ 52 15 ] loss: 0.3921397626399994 2022-08-12 00:25:16.588041
Epoch:[ 52 16 ] loss: 0.39170700311660767 2022-08-12 00:25:21.894335
Epoch:[ 52 17 ] loss: 0.3929302990436554 2022-08-12 00:25:22.314657
Epoch:[ 52 18 ] loss: 0.3916163444519043 2022-08-12 00:25:22.735574
Epoch:[ 52 19 ] loss: 0.3901805579662323 2022-08-12 00:25:23.148892
Training_Epoch:[ 52 ] Training_loss: 0.39070906192064286 2022-08-12 00:25:23.149616
learning rate:  0.0017748212499999999
val: 1 0.3991490602493286
val: 2 0.39953193068504333
val: 3 0.39862939715385437
val: 4 0.4070641100406647
val: 5 0.396134614944458
val: 6 0.40080541372299194
val: 7 0.402828186750412
val: 8 0.4087925851345062
val: 9 0.40469130873680115
val: 10 0.40679895877838135
val: 11 0.4137391149997711
val: 12 0.4022475779056549
val: 13 0.40079328417778015
val: 14 0.4021998345851898
val: 15 0.40791091322898865
val: 16 0.4109854996204376
val: 17 0.39591503143310547
val: 18 0.40313535928726196
val: 19 0.39866408705711365
val: 20 0.40040820837020874
val_Epoch:[ 52 ] val_loss: 0.4030212238430977 2022-08-12 00:25:26.742808
start training 2022-08-12 00:25:26.843644
Epoch:[ 53 0 ] loss: 0.3920927345752716 2022-08-12 00:25:40.877222
Epoch:[ 53 1 ] loss: 0.38838520646095276 2022-08-12 00:25:41.339763
Epoch:[ 53 2 ] loss: 0.39383459091186523 2022-08-12 00:25:41.759639
Epoch:[ 53 3 ] loss: 0.387899786233902 2022-08-12 00:25:42.183730
Epoch:[ 53 4 ] loss: 0.39062178134918213 2022-08-12 00:25:42.606828
Epoch:[ 53 5 ] loss: 0.39027875661849976 2022-08-12 00:25:43.032197
Epoch:[ 53 6 ] loss: 0.3883123993873596 2022-08-12 00:25:43.460132
Epoch:[ 53 7 ] loss: 0.38769400119781494 2022-08-12 00:25:43.883591
Epoch:[ 53 8 ] loss: 0.38895106315612793 2022-08-12 00:25:44.306519
Epoch:[ 53 9 ] loss: 0.38955384492874146 2022-08-12 00:25:44.726868
Epoch:[ 53 10 ] loss: 0.39093077182769775 2022-08-12 00:25:45.140423
Epoch:[ 53 11 ] loss: 0.38945549726486206 2022-08-12 00:25:45.564514
Epoch:[ 53 12 ] loss: 0.389030784368515 2022-08-12 00:25:45.987925
Epoch:[ 53 13 ] loss: 0.388352632522583 2022-08-12 00:25:46.407843
Epoch:[ 53 14 ] loss: 0.3904893100261688 2022-08-12 00:25:46.820818
Epoch:[ 53 15 ] loss: 0.38784605264663696 2022-08-12 00:25:47.246260
Epoch:[ 53 16 ] loss: 0.3890165090560913 2022-08-12 00:25:53.049366
Epoch:[ 53 17 ] loss: 0.3885094225406647 2022-08-12 00:25:53.471653
Epoch:[ 53 18 ] loss: 0.3875419795513153 2022-08-12 00:25:53.898042
Epoch:[ 53 19 ] loss: 0.38937944173812866 2022-08-12 00:25:54.322790
Training_Epoch:[ 53 ] Training_loss: 0.38940882831811907 2022-08-12 00:25:54.323469
learning rate:  0.0017748212499999999
val: 1 0.40272465348243713
val: 2 0.3978343605995178
val: 3 0.4030601978302002
val: 4 0.4086797833442688
val: 5 0.4015422463417053
val: 6 0.40326645970344543
val: 7 0.40607142448425293
val: 8 0.4011708199977875
val: 9 0.40646347403526306
val: 10 0.4012715816497803
val: 11 0.40028253197669983
val: 12 0.39917975664138794
val: 13 0.4078981578350067
val: 14 0.402321994304657
val: 15 0.39836353063583374
val: 16 0.4024614989757538
val: 17 0.39335545897483826
val: 18 0.4027053117752075
val: 19 0.39379972219467163
val: 20 0.40031832456588745
val_Epoch:[ 53 ] val_loss: 0.4016385644674301 2022-08-12 00:25:57.966286
start training 2022-08-12 00:25:58.065634
Epoch:[ 54 0 ] loss: 0.3882717192173004 2022-08-12 00:26:12.365244
Epoch:[ 54 1 ] loss: 0.3867502808570862 2022-08-12 00:26:12.797059
Epoch:[ 54 2 ] loss: 0.3880814015865326 2022-08-12 00:26:13.223453
Epoch:[ 54 3 ] loss: 0.38749760389328003 2022-08-12 00:26:13.650535
Epoch:[ 54 4 ] loss: 0.38958004117012024 2022-08-12 00:26:14.074342
Epoch:[ 54 5 ] loss: 0.390464186668396 2022-08-12 00:26:14.495613
Epoch:[ 54 6 ] loss: 0.38773807883262634 2022-08-12 00:26:14.923477
Epoch:[ 54 7 ] loss: 0.38944166898727417 2022-08-12 00:26:15.342060
Epoch:[ 54 8 ] loss: 0.3908408582210541 2022-08-12 00:26:15.763791
Epoch:[ 54 9 ] loss: 0.3869107961654663 2022-08-12 00:26:16.189749
Epoch:[ 54 10 ] loss: 0.3876745104789734 2022-08-12 00:26:16.615443
Epoch:[ 54 11 ] loss: 0.3876488208770752 2022-08-12 00:26:17.032786
Epoch:[ 54 12 ] loss: 0.38587936758995056 2022-08-12 00:26:17.447305
Epoch:[ 54 13 ] loss: 0.39058172702789307 2022-08-12 00:26:17.867767
Epoch:[ 54 14 ] loss: 0.38734495639801025 2022-08-12 00:26:18.297839
Epoch:[ 54 15 ] loss: 0.38940244913101196 2022-08-12 00:26:18.717661
Epoch:[ 54 16 ] loss: 0.3881088197231293 2022-08-12 00:26:24.435408
Epoch:[ 54 17 ] loss: 0.38805267214775085 2022-08-12 00:26:24.860737
Epoch:[ 54 18 ] loss: 0.38863664865493774 2022-08-12 00:26:25.284120
Epoch:[ 54 19 ] loss: 0.3918689489364624 2022-08-12 00:26:25.702604
Training_Epoch:[ 54 ] Training_loss: 0.38853877782821655 2022-08-12 00:26:25.703300
learning rate:  0.0017748212499999999
val: 1 0.40790048241615295
val: 2 0.39921945333480835
val: 3 0.3998767137527466
val: 4 0.39749041199684143
val: 5 0.39675024151802063
val: 6 0.4009878933429718
val: 7 0.4047800302505493
val: 8 0.4031739830970764
val: 9 0.40081724524497986
val: 10 0.40354451537132263
val: 11 0.3967052400112152
val: 12 0.3994159698486328
val: 13 0.4028208553791046
val: 14 0.40195411443710327
val: 15 0.39625000953674316
val: 16 0.3978506624698639
val: 17 0.3988758325576782
val: 18 0.4050503373146057
val: 19 0.4041561484336853
val: 20 0.4027436077594757
val_Epoch:[ 54 ] val_loss: 0.4010181874036789 2022-08-12 00:26:29.319273
start training 2022-08-12 00:26:29.412739
Epoch:[ 55 0 ] loss: 0.38776543736457825 2022-08-12 00:26:44.213057
Epoch:[ 55 1 ] loss: 0.3861725330352783 2022-08-12 00:26:44.638932
Epoch:[ 55 2 ] loss: 0.3875391185283661 2022-08-12 00:26:45.060653
Epoch:[ 55 3 ] loss: 0.3867295980453491 2022-08-12 00:26:45.497901
Epoch:[ 55 4 ] loss: 0.3889828622341156 2022-08-12 00:26:45.913820
Epoch:[ 55 5 ] loss: 0.389379620552063 2022-08-12 00:26:46.334988
Epoch:[ 55 6 ] loss: 0.38873451948165894 2022-08-12 00:26:46.763242
Epoch:[ 55 7 ] loss: 0.3862602114677429 2022-08-12 00:26:47.187653
Epoch:[ 55 8 ] loss: 0.38790738582611084 2022-08-12 00:26:47.608333
Epoch:[ 55 9 ] loss: 0.3859802782535553 2022-08-12 00:26:48.027022
Epoch:[ 55 10 ] loss: 0.3893176019191742 2022-08-12 00:26:48.452996
Epoch:[ 55 11 ] loss: 0.38878199458122253 2022-08-12 00:26:48.880513
Epoch:[ 55 12 ] loss: 0.3871583938598633 2022-08-12 00:26:49.306585
Epoch:[ 55 13 ] loss: 0.3880433738231659 2022-08-12 00:26:49.730700
Epoch:[ 55 14 ] loss: 0.38807299733161926 2022-08-12 00:26:50.150934
Epoch:[ 55 15 ] loss: 0.3892376720905304 2022-08-12 00:26:50.575835
Epoch:[ 55 16 ] loss: 0.3883250653743744 2022-08-12 00:26:56.127404
Epoch:[ 55 17 ] loss: 0.38902512192726135 2022-08-12 00:26:56.549960
Epoch:[ 55 18 ] loss: 0.3888002932071686 2022-08-12 00:26:56.983563
Epoch:[ 55 19 ] loss: 0.3883620798587799 2022-08-12 00:26:57.408450
Training_Epoch:[ 55 ] Training_loss: 0.3880288079380989 2022-08-12 00:26:57.409126
learning rate:  0.0017748212499999999
val: 1 0.39751577377319336
val: 2 0.4015682637691498
val: 3 0.3965250551700592
val: 4 0.40563860535621643
val: 5 0.3985825181007385
val: 6 0.39450088143348694
val: 7 0.4016647934913635
val: 8 0.3983420729637146
val: 9 0.394954651594162
val: 10 0.40406835079193115
val: 11 0.3968643844127655
val: 12 0.39443913102149963
val: 13 0.3949199616909027
val: 14 0.3978630602359772
val: 15 0.4027371406555176
val: 16 0.40175172686576843
val: 17 0.3949544131755829
val: 18 0.4011748731136322
val: 19 0.3983255624771118
val: 20 0.39665624499320984
val_Epoch:[ 55 ] val_loss: 0.39865237325429914 2022-08-12 00:27:01.042371
start training 2022-08-12 00:27:01.136841
Epoch:[ 56 0 ] loss: 0.386701762676239 2022-08-12 00:27:15.420082
Epoch:[ 56 1 ] loss: 0.3872598111629486 2022-08-12 00:27:15.844141
Epoch:[ 56 2 ] loss: 0.38772499561309814 2022-08-12 00:27:16.263868
Epoch:[ 56 3 ] loss: 0.38506636023521423 2022-08-12 00:27:16.685847
Epoch:[ 56 4 ] loss: 0.38571542501449585 2022-08-12 00:27:17.117057
Epoch:[ 56 5 ] loss: 0.38728201389312744 2022-08-12 00:27:17.541651
Epoch:[ 56 6 ] loss: 0.3850864768028259 2022-08-12 00:27:17.969324
Epoch:[ 56 7 ] loss: 0.38519999384880066 2022-08-12 00:27:18.383724
Epoch:[ 56 8 ] loss: 0.3878397047519684 2022-08-12 00:27:18.802513
Epoch:[ 56 9 ] loss: 0.3880746066570282 2022-08-12 00:27:19.227987
Epoch:[ 56 10 ] loss: 0.3868887424468994 2022-08-12 00:27:19.649814
Epoch:[ 56 11 ] loss: 0.38708946108818054 2022-08-12 00:27:20.069213
Epoch:[ 56 12 ] loss: 0.38645339012145996 2022-08-12 00:27:20.490252
Epoch:[ 56 13 ] loss: 0.3885669708251953 2022-08-12 00:27:20.913961
Epoch:[ 56 14 ] loss: 0.3867497742176056 2022-08-12 00:27:21.335093
Epoch:[ 56 15 ] loss: 0.3886116147041321 2022-08-12 00:27:21.755954
Epoch:[ 56 16 ] loss: 0.3886125981807709 2022-08-12 00:27:27.160611
Epoch:[ 56 17 ] loss: 0.38676780462265015 2022-08-12 00:27:27.570442
Epoch:[ 56 18 ] loss: 0.38700932264328003 2022-08-12 00:27:27.995132
Epoch:[ 56 19 ] loss: 0.38951751589775085 2022-08-12 00:27:28.425984
Training_Epoch:[ 56 ] Training_loss: 0.38711091727018354 2022-08-12 00:27:28.426711
learning rate:  0.0017748212499999999
val: 1 0.4077010154724121
val: 2 0.40016260743141174
val: 3 0.3994269371032715
val: 4 0.3941153585910797
val: 5 0.40250229835510254
val: 6 0.4034455120563507
val: 7 0.3985523283481598
val: 8 0.39779382944107056
val: 9 0.3934052288532257
val: 10 0.39536911249160767
val: 11 0.40484076738357544
val: 12 0.3981136977672577
val: 13 0.40255725383758545
val: 14 0.4025140404701233
val: 15 0.4000292420387268
val: 16 0.3941241502761841
val: 17 0.39927029609680176
val: 18 0.3944889008998871
val: 19 0.3969174921512604
val: 20 0.4036587178707123
val_Epoch:[ 56 ] val_loss: 0.39944943934679034 2022-08-12 00:27:31.893186
start training 2022-08-12 00:27:31.987936
Epoch:[ 57 0 ] loss: 0.38603657484054565 2022-08-12 00:27:46.687840
Epoch:[ 57 1 ] loss: 0.38553041219711304 2022-08-12 00:27:47.101830
Epoch:[ 57 2 ] loss: 0.3849658668041229 2022-08-12 00:27:47.523559
Epoch:[ 57 3 ] loss: 0.3857881426811218 2022-08-12 00:27:47.951455
Epoch:[ 57 4 ] loss: 0.3860337436199188 2022-08-12 00:27:48.370372
Epoch:[ 57 5 ] loss: 0.3872932493686676 2022-08-12 00:27:48.784333
Epoch:[ 57 6 ] loss: 0.38534677028656006 2022-08-12 00:27:49.210346
Epoch:[ 57 7 ] loss: 0.38593292236328125 2022-08-12 00:27:49.636109
Epoch:[ 57 8 ] loss: 0.38817429542541504 2022-08-12 00:27:50.059408
Epoch:[ 57 9 ] loss: 0.3841238021850586 2022-08-12 00:27:50.477633
Epoch:[ 57 10 ] loss: 0.3857414424419403 2022-08-12 00:27:50.900857
Epoch:[ 57 11 ] loss: 0.38843828439712524 2022-08-12 00:27:51.321076
Epoch:[ 57 12 ] loss: 0.3866172730922699 2022-08-12 00:27:51.743556
Epoch:[ 57 13 ] loss: 0.3872472941875458 2022-08-12 00:27:52.168648
Epoch:[ 57 14 ] loss: 0.38513004779815674 2022-08-12 00:27:52.594379
Epoch:[ 57 15 ] loss: 0.3849036991596222 2022-08-12 00:27:53.011420
Epoch:[ 57 16 ] loss: 0.387082576751709 2022-08-12 00:27:58.341149
Epoch:[ 57 17 ] loss: 0.38734170794487 2022-08-12 00:27:58.762540
Epoch:[ 57 18 ] loss: 0.386495441198349 2022-08-12 00:27:59.188774
Epoch:[ 57 19 ] loss: 0.38614603877067566 2022-08-12 00:27:59.607413
Training_Epoch:[ 57 ] Training_loss: 0.3862184792757034 2022-08-12 00:27:59.608086
learning rate:  0.0017748212499999999
val: 1 0.3995894193649292
val: 2 0.40467211604118347
val: 3 0.40678682923316956
val: 4 0.3943578898906708
val: 5 0.39493200182914734
val: 6 0.3978627920150757
val: 7 0.39995136857032776
val: 8 0.3985667824745178
val: 9 0.39880234003067017
val: 10 0.3967772126197815
val: 11 0.3959265351295471
val: 12 0.4042024612426758
val: 13 0.4039090573787689
val: 14 0.39451131224632263
val: 15 0.39566570520401
val: 16 0.39968109130859375
val: 17 0.40620216727256775
val: 18 0.40315306186676025
val: 19 0.4005184769630432
val: 20 0.39717209339141846
val_Epoch:[ 57 ] val_loss: 0.39966203570365905 2022-08-12 00:28:03.127383
start training 2022-08-12 00:28:03.224014
Epoch:[ 58 0 ] loss: 0.38403329253196716 2022-08-12 00:28:17.023299
Epoch:[ 58 1 ] loss: 0.38739219307899475 2022-08-12 00:28:17.894125
Epoch:[ 58 2 ] loss: 0.3853461444377899 2022-08-12 00:28:18.321011
Epoch:[ 58 3 ] loss: 0.38551953434944153 2022-08-12 00:28:18.745556
Epoch:[ 58 4 ] loss: 0.38602882623672485 2022-08-12 00:28:19.169147
Epoch:[ 58 5 ] loss: 0.38706400990486145 2022-08-12 00:28:19.588639
Epoch:[ 58 6 ] loss: 0.3865831196308136 2022-08-12 00:28:20.013809
Epoch:[ 58 7 ] loss: 0.38582441210746765 2022-08-12 00:28:20.436746
Epoch:[ 58 8 ] loss: 0.3850523829460144 2022-08-12 00:28:20.859354
Epoch:[ 58 9 ] loss: 0.3874477446079254 2022-08-12 00:28:21.281512
Epoch:[ 58 10 ] loss: 0.38688308000564575 2022-08-12 00:28:21.703324
Epoch:[ 58 11 ] loss: 0.38482990860939026 2022-08-12 00:28:22.121621
Epoch:[ 58 12 ] loss: 0.3853633999824524 2022-08-12 00:28:22.544362
Epoch:[ 58 13 ] loss: 0.38788989186286926 2022-08-12 00:28:22.969276
Epoch:[ 58 14 ] loss: 0.38657501339912415 2022-08-12 00:28:23.391898
Epoch:[ 58 15 ] loss: 0.3879666328430176 2022-08-12 00:28:23.808313
Epoch:[ 58 16 ] loss: 0.3883657157421112 2022-08-12 00:28:29.226382
Epoch:[ 58 17 ] loss: 0.38738203048706055 2022-08-12 00:28:29.645699
Epoch:[ 58 18 ] loss: 0.38634368777275085 2022-08-12 00:28:30.067775
Epoch:[ 58 19 ] loss: 0.3867247402667999 2022-08-12 00:28:30.488000
Training_Epoch:[ 58 ] Training_loss: 0.3864307880401611 2022-08-12 00:28:30.488700
learning rate:  0.0017748212499999999
val: 1 0.4031335413455963
val: 2 0.3988249599933624
val: 3 0.40806955099105835
val: 4 0.40041062235832214
val: 5 0.3945370018482208
val: 6 0.40272057056427
val: 7 0.4002477824687958
val: 8 0.4045926332473755
val: 9 0.3984414339065552
val: 10 0.39932310581207275
val: 11 0.40291374921798706
val: 12 0.39899954199790955
val: 13 0.3994160294532776
val: 14 0.40215864777565
val: 15 0.40470024943351746
val: 16 0.40249472856521606
val: 17 0.40573903918266296
val: 18 0.39781537652015686
val: 19 0.39819860458374023
val: 20 0.40288665890693665
val_Epoch:[ 58 ] val_loss: 0.40128119140863416 2022-08-12 00:28:34.066045
start training 2022-08-12 00:28:34.161715
Epoch:[ 59 0 ] loss: 0.38670507073402405 2022-08-12 00:28:48.741367
Epoch:[ 59 1 ] loss: 0.38462725281715393 2022-08-12 00:28:49.162571
Epoch:[ 59 2 ] loss: 0.3847743570804596 2022-08-12 00:28:49.585072
Epoch:[ 59 3 ] loss: 0.38707420229911804 2022-08-12 00:28:50.008290
Epoch:[ 59 4 ] loss: 0.3838021755218506 2022-08-12 00:28:50.434610
Epoch:[ 59 5 ] loss: 0.38475650548934937 2022-08-12 00:28:50.865618
Epoch:[ 59 6 ] loss: 0.3856011629104614 2022-08-12 00:28:51.286061
Epoch:[ 59 7 ] loss: 0.3845036029815674 2022-08-12 00:28:51.710235
Epoch:[ 59 8 ] loss: 0.3834543824195862 2022-08-12 00:28:52.136000
Epoch:[ 59 9 ] loss: 0.3872777223587036 2022-08-12 00:28:52.556400
Epoch:[ 59 10 ] loss: 0.3850519061088562 2022-08-12 00:28:52.984430
Epoch:[ 59 11 ] loss: 0.38318175077438354 2022-08-12 00:28:53.409005
Epoch:[ 59 12 ] loss: 0.38503628969192505 2022-08-12 00:28:53.828891
Epoch:[ 59 13 ] loss: 0.38461655378341675 2022-08-12 00:28:54.242870
Epoch:[ 59 14 ] loss: 0.38618770241737366 2022-08-12 00:28:54.662223
Epoch:[ 59 15 ] loss: 0.3871321976184845 2022-08-12 00:28:55.085758
Epoch:[ 59 16 ] loss: 0.384995698928833 2022-08-12 00:29:00.381578
Epoch:[ 59 17 ] loss: 0.38499340415000916 2022-08-12 00:29:00.794572
Epoch:[ 59 18 ] loss: 0.3849424123764038 2022-08-12 00:29:01.221619
Epoch:[ 59 19 ] loss: 0.3860316574573517 2022-08-12 00:29:01.649996
Training_Epoch:[ 59 ] Training_loss: 0.3852373003959656 2022-08-12 00:29:01.650750
learning rate:  0.0017748212499999999
val: 1 0.40525367856025696
val: 2 0.40502533316612244
val: 3 0.40590912103652954
val: 4 0.397422730922699
val: 5 0.4069407880306244
val: 6 0.4010820984840393
val: 7 0.3968932330608368
val: 8 0.4074700176715851
val: 9 0.40524622797966003
val: 10 0.40121978521347046
val: 11 0.39825695753097534
val: 12 0.40320315957069397
val: 13 0.41020312905311584
val: 14 0.4017188549041748
val: 15 0.39816561341285706
val: 16 0.4043453633785248
val: 17 0.4065784513950348
val: 18 0.411467045545578
val: 19 0.40219631791114807
val: 20 0.41884690523147583
val_Epoch:[ 59 ] val_loss: 0.4043722406029701 2022-08-12 00:29:05.191620
start training 2022-08-12 00:29:05.286329
Epoch:[ 60 0 ] loss: 0.3863396644592285 2022-08-12 00:29:19.836792
Epoch:[ 60 1 ] loss: 0.3845663070678711 2022-08-12 00:29:20.262690
Epoch:[ 60 2 ] loss: 0.3865422308444977 2022-08-12 00:29:20.686897
Epoch:[ 60 3 ] loss: 0.38853520154953003 2022-08-12 00:29:21.112145
Epoch:[ 60 4 ] loss: 0.38570553064346313 2022-08-12 00:29:21.539482
Epoch:[ 60 5 ] loss: 0.3863624930381775 2022-08-12 00:29:21.962573
Epoch:[ 60 6 ] loss: 0.384867399930954 2022-08-12 00:29:22.383594
Epoch:[ 60 7 ] loss: 0.3872745931148529 2022-08-12 00:29:22.797702
Epoch:[ 60 8 ] loss: 0.3838801383972168 2022-08-12 00:29:23.217816
Epoch:[ 60 9 ] loss: 0.3866025507450104 2022-08-12 00:29:23.646194
Epoch:[ 60 10 ] loss: 0.3859421908855438 2022-08-12 00:29:24.072205
Epoch:[ 60 11 ] loss: 0.3869333863258362 2022-08-12 00:29:24.490592
Epoch:[ 60 12 ] loss: 0.3878166079521179 2022-08-12 00:29:24.910873
Epoch:[ 60 13 ] loss: 0.38890841603279114 2022-08-12 00:29:25.335431
Epoch:[ 60 14 ] loss: 0.38824284076690674 2022-08-12 00:29:25.759887
Epoch:[ 60 15 ] loss: 0.38451123237609863 2022-08-12 00:29:26.187111
Epoch:[ 60 16 ] loss: 0.3867730498313904 2022-08-12 00:29:31.245398
Epoch:[ 60 17 ] loss: 0.3877454102039337 2022-08-12 00:29:31.669215
Epoch:[ 60 18 ] loss: 0.38651707768440247 2022-08-12 00:29:32.103067
Epoch:[ 60 19 ] loss: 0.3877604007720947 2022-08-12 00:29:32.526107
Training_Epoch:[ 60 ] Training_loss: 0.38659133613109586 2022-08-12 00:29:32.526788
learning rate:  0.0017748212499999999
netparams have been saved once 60
val: 1 0.40201807022094727
val: 2 0.40468406677246094
val: 3 0.4038752019405365
val: 4 0.40026214718818665
val: 5 0.4034443795681
val: 6 0.4048309326171875
val: 7 0.4051428735256195
val: 8 0.41233938932418823
val: 9 0.41757142543792725
val: 10 0.3963736891746521
val: 11 0.4077134430408478
val: 12 0.4166625440120697
val: 13 0.40919846296310425
val: 14 0.3965173363685608
val: 15 0.41341516375541687
val: 16 0.40232592821121216
val: 17 0.40831300616264343
val: 18 0.40748733282089233
val: 19 0.40446779131889343
val: 20 0.40455353260040283
val_Epoch:[ 60 ] val_loss: 0.4060598358511925 2022-08-12 00:29:36.138429
start training 2022-08-12 00:29:36.235942
Epoch:[ 61 0 ] loss: 0.3867771625518799 2022-08-12 00:29:50.332843
Epoch:[ 61 1 ] loss: 0.3846639394760132 2022-08-12 00:29:51.171980
Epoch:[ 61 2 ] loss: 0.3852406144142151 2022-08-12 00:29:51.598858
Epoch:[ 61 3 ] loss: 0.38500526547431946 2022-08-12 00:29:52.028570
Epoch:[ 61 4 ] loss: 0.38672107458114624 2022-08-12 00:29:52.452364
Epoch:[ 61 5 ] loss: 0.3847919702529907 2022-08-12 00:29:52.874206
Epoch:[ 61 6 ] loss: 0.3851161599159241 2022-08-12 00:29:53.292040
Epoch:[ 61 7 ] loss: 0.38385918736457825 2022-08-12 00:29:53.716998
Epoch:[ 61 8 ] loss: 0.3853907585144043 2022-08-12 00:29:54.139957
Epoch:[ 61 9 ] loss: 0.386446475982666 2022-08-12 00:29:54.566301
Epoch:[ 61 10 ] loss: 0.38604408502578735 2022-08-12 00:29:54.985392
Epoch:[ 61 11 ] loss: 0.38702893257141113 2022-08-12 00:29:55.401677
Epoch:[ 61 12 ] loss: 0.3857821822166443 2022-08-12 00:29:55.823529
Epoch:[ 61 13 ] loss: 0.3867776095867157 2022-08-12 00:29:56.246445
Epoch:[ 61 14 ] loss: 0.38781261444091797 2022-08-12 00:29:56.676797
Epoch:[ 61 15 ] loss: 0.3852774202823639 2022-08-12 00:29:57.094544
Epoch:[ 61 16 ] loss: 0.3842453360557556 2022-08-12 00:30:02.328836
Epoch:[ 61 17 ] loss: 0.38516730070114136 2022-08-12 00:30:02.895692
Epoch:[ 61 18 ] loss: 0.3843325674533844 2022-08-12 00:30:03.311731
Epoch:[ 61 19 ] loss: 0.3835034668445587 2022-08-12 00:30:03.732096
Training_Epoch:[ 61 ] Training_loss: 0.3854992061853409 2022-08-12 00:30:03.732751
learning rate:  0.0015085980624999999
val: 1 0.3893967866897583
val: 2 0.3947165310382843
val: 3 0.39303067326545715
val: 4 0.39739322662353516
val: 5 0.3922954201698303
val: 6 0.391583114862442
val: 7 0.4009120762348175
val: 8 0.39443278312683105
val: 9 0.3949091136455536
val: 10 0.3945716619491577
val: 11 0.3941391408443451
val: 12 0.4001116454601288
val: 13 0.39467841386795044
val: 14 0.40215030312538147
val: 15 0.3984748423099518
val: 16 0.3969859480857849
val: 17 0.3938913345336914
val: 18 0.39807119965553284
val: 19 0.3926834464073181
val: 20 0.4002085030078888
val_Epoch:[ 61 ] val_loss: 0.39573180824518206 2022-08-12 00:30:07.315457
start training 2022-08-12 00:30:07.411010
Epoch:[ 62 0 ] loss: 0.3827870488166809 2022-08-12 00:30:22.382173
Epoch:[ 62 1 ] loss: 0.38258129358291626 2022-08-12 00:30:22.806268
Epoch:[ 62 2 ] loss: 0.3834611475467682 2022-08-12 00:30:23.228448
Epoch:[ 62 3 ] loss: 0.38311150670051575 2022-08-12 00:30:23.652250
Epoch:[ 62 4 ] loss: 0.3832692801952362 2022-08-12 00:30:24.065324
Epoch:[ 62 5 ] loss: 0.383703351020813 2022-08-12 00:30:24.491643
Epoch:[ 62 6 ] loss: 0.3819780647754669 2022-08-12 00:30:24.919390
Epoch:[ 62 7 ] loss: 0.3844766616821289 2022-08-12 00:30:25.338735
Epoch:[ 62 8 ] loss: 0.3817928731441498 2022-08-12 00:30:25.754883
Epoch:[ 62 9 ] loss: 0.3836776614189148 2022-08-12 00:30:26.178772
Epoch:[ 62 10 ] loss: 0.3824167847633362 2022-08-12 00:30:26.605885
Epoch:[ 62 11 ] loss: 0.3828085958957672 2022-08-12 00:30:27.032328
Epoch:[ 62 12 ] loss: 0.38401904702186584 2022-08-12 00:30:27.455681
Epoch:[ 62 13 ] loss: 0.384472131729126 2022-08-12 00:30:27.878938
Epoch:[ 62 14 ] loss: 0.3820067048072815 2022-08-12 00:30:28.298237
Epoch:[ 62 15 ] loss: 0.3827146291732788 2022-08-12 00:30:28.727323
Epoch:[ 62 16 ] loss: 0.38394543528556824 2022-08-12 00:30:34.809691
Epoch:[ 62 17 ] loss: 0.3812783658504486 2022-08-12 00:30:35.233823
Epoch:[ 62 18 ] loss: 0.3833121955394745 2022-08-12 00:30:35.661764
Epoch:[ 62 19 ] loss: 0.3836994469165802 2022-08-12 00:30:36.087911
Training_Epoch:[ 62 ] Training_loss: 0.3830756112933159 2022-08-12 00:30:36.088696
learning rate:  0.0015085980624999999
val: 1 0.39811405539512634
val: 2 0.40112876892089844
val: 3 0.401563435792923
val: 4 0.40545007586479187
val: 5 0.4028741717338562
val: 6 0.39901798963546753
val: 7 0.4030177593231201
val: 8 0.40257886052131653
val: 9 0.4049714207649231
val: 10 0.3958418369293213
val: 11 0.39643144607543945
val: 12 0.3982277512550354
val: 13 0.39632779359817505
val: 14 0.4104432165622711
val: 15 0.3991040885448456
val: 16 0.3960248529911041
val: 17 0.40350341796875
val: 18 0.39897119998931885
val: 19 0.39488545060157776
val: 20 0.3982395827770233
val_Epoch:[ 62 ] val_loss: 0.40033585876226424 2022-08-12 00:30:39.661747
start training 2022-08-12 00:30:39.760734
Epoch:[ 63 0 ] loss: 0.3827587962150574 2022-08-12 00:30:54.356579
Epoch:[ 63 1 ] loss: 0.3809819221496582 2022-08-12 00:30:54.779082
Epoch:[ 63 2 ] loss: 0.3809332251548767 2022-08-12 00:30:55.202571
Epoch:[ 63 3 ] loss: 0.38437262177467346 2022-08-12 00:30:55.627523
Epoch:[ 63 4 ] loss: 0.3838052749633789 2022-08-12 00:30:56.049926
Epoch:[ 63 5 ] loss: 0.3855114281177521 2022-08-12 00:30:56.464028
Epoch:[ 63 6 ] loss: 0.3837883770465851 2022-08-12 00:30:56.887737
Epoch:[ 63 7 ] loss: 0.38327842950820923 2022-08-12 00:30:57.318335
Epoch:[ 63 8 ] loss: 0.3830808699131012 2022-08-12 00:30:57.735508
Epoch:[ 63 9 ] loss: 0.3811817765235901 2022-08-12 00:30:58.156704
Epoch:[ 63 10 ] loss: 0.3840426802635193 2022-08-12 00:30:58.579379
Epoch:[ 63 11 ] loss: 0.384070485830307 2022-08-12 00:30:59.009574
Epoch:[ 63 12 ] loss: 0.38448020815849304 2022-08-12 00:30:59.430878
Epoch:[ 63 13 ] loss: 0.384947270154953 2022-08-12 00:30:59.856648
Epoch:[ 63 14 ] loss: 0.38372308015823364 2022-08-12 00:31:00.285438
Epoch:[ 63 15 ] loss: 0.3843487799167633 2022-08-12 00:31:00.698662
Epoch:[ 63 16 ] loss: 0.3822098970413208 2022-08-12 00:31:05.729938
Epoch:[ 63 17 ] loss: 0.3839552700519562 2022-08-12 00:31:06.159808
Epoch:[ 63 18 ] loss: 0.38396313786506653 2022-08-12 00:31:06.586952
Epoch:[ 63 19 ] loss: 0.38347241282463074 2022-08-12 00:31:07.010511
Training_Epoch:[ 63 ] Training_loss: 0.3834452971816063 2022-08-12 00:31:07.011218
learning rate:  0.0015085980624999999
val: 1 0.395216166973114
val: 2 0.3984867334365845
val: 3 0.39759987592697144
val: 4 0.39398470520973206
val: 5 0.39181196689605713
val: 6 0.39233848452568054
val: 7 0.3914317190647125
val: 8 0.4036369025707245
val: 9 0.3895412087440491
val: 10 0.3920935094356537
val: 11 0.3999003767967224
val: 12 0.3998991549015045
val: 13 0.39503198862075806
val: 14 0.39816969633102417
val: 15 0.39807015657424927
val: 16 0.3998543620109558
val: 17 0.38998275995254517
val: 18 0.3963814973831177
val: 19 0.3916149437427521
val: 20 0.39856410026550293
val_Epoch:[ 63 ] val_loss: 0.39568051546812055 2022-08-12 00:31:10.626770
start training 2022-08-12 00:31:10.727776
Epoch:[ 64 0 ] loss: 0.38088086247444153 2022-08-12 00:31:24.992463
Epoch:[ 64 1 ] loss: 0.38081789016723633 2022-08-12 00:31:25.668796
Epoch:[ 64 2 ] loss: 0.38303759694099426 2022-08-12 00:31:26.089316
Epoch:[ 64 3 ] loss: 0.3822054862976074 2022-08-12 00:31:26.509971
Epoch:[ 64 4 ] loss: 0.38285157084465027 2022-08-12 00:31:26.930762
Epoch:[ 64 5 ] loss: 0.3826316297054291 2022-08-12 00:31:27.357789
Epoch:[ 64 6 ] loss: 0.3819938600063324 2022-08-12 00:31:27.785426
Epoch:[ 64 7 ] loss: 0.3827207684516907 2022-08-12 00:31:28.202070
Epoch:[ 64 8 ] loss: 0.3828972578048706 2022-08-12 00:31:28.626263
Epoch:[ 64 9 ] loss: 0.38453492522239685 2022-08-12 00:31:29.047889
Epoch:[ 64 10 ] loss: 0.38510847091674805 2022-08-12 00:31:29.473841
Epoch:[ 64 11 ] loss: 0.3823632597923279 2022-08-12 00:31:29.896824
Epoch:[ 64 12 ] loss: 0.385113000869751 2022-08-12 00:31:30.321266
Epoch:[ 64 13 ] loss: 0.3840220868587494 2022-08-12 00:31:30.745938
Epoch:[ 64 14 ] loss: 0.38334178924560547 2022-08-12 00:31:31.170328
Epoch:[ 64 15 ] loss: 0.38604554533958435 2022-08-12 00:31:31.584391
Epoch:[ 64 16 ] loss: 0.3856523334980011 2022-08-12 00:31:36.757405
Epoch:[ 64 17 ] loss: 0.38185861706733704 2022-08-12 00:31:37.179550
Epoch:[ 64 18 ] loss: 0.3842155635356903 2022-08-12 00:31:37.599961
Epoch:[ 64 19 ] loss: 0.3839949071407318 2022-08-12 00:31:38.015391
Training_Epoch:[ 64 ] Training_loss: 0.3833143711090088 2022-08-12 00:31:38.016097
learning rate:  0.0015085980624999999
val: 1 0.39978787302970886
val: 2 0.3992765545845032
val: 3 0.39907801151275635
val: 4 0.3978863060474396
val: 5 0.39582163095474243
val: 6 0.39647769927978516
val: 7 0.396695613861084
val: 8 0.39782217144966125
val: 9 0.40012383460998535
val: 10 0.40080973505973816
val: 11 0.39668938517570496
val: 12 0.3965308368206024
val: 13 0.3986416161060333
val: 14 0.3910401463508606
val: 15 0.39481282234191895
val: 16 0.3915700316429138
val: 17 0.397320955991745
val: 18 0.39221081137657166
val: 19 0.39717939496040344
val: 20 0.3981770873069763
val_Epoch:[ 64 ] val_loss: 0.39689762592315675 2022-08-12 00:31:41.682478
start training 2022-08-12 00:31:41.777293
Epoch:[ 65 0 ] loss: 0.381675660610199 2022-08-12 00:31:55.957660
Epoch:[ 65 1 ] loss: 0.38437873125076294 2022-08-12 00:31:56.632835
Epoch:[ 65 2 ] loss: 0.38233333826065063 2022-08-12 00:31:57.058941
Epoch:[ 65 3 ] loss: 0.3830314874649048 2022-08-12 00:31:57.479030
Epoch:[ 65 4 ] loss: 0.3823212683200836 2022-08-12 00:31:57.904939
Epoch:[ 65 5 ] loss: 0.382124125957489 2022-08-12 00:31:58.325823
Epoch:[ 65 6 ] loss: 0.3820052742958069 2022-08-12 00:31:58.750582
Epoch:[ 65 7 ] loss: 0.38048598170280457 2022-08-12 00:31:59.176488
Epoch:[ 65 8 ] loss: 0.3817921578884125 2022-08-12 00:31:59.598649
Epoch:[ 65 9 ] loss: 0.38328486680984497 2022-08-12 00:32:00.016182
Epoch:[ 65 10 ] loss: 0.38109225034713745 2022-08-12 00:32:00.438345
Epoch:[ 65 11 ] loss: 0.3837847113609314 2022-08-12 00:32:00.861619
Epoch:[ 65 12 ] loss: 0.38157904148101807 2022-08-12 00:32:01.280167
Epoch:[ 65 13 ] loss: 0.38401710987091064 2022-08-12 00:32:01.694822
Epoch:[ 65 14 ] loss: 0.3875656723976135 2022-08-12 00:32:02.121949
Epoch:[ 65 15 ] loss: 0.3801920413970947 2022-08-12 00:32:02.550024
Epoch:[ 65 16 ] loss: 0.3830677568912506 2022-08-12 00:32:07.624596
Epoch:[ 65 17 ] loss: 0.381339430809021 2022-08-12 00:32:08.052174
Epoch:[ 65 18 ] loss: 0.38352498412132263 2022-08-12 00:32:08.473586
Epoch:[ 65 19 ] loss: 0.38065996766090393 2022-08-12 00:32:08.898708
Training_Epoch:[ 65 ] Training_loss: 0.38251279294490814 2022-08-12 00:32:08.899413
learning rate:  0.0015085980624999999
val: 1 0.40402352809906006
val: 2 0.3995766043663025
val: 3 0.3944472670555115
val: 4 0.40435224771499634
val: 5 0.40871670842170715
val: 6 0.4029541015625
val: 7 0.4021008610725403
val: 8 0.40394821763038635
val: 9 0.39627131819725037
val: 10 0.4093101918697357
val: 11 0.403437077999115
val: 12 0.4063986837863922
val: 13 0.40838339924812317
val: 14 0.4018678367137909
val: 15 0.39730826020240784
val: 16 0.39984074234962463
val: 17 0.3991178870201111
val: 18 0.405719131231308
val: 19 0.40353265404701233
val: 20 0.3945857882499695
val_Epoch:[ 65 ] val_loss: 0.40229462534189225 2022-08-12 00:32:12.388682
start training 2022-08-12 00:32:12.486507
Epoch:[ 66 0 ] loss: 0.38282597064971924 2022-08-12 00:32:27.240299
Epoch:[ 66 1 ] loss: 0.38139408826828003 2022-08-12 00:32:27.656159
Epoch:[ 66 2 ] loss: 0.3819578289985657 2022-08-12 00:32:28.081817
Epoch:[ 66 3 ] loss: 0.3822353184223175 2022-08-12 00:32:28.512717
Epoch:[ 66 4 ] loss: 0.3829338252544403 2022-08-12 00:32:28.935194
Epoch:[ 66 5 ] loss: 0.38342049717903137 2022-08-12 00:32:29.354510
Epoch:[ 66 6 ] loss: 0.3850352168083191 2022-08-12 00:32:29.778166
Epoch:[ 66 7 ] loss: 0.3840862512588501 2022-08-12 00:32:30.201922
Epoch:[ 66 8 ] loss: 0.38175204396247864 2022-08-12 00:32:30.626798
Epoch:[ 66 9 ] loss: 0.3834187388420105 2022-08-12 00:32:31.052042
Epoch:[ 66 10 ] loss: 0.38629379868507385 2022-08-12 00:32:31.477571
Epoch:[ 66 11 ] loss: 0.3833628296852112 2022-08-12 00:32:31.898454
Epoch:[ 66 12 ] loss: 0.3854511082172394 2022-08-12 00:32:32.315383
Epoch:[ 66 13 ] loss: 0.3840424418449402 2022-08-12 00:32:32.734258
Epoch:[ 66 14 ] loss: 0.3848463296890259 2022-08-12 00:32:33.166256
Epoch:[ 66 15 ] loss: 0.3863324224948883 2022-08-12 00:32:33.587606
Epoch:[ 66 16 ] loss: 0.3840809166431427 2022-08-12 00:32:39.050056
Epoch:[ 66 17 ] loss: 0.3839103877544403 2022-08-12 00:32:39.473165
Epoch:[ 66 18 ] loss: 0.38377806544303894 2022-08-12 00:32:39.898842
Epoch:[ 66 19 ] loss: 0.38360413908958435 2022-08-12 00:32:40.317507
Training_Epoch:[ 66 ] Training_loss: 0.38373811095952987 2022-08-12 00:32:40.318191
learning rate:  0.0015085980624999999
val: 1 0.39802640676498413
val: 2 0.3987725079059601
val: 3 0.3982691764831543
val: 4 0.39013832807540894
val: 5 0.3981587588787079
val: 6 0.39875826239585876
val: 7 0.39193204045295715
val: 8 0.40719443559646606
val: 9 0.39886578917503357
val: 10 0.3990342319011688
val: 11 0.394117146730423
val: 12 0.393383264541626
val: 13 0.3992193937301636
val: 14 0.4012398421764374
val: 15 0.39620715379714966
val: 16 0.4014093279838562
val: 17 0.3947732150554657
val: 18 0.40101656317710876
val: 19 0.3960071802139282
val: 20 0.40130317211151123
val_Epoch:[ 66 ] val_loss: 0.3978913098573685 2022-08-12 00:32:43.828795
start training 2022-08-12 00:32:43.926115
Epoch:[ 67 0 ] loss: 0.38084331154823303 2022-08-12 00:32:58.462987
Epoch:[ 67 1 ] loss: 0.38243308663368225 2022-08-12 00:32:58.889272
Epoch:[ 67 2 ] loss: 0.3792954683303833 2022-08-12 00:32:59.312720
Epoch:[ 67 3 ] loss: 0.38252466917037964 2022-08-12 00:32:59.737989
Epoch:[ 67 4 ] loss: 0.37968364357948303 2022-08-12 00:33:00.162239
Epoch:[ 67 5 ] loss: 0.3833466172218323 2022-08-12 00:33:00.582567
Epoch:[ 67 6 ] loss: 0.38128936290740967 2022-08-12 00:33:00.995295
Epoch:[ 67 7 ] loss: 0.38193342089653015 2022-08-12 00:33:01.417007
Epoch:[ 67 8 ] loss: 0.38449254631996155 2022-08-12 00:33:01.847544
Epoch:[ 67 9 ] loss: 0.382508784532547 2022-08-12 00:33:02.266051
Epoch:[ 67 10 ] loss: 0.38266721367836 2022-08-12 00:33:02.680509
Epoch:[ 67 11 ] loss: 0.38261279463768005 2022-08-12 00:33:03.106575
Epoch:[ 67 12 ] loss: 0.3823606073856354 2022-08-12 00:33:03.533578
Epoch:[ 67 13 ] loss: 0.381794810295105 2022-08-12 00:33:03.956705
Epoch:[ 67 14 ] loss: 0.3853963017463684 2022-08-12 00:33:04.376857
Epoch:[ 67 15 ] loss: 0.3820587992668152 2022-08-12 00:33:04.801020
Epoch:[ 67 16 ] loss: 0.38427963852882385 2022-08-12 00:33:10.245412
Epoch:[ 67 17 ] loss: 0.38156765699386597 2022-08-12 00:33:10.673318
Epoch:[ 67 18 ] loss: 0.3822089433670044 2022-08-12 00:33:11.098270
Epoch:[ 67 19 ] loss: 0.382539302110672 2022-08-12 00:33:11.516863
Training_Epoch:[ 67 ] Training_loss: 0.3822918489575386 2022-08-12 00:33:11.517521
learning rate:  0.0015085980624999999
val: 1 0.39734214544296265
val: 2 0.4053347706794739
val: 3 0.4027767777442932
val: 4 0.3972490429878235
val: 5 0.40081632137298584
val: 6 0.40209895372390747
val: 7 0.39941003918647766
val: 8 0.403691828250885
val: 9 0.39712560176849365
val: 10 0.394961953163147
val: 11 0.4060075283050537
val: 12 0.39344626665115356
val: 13 0.4005126655101776
val: 14 0.3990456163883209
val: 15 0.3969743549823761
val: 16 0.4017173647880554
val: 17 0.39250481128692627
val: 18 0.4027555584907532
val: 19 0.3946850299835205
val: 20 0.3933110535144806
val_Epoch:[ 67 ] val_loss: 0.3990883842110634 2022-08-12 00:33:15.136811
start training 2022-08-12 00:33:15.237196
Epoch:[ 68 0 ] loss: 0.3815944790840149 2022-08-12 00:33:29.959242
Epoch:[ 68 1 ] loss: 0.37940001487731934 2022-08-12 00:33:30.402774
Epoch:[ 68 2 ] loss: 0.38196131587028503 2022-08-12 00:33:30.827765
Epoch:[ 68 3 ] loss: 0.3831167221069336 2022-08-12 00:33:31.250321
Epoch:[ 68 4 ] loss: 0.37957659363746643 2022-08-12 00:33:31.674275
Epoch:[ 68 5 ] loss: 0.3792245388031006 2022-08-12 00:33:32.096016
Epoch:[ 68 6 ] loss: 0.38068339228630066 2022-08-12 00:33:32.522228
Epoch:[ 68 7 ] loss: 0.381552129983902 2022-08-12 00:33:32.941029
Epoch:[ 68 8 ] loss: 0.38031625747680664 2022-08-12 00:33:33.357269
Epoch:[ 68 9 ] loss: 0.38078081607818604 2022-08-12 00:33:33.777555
Epoch:[ 68 10 ] loss: 0.37944188714027405 2022-08-12 00:33:34.210363
Epoch:[ 68 11 ] loss: 0.38125643134117126 2022-08-12 00:33:34.631927
Epoch:[ 68 12 ] loss: 0.38133618235588074 2022-08-12 00:33:35.049592
Epoch:[ 68 13 ] loss: 0.38278496265411377 2022-08-12 00:33:35.470206
Epoch:[ 68 14 ] loss: 0.3808162808418274 2022-08-12 00:33:35.897008
Epoch:[ 68 15 ] loss: 0.3799869418144226 2022-08-12 00:33:36.320787
Epoch:[ 68 16 ] loss: 0.3807496130466461 2022-08-12 00:33:41.520821
Epoch:[ 68 17 ] loss: 0.37996289134025574 2022-08-12 00:33:41.944398
Epoch:[ 68 18 ] loss: 0.38225024938583374 2022-08-12 00:33:42.371623
Epoch:[ 68 19 ] loss: 0.38246381282806396 2022-08-12 00:33:42.789734
Training_Epoch:[ 68 ] Training_loss: 0.38096277564764025 2022-08-12 00:33:42.790411
learning rate:  0.0015085980624999999
val: 1 0.3992474675178528
val: 2 0.41419878602027893
val: 3 0.4016110599040985
val: 4 0.4073326289653778
val: 5 0.39947956800460815
val: 6 0.39365994930267334
val: 7 0.40037479996681213
val: 8 0.3966338038444519
val: 9 0.4045341908931732
val: 10 0.39541715383529663
val: 11 0.39177533984184265
val: 12 0.4038918614387512
val: 13 0.395250529050827
val: 14 0.39648857712745667
val: 15 0.39935562014579773
val: 16 0.4009765088558197
val: 17 0.4019269049167633
val: 18 0.40251806378364563
val: 19 0.3950299322605133
val: 20 0.4032416045665741
val_Epoch:[ 68 ] val_loss: 0.4001472175121307 2022-08-12 00:33:46.285140
start training 2022-08-12 00:33:46.383736
Epoch:[ 69 0 ] loss: 0.3821498453617096 2022-08-12 00:34:00.883360
Epoch:[ 69 1 ] loss: 0.380071759223938 2022-08-12 00:34:01.304650
Epoch:[ 69 2 ] loss: 0.3783247470855713 2022-08-12 00:34:01.730401
Epoch:[ 69 3 ] loss: 0.3808821737766266 2022-08-12 00:34:02.156382
Epoch:[ 69 4 ] loss: 0.3824886679649353 2022-08-12 00:34:02.577032
Epoch:[ 69 5 ] loss: 0.3819338083267212 2022-08-12 00:34:03.002658
Epoch:[ 69 6 ] loss: 0.38092052936553955 2022-08-12 00:34:03.426746
Epoch:[ 69 7 ] loss: 0.38426798582077026 2022-08-12 00:34:03.848705
Epoch:[ 69 8 ] loss: 0.3831706643104553 2022-08-12 00:34:04.275451
Epoch:[ 69 9 ] loss: 0.3813706636428833 2022-08-12 00:34:04.699958
Epoch:[ 69 10 ] loss: 0.38155505061149597 2022-08-12 00:34:05.124610
Epoch:[ 69 11 ] loss: 0.38376134634017944 2022-08-12 00:34:05.546349
Epoch:[ 69 12 ] loss: 0.38179177045822144 2022-08-12 00:34:05.966558
Epoch:[ 69 13 ] loss: 0.3848268985748291 2022-08-12 00:34:06.392680
Epoch:[ 69 14 ] loss: 0.3830645978450775 2022-08-12 00:34:06.816080
Epoch:[ 69 15 ] loss: 0.38367804884910583 2022-08-12 00:34:07.235086
Epoch:[ 69 16 ] loss: 0.38286811113357544 2022-08-12 00:34:12.393220
Epoch:[ 69 17 ] loss: 0.38516587018966675 2022-08-12 00:34:12.816564
Epoch:[ 69 18 ] loss: 0.3827231824398041 2022-08-12 00:34:13.246024
Epoch:[ 69 19 ] loss: 0.3831334710121155 2022-08-12 00:34:13.665712
Training_Epoch:[ 69 ] Training_loss: 0.38240745961666106 2022-08-12 00:34:13.666373
learning rate:  0.0015085980624999999
val: 1 0.4035443961620331
val: 2 0.4066658020019531
val: 3 0.4049952030181885
val: 4 0.40269196033477783
val: 5 0.4071929156780243
val: 6 0.4114531874656677
val: 7 0.398987352848053
val: 8 0.4010181725025177
val: 9 0.40487489104270935
val: 10 0.40444356203079224
val: 11 0.40526580810546875
val: 12 0.40856826305389404
val: 13 0.4099086821079254
val: 14 0.4108283519744873
val: 15 0.4080899655818939
val: 16 0.40855687856674194
val: 17 0.4086188077926636
val: 18 0.40685027837753296
val: 19 0.40123552083969116
val: 20 0.4070194363594055
val_Epoch:[ 69 ] val_loss: 0.4060404717922211 2022-08-12 00:34:17.206968
start training 2022-08-12 00:34:17.304295
Epoch:[ 70 0 ] loss: 0.3824933171272278 2022-08-12 00:34:31.845548
Epoch:[ 70 1 ] loss: 0.380311518907547 2022-08-12 00:34:32.284604
Epoch:[ 70 2 ] loss: 0.38252371549606323 2022-08-12 00:34:32.711944
Epoch:[ 70 3 ] loss: 0.38221311569213867 2022-08-12 00:34:33.130609
Epoch:[ 70 4 ] loss: 0.38243937492370605 2022-08-12 00:34:33.555483
Epoch:[ 70 5 ] loss: 0.38281190395355225 2022-08-12 00:34:33.980867
Epoch:[ 70 6 ] loss: 0.38312751054763794 2022-08-12 00:34:34.409636
Epoch:[ 70 7 ] loss: 0.3827573359012604 2022-08-12 00:34:34.831317
Epoch:[ 70 8 ] loss: 0.3835156559944153 2022-08-12 00:34:35.253705
Epoch:[ 70 9 ] loss: 0.3816535174846649 2022-08-12 00:34:35.676305
Epoch:[ 70 10 ] loss: 0.3835982382297516 2022-08-12 00:34:36.099429
Epoch:[ 70 11 ] loss: 0.38405555486679077 2022-08-12 00:34:36.525843
Epoch:[ 70 12 ] loss: 0.3836156725883484 2022-08-12 00:34:36.948815
Epoch:[ 70 13 ] loss: 0.3833993077278137 2022-08-12 00:34:37.375048
Epoch:[ 70 14 ] loss: 0.38284286856651306 2022-08-12 00:34:37.792961
Epoch:[ 70 15 ] loss: 0.38144150376319885 2022-08-12 00:34:38.208978
Epoch:[ 70 16 ] loss: 0.3826184868812561 2022-08-12 00:34:43.480426
Epoch:[ 70 17 ] loss: 0.3811286389827728 2022-08-12 00:34:43.898670
Epoch:[ 70 18 ] loss: 0.3826204240322113 2022-08-12 00:34:44.325436
Epoch:[ 70 19 ] loss: 0.3824826776981354 2022-08-12 00:34:44.748119
Training_Epoch:[ 70 ] Training_loss: 0.3825825169682503 2022-08-12 00:34:44.748835
learning rate:  0.0015085980624999999
netparams have been saved once 70
val: 1 0.3939080536365509
val: 2 0.3966694474220276
val: 3 0.3983449339866638
val: 4 0.39713725447654724
val: 5 0.3914724290370941
val: 6 0.399585485458374
val: 7 0.3981470465660095
val: 8 0.39046886563301086
val: 9 0.3946830630302429
val: 10 0.39732733368873596
val: 11 0.39922434091567993
val: 12 0.39687833189964294
val: 13 0.39458146691322327
val: 14 0.3934570848941803
val: 15 0.39913317561149597
val: 16 0.3976356089115143
val: 17 0.3963925838470459
val: 18 0.3939239978790283
val: 19 0.39589935541152954
val: 20 0.39175570011138916
val_Epoch:[ 70 ] val_loss: 0.3958312779664993 2022-08-12 00:34:48.439126
start training 2022-08-12 00:34:48.535194
Epoch:[ 71 0 ] loss: 0.37955254316329956 2022-08-12 00:35:02.963413
Epoch:[ 71 1 ] loss: 0.38043299317359924 2022-08-12 00:35:03.410541
Epoch:[ 71 2 ] loss: 0.3805588185787201 2022-08-12 00:35:03.836569
Epoch:[ 71 3 ] loss: 0.37864595651626587 2022-08-12 00:35:04.255646
Epoch:[ 71 4 ] loss: 0.38077449798583984 2022-08-12 00:35:04.680041
Epoch:[ 71 5 ] loss: 0.38012197613716125 2022-08-12 00:35:05.104546
Epoch:[ 71 6 ] loss: 0.3807336986064911 2022-08-12 00:35:05.528502
Epoch:[ 71 7 ] loss: 0.3809709846973419 2022-08-12 00:35:05.954335
Epoch:[ 71 8 ] loss: 0.37880975008010864 2022-08-12 00:35:06.383832
Epoch:[ 71 9 ] loss: 0.3800062835216522 2022-08-12 00:35:06.799155
Epoch:[ 71 10 ] loss: 0.3797212541103363 2022-08-12 00:35:07.223992
Epoch:[ 71 11 ] loss: 0.3781270682811737 2022-08-12 00:35:07.649086
Epoch:[ 71 12 ] loss: 0.3817461431026459 2022-08-12 00:35:08.070580
Epoch:[ 71 13 ] loss: 0.3806910812854767 2022-08-12 00:35:08.486324
Epoch:[ 71 14 ] loss: 0.37922751903533936 2022-08-12 00:35:08.912518
Epoch:[ 71 15 ] loss: 0.37879520654678345 2022-08-12 00:35:09.339306
Epoch:[ 71 16 ] loss: 0.3814026415348053 2022-08-12 00:35:14.563998
Epoch:[ 71 17 ] loss: 0.379795104265213 2022-08-12 00:35:14.978397
Epoch:[ 71 18 ] loss: 0.3795337677001953 2022-08-12 00:35:15.404774
Epoch:[ 71 19 ] loss: 0.37968701124191284 2022-08-12 00:35:15.833250
Training_Epoch:[ 71 ] Training_loss: 0.3799667149782181 2022-08-12 00:35:15.833992
learning rate:  0.0012823083531249997
val: 1 0.4062947928905487
val: 2 0.4053904712200165
val: 3 0.39582911133766174
val: 4 0.3973916471004486
val: 5 0.4018462598323822
val: 6 0.39910081028938293
val: 7 0.3947049677371979
val: 8 0.39797443151474
val: 9 0.40118783712387085
val: 10 0.3991810083389282
val: 11 0.4008423686027527
val: 12 0.4074952304363251
val: 13 0.404697984457016
val: 14 0.40632376074790955
val: 15 0.398863822221756
val: 16 0.40113121271133423
val: 17 0.4042753279209137
val: 18 0.39925575256347656
val: 19 0.39928728342056274
val: 20 0.39357563853263855
val_Epoch:[ 71 ] val_loss: 0.4007324859499931 2022-08-12 00:35:19.509349
start training 2022-08-12 00:35:19.606380
Epoch:[ 72 0 ] loss: 0.3792719542980194 2022-08-12 00:35:34.366651
Epoch:[ 72 1 ] loss: 0.37849605083465576 2022-08-12 00:35:34.790368
Epoch:[ 72 2 ] loss: 0.3788161873817444 2022-08-12 00:35:35.214603
Epoch:[ 72 3 ] loss: 0.3788296580314636 2022-08-12 00:35:35.635206
Epoch:[ 72 4 ] loss: 0.37941238284111023 2022-08-12 00:35:36.063003
Epoch:[ 72 5 ] loss: 0.38067466020584106 2022-08-12 00:35:36.489934
Epoch:[ 72 6 ] loss: 0.3811023533344269 2022-08-12 00:35:36.906705
Epoch:[ 72 7 ] loss: 0.3779669404029846 2022-08-12 00:35:37.332829
Epoch:[ 72 8 ] loss: 0.3824135661125183 2022-08-12 00:35:37.757869
Epoch:[ 72 9 ] loss: 0.3809678554534912 2022-08-12 00:35:38.182474
Epoch:[ 72 10 ] loss: 0.38265764713287354 2022-08-12 00:35:38.603163
Epoch:[ 72 11 ] loss: 0.37960824370384216 2022-08-12 00:35:39.026693
Epoch:[ 72 12 ] loss: 0.37968865036964417 2022-08-12 00:35:39.449035
Epoch:[ 72 13 ] loss: 0.38113659620285034 2022-08-12 00:35:39.874763
Epoch:[ 72 14 ] loss: 0.37939903140068054 2022-08-12 00:35:40.302010
Epoch:[ 72 15 ] loss: 0.3788561522960663 2022-08-12 00:35:40.725489
Epoch:[ 72 16 ] loss: 0.37838125228881836 2022-08-12 00:35:46.060629
Epoch:[ 72 17 ] loss: 0.380410373210907 2022-08-12 00:35:46.482522
Epoch:[ 72 18 ] loss: 0.38181227445602417 2022-08-12 00:35:46.903113
Epoch:[ 72 19 ] loss: 0.37961387634277344 2022-08-12 00:35:47.326681
Training_Epoch:[ 72 ] Training_loss: 0.3799757853150368 2022-08-12 00:35:47.327429
learning rate:  0.0012823083531249997
val: 1 0.3958689570426941
val: 2 0.3936041593551636
val: 3 0.39654073119163513
val: 4 0.3953443467617035
val: 5 0.39935654401779175
val: 6 0.3943006098270416
val: 7 0.3985206186771393
val: 8 0.3972346782684326
val: 9 0.39937537908554077
val: 10 0.3933277726173401
val: 11 0.3979327082633972
val: 12 0.39497262239456177
val: 13 0.3960065543651581
val: 14 0.38907700777053833
val: 15 0.4010063409805298
val: 16 0.38840922713279724
val: 17 0.40501853823661804
val: 18 0.3889961838722229
val: 19 0.3940742313861847
val: 20 0.3854089081287384
val_Epoch:[ 72 ] val_loss: 0.39521880596876147 2022-08-12 00:35:50.883514
start training 2022-08-12 00:35:50.983229
Epoch:[ 73 0 ] loss: 0.37956908345222473 2022-08-12 00:36:05.558207
Epoch:[ 73 1 ] loss: 0.37877193093299866 2022-08-12 00:36:05.998017
Epoch:[ 73 2 ] loss: 0.3804212212562561 2022-08-12 00:36:06.427356
Epoch:[ 73 3 ] loss: 0.378647118806839 2022-08-12 00:36:06.855627
Epoch:[ 73 4 ] loss: 0.3801981806755066 2022-08-12 00:36:07.272341
Epoch:[ 73 5 ] loss: 0.379508376121521 2022-08-12 00:36:07.686752
Epoch:[ 73 6 ] loss: 0.37942230701446533 2022-08-12 00:36:08.109017
Epoch:[ 73 7 ] loss: 0.3790026307106018 2022-08-12 00:36:08.538968
Epoch:[ 73 8 ] loss: 0.3792344629764557 2022-08-12 00:36:08.962120
Epoch:[ 73 9 ] loss: 0.3786364197731018 2022-08-12 00:36:09.376283
Epoch:[ 73 10 ] loss: 0.37985819578170776 2022-08-12 00:36:09.802255
Epoch:[ 73 11 ] loss: 0.3798291087150574 2022-08-12 00:36:10.224708
Epoch:[ 73 12 ] loss: 0.3787567615509033 2022-08-12 00:36:10.650304
Epoch:[ 73 13 ] loss: 0.37952640652656555 2022-08-12 00:36:11.069952
Epoch:[ 73 14 ] loss: 0.37832921743392944 2022-08-12 00:36:11.494919
Epoch:[ 73 15 ] loss: 0.3787727355957031 2022-08-12 00:36:11.917471
Epoch:[ 73 16 ] loss: 0.37729495763778687 2022-08-12 00:36:17.345264
Epoch:[ 73 17 ] loss: 0.3788815438747406 2022-08-12 00:36:17.766414
Epoch:[ 73 18 ] loss: 0.3788767158985138 2022-08-12 00:36:18.189205
Epoch:[ 73 19 ] loss: 0.37977519631385803 2022-08-12 00:36:18.614995
Training_Epoch:[ 73 ] Training_loss: 0.37916562855243685 2022-08-12 00:36:18.615719
learning rate:  0.0012823083531249997
val: 1 0.39492133259773254
val: 2 0.396525502204895
val: 3 0.39440441131591797
val: 4 0.39970412850379944
val: 5 0.3912737965583801
val: 6 0.3962816894054413
val: 7 0.3943455219268799
val: 8 0.39782053232192993
val: 9 0.39297711849212646
val: 10 0.3956993520259857
val: 11 0.39959287643432617
val: 12 0.391226202249527
val: 13 0.3934252858161926
val: 14 0.39674341678619385
val: 15 0.3917665481567383
val: 16 0.3913269340991974
val: 17 0.3979527950286865
val: 18 0.39489755034446716
val: 19 0.39953112602233887
val: 20 0.3962526023387909
val_Epoch:[ 73 ] val_loss: 0.39533343613147737 2022-08-12 00:36:22.194362
start training 2022-08-12 00:36:22.292462
Epoch:[ 74 0 ] loss: 0.3769151270389557 2022-08-12 00:36:36.525624
Epoch:[ 74 1 ] loss: 0.3774442672729492 2022-08-12 00:36:36.980244
Epoch:[ 74 2 ] loss: 0.3771558701992035 2022-08-12 00:36:37.404142
Epoch:[ 74 3 ] loss: 0.3775425851345062 2022-08-12 00:36:37.828247
Epoch:[ 74 4 ] loss: 0.3777126669883728 2022-08-12 00:36:38.251319
Epoch:[ 74 5 ] loss: 0.37716615200042725 2022-08-12 00:36:38.676482
Epoch:[ 74 6 ] loss: 0.3767082095146179 2022-08-12 00:36:39.101427
Epoch:[ 74 7 ] loss: 0.3782918453216553 2022-08-12 00:36:39.522421
Epoch:[ 74 8 ] loss: 0.37838682532310486 2022-08-12 00:36:39.947863
Epoch:[ 74 9 ] loss: 0.3798031806945801 2022-08-12 00:36:40.372761
Epoch:[ 74 10 ] loss: 0.37975460290908813 2022-08-12 00:36:40.795788
Epoch:[ 74 11 ] loss: 0.37935104966163635 2022-08-12 00:36:41.221826
Epoch:[ 74 12 ] loss: 0.3821181654930115 2022-08-12 00:36:41.645191
Epoch:[ 74 13 ] loss: 0.37744566798210144 2022-08-12 00:36:42.064754
Epoch:[ 74 14 ] loss: 0.37854549288749695 2022-08-12 00:36:42.480050
Epoch:[ 74 15 ] loss: 0.37997016310691833 2022-08-12 00:36:42.899256
Epoch:[ 74 16 ] loss: 0.37723228335380554 2022-08-12 00:36:48.163131
Epoch:[ 74 17 ] loss: 0.37916597723960876 2022-08-12 00:36:48.592730
Epoch:[ 74 18 ] loss: 0.3791155219078064 2022-08-12 00:36:49.014143
Epoch:[ 74 19 ] loss: 0.380066841840744 2022-08-12 00:36:49.431733
Training_Epoch:[ 74 ] Training_loss: 0.3784946247935295 2022-08-12 00:36:49.432380
learning rate:  0.0012823083531249997
val: 1 0.4000784754753113
val: 2 0.3955363929271698
val: 3 0.3990965485572815
val: 4 0.3951496481895447
val: 5 0.40225428342819214
val: 6 0.391896516084671
val: 7 0.3977944254875183
val: 8 0.39438849687576294
val: 9 0.3864465355873108
val: 10 0.39188164472579956
val: 11 0.3893734812736511
val: 12 0.3929348587989807
val: 13 0.40028437972068787
val: 14 0.3970794677734375
val: 15 0.3974176049232483
val: 16 0.3989747166633606
val: 17 0.3942308723926544
val: 18 0.3989029824733734
val: 19 0.39734792709350586
val: 20 0.3928501605987549
val_Epoch:[ 74 ] val_loss: 0.39569597095251086 2022-08-12 00:36:52.993876
start training 2022-08-12 00:36:53.092744
Epoch:[ 75 0 ] loss: 0.3807719051837921 2022-08-12 00:37:07.272787
Epoch:[ 75 1 ] loss: 0.37876152992248535 2022-08-12 00:37:07.933233
Epoch:[ 75 2 ] loss: 0.3762100040912628 2022-08-12 00:37:08.357479
Epoch:[ 75 3 ] loss: 0.3781307339668274 2022-08-12 00:37:08.770123
Epoch:[ 75 4 ] loss: 0.3785085678100586 2022-08-12 00:37:09.194082
Epoch:[ 75 5 ] loss: 0.37899959087371826 2022-08-12 00:37:09.616978
Epoch:[ 75 6 ] loss: 0.3790951371192932 2022-08-12 00:37:10.036364
Epoch:[ 75 7 ] loss: 0.37836965918540955 2022-08-12 00:37:10.453345
Epoch:[ 75 8 ] loss: 0.37925612926483154 2022-08-12 00:37:10.878291
Epoch:[ 75 9 ] loss: 0.37854665517807007 2022-08-12 00:37:11.303718
Epoch:[ 75 10 ] loss: 0.3785765469074249 2022-08-12 00:37:11.730897
Epoch:[ 75 11 ] loss: 0.3798414468765259 2022-08-12 00:37:12.152821
Epoch:[ 75 12 ] loss: 0.3782369792461395 2022-08-12 00:37:12.581499
Epoch:[ 75 13 ] loss: 0.3791297376155853 2022-08-12 00:37:12.996828
Epoch:[ 75 14 ] loss: 0.37693846225738525 2022-08-12 00:37:13.421212
Epoch:[ 75 15 ] loss: 0.3782106637954712 2022-08-12 00:37:13.844595
Epoch:[ 75 16 ] loss: 0.37796634435653687 2022-08-12 00:37:18.968839
Epoch:[ 75 17 ] loss: 0.3783457577228546 2022-08-12 00:37:20.020345
Epoch:[ 75 18 ] loss: 0.3788986802101135 2022-08-12 00:37:20.445824
Epoch:[ 75 19 ] loss: 0.3788619935512543 2022-08-12 00:37:20.871036
Training_Epoch:[ 75 ] Training_loss: 0.378582826256752 2022-08-12 00:37:20.871798
learning rate:  0.0012823083531249997
val: 1 0.3940909504890442
val: 2 0.39403972029685974
val: 3 0.3950017988681793
val: 4 0.3967798352241516
val: 5 0.393110990524292
val: 6 0.3992331922054291
val: 7 0.3972378373146057
val: 8 0.4048989713191986
val: 9 0.39540937542915344
val: 10 0.40033745765686035
val: 11 0.40050625801086426
val: 12 0.3946581780910492
val: 13 0.40008291602134705
val: 14 0.40210890769958496
val: 15 0.4008615016937256
val: 16 0.39535877108573914
val: 17 0.3882783353328705
val: 18 0.39779752492904663
val: 19 0.3948817849159241
val: 20 0.4022277891635895
val_Epoch:[ 75 ] val_loss: 0.39734510481357577 2022-08-12 00:37:24.397873
start training 2022-08-12 00:37:24.492999
Epoch:[ 76 0 ] loss: 0.3763997554779053 2022-08-12 00:37:38.424316
Epoch:[ 76 1 ] loss: 0.3777296245098114 2022-08-12 00:37:38.860334
Epoch:[ 76 2 ] loss: 0.3762510418891907 2022-08-12 00:37:39.286407
Epoch:[ 76 3 ] loss: 0.3780648410320282 2022-08-12 00:37:39.711892
Epoch:[ 76 4 ] loss: 0.3777307868003845 2022-08-12 00:37:40.138465
Epoch:[ 76 5 ] loss: 0.37739595770835876 2022-08-12 00:37:40.559148
Epoch:[ 76 6 ] loss: 0.38004401326179504 2022-08-12 00:37:40.984918
Epoch:[ 76 7 ] loss: 0.3759669065475464 2022-08-12 00:37:41.404400
Epoch:[ 76 8 ] loss: 0.37638258934020996 2022-08-12 00:37:41.829711
Epoch:[ 76 9 ] loss: 0.3796851933002472 2022-08-12 00:37:42.254836
Epoch:[ 76 10 ] loss: 0.37896662950515747 2022-08-12 00:37:42.680339
Epoch:[ 76 11 ] loss: 0.37877020239830017 2022-08-12 00:37:43.100659
Epoch:[ 76 12 ] loss: 0.3792079985141754 2022-08-12 00:37:43.515158
Epoch:[ 76 13 ] loss: 0.37866833806037903 2022-08-12 00:37:43.934735
Epoch:[ 76 14 ] loss: 0.3798506259918213 2022-08-12 00:37:44.362587
Epoch:[ 76 15 ] loss: 0.37796124815940857 2022-08-12 00:37:44.787895
Epoch:[ 76 16 ] loss: 0.377702921628952 2022-08-12 00:37:50.859825
Epoch:[ 76 17 ] loss: 0.3778650462627411 2022-08-12 00:37:51.285386
Epoch:[ 76 18 ] loss: 0.3800354599952698 2022-08-12 00:37:51.706696
Epoch:[ 76 19 ] loss: 0.3783181309700012 2022-08-12 00:37:52.127619
Training_Epoch:[ 76 ] Training_loss: 0.37814986556768415 2022-08-12 00:37:52.128308
learning rate:  0.0012823083531249997
val: 1 0.4061061441898346
val: 2 0.40057942271232605
val: 3 0.4040813148021698
val: 4 0.39637067914009094
val: 5 0.399710476398468
val: 6 0.40320509672164917
val: 7 0.3989337682723999
val: 8 0.38899773359298706
val: 9 0.40041282773017883
val: 10 0.3996939957141876
val: 11 0.3988029956817627
val: 12 0.40112748742103577
val: 13 0.40169960260391235
val: 14 0.3998371958732605
val: 15 0.3908088803291321
val: 16 0.39693254232406616
val: 17 0.39460718631744385
val: 18 0.4027245342731476
val: 19 0.39912351965904236
val: 20 0.39174649119377136
val_Epoch:[ 76 ] val_loss: 0.39877509474754336 2022-08-12 00:37:55.784801
start training 2022-08-12 00:37:55.884542
Epoch:[ 77 0 ] loss: 0.37891238927841187 2022-08-12 00:38:09.797934
Epoch:[ 77 1 ] loss: 0.3779371678829193 2022-08-12 00:38:10.343867
Epoch:[ 77 2 ] loss: 0.3756650686264038 2022-08-12 00:38:10.769191
Epoch:[ 77 3 ] loss: 0.3786049783229828 2022-08-12 00:38:11.187849
Epoch:[ 77 4 ] loss: 0.3762412965297699 2022-08-12 00:38:11.611267
Epoch:[ 77 5 ] loss: 0.37794607877731323 2022-08-12 00:38:12.038223
Epoch:[ 77 6 ] loss: 0.37802809476852417 2022-08-12 00:38:12.465319
Epoch:[ 77 7 ] loss: 0.3780084550380707 2022-08-12 00:38:12.890449
Epoch:[ 77 8 ] loss: 0.378266304731369 2022-08-12 00:38:13.313226
Epoch:[ 77 9 ] loss: 0.37758079171180725 2022-08-12 00:38:13.733099
Epoch:[ 77 10 ] loss: 0.3775653541088104 2022-08-12 00:38:14.156698
Epoch:[ 77 11 ] loss: 0.37677839398384094 2022-08-12 00:38:14.580022
Epoch:[ 77 12 ] loss: 0.37739530205726624 2022-08-12 00:38:15.008308
Epoch:[ 77 13 ] loss: 0.3780765235424042 2022-08-12 00:38:15.432738
Epoch:[ 77 14 ] loss: 0.3792949616909027 2022-08-12 00:38:15.854843
Epoch:[ 77 15 ] loss: 0.37726736068725586 2022-08-12 00:38:16.268013
Epoch:[ 77 16 ] loss: 0.3761990964412689 2022-08-12 00:38:21.729169
Epoch:[ 77 17 ] loss: 0.3775201141834259 2022-08-12 00:38:22.150749
Epoch:[ 77 18 ] loss: 0.380307137966156 2022-08-12 00:38:22.575024
Epoch:[ 77 19 ] loss: 0.37820377945899963 2022-08-12 00:38:22.991648
Training_Epoch:[ 77 ] Training_loss: 0.37778993248939513 2022-08-12 00:38:22.992285
learning rate:  0.0012823083531249997
val: 1 0.40303584933280945
val: 2 0.39653292298316956
val: 3 0.4028265178203583
val: 4 0.39698708057403564
val: 5 0.3973068594932556
val: 6 0.3917000889778137
val: 7 0.4005793035030365
val: 8 0.39689046144485474
val: 9 0.38961261510849
val: 10 0.3950701355934143
val: 11 0.4025232791900635
val: 12 0.39848583936691284
val: 13 0.39466342329978943
val: 14 0.3945325016975403
val: 15 0.3956688344478607
val: 16 0.3966204524040222
val: 17 0.3943450152873993
val: 18 0.395281046628952
val: 19 0.39812061190605164
val: 20 0.3946639895439148
val_Epoch:[ 77 ] val_loss: 0.39677234143018725 2022-08-12 00:38:26.437459
start training 2022-08-12 00:38:26.538438
Epoch:[ 78 0 ] loss: 0.3762134611606598 2022-08-12 00:38:41.088479
Epoch:[ 78 1 ] loss: 0.3787171244621277 2022-08-12 00:38:41.509910
Epoch:[ 78 2 ] loss: 0.37737640738487244 2022-08-12 00:38:41.933689
Epoch:[ 78 3 ] loss: 0.37804532051086426 2022-08-12 00:38:42.355120
Epoch:[ 78 4 ] loss: 0.3782031536102295 2022-08-12 00:38:42.779312
Epoch:[ 78 5 ] loss: 0.37936997413635254 2022-08-12 00:38:43.203856
Epoch:[ 78 6 ] loss: 0.3782842755317688 2022-08-12 00:38:43.632783
Epoch:[ 78 7 ] loss: 0.3770267963409424 2022-08-12 00:38:44.060938
Epoch:[ 78 8 ] loss: 0.3773422837257385 2022-08-12 00:38:44.475598
Epoch:[ 78 9 ] loss: 0.37660565972328186 2022-08-12 00:38:44.893452
Epoch:[ 78 10 ] loss: 0.37672102451324463 2022-08-12 00:38:45.319978
Epoch:[ 78 11 ] loss: 0.3756386339664459 2022-08-12 00:38:45.743482
Epoch:[ 78 12 ] loss: 0.3755123019218445 2022-08-12 00:38:46.161311
Epoch:[ 78 13 ] loss: 0.37469711899757385 2022-08-12 00:38:46.582767
Epoch:[ 78 14 ] loss: 0.3763730823993683 2022-08-12 00:38:47.010056
Epoch:[ 78 15 ] loss: 0.3799380660057068 2022-08-12 00:38:47.434894
Epoch:[ 78 16 ] loss: 0.3753284811973572 2022-08-12 00:38:52.644317
Epoch:[ 78 17 ] loss: 0.378467321395874 2022-08-12 00:38:53.065461
Epoch:[ 78 18 ] loss: 0.3771989345550537 2022-08-12 00:38:53.490790
Epoch:[ 78 19 ] loss: 0.37750089168548584 2022-08-12 00:38:53.918280
Training_Epoch:[ 78 ] Training_loss: 0.37722801566123965 2022-08-12 00:38:53.918987
learning rate:  0.0012823083531249997
val: 1 0.3957127332687378
val: 2 0.3929879665374756
val: 3 0.4024009108543396
val: 4 0.3862966299057007
val: 5 0.39553752541542053
val: 6 0.40194088220596313
val: 7 0.39432403445243835
val: 8 0.39830073714256287
val: 9 0.3957692086696625
val: 10 0.3999355435371399
val: 11 0.3989510238170624
val: 12 0.4093002378940582
val: 13 0.39647042751312256
val: 14 0.39457255601882935
val: 15 0.40022769570350647
val: 16 0.3974308371543884
val: 17 0.39558878540992737
val: 18 0.39743572473526
val: 19 0.4029732942581177
val: 20 0.39839527010917664
val_Epoch:[ 78 ] val_loss: 0.3977276012301445 2022-08-12 00:38:57.537771
start training 2022-08-12 00:38:57.637120
Epoch:[ 79 0 ] loss: 0.37652602791786194 2022-08-12 00:39:12.324850
Epoch:[ 79 1 ] loss: 0.3769874572753906 2022-08-12 00:39:12.748579
Epoch:[ 79 2 ] loss: 0.3757159411907196 2022-08-12 00:39:13.173220
Epoch:[ 79 3 ] loss: 0.3754332661628723 2022-08-12 00:39:13.592559
Epoch:[ 79 4 ] loss: 0.37698042392730713 2022-08-12 00:39:14.015168
Epoch:[ 79 5 ] loss: 0.3778313994407654 2022-08-12 00:39:14.438149
Epoch:[ 79 6 ] loss: 0.3774932026863098 2022-08-12 00:39:14.859597
Epoch:[ 79 7 ] loss: 0.37773430347442627 2022-08-12 00:39:15.282888
Epoch:[ 79 8 ] loss: 0.3785533308982849 2022-08-12 00:39:15.708494
Epoch:[ 79 9 ] loss: 0.3784833550453186 2022-08-12 00:39:16.133788
Epoch:[ 79 10 ] loss: 0.37688887119293213 2022-08-12 00:39:16.553450
Epoch:[ 79 11 ] loss: 0.3779035806655884 2022-08-12 00:39:16.982745
Epoch:[ 79 12 ] loss: 0.37750765681266785 2022-08-12 00:39:17.404785
Epoch:[ 79 13 ] loss: 0.37616655230522156 2022-08-12 00:39:17.825881
Epoch:[ 79 14 ] loss: 0.377806156873703 2022-08-12 00:39:18.254712
Epoch:[ 79 15 ] loss: 0.37839120626449585 2022-08-12 00:39:18.679824
Epoch:[ 79 16 ] loss: 0.378445029258728 2022-08-12 00:39:24.229941
Epoch:[ 79 17 ] loss: 0.37715843319892883 2022-08-12 00:39:24.650858
Epoch:[ 79 18 ] loss: 0.37944671511650085 2022-08-12 00:39:25.074745
Epoch:[ 79 19 ] loss: 0.37662091851234436 2022-08-12 00:39:25.497876
Training_Epoch:[ 79 ] Training_loss: 0.37740369141101837 2022-08-12 00:39:25.498605
learning rate:  0.0012823083531249997
val: 1 0.3983430862426758
val: 2 0.3956366777420044
val: 3 0.40032628178596497
val: 4 0.4006141424179077
val: 5 0.3935510814189911
val: 6 0.3959701359272003
val: 7 0.3959256708621979
val: 8 0.39766135811805725
val: 9 0.40257883071899414
val: 10 0.40247833728790283
val: 11 0.3961294889450073
val: 12 0.4030282199382782
val: 13 0.3923187851905823
val: 14 0.3936271071434021
val: 15 0.3934134542942047
val: 16 0.40513476729393005
val: 17 0.39313963055610657
val: 18 0.3967292308807373
val: 19 0.39818742871284485
val: 20 0.39111173152923584
val_Epoch:[ 79 ] val_loss: 0.39729527235031126 2022-08-12 00:39:29.065171
start training 2022-08-12 00:39:29.170004
Epoch:[ 80 0 ] loss: 0.37598946690559387 2022-08-12 00:39:44.172276
Epoch:[ 80 1 ] loss: 0.37839916348457336 2022-08-12 00:39:44.598085
Epoch:[ 80 2 ] loss: 0.37603259086608887 2022-08-12 00:39:45.017928
Epoch:[ 80 3 ] loss: 0.3773317039012909 2022-08-12 00:39:45.435116
Epoch:[ 80 4 ] loss: 0.37697282433509827 2022-08-12 00:39:45.852450
Epoch:[ 80 5 ] loss: 0.3776804506778717 2022-08-12 00:39:46.277144
Epoch:[ 80 6 ] loss: 0.3778654932975769 2022-08-12 00:39:46.701706
Epoch:[ 80 7 ] loss: 0.37749427556991577 2022-08-12 00:39:47.119535
Epoch:[ 80 8 ] loss: 0.37598127126693726 2022-08-12 00:39:47.540641
Epoch:[ 80 9 ] loss: 0.3786567151546478 2022-08-12 00:39:47.964483
Epoch:[ 80 10 ] loss: 0.37642163038253784 2022-08-12 00:39:48.391454
Epoch:[ 80 11 ] loss: 0.3796999752521515 2022-08-12 00:39:48.814785
Epoch:[ 80 12 ] loss: 0.37777256965637207 2022-08-12 00:39:49.236919
Epoch:[ 80 13 ] loss: 0.3782304525375366 2022-08-12 00:39:49.659370
Epoch:[ 80 14 ] loss: 0.377464234828949 2022-08-12 00:39:50.085869
Epoch:[ 80 15 ] loss: 0.37835362553596497 2022-08-12 00:39:50.510085
Epoch:[ 80 16 ] loss: 0.37749552726745605 2022-08-12 00:39:56.016717
Epoch:[ 80 17 ] loss: 0.3781750202178955 2022-08-12 00:39:56.435157
Epoch:[ 80 18 ] loss: 0.3754726052284241 2022-08-12 00:39:56.864859
Epoch:[ 80 19 ] loss: 0.3770201802253723 2022-08-12 00:39:57.289531
Training_Epoch:[ 80 ] Training_loss: 0.37742548882961274 2022-08-12 00:39:57.290256
learning rate:  0.0012823083531249997
netparams have been saved once 80
val: 1 0.3977515995502472
val: 2 0.39626869559288025
val: 3 0.3891623616218567
val: 4 0.3971877098083496
val: 5 0.3992440402507782
val: 6 0.3983854055404663
val: 7 0.39703792333602905
val: 8 0.3894970715045929
val: 9 0.3956308960914612
val: 10 0.3967846632003784
val: 11 0.39570531249046326
val: 12 0.3997635841369629
val: 13 0.3962412476539612
val: 14 0.3912258446216583
val: 15 0.39345782995224
val: 16 0.3929261267185211
val: 17 0.39572855830192566
val: 18 0.3915005028247833
val: 19 0.397807240486145
val: 20 0.4011177718639374
val_Epoch:[ 80 ] val_loss: 0.3956212192773819 2022-08-12 00:40:00.889168
start training 2022-08-12 00:40:00.986767
Epoch:[ 81 0 ] loss: 0.37597063183784485 2022-08-12 00:40:15.882620
Epoch:[ 81 1 ] loss: 0.37528449296951294 2022-08-12 00:40:16.307194
Epoch:[ 81 2 ] loss: 0.37447139620780945 2022-08-12 00:40:16.736055
Epoch:[ 81 3 ] loss: 0.37684395909309387 2022-08-12 00:40:17.156313
Epoch:[ 81 4 ] loss: 0.373680979013443 2022-08-12 00:40:17.578008
Epoch:[ 81 5 ] loss: 0.3750333786010742 2022-08-12 00:40:18.001785
Epoch:[ 81 6 ] loss: 0.3761520981788635 2022-08-12 00:40:18.422505
Epoch:[ 81 7 ] loss: 0.3772871196269989 2022-08-12 00:40:18.845211
Epoch:[ 81 8 ] loss: 0.376392126083374 2022-08-12 00:40:19.271552
Epoch:[ 81 9 ] loss: 0.37801605463027954 2022-08-12 00:40:19.697239
Epoch:[ 81 10 ] loss: 0.37744244933128357 2022-08-12 00:40:20.118981
Epoch:[ 81 11 ] loss: 0.37632957100868225 2022-08-12 00:40:20.533521
Epoch:[ 81 12 ] loss: 0.375669926404953 2022-08-12 00:40:20.952679
Epoch:[ 81 13 ] loss: 0.3748648762702942 2022-08-12 00:40:21.386221
Epoch:[ 81 14 ] loss: 0.3763681650161743 2022-08-12 00:40:21.806073
Epoch:[ 81 15 ] loss: 0.3764299154281616 2022-08-12 00:40:22.229469
Epoch:[ 81 16 ] loss: 0.37714827060699463 2022-08-12 00:40:27.576565
Epoch:[ 81 17 ] loss: 0.3764181137084961 2022-08-12 00:40:28.006183
Epoch:[ 81 18 ] loss: 0.3756299316883087 2022-08-12 00:40:28.426266
Epoch:[ 81 19 ] loss: 0.3770104646682739 2022-08-12 00:40:28.840412
Training_Epoch:[ 81 ] Training_loss: 0.37612219601869584 2022-08-12 00:40:28.841140
learning rate:  0.0010899621001562497
val: 1 0.3951261341571808
val: 2 0.3936072587966919
val: 3 0.4007609784603119
val: 4 0.3983944356441498
val: 5 0.39282479882240295
val: 6 0.3979266285896301
val: 7 0.3942849040031433
val: 8 0.39220720529556274
val: 9 0.39723777770996094
val: 10 0.39955854415893555
val: 11 0.4010290503501892
val: 12 0.39899593591690063
val: 13 0.3955411911010742
val: 14 0.3929680585861206
val: 15 0.40306246280670166
val: 16 0.40199461579322815
val: 17 0.4026857912540436
val: 18 0.4022904634475708
val: 19 0.3941001892089844
val: 20 0.39085739850997925
val_Epoch:[ 81 ] val_loss: 0.3972726911306381 2022-08-12 00:40:32.447326
start training 2022-08-12 00:40:32.550367
Epoch:[ 82 0 ] loss: 0.375283807516098 2022-08-12 00:40:46.471960
Epoch:[ 82 1 ] loss: 0.3747740387916565 2022-08-12 00:40:46.915092
Epoch:[ 82 2 ] loss: 0.3765452802181244 2022-08-12 00:40:47.345775
Epoch:[ 82 3 ] loss: 0.37550511956214905 2022-08-12 00:40:47.768292
Epoch:[ 82 4 ] loss: 0.3744104206562042 2022-08-12 00:40:48.190486
Epoch:[ 82 5 ] loss: 0.3750368356704712 2022-08-12 00:40:48.611293
Epoch:[ 82 6 ] loss: 0.37622055411338806 2022-08-12 00:40:49.037143
Epoch:[ 82 7 ] loss: 0.3732507526874542 2022-08-12 00:40:49.462533
Epoch:[ 82 8 ] loss: 0.377864807844162 2022-08-12 00:40:49.883140
Epoch:[ 82 9 ] loss: 0.374798983335495 2022-08-12 00:40:50.308429
Epoch:[ 82 10 ] loss: 0.3756932318210602 2022-08-12 00:40:50.735204
Epoch:[ 82 11 ] loss: 0.37560850381851196 2022-08-12 00:40:51.160656
Epoch:[ 82 12 ] loss: 0.37557464838027954 2022-08-12 00:40:51.587809
Epoch:[ 82 13 ] loss: 0.3742680549621582 2022-08-12 00:40:52.011596
Epoch:[ 82 14 ] loss: 0.3750152885913849 2022-08-12 00:40:52.433828
Epoch:[ 82 15 ] loss: 0.37585827708244324 2022-08-12 00:40:52.850414
Epoch:[ 82 16 ] loss: 0.3744068443775177 2022-08-12 00:40:58.279856
Epoch:[ 82 17 ] loss: 0.375895231962204 2022-08-12 00:40:58.722798
Epoch:[ 82 18 ] loss: 0.37621358036994934 2022-08-12 00:40:59.143066
Epoch:[ 82 19 ] loss: 0.375564306974411 2022-08-12 00:40:59.556378
Training_Epoch:[ 82 ] Training_loss: 0.37538942843675616 2022-08-12 00:40:59.557077
learning rate:  0.0010899621001562497
val: 1 0.3970913887023926
val: 2 0.39733996987342834
val: 3 0.3929901123046875
val: 4 0.39357876777648926
val: 5 0.3947170674800873
val: 6 0.3949476182460785
val: 7 0.3974273204803467
val: 8 0.3931904137134552
val: 9 0.3987410366535187
val: 10 0.3983270823955536
val: 11 0.4030754864215851
val: 12 0.39654144644737244
val: 13 0.3958303928375244
val: 14 0.40507498383522034
val: 15 0.39151716232299805
val: 16 0.40139850974082947
val: 17 0.4023265540599823
val: 18 0.396291583776474
val: 19 0.39711543917655945
val: 20 0.3945757746696472
val_Epoch:[ 82 ] val_loss: 0.39710490554571154 2022-08-12 00:41:03.177282
start training 2022-08-12 00:41:03.278243
Epoch:[ 83 0 ] loss: 0.37294018268585205 2022-08-12 00:41:17.097343
Epoch:[ 83 1 ] loss: 0.37449032068252563 2022-08-12 00:41:17.698399
Epoch:[ 83 2 ] loss: 0.37363383173942566 2022-08-12 00:41:18.118858
Epoch:[ 83 3 ] loss: 0.37581539154052734 2022-08-12 00:41:18.541695
Epoch:[ 83 4 ] loss: 0.37384364008903503 2022-08-12 00:41:18.971327
Epoch:[ 83 5 ] loss: 0.37575563788414 2022-08-12 00:41:19.391860
Epoch:[ 83 6 ] loss: 0.3738732635974884 2022-08-12 00:41:19.815295
Epoch:[ 83 7 ] loss: 0.3750193119049072 2022-08-12 00:41:20.239309
Epoch:[ 83 8 ] loss: 0.37312373518943787 2022-08-12 00:41:20.664931
Epoch:[ 83 9 ] loss: 0.3745481073856354 2022-08-12 00:41:21.082241
Epoch:[ 83 10 ] loss: 0.3754502534866333 2022-08-12 00:41:21.499865
Epoch:[ 83 11 ] loss: 0.37426048517227173 2022-08-12 00:41:21.919891
Epoch:[ 83 12 ] loss: 0.37458357214927673 2022-08-12 00:41:22.348516
Epoch:[ 83 13 ] loss: 0.3750440776348114 2022-08-12 00:41:22.768973
Epoch:[ 83 14 ] loss: 0.3772571384906769 2022-08-12 00:41:23.190489
Epoch:[ 83 15 ] loss: 0.3752508759498596 2022-08-12 00:41:23.611993
Epoch:[ 83 16 ] loss: 0.3746470510959625 2022-08-12 00:41:29.377482
Epoch:[ 83 17 ] loss: 0.37601932883262634 2022-08-12 00:41:29.793039
Epoch:[ 83 18 ] loss: 0.3743666112422943 2022-08-12 00:41:30.221095
Epoch:[ 83 19 ] loss: 0.3757137358188629 2022-08-12 00:41:30.647756
Training_Epoch:[ 83 ] Training_loss: 0.3747818276286125 2022-08-12 00:41:30.648418
learning rate:  0.0010899621001562497
val: 1 0.3938906788825989
val: 2 0.39549216628074646
val: 3 0.3919996917247772
val: 4 0.3980087637901306
val: 5 0.38988152146339417
val: 6 0.39293941855430603
val: 7 0.3904684782028198
val: 8 0.3842974901199341
val: 9 0.39543649554252625
val: 10 0.3983403742313385
val: 11 0.39729225635528564
val: 12 0.39665448665618896
val: 13 0.39941707253456116
val: 14 0.39478054642677307
val: 15 0.39693325757980347
val: 16 0.39702507853507996
val: 17 0.3885436952114105
val: 18 0.39615052938461304
val: 19 0.3937980532646179
val: 20 0.39787763357162476
val_Epoch:[ 83 ] val_loss: 0.3944613844156265 2022-08-12 00:41:34.167285
start training 2022-08-12 00:41:34.263053
Epoch:[ 84 0 ] loss: 0.3745775818824768 2022-08-12 00:41:49.248273
Epoch:[ 84 1 ] loss: 0.37328049540519714 2022-08-12 00:41:49.668600
Epoch:[ 84 2 ] loss: 0.3724833130836487 2022-08-12 00:41:50.093504
Epoch:[ 84 3 ] loss: 0.3724415898323059 2022-08-12 00:41:50.522738
Epoch:[ 84 4 ] loss: 0.3730849623680115 2022-08-12 00:41:50.944621
Epoch:[ 84 5 ] loss: 0.374402791261673 2022-08-12 00:41:51.370083
Epoch:[ 84 6 ] loss: 0.37401777505874634 2022-08-12 00:41:51.791351
Epoch:[ 84 7 ] loss: 0.37427768111228943 2022-08-12 00:41:52.216053
Epoch:[ 84 8 ] loss: 0.3753412961959839 2022-08-12 00:41:52.641250
Epoch:[ 84 9 ] loss: 0.37365320324897766 2022-08-12 00:41:53.065050
Epoch:[ 84 10 ] loss: 0.3736724555492401 2022-08-12 00:41:53.494943
Epoch:[ 84 11 ] loss: 0.37446704506874084 2022-08-12 00:41:53.909571
Epoch:[ 84 12 ] loss: 0.37477439641952515 2022-08-12 00:41:54.329414
Epoch:[ 84 13 ] loss: 0.3733452260494232 2022-08-12 00:41:54.758322
Epoch:[ 84 14 ] loss: 0.3750668466091156 2022-08-12 00:41:55.181430
Epoch:[ 84 15 ] loss: 0.37424036860466003 2022-08-12 00:41:55.599832
Epoch:[ 84 16 ] loss: 0.37488654255867004 2022-08-12 00:42:00.863624
Epoch:[ 84 17 ] loss: 0.37751176953315735 2022-08-12 00:42:01.285029
Epoch:[ 84 18 ] loss: 0.37625348567962646 2022-08-12 00:42:01.711291
Epoch:[ 84 19 ] loss: 0.3774949014186859 2022-08-12 00:42:02.135916
Training_Epoch:[ 84 ] Training_loss: 0.3744636863470078 2022-08-12 00:42:02.136606
learning rate:  0.0010899621001562497
val: 1 0.3885878324508667
val: 2 0.3939768075942993
val: 3 0.3960857689380646
val: 4 0.38995906710624695
val: 5 0.3969687521457672
val: 6 0.3920484781265259
val: 7 0.40503501892089844
val: 8 0.3949497640132904
val: 9 0.391390860080719
val: 10 0.3961130380630493
val: 11 0.3900686800479889
val: 12 0.39784473180770874
val: 13 0.3966430723667145
val: 14 0.39936649799346924
val: 15 0.39530226588249207
val: 16 0.40084636211395264
val: 17 0.40090373158454895
val: 18 0.4018687605857849
val: 19 0.4010276198387146
val: 20 0.39315271377563477
val_Epoch:[ 84 ] val_loss: 0.39610699117183684 2022-08-12 00:42:05.784666
start training 2022-08-12 00:42:05.876640
Epoch:[ 85 0 ] loss: 0.3755074441432953 2022-08-12 00:42:20.236416
Epoch:[ 85 1 ] loss: 0.3731169104576111 2022-08-12 00:42:20.947241
Epoch:[ 85 2 ] loss: 0.3749193847179413 2022-08-12 00:42:21.370266
Epoch:[ 85 3 ] loss: 0.37427622079849243 2022-08-12 00:42:21.792744
Epoch:[ 85 4 ] loss: 0.3733500838279724 2022-08-12 00:42:22.214485
Epoch:[ 85 5 ] loss: 0.3760901093482971 2022-08-12 00:42:22.627579
Epoch:[ 85 6 ] loss: 0.3731217086315155 2022-08-12 00:42:23.052752
Epoch:[ 85 7 ] loss: 0.37564006447792053 2022-08-12 00:42:23.481435
Epoch:[ 85 8 ] loss: 0.37522703409194946 2022-08-12 00:42:23.901168
Epoch:[ 85 9 ] loss: 0.3737235367298126 2022-08-12 00:42:24.315183
Epoch:[ 85 10 ] loss: 0.37431374192237854 2022-08-12 00:42:24.740005
Epoch:[ 85 11 ] loss: 0.3754827082157135 2022-08-12 00:42:25.165186
Epoch:[ 85 12 ] loss: 0.3744461238384247 2022-08-12 00:42:25.590986
Epoch:[ 85 13 ] loss: 0.374568909406662 2022-08-12 00:42:26.012967
Epoch:[ 85 14 ] loss: 0.3726902902126312 2022-08-12 00:42:26.437029
Epoch:[ 85 15 ] loss: 0.3751043677330017 2022-08-12 00:42:26.855601
Epoch:[ 85 16 ] loss: 0.37432780861854553 2022-08-12 00:42:31.962161
Epoch:[ 85 17 ] loss: 0.37559863924980164 2022-08-12 00:42:32.386395
Epoch:[ 85 18 ] loss: 0.3740481734275818 2022-08-12 00:42:32.809916
Epoch:[ 85 19 ] loss: 0.37615764141082764 2022-08-12 00:42:33.230833
Training_Epoch:[ 85 ] Training_loss: 0.3745855450630188 2022-08-12 00:42:33.231521
learning rate:  0.0010899621001562497
val: 1 0.41153275966644287
val: 2 0.39613619446754456
val: 3 0.3998384475708008
val: 4 0.39903169870376587
val: 5 0.3925524353981018
val: 6 0.39685800671577454
val: 7 0.40402963757514954
val: 8 0.3963930904865265
val: 9 0.39854007959365845
val: 10 0.3967089056968689
val: 11 0.3985542953014374
val: 12 0.39907893538475037
val: 13 0.3984874188899994
val: 14 0.40119877457618713
val: 15 0.4011825919151306
val: 16 0.400852769613266
val: 17 0.3967949450016022
val: 18 0.39841964840888977
val: 19 0.40575680136680603
val: 20 0.4044455289840698
val_Epoch:[ 85 ] val_loss: 0.3998196482658386 2022-08-12 00:42:36.696043
start training 2022-08-12 00:42:36.790891
Epoch:[ 86 0 ] loss: 0.3724089562892914 2022-08-12 00:42:51.639349
Epoch:[ 86 1 ] loss: 0.3724265992641449 2022-08-12 00:42:52.064621
Epoch:[ 86 2 ] loss: 0.37292376160621643 2022-08-12 00:42:52.480946
Epoch:[ 86 3 ] loss: 0.3747783601284027 2022-08-12 00:42:52.902036
Epoch:[ 86 4 ] loss: 0.37413284182548523 2022-08-12 00:42:53.325072
Epoch:[ 86 5 ] loss: 0.37501925230026245 2022-08-12 00:42:53.750432
Epoch:[ 86 6 ] loss: 0.3749855160713196 2022-08-12 00:42:54.172018
Epoch:[ 86 7 ] loss: 0.37354081869125366 2022-08-12 00:42:54.595771
Epoch:[ 86 8 ] loss: 0.3737746775150299 2022-08-12 00:42:55.022765
Epoch:[ 86 9 ] loss: 0.3742212653160095 2022-08-12 00:42:55.448011
Epoch:[ 86 10 ] loss: 0.37427788972854614 2022-08-12 00:42:55.869837
Epoch:[ 86 11 ] loss: 0.3782762587070465 2022-08-12 00:42:56.293325
Epoch:[ 86 12 ] loss: 0.3733171224594116 2022-08-12 00:42:56.717982
Epoch:[ 86 13 ] loss: 0.3782099783420563 2022-08-12 00:42:57.138794
Epoch:[ 86 14 ] loss: 0.37418827414512634 2022-08-12 00:42:57.553087
Epoch:[ 86 15 ] loss: 0.37524867057800293 2022-08-12 00:42:57.976682
Epoch:[ 86 16 ] loss: 0.37663573026657104 2022-08-12 00:43:03.019107
Epoch:[ 86 17 ] loss: 0.3748171329498291 2022-08-12 00:43:03.447587
Epoch:[ 86 18 ] loss: 0.3769954442977905 2022-08-12 00:43:03.868063
Epoch:[ 86 19 ] loss: 0.3766137361526489 2022-08-12 00:43:04.285873
Training_Epoch:[ 86 ] Training_loss: 0.37483961433172225 2022-08-12 00:43:04.286614
learning rate:  0.0010899621001562497
val: 1 0.3927344083786011
val: 2 0.3930196464061737
val: 3 0.39717331528663635
val: 4 0.3946875333786011
val: 5 0.39276716113090515
val: 6 0.3954218327999115
val: 7 0.39485296607017517
val: 8 0.390630841255188
val: 9 0.3957495093345642
val: 10 0.3949944078922272
val: 11 0.40184420347213745
val: 12 0.3954261541366577
val: 13 0.3994901478290558
val: 14 0.3976533114910126
val: 15 0.3975639045238495
val: 16 0.4024478793144226
val: 17 0.3970538377761841
val: 18 0.39533179998397827
val: 19 0.4039466977119446
val: 20 0.39574387669563293
val_Epoch:[ 86 ] val_loss: 0.39642667174339297 2022-08-12 00:43:07.858111
start training 2022-08-12 00:43:07.952660
Epoch:[ 87 0 ] loss: 0.37487196922302246 2022-08-12 00:43:22.110033
Epoch:[ 87 1 ] loss: 0.37334108352661133 2022-08-12 00:43:22.555456
Epoch:[ 87 2 ] loss: 0.37426576018333435 2022-08-12 00:43:22.976929
Epoch:[ 87 3 ] loss: 0.3736649751663208 2022-08-12 00:43:23.398397
Epoch:[ 87 4 ] loss: 0.37519025802612305 2022-08-12 00:43:23.817607
Epoch:[ 87 5 ] loss: 0.37364616990089417 2022-08-12 00:43:24.247291
Epoch:[ 87 6 ] loss: 0.3736591041088104 2022-08-12 00:43:24.666884
Epoch:[ 87 7 ] loss: 0.3755568861961365 2022-08-12 00:43:25.090305
Epoch:[ 87 8 ] loss: 0.37360838055610657 2022-08-12 00:43:25.513991
Epoch:[ 87 9 ] loss: 0.37412092089653015 2022-08-12 00:43:25.940025
Epoch:[ 87 10 ] loss: 0.3741200268268585 2022-08-12 00:43:26.367386
Epoch:[ 87 11 ] loss: 0.37420931458473206 2022-08-12 00:43:26.782579
Epoch:[ 87 12 ] loss: 0.37521567940711975 2022-08-12 00:43:27.206830
Epoch:[ 87 13 ] loss: 0.37277501821517944 2022-08-12 00:43:27.629634
Epoch:[ 87 14 ] loss: 0.3731462061405182 2022-08-12 00:43:28.055905
Epoch:[ 87 15 ] loss: 0.3737558424472809 2022-08-12 00:43:28.479251
Epoch:[ 87 16 ] loss: 0.3747662305831909 2022-08-12 00:43:33.907475
Epoch:[ 87 17 ] loss: 0.3750154376029968 2022-08-12 00:43:34.323122
Epoch:[ 87 18 ] loss: 0.3752748370170593 2022-08-12 00:43:34.747755
Epoch:[ 87 19 ] loss: 0.3765166103839874 2022-08-12 00:43:35.171372
Training_Epoch:[ 87 ] Training_loss: 0.3743360355496407 2022-08-12 00:43:35.172124
learning rate:  0.0010899621001562497
val: 1 0.40104636549949646
val: 2 0.3931320905685425
val: 3 0.3974727392196655
val: 4 0.3955617845058441
val: 5 0.3928365707397461
val: 6 0.3922010660171509
val: 7 0.3969823122024536
val: 8 0.3950093388557434
val: 9 0.40115973353385925
val: 10 0.39283865690231323
val: 11 0.39301440119743347
val: 12 0.40239831805229187
val: 13 0.3994649052619934
val: 14 0.39358365535736084
val: 15 0.3941986560821533
val: 16 0.3960866630077362
val: 17 0.4016851484775543
val: 18 0.39339563250541687
val: 19 0.3964243233203888
val: 20 0.39653855562210083
val_Epoch:[ 87 ] val_loss: 0.39625154584646227 2022-08-12 00:43:38.678085
start training 2022-08-12 00:43:38.771971
Epoch:[ 88 0 ] loss: 0.37337225675582886 2022-08-12 00:43:53.453826
Epoch:[ 88 1 ] loss: 0.37211117148399353 2022-08-12 00:43:53.873480
Epoch:[ 88 2 ] loss: 0.3748129606246948 2022-08-12 00:43:54.298977
Epoch:[ 88 3 ] loss: 0.37532374262809753 2022-08-12 00:43:54.724865
Epoch:[ 88 4 ] loss: 0.37211838364601135 2022-08-12 00:43:55.149820
Epoch:[ 88 5 ] loss: 0.37444403767585754 2022-08-12 00:43:55.572711
Epoch:[ 88 6 ] loss: 0.374329149723053 2022-08-12 00:43:55.996341
Epoch:[ 88 7 ] loss: 0.37202805280685425 2022-08-12 00:43:56.420347
Epoch:[ 88 8 ] loss: 0.3748559057712555 2022-08-12 00:43:56.844184
Epoch:[ 88 9 ] loss: 0.37304335832595825 2022-08-12 00:43:57.264985
Epoch:[ 88 10 ] loss: 0.3749343454837799 2022-08-12 00:43:57.691872
Epoch:[ 88 11 ] loss: 0.3722117841243744 2022-08-12 00:43:58.109962
Epoch:[ 88 12 ] loss: 0.37448421120643616 2022-08-12 00:43:58.526596
Epoch:[ 88 13 ] loss: 0.37214231491088867 2022-08-12 00:43:58.949343
Epoch:[ 88 14 ] loss: 0.373683899641037 2022-08-12 00:43:59.377540
Epoch:[ 88 15 ] loss: 0.37176600098609924 2022-08-12 00:43:59.803524
Epoch:[ 88 16 ] loss: 0.3732028305530548 2022-08-12 00:44:04.989032
Epoch:[ 88 17 ] loss: 0.37310343980789185 2022-08-12 00:44:05.409085
Epoch:[ 88 18 ] loss: 0.3725362718105316 2022-08-12 00:44:05.833665
Epoch:[ 88 19 ] loss: 0.37269508838653564 2022-08-12 00:44:06.254316
Training_Epoch:[ 88 ] Training_loss: 0.3733599603176117 2022-08-12 00:44:06.255000
learning rate:  0.0010899621001562497
val: 1 0.3951306939125061
val: 2 0.3965000808238983
val: 3 0.3962882161140442
val: 4 0.3939376771450043
val: 5 0.3974458575248718
val: 6 0.39685019850730896
val: 7 0.398826003074646
val: 8 0.40397271513938904
val: 9 0.3991466164588928
val: 10 0.397835373878479
val: 11 0.3976375162601471
val: 12 0.40231287479400635
val: 13 0.39876100420951843
val: 14 0.40017491579055786
val: 15 0.3974863290786743
val: 16 0.4034624993801117
val: 17 0.3955572843551636
val: 18 0.392493337392807
val: 19 0.4038870632648468
val: 20 0.4032546281814575
val_Epoch:[ 88 ] val_loss: 0.39854804426431656 2022-08-12 00:44:09.823534
start training 2022-08-12 00:44:09.939333
Epoch:[ 89 0 ] loss: 0.3725660741329193 2022-08-12 00:44:24.031110
Epoch:[ 89 1 ] loss: 0.37319839000701904 2022-08-12 00:44:24.460941
Epoch:[ 89 2 ] loss: 0.3720327913761139 2022-08-12 00:44:24.882629
Epoch:[ 89 3 ] loss: 0.3718586564064026 2022-08-12 00:44:25.309278
Epoch:[ 89 4 ] loss: 0.373044490814209 2022-08-12 00:44:25.730438
Epoch:[ 89 5 ] loss: 0.3714400827884674 2022-08-12 00:44:26.149011
Epoch:[ 89 6 ] loss: 0.3727864623069763 2022-08-12 00:44:26.570079
Epoch:[ 89 7 ] loss: 0.37286800146102905 2022-08-12 00:44:26.995749
Epoch:[ 89 8 ] loss: 0.3732398450374603 2022-08-12 00:44:27.420053
Epoch:[ 89 9 ] loss: 0.37092941999435425 2022-08-12 00:44:27.839998
Epoch:[ 89 10 ] loss: 0.3748236298561096 2022-08-12 00:44:28.266429
Epoch:[ 89 11 ] loss: 0.37409350275993347 2022-08-12 00:44:28.690789
Epoch:[ 89 12 ] loss: 0.37310272455215454 2022-08-12 00:44:29.111592
Epoch:[ 89 13 ] loss: 0.37277480959892273 2022-08-12 00:44:29.538070
Epoch:[ 89 14 ] loss: 0.37508490681648254 2022-08-12 00:44:29.968874
Epoch:[ 89 15 ] loss: 0.37387606501579285 2022-08-12 00:44:30.388544
Epoch:[ 89 16 ] loss: 0.3759154677391052 2022-08-12 00:44:35.895658
Epoch:[ 89 17 ] loss: 0.3736777603626251 2022-08-12 00:44:36.331983
Epoch:[ 89 18 ] loss: 0.3744639754295349 2022-08-12 00:44:36.759683
Epoch:[ 89 19 ] loss: 0.37249428033828735 2022-08-12 00:44:37.183480
Training_Epoch:[ 89 ] Training_loss: 0.373213566839695 2022-08-12 00:44:37.184190
learning rate:  0.0010899621001562497
val: 1 0.3984658420085907
val: 2 0.3869905471801758
val: 3 0.39758217334747314
val: 4 0.4021436870098114
val: 5 0.40019291639328003
val: 6 0.39595168828964233
val: 7 0.3905099332332611
val: 8 0.3966757655143738
val: 9 0.39697548747062683
val: 10 0.3986797332763672
val: 11 0.4005314111709595
val: 12 0.39682185649871826
val: 13 0.3998735249042511
val: 14 0.39556625485420227
val: 15 0.39897391200065613
val: 16 0.3899722993373871
val: 17 0.4016679525375366
val: 18 0.3921871483325958
val: 19 0.39658161997795105
val: 20 0.3956393599510193
val_Epoch:[ 89 ] val_loss: 0.396599155664444 2022-08-12 00:44:40.834431
start training 2022-08-12 00:44:40.927162
Epoch:[ 90 0 ] loss: 0.37467387318611145 2022-08-12 00:44:55.560445
Epoch:[ 90 1 ] loss: 0.3719342052936554 2022-08-12 00:44:55.986298
Epoch:[ 90 2 ] loss: 0.3734295964241028 2022-08-12 00:44:56.406403
Epoch:[ 90 3 ] loss: 0.3735526204109192 2022-08-12 00:44:56.831994
Epoch:[ 90 4 ] loss: 0.3749569058418274 2022-08-12 00:44:57.254551
Epoch:[ 90 5 ] loss: 0.3743014335632324 2022-08-12 00:44:57.679765
Epoch:[ 90 6 ] loss: 0.37240463495254517 2022-08-12 00:44:58.106386
Epoch:[ 90 7 ] loss: 0.3750232756137848 2022-08-12 00:44:58.528654
Epoch:[ 90 8 ] loss: 0.37360498309135437 2022-08-12 00:44:58.950525
Epoch:[ 90 9 ] loss: 0.3754691183567047 2022-08-12 00:44:59.364011
Epoch:[ 90 10 ] loss: 0.3747352063655853 2022-08-12 00:44:59.784858
Epoch:[ 90 11 ] loss: 0.3753066062927246 2022-08-12 00:45:00.214765
Epoch:[ 90 12 ] loss: 0.37608253955841064 2022-08-12 00:45:00.640014
Epoch:[ 90 13 ] loss: 0.3748224675655365 2022-08-12 00:45:01.059366
Epoch:[ 90 14 ] loss: 0.37530282139778137 2022-08-12 00:45:01.480420
Epoch:[ 90 15 ] loss: 0.3732418119907379 2022-08-12 00:45:01.909539
Epoch:[ 90 16 ] loss: 0.3764370381832123 2022-08-12 00:45:07.262282
Epoch:[ 90 17 ] loss: 0.37337014079093933 2022-08-12 00:45:07.679492
Epoch:[ 90 18 ] loss: 0.3774196207523346 2022-08-12 00:45:08.103315
Epoch:[ 90 19 ] loss: 0.37358933687210083 2022-08-12 00:45:08.528763
Training_Epoch:[ 90 ] Training_loss: 0.37448291182518006 2022-08-12 00:45:08.529430
learning rate:  0.0010899621001562497
netparams have been saved once 90
val: 1 0.4024217426776886
val: 2 0.39862459897994995
val: 3 0.39732682704925537
val: 4 0.3908007740974426
val: 5 0.39420080184936523
val: 6 0.4025726914405823
val: 7 0.4000139832496643
val: 8 0.39412015676498413
val: 9 0.3994971811771393
val: 10 0.39809340238571167
val: 11 0.3976058065891266
val: 12 0.39557790756225586
val: 13 0.39166584610939026
val: 14 0.3994470238685608
val: 15 0.3999137878417969
val: 16 0.3977177143096924
val: 17 0.39799708127975464
val: 18 0.3959581255912781
val: 19 0.3964855968952179
val: 20 0.40079185366630554
val_Epoch:[ 90 ] val_loss: 0.3975416451692581 2022-08-12 00:45:12.103705
start training 2022-08-12 00:45:12.195886
Epoch:[ 91 0 ] loss: 0.37332382798194885 2022-08-12 00:45:26.984872
Epoch:[ 91 1 ] loss: 0.3727129101753235 2022-08-12 00:45:27.407690
Epoch:[ 91 2 ] loss: 0.374025821685791 2022-08-12 00:45:27.828277
Epoch:[ 91 3 ] loss: 0.3723333179950714 2022-08-12 00:45:28.253617
Epoch:[ 91 4 ] loss: 0.3741031885147095 2022-08-12 00:45:28.672612
Epoch:[ 91 5 ] loss: 0.37274011969566345 2022-08-12 00:45:29.088459
Epoch:[ 91 6 ] loss: 0.37316250801086426 2022-08-12 00:45:29.512311
Epoch:[ 91 7 ] loss: 0.37237247824668884 2022-08-12 00:45:29.949792
Epoch:[ 91 8 ] loss: 0.37299224734306335 2022-08-12 00:45:30.371190
Epoch:[ 91 9 ] loss: 0.37271925806999207 2022-08-12 00:45:30.786906
Epoch:[ 91 10 ] loss: 0.37192749977111816 2022-08-12 00:45:31.210957
Epoch:[ 91 11 ] loss: 0.3718540370464325 2022-08-12 00:45:31.635414
Epoch:[ 91 12 ] loss: 0.37209492921829224 2022-08-12 00:45:32.062937
Epoch:[ 91 13 ] loss: 0.37400126457214355 2022-08-12 00:45:32.484171
Epoch:[ 91 14 ] loss: 0.3720434606075287 2022-08-12 00:45:32.910142
Epoch:[ 91 15 ] loss: 0.37205392122268677 2022-08-12 00:45:33.332441
Epoch:[ 91 16 ] loss: 0.37083807587623596 2022-08-12 00:45:38.947094
Epoch:[ 91 17 ] loss: 0.3731815814971924 2022-08-12 00:45:39.373053
Epoch:[ 91 18 ] loss: 0.371528297662735 2022-08-12 00:45:39.796477
Epoch:[ 91 19 ] loss: 0.37263932824134827 2022-08-12 00:45:40.222215
Training_Epoch:[ 91 ] Training_loss: 0.3726324036717415 2022-08-12 00:45:40.222932
learning rate:  0.0009264677851328122
val: 1 0.3979501724243164
val: 2 0.3881746530532837
val: 3 0.4016621708869934
val: 4 0.3962291479110718
val: 5 0.3911198377609253
val: 6 0.39583638310432434
val: 7 0.3948379456996918
val: 8 0.38971808552742004
val: 9 0.39674806594848633
val: 10 0.3972022831439972
val: 11 0.39712122082710266
val: 12 0.39355167746543884
val: 13 0.3929711580276489
val: 14 0.40153971314430237
val: 15 0.3994419574737549
val: 16 0.39320310950279236
val: 17 0.3902217149734497
val: 18 0.39309775829315186
val: 19 0.3945073187351227
val: 20 0.3962692618370056
val_Epoch:[ 91 ] val_loss: 0.39507018178701403 2022-08-12 00:45:43.872409
start training 2022-08-12 00:45:43.968233
Epoch:[ 92 0 ] loss: 0.3700104355812073 2022-08-12 00:45:57.847214
Epoch:[ 92 1 ] loss: 0.37320104241371155 2022-08-12 00:45:58.579083
Epoch:[ 92 2 ] loss: 0.37053561210632324 2022-08-12 00:45:58.996165
Epoch:[ 92 3 ] loss: 0.3696001172065735 2022-08-12 00:45:59.413855
Epoch:[ 92 4 ] loss: 0.3700791001319885 2022-08-12 00:45:59.841807
Epoch:[ 92 5 ] loss: 0.3712001442909241 2022-08-12 00:46:00.270051
Epoch:[ 92 6 ] loss: 0.37148720026016235 2022-08-12 00:46:00.692513
Epoch:[ 92 7 ] loss: 0.3712657690048218 2022-08-12 00:46:01.114632
Epoch:[ 92 8 ] loss: 0.37122011184692383 2022-08-12 00:46:01.538288
Epoch:[ 92 9 ] loss: 0.37044551968574524 2022-08-12 00:46:01.960331
Epoch:[ 92 10 ] loss: 0.37179282307624817 2022-08-12 00:46:02.384355
Epoch:[ 92 11 ] loss: 0.3709985911846161 2022-08-12 00:46:02.802623
Epoch:[ 92 12 ] loss: 0.3728092908859253 2022-08-12 00:46:03.228501
Epoch:[ 92 13 ] loss: 0.3717532753944397 2022-08-12 00:46:03.647823
Epoch:[ 92 14 ] loss: 0.37102290987968445 2022-08-12 00:46:04.062593
Epoch:[ 92 15 ] loss: 0.372723251581192 2022-08-12 00:46:04.484099
Epoch:[ 92 16 ] loss: 0.3736264407634735 2022-08-12 00:46:10.366317
Epoch:[ 92 17 ] loss: 0.3718112111091614 2022-08-12 00:46:10.783272
Epoch:[ 92 18 ] loss: 0.3726810812950134 2022-08-12 00:46:11.208768
Epoch:[ 92 19 ] loss: 0.3732945919036865 2022-08-12 00:46:11.632810
Training_Epoch:[ 92 ] Training_loss: 0.3715779259800911 2022-08-12 00:46:11.633460
learning rate:  0.0009264677851328122
val: 1 0.3946201205253601
val: 2 0.3918314576148987
val: 3 0.3941228687763214
val: 4 0.3959096670150757
val: 5 0.39032530784606934
val: 6 0.38911381363868713
val: 7 0.39241501688957214
val: 8 0.3940906822681427
val: 9 0.3952586054801941
val: 10 0.3989945352077484
val: 11 0.4016879200935364
val: 12 0.4036329984664917
val: 13 0.39018553495407104
val: 14 0.390665203332901
val: 15 0.3968418538570404
val: 16 0.3928295373916626
val: 17 0.38850072026252747
val: 18 0.3976319134235382
val: 19 0.38742637634277344
val: 20 0.3986199200153351
val_Epoch:[ 92 ] val_loss: 0.3942352026700974 2022-08-12 00:46:15.116105
start training 2022-08-12 00:46:15.211107
Epoch:[ 93 0 ] loss: 0.369718462228775 2022-08-12 00:46:29.378365
Epoch:[ 93 1 ] loss: 0.3709704279899597 2022-08-12 00:46:29.807798
Epoch:[ 93 2 ] loss: 0.37144872546195984 2022-08-12 00:46:30.226653
Epoch:[ 93 3 ] loss: 0.3710433840751648 2022-08-12 00:46:30.651177
Epoch:[ 93 4 ] loss: 0.37169158458709717 2022-08-12 00:46:31.072962
Epoch:[ 93 5 ] loss: 0.3711678683757782 2022-08-12 00:46:31.490223
Epoch:[ 93 6 ] loss: 0.3711235225200653 2022-08-12 00:46:31.912512
Epoch:[ 93 7 ] loss: 0.37120920419692993 2022-08-12 00:46:32.337100
Epoch:[ 93 8 ] loss: 0.37021592259407043 2022-08-12 00:46:32.759024
Epoch:[ 93 9 ] loss: 0.3700820803642273 2022-08-12 00:46:33.179520
Epoch:[ 93 10 ] loss: 0.3692391812801361 2022-08-12 00:46:33.604276
Epoch:[ 93 11 ] loss: 0.37100398540496826 2022-08-12 00:46:34.019356
Epoch:[ 93 12 ] loss: 0.37119612097740173 2022-08-12 00:46:34.439303
Epoch:[ 93 13 ] loss: 0.3702971339225769 2022-08-12 00:46:34.865379
Epoch:[ 93 14 ] loss: 0.37234216928482056 2022-08-12 00:46:35.294002
Epoch:[ 93 15 ] loss: 0.3708460330963135 2022-08-12 00:46:35.727319
Epoch:[ 93 16 ] loss: 0.3691956102848053 2022-08-12 00:46:41.228023
Epoch:[ 93 17 ] loss: 0.3718869090080261 2022-08-12 00:46:41.654087
Epoch:[ 93 18 ] loss: 0.3717430531978607 2022-08-12 00:46:42.087982
Epoch:[ 93 19 ] loss: 0.3727734088897705 2022-08-12 00:46:42.509122
Training_Epoch:[ 93 ] Training_loss: 0.37095973938703536 2022-08-12 00:46:42.509776
learning rate:  0.0009264677851328122
val: 1 0.399297297000885
val: 2 0.3975258469581604
val: 3 0.3920774757862091
val: 4 0.395399808883667
val: 5 0.39090409874916077
val: 6 0.3953850567340851
val: 7 0.39203885197639465
val: 8 0.3943343758583069
val: 9 0.39726391434669495
val: 10 0.3885790705680847
val: 11 0.3937303423881531
val: 12 0.3967861533164978
val: 13 0.3978923261165619
val: 14 0.3924189507961273
val: 15 0.39093995094299316
val: 16 0.3963260054588318
val: 17 0.40193819999694824
val: 18 0.39445629715919495
val: 19 0.3994618356227875
val: 20 0.3883819878101349
val_Epoch:[ 93 ] val_loss: 0.394756892323494 2022-08-12 00:46:46.085512
start training 2022-08-12 00:46:46.184798
Epoch:[ 94 0 ] loss: 0.36967092752456665 2022-08-12 00:47:01.129588
Epoch:[ 94 1 ] loss: 0.37137579917907715 2022-08-12 00:47:01.563549
Epoch:[ 94 2 ] loss: 0.369303435087204 2022-08-12 00:47:01.986565
Epoch:[ 94 3 ] loss: 0.36981281638145447 2022-08-12 00:47:02.409220
Epoch:[ 94 4 ] loss: 0.3700280487537384 2022-08-12 00:47:02.827489
Epoch:[ 94 5 ] loss: 0.3710058629512787 2022-08-12 00:47:03.252294
Epoch:[ 94 6 ] loss: 0.3699340522289276 2022-08-12 00:47:03.674487
Epoch:[ 94 7 ] loss: 0.37143754959106445 2022-08-12 00:47:04.100472
Epoch:[ 94 8 ] loss: 0.3691166639328003 2022-08-12 00:47:04.521220
Epoch:[ 94 9 ] loss: 0.370597779750824 2022-08-12 00:47:04.936682
Epoch:[ 94 10 ] loss: 0.3698756992816925 2022-08-12 00:47:05.357378
Epoch:[ 94 11 ] loss: 0.37000784277915955 2022-08-12 00:47:05.782540
Epoch:[ 94 12 ] loss: 0.37115365266799927 2022-08-12 00:47:06.204420
Epoch:[ 94 13 ] loss: 0.3722917139530182 2022-08-12 00:47:06.621959
Epoch:[ 94 14 ] loss: 0.3714296817779541 2022-08-12 00:47:07.044940
Epoch:[ 94 15 ] loss: 0.37228333950042725 2022-08-12 00:47:07.472097
Epoch:[ 94 16 ] loss: 0.37062618136405945 2022-08-12 00:47:13.027911
Epoch:[ 94 17 ] loss: 0.3704964220523834 2022-08-12 00:47:13.446807
Epoch:[ 94 18 ] loss: 0.3724052309989929 2022-08-12 00:47:13.872582
Epoch:[ 94 19 ] loss: 0.36978450417518616 2022-08-12 00:47:14.298018
Training_Epoch:[ 94 ] Training_loss: 0.37063186019659045 2022-08-12 00:47:14.298697
learning rate:  0.0009264677851328122
val: 1 0.3937497138977051
val: 2 0.39296314120292664
val: 3 0.3925352692604065
val: 4 0.3997238576412201
val: 5 0.3960721790790558
val: 6 0.39567887783050537
val: 7 0.3980063498020172
val: 8 0.394839346408844
val: 9 0.4024369716644287
val: 10 0.4017305374145508
val: 11 0.39036983251571655
val: 12 0.4023110866546631
val: 13 0.4020984172821045
val: 14 0.39101526141166687
val: 15 0.3974153995513916
val: 16 0.3946247398853302
val: 17 0.3900839686393738
val: 18 0.39812278747558594
val: 19 0.39906954765319824
val: 20 0.39573970437049866
val_Epoch:[ 94 ] val_loss: 0.3964293494820595 2022-08-12 00:47:17.826379
start training 2022-08-12 00:47:17.921760
Epoch:[ 95 0 ] loss: 0.3705788850784302 2022-08-12 00:47:31.955105
Epoch:[ 95 1 ] loss: 0.37016811966896057 2022-08-12 00:47:32.395277
Epoch:[ 95 2 ] loss: 0.3697323799133301 2022-08-12 00:47:32.819095
Epoch:[ 95 3 ] loss: 0.36946630477905273 2022-08-12 00:47:33.234948
Epoch:[ 95 4 ] loss: 0.3690536618232727 2022-08-12 00:47:33.654334
Epoch:[ 95 5 ] loss: 0.36961907148361206 2022-08-12 00:47:34.078081
Epoch:[ 95 6 ] loss: 0.3698654770851135 2022-08-12 00:47:34.502325
Epoch:[ 95 7 ] loss: 0.37031668424606323 2022-08-12 00:47:34.919525
Epoch:[ 95 8 ] loss: 0.3712478280067444 2022-08-12 00:47:35.343233
Epoch:[ 95 9 ] loss: 0.37045612931251526 2022-08-12 00:47:35.768942
Epoch:[ 95 10 ] loss: 0.3699670732021332 2022-08-12 00:47:36.195138
Epoch:[ 95 11 ] loss: 0.37099209427833557 2022-08-12 00:47:36.612993
Epoch:[ 95 12 ] loss: 0.37084218859672546 2022-08-12 00:47:37.035424
Epoch:[ 95 13 ] loss: 0.37006354331970215 2022-08-12 00:47:37.458696
Epoch:[ 95 14 ] loss: 0.37326136231422424 2022-08-12 00:47:37.882909
Epoch:[ 95 15 ] loss: 0.36975085735321045 2022-08-12 00:47:38.311690
Epoch:[ 95 16 ] loss: 0.37096691131591797 2022-08-12 00:47:44.035058
Epoch:[ 95 17 ] loss: 0.3721676170825958 2022-08-12 00:47:44.460336
Epoch:[ 95 18 ] loss: 0.36977022886276245 2022-08-12 00:47:44.889688
Epoch:[ 95 19 ] loss: 0.37094464898109436 2022-08-12 00:47:45.311859
Training_Epoch:[ 95 ] Training_loss: 0.3704615533351898 2022-08-12 00:47:45.312595
learning rate:  0.0009264677851328122
val: 1 0.39023712277412415
val: 2 0.39778774976730347
val: 3 0.3903805613517761
val: 4 0.3925873935222626
val: 5 0.40171778202056885
val: 6 0.38904303312301636
val: 7 0.39507514238357544
val: 8 0.39243558049201965
val: 9 0.3995055556297302
val: 10 0.3895290493965149
val: 11 0.40121734142303467
val: 12 0.39913392066955566
val: 13 0.3993229269981384
val: 14 0.3963133990764618
val: 15 0.3952311873435974
val: 16 0.395489901304245
val: 17 0.39746972918510437
val: 18 0.3978619873523712
val: 19 0.397478312253952
val: 20 0.40282002091407776
val_Epoch:[ 95 ] val_loss: 0.3960318848490715 2022-08-12 00:47:48.870570
start training 2022-08-12 00:47:48.964377
Epoch:[ 96 0 ] loss: 0.36997395753860474 2022-08-12 00:48:03.129918
Epoch:[ 96 1 ] loss: 0.3704506754875183 2022-08-12 00:48:03.570343
Epoch:[ 96 2 ] loss: 0.3699856102466583 2022-08-12 00:48:04.015268
Epoch:[ 96 3 ] loss: 0.37013787031173706 2022-08-12 00:48:04.441560
Epoch:[ 96 4 ] loss: 0.37024763226509094 2022-08-12 00:48:04.865099
Epoch:[ 96 5 ] loss: 0.3727266192436218 2022-08-12 00:48:05.289695
Epoch:[ 96 6 ] loss: 0.37153610587120056 2022-08-12 00:48:05.706994
Epoch:[ 96 7 ] loss: 0.37069031596183777 2022-08-12 00:48:06.123631
Epoch:[ 96 8 ] loss: 0.3703193664550781 2022-08-12 00:48:06.547724
Epoch:[ 96 9 ] loss: 0.37006276845932007 2022-08-12 00:48:06.972138
Epoch:[ 96 10 ] loss: 0.3722720742225647 2022-08-12 00:48:07.390218
Epoch:[ 96 11 ] loss: 0.37084853649139404 2022-08-12 00:48:07.809023
Epoch:[ 96 12 ] loss: 0.3725622594356537 2022-08-12 00:48:08.231052
Epoch:[ 96 13 ] loss: 0.3703613877296448 2022-08-12 00:48:08.654698
Epoch:[ 96 14 ] loss: 0.370134562253952 2022-08-12 00:48:09.073434
Epoch:[ 96 15 ] loss: 0.3716092109680176 2022-08-12 00:48:09.499905
Epoch:[ 96 16 ] loss: 0.3720826506614685 2022-08-12 00:48:15.154775
Epoch:[ 96 17 ] loss: 0.3730228543281555 2022-08-12 00:48:15.575204
Epoch:[ 96 18 ] loss: 0.37158334255218506 2022-08-12 00:48:16.000133
Epoch:[ 96 19 ] loss: 0.3713151514530182 2022-08-12 00:48:16.423304
Training_Epoch:[ 96 ] Training_loss: 0.37109614759683607 2022-08-12 00:48:16.423985
learning rate:  0.0009264677851328122
val: 1 0.40138038992881775
val: 2 0.3988122045993805
val: 3 0.3950488567352295
val: 4 0.3912540376186371
val: 5 0.4024893343448639
val: 6 0.39945459365844727
val: 7 0.3965269923210144
val: 8 0.3967233896255493
val: 9 0.40026700496673584
val: 10 0.39245960116386414
val: 11 0.3944019675254822
val: 12 0.39256301522254944
val: 13 0.39401495456695557
val: 14 0.3977864682674408
val: 15 0.3931090533733368
val: 16 0.39353033900260925
val: 17 0.39122214913368225
val: 18 0.39282703399658203
val: 19 0.3943425714969635
val: 20 0.398865669965744
val_Epoch:[ 96 ] val_loss: 0.3958539813756943 2022-08-12 00:48:19.967323
start training 2022-08-12 00:48:20.064102
Epoch:[ 97 0 ] loss: 0.36759623885154724 2022-08-12 00:48:34.160962
Epoch:[ 97 1 ] loss: 0.3694339394569397 2022-08-12 00:48:34.650660
Epoch:[ 97 2 ] loss: 0.3702930510044098 2022-08-12 00:48:35.074425
Epoch:[ 97 3 ] loss: 0.37051668763160706 2022-08-12 00:48:35.499688
Epoch:[ 97 4 ] loss: 0.369783878326416 2022-08-12 00:48:35.919426
Epoch:[ 97 5 ] loss: 0.3702126443386078 2022-08-12 00:48:36.342837
Epoch:[ 97 6 ] loss: 0.36928611993789673 2022-08-12 00:48:36.769552
Epoch:[ 97 7 ] loss: 0.3707652986049652 2022-08-12 00:48:37.194230
Epoch:[ 97 8 ] loss: 0.36792999505996704 2022-08-12 00:48:37.612919
Epoch:[ 97 9 ] loss: 0.3700322210788727 2022-08-12 00:48:38.034256
Epoch:[ 97 10 ] loss: 0.36974844336509705 2022-08-12 00:48:38.460075
Epoch:[ 97 11 ] loss: 0.3699130117893219 2022-08-12 00:48:38.886702
Epoch:[ 97 12 ] loss: 0.37089186906814575 2022-08-12 00:48:39.313893
Epoch:[ 97 13 ] loss: 0.3697429895401001 2022-08-12 00:48:39.737407
Epoch:[ 97 14 ] loss: 0.3707895576953888 2022-08-12 00:48:40.160929
Epoch:[ 97 15 ] loss: 0.3706956207752228 2022-08-12 00:48:40.580379
Epoch:[ 97 16 ] loss: 0.3711528778076172 2022-08-12 00:48:45.990702
Epoch:[ 97 17 ] loss: 0.3702681362628937 2022-08-12 00:48:46.528011
Epoch:[ 97 18 ] loss: 0.3706033229827881 2022-08-12 00:48:46.948681
Epoch:[ 97 19 ] loss: 0.3716038763523102 2022-08-12 00:48:47.364845
Training_Epoch:[ 97 ] Training_loss: 0.37006298899650575 2022-08-12 00:48:47.365538
learning rate:  0.0009264677851328122
val: 1 0.3951880931854248
val: 2 0.39745453000068665
val: 3 0.397921621799469
val: 4 0.39041587710380554
val: 5 0.3963734209537506
val: 6 0.3943672776222229
val: 7 0.39871451258659363
val: 8 0.3958631455898285
val: 9 0.39909112453460693
val: 10 0.38904333114624023
val: 11 0.3986312747001648
val: 12 0.4008164703845978
val: 13 0.39252811670303345
val: 14 0.3986615240573883
val: 15 0.39945441484451294
val: 16 0.3931785821914673
val: 17 0.3960122764110565
val: 18 0.392928808927536
val: 19 0.3946896493434906
val: 20 0.39695480465888977
val_Epoch:[ 97 ] val_loss: 0.3959144428372383 2022-08-12 00:48:50.936934
start training 2022-08-12 00:48:51.039019
Epoch:[ 98 0 ] loss: 0.36999189853668213 2022-08-12 00:49:05.209068
Epoch:[ 98 1 ] loss: 0.3680083453655243 2022-08-12 00:49:05.651734
Epoch:[ 98 2 ] loss: 0.37043851613998413 2022-08-12 00:49:06.077699
Epoch:[ 98 3 ] loss: 0.3691084086894989 2022-08-12 00:49:06.493538
Epoch:[ 98 4 ] loss: 0.3690355122089386 2022-08-12 00:49:06.911262
Epoch:[ 98 5 ] loss: 0.3700241446495056 2022-08-12 00:49:07.330871
Epoch:[ 98 6 ] loss: 0.36950889229774475 2022-08-12 00:49:07.757450
Epoch:[ 98 7 ] loss: 0.3686375319957733 2022-08-12 00:49:08.176046
Epoch:[ 98 8 ] loss: 0.3692355155944824 2022-08-12 00:49:08.595831
Epoch:[ 98 9 ] loss: 0.36930134892463684 2022-08-12 00:49:09.016377
Epoch:[ 98 10 ] loss: 0.36844998598098755 2022-08-12 00:49:09.442312
Epoch:[ 98 11 ] loss: 0.36975333094596863 2022-08-12 00:49:09.869775
Epoch:[ 98 12 ] loss: 0.37110134959220886 2022-08-12 00:49:10.290811
Epoch:[ 98 13 ] loss: 0.3682628870010376 2022-08-12 00:49:10.721053
Epoch:[ 98 14 ] loss: 0.36978304386138916 2022-08-12 00:49:11.144028
Epoch:[ 98 15 ] loss: 0.36842799186706543 2022-08-12 00:49:11.564889
Epoch:[ 98 16 ] loss: 0.36997073888778687 2022-08-12 00:49:16.848003
Epoch:[ 98 17 ] loss: 0.3691876232624054 2022-08-12 00:49:17.267543
Epoch:[ 98 18 ] loss: 0.37005969882011414 2022-08-12 00:49:17.684964
Epoch:[ 98 19 ] loss: 0.37012749910354614 2022-08-12 00:49:18.108991
Training_Epoch:[ 98 ] Training_loss: 0.369420713186264 2022-08-12 00:49:18.109842
learning rate:  0.0009264677851328122
val: 1 0.3950602412223816
val: 2 0.3975484073162079
val: 3 0.39571258425712585
val: 4 0.4007442891597748
val: 5 0.39761728048324585
val: 6 0.3933115303516388
val: 7 0.38868650794029236
val: 8 0.3993193209171295
val: 9 0.38798987865448
val: 10 0.399761825799942
val: 11 0.39662137627601624
val: 12 0.393511027097702
val: 13 0.3943319618701935
val: 14 0.39970436692237854
val: 15 0.39315977692604065
val: 16 0.39862197637557983
val: 17 0.3922485113143921
val: 18 0.3951146900653839
val: 19 0.39684855937957764
val: 20 0.3952975571155548
val_Epoch:[ 98 ] val_loss: 0.39556058347225187 2022-08-12 00:49:21.716098
start training 2022-08-12 00:49:21.815920
Epoch:[ 99 0 ] loss: 0.3687020242214203 2022-08-12 00:49:36.347715
Epoch:[ 99 1 ] loss: 0.3695318102836609 2022-08-12 00:49:36.770498
Epoch:[ 99 2 ] loss: 0.36729323863983154 2022-08-12 00:49:37.185218
Epoch:[ 99 3 ] loss: 0.3681790232658386 2022-08-12 00:49:37.607032
Epoch:[ 99 4 ] loss: 0.3687787652015686 2022-08-12 00:49:38.031221
Epoch:[ 99 5 ] loss: 0.36911630630493164 2022-08-12 00:49:38.458380
Epoch:[ 99 6 ] loss: 0.37018707394599915 2022-08-12 00:49:38.880192
Epoch:[ 99 7 ] loss: 0.369726300239563 2022-08-12 00:49:39.306185
Epoch:[ 99 8 ] loss: 0.3692847788333893 2022-08-12 00:49:39.728492
Epoch:[ 99 9 ] loss: 0.3684990108013153 2022-08-12 00:49:40.152673
Epoch:[ 99 10 ] loss: 0.36897194385528564 2022-08-12 00:49:40.578195
Epoch:[ 99 11 ] loss: 0.36863306164741516 2022-08-12 00:49:41.000449
Epoch:[ 99 12 ] loss: 0.3695416748523712 2022-08-12 00:49:41.429245
Epoch:[ 99 13 ] loss: 0.3708968162536621 2022-08-12 00:49:41.843846
Epoch:[ 99 14 ] loss: 0.3705500066280365 2022-08-12 00:49:42.271416
Epoch:[ 99 15 ] loss: 0.37094011902809143 2022-08-12 00:49:42.700881
Epoch:[ 99 16 ] loss: 0.36876317858695984 2022-08-12 00:49:48.023733
Epoch:[ 99 17 ] loss: 0.3704162836074829 2022-08-12 00:49:48.439570
Epoch:[ 99 18 ] loss: 0.3696841895580292 2022-08-12 00:49:48.865144
Epoch:[ 99 19 ] loss: 0.37048178911209106 2022-08-12 00:49:49.291786
Training_Epoch:[ 99 ] Training_loss: 0.3694088697433472 2022-08-12 00:49:49.292496
learning rate:  0.0009264677851328122
val: 1 0.39323925971984863
val: 2 0.3943632245063782
val: 3 0.3895701467990875
val: 4 0.3977930247783661
val: 5 0.39483511447906494
val: 6 0.39475348591804504
val: 7 0.3930613696575165
val: 8 0.3955855071544647
val: 9 0.4040694832801819
val: 10 0.39842426776885986
val: 11 0.38902711868286133
val: 12 0.39793017506599426
val: 13 0.3895500600337982
val: 14 0.393439382314682
val: 15 0.3930880129337311
val: 16 0.39563068747520447
val: 17 0.4037338197231293
val: 18 0.3975633680820465
val: 19 0.3981131315231323
val: 20 0.3969506025314331
val_Epoch:[ 99 ] val_loss: 0.3955360621213913 2022-08-12 00:49:52.855085
start training 2022-08-12 00:49:52.950287
Epoch:[ 100 0 ] loss: 0.36629626154899597 2022-08-12 00:50:07.311104
Epoch:[ 100 1 ] loss: 0.37046974897384644 2022-08-12 00:50:07.750797
Epoch:[ 100 2 ] loss: 0.3686095178127289 2022-08-12 00:50:08.165228
Epoch:[ 100 3 ] loss: 0.368404358625412 2022-08-12 00:50:08.588431
Epoch:[ 100 4 ] loss: 0.36890238523483276 2022-08-12 00:50:09.012035
Epoch:[ 100 5 ] loss: 0.3683515787124634 2022-08-12 00:50:09.429640
Epoch:[ 100 6 ] loss: 0.36936017870903015 2022-08-12 00:50:09.853499
Epoch:[ 100 7 ] loss: 0.3681507706642151 2022-08-12 00:50:10.277827
Epoch:[ 100 8 ] loss: 0.36981379985809326 2022-08-12 00:50:10.700372
Epoch:[ 100 9 ] loss: 0.3698006570339203 2022-08-12 00:50:11.121582
Epoch:[ 100 10 ] loss: 0.37055227160453796 2022-08-12 00:50:11.543364
Epoch:[ 100 11 ] loss: 0.36858806014060974 2022-08-12 00:50:11.962677
Epoch:[ 100 12 ] loss: 0.37104296684265137 2022-08-12 00:50:12.381119
Epoch:[ 100 13 ] loss: 0.3709723651409149 2022-08-12 00:50:12.804745
Epoch:[ 100 14 ] loss: 0.3702603280544281 2022-08-12 00:50:13.238822
Epoch:[ 100 15 ] loss: 0.3728359043598175 2022-08-12 00:50:13.657353
Epoch:[ 100 16 ] loss: 0.371041864156723 2022-08-12 00:50:19.269420
Epoch:[ 100 17 ] loss: 0.37477725744247437 2022-08-12 00:50:19.694463
Epoch:[ 100 18 ] loss: 0.3721291720867157 2022-08-12 00:50:20.117110
Epoch:[ 100 19 ] loss: 0.3709692060947418 2022-08-12 00:50:20.537610
Training_Epoch:[ 100 ] Training_loss: 0.3700664326548576 2022-08-12 00:50:20.538283
learning rate:  0.0009264677851328122
netparams have been saved once 100
val: 1 0.3953578770160675
val: 2 0.39207586646080017
val: 3 0.39509356021881104
val: 4 0.3970614969730377
val: 5 0.398629754781723
val: 6 0.4008188843727112
val: 7 0.3911442756652832
val: 8 0.39380618929862976
val: 9 0.4040658175945282
val: 10 0.4043613374233246
val: 11 0.40016427636146545
val: 12 0.3953518569469452
val: 13 0.4013413190841675
val: 14 0.39929336309432983
val: 15 0.4013897180557251
val: 16 0.39071008563041687
val: 17 0.39391568303108215
val: 18 0.3958424925804138
val: 19 0.3932485282421112
val: 20 0.4003430902957916
val_Epoch:[ 100 ] val_loss: 0.39720077365636824 2022-08-12 00:50:24.159862
start training 2022-08-12 00:50:24.254373
Epoch:[ 101 0 ] loss: 0.3689500689506531 2022-08-12 00:50:38.362915
Epoch:[ 101 1 ] loss: 0.3699302077293396 2022-08-12 00:50:38.968089
Epoch:[ 101 2 ] loss: 0.3698723018169403 2022-08-12 00:50:39.394523
Epoch:[ 101 3 ] loss: 0.36879923939704895 2022-08-12 00:50:39.812409
Epoch:[ 101 4 ] loss: 0.3683333694934845 2022-08-12 00:50:40.235496
Epoch:[ 101 5 ] loss: 0.36870861053466797 2022-08-12 00:50:40.659210
Epoch:[ 101 6 ] loss: 0.36935463547706604 2022-08-12 00:50:41.080519
Epoch:[ 101 7 ] loss: 0.36877378821372986 2022-08-12 00:50:41.508042
Epoch:[ 101 8 ] loss: 0.36847588419914246 2022-08-12 00:50:41.934362
Epoch:[ 101 9 ] loss: 0.36927518248558044 2022-08-12 00:50:42.355250
Epoch:[ 101 10 ] loss: 0.3675934672355652 2022-08-12 00:50:42.770995
Epoch:[ 101 11 ] loss: 0.37005847692489624 2022-08-12 00:50:43.189252
Epoch:[ 101 12 ] loss: 0.3683338463306427 2022-08-12 00:50:43.614415
Epoch:[ 101 13 ] loss: 0.36956122517585754 2022-08-12 00:50:44.035678
Epoch:[ 101 14 ] loss: 0.36954978108406067 2022-08-12 00:50:44.454943
Epoch:[ 101 15 ] loss: 0.36950793862342834 2022-08-12 00:50:44.878596
Epoch:[ 101 16 ] loss: 0.36958110332489014 2022-08-12 00:50:50.410931
Epoch:[ 101 17 ] loss: 0.36979129910469055 2022-08-12 00:50:50.828144
Epoch:[ 101 18 ] loss: 0.3702548146247864 2022-08-12 00:50:51.242453
Epoch:[ 101 19 ] loss: 0.3680674731731415 2022-08-12 00:50:51.666992
Training_Epoch:[ 101 ] Training_loss: 0.3691386356949806 2022-08-12 00:50:51.667660
learning rate:  0.0007874976173628904
val: 1 0.3956603407859802
val: 2 0.40025001764297485
val: 3 0.39595329761505127
val: 4 0.3978877067565918
val: 5 0.3942772448062897
val: 6 0.3996046781539917
val: 7 0.3961557149887085
val: 8 0.39589399099349976
val: 9 0.3990846276283264
val: 10 0.40030038356781006
val: 11 0.40053683519363403
val: 12 0.3960946798324585
val: 13 0.39957842230796814
val: 14 0.39494532346725464
val: 15 0.39109161496162415
val: 16 0.39626437425613403
val: 17 0.397993803024292
val: 18 0.38961708545684814
val: 19 0.39298591017723083
val: 20 0.40315014123916626
val_Epoch:[ 101 ] val_loss: 0.39686630964279174 2022-08-12 00:50:55.273795
start training 2022-08-12 00:50:55.368746
Epoch:[ 102 0 ] loss: 0.36949479579925537 2022-08-12 00:51:10.127185
Epoch:[ 102 1 ] loss: 0.3674733340740204 2022-08-12 00:51:10.551728
Epoch:[ 102 2 ] loss: 0.3691956400871277 2022-08-12 00:51:10.971606
Epoch:[ 102 3 ] loss: 0.3666396141052246 2022-08-12 00:51:11.389044
Epoch:[ 102 4 ] loss: 0.36885589361190796 2022-08-12 00:51:11.808479
Epoch:[ 102 5 ] loss: 0.3684435188770294 2022-08-12 00:51:12.235716
Epoch:[ 102 6 ] loss: 0.3676412105560303 2022-08-12 00:51:12.657210
Epoch:[ 102 7 ] loss: 0.3680698871612549 2022-08-12 00:51:13.077896
Epoch:[ 102 8 ] loss: 0.36680126190185547 2022-08-12 00:51:13.500051
Epoch:[ 102 9 ] loss: 0.3680986762046814 2022-08-12 00:51:13.926412
Epoch:[ 102 10 ] loss: 0.37004154920578003 2022-08-12 00:51:14.354148
Epoch:[ 102 11 ] loss: 0.36901187896728516 2022-08-12 00:51:14.769883
Epoch:[ 102 12 ] loss: 0.3681067228317261 2022-08-12 00:51:15.193061
Epoch:[ 102 13 ] loss: 0.367443323135376 2022-08-12 00:51:15.616623
Epoch:[ 102 14 ] loss: 0.36865663528442383 2022-08-12 00:51:16.040982
Epoch:[ 102 15 ] loss: 0.36834263801574707 2022-08-12 00:51:16.469826
Epoch:[ 102 16 ] loss: 0.3687681257724762 2022-08-12 00:51:22.468456
Epoch:[ 102 17 ] loss: 0.3691212832927704 2022-08-12 00:51:22.891613
Epoch:[ 102 18 ] loss: 0.36931803822517395 2022-08-12 00:51:23.315442
Epoch:[ 102 19 ] loss: 0.3689620792865753 2022-08-12 00:51:23.739361
Training_Epoch:[ 102 ] Training_loss: 0.3684243053197861 2022-08-12 00:51:23.740103
learning rate:  0.0007874976173628904
val: 1 0.39238134026527405
val: 2 0.3951261043548584
val: 3 0.39340633153915405
val: 4 0.4017746150493622
val: 5 0.3940943777561188
val: 6 0.39436665177345276
val: 7 0.4005228281021118
val: 8 0.3990005850791931
val: 9 0.39699968695640564
val: 10 0.3943882882595062
val: 11 0.4006357789039612
val: 12 0.39697265625
val: 13 0.39794549345970154
val: 14 0.3972265124320984
val: 15 0.39189040660858154
val: 16 0.39301207661628723
val: 17 0.39861351251602173
val: 18 0.4000369608402252
val: 19 0.39439237117767334
val: 20 0.405476450920105
val_Epoch:[ 102 ] val_loss: 0.3969131514430046 2022-08-12 00:51:27.323219
start training 2022-08-12 00:51:27.420869
Epoch:[ 103 0 ] loss: 0.36765316128730774 2022-08-12 00:51:41.953412
Epoch:[ 103 1 ] loss: 0.36926552653312683 2022-08-12 00:51:42.381141
Epoch:[ 103 2 ] loss: 0.3680863678455353 2022-08-12 00:51:42.805711
Epoch:[ 103 3 ] loss: 0.36807334423065186 2022-08-12 00:51:43.230085
Epoch:[ 103 4 ] loss: 0.36678701639175415 2022-08-12 00:51:43.651964
Epoch:[ 103 5 ] loss: 0.3680991232395172 2022-08-12 00:51:44.063099
Epoch:[ 103 6 ] loss: 0.367989182472229 2022-08-12 00:51:44.485575
Epoch:[ 103 7 ] loss: 0.3676067590713501 2022-08-12 00:51:44.911127
Epoch:[ 103 8 ] loss: 0.3677327334880829 2022-08-12 00:51:45.332527
Epoch:[ 103 9 ] loss: 0.3674846589565277 2022-08-12 00:51:45.749053
Epoch:[ 103 10 ] loss: 0.3666706085205078 2022-08-12 00:51:46.176949
Epoch:[ 103 11 ] loss: 0.367576539516449 2022-08-12 00:51:46.603494
Epoch:[ 103 12 ] loss: 0.3666793406009674 2022-08-12 00:51:47.029226
Epoch:[ 103 13 ] loss: 0.3679598271846771 2022-08-12 00:51:47.449303
Epoch:[ 103 14 ] loss: 0.36767134070396423 2022-08-12 00:51:47.872023
Epoch:[ 103 15 ] loss: 0.36789724230766296 2022-08-12 00:51:48.292978
Epoch:[ 103 16 ] loss: 0.36802858114242554 2022-08-12 00:51:53.661257
Epoch:[ 103 17 ] loss: 0.3688773214817047 2022-08-12 00:51:54.086455
Epoch:[ 103 18 ] loss: 0.3682175278663635 2022-08-12 00:51:54.514333
Epoch:[ 103 19 ] loss: 0.36947551369667053 2022-08-12 00:51:54.937875
Training_Epoch:[ 103 ] Training_loss: 0.36789158582687376 2022-08-12 00:51:54.938546
learning rate:  0.0007874976173628904
val: 1 0.39952516555786133
val: 2 0.3968874514102936
val: 3 0.3926464021205902
val: 4 0.39540883898735046
val: 5 0.39159858226776123
val: 6 0.3962220251560211
val: 7 0.3995334208011627
val: 8 0.3931521475315094
val: 9 0.39126625657081604
val: 10 0.3988707661628723
val: 11 0.40138739347457886
val: 12 0.39372995495796204
val: 13 0.3955593407154083
val: 14 0.3875185251235962
val: 15 0.39424723386764526
val: 16 0.3948521912097931
val: 17 0.4040799140930176
val: 18 0.39894720911979675
val: 19 0.39296069741249084
val: 20 0.39551153779029846
val_Epoch:[ 103 ] val_loss: 0.39569525271654127 2022-08-12 00:51:58.521215
start training 2022-08-12 00:51:58.619084
Epoch:[ 104 0 ] loss: 0.3657289743423462 2022-08-12 00:52:12.821512
Epoch:[ 104 1 ] loss: 0.36662861704826355 2022-08-12 00:52:13.245389
Epoch:[ 104 2 ] loss: 0.3672391176223755 2022-08-12 00:52:13.663636
Epoch:[ 104 3 ] loss: 0.3688881993293762 2022-08-12 00:52:14.084746
Epoch:[ 104 4 ] loss: 0.36809125542640686 2022-08-12 00:52:14.507635
Epoch:[ 104 5 ] loss: 0.3687795102596283 2022-08-12 00:52:14.932934
Epoch:[ 104 6 ] loss: 0.36809077858924866 2022-08-12 00:52:15.357979
Epoch:[ 104 7 ] loss: 0.3660925626754761 2022-08-12 00:52:15.776863
Epoch:[ 104 8 ] loss: 0.36626991629600525 2022-08-12 00:52:16.200551
Epoch:[ 104 9 ] loss: 0.3684069514274597 2022-08-12 00:52:16.617753
Epoch:[ 104 10 ] loss: 0.3678424656391144 2022-08-12 00:52:17.040789
Epoch:[ 104 11 ] loss: 0.366718590259552 2022-08-12 00:52:17.467119
Epoch:[ 104 12 ] loss: 0.36682653427124023 2022-08-12 00:52:17.894425
Epoch:[ 104 13 ] loss: 0.3685292899608612 2022-08-12 00:52:18.316202
Epoch:[ 104 14 ] loss: 0.3659442663192749 2022-08-12 00:52:18.731242
Epoch:[ 104 15 ] loss: 0.3668782711029053 2022-08-12 00:52:19.149212
Epoch:[ 104 16 ] loss: 0.36816802620887756 2022-08-12 00:52:24.623504
Epoch:[ 104 17 ] loss: 0.3676135241985321 2022-08-12 00:52:25.063394
Epoch:[ 104 18 ] loss: 0.3671417534351349 2022-08-12 00:52:25.486672
Epoch:[ 104 19 ] loss: 0.36757394671440125 2022-08-12 00:52:25.910932
Training_Epoch:[ 104 ] Training_loss: 0.367372627556324 2022-08-12 00:52:25.911724
learning rate:  0.0007874976173628904
val: 1 0.38955965638160706
val: 2 0.38675642013549805
val: 3 0.39487919211387634
val: 4 0.3924490511417389
val: 5 0.39610543847084045
val: 6 0.39536479115486145
val: 7 0.39800065755844116
val: 8 0.39013683795928955
val: 9 0.3956758975982666
val: 10 0.39846092462539673
val: 11 0.40125539898872375
val: 12 0.3907020390033722
val: 13 0.3926531672477722
val: 14 0.3911392390727997
val: 15 0.3995892405509949
val: 16 0.3909294307231903
val: 17 0.3943921625614166
val: 18 0.4031826853752136
val: 19 0.3928239047527313
val: 20 0.39406242966651917
val_Epoch:[ 104 ] val_loss: 0.3944059282541275 2022-08-12 00:52:29.467510
start training 2022-08-12 00:52:29.566302
Epoch:[ 105 0 ] loss: 0.36628180742263794 2022-08-12 00:52:43.983264
Epoch:[ 105 1 ] loss: 0.3658803701400757 2022-08-12 00:52:44.426664
Epoch:[ 105 2 ] loss: 0.36667054891586304 2022-08-12 00:52:44.841942
Epoch:[ 105 3 ] loss: 0.3669548034667969 2022-08-12 00:52:45.261767
Epoch:[ 105 4 ] loss: 0.3655077815055847 2022-08-12 00:52:45.688050
Epoch:[ 105 5 ] loss: 0.3669947385787964 2022-08-12 00:52:46.109007
Epoch:[ 105 6 ] loss: 0.3656059205532074 2022-08-12 00:52:46.530034
Epoch:[ 105 7 ] loss: 0.3670286238193512 2022-08-12 00:52:46.950344
Epoch:[ 105 8 ] loss: 0.36593466997146606 2022-08-12 00:52:47.380489
Epoch:[ 105 9 ] loss: 0.3660503923892975 2022-08-12 00:52:47.804787
Epoch:[ 105 10 ] loss: 0.3664298951625824 2022-08-12 00:52:48.222459
Epoch:[ 105 11 ] loss: 0.3668001592159271 2022-08-12 00:52:48.645857
Epoch:[ 105 12 ] loss: 0.3664339482784271 2022-08-12 00:52:49.070162
Epoch:[ 105 13 ] loss: 0.3663877546787262 2022-08-12 00:52:49.492318
Epoch:[ 105 14 ] loss: 0.36734452843666077 2022-08-12 00:52:49.918297
Epoch:[ 105 15 ] loss: 0.3685343563556671 2022-08-12 00:52:50.341663
Epoch:[ 105 16 ] loss: 0.3667866885662079 2022-08-12 00:52:55.647310
Epoch:[ 105 17 ] loss: 0.3682135343551636 2022-08-12 00:52:56.071378
Epoch:[ 105 18 ] loss: 0.3685056269168854 2022-08-12 00:52:56.500365
Epoch:[ 105 19 ] loss: 0.36850452423095703 2022-08-12 00:52:56.923111
Training_Epoch:[ 105 ] Training_loss: 0.36684253364801406 2022-08-12 00:52:56.923889
learning rate:  0.0007874976173628904
val: 1 0.39458978176116943
val: 2 0.3929159939289093
val: 3 0.39768776297569275
val: 4 0.3980196416378021
val: 5 0.4029759168624878
val: 6 0.39395952224731445
val: 7 0.40086624026298523
val: 8 0.38987892866134644
val: 9 0.395815372467041
val: 10 0.39179497957229614
val: 11 0.3896138072013855
val: 12 0.39761069416999817
val: 13 0.40114614367485046
val: 14 0.39672526717185974
val: 15 0.39246416091918945
val: 16 0.4095611274242401
val: 17 0.3945830166339874
val: 18 0.40199577808380127
val: 19 0.38975852727890015
val: 20 0.3959333598613739
val_Epoch:[ 105 ] val_loss: 0.39639480113983155 2022-08-12 00:53:00.456188
start training 2022-08-12 00:53:00.551068
Epoch:[ 106 0 ] loss: 0.3669454753398895 2022-08-12 00:53:15.284058
Epoch:[ 106 1 ] loss: 0.3668785095214844 2022-08-12 00:53:15.709009
Epoch:[ 106 2 ] loss: 0.36498165130615234 2022-08-12 00:53:16.134983
Epoch:[ 106 3 ] loss: 0.3669686019420624 2022-08-12 00:53:16.552917
Epoch:[ 106 4 ] loss: 0.3674432337284088 2022-08-12 00:53:16.976015
Epoch:[ 106 5 ] loss: 0.3665875792503357 2022-08-12 00:53:17.396847
Epoch:[ 106 6 ] loss: 0.36634382605552673 2022-08-12 00:53:17.824706
Epoch:[ 106 7 ] loss: 0.3674847185611725 2022-08-12 00:53:18.248794
Epoch:[ 106 8 ] loss: 0.365818053483963 2022-08-12 00:53:18.672513
Epoch:[ 106 9 ] loss: 0.3674594461917877 2022-08-12 00:53:19.096746
Epoch:[ 106 10 ] loss: 0.36687424778938293 2022-08-12 00:53:19.519417
Epoch:[ 106 11 ] loss: 0.3659003973007202 2022-08-12 00:53:19.931679
Epoch:[ 106 12 ] loss: 0.36773350834846497 2022-08-12 00:53:20.359703
Epoch:[ 106 13 ] loss: 0.36625298857688904 2022-08-12 00:53:20.790902
Epoch:[ 106 14 ] loss: 0.3664630353450775 2022-08-12 00:53:21.214955
Epoch:[ 106 15 ] loss: 0.36865508556365967 2022-08-12 00:53:21.633466
Epoch:[ 106 16 ] loss: 0.3672217130661011 2022-08-12 00:53:27.045769
Epoch:[ 106 17 ] loss: 0.36756208539009094 2022-08-12 00:53:27.469171
Epoch:[ 106 18 ] loss: 0.36656898260116577 2022-08-12 00:53:27.897083
Epoch:[ 106 19 ] loss: 0.3666588068008423 2022-08-12 00:53:28.319101
Training_Epoch:[ 106 ] Training_loss: 0.36684009730815886 2022-08-12 00:53:28.319897
learning rate:  0.0007874976173628904
val: 1 0.38881930708885193
val: 2 0.3977015018463135
val: 3 0.3919026553630829
val: 4 0.39113694429397583
val: 5 0.3899688124656677
val: 6 0.39894261956214905
val: 7 0.396492600440979
val: 8 0.3963983654975891
val: 9 0.3992759585380554
val: 10 0.3981384038925171
val: 11 0.39930760860443115
val: 12 0.3934430181980133
val: 13 0.39660972356796265
val: 14 0.39673715829849243
val: 15 0.3927496671676636
val: 16 0.3964254856109619
val: 17 0.3946652114391327
val: 18 0.3912385404109955
val: 19 0.3927250802516937
val: 20 0.39481812715530396
val_Epoch:[ 106 ] val_loss: 0.3948748394846916 2022-08-12 00:53:31.971605
start training 2022-08-12 00:53:32.071860
Epoch:[ 107 0 ] loss: 0.3650129437446594 2022-08-12 00:53:46.796136
Epoch:[ 107 1 ] loss: 0.36610081791877747 2022-08-12 00:53:47.220106
Epoch:[ 107 2 ] loss: 0.3656127452850342 2022-08-12 00:53:47.644236
Epoch:[ 107 3 ] loss: 0.36615490913391113 2022-08-12 00:53:48.064916
Epoch:[ 107 4 ] loss: 0.36694979667663574 2022-08-12 00:53:48.488019
Epoch:[ 107 5 ] loss: 0.3669244050979614 2022-08-12 00:53:48.908415
Epoch:[ 107 6 ] loss: 0.3651832342147827 2022-08-12 00:53:49.332466
Epoch:[ 107 7 ] loss: 0.364532470703125 2022-08-12 00:53:49.752970
Epoch:[ 107 8 ] loss: 0.36408621072769165 2022-08-12 00:53:50.167859
Epoch:[ 107 9 ] loss: 0.36646342277526855 2022-08-12 00:53:50.592455
Epoch:[ 107 10 ] loss: 0.3651691973209381 2022-08-12 00:53:51.023817
Epoch:[ 107 11 ] loss: 0.3662889301776886 2022-08-12 00:53:51.451205
Epoch:[ 107 12 ] loss: 0.36561211943626404 2022-08-12 00:53:51.871805
Epoch:[ 107 13 ] loss: 0.3650156259536743 2022-08-12 00:53:52.293657
Epoch:[ 107 14 ] loss: 0.3672511577606201 2022-08-12 00:53:52.713401
Epoch:[ 107 15 ] loss: 0.365478515625 2022-08-12 00:53:53.138948
Epoch:[ 107 16 ] loss: 0.3668636977672577 2022-08-12 00:53:58.580508
Epoch:[ 107 17 ] loss: 0.36733829975128174 2022-08-12 00:53:59.001781
Epoch:[ 107 18 ] loss: 0.36849039793014526 2022-08-12 00:53:59.425108
Epoch:[ 107 19 ] loss: 0.3682183623313904 2022-08-12 00:53:59.848531
Training_Epoch:[ 107 ] Training_loss: 0.3661373630166054 2022-08-12 00:53:59.849226
learning rate:  0.0007874976173628904
val: 1 0.39303621649742126
val: 2 0.4073066711425781
val: 3 0.39685213565826416
val: 4 0.40017810463905334
val: 5 0.401741087436676
val: 6 0.3922756314277649
val: 7 0.3989657461643219
val: 8 0.39841604232788086
val: 9 0.3946450650691986
val: 10 0.3970029056072235
val: 11 0.3964434564113617
val: 12 0.3971594572067261
val: 13 0.3986276388168335
val: 14 0.40033984184265137
val: 15 0.3947109878063202
val: 16 0.3943677842617035
val: 17 0.404184490442276
val: 18 0.39795568585395813
val: 19 0.39558133482933044
val: 20 0.3916928768157959
val_Epoch:[ 107 ] val_loss: 0.397574158012867 2022-08-12 00:54:03.383614
start training 2022-08-12 00:54:03.477015
Epoch:[ 108 0 ] loss: 0.36568376421928406 2022-08-12 00:54:18.299330
Epoch:[ 108 1 ] loss: 0.36753222346305847 2022-08-12 00:54:18.724887
Epoch:[ 108 2 ] loss: 0.36561834812164307 2022-08-12 00:54:19.149719
Epoch:[ 108 3 ] loss: 0.3661714196205139 2022-08-12 00:54:19.571406
Epoch:[ 108 4 ] loss: 0.3652680218219757 2022-08-12 00:54:19.996214
Epoch:[ 108 5 ] loss: 0.36529117822647095 2022-08-12 00:54:20.413993
Epoch:[ 108 6 ] loss: 0.36596524715423584 2022-08-12 00:54:20.828839
Epoch:[ 108 7 ] loss: 0.36593693494796753 2022-08-12 00:54:21.254083
Epoch:[ 108 8 ] loss: 0.36559993028640747 2022-08-12 00:54:21.686253
Epoch:[ 108 9 ] loss: 0.36611440777778625 2022-08-12 00:54:22.114052
Epoch:[ 108 10 ] loss: 0.36533305048942566 2022-08-12 00:54:22.529498
Epoch:[ 108 11 ] loss: 0.36566510796546936 2022-08-12 00:54:22.953086
Epoch:[ 108 12 ] loss: 0.3666498363018036 2022-08-12 00:54:23.378100
Epoch:[ 108 13 ] loss: 0.36773255467414856 2022-08-12 00:54:23.803383
Epoch:[ 108 14 ] loss: 0.3674873411655426 2022-08-12 00:54:24.230045
Epoch:[ 108 15 ] loss: 0.36538857221603394 2022-08-12 00:54:24.654494
Epoch:[ 108 16 ] loss: 0.36869755387306213 2022-08-12 00:54:30.189400
Epoch:[ 108 17 ] loss: 0.36601126194000244 2022-08-12 00:54:30.607124
Epoch:[ 108 18 ] loss: 0.36689120531082153 2022-08-12 00:54:31.031599
Epoch:[ 108 19 ] loss: 0.3669138252735138 2022-08-12 00:54:31.456376
Training_Epoch:[ 108 ] Training_loss: 0.36629758924245837 2022-08-12 00:54:31.457133
learning rate:  0.0007874976173628904
val: 1 0.40004658699035645
val: 2 0.39638209342956543
val: 3 0.3989052474498749
val: 4 0.38740795850753784
val: 5 0.40247842669487
val: 6 0.39267218112945557
val: 7 0.3998822569847107
val: 8 0.40674319863319397
val: 9 0.3920547664165497
val: 10 0.3998497724533081
val: 11 0.3974801003932953
val: 12 0.39599013328552246
val: 13 0.392543226480484
val: 14 0.40167659521102905
val: 15 0.39665403962135315
val: 16 0.3893280327320099
val: 17 0.39171311259269714
val: 18 0.391452819108963
val: 19 0.3908609449863434
val: 20 0.40269720554351807
val_Epoch:[ 108 ] val_loss: 0.3963409349322319 2022-08-12 00:54:35.063418
start training 2022-08-12 00:54:35.159763
Epoch:[ 109 0 ] loss: 0.36648252606391907 2022-08-12 00:54:49.818002
Epoch:[ 109 1 ] loss: 0.36600786447525024 2022-08-12 00:54:50.246396
Epoch:[ 109 2 ] loss: 0.36682629585266113 2022-08-12 00:54:50.667877
Epoch:[ 109 3 ] loss: 0.36423179507255554 2022-08-12 00:54:51.080995
Epoch:[ 109 4 ] loss: 0.367669016122818 2022-08-12 00:54:51.506986
Epoch:[ 109 5 ] loss: 0.365182489156723 2022-08-12 00:54:51.932107
Epoch:[ 109 6 ] loss: 0.3652278184890747 2022-08-12 00:54:52.355892
Epoch:[ 109 7 ] loss: 0.3670400083065033 2022-08-12 00:54:52.776696
Epoch:[ 109 8 ] loss: 0.36438724398612976 2022-08-12 00:54:53.200825
Epoch:[ 109 9 ] loss: 0.36612966656684875 2022-08-12 00:54:53.620990
Epoch:[ 109 10 ] loss: 0.365416944026947 2022-08-12 00:54:54.045230
Epoch:[ 109 11 ] loss: 0.3654659390449524 2022-08-12 00:54:54.470867
Epoch:[ 109 12 ] loss: 0.36570703983306885 2022-08-12 00:54:54.893788
Epoch:[ 109 13 ] loss: 0.3664925694465637 2022-08-12 00:54:55.311198
Epoch:[ 109 14 ] loss: 0.366194486618042 2022-08-12 00:54:55.726949
Epoch:[ 109 15 ] loss: 0.3659942150115967 2022-08-12 00:54:56.149430
Epoch:[ 109 16 ] loss: 0.3662593960762024 2022-08-12 00:55:01.416643
Epoch:[ 109 17 ] loss: 0.3658296465873718 2022-08-12 00:55:01.836153
Epoch:[ 109 18 ] loss: 0.3664989471435547 2022-08-12 00:55:02.252021
Epoch:[ 109 19 ] loss: 0.367036372423172 2022-08-12 00:55:02.673206
Training_Epoch:[ 109 ] Training_loss: 0.3660040140151978 2022-08-12 00:55:02.673910
learning rate:  0.0007874976173628904
val: 1 0.40179306268692017
val: 2 0.40076860785484314
val: 3 0.4023066759109497
val: 4 0.40422874689102173
val: 5 0.407317578792572
val: 6 0.400600790977478
val: 7 0.40555429458618164
val: 8 0.39903363585472107
val: 9 0.39784005284309387
val: 10 0.39955446124076843
val: 11 0.40328478813171387
val: 12 0.4004950225353241
val: 13 0.4012729227542877
val: 14 0.4007381200790405
val: 15 0.39575836062431335
val: 16 0.38959985971450806
val: 17 0.3949487507343292
val: 18 0.39922308921813965
val: 19 0.3937376141548157
val: 20 0.3970951437950134
val_Epoch:[ 109 ] val_loss: 0.39975757896900177 2022-08-12 00:55:06.223558
start training 2022-08-12 00:55:06.321009
Epoch:[ 110 0 ] loss: 0.365536630153656 2022-08-12 00:55:21.009174
Epoch:[ 110 1 ] loss: 0.3650535047054291 2022-08-12 00:55:21.429148
Epoch:[ 110 2 ] loss: 0.3664856255054474 2022-08-12 00:55:21.842334
Epoch:[ 110 3 ] loss: 0.36659830808639526 2022-08-12 00:55:22.266537
Epoch:[ 110 4 ] loss: 0.36462438106536865 2022-08-12 00:55:22.697219
Epoch:[ 110 5 ] loss: 0.3654065728187561 2022-08-12 00:55:23.115862
Epoch:[ 110 6 ] loss: 0.3650415241718292 2022-08-12 00:55:23.529393
Epoch:[ 110 7 ] loss: 0.3662572503089905 2022-08-12 00:55:23.954389
Epoch:[ 110 8 ] loss: 0.36702609062194824 2022-08-12 00:55:24.381117
Epoch:[ 110 9 ] loss: 0.3654758632183075 2022-08-12 00:55:24.801301
Epoch:[ 110 10 ] loss: 0.3660651743412018 2022-08-12 00:55:25.224481
Epoch:[ 110 11 ] loss: 0.3669270873069763 2022-08-12 00:55:25.649716
Epoch:[ 110 12 ] loss: 0.36684831976890564 2022-08-12 00:55:26.068426
Epoch:[ 110 13 ] loss: 0.36632174253463745 2022-08-12 00:55:26.491667
Epoch:[ 110 14 ] loss: 0.3667921721935272 2022-08-12 00:55:26.917267
Epoch:[ 110 15 ] loss: 0.3669019937515259 2022-08-12 00:55:27.341166
Epoch:[ 110 16 ] loss: 0.3667295575141907 2022-08-12 00:55:32.504119
Epoch:[ 110 17 ] loss: 0.3678864538669586 2022-08-12 00:55:32.928816
Epoch:[ 110 18 ] loss: 0.3671981394290924 2022-08-12 00:55:33.356524
Epoch:[ 110 19 ] loss: 0.36609992384910583 2022-08-12 00:55:33.779843
Training_Epoch:[ 110 ] Training_loss: 0.3662638157606125 2022-08-12 00:55:33.780533
learning rate:  0.0007874976173628904
netparams have been saved once 110
val: 1 0.3976520001888275
val: 2 0.39757242798805237
val: 3 0.39149484038352966
val: 4 0.39667364954948425
val: 5 0.3970973491668701
val: 6 0.40114885568618774
val: 7 0.39353322982788086
val: 8 0.3889440894126892
val: 9 0.4034630358219147
val: 10 0.3901953101158142
val: 11 0.39743009209632874
val: 12 0.3911767899990082
val: 13 0.3963419198989868
val: 14 0.40245264768600464
val: 15 0.3954150974750519
val: 16 0.3929700255393982
val: 17 0.39303651452064514
val: 18 0.39231041073799133
val: 19 0.3951061964035034
val: 20 0.39924851059913635
val_Epoch:[ 110 ] val_loss: 0.39566314965486526 2022-08-12 00:55:37.441155
start training 2022-08-12 00:55:37.536375
Epoch:[ 111 0 ] loss: 0.36550188064575195 2022-08-12 00:55:52.305899
Epoch:[ 111 1 ] loss: 0.3650951087474823 2022-08-12 00:55:52.731705
Epoch:[ 111 2 ] loss: 0.36555689573287964 2022-08-12 00:55:53.156528
Epoch:[ 111 3 ] loss: 0.3663407862186432 2022-08-12 00:55:53.576802
Epoch:[ 111 4 ] loss: 0.3661423921585083 2022-08-12 00:55:54.002577
Epoch:[ 111 5 ] loss: 0.36786866188049316 2022-08-12 00:55:54.426411
Epoch:[ 111 6 ] loss: 0.36537763476371765 2022-08-12 00:55:54.848930
Epoch:[ 111 7 ] loss: 0.3644797205924988 2022-08-12 00:55:55.273193
Epoch:[ 111 8 ] loss: 0.36660757660865784 2022-08-12 00:55:55.703981
Epoch:[ 111 9 ] loss: 0.36576858162879944 2022-08-12 00:55:56.124134
Epoch:[ 111 10 ] loss: 0.365254670381546 2022-08-12 00:55:56.542354
Epoch:[ 111 11 ] loss: 0.36429497599601746 2022-08-12 00:55:56.963582
Epoch:[ 111 12 ] loss: 0.3649710714817047 2022-08-12 00:55:57.388963
Epoch:[ 111 13 ] loss: 0.36328160762786865 2022-08-12 00:55:57.812845
Epoch:[ 111 14 ] loss: 0.36565858125686646 2022-08-12 00:55:58.230088
Epoch:[ 111 15 ] loss: 0.3665502965450287 2022-08-12 00:55:58.652802
Epoch:[ 111 16 ] loss: 0.3635670244693756 2022-08-12 00:56:03.732164
Epoch:[ 111 17 ] loss: 0.3670511543750763 2022-08-12 00:56:04.250235
Epoch:[ 111 18 ] loss: 0.36730414628982544 2022-08-12 00:56:04.670706
Epoch:[ 111 19 ] loss: 0.366182416677475 2022-08-12 00:56:05.087565
Training_Epoch:[ 111 ] Training_loss: 0.3656427592039108 2022-08-12 00:56:05.088350
learning rate:  0.0006693729747584568
val: 1 0.3949242830276489
val: 2 0.39787188172340393
val: 3 0.39616912603378296
val: 4 0.3998109996318817
val: 5 0.3942107856273651
val: 6 0.3991388976573944
val: 7 0.3992530405521393
val: 8 0.39575260877609253
val: 9 0.3986012935638428
val: 10 0.40146687626838684
val: 11 0.3886287808418274
val: 12 0.3970544636249542
val: 13 0.3928506076335907
val: 14 0.39791277050971985
val: 15 0.3956875801086426
val: 16 0.39940905570983887
val: 17 0.40160906314849854
val: 18 0.40515652298927307
val: 19 0.40072426199913025
val: 20 0.39784854650497437
val_Epoch:[ 111 ] val_loss: 0.3977040722966194 2022-08-12 00:56:08.682902
start training 2022-08-12 00:56:08.778325
Epoch:[ 112 0 ] loss: 0.36404502391815186 2022-08-12 00:56:22.698431
Epoch:[ 112 1 ] loss: 0.3645997643470764 2022-08-12 00:56:23.119199
Epoch:[ 112 2 ] loss: 0.3643181324005127 2022-08-12 00:56:23.555863
Epoch:[ 112 3 ] loss: 0.3642396926879883 2022-08-12 00:56:23.980716
Epoch:[ 112 4 ] loss: 0.3657955527305603 2022-08-12 00:56:24.399730
Epoch:[ 112 5 ] loss: 0.36726364493370056 2022-08-12 00:56:24.827113
Epoch:[ 112 6 ] loss: 0.364854633808136 2022-08-12 00:56:25.254029
Epoch:[ 112 7 ] loss: 0.36588001251220703 2022-08-12 00:56:25.681569
Epoch:[ 112 8 ] loss: 0.364631712436676 2022-08-12 00:56:26.104189
Epoch:[ 112 9 ] loss: 0.3649669587612152 2022-08-12 00:56:26.527718
Epoch:[ 112 10 ] loss: 0.36659401655197144 2022-08-12 00:56:26.947156
Epoch:[ 112 11 ] loss: 0.3663488030433655 2022-08-12 00:56:27.370468
Epoch:[ 112 12 ] loss: 0.36521604657173157 2022-08-12 00:56:27.798226
Epoch:[ 112 13 ] loss: 0.3650895655155182 2022-08-12 00:56:28.221160
Epoch:[ 112 14 ] loss: 0.3643219769001007 2022-08-12 00:56:28.647446
Epoch:[ 112 15 ] loss: 0.36444222927093506 2022-08-12 00:56:29.062381
Epoch:[ 112 16 ] loss: 0.36525145173072815 2022-08-12 00:56:34.588969
Epoch:[ 112 17 ] loss: 0.3656933307647705 2022-08-12 00:56:35.020895
Epoch:[ 112 18 ] loss: 0.3658562898635864 2022-08-12 00:56:35.452913
Epoch:[ 112 19 ] loss: 0.3663954734802246 2022-08-12 00:56:35.877264
Training_Epoch:[ 112 ] Training_loss: 0.3652902156114578 2022-08-12 00:56:35.877990
learning rate:  0.0006693729747584568
val: 1 0.3956303894519806
val: 2 0.3944627642631531
val: 3 0.39121589064598083
val: 4 0.3970602750778198
val: 5 0.39521118998527527
val: 6 0.39913445711135864
val: 7 0.40682119131088257
val: 8 0.3938519060611725
val: 9 0.3929346799850464
val: 10 0.3912922739982605
val: 11 0.3943972885608673
val: 12 0.39000120759010315
val: 13 0.3901803195476532
val: 14 0.40265312790870667
val: 15 0.3969341516494751
val: 16 0.39619243144989014
val: 17 0.3963351845741272
val: 18 0.3939894139766693
val: 19 0.3979934751987457
val: 20 0.4019527733325958
val_Epoch:[ 112 ] val_loss: 0.3959122195839882 2022-08-12 00:56:39.410954
start training 2022-08-12 00:56:39.505149
Epoch:[ 113 0 ] loss: 0.36463838815689087 2022-08-12 00:56:54.408849
Epoch:[ 113 1 ] loss: 0.36509549617767334 2022-08-12 00:56:54.821407
Epoch:[ 113 2 ] loss: 0.3643559515476227 2022-08-12 00:56:55.245723
Epoch:[ 113 3 ] loss: 0.36457720398902893 2022-08-12 00:56:55.671759
Epoch:[ 113 4 ] loss: 0.36248305439949036 2022-08-12 00:56:56.091901
Epoch:[ 113 5 ] loss: 0.36473548412323 2022-08-12 00:56:56.507517
Epoch:[ 113 6 ] loss: 0.36338454484939575 2022-08-12 00:56:56.936236
Epoch:[ 113 7 ] loss: 0.3661401569843292 2022-08-12 00:56:57.364031
Epoch:[ 113 8 ] loss: 0.3643576204776764 2022-08-12 00:56:57.791219
Epoch:[ 113 9 ] loss: 0.3642992675304413 2022-08-12 00:56:58.211507
Epoch:[ 113 10 ] loss: 0.36460572481155396 2022-08-12 00:56:58.636035
Epoch:[ 113 11 ] loss: 0.36501193046569824 2022-08-12 00:56:59.053654
Epoch:[ 113 12 ] loss: 0.366322785615921 2022-08-12 00:56:59.480561
Epoch:[ 113 13 ] loss: 0.3641427755355835 2022-08-12 00:56:59.906875
Epoch:[ 113 14 ] loss: 0.36599501967430115 2022-08-12 00:57:00.332631
Epoch:[ 113 15 ] loss: 0.3651432693004608 2022-08-12 00:57:00.750523
Epoch:[ 113 16 ] loss: 0.3652428090572357 2022-08-12 00:57:05.547636
Epoch:[ 113 17 ] loss: 0.36541515588760376 2022-08-12 00:57:05.973421
Epoch:[ 113 18 ] loss: 0.3650941252708435 2022-08-12 00:57:06.403189
Epoch:[ 113 19 ] loss: 0.36563727259635925 2022-08-12 00:57:06.830449
Training_Epoch:[ 113 ] Training_loss: 0.364833901822567 2022-08-12 00:57:06.831221
learning rate:  0.0006693729747584568
val: 1 0.39826661348342896
val: 2 0.3970508575439453
val: 3 0.39978715777397156
val: 4 0.3981375992298126
val: 5 0.40266355872154236
val: 6 0.40620100498199463
val: 7 0.39243438839912415
val: 8 0.3974781632423401
val: 9 0.4009082317352295
val: 10 0.3976258933544159
val: 11 0.40487655997276306
val: 12 0.39448148012161255
val: 13 0.3978198766708374
val: 14 0.4011475443840027
val: 15 0.4002518653869629
val: 16 0.3959229588508606
val: 17 0.3967684507369995
val: 18 0.4016377031803131
val: 19 0.39369314908981323
val: 20 0.4001297354698181
val_Epoch:[ 113 ] val_loss: 0.3988641396164894 2022-08-12 00:57:10.476070
start training 2022-08-12 00:57:10.574513
Epoch:[ 114 0 ] loss: 0.36459651589393616 2022-08-12 00:57:24.851648
Epoch:[ 114 1 ] loss: 0.36324840784072876 2022-08-12 00:57:25.322218
Epoch:[ 114 2 ] loss: 0.3636743724346161 2022-08-12 00:57:25.747517
Epoch:[ 114 3 ] loss: 0.3647960126399994 2022-08-12 00:57:26.170330
Epoch:[ 114 4 ] loss: 0.364348828792572 2022-08-12 00:57:26.592488
Epoch:[ 114 5 ] loss: 0.3634648621082306 2022-08-12 00:57:27.006723
Epoch:[ 114 6 ] loss: 0.36457347869873047 2022-08-12 00:57:27.425731
Epoch:[ 114 7 ] loss: 0.3638327121734619 2022-08-12 00:57:27.851293
Epoch:[ 114 8 ] loss: 0.36444973945617676 2022-08-12 00:57:28.272526
Epoch:[ 114 9 ] loss: 0.36321312189102173 2022-08-12 00:57:28.696066
Epoch:[ 114 10 ] loss: 0.36512139439582825 2022-08-12 00:57:29.115975
Epoch:[ 114 11 ] loss: 0.365038126707077 2022-08-12 00:57:29.539823
Epoch:[ 114 12 ] loss: 0.3635418117046356 2022-08-12 00:57:29.962039
Epoch:[ 114 13 ] loss: 0.3640497624874115 2022-08-12 00:57:30.383053
Epoch:[ 114 14 ] loss: 0.3642241060733795 2022-08-12 00:57:30.807971
Epoch:[ 114 15 ] loss: 0.36559075117111206 2022-08-12 00:57:31.228569
Epoch:[ 114 16 ] loss: 0.3660649359226227 2022-08-12 00:57:37.176788
Epoch:[ 114 17 ] loss: 0.3639538586139679 2022-08-12 00:57:37.594621
Epoch:[ 114 18 ] loss: 0.3651813268661499 2022-08-12 00:57:38.011958
Epoch:[ 114 19 ] loss: 0.3648740351200104 2022-08-12 00:57:38.437162
Training_Epoch:[ 114 ] Training_loss: 0.36439190804958344 2022-08-12 00:57:38.437829
learning rate:  0.0006693729747584568
val: 1 0.40071967244148254
val: 2 0.3920672833919525
val: 3 0.3964281678199768
val: 4 0.4044579267501831
val: 5 0.390553742647171
val: 6 0.39849668741226196
val: 7 0.39696362614631653
val: 8 0.39909830689430237
val: 9 0.3959026634693146
val: 10 0.39604371786117554
val: 11 0.39660781621932983
val: 12 0.3977801203727722
val: 13 0.393967866897583
val: 14 0.3912614583969116
val: 15 0.40217968821525574
val: 16 0.3982054889202118
val: 17 0.385851114988327
val: 18 0.40170788764953613
val: 19 0.4005868434906006
val: 20 0.3948912024497986
val_Epoch:[ 114 ] val_loss: 0.39668856412172315 2022-08-12 00:57:41.998544
start training 2022-08-12 00:57:42.098055
Epoch:[ 115 0 ] loss: 0.362942099571228 2022-08-12 00:57:57.034499
Epoch:[ 115 1 ] loss: 0.36449000239372253 2022-08-12 00:57:57.449540
Epoch:[ 115 2 ] loss: 0.363421767950058 2022-08-12 00:57:57.874937
Epoch:[ 115 3 ] loss: 0.36347633600234985 2022-08-12 00:57:58.301516
Epoch:[ 115 4 ] loss: 0.3654190003871918 2022-08-12 00:57:58.724319
Epoch:[ 115 5 ] loss: 0.36357584595680237 2022-08-12 00:57:59.145072
Epoch:[ 115 6 ] loss: 0.3651905059814453 2022-08-12 00:57:59.567473
Epoch:[ 115 7 ] loss: 0.36453977227211 2022-08-12 00:57:59.987863
Epoch:[ 115 8 ] loss: 0.36322805285453796 2022-08-12 00:58:00.412737
Epoch:[ 115 9 ] loss: 0.36412739753723145 2022-08-12 00:58:00.843744
Epoch:[ 115 10 ] loss: 0.3638237714767456 2022-08-12 00:58:01.267811
Epoch:[ 115 11 ] loss: 0.3649328947067261 2022-08-12 00:58:01.684943
Epoch:[ 115 12 ] loss: 0.36435627937316895 2022-08-12 00:58:02.100599
Epoch:[ 115 13 ] loss: 0.3647683560848236 2022-08-12 00:58:02.519707
Epoch:[ 115 14 ] loss: 0.36373019218444824 2022-08-12 00:58:02.948757
Epoch:[ 115 15 ] loss: 0.3642437160015106 2022-08-12 00:58:03.368758
Epoch:[ 115 16 ] loss: 0.3628135621547699 2022-08-12 00:58:09.333771
Epoch:[ 115 17 ] loss: 0.36536696553230286 2022-08-12 00:58:09.755387
Epoch:[ 115 18 ] loss: 0.36407360434532166 2022-08-12 00:58:10.178567
Epoch:[ 115 19 ] loss: 0.36461514234542847 2022-08-12 00:58:10.599984
Training_Epoch:[ 115 ] Training_loss: 0.36415676325559615 2022-08-12 00:58:10.600708
learning rate:  0.0006693729747584568
val: 1 0.39854365587234497
val: 2 0.39690306782722473
val: 3 0.40160059928894043
val: 4 0.3971734344959259
val: 5 0.4027610123157501
val: 6 0.39953917264938354
val: 7 0.40022891759872437
val: 8 0.39783668518066406
val: 9 0.3982650637626648
val: 10 0.3974171280860901
val: 11 0.39359915256500244
val: 12 0.3968946933746338
val: 13 0.3948201835155487
val: 14 0.39718395471572876
val: 15 0.3953015208244324
val: 16 0.3975902199745178
val: 17 0.3925850987434387
val: 18 0.39207348227500916
val: 19 0.3969450891017914
val: 20 0.3964187502861023
val_Epoch:[ 115 ] val_loss: 0.3971840441226959 2022-08-12 00:58:14.224170
start training 2022-08-12 00:58:14.320758
Epoch:[ 116 0 ] loss: 0.36330100893974304 2022-08-12 00:58:29.052638
Epoch:[ 116 1 ] loss: 0.36267831921577454 2022-08-12 00:58:29.478579
Epoch:[ 116 2 ] loss: 0.36220166087150574 2022-08-12 00:58:29.904915
Epoch:[ 116 3 ] loss: 0.3648192286491394 2022-08-12 00:58:30.329275
Epoch:[ 116 4 ] loss: 0.36416977643966675 2022-08-12 00:58:30.741383
Epoch:[ 116 5 ] loss: 0.36415839195251465 2022-08-12 00:58:31.164131
Epoch:[ 116 6 ] loss: 0.3646441400051117 2022-08-12 00:58:31.595764
Epoch:[ 116 7 ] loss: 0.3639450669288635 2022-08-12 00:58:32.015067
Epoch:[ 116 8 ] loss: 0.36487293243408203 2022-08-12 00:58:32.429226
Epoch:[ 116 9 ] loss: 0.3637221157550812 2022-08-12 00:58:32.857597
Epoch:[ 116 10 ] loss: 0.3638893961906433 2022-08-12 00:58:33.285086
Epoch:[ 116 11 ] loss: 0.36411818861961365 2022-08-12 00:58:33.709227
Epoch:[ 116 12 ] loss: 0.36487647891044617 2022-08-12 00:58:34.129487
Epoch:[ 116 13 ] loss: 0.3648339807987213 2022-08-12 00:58:34.552380
Epoch:[ 116 14 ] loss: 0.3662847578525543 2022-08-12 00:58:34.973930
Epoch:[ 116 15 ] loss: 0.365177720785141 2022-08-12 00:58:35.398516
Epoch:[ 116 16 ] loss: 0.3644617795944214 2022-08-12 00:58:40.665280
Epoch:[ 116 17 ] loss: 0.36590903997421265 2022-08-12 00:58:41.085570
Epoch:[ 116 18 ] loss: 0.3649069368839264 2022-08-12 00:58:41.514140
Epoch:[ 116 19 ] loss: 0.3666323721408844 2022-08-12 00:58:41.936168
Training_Epoch:[ 116 ] Training_loss: 0.36448016464710237 2022-08-12 00:58:41.936822
learning rate:  0.0006693729747584568
val: 1 0.3931214213371277
val: 2 0.3923214375972748
val: 3 0.4087224304676056
val: 4 0.3924398720264435
val: 5 0.39592790603637695
val: 6 0.39948928356170654
val: 7 0.39762863516807556
val: 8 0.40752100944519043
val: 9 0.4005284309387207
val: 10 0.3953319787979126
val: 11 0.3948100507259369
val: 12 0.3865174353122711
val: 13 0.39922428131103516
val: 14 0.39823487401008606
val: 15 0.39380964636802673
val: 16 0.4013514816761017
val: 17 0.3916800320148468
val: 18 0.3939122259616852
val: 19 0.39636120200157166
val: 20 0.3933117687702179
val_Epoch:[ 116 ] val_loss: 0.39661227017641065 2022-08-12 00:58:45.481635
start training 2022-08-12 00:58:45.580138
Epoch:[ 117 0 ] loss: 0.36428141593933105 2022-08-12 00:59:00.265019
Epoch:[ 117 1 ] loss: 0.36325380206108093 2022-08-12 00:59:00.683106
Epoch:[ 117 2 ] loss: 0.3642023503780365 2022-08-12 00:59:01.107352
Epoch:[ 117 3 ] loss: 0.3623059391975403 2022-08-12 00:59:01.530983
Epoch:[ 117 4 ] loss: 0.36499714851379395 2022-08-12 00:59:01.954619
Epoch:[ 117 5 ] loss: 0.3625730276107788 2022-08-12 00:59:02.376447
Epoch:[ 117 6 ] loss: 0.3640451431274414 2022-08-12 00:59:02.797905
Epoch:[ 117 7 ] loss: 0.3623274266719818 2022-08-12 00:59:03.210775
Epoch:[ 117 8 ] loss: 0.3642576038837433 2022-08-12 00:59:03.631212
Epoch:[ 117 9 ] loss: 0.36365804076194763 2022-08-12 00:59:04.059167
Epoch:[ 117 10 ] loss: 0.3638031482696533 2022-08-12 00:59:04.478479
Epoch:[ 117 11 ] loss: 0.36400365829467773 2022-08-12 00:59:04.893975
Epoch:[ 117 12 ] loss: 0.363841712474823 2022-08-12 00:59:05.318660
Epoch:[ 117 13 ] loss: 0.36435285210609436 2022-08-12 00:59:05.746535
Epoch:[ 117 14 ] loss: 0.3649601638317108 2022-08-12 00:59:06.171175
Epoch:[ 117 15 ] loss: 0.36556902527809143 2022-08-12 00:59:06.590960
Epoch:[ 117 16 ] loss: 0.3657948672771454 2022-08-12 00:59:11.795362
Epoch:[ 117 17 ] loss: 0.3645813465118408 2022-08-12 00:59:12.221181
Epoch:[ 117 18 ] loss: 0.36517661809921265 2022-08-12 00:59:12.645402
Epoch:[ 117 19 ] loss: 0.36599838733673096 2022-08-12 00:59:13.066166
Training_Epoch:[ 117 ] Training_loss: 0.3641991838812828 2022-08-12 00:59:13.066843
learning rate:  0.0006693729747584568
val: 1 0.4026499092578888
val: 2 0.38915321230888367
val: 3 0.40011361241340637
val: 4 0.39447107911109924
val: 5 0.39215028285980225
val: 6 0.39459922909736633
val: 7 0.3974425494670868
val: 8 0.39842772483825684
val: 9 0.39458101987838745
val: 10 0.39881616830825806
val: 11 0.3987264931201935
val: 12 0.40134185552597046
val: 13 0.4001340866088867
val: 14 0.39783793687820435
val: 15 0.39693546295166016
val: 16 0.4018542766571045
val: 17 0.39687713980674744
val: 18 0.39994996786117554
val: 19 0.38979867100715637
val: 20 0.4018811285495758
val_Epoch:[ 117 ] val_loss: 0.3973870903253555 2022-08-12 00:59:16.611231
start training 2022-08-12 00:59:16.709397
Epoch:[ 118 0 ] loss: 0.3646434545516968 2022-08-12 00:59:31.296921
Epoch:[ 118 1 ] loss: 0.36643335223197937 2022-08-12 00:59:31.710924
Epoch:[ 118 2 ] loss: 0.3640349507331848 2022-08-12 00:59:32.134009
Epoch:[ 118 3 ] loss: 0.3650478422641754 2022-08-12 00:59:32.561478
Epoch:[ 118 4 ] loss: 0.3643839657306671 2022-08-12 00:59:32.984355
Epoch:[ 118 5 ] loss: 0.3654235899448395 2022-08-12 00:59:33.405534
Epoch:[ 118 6 ] loss: 0.36482658982276917 2022-08-12 00:59:33.832490
Epoch:[ 118 7 ] loss: 0.3635723292827606 2022-08-12 00:59:34.259734
Epoch:[ 118 8 ] loss: 0.3671923875808716 2022-08-12 00:59:34.685611
Epoch:[ 118 9 ] loss: 0.36493831872940063 2022-08-12 00:59:35.106401
Epoch:[ 118 10 ] loss: 0.36554664373397827 2022-08-12 00:59:35.532407
Epoch:[ 118 11 ] loss: 0.3647238612174988 2022-08-12 00:59:35.956235
Epoch:[ 118 12 ] loss: 0.36374005675315857 2022-08-12 00:59:36.381379
Epoch:[ 118 13 ] loss: 0.36546894907951355 2022-08-12 00:59:36.801828
Epoch:[ 118 14 ] loss: 0.36474013328552246 2022-08-12 00:59:37.228298
Epoch:[ 118 15 ] loss: 0.3636893928050995 2022-08-12 00:59:37.647541
Epoch:[ 118 16 ] loss: 0.3646053075790405 2022-08-12 00:59:42.938036
Epoch:[ 118 17 ] loss: 0.36492618918418884 2022-08-12 00:59:43.367064
Epoch:[ 118 18 ] loss: 0.3646494448184967 2022-08-12 00:59:43.792456
Epoch:[ 118 19 ] loss: 0.36599066853523254 2022-08-12 00:59:44.217132
Training_Epoch:[ 118 ] Training_loss: 0.36492887139320374 2022-08-12 00:59:44.217836
learning rate:  0.0006693729747584568
val: 1 0.3929079473018646
val: 2 0.400516152381897
val: 3 0.40147337317466736
val: 4 0.4048829674720764
val: 5 0.3953717052936554
val: 6 0.3884592652320862
val: 7 0.39702510833740234
val: 8 0.4025349020957947
val: 9 0.40042680501937866
val: 10 0.39399755001068115
val: 11 0.39698705077171326
val: 12 0.3952053487300873
val: 13 0.40221813321113586
val: 14 0.3969818651676178
val: 15 0.39508703351020813
val: 16 0.3952528238296509
val: 17 0.3948133587837219
val: 18 0.3955162465572357
val: 19 0.39647912979125977
val: 20 0.3996550440788269
val_Epoch:[ 118 ] val_loss: 0.3972895905375481 2022-08-12 00:59:47.808168
start training 2022-08-12 00:59:47.908048
Epoch:[ 119 0 ] loss: 0.3639117181301117 2022-08-12 01:00:02.881752
Epoch:[ 119 1 ] loss: 0.3629778325557709 2022-08-12 01:00:03.304376
Epoch:[ 119 2 ] loss: 0.3631614148616791 2022-08-12 01:00:03.726712
Epoch:[ 119 3 ] loss: 0.3637534976005554 2022-08-12 01:00:04.138650
Epoch:[ 119 4 ] loss: 0.36339816451072693 2022-08-12 01:00:04.570200
Epoch:[ 119 5 ] loss: 0.36511340737342834 2022-08-12 01:00:04.997494
Epoch:[ 119 6 ] loss: 0.3644863963127136 2022-08-12 01:00:05.419665
Epoch:[ 119 7 ] loss: 0.3622586727142334 2022-08-12 01:00:05.834578
Epoch:[ 119 8 ] loss: 0.36375436186790466 2022-08-12 01:00:06.258788
Epoch:[ 119 9 ] loss: 0.36573466658592224 2022-08-12 01:00:06.682493
Epoch:[ 119 10 ] loss: 0.3641412556171417 2022-08-12 01:00:07.105178
Epoch:[ 119 11 ] loss: 0.36432957649230957 2022-08-12 01:00:07.528704
Epoch:[ 119 12 ] loss: 0.36442193388938904 2022-08-12 01:00:07.949555
Epoch:[ 119 13 ] loss: 0.36205604672431946 2022-08-12 01:00:08.370726
Epoch:[ 119 14 ] loss: 0.3657701015472412 2022-08-12 01:00:08.792989
Epoch:[ 119 15 ] loss: 0.36201491951942444 2022-08-12 01:00:09.213028
Epoch:[ 119 16 ] loss: 0.36314845085144043 2022-08-12 01:00:14.373596
Epoch:[ 119 17 ] loss: 0.36367663741111755 2022-08-12 01:00:14.785829
Epoch:[ 119 18 ] loss: 0.3657735586166382 2022-08-12 01:00:15.211908
Epoch:[ 119 19 ] loss: 0.3649296164512634 2022-08-12 01:00:15.636931
Training_Epoch:[ 119 ] Training_loss: 0.36394061148166656 2022-08-12 01:00:15.637610
learning rate:  0.0006693729747584568
val: 1 0.3985166847705841
val: 2 0.39117905497550964
val: 3 0.39672568440437317
val: 4 0.39140021800994873
val: 5 0.40432050824165344
val: 6 0.39417481422424316
val: 7 0.39588645100593567
val: 8 0.3987142741680145
val: 9 0.3966868221759796
val: 10 0.4079027771949768
val: 11 0.3911319375038147
val: 12 0.39866307377815247
val: 13 0.39935871958732605
val: 14 0.3967275023460388
val: 15 0.3972405195236206
val: 16 0.3978327214717865
val: 17 0.4043657183647156
val: 18 0.39626243710517883
val: 19 0.39126235246658325
val: 20 0.3930366039276123
val_Epoch:[ 119 ] val_loss: 0.3970694437623024 2022-08-12 01:00:19.263436
start training 2022-08-12 01:00:19.362130
Epoch:[ 120 0 ] loss: 0.3632116913795471 2022-08-12 01:00:34.166266
Epoch:[ 120 1 ] loss: 0.3628920316696167 2022-08-12 01:00:34.588627
Epoch:[ 120 2 ] loss: 0.3625812530517578 2022-08-12 01:00:35.019343
Epoch:[ 120 3 ] loss: 0.36469292640686035 2022-08-12 01:00:35.444732
Epoch:[ 120 4 ] loss: 0.3639961779117584 2022-08-12 01:00:35.865969
Epoch:[ 120 5 ] loss: 0.3647567331790924 2022-08-12 01:00:36.289549
Epoch:[ 120 6 ] loss: 0.36260464787483215 2022-08-12 01:00:36.713307
Epoch:[ 120 7 ] loss: 0.36561790108680725 2022-08-12 01:00:37.133771
Epoch:[ 120 8 ] loss: 0.3629986047744751 2022-08-12 01:00:37.561373
Epoch:[ 120 9 ] loss: 0.3627855181694031 2022-08-12 01:00:37.983515
Epoch:[ 120 10 ] loss: 0.3639392852783203 2022-08-12 01:00:38.406031
Epoch:[ 120 11 ] loss: 0.3633701503276825 2022-08-12 01:00:38.819949
Epoch:[ 120 12 ] loss: 0.3644455373287201 2022-08-12 01:00:39.239837
Epoch:[ 120 13 ] loss: 0.3642868101596832 2022-08-12 01:00:39.664435
Epoch:[ 120 14 ] loss: 0.36451640725135803 2022-08-12 01:00:40.090392
Epoch:[ 120 15 ] loss: 0.36508825421333313 2022-08-12 01:00:40.508184
Epoch:[ 120 16 ] loss: 0.3656989336013794 2022-08-12 01:00:45.691942
Epoch:[ 120 17 ] loss: 0.3633643686771393 2022-08-12 01:00:46.117346
Epoch:[ 120 18 ] loss: 0.36579224467277527 2022-08-12 01:00:46.542505
Epoch:[ 120 19 ] loss: 0.36558637022972107 2022-08-12 01:00:46.961754
Training_Epoch:[ 120 ] Training_loss: 0.3641112923622131 2022-08-12 01:00:46.962481
learning rate:  0.0006693729747584568
netparams have been saved once 120
val: 1 0.3928138017654419
val: 2 0.3948325514793396
val: 3 0.39728158712387085
val: 4 0.3994329571723938
val: 5 0.4036302864551544
val: 6 0.39727774262428284
val: 7 0.3987276554107666
val: 8 0.3965577185153961
val: 9 0.40117818117141724
val: 10 0.3867039084434509
val: 11 0.3945906162261963
val: 12 0.40478774905204773
val: 13 0.39629819989204407
val: 14 0.39662104845046997
val: 15 0.40185287594795227
val: 16 0.39773446321487427
val: 17 0.3952656090259552
val: 18 0.39865612983703613
val: 19 0.40157070755958557
val: 20 0.40448620915412903
val_Epoch:[ 120 ] val_loss: 0.39801499992609024 2022-08-12 01:00:50.586449
start training 2022-08-12 01:00:50.687002
Epoch:[ 121 0 ] loss: 0.362933486700058 2022-08-12 01:01:05.229907
Epoch:[ 121 1 ] loss: 0.3641989827156067 2022-08-12 01:01:05.655801
Epoch:[ 121 2 ] loss: 0.36268678307533264 2022-08-12 01:01:06.077424
Epoch:[ 121 3 ] loss: 0.36195459961891174 2022-08-12 01:01:06.494706
Epoch:[ 121 4 ] loss: 0.36206406354904175 2022-08-12 01:01:06.913226
Epoch:[ 121 5 ] loss: 0.36172619462013245 2022-08-12 01:01:07.334041
Epoch:[ 121 6 ] loss: 0.36208316683769226 2022-08-12 01:01:07.757383
Epoch:[ 121 7 ] loss: 0.3611080050468445 2022-08-12 01:01:08.180258
Epoch:[ 121 8 ] loss: 0.3637480139732361 2022-08-12 01:01:08.603185
Epoch:[ 121 9 ] loss: 0.36171695590019226 2022-08-12 01:01:09.022385
Epoch:[ 121 10 ] loss: 0.36252397298812866 2022-08-12 01:01:09.442483
Epoch:[ 121 11 ] loss: 0.3618547022342682 2022-08-12 01:01:09.865834
Epoch:[ 121 12 ] loss: 0.3620680868625641 2022-08-12 01:01:10.288545
Epoch:[ 121 13 ] loss: 0.36224687099456787 2022-08-12 01:01:10.707156
Epoch:[ 121 14 ] loss: 0.3618265986442566 2022-08-12 01:01:11.136298
Epoch:[ 121 15 ] loss: 0.36113545298576355 2022-08-12 01:01:11.554484
Epoch:[ 121 16 ] loss: 0.3622985780239105 2022-08-12 01:01:16.843325
Epoch:[ 121 17 ] loss: 0.36292141675949097 2022-08-12 01:01:17.256491
Epoch:[ 121 18 ] loss: 0.3634242117404938 2022-08-12 01:01:17.680727
Epoch:[ 121 19 ] loss: 0.3624249994754791 2022-08-12 01:01:18.101596
Training_Epoch:[ 121 ] Training_loss: 0.3623472571372986 2022-08-12 01:01:18.102331
learning rate:  0.0005689670285446883
val: 1 0.3995593190193176
val: 2 0.3999023139476776
val: 3 0.3957890272140503
val: 4 0.3961794972419739
val: 5 0.3966660797595978
val: 6 0.40099409222602844
val: 7 0.3985406160354614
val: 8 0.3946998715400696
val: 9 0.40412837266921997
val: 10 0.3921784460544586
val: 11 0.3882859945297241
val: 12 0.4055302143096924
val: 13 0.4001700282096863
val: 14 0.39513033628463745
val: 15 0.4017723500728607
val: 16 0.3971506655216217
val: 17 0.3994542360305786
val: 18 0.39642417430877686
val: 19 0.3969549536705017
val: 20 0.3907029330730438
val_Epoch:[ 121 ] val_loss: 0.3975106760859489 2022-08-12 01:01:21.593318
start training 2022-08-12 01:01:21.694226
Epoch:[ 122 0 ] loss: 0.36258354783058167 2022-08-12 01:01:35.578435
Epoch:[ 122 1 ] loss: 0.36088669300079346 2022-08-12 01:01:36.143387
Epoch:[ 122 2 ] loss: 0.36074313521385193 2022-08-12 01:01:36.574677
Epoch:[ 122 3 ] loss: 0.3616199493408203 2022-08-12 01:01:36.997954
Epoch:[ 122 4 ] loss: 0.3618704378604889 2022-08-12 01:01:37.419352
Epoch:[ 122 5 ] loss: 0.36045023798942566 2022-08-12 01:01:37.842180
Epoch:[ 122 6 ] loss: 0.36170533299446106 2022-08-12 01:01:38.265413
Epoch:[ 122 7 ] loss: 0.36106157302856445 2022-08-12 01:01:38.685280
Epoch:[ 122 8 ] loss: 0.3630785346031189 2022-08-12 01:01:39.117120
Epoch:[ 122 9 ] loss: 0.36159372329711914 2022-08-12 01:01:39.535475
Epoch:[ 122 10 ] loss: 0.36146533489227295 2022-08-12 01:01:39.949267
Epoch:[ 122 11 ] loss: 0.36267372965812683 2022-08-12 01:01:40.369709
Epoch:[ 122 12 ] loss: 0.36147424578666687 2022-08-12 01:01:40.797342
Epoch:[ 122 13 ] loss: 0.35935133695602417 2022-08-12 01:01:41.220290
Epoch:[ 122 14 ] loss: 0.3616805672645569 2022-08-12 01:01:41.636440
Epoch:[ 122 15 ] loss: 0.36190930008888245 2022-08-12 01:01:42.059945
Epoch:[ 122 16 ] loss: 0.36183059215545654 2022-08-12 01:01:47.713470
Epoch:[ 122 17 ] loss: 0.36235421895980835 2022-08-12 01:01:48.127621
Epoch:[ 122 18 ] loss: 0.36188703775405884 2022-08-12 01:01:48.549719
Epoch:[ 122 19 ] loss: 0.3617250621318817 2022-08-12 01:01:48.976270
Training_Epoch:[ 122 ] Training_loss: 0.36159722954034806 2022-08-12 01:01:48.976927
learning rate:  0.0005689670285446883
val: 1 0.40300464630126953
val: 2 0.4017893373966217
val: 3 0.39264893531799316
val: 4 0.40414512157440186
val: 5 0.3978394865989685
val: 6 0.3997989594936371
val: 7 0.4003019630908966
val: 8 0.3947801887989044
val: 9 0.39323127269744873
val: 10 0.4040437340736389
val: 11 0.4056212604045868
val: 12 0.38887301087379456
val: 13 0.4006972312927246
val: 14 0.40135622024536133
val: 15 0.4072541892528534
val: 16 0.3945993483066559
val: 17 0.40694811940193176
val: 18 0.4033520221710205
val: 19 0.40927454829216003
val: 20 0.39526963233947754
val_Epoch:[ 122 ] val_loss: 0.40024146139621736 2022-08-12 01:01:52.497087
start training 2022-08-12 01:01:52.594888
Epoch:[ 123 0 ] loss: 0.3600081503391266 2022-08-12 01:02:07.405803
Epoch:[ 123 1 ] loss: 0.36096593737602234 2022-08-12 01:02:07.828499
Epoch:[ 123 2 ] loss: 0.35994771122932434 2022-08-12 01:02:08.245628
Epoch:[ 123 3 ] loss: 0.3606884181499481 2022-08-12 01:02:08.666069
Epoch:[ 123 4 ] loss: 0.36189162731170654 2022-08-12 01:02:09.091099
Epoch:[ 123 5 ] loss: 0.3612349033355713 2022-08-12 01:02:09.514989
Epoch:[ 123 6 ] loss: 0.3618929088115692 2022-08-12 01:02:09.932796
Epoch:[ 123 7 ] loss: 0.36185598373413086 2022-08-12 01:02:10.355037
Epoch:[ 123 8 ] loss: 0.3607323169708252 2022-08-12 01:02:10.783338
Epoch:[ 123 9 ] loss: 0.362310528755188 2022-08-12 01:02:11.210974
Epoch:[ 123 10 ] loss: 0.36017340421676636 2022-08-12 01:02:11.640732
Epoch:[ 123 11 ] loss: 0.360795259475708 2022-08-12 01:02:12.067877
Epoch:[ 123 12 ] loss: 0.36169543862342834 2022-08-12 01:02:12.486366
Epoch:[ 123 13 ] loss: 0.36212918162345886 2022-08-12 01:02:12.912494
Epoch:[ 123 14 ] loss: 0.3610210716724396 2022-08-12 01:02:13.335290
Epoch:[ 123 15 ] loss: 0.362954318523407 2022-08-12 01:02:13.765440
Epoch:[ 123 16 ] loss: 0.3596702516078949 2022-08-12 01:02:18.930941
Epoch:[ 123 17 ] loss: 0.36269041895866394 2022-08-12 01:02:19.357170
Epoch:[ 123 18 ] loss: 0.3623194694519043 2022-08-12 01:02:19.787494
Epoch:[ 123 19 ] loss: 0.36255714297294617 2022-08-12 01:02:20.209142
Training_Epoch:[ 123 ] Training_loss: 0.3613767221570015 2022-08-12 01:02:20.209872
learning rate:  0.0005689670285446883
val: 1 0.3977634012699127
val: 2 0.39712807536125183
val: 3 0.39650535583496094
val: 4 0.39970070123672485
val: 5 0.3923121392726898
val: 6 0.40561699867248535
val: 7 0.39892882108688354
val: 8 0.3961344361305237
val: 9 0.3925933241844177
val: 10 0.3924177289009094
val: 11 0.39509788155555725
val: 12 0.39760658144950867
val: 13 0.3922246992588043
val: 14 0.4040680527687073
val: 15 0.40297070145606995
val: 16 0.3992003798484802
val: 17 0.40269583463668823
val: 18 0.3965357840061188
val: 19 0.39825040102005005
val: 20 0.3964151442050934
val_Epoch:[ 123 ] val_loss: 0.3977083221077919 2022-08-12 01:02:23.825349
start training 2022-08-12 01:02:23.922316
Epoch:[ 124 0 ] loss: 0.36234110593795776 2022-08-12 01:02:37.825267
Epoch:[ 124 1 ] loss: 0.3613656461238861 2022-08-12 01:02:38.269596
Epoch:[ 124 2 ] loss: 0.36193016171455383 2022-08-12 01:02:38.710692
Epoch:[ 124 3 ] loss: 0.3619329333305359 2022-08-12 01:02:39.134069
Epoch:[ 124 4 ] loss: 0.36107033491134644 2022-08-12 01:02:39.559682
Epoch:[ 124 5 ] loss: 0.3614174723625183 2022-08-12 01:02:39.982379
Epoch:[ 124 6 ] loss: 0.3624713718891144 2022-08-12 01:02:40.402156
Epoch:[ 124 7 ] loss: 0.3602587878704071 2022-08-12 01:02:40.818657
Epoch:[ 124 8 ] loss: 0.3644022047519684 2022-08-12 01:02:41.238234
Epoch:[ 124 9 ] loss: 0.3627960979938507 2022-08-12 01:02:41.665901
Epoch:[ 124 10 ] loss: 0.3603259325027466 2022-08-12 01:02:42.085806
Epoch:[ 124 11 ] loss: 0.3622185289859772 2022-08-12 01:02:42.507133
Epoch:[ 124 12 ] loss: 0.3623967468738556 2022-08-12 01:02:42.928210
Epoch:[ 124 13 ] loss: 0.36257585883140564 2022-08-12 01:02:43.353893
Epoch:[ 124 14 ] loss: 0.36269909143447876 2022-08-12 01:02:43.784467
Epoch:[ 124 15 ] loss: 0.36239200830459595 2022-08-12 01:02:44.202952
Epoch:[ 124 16 ] loss: 0.36245712637901306 2022-08-12 01:02:49.812237
Epoch:[ 124 17 ] loss: 0.3617662191390991 2022-08-12 01:02:50.238983
Epoch:[ 124 18 ] loss: 0.36350372433662415 2022-08-12 01:02:50.663127
Epoch:[ 124 19 ] loss: 0.36184728145599365 2022-08-12 01:02:51.087264
Training_Epoch:[ 124 ] Training_loss: 0.36210843175649643 2022-08-12 01:02:51.088011
learning rate:  0.0005689670285446883
val: 1 0.40425118803977966
val: 2 0.3975573778152466
val: 3 0.402708500623703
val: 4 0.4008704721927643
val: 5 0.3968508839607239
val: 6 0.3975619673728943
val: 7 0.41076162457466125
val: 8 0.39971739053726196
val: 9 0.39007171988487244
val: 10 0.40490463376045227
val: 11 0.40148597955703735
val: 12 0.4005252420902252
val: 13 0.39936134219169617
val: 14 0.406698077917099
val: 15 0.39586707949638367
val: 16 0.3985763192176819
val: 17 0.39366400241851807
val: 18 0.40045425295829773
val: 19 0.3945960998535156
val: 20 0.4025738537311554
val_Epoch:[ 124 ] val_loss: 0.3999529004096985 2022-08-12 01:02:54.593990
start training 2022-08-12 01:02:54.692145
Epoch:[ 125 0 ] loss: 0.36195093393325806 2022-08-12 01:03:08.874240
Epoch:[ 125 1 ] loss: 0.3617684245109558 2022-08-12 01:03:09.311780
Epoch:[ 125 2 ] loss: 0.3615484833717346 2022-08-12 01:03:09.731633
Epoch:[ 125 3 ] loss: 0.3608458936214447 2022-08-12 01:03:10.158383
Epoch:[ 125 4 ] loss: 0.3621624708175659 2022-08-12 01:03:10.580628
Epoch:[ 125 5 ] loss: 0.3597888648509979 2022-08-12 01:03:11.000465
Epoch:[ 125 6 ] loss: 0.3605462908744812 2022-08-12 01:03:11.423919
Epoch:[ 125 7 ] loss: 0.3617907464504242 2022-08-12 01:03:11.850341
Epoch:[ 125 8 ] loss: 0.36085763573646545 2022-08-12 01:03:12.276802
Epoch:[ 125 9 ] loss: 0.3623107373714447 2022-08-12 01:03:12.698273
Epoch:[ 125 10 ] loss: 0.3617485761642456 2022-08-12 01:03:13.123420
Epoch:[ 125 11 ] loss: 0.36051279306411743 2022-08-12 01:03:13.547074
Epoch:[ 125 12 ] loss: 0.3623279631137848 2022-08-12 01:03:13.968964
Epoch:[ 125 13 ] loss: 0.3624948561191559 2022-08-12 01:03:14.395979
Epoch:[ 125 14 ] loss: 0.3624225854873657 2022-08-12 01:03:14.824040
Epoch:[ 125 15 ] loss: 0.3619993031024933 2022-08-12 01:03:15.245734
Epoch:[ 125 16 ] loss: 0.36212772130966187 2022-08-12 01:03:20.499180
Epoch:[ 125 17 ] loss: 0.3629162609577179 2022-08-12 01:03:20.926298
Epoch:[ 125 18 ] loss: 0.36142605543136597 2022-08-12 01:03:22.002172
Epoch:[ 125 19 ] loss: 0.3613699972629547 2022-08-12 01:03:22.415677
Training_Epoch:[ 125 ] Training_loss: 0.3616458296775818 2022-08-12 01:03:22.416394
learning rate:  0.0005689670285446883
val: 1 0.40645796060562134
val: 2 0.4007856547832489
val: 3 0.3975489139556885
val: 4 0.40152719616889954
val: 5 0.40165695548057556
val: 6 0.39878329634666443
val: 7 0.3955657184123993
val: 8 0.4013535976409912
val: 9 0.39714670181274414
val: 10 0.4028465747833252
val: 11 0.3991491198539734
val: 12 0.3935857117176056
val: 13 0.3990580439567566
val: 14 0.4056587815284729
val: 15 0.3993929624557495
val: 16 0.3959278464317322
val: 17 0.3949224054813385
val: 18 0.4001975357532501
val: 19 0.3968057930469513
val: 20 0.40409353375434875
val_Epoch:[ 125 ] val_loss: 0.39962321519851685 2022-08-12 01:03:26.005833
start training 2022-08-12 01:03:26.103576
Epoch:[ 126 0 ] loss: 0.3611118197441101 2022-08-12 01:03:39.726209
Epoch:[ 126 1 ] loss: 0.36090853810310364 2022-08-12 01:03:40.232606
Epoch:[ 126 2 ] loss: 0.3605734407901764 2022-08-12 01:03:40.669322
Epoch:[ 126 3 ] loss: 0.36268141865730286 2022-08-12 01:03:41.092549
Epoch:[ 126 4 ] loss: 0.36219552159309387 2022-08-12 01:03:41.517419
Epoch:[ 126 5 ] loss: 0.3606504499912262 2022-08-12 01:03:41.932445
Epoch:[ 126 6 ] loss: 0.36366474628448486 2022-08-12 01:03:42.357197
Epoch:[ 126 7 ] loss: 0.3605959117412567 2022-08-12 01:03:42.783150
Epoch:[ 126 8 ] loss: 0.36185938119888306 2022-08-12 01:03:43.205472
Epoch:[ 126 9 ] loss: 0.3631298840045929 2022-08-12 01:03:43.620448
Epoch:[ 126 10 ] loss: 0.36221277713775635 2022-08-12 01:03:44.046421
Epoch:[ 126 11 ] loss: 0.3630894720554352 2022-08-12 01:03:44.476236
Epoch:[ 126 12 ] loss: 0.3615506589412689 2022-08-12 01:03:44.908252
Epoch:[ 126 13 ] loss: 0.363314688205719 2022-08-12 01:03:45.330149
Epoch:[ 126 14 ] loss: 0.3621842563152313 2022-08-12 01:03:45.755470
Epoch:[ 126 15 ] loss: 0.362619012594223 2022-08-12 01:03:46.174380
Epoch:[ 126 16 ] loss: 0.3618878722190857 2022-08-12 01:03:52.057015
Epoch:[ 126 17 ] loss: 0.3607882857322693 2022-08-12 01:03:52.567480
Epoch:[ 126 18 ] loss: 0.3627198040485382 2022-08-12 01:03:52.995325
Epoch:[ 126 19 ] loss: 0.36245161294937134 2022-08-12 01:03:53.420264
Training_Epoch:[ 126 ] Training_loss: 0.36200947761535646 2022-08-12 01:03:53.420938
learning rate:  0.0005689670285446883
val: 1 0.3907075822353363
val: 2 0.4009217917919159
val: 3 0.39525309205055237
val: 4 0.39554545283317566
val: 5 0.40254682302474976
val: 6 0.4037512540817261
val: 7 0.39489734172821045
val: 8 0.39761805534362793
val: 9 0.399464875459671
val: 10 0.39976951479911804
val: 11 0.40017616748809814
val: 12 0.40100300312042236
val: 13 0.3979623019695282
val: 14 0.4025900065898895
val: 15 0.3924644887447357
val: 16 0.3927793800830841
val: 17 0.3941698372364044
val: 18 0.3933160603046417
val: 19 0.3977944552898407
val: 20 0.4013112187385559
val_Epoch:[ 126 ] val_loss: 0.3977021351456642 2022-08-12 01:03:56.944695
start training 2022-08-12 01:03:57.043188
Epoch:[ 127 0 ] loss: 0.36017751693725586 2022-08-12 01:04:10.948323
Epoch:[ 127 1 ] loss: 0.36118945479393005 2022-08-12 01:04:11.386835
Epoch:[ 127 2 ] loss: 0.36192086338996887 2022-08-12 01:04:11.805261
Epoch:[ 127 3 ] loss: 0.3611922264099121 2022-08-12 01:04:12.226118
Epoch:[ 127 4 ] loss: 0.3611139953136444 2022-08-12 01:04:12.648536
Epoch:[ 127 5 ] loss: 0.361483633518219 2022-08-12 01:04:13.074881
Epoch:[ 127 6 ] loss: 0.3614727556705475 2022-08-12 01:04:13.496078
Epoch:[ 127 7 ] loss: 0.36032119393348694 2022-08-12 01:04:13.919545
Epoch:[ 127 8 ] loss: 0.3623579442501068 2022-08-12 01:04:14.342703
Epoch:[ 127 9 ] loss: 0.36278536915779114 2022-08-12 01:04:14.767142
Epoch:[ 127 10 ] loss: 0.3617873787879944 2022-08-12 01:04:15.189413
Epoch:[ 127 11 ] loss: 0.3619040846824646 2022-08-12 01:04:15.608184
Epoch:[ 127 12 ] loss: 0.3606867790222168 2022-08-12 01:04:16.033803
Epoch:[ 127 13 ] loss: 0.3618732988834381 2022-08-12 01:04:16.450988
Epoch:[ 127 14 ] loss: 0.3620782494544983 2022-08-12 01:04:16.868414
Epoch:[ 127 15 ] loss: 0.36240023374557495 2022-08-12 01:04:17.290108
Epoch:[ 127 16 ] loss: 0.36145535111427307 2022-08-12 01:04:23.004378
Epoch:[ 127 17 ] loss: 0.361588716506958 2022-08-12 01:04:23.417341
Epoch:[ 127 18 ] loss: 0.36231184005737305 2022-08-12 01:04:23.841086
Epoch:[ 127 19 ] loss: 0.3636768162250519 2022-08-12 01:04:24.271558
Training_Epoch:[ 127 ] Training_loss: 0.3616888850927353 2022-08-12 01:04:24.272332
learning rate:  0.0005689670285446883
val: 1 0.40533822774887085
val: 2 0.40280598402023315
val: 3 0.401876300573349
val: 4 0.3977993130683899
val: 5 0.3983334004878998
val: 6 0.40365347266197205
val: 7 0.39777672290802
val: 8 0.40532174706459045
val: 9 0.39987093210220337
val: 10 0.40659862756729126
val: 11 0.4008439779281616
val: 12 0.3977563679218292
val: 13 0.39624688029289246
val: 14 0.40290218591690063
val: 15 0.39287257194519043
val: 16 0.40647071599960327
val: 17 0.39214274287223816
val: 18 0.3963533043861389
val: 19 0.40187498927116394
val: 20 0.3948691189289093
val_Epoch:[ 127 ] val_loss: 0.4000853791832924 2022-08-12 01:04:27.864445
start training 2022-08-12 01:04:27.961382
Epoch:[ 128 0 ] loss: 0.35973232984542847 2022-08-12 01:04:41.971274
Epoch:[ 128 1 ] loss: 0.3612295985221863 2022-08-12 01:04:42.452220
Epoch:[ 128 2 ] loss: 0.36152544617652893 2022-08-12 01:04:42.867356
Epoch:[ 128 3 ] loss: 0.36199870705604553 2022-08-12 01:04:43.290654
Epoch:[ 128 4 ] loss: 0.3612101078033447 2022-08-12 01:04:43.721296
Epoch:[ 128 5 ] loss: 0.3625452518463135 2022-08-12 01:04:44.136413
Epoch:[ 128 6 ] loss: 0.3616718053817749 2022-08-12 01:04:44.560638
Epoch:[ 128 7 ] loss: 0.3614611327648163 2022-08-12 01:04:44.984975
Epoch:[ 128 8 ] loss: 0.3613688051700592 2022-08-12 01:04:45.408327
Epoch:[ 128 9 ] loss: 0.36139610409736633 2022-08-12 01:04:45.825957
Epoch:[ 128 10 ] loss: 0.36014649271965027 2022-08-12 01:04:46.248475
Epoch:[ 128 11 ] loss: 0.362758070230484 2022-08-12 01:04:46.674179
Epoch:[ 128 12 ] loss: 0.361879825592041 2022-08-12 01:04:47.088407
Epoch:[ 128 13 ] loss: 0.3610519766807556 2022-08-12 01:04:47.513064
Epoch:[ 128 14 ] loss: 0.36188527941703796 2022-08-12 01:04:47.942417
Epoch:[ 128 15 ] loss: 0.36267203092575073 2022-08-12 01:04:48.368756
Epoch:[ 128 16 ] loss: 0.36134207248687744 2022-08-12 01:04:54.029697
Epoch:[ 128 17 ] loss: 0.3612368702888489 2022-08-12 01:04:54.454769
Epoch:[ 128 18 ] loss: 0.3626405894756317 2022-08-12 01:04:54.879601
Epoch:[ 128 19 ] loss: 0.36041536927223206 2022-08-12 01:04:55.299816
Training_Epoch:[ 128 ] Training_loss: 0.3615083932876587 2022-08-12 01:04:55.300526
learning rate:  0.0005689670285446883
val: 1 0.4016788899898529
val: 2 0.4002721905708313
val: 3 0.3974223732948303
val: 4 0.40371784567832947
val: 5 0.3930887281894684
val: 6 0.39922478795051575
val: 7 0.3986896574497223
val: 8 0.3925239145755768
val: 9 0.3954501152038574
val: 10 0.4004751741886139
val: 11 0.3975910246372223
val: 12 0.39787930250167847
val: 13 0.40339207649230957
val: 14 0.401426762342453
val: 15 0.39693713188171387
val: 16 0.40050384402275085
val: 17 0.40099984407424927
val: 18 0.39833980798721313
val: 19 0.4066155254840851
val: 20 0.39701026678085327
val_Epoch:[ 128 ] val_loss: 0.39916196316480634 2022-08-12 01:04:58.907051
start training 2022-08-12 01:04:59.009293
Epoch:[ 129 0 ] loss: 0.3622320890426636 2022-08-12 01:05:13.768680
Epoch:[ 129 1 ] loss: 0.3618033826351166 2022-08-12 01:05:14.195347
Epoch:[ 129 2 ] loss: 0.3613416254520416 2022-08-12 01:05:14.611755
Epoch:[ 129 3 ] loss: 0.3618661165237427 2022-08-12 01:05:15.037094
Epoch:[ 129 4 ] loss: 0.3614635467529297 2022-08-12 01:05:15.460813
Epoch:[ 129 5 ] loss: 0.36316367983818054 2022-08-12 01:05:15.890525
Epoch:[ 129 6 ] loss: 0.35994651913642883 2022-08-12 01:05:16.315159
Epoch:[ 129 7 ] loss: 0.3615003824234009 2022-08-12 01:05:16.739920
Epoch:[ 129 8 ] loss: 0.3608856201171875 2022-08-12 01:05:17.161959
Epoch:[ 129 9 ] loss: 0.3613422214984894 2022-08-12 01:05:17.581289
Epoch:[ 129 10 ] loss: 0.3627427816390991 2022-08-12 01:05:17.995676
Epoch:[ 129 11 ] loss: 0.36042776703834534 2022-08-12 01:05:18.419511
Epoch:[ 129 12 ] loss: 0.3605368435382843 2022-08-12 01:05:18.845041
Epoch:[ 129 13 ] loss: 0.3603591024875641 2022-08-12 01:05:19.260941
Epoch:[ 129 14 ] loss: 0.36154505610466003 2022-08-12 01:05:19.680440
Epoch:[ 129 15 ] loss: 0.36181291937828064 2022-08-12 01:05:20.105758
Epoch:[ 129 16 ] loss: 0.3613908886909485 2022-08-12 01:05:25.485328
Epoch:[ 129 17 ] loss: 0.36180728673934937 2022-08-12 01:05:25.905699
Epoch:[ 129 18 ] loss: 0.3618403971195221 2022-08-12 01:05:26.333992
Epoch:[ 129 19 ] loss: 0.36166292428970337 2022-08-12 01:05:26.759055
Training_Epoch:[ 129 ] Training_loss: 0.3614835575222969 2022-08-12 01:05:26.759739
learning rate:  0.0005689670285446883
val: 1 0.3989786207675934
val: 2 0.39599427580833435
val: 3 0.40110573172569275
val: 4 0.39489316940307617
val: 5 0.39247119426727295
val: 6 0.3937236964702606
val: 7 0.396270215511322
val: 8 0.39943498373031616
val: 9 0.39588576555252075
val: 10 0.40053755044937134
val: 11 0.3984982967376709
val: 12 0.40524646639823914
val: 13 0.39947932958602905
val: 14 0.39777758717536926
val: 15 0.39751893281936646
val: 16 0.3994428217411041
val: 17 0.3983422517776489
val: 18 0.40710094571113586
val: 19 0.4003084897994995
val: 20 0.39186760783195496
val_Epoch:[ 129 ] val_loss: 0.39824389666318893 2022-08-12 01:05:30.387253
start training 2022-08-12 01:05:30.486072
Epoch:[ 130 0 ] loss: 0.360090970993042 2022-08-12 01:05:45.211794
Epoch:[ 130 1 ] loss: 0.35979557037353516 2022-08-12 01:05:45.637040
Epoch:[ 130 2 ] loss: 0.3610808849334717 2022-08-12 01:05:46.055351
Epoch:[ 130 3 ] loss: 0.3613009750843048 2022-08-12 01:05:46.473892
Epoch:[ 130 4 ] loss: 0.3618224263191223 2022-08-12 01:05:46.898060
Epoch:[ 130 5 ] loss: 0.3620814383029938 2022-08-12 01:05:47.321229
Epoch:[ 130 6 ] loss: 0.3615588843822479 2022-08-12 01:05:47.739143
Epoch:[ 130 7 ] loss: 0.36208048462867737 2022-08-12 01:05:48.159087
Epoch:[ 130 8 ] loss: 0.3615663945674896 2022-08-12 01:05:48.581515
Epoch:[ 130 9 ] loss: 0.36010149121284485 2022-08-12 01:05:49.008128
Epoch:[ 130 10 ] loss: 0.36210760474205017 2022-08-12 01:05:49.434825
Epoch:[ 130 11 ] loss: 0.3616926074028015 2022-08-12 01:05:49.857364
Epoch:[ 130 12 ] loss: 0.36165618896484375 2022-08-12 01:05:50.280301
Epoch:[ 130 13 ] loss: 0.36176609992980957 2022-08-12 01:05:50.706526
Epoch:[ 130 14 ] loss: 0.36154329776763916 2022-08-12 01:05:51.127927
Epoch:[ 130 15 ] loss: 0.36139851808547974 2022-08-12 01:05:51.552026
Epoch:[ 130 16 ] loss: 0.3622395992279053 2022-08-12 01:05:57.653658
Epoch:[ 130 17 ] loss: 0.3617077171802521 2022-08-12 01:05:58.075289
Epoch:[ 130 18 ] loss: 0.36109018325805664 2022-08-12 01:05:58.497849
Epoch:[ 130 19 ] loss: 0.3629508316516876 2022-08-12 01:05:58.917341
Training_Epoch:[ 130 ] Training_loss: 0.3614816084504128 2022-08-12 01:05:58.918040
learning rate:  0.0005689670285446883
netparams have been saved once 130
val: 1 0.40077874064445496
val: 2 0.3988019526004791
val: 3 0.3962416350841522
val: 4 0.39428308606147766
val: 5 0.39803919196128845
val: 6 0.40156516432762146
val: 7 0.39456960558891296
val: 8 0.3973793387413025
val: 9 0.4052793085575104
val: 10 0.398567795753479
val: 11 0.4029301106929779
val: 12 0.39934638142585754
val: 13 0.3995857536792755
val: 14 0.3952505886554718
val: 15 0.3975328803062439
val: 16 0.40263524651527405
val: 17 0.3931921720504761
val: 18 0.3947206437587738
val: 19 0.3946176767349243
val: 20 0.39651623368263245
val_Epoch:[ 130 ] val_loss: 0.3980916753411293 2022-08-12 01:06:02.618791
start training 2022-08-12 01:06:02.715424
Epoch:[ 131 0 ] loss: 0.3598383367061615 2022-08-12 01:06:17.005793
Epoch:[ 131 1 ] loss: 0.36213457584381104 2022-08-12 01:06:17.445677
Epoch:[ 131 2 ] loss: 0.3607129454612732 2022-08-12 01:06:17.873889
Epoch:[ 131 3 ] loss: 0.36072757840156555 2022-08-12 01:06:18.294123
Epoch:[ 131 4 ] loss: 0.3609084486961365 2022-08-12 01:06:18.709729
Epoch:[ 131 5 ] loss: 0.36052191257476807 2022-08-12 01:06:19.130444
Epoch:[ 131 6 ] loss: 0.3602195680141449 2022-08-12 01:06:19.554280
Epoch:[ 131 7 ] loss: 0.36113426089286804 2022-08-12 01:06:19.978813
Epoch:[ 131 8 ] loss: 0.36046308279037476 2022-08-12 01:06:20.396580
Epoch:[ 131 9 ] loss: 0.3607986271381378 2022-08-12 01:06:20.817978
Epoch:[ 131 10 ] loss: 0.36076390743255615 2022-08-12 01:06:21.246411
Epoch:[ 131 11 ] loss: 0.36124709248542786 2022-08-12 01:06:21.673664
Epoch:[ 131 12 ] loss: 0.3590092360973358 2022-08-12 01:06:22.094681
Epoch:[ 131 13 ] loss: 0.3616676926612854 2022-08-12 01:06:22.516803
Epoch:[ 131 14 ] loss: 0.35839149355888367 2022-08-12 01:06:22.938075
Epoch:[ 131 15 ] loss: 0.3609345853328705 2022-08-12 01:06:23.364656
Epoch:[ 131 16 ] loss: 0.35941386222839355 2022-08-12 01:06:28.760366
Epoch:[ 131 17 ] loss: 0.36081260442733765 2022-08-12 01:06:29.183985
Epoch:[ 131 18 ] loss: 0.3614921271800995 2022-08-12 01:06:29.614135
Epoch:[ 131 19 ] loss: 0.36106863617897034 2022-08-12 01:06:30.038397
Training_Epoch:[ 131 ] Training_loss: 0.3606130287051201 2022-08-12 01:06:30.039071
learning rate:  0.000483621974262985
val: 1 0.3942529857158661
val: 2 0.4012330174446106
val: 3 0.3919456899166107
val: 4 0.38845154643058777
val: 5 0.4020487070083618
val: 6 0.3972640633583069
val: 7 0.3989388942718506
val: 8 0.3959159255027771
val: 9 0.3921997547149658
val: 10 0.39533182978630066
val: 11 0.3937126696109772
val: 12 0.3977092504501343
val: 13 0.3992269039154053
val: 14 0.393081396818161
val: 15 0.39359164237976074
val: 16 0.4063398838043213
val: 17 0.39874789118766785
val: 18 0.4016807973384857
val: 19 0.4025038480758667
val: 20 0.4085477590560913
val_Epoch:[ 131 ] val_loss: 0.39763622283935546 2022-08-12 01:06:33.625290
start training 2022-08-12 01:06:33.721639
Epoch:[ 132 0 ] loss: 0.35999563336372375 2022-08-12 01:06:47.836558
Epoch:[ 132 1 ] loss: 0.3599802851676941 2022-08-12 01:06:48.276523
Epoch:[ 132 2 ] loss: 0.3594067394733429 2022-08-12 01:06:48.693614
Epoch:[ 132 3 ] loss: 0.359983891248703 2022-08-12 01:06:49.115756
Epoch:[ 132 4 ] loss: 0.3596068322658539 2022-08-12 01:06:49.541075
Epoch:[ 132 5 ] loss: 0.36018288135528564 2022-08-12 01:06:49.965609
Epoch:[ 132 6 ] loss: 0.360113263130188 2022-08-12 01:06:50.385329
Epoch:[ 132 7 ] loss: 0.3608105182647705 2022-08-12 01:06:50.807864
Epoch:[ 132 8 ] loss: 0.3585042953491211 2022-08-12 01:06:51.232193
Epoch:[ 132 9 ] loss: 0.35959765315055847 2022-08-12 01:06:51.657558
Epoch:[ 132 10 ] loss: 0.35975584387779236 2022-08-12 01:06:52.082592
Epoch:[ 132 11 ] loss: 0.3601035475730896 2022-08-12 01:06:52.507575
Epoch:[ 132 12 ] loss: 0.36074337363243103 2022-08-12 01:06:52.933471
Epoch:[ 132 13 ] loss: 0.35974830389022827 2022-08-12 01:06:53.359674
Epoch:[ 132 14 ] loss: 0.35904428362846375 2022-08-12 01:06:53.772549
Epoch:[ 132 15 ] loss: 0.35975906252861023 2022-08-12 01:06:54.194659
Epoch:[ 132 16 ] loss: 0.3597147762775421 2022-08-12 01:07:00.022984
Epoch:[ 132 17 ] loss: 0.3602980971336365 2022-08-12 01:07:00.441652
Epoch:[ 132 18 ] loss: 0.3596118986606598 2022-08-12 01:07:00.869661
Epoch:[ 132 19 ] loss: 0.3601960837841034 2022-08-12 01:07:01.293175
Training_Epoch:[ 132 ] Training_loss: 0.3598578631877899 2022-08-12 01:07:01.293912
learning rate:  0.000483621974262985
val: 1 0.39806047081947327
val: 2 0.3971286416053772
val: 3 0.39440491795539856
val: 4 0.4015757739543915
val: 5 0.4003635346889496
val: 6 0.3983619511127472
val: 7 0.40168511867523193
val: 8 0.3982517123222351
val: 9 0.3981175422668457
val: 10 0.39473772048950195
val: 11 0.3972485661506653
val: 12 0.4050210118293762
val: 13 0.39917853474617004
val: 14 0.40414535999298096
val: 15 0.4010484218597412
val: 16 0.4050309360027313
val: 17 0.40528762340545654
val: 18 0.4029136300086975
val: 19 0.40712055563926697
val: 20 0.40408846735954285
val_Epoch:[ 132 ] val_loss: 0.40068852454423903 2022-08-12 01:07:04.838591
start training 2022-08-12 01:07:04.939886
Epoch:[ 133 0 ] loss: 0.3597913384437561 2022-08-12 01:07:19.829708
Epoch:[ 133 1 ] loss: 0.358337938785553 2022-08-12 01:07:20.253550
Epoch:[ 133 2 ] loss: 0.3589527904987335 2022-08-12 01:07:20.680746
Epoch:[ 133 3 ] loss: 0.35913652181625366 2022-08-12 01:07:21.100571
Epoch:[ 133 4 ] loss: 0.35932841897010803 2022-08-12 01:07:21.517479
Epoch:[ 133 5 ] loss: 0.3594515919685364 2022-08-12 01:07:21.943121
Epoch:[ 133 6 ] loss: 0.35813984274864197 2022-08-12 01:07:22.370656
Epoch:[ 133 7 ] loss: 0.3603883981704712 2022-08-12 01:07:22.794044
Epoch:[ 133 8 ] loss: 0.35848158597946167 2022-08-12 01:07:23.217021
Epoch:[ 133 9 ] loss: 0.3602670431137085 2022-08-12 01:07:23.639640
Epoch:[ 133 10 ] loss: 0.358379065990448 2022-08-12 01:07:24.062942
Epoch:[ 133 11 ] loss: 0.3604304790496826 2022-08-12 01:07:24.486845
Epoch:[ 133 12 ] loss: 0.35906246304512024 2022-08-12 01:07:24.907409
Epoch:[ 133 13 ] loss: 0.358723521232605 2022-08-12 01:07:25.340036
Epoch:[ 133 14 ] loss: 0.35773220658302307 2022-08-12 01:07:25.757440
Epoch:[ 133 15 ] loss: 0.3591580390930176 2022-08-12 01:07:26.172478
Epoch:[ 133 16 ] loss: 0.36071711778640747 2022-08-12 01:07:31.169476
Epoch:[ 133 17 ] loss: 0.3577347695827484 2022-08-12 01:07:31.593447
Epoch:[ 133 18 ] loss: 0.3597545623779297 2022-08-12 01:07:32.014716
Epoch:[ 133 19 ] loss: 0.36072054505348206 2022-08-12 01:07:32.437334
Training_Epoch:[ 133 ] Training_loss: 0.3592344120144844 2022-08-12 01:07:32.438071
learning rate:  0.000483621974262985
val: 1 0.39945805072784424
val: 2 0.40661710500717163
val: 3 0.4064752161502838
val: 4 0.4016067087650299
val: 5 0.4050225019454956
val: 6 0.3989615738391876
val: 7 0.40556061267852783
val: 8 0.39649689197540283
val: 9 0.4078136682510376
val: 10 0.3937067985534668
val: 11 0.3984992802143097
val: 12 0.4030143916606903
val: 13 0.4022725820541382
val: 14 0.40216168761253357
val: 15 0.40348803997039795
val: 16 0.39268413186073303
val: 17 0.40096515417099
val: 18 0.3982466459274292
val: 19 0.3951852023601532
val: 20 0.4002322256565094
val_Epoch:[ 133 ] val_loss: 0.4009234234690666 2022-08-12 01:07:35.999657
start training 2022-08-12 01:07:36.099071
Epoch:[ 134 0 ] loss: 0.35936349630355835 2022-08-12 01:07:50.785998
Epoch:[ 134 1 ] loss: 0.358061283826828 2022-08-12 01:07:51.208713
Epoch:[ 134 2 ] loss: 0.3585588335990906 2022-08-12 01:07:51.629698
Epoch:[ 134 3 ] loss: 0.3593665063381195 2022-08-12 01:07:52.053320
Epoch:[ 134 4 ] loss: 0.36003196239471436 2022-08-12 01:07:52.475980
Epoch:[ 134 5 ] loss: 0.3596669137477875 2022-08-12 01:07:52.901599
Epoch:[ 134 6 ] loss: 0.35837867856025696 2022-08-12 01:07:53.327276
Epoch:[ 134 7 ] loss: 0.35931551456451416 2022-08-12 01:07:53.750657
Epoch:[ 134 8 ] loss: 0.3605041801929474 2022-08-12 01:07:54.169737
Epoch:[ 134 9 ] loss: 0.3593728840351105 2022-08-12 01:07:54.586748
Epoch:[ 134 10 ] loss: 0.3603300154209137 2022-08-12 01:07:55.007258
Epoch:[ 134 11 ] loss: 0.3585756719112396 2022-08-12 01:07:55.432263
Epoch:[ 134 12 ] loss: 0.3588489890098572 2022-08-12 01:07:55.853880
Epoch:[ 134 13 ] loss: 0.3595483601093292 2022-08-12 01:07:56.276368
Epoch:[ 134 14 ] loss: 0.360514760017395 2022-08-12 01:07:56.697875
Epoch:[ 134 15 ] loss: 0.35975638031959534 2022-08-12 01:07:57.124123
Epoch:[ 134 16 ] loss: 0.3596636652946472 2022-08-12 01:08:02.527438
Epoch:[ 134 17 ] loss: 0.35956892371177673 2022-08-12 01:08:02.945473
Epoch:[ 134 18 ] loss: 0.3593839108943939 2022-08-12 01:08:03.365060
Epoch:[ 134 19 ] loss: 0.359605610370636 2022-08-12 01:08:03.785104
Training_Epoch:[ 134 ] Training_loss: 0.35942082703113554 2022-08-12 01:08:03.785800
learning rate:  0.000483621974262985
val: 1 0.398678719997406
val: 2 0.39472687244415283
val: 3 0.39415499567985535
val: 4 0.40278753638267517
val: 5 0.40048179030418396
val: 6 0.3963080048561096
val: 7 0.406120628118515
val: 8 0.39966708421707153
val: 9 0.4067566692829132
val: 10 0.3987603783607483
val: 11 0.3995926082134247
val: 12 0.4029145836830139
val: 13 0.395845890045166
val: 14 0.39813941717147827
val: 15 0.39695677161216736
val: 16 0.4108275771141052
val: 17 0.3946411609649658
val: 18 0.3962530493736267
val: 19 0.3904435336589813
val: 20 0.40241867303848267
val_Epoch:[ 134 ] val_loss: 0.3993237972259521 2022-08-12 01:08:07.336860
start training 2022-08-12 01:08:07.437394
Epoch:[ 135 0 ] loss: 0.35887011885643005 2022-08-12 01:08:21.931358
Epoch:[ 135 1 ] loss: 0.35862794518470764 2022-08-12 01:08:22.373312
Epoch:[ 135 2 ] loss: 0.3590448796749115 2022-08-12 01:08:22.799204
Epoch:[ 135 3 ] loss: 0.36036962270736694 2022-08-12 01:08:23.224027
Epoch:[ 135 4 ] loss: 0.3589780628681183 2022-08-12 01:08:23.643511
Epoch:[ 135 5 ] loss: 0.3585827052593231 2022-08-12 01:08:24.064921
Epoch:[ 135 6 ] loss: 0.3589795231819153 2022-08-12 01:08:24.485286
Epoch:[ 135 7 ] loss: 0.3589521050453186 2022-08-12 01:08:24.913341
Epoch:[ 135 8 ] loss: 0.35766318440437317 2022-08-12 01:08:25.331876
Epoch:[ 135 9 ] loss: 0.3584706485271454 2022-08-12 01:08:25.750302
Epoch:[ 135 10 ] loss: 0.35917574167251587 2022-08-12 01:08:26.172106
Epoch:[ 135 11 ] loss: 0.35791200399398804 2022-08-12 01:08:26.594904
Epoch:[ 135 12 ] loss: 0.35930582880973816 2022-08-12 01:08:27.012744
Epoch:[ 135 13 ] loss: 0.35887444019317627 2022-08-12 01:08:27.435033
Epoch:[ 135 14 ] loss: 0.3589351773262024 2022-08-12 01:08:27.864022
Epoch:[ 135 15 ] loss: 0.36169207096099854 2022-08-12 01:08:28.284861
Epoch:[ 135 16 ] loss: 0.3595413267612457 2022-08-12 01:08:33.441530
Epoch:[ 135 17 ] loss: 0.3595791459083557 2022-08-12 01:08:33.868974
Epoch:[ 135 18 ] loss: 0.35855409502983093 2022-08-12 01:08:34.293943
Epoch:[ 135 19 ] loss: 0.3603963255882263 2022-08-12 01:08:34.712662
Training_Epoch:[ 135 ] Training_loss: 0.3591252475976944 2022-08-12 01:08:34.713376
learning rate:  0.000483621974262985
val: 1 0.39703723788261414
val: 2 0.40489378571510315
val: 3 0.39722567796707153
val: 4 0.4065881073474884
val: 5 0.3882937729358673
val: 6 0.4048073887825012
val: 7 0.4006250202655792
val: 8 0.4038352966308594
val: 9 0.3958772122859955
val: 10 0.399787575006485
val: 11 0.4032042324542999
val: 12 0.4031875729560852
val: 13 0.4026094377040863
val: 14 0.40626657009124756
val: 15 0.39969339966773987
val: 16 0.40184107422828674
val: 17 0.40035584568977356
val: 18 0.3969589173793793
val: 19 0.39526882767677307
val: 20 0.40208473801612854
val_Epoch:[ 135 ] val_loss: 0.40052208453416827 2022-08-12 01:08:38.256249
start training 2022-08-12 01:08:38.357466
Epoch:[ 136 0 ] loss: 0.35909968614578247 2022-08-12 01:08:52.927684
Epoch:[ 136 1 ] loss: 0.3586057722568512 2022-08-12 01:08:53.373192
Epoch:[ 136 2 ] loss: 0.3577437400817871 2022-08-12 01:08:53.798989
Epoch:[ 136 3 ] loss: 0.35818958282470703 2022-08-12 01:08:54.220617
Epoch:[ 136 4 ] loss: 0.3586086630821228 2022-08-12 01:08:54.641348
Epoch:[ 136 5 ] loss: 0.35903260111808777 2022-08-12 01:08:55.066377
Epoch:[ 136 6 ] loss: 0.35845041275024414 2022-08-12 01:08:55.492264
Epoch:[ 136 7 ] loss: 0.3597742021083832 2022-08-12 01:08:55.914284
Epoch:[ 136 8 ] loss: 0.3588007688522339 2022-08-12 01:08:56.341317
Epoch:[ 136 9 ] loss: 0.3597535192966461 2022-08-12 01:08:56.764366
Epoch:[ 136 10 ] loss: 0.35926780104637146 2022-08-12 01:08:57.190379
Epoch:[ 136 11 ] loss: 0.3576600253582001 2022-08-12 01:08:57.612005
Epoch:[ 136 12 ] loss: 0.3588496446609497 2022-08-12 01:08:58.037053
Epoch:[ 136 13 ] loss: 0.3579269349575043 2022-08-12 01:08:58.459126
Epoch:[ 136 14 ] loss: 0.3597632348537445 2022-08-12 01:08:58.886657
Epoch:[ 136 15 ] loss: 0.3589254915714264 2022-08-12 01:08:59.301659
Epoch:[ 136 16 ] loss: 0.36027130484580994 2022-08-12 01:09:04.661585
Epoch:[ 136 17 ] loss: 0.35921499133110046 2022-08-12 01:09:05.081108
Epoch:[ 136 18 ] loss: 0.3601474463939667 2022-08-12 01:09:05.503179
Epoch:[ 136 19 ] loss: 0.3607946038246155 2022-08-12 01:09:05.922432
Training_Epoch:[ 136 ] Training_loss: 0.3590440213680267 2022-08-12 01:09:05.923096
learning rate:  0.000483621974262985
val: 1 0.3980002999305725
val: 2 0.399262398481369
val: 3 0.40246865153312683
val: 4 0.4006477892398834
val: 5 0.3993460237979889
val: 6 0.40796443819999695
val: 7 0.3961908519268036
val: 8 0.4027547538280487
val: 9 0.3961241543292999
val: 10 0.39873236417770386
val: 11 0.40273812413215637
val: 12 0.3978434205055237
val: 13 0.3936918079853058
val: 14 0.3994823098182678
val: 15 0.397810161113739
val: 16 0.3982665538787842
val: 17 0.4009106755256653
val: 18 0.3989987075328827
val: 19 0.4058597981929779
val: 20 0.39289146661758423
val_Epoch:[ 136 ] val_loss: 0.39949923753738403 2022-08-12 01:09:09.559839
start training 2022-08-12 01:09:09.661389
Epoch:[ 137 0 ] loss: 0.3598359227180481 2022-08-12 01:09:24.030385
Epoch:[ 137 1 ] loss: 0.3578709065914154 2022-08-12 01:09:24.451166
Epoch:[ 137 2 ] loss: 0.35794198513031006 2022-08-12 01:09:24.876659
Epoch:[ 137 3 ] loss: 0.357949823141098 2022-08-12 01:09:25.300186
Epoch:[ 137 4 ] loss: 0.35840392112731934 2022-08-12 01:09:25.723919
Epoch:[ 137 5 ] loss: 0.3599010705947876 2022-08-12 01:09:26.145565
Epoch:[ 137 6 ] loss: 0.35810375213623047 2022-08-12 01:09:26.569491
Epoch:[ 137 7 ] loss: 0.35848739743232727 2022-08-12 01:09:26.990594
Epoch:[ 137 8 ] loss: 0.35788217186927795 2022-08-12 01:09:27.411990
Epoch:[ 137 9 ] loss: 0.3587017059326172 2022-08-12 01:09:27.825208
Epoch:[ 137 10 ] loss: 0.3602096438407898 2022-08-12 01:09:28.249085
Epoch:[ 137 11 ] loss: 0.35904550552368164 2022-08-12 01:09:28.674528
Epoch:[ 137 12 ] loss: 0.36025574803352356 2022-08-12 01:09:29.093039
Epoch:[ 137 13 ] loss: 0.35873326659202576 2022-08-12 01:09:29.509590
Epoch:[ 137 14 ] loss: 0.3609076738357544 2022-08-12 01:09:29.934413
Epoch:[ 137 15 ] loss: 0.36039024591445923 2022-08-12 01:09:30.363892
Epoch:[ 137 16 ] loss: 0.3582969903945923 2022-08-12 01:09:36.077288
Epoch:[ 137 17 ] loss: 0.36016350984573364 2022-08-12 01:09:36.499056
Epoch:[ 137 18 ] loss: 0.35925623774528503 2022-08-12 01:09:36.926655
Epoch:[ 137 19 ] loss: 0.35845547914505005 2022-08-12 01:09:37.343377
Training_Epoch:[ 137 ] Training_loss: 0.3590396478772163 2022-08-12 01:09:37.344072
learning rate:  0.000483621974262985
val: 1 0.3995523154735565
val: 2 0.3996100425720215
val: 3 0.40196216106414795
val: 4 0.39645683765411377
val: 5 0.39725300669670105
val: 6 0.4007070064544678
val: 7 0.4032062888145447
val: 8 0.39780503511428833
val: 9 0.404473215341568
val: 10 0.4102720618247986
val: 11 0.3934312164783478
val: 12 0.39572420716285706
val: 13 0.4072260558605194
val: 14 0.39416301250457764
val: 15 0.3982120752334595
val: 16 0.4059041738510132
val: 17 0.40231406688690186
val: 18 0.39607542753219604
val: 19 0.3961732089519501
val: 20 0.39967748522758484
val_Epoch:[ 137 ] val_loss: 0.4000099450349808 2022-08-12 01:09:40.920243
start training 2022-08-12 01:09:41.018092
Epoch:[ 138 0 ] loss: 0.3575895428657532 2022-08-12 01:09:55.976424
Epoch:[ 138 1 ] loss: 0.3585663139820099 2022-08-12 01:09:56.402003
Epoch:[ 138 2 ] loss: 0.3576947748661041 2022-08-12 01:09:56.822284
Epoch:[ 138 3 ] loss: 0.3602908253669739 2022-08-12 01:09:57.246342
Epoch:[ 138 4 ] loss: 0.3572632074356079 2022-08-12 01:09:57.670473
Epoch:[ 138 5 ] loss: 0.3607431650161743 2022-08-12 01:09:58.096956
Epoch:[ 138 6 ] loss: 0.358905166387558 2022-08-12 01:09:58.520040
Epoch:[ 138 7 ] loss: 0.3587864935398102 2022-08-12 01:09:58.942189
Epoch:[ 138 8 ] loss: 0.35920557379722595 2022-08-12 01:09:59.367744
Epoch:[ 138 9 ] loss: 0.35988935828208923 2022-08-12 01:09:59.791155
Epoch:[ 138 10 ] loss: 0.35824424028396606 2022-08-12 01:10:00.205076
Epoch:[ 138 11 ] loss: 0.3582739233970642 2022-08-12 01:10:00.630128
Epoch:[ 138 12 ] loss: 0.35914146900177 2022-08-12 01:10:01.060831
Epoch:[ 138 13 ] loss: 0.3592086732387543 2022-08-12 01:10:01.480498
Epoch:[ 138 14 ] loss: 0.3596610724925995 2022-08-12 01:10:01.895604
Epoch:[ 138 15 ] loss: 0.35895034670829773 2022-08-12 01:10:02.319941
Epoch:[ 138 16 ] loss: 0.36104676127433777 2022-08-12 01:10:08.068863
Epoch:[ 138 17 ] loss: 0.35933157801628113 2022-08-12 01:10:08.484370
Epoch:[ 138 18 ] loss: 0.359652578830719 2022-08-12 01:10:08.917707
Epoch:[ 138 19 ] loss: 0.3599652349948883 2022-08-12 01:10:09.341187
Training_Epoch:[ 138 ] Training_loss: 0.35912051498889924 2022-08-12 01:10:09.341867
learning rate:  0.000483621974262985
val: 1 0.3939858675003052
val: 2 0.39624345302581787
val: 3 0.3969022035598755
val: 4 0.39753007888793945
val: 5 0.40061041712760925
val: 6 0.40260791778564453
val: 7 0.40284401178359985
val: 8 0.396472692489624
val: 9 0.4008152484893799
val: 10 0.40724483132362366
val: 11 0.3931655287742615
val: 12 0.39836955070495605
val: 13 0.3951517641544342
val: 14 0.4014735817909241
val: 15 0.3975960314273834
val: 16 0.40033650398254395
val: 17 0.4039895832538605
val: 18 0.3961484134197235
val: 19 0.3972013294696808
val: 20 0.3977605998516083
val_Epoch:[ 138 ] val_loss: 0.3988224804401398 2022-08-12 01:10:12.910636
start training 2022-08-12 01:10:13.007572
Epoch:[ 139 0 ] loss: 0.35821476578712463 2022-08-12 01:10:27.383295
Epoch:[ 139 1 ] loss: 0.35961124300956726 2022-08-12 01:10:27.825476
Epoch:[ 139 2 ] loss: 0.3581100106239319 2022-08-12 01:10:28.242011
Epoch:[ 139 3 ] loss: 0.3594226837158203 2022-08-12 01:10:28.663910
Epoch:[ 139 4 ] loss: 0.3582874834537506 2022-08-12 01:10:29.084960
Epoch:[ 139 5 ] loss: 0.3600894808769226 2022-08-12 01:10:29.510409
Epoch:[ 139 6 ] loss: 0.3586159646511078 2022-08-12 01:10:29.931690
Epoch:[ 139 7 ] loss: 0.35903772711753845 2022-08-12 01:10:30.349133
Epoch:[ 139 8 ] loss: 0.3598080277442932 2022-08-12 01:10:30.771111
Epoch:[ 139 9 ] loss: 0.35900822281837463 2022-08-12 01:10:31.196297
Epoch:[ 139 10 ] loss: 0.35785728693008423 2022-08-12 01:10:31.625444
Epoch:[ 139 11 ] loss: 0.35868263244628906 2022-08-12 01:10:32.050075
Epoch:[ 139 12 ] loss: 0.35976672172546387 2022-08-12 01:10:32.475780
Epoch:[ 139 13 ] loss: 0.3600850999355316 2022-08-12 01:10:32.895705
Epoch:[ 139 14 ] loss: 0.3592287600040436 2022-08-12 01:10:33.315444
Epoch:[ 139 15 ] loss: 0.35932308435440063 2022-08-12 01:10:33.741255
Epoch:[ 139 16 ] loss: 0.3601047992706299 2022-08-12 01:10:38.906002
Epoch:[ 139 17 ] loss: 0.35882025957107544 2022-08-12 01:10:39.329829
Epoch:[ 139 18 ] loss: 0.3594142496585846 2022-08-12 01:10:39.754619
Epoch:[ 139 19 ] loss: 0.3598071336746216 2022-08-12 01:10:40.181784
Training_Epoch:[ 139 ] Training_loss: 0.3591647818684578 2022-08-12 01:10:40.182512
learning rate:  0.000483621974262985
val: 1 0.4038347601890564
val: 2 0.3992898762226105
val: 3 0.40030035376548767
val: 4 0.39878180623054504
val: 5 0.40742772817611694
val: 6 0.40646132826805115
val: 7 0.39905810356140137
val: 8 0.39897778630256653
val: 9 0.398408442735672
val: 10 0.40051859617233276
val: 11 0.3911959230899811
val: 12 0.4022563397884369
val: 13 0.39219599962234497
val: 14 0.4019254148006439
val: 15 0.39799031615257263
val: 16 0.3971948027610779
val: 17 0.3943358063697815
val: 18 0.3993750214576721
val: 19 0.40121108293533325
val: 20 0.39835813641548157
val_Epoch:[ 139 ] val_loss: 0.3994548812508583 2022-08-12 01:10:43.798762
start training 2022-08-12 01:10:43.899442
Epoch:[ 140 0 ] loss: 0.3588297963142395 2022-08-12 01:10:58.604453
Epoch:[ 140 1 ] loss: 0.358436644077301 2022-08-12 01:10:59.025980
Epoch:[ 140 2 ] loss: 0.3577803075313568 2022-08-12 01:10:59.450744
Epoch:[ 140 3 ] loss: 0.35678303241729736 2022-08-12 01:10:59.870450
Epoch:[ 140 4 ] loss: 0.3578716814517975 2022-08-12 01:11:00.296571
Epoch:[ 140 5 ] loss: 0.35825568437576294 2022-08-12 01:11:00.715266
Epoch:[ 140 6 ] loss: 0.35726696252822876 2022-08-12 01:11:01.130899
Epoch:[ 140 7 ] loss: 0.3576022982597351 2022-08-12 01:11:01.552282
Epoch:[ 140 8 ] loss: 0.3577684760093689 2022-08-12 01:11:01.976690
Epoch:[ 140 9 ] loss: 0.35902589559555054 2022-08-12 01:11:02.401314
Epoch:[ 140 10 ] loss: 0.35890448093414307 2022-08-12 01:11:02.817049
Epoch:[ 140 11 ] loss: 0.3585367202758789 2022-08-12 01:11:03.240296
Epoch:[ 140 12 ] loss: 0.3596780598163605 2022-08-12 01:11:03.668146
Epoch:[ 140 13 ] loss: 0.35917988419532776 2022-08-12 01:11:04.094923
Epoch:[ 140 14 ] loss: 0.356797456741333 2022-08-12 01:11:04.518729
Epoch:[ 140 15 ] loss: 0.3589458465576172 2022-08-12 01:11:04.941327
Epoch:[ 140 16 ] loss: 0.3596958518028259 2022-08-12 01:11:10.267076
Epoch:[ 140 17 ] loss: 0.3591361939907074 2022-08-12 01:11:10.683978
Epoch:[ 140 18 ] loss: 0.35934850573539734 2022-08-12 01:11:11.110125
Epoch:[ 140 19 ] loss: 0.36031097173690796 2022-08-12 01:11:11.529799
Training_Epoch:[ 140 ] Training_loss: 0.3585077375173569 2022-08-12 01:11:11.530492
learning rate:  0.000483621974262985
netparams have been saved once 140
val: 1 0.39431893825531006
val: 2 0.3987290859222412
val: 3 0.40054067969322205
val: 4 0.39270779490470886
val: 5 0.396345853805542
val: 6 0.40523988008499146
val: 7 0.3989056348800659
val: 8 0.39982202649116516
val: 9 0.39995914697647095
val: 10 0.39055532217025757
val: 11 0.3974848687648773
val: 12 0.404062420129776
val: 13 0.4001532196998596
val: 14 0.3957819640636444
val: 15 0.3927740752696991
val: 16 0.3993867039680481
val: 17 0.3967808783054352
val: 18 0.39380618929862976
val: 19 0.39738327264785767
val: 20 0.39602863788604736
val_Epoch:[ 140 ] val_loss: 0.3975383296608925 2022-08-12 01:11:15.111373
start training 2022-08-12 01:11:15.229531
Epoch:[ 141 0 ] loss: 0.35856756567955017 2022-08-12 01:11:29.253989
Epoch:[ 141 1 ] loss: 0.3588631749153137 2022-08-12 01:11:29.687591
Epoch:[ 141 2 ] loss: 0.3593570291996002 2022-08-12 01:11:30.119616
Epoch:[ 141 3 ] loss: 0.3594212830066681 2022-08-12 01:11:30.550796
Epoch:[ 141 4 ] loss: 0.3589557707309723 2022-08-12 01:11:30.970162
Epoch:[ 141 5 ] loss: 0.35923221707344055 2022-08-12 01:11:31.387494
Epoch:[ 141 6 ] loss: 0.35913363099098206 2022-08-12 01:11:31.813707
Epoch:[ 141 7 ] loss: 0.3581313490867615 2022-08-12 01:11:32.241695
Epoch:[ 141 8 ] loss: 0.35790523886680603 2022-08-12 01:11:32.664369
Epoch:[ 141 9 ] loss: 0.35828590393066406 2022-08-12 01:11:33.084021
Epoch:[ 141 10 ] loss: 0.35917529463768005 2022-08-12 01:11:33.507984
Epoch:[ 141 11 ] loss: 0.35724568367004395 2022-08-12 01:11:33.929515
Epoch:[ 141 12 ] loss: 0.3595178425312042 2022-08-12 01:11:34.353681
Epoch:[ 141 13 ] loss: 0.35857269167900085 2022-08-12 01:11:34.778330
Epoch:[ 141 14 ] loss: 0.3601001799106598 2022-08-12 01:11:35.208128
Epoch:[ 141 15 ] loss: 0.3579612970352173 2022-08-12 01:11:35.628475
Epoch:[ 141 16 ] loss: 0.35888606309890747 2022-08-12 01:11:41.359279
Epoch:[ 141 17 ] loss: 0.3589286804199219 2022-08-12 01:11:41.782388
Epoch:[ 141 18 ] loss: 0.35721200704574585 2022-08-12 01:11:42.200912
Epoch:[ 141 19 ] loss: 0.35890859365463257 2022-08-12 01:11:42.616614
Training_Epoch:[ 141 ] Training_loss: 0.35871807485818863 2022-08-12 01:11:42.617308
learning rate:  0.00041107867812353725
val: 1 0.3992067575454712
val: 2 0.40509170293807983
val: 3 0.40014809370040894
val: 4 0.3998293876647949
val: 5 0.3971915543079376
val: 6 0.4011428952217102
val: 7 0.4034922420978546
val: 8 0.3969460129737854
val: 9 0.40249553322792053
val: 10 0.39443156123161316
val: 11 0.40460970997810364
val: 12 0.3994390368461609
val: 13 0.404143750667572
val: 14 0.3971458375453949
val: 15 0.4024180471897125
val: 16 0.4023967385292053
val: 17 0.3954102098941803
val: 18 0.4026496112346649
val: 19 0.39730119705200195
val: 20 0.40634942054748535
val_Epoch:[ 141 ] val_loss: 0.4005919650197029 2022-08-12 01:11:46.176323
start training 2022-08-12 01:11:46.277627
Epoch:[ 142 0 ] loss: 0.3589451014995575 2022-08-12 01:12:00.559342
Epoch:[ 142 1 ] loss: 0.35617223381996155 2022-08-12 01:12:00.993127
Epoch:[ 142 2 ] loss: 0.356082558631897 2022-08-12 01:12:01.418181
Epoch:[ 142 3 ] loss: 0.3581523895263672 2022-08-12 01:12:01.840141
Epoch:[ 142 4 ] loss: 0.35825785994529724 2022-08-12 01:12:02.253417
Epoch:[ 142 5 ] loss: 0.3579097390174866 2022-08-12 01:12:02.677044
Epoch:[ 142 6 ] loss: 0.3582414388656616 2022-08-12 01:12:03.103043
Epoch:[ 142 7 ] loss: 0.3579663038253784 2022-08-12 01:12:03.521501
Epoch:[ 142 8 ] loss: 0.3575091063976288 2022-08-12 01:12:03.944904
Epoch:[ 142 9 ] loss: 0.3583962023258209 2022-08-12 01:12:04.365060
Epoch:[ 142 10 ] loss: 0.35605692863464355 2022-08-12 01:12:04.792730
Epoch:[ 142 11 ] loss: 0.35792097449302673 2022-08-12 01:12:05.213306
Epoch:[ 142 12 ] loss: 0.3574221730232239 2022-08-12 01:12:05.633965
Epoch:[ 142 13 ] loss: 0.358041912317276 2022-08-12 01:12:06.055195
Epoch:[ 142 14 ] loss: 0.3572242558002472 2022-08-12 01:12:06.472311
Epoch:[ 142 15 ] loss: 0.35756659507751465 2022-08-12 01:12:06.896927
Epoch:[ 142 16 ] loss: 0.3573414087295532 2022-08-12 01:12:12.350828
Epoch:[ 142 17 ] loss: 0.3584520220756531 2022-08-12 01:12:12.772113
Epoch:[ 142 18 ] loss: 0.3589552342891693 2022-08-12 01:12:13.193376
Epoch:[ 142 19 ] loss: 0.3583219051361084 2022-08-12 01:12:13.617553
Training_Epoch:[ 142 ] Training_loss: 0.35774681717157364 2022-08-12 01:12:13.618240
learning rate:  0.00041107867812353725
val: 1 0.40550994873046875
val: 2 0.395974338054657
val: 3 0.3907620310783386
val: 4 0.405160129070282
val: 5 0.3974679708480835
val: 6 0.3992653489112854
val: 7 0.4001826047897339
val: 8 0.39809516072273254
val: 9 0.3999771475791931
val: 10 0.4056381285190582
val: 11 0.3965299129486084
val: 12 0.40004390478134155
val: 13 0.4008260667324066
val: 14 0.3947378396987915
val: 15 0.3983221650123596
val: 16 0.4054589569568634
val: 17 0.40148240327835083
val: 18 0.3951793313026428
val: 19 0.394920289516449
val: 20 0.39671069383621216
val_Epoch:[ 142 ] val_loss: 0.39911221861839297 2022-08-12 01:12:17.238301
start training 2022-08-12 01:12:17.336506
Epoch:[ 143 0 ] loss: 0.3571941554546356 2022-08-12 01:12:31.715772
Epoch:[ 143 1 ] loss: 0.3578775227069855 2022-08-12 01:12:32.154307
Epoch:[ 143 2 ] loss: 0.35751181840896606 2022-08-12 01:12:32.576640
Epoch:[ 143 3 ] loss: 0.3566472828388214 2022-08-12 01:12:33.001870
Epoch:[ 143 4 ] loss: 0.3560730814933777 2022-08-12 01:12:33.425713
Epoch:[ 143 5 ] loss: 0.35749661922454834 2022-08-12 01:12:33.850543
Epoch:[ 143 6 ] loss: 0.35749489068984985 2022-08-12 01:12:34.274525
Epoch:[ 143 7 ] loss: 0.3572072982788086 2022-08-12 01:12:34.695264
Epoch:[ 143 8 ] loss: 0.356100857257843 2022-08-12 01:12:35.121018
Epoch:[ 143 9 ] loss: 0.35762953758239746 2022-08-12 01:12:35.543216
Epoch:[ 143 10 ] loss: 0.3570629954338074 2022-08-12 01:12:35.966399
Epoch:[ 143 11 ] loss: 0.3566961884498596 2022-08-12 01:12:36.388618
Epoch:[ 143 12 ] loss: 0.3573082983493805 2022-08-12 01:12:36.809746
Epoch:[ 143 13 ] loss: 0.3575309216976166 2022-08-12 01:12:37.222123
Epoch:[ 143 14 ] loss: 0.3560560941696167 2022-08-12 01:12:37.646428
Epoch:[ 143 15 ] loss: 0.3576521873474121 2022-08-12 01:12:38.080358
Epoch:[ 143 16 ] loss: 0.35843977332115173 2022-08-12 01:12:43.434120
Epoch:[ 143 17 ] loss: 0.3582989573478699 2022-08-12 01:12:43.851542
Epoch:[ 143 18 ] loss: 0.35781216621398926 2022-08-12 01:12:44.275475
Epoch:[ 143 19 ] loss: 0.357042521238327 2022-08-12 01:12:44.699753
Training_Epoch:[ 143 ] Training_loss: 0.3572566583752632 2022-08-12 01:12:44.700466
learning rate:  0.00041107867812353725
val: 1 0.3908960521221161
val: 2 0.39917635917663574
val: 3 0.4043101370334625
val: 4 0.4042871594429016
val: 5 0.400169312953949
val: 6 0.40772366523742676
val: 7 0.3896603286266327
val: 8 0.4031056761741638
val: 9 0.3994419574737549
val: 10 0.4026471674442291
val: 11 0.40550410747528076
val: 12 0.3948099911212921
val: 13 0.40418800711631775
val: 14 0.3984237611293793
val: 15 0.4018685519695282
val: 16 0.39408770203590393
val: 17 0.4009714126586914
val: 18 0.3994874954223633
val: 19 0.3981234133243561
val: 20 0.40540042519569397
val_Epoch:[ 143 ] val_loss: 0.4002141341567039 2022-08-12 01:12:48.244751
start training 2022-08-12 01:12:48.345107
Epoch:[ 144 0 ] loss: 0.3565009534358978 2022-08-12 01:13:03.059137
Epoch:[ 144 1 ] loss: 0.35634645819664 2022-08-12 01:13:03.478308
Epoch:[ 144 2 ] loss: 0.3572387397289276 2022-08-12 01:13:03.903137
Epoch:[ 144 3 ] loss: 0.35556739568710327 2022-08-12 01:13:04.330125
Epoch:[ 144 4 ] loss: 0.3563767671585083 2022-08-12 01:13:04.754753
Epoch:[ 144 5 ] loss: 0.3573795557022095 2022-08-12 01:13:05.174013
Epoch:[ 144 6 ] loss: 0.35625267028808594 2022-08-12 01:13:05.589950
Epoch:[ 144 7 ] loss: 0.3586513102054596 2022-08-12 01:13:06.008835
Epoch:[ 144 8 ] loss: 0.35668855905532837 2022-08-12 01:13:06.435577
Epoch:[ 144 9 ] loss: 0.3570755124092102 2022-08-12 01:13:06.856782
Epoch:[ 144 10 ] loss: 0.35622185468673706 2022-08-12 01:13:07.277729
Epoch:[ 144 11 ] loss: 0.35568755865097046 2022-08-12 01:13:07.699738
Epoch:[ 144 12 ] loss: 0.35684555768966675 2022-08-12 01:13:08.130156
Epoch:[ 144 13 ] loss: 0.3567373752593994 2022-08-12 01:13:08.555364
Epoch:[ 144 14 ] loss: 0.35706332325935364 2022-08-12 01:13:08.976030
Epoch:[ 144 15 ] loss: 0.3574778139591217 2022-08-12 01:13:09.399952
Epoch:[ 144 16 ] loss: 0.3582133948802948 2022-08-12 01:13:14.888939
Epoch:[ 144 17 ] loss: 0.35841479897499084 2022-08-12 01:13:15.304964
Epoch:[ 144 18 ] loss: 0.3574356436729431 2022-08-12 01:13:15.729971
Epoch:[ 144 19 ] loss: 0.356507271528244 2022-08-12 01:13:16.152228
Training_Epoch:[ 144 ] Training_loss: 0.3569341257214546 2022-08-12 01:13:16.152946
learning rate:  0.00041107867812353725
val: 1 0.406569242477417
val: 2 0.4046635925769806
val: 3 0.3975907266139984
val: 4 0.39082539081573486
val: 5 0.39516761898994446
val: 6 0.4005407691001892
val: 7 0.39856791496276855
val: 8 0.39790186285972595
val: 9 0.3953907787799835
val: 10 0.40370914340019226
val: 11 0.3994539678096771
val: 12 0.40713071823120117
val: 13 0.3955971896648407
val: 14 0.40041661262512207
val: 15 0.3980826735496521
val: 16 0.3955487906932831
val: 17 0.40039902925491333
val: 18 0.40663233399391174
val: 19 0.4103934168815613
val: 20 0.40099668502807617
val_Epoch:[ 144 ] val_loss: 0.4002789229154587 2022-08-12 01:13:19.718415
start training 2022-08-12 01:13:19.819343
Epoch:[ 145 0 ] loss: 0.35659360885620117 2022-08-12 01:13:33.661670
Epoch:[ 145 1 ] loss: 0.3567407429218292 2022-08-12 01:13:34.095994
Epoch:[ 145 2 ] loss: 0.35723280906677246 2022-08-12 01:13:34.541578
Epoch:[ 145 3 ] loss: 0.35668817162513733 2022-08-12 01:13:34.963149
Epoch:[ 145 4 ] loss: 0.35587456822395325 2022-08-12 01:13:35.387871
Epoch:[ 145 5 ] loss: 0.3563433885574341 2022-08-12 01:13:35.810362
Epoch:[ 145 6 ] loss: 0.3567173480987549 2022-08-12 01:13:36.230130
Epoch:[ 145 7 ] loss: 0.35738739371299744 2022-08-12 01:13:36.661532
Epoch:[ 145 8 ] loss: 0.3568902313709259 2022-08-12 01:13:37.086731
Epoch:[ 145 9 ] loss: 0.3573233187198639 2022-08-12 01:13:37.507601
Epoch:[ 145 10 ] loss: 0.357325941324234 2022-08-12 01:13:37.924651
Epoch:[ 145 11 ] loss: 0.3561001420021057 2022-08-12 01:13:38.344456
Epoch:[ 145 12 ] loss: 0.35626643896102905 2022-08-12 01:13:38.768924
Epoch:[ 145 13 ] loss: 0.3575294315814972 2022-08-12 01:13:39.192162
Epoch:[ 145 14 ] loss: 0.35660427808761597 2022-08-12 01:13:39.609826
Epoch:[ 145 15 ] loss: 0.3573334217071533 2022-08-12 01:13:40.031541
Epoch:[ 145 16 ] loss: 0.3575970232486725 2022-08-12 01:13:46.136657
Epoch:[ 145 17 ] loss: 0.3584563434123993 2022-08-12 01:13:46.557993
Epoch:[ 145 18 ] loss: 0.35659757256507874 2022-08-12 01:13:46.985651
Epoch:[ 145 19 ] loss: 0.35969746112823486 2022-08-12 01:13:47.411149
Training_Epoch:[ 145 ] Training_loss: 0.3570649817585945 2022-08-12 01:13:47.411845
learning rate:  0.00041107867812353725
val: 1 0.4053604006767273
val: 2 0.40123987197875977
val: 3 0.39634451270103455
val: 4 0.40531209111213684
val: 5 0.39944496750831604
val: 6 0.3908289074897766
val: 7 0.40163564682006836
val: 8 0.39480534195899963
val: 9 0.39920464158058167
val: 10 0.40142473578453064
val: 11 0.40756669640541077
val: 12 0.39778441190719604
val: 13 0.3933327794075012
val: 14 0.39489802718162537
val: 15 0.390280544757843
val: 16 0.4011906683444977
val: 17 0.3951232135295868
val: 18 0.40179312229156494
val: 19 0.40053480863571167
val: 20 0.4109899699687958
val_Epoch:[ 145 ] val_loss: 0.3994547680020332 2022-08-12 01:13:50.959034
start training 2022-08-12 01:13:51.061216
Epoch:[ 146 0 ] loss: 0.35768958926200867 2022-08-12 01:14:05.063353
Epoch:[ 146 1 ] loss: 0.35629862546920776 2022-08-12 01:14:05.502576
Epoch:[ 146 2 ] loss: 0.3574087917804718 2022-08-12 01:14:05.940511
Epoch:[ 146 3 ] loss: 0.35682213306427 2022-08-12 01:14:06.362787
Epoch:[ 146 4 ] loss: 0.3568457067012787 2022-08-12 01:14:06.776658
Epoch:[ 146 5 ] loss: 0.3557042181491852 2022-08-12 01:14:07.199218
Epoch:[ 146 6 ] loss: 0.3575611114501953 2022-08-12 01:14:07.624907
Epoch:[ 146 7 ] loss: 0.3561217784881592 2022-08-12 01:14:08.045065
Epoch:[ 146 8 ] loss: 0.3579699397087097 2022-08-12 01:14:08.461624
Epoch:[ 146 9 ] loss: 0.3575281500816345 2022-08-12 01:14:08.884868
Epoch:[ 146 10 ] loss: 0.35719534754753113 2022-08-12 01:14:09.311277
Epoch:[ 146 11 ] loss: 0.3575183153152466 2022-08-12 01:14:09.741938
Epoch:[ 146 12 ] loss: 0.35764166712760925 2022-08-12 01:14:10.165169
Epoch:[ 146 13 ] loss: 0.35765841603279114 2022-08-12 01:14:10.587409
Epoch:[ 146 14 ] loss: 0.35794925689697266 2022-08-12 01:14:11.007970
Epoch:[ 146 15 ] loss: 0.35613662004470825 2022-08-12 01:14:11.431393
Epoch:[ 146 16 ] loss: 0.3570096492767334 2022-08-12 01:14:17.179140
Epoch:[ 146 17 ] loss: 0.35626325011253357 2022-08-12 01:14:17.603166
Epoch:[ 146 18 ] loss: 0.35738325119018555 2022-08-12 01:14:18.033101
Epoch:[ 146 19 ] loss: 0.3588297665119171 2022-08-12 01:14:18.457828
Training_Epoch:[ 146 ] Training_loss: 0.35717677921056745 2022-08-12 01:14:18.458533
learning rate:  0.00041107867812353725
val: 1 0.4031831920146942
val: 2 0.40226250886917114
val: 3 0.406620591878891
val: 4 0.39702364802360535
val: 5 0.40175309777259827
val: 6 0.4009406268596649
val: 7 0.40119490027427673
val: 8 0.399943470954895
val: 9 0.4051033854484558
val: 10 0.3965120017528534
val: 11 0.3979637324810028
val: 12 0.3990561366081238
val: 13 0.3943895697593689
val: 14 0.3990745544433594
val: 15 0.40181922912597656
val: 16 0.3999670147895813
val: 17 0.40837550163269043
val: 18 0.4012220799922943
val: 19 0.39968565106391907
val: 20 0.4038899540901184
val_Epoch:[ 146 ] val_loss: 0.400999042391777 2022-08-12 01:14:22.093953
start training 2022-08-12 01:14:22.193850
Epoch:[ 147 0 ] loss: 0.35605278611183167 2022-08-12 01:14:36.345794
Epoch:[ 147 1 ] loss: 0.3568548262119293 2022-08-12 01:14:36.921410
Epoch:[ 147 2 ] loss: 0.3564724922180176 2022-08-12 01:14:37.345032
Epoch:[ 147 3 ] loss: 0.35595083236694336 2022-08-12 01:14:37.769585
Epoch:[ 147 4 ] loss: 0.35640016198158264 2022-08-12 01:14:38.195810
Epoch:[ 147 5 ] loss: 0.35802164673805237 2022-08-12 01:14:38.617614
Epoch:[ 147 6 ] loss: 0.35685163736343384 2022-08-12 01:14:39.036193
Epoch:[ 147 7 ] loss: 0.3572467863559723 2022-08-12 01:14:39.455924
Epoch:[ 147 8 ] loss: 0.3555293381214142 2022-08-12 01:14:39.886493
Epoch:[ 147 9 ] loss: 0.3578454554080963 2022-08-12 01:14:40.305867
Epoch:[ 147 10 ] loss: 0.35658004879951477 2022-08-12 01:14:40.725535
Epoch:[ 147 11 ] loss: 0.3566087484359741 2022-08-12 01:14:41.147507
Epoch:[ 147 12 ] loss: 0.3573787808418274 2022-08-12 01:14:41.574187
Epoch:[ 147 13 ] loss: 0.3565811216831207 2022-08-12 01:14:41.999737
Epoch:[ 147 14 ] loss: 0.35696473717689514 2022-08-12 01:14:42.413946
Epoch:[ 147 15 ] loss: 0.35735952854156494 2022-08-12 01:14:42.837238
Epoch:[ 147 16 ] loss: 0.3576495051383972 2022-08-12 01:14:48.210867
Epoch:[ 147 17 ] loss: 0.35749512910842896 2022-08-12 01:14:48.629687
Epoch:[ 147 18 ] loss: 0.3560010492801666 2022-08-12 01:14:49.060460
Epoch:[ 147 19 ] loss: 0.3567472994327545 2022-08-12 01:14:49.490511
Training_Epoch:[ 147 ] Training_loss: 0.3568295955657959 2022-08-12 01:14:49.491254
learning rate:  0.00041107867812353725
val: 1 0.3976851999759674
val: 2 0.39657196402549744
val: 3 0.4057019352912903
val: 4 0.39417415857315063
val: 5 0.4001648724079132
val: 6 0.4027017056941986
val: 7 0.398756206035614
val: 8 0.4114168882369995
val: 9 0.4012211561203003
val: 10 0.39919131994247437
val: 11 0.40045157074928284
val: 12 0.40158209204673767
val: 13 0.39749008417129517
val: 14 0.4058396518230438
val: 15 0.4001602828502655
val: 16 0.39847713708877563
val: 17 0.4049684405326843
val: 18 0.40297913551330566
val: 19 0.39540231227874756
val: 20 0.4080425798892975
val_Epoch:[ 147 ] val_loss: 0.4011489346623421 2022-08-12 01:14:53.076452
start training 2022-08-12 01:14:53.179180
Epoch:[ 148 0 ] loss: 0.356057345867157 2022-08-12 01:15:07.724608
Epoch:[ 148 1 ] loss: 0.3571148216724396 2022-08-12 01:15:08.167558
Epoch:[ 148 2 ] loss: 0.35565972328186035 2022-08-12 01:15:08.591131
Epoch:[ 148 3 ] loss: 0.356599897146225 2022-08-12 01:15:09.010800
Epoch:[ 148 4 ] loss: 0.35696494579315186 2022-08-12 01:15:09.424950
Epoch:[ 148 5 ] loss: 0.35612475872039795 2022-08-12 01:15:09.850956
Epoch:[ 148 6 ] loss: 0.3563539683818817 2022-08-12 01:15:10.283360
Epoch:[ 148 7 ] loss: 0.3563779294490814 2022-08-12 01:15:10.706131
Epoch:[ 148 8 ] loss: 0.35725346207618713 2022-08-12 01:15:11.127732
Epoch:[ 148 9 ] loss: 0.35743871331214905 2022-08-12 01:15:11.551434
Epoch:[ 148 10 ] loss: 0.35818514227867126 2022-08-12 01:15:11.970372
Epoch:[ 148 11 ] loss: 0.35838204622268677 2022-08-12 01:15:12.392489
Epoch:[ 148 12 ] loss: 0.3559161126613617 2022-08-12 01:15:12.818500
Epoch:[ 148 13 ] loss: 0.3576962649822235 2022-08-12 01:15:13.244097
Epoch:[ 148 14 ] loss: 0.3570585250854492 2022-08-12 01:15:13.662695
Epoch:[ 148 15 ] loss: 0.35606077313423157 2022-08-12 01:15:14.077870
Epoch:[ 148 16 ] loss: 0.35672909021377563 2022-08-12 01:15:19.463595
Epoch:[ 148 17 ] loss: 0.3561752140522003 2022-08-12 01:15:19.885745
Epoch:[ 148 18 ] loss: 0.35907381772994995 2022-08-12 01:15:20.305771
Epoch:[ 148 19 ] loss: 0.3563465476036072 2022-08-12 01:15:20.720390
Training_Epoch:[ 148 ] Training_loss: 0.3568784549832344 2022-08-12 01:15:20.721129
learning rate:  0.00041107867812353725
val: 1 0.40557679533958435
val: 2 0.39768359065055847
val: 3 0.39776885509490967
val: 4 0.40269970893859863
val: 5 0.41257962584495544
val: 6 0.40813925862312317
val: 7 0.4052814543247223
val: 8 0.39787039160728455
val: 9 0.39685118198394775
val: 10 0.4018573760986328
val: 11 0.39751529693603516
val: 12 0.39690282940864563
val: 13 0.40269458293914795
val: 14 0.39538267254829407
val: 15 0.39804601669311523
val: 16 0.40032950043678284
val: 17 0.4017293453216553
val: 18 0.40804582834243774
val: 19 0.4024590253829956
val: 20 0.39582327008247375
val_Epoch:[ 148 ] val_loss: 0.40126183032989504 2022-08-12 01:15:24.260661
start training 2022-08-12 01:15:24.357800
Epoch:[ 149 0 ] loss: 0.3557705581188202 2022-08-12 01:15:38.383581
Epoch:[ 149 1 ] loss: 0.3567849397659302 2022-08-12 01:15:38.949287
Epoch:[ 149 2 ] loss: 0.35718899965286255 2022-08-12 01:15:39.373379
Epoch:[ 149 3 ] loss: 0.3578626215457916 2022-08-12 01:15:39.789728
Epoch:[ 149 4 ] loss: 0.3580256402492523 2022-08-12 01:15:40.202993
Epoch:[ 149 5 ] loss: 0.3579297661781311 2022-08-12 01:15:40.624278
Epoch:[ 149 6 ] loss: 0.35733217000961304 2022-08-12 01:15:41.055152
Epoch:[ 149 7 ] loss: 0.35558611154556274 2022-08-12 01:15:41.471056
Epoch:[ 149 8 ] loss: 0.35688796639442444 2022-08-12 01:15:41.894277
Epoch:[ 149 9 ] loss: 0.3574325740337372 2022-08-12 01:15:42.316583
Epoch:[ 149 10 ] loss: 0.3571596145629883 2022-08-12 01:15:42.744285
Epoch:[ 149 11 ] loss: 0.3581346571445465 2022-08-12 01:15:43.164863
Epoch:[ 149 12 ] loss: 0.3573257029056549 2022-08-12 01:15:43.586489
Epoch:[ 149 13 ] loss: 0.3581688702106476 2022-08-12 01:15:44.012729
Epoch:[ 149 14 ] loss: 0.3578207492828369 2022-08-12 01:15:44.430317
Epoch:[ 149 15 ] loss: 0.3572927713394165 2022-08-12 01:15:44.855695
Epoch:[ 149 16 ] loss: 0.35759449005126953 2022-08-12 01:15:50.391393
Epoch:[ 149 17 ] loss: 0.35781198740005493 2022-08-12 01:15:50.827019
Epoch:[ 149 18 ] loss: 0.35594865679740906 2022-08-12 01:15:51.248060
Epoch:[ 149 19 ] loss: 0.35640618205070496 2022-08-12 01:15:51.673453
Training_Epoch:[ 149 ] Training_loss: 0.35722325146198275 2022-08-12 01:15:51.674127
learning rate:  0.00041107867812353725
val: 1 0.39730197191238403
val: 2 0.39397546648979187
val: 3 0.40144115686416626
val: 4 0.3909435570240021
val: 5 0.4061894118785858
val: 6 0.39998385310173035
val: 7 0.40766847133636475
val: 8 0.40662461519241333
val: 9 0.391189843416214
val: 10 0.39991846680641174
val: 11 0.4017690122127533
val: 12 0.41492655873298645
val: 13 0.3984392285346985
val: 14 0.39693814516067505
val: 15 0.40141332149505615
val: 16 0.3974899351596832
val: 17 0.39624473452568054
val: 18 0.4058644771575928
val: 19 0.39823082089424133
val: 20 0.39814382791519165
val_Epoch:[ 149 ] val_loss: 0.40023484379053115 2022-08-12 01:15:55.236764
start training 2022-08-12 01:15:55.338052
Epoch:[ 150 0 ] loss: 0.3572714626789093 2022-08-12 01:16:09.631463
Epoch:[ 150 1 ] loss: 0.35730379819869995 2022-08-12 01:16:10.068521
Epoch:[ 150 2 ] loss: 0.3556821644306183 2022-08-12 01:16:10.485137
Epoch:[ 150 3 ] loss: 0.35639098286628723 2022-08-12 01:16:10.910153
Epoch:[ 150 4 ] loss: 0.35611146688461304 2022-08-12 01:16:11.335284
Epoch:[ 150 5 ] loss: 0.35640692710876465 2022-08-12 01:16:11.765653
Epoch:[ 150 6 ] loss: 0.35616597533226013 2022-08-12 01:16:12.185383
Epoch:[ 150 7 ] loss: 0.35623806715011597 2022-08-12 01:16:12.609351
Epoch:[ 150 8 ] loss: 0.3562948703765869 2022-08-12 01:16:13.029446
Epoch:[ 150 9 ] loss: 0.3557191491127014 2022-08-12 01:16:13.454102
Epoch:[ 150 10 ] loss: 0.3561668395996094 2022-08-12 01:16:13.877332
Epoch:[ 150 11 ] loss: 0.3569639027118683 2022-08-12 01:16:14.302513
Epoch:[ 150 12 ] loss: 0.35654664039611816 2022-08-12 01:16:14.721993
Epoch:[ 150 13 ] loss: 0.3556376099586487 2022-08-12 01:16:15.138553
Epoch:[ 150 14 ] loss: 0.3574073612689972 2022-08-12 01:16:15.561369
Epoch:[ 150 15 ] loss: 0.35628542304039 2022-08-12 01:16:15.988423
Epoch:[ 150 16 ] loss: 0.3573189079761505 2022-08-12 01:16:21.471504
Epoch:[ 150 17 ] loss: 0.3571239113807678 2022-08-12 01:16:21.890017
Epoch:[ 150 18 ] loss: 0.3592790961265564 2022-08-12 01:16:22.318240
Epoch:[ 150 19 ] loss: 0.35910314321517944 2022-08-12 01:16:22.741915
Training_Epoch:[ 150 ] Training_loss: 0.35677088499069215 2022-08-12 01:16:22.742664
learning rate:  0.00041107867812353725
netparams have been saved once 150
val: 1 0.4023163318634033
val: 2 0.3959069550037384
val: 3 0.4031987488269806
val: 4 0.39570170640945435
val: 5 0.40290385484695435
val: 6 0.39744922518730164
val: 7 0.4055953323841095
val: 8 0.40856292843818665
val: 9 0.40334469079971313
val: 10 0.4004242718219757
val: 11 0.40954339504241943
val: 12 0.3979710340499878
val: 13 0.4019884765148163
val: 14 0.4048554301261902
val: 15 0.3952677249908447
val: 16 0.4028630554676056
val: 17 0.3989996612071991
val: 18 0.40129533410072327
val: 19 0.3986890912055969
val: 20 0.39957791566848755
val_Epoch:[ 150 ] val_loss: 0.4013227581977844 2022-08-12 01:16:26.370333
start training 2022-08-12 01:16:26.473961
Epoch:[ 151 0 ] loss: 0.3578447699546814 2022-08-12 01:16:41.103973
Epoch:[ 151 1 ] loss: 0.35544511675834656 2022-08-12 01:16:41.526229
Epoch:[ 151 2 ] loss: 0.35704949498176575 2022-08-12 01:16:41.952804
Epoch:[ 151 3 ] loss: 0.3571879267692566 2022-08-12 01:16:42.377302
Epoch:[ 151 4 ] loss: 0.3567284345626831 2022-08-12 01:16:42.803553
Epoch:[ 151 5 ] loss: 0.3579912483692169 2022-08-12 01:16:43.220558
Epoch:[ 151 6 ] loss: 0.35635867714881897 2022-08-12 01:16:43.636540
Epoch:[ 151 7 ] loss: 0.3567012846469879 2022-08-12 01:16:44.056036
Epoch:[ 151 8 ] loss: 0.35821205377578735 2022-08-12 01:16:44.482014
Epoch:[ 151 9 ] loss: 0.3560582995414734 2022-08-12 01:16:44.902029
Epoch:[ 151 10 ] loss: 0.35677003860473633 2022-08-12 01:16:45.324163
Epoch:[ 151 11 ] loss: 0.3572583496570587 2022-08-12 01:16:45.745923
Epoch:[ 151 12 ] loss: 0.35644516348838806 2022-08-12 01:16:46.170211
Epoch:[ 151 13 ] loss: 0.3566388785839081 2022-08-12 01:16:46.596001
Epoch:[ 151 14 ] loss: 0.3568737804889679 2022-08-12 01:16:47.015360
Epoch:[ 151 15 ] loss: 0.35722827911376953 2022-08-12 01:16:47.438984
Epoch:[ 151 16 ] loss: 0.35707297921180725 2022-08-12 01:16:52.540445
Epoch:[ 151 17 ] loss: 0.3565654158592224 2022-08-12 01:16:52.965862
Epoch:[ 151 18 ] loss: 0.35687577724456787 2022-08-12 01:16:53.391301
Epoch:[ 151 19 ] loss: 0.35709667205810547 2022-08-12 01:16:53.815515
Training_Epoch:[ 151 ] Training_loss: 0.3569201320409775 2022-08-12 01:16:53.816392
learning rate:  0.00034941687640500663
val: 1 0.3981218934059143
val: 2 0.39852479100227356
val: 3 0.39888373017311096
val: 4 0.4012814462184906
val: 5 0.40226778388023376
val: 6 0.39937877655029297
val: 7 0.39535900950431824
val: 8 0.4031035304069519
val: 9 0.4051804542541504
val: 10 0.402957022190094
val: 11 0.4138505756855011
val: 12 0.3965476155281067
val: 13 0.39997026324272156
val: 14 0.3988465964794159
val: 15 0.39986127614974976
val: 16 0.4044017195701599
val: 17 0.4139750897884369
val: 18 0.3977789878845215
val: 19 0.3937670588493347
val: 20 0.40245360136032104
val_Epoch:[ 151 ] val_loss: 0.401325561106205 2022-08-12 01:16:57.378228
start training 2022-08-12 01:16:57.477622
Epoch:[ 152 0 ] loss: 0.3567919433116913 2022-08-12 01:17:12.295627
Epoch:[ 152 1 ] loss: 0.3563566505908966 2022-08-12 01:17:12.717974
Epoch:[ 152 2 ] loss: 0.35672664642333984 2022-08-12 01:17:13.141315
Epoch:[ 152 3 ] loss: 0.35578832030296326 2022-08-12 01:17:13.571738
Epoch:[ 152 4 ] loss: 0.3563429117202759 2022-08-12 01:17:13.992034
Epoch:[ 152 5 ] loss: 0.35694563388824463 2022-08-12 01:17:14.416731
Epoch:[ 152 6 ] loss: 0.3555169403553009 2022-08-12 01:17:14.840561
Epoch:[ 152 7 ] loss: 0.35703784227371216 2022-08-12 01:17:15.264887
Epoch:[ 152 8 ] loss: 0.35572564601898193 2022-08-12 01:17:15.681224
Epoch:[ 152 9 ] loss: 0.35611650347709656 2022-08-12 01:17:16.097092
Epoch:[ 152 10 ] loss: 0.3558022081851959 2022-08-12 01:17:16.518034
Epoch:[ 152 11 ] loss: 0.35605794191360474 2022-08-12 01:17:16.946410
Epoch:[ 152 12 ] loss: 0.35672804713249207 2022-08-12 01:17:17.367352
Epoch:[ 152 13 ] loss: 0.35559922456741333 2022-08-12 01:17:17.788050
Epoch:[ 152 14 ] loss: 0.356880247592926 2022-08-12 01:17:18.209356
Epoch:[ 152 15 ] loss: 0.35678595304489136 2022-08-12 01:17:18.635370
Epoch:[ 152 16 ] loss: 0.35509034991264343 2022-08-12 01:17:23.992993
Epoch:[ 152 17 ] loss: 0.35585784912109375 2022-08-12 01:17:24.408508
Epoch:[ 152 18 ] loss: 0.3560817539691925 2022-08-12 01:17:24.840934
Epoch:[ 152 19 ] loss: 0.3561888635158539 2022-08-12 01:17:25.267625
Training_Epoch:[ 152 ] Training_loss: 0.3562210738658905 2022-08-12 01:17:25.268344
learning rate:  0.00034941687640500663
val: 1 0.40207213163375854
val: 2 0.4024399220943451
val: 3 0.4018840789794922
val: 4 0.4010310769081116
val: 5 0.39218634366989136
val: 6 0.39878472685813904
val: 7 0.40252357721328735
val: 8 0.4069385528564453
val: 9 0.3981427252292633
val: 10 0.4030708074569702
val: 11 0.40534988045692444
val: 12 0.3933109641075134
val: 13 0.4027491807937622
val: 14 0.40190428495407104
val: 15 0.396781861782074
val: 16 0.40146031975746155
val: 17 0.4111899435520172
val: 18 0.40290567278862
val: 19 0.3969227075576782
val: 20 0.4048103988170624
val_Epoch:[ 152 ] val_loss: 0.40132295787334443 2022-08-12 01:17:28.920845
start training 2022-08-12 01:17:29.020111
Epoch:[ 153 0 ] loss: 0.35579219460487366 2022-08-12 01:17:43.446354
Epoch:[ 153 1 ] loss: 0.35649827122688293 2022-08-12 01:17:43.872133
Epoch:[ 153 2 ] loss: 0.3556681275367737 2022-08-12 01:17:44.287433
Epoch:[ 153 3 ] loss: 0.3566305935382843 2022-08-12 01:17:44.702043
Epoch:[ 153 4 ] loss: 0.3563741445541382 2022-08-12 01:17:45.125915
Epoch:[ 153 5 ] loss: 0.3555072247982025 2022-08-12 01:17:45.555804
Epoch:[ 153 6 ] loss: 0.35670655965805054 2022-08-12 01:17:45.975886
Epoch:[ 153 7 ] loss: 0.35548579692840576 2022-08-12 01:17:46.391919
Epoch:[ 153 8 ] loss: 0.35574451088905334 2022-08-12 01:17:46.818016
Epoch:[ 153 9 ] loss: 0.35542553663253784 2022-08-12 01:17:47.244082
Epoch:[ 153 10 ] loss: 0.354900598526001 2022-08-12 01:17:47.668938
Epoch:[ 153 11 ] loss: 0.3567279875278473 2022-08-12 01:17:48.090515
Epoch:[ 153 12 ] loss: 0.35593709349632263 2022-08-12 01:17:48.516173
Epoch:[ 153 13 ] loss: 0.35573938488960266 2022-08-12 01:17:48.938825
Epoch:[ 153 14 ] loss: 0.3558143973350525 2022-08-12 01:17:49.360941
Epoch:[ 153 15 ] loss: 0.3560910224914551 2022-08-12 01:17:49.786693
Epoch:[ 153 16 ] loss: 0.35488349199295044 2022-08-12 01:17:54.921514
Epoch:[ 153 17 ] loss: 0.35531511902809143 2022-08-12 01:17:55.348341
Epoch:[ 153 18 ] loss: 0.35650864243507385 2022-08-12 01:17:55.772846
Epoch:[ 153 19 ] loss: 0.35698869824409485 2022-08-12 01:17:56.198963
Training_Epoch:[ 153 ] Training_loss: 0.3559369698166847 2022-08-12 01:17:56.199628
learning rate:  0.00034941687640500663
val: 1 0.4010453522205353
val: 2 0.39617684483528137
val: 3 0.3993019759654999
val: 4 0.39966994524002075
val: 5 0.40645501017570496
val: 6 0.3956676721572876
val: 7 0.4015819728374481
val: 8 0.40471699833869934
val: 9 0.4016623795032501
val: 10 0.3981301188468933
val: 11 0.40321090817451477
val: 12 0.4037684500217438
val: 13 0.40631499886512756
val: 14 0.39929768443107605
val: 15 0.3989487588405609
val: 16 0.4031912088394165
val: 17 0.3980086147785187
val: 18 0.39825737476348877
val: 19 0.4001162052154541
val: 20 0.398494690656662
val_Epoch:[ 153 ] val_loss: 0.40070085823535917 2022-08-12 01:17:59.783873
start training 2022-08-12 01:17:59.883822
Epoch:[ 154 0 ] loss: 0.35616692900657654 2022-08-12 01:18:14.804856
Epoch:[ 154 1 ] loss: 0.35658541321754456 2022-08-12 01:18:15.224796
Epoch:[ 154 2 ] loss: 0.3564195930957794 2022-08-12 01:18:15.650434
Epoch:[ 154 3 ] loss: 0.35619667172431946 2022-08-12 01:18:16.071968
Epoch:[ 154 4 ] loss: 0.355640709400177 2022-08-12 01:18:16.494279
Epoch:[ 154 5 ] loss: 0.355943500995636 2022-08-12 01:18:16.910229
Epoch:[ 154 6 ] loss: 0.35564109683036804 2022-08-12 01:18:17.328441
Epoch:[ 154 7 ] loss: 0.35440993309020996 2022-08-12 01:18:17.752656
Epoch:[ 154 8 ] loss: 0.3556785583496094 2022-08-12 01:18:18.174854
Epoch:[ 154 9 ] loss: 0.35750341415405273 2022-08-12 01:18:18.590112
Epoch:[ 154 10 ] loss: 0.35609346628189087 2022-08-12 01:18:19.010769
Epoch:[ 154 11 ] loss: 0.35561513900756836 2022-08-12 01:18:19.436890
Epoch:[ 154 12 ] loss: 0.3571016788482666 2022-08-12 01:18:19.864410
Epoch:[ 154 13 ] loss: 0.3557339012622833 2022-08-12 01:18:20.297246
Epoch:[ 154 14 ] loss: 0.35572901368141174 2022-08-12 01:18:20.724988
Epoch:[ 154 15 ] loss: 0.3562844693660736 2022-08-12 01:18:21.142922
Epoch:[ 154 16 ] loss: 0.3555034399032593 2022-08-12 01:18:26.700290
Epoch:[ 154 17 ] loss: 0.3551918566226959 2022-08-12 01:18:27.120894
Epoch:[ 154 18 ] loss: 0.35441121459007263 2022-08-12 01:18:27.544293
Epoch:[ 154 19 ] loss: 0.35611534118652344 2022-08-12 01:18:27.965929
Training_Epoch:[ 154 ] Training_loss: 0.3558982670307159 2022-08-12 01:18:27.966614
learning rate:  0.00034941687640500663
val: 1 0.4006066620349884
val: 2 0.4045369625091553
val: 3 0.40512120723724365
val: 4 0.39990776777267456
val: 5 0.40231144428253174
val: 6 0.41043660044670105
val: 7 0.40550515055656433
val: 8 0.40356937050819397
val: 9 0.4076298773288727
val: 10 0.40420281887054443
val: 11 0.39490246772766113
val: 12 0.4072900712490082
val: 13 0.4070042669773102
val: 14 0.3999462425708771
val: 15 0.4035555422306061
val: 16 0.4007454514503479
val: 17 0.3936631977558136
val: 18 0.39540159702301025
val: 19 0.4085155129432678
val: 20 0.4022880494594574
val_Epoch:[ 154 ] val_loss: 0.4028570130467415 2022-08-12 01:18:31.610840
start training 2022-08-12 01:18:31.711122
Epoch:[ 155 0 ] loss: 0.3553673028945923 2022-08-12 01:18:46.351249
Epoch:[ 155 1 ] loss: 0.3554997444152832 2022-08-12 01:18:46.771092
Epoch:[ 155 2 ] loss: 0.35480111837387085 2022-08-12 01:18:47.191391
Epoch:[ 155 3 ] loss: 0.35574692487716675 2022-08-12 01:18:47.612972
Epoch:[ 155 4 ] loss: 0.35523661971092224 2022-08-12 01:18:48.038327
Epoch:[ 155 5 ] loss: 0.355962872505188 2022-08-12 01:18:48.463707
Epoch:[ 155 6 ] loss: 0.3547876179218292 2022-08-12 01:18:48.886549
Epoch:[ 155 7 ] loss: 0.3557586371898651 2022-08-12 01:18:49.311331
Epoch:[ 155 8 ] loss: 0.3550637662410736 2022-08-12 01:18:49.736379
Epoch:[ 155 9 ] loss: 0.35583674907684326 2022-08-12 01:18:50.156853
Epoch:[ 155 10 ] loss: 0.35566484928131104 2022-08-12 01:18:50.584373
Epoch:[ 155 11 ] loss: 0.3556290566921234 2022-08-12 01:18:51.009020
Epoch:[ 155 12 ] loss: 0.3556191027164459 2022-08-12 01:18:51.430972
Epoch:[ 155 13 ] loss: 0.35562407970428467 2022-08-12 01:18:51.848072
Epoch:[ 155 14 ] loss: 0.3559364676475525 2022-08-12 01:18:52.273584
Epoch:[ 155 15 ] loss: 0.3554166555404663 2022-08-12 01:18:52.698819
Epoch:[ 155 16 ] loss: 0.3554803133010864 2022-08-12 01:18:58.058334
Epoch:[ 155 17 ] loss: 0.3549318015575409 2022-08-12 01:18:58.474716
Epoch:[ 155 18 ] loss: 0.3567819893360138 2022-08-12 01:18:58.895481
Epoch:[ 155 19 ] loss: 0.35550907254219055 2022-08-12 01:18:59.325990
Training_Epoch:[ 155 ] Training_loss: 0.3555327370762825 2022-08-12 01:18:59.326726
learning rate:  0.00034941687640500663
val: 1 0.40112191438674927
val: 2 0.4005243480205536
val: 3 0.40257754921913147
val: 4 0.4040570557117462
val: 5 0.40372568368911743
val: 6 0.4009799361228943
val: 7 0.4030308425426483
val: 8 0.40761664509773254
val: 9 0.3973335921764374
val: 10 0.40792250633239746
val: 11 0.3973453938961029
val: 12 0.3996630609035492
val: 13 0.39917653799057007
val: 14 0.4005957841873169
val: 15 0.40284377336502075
val: 16 0.39768511056900024
val: 17 0.4078408479690552
val: 18 0.3967415392398834
val: 19 0.40481746196746826
val: 20 0.40421047806739807
val_Epoch:[ 155 ] val_loss: 0.40199050307273865 2022-08-12 01:19:02.887789
start training 2022-08-12 01:19:02.992085
Epoch:[ 156 0 ] loss: 0.35505208373069763 2022-08-12 01:19:17.689906
Epoch:[ 156 1 ] loss: 0.3539469540119171 2022-08-12 01:19:18.102510
Epoch:[ 156 2 ] loss: 0.3545202612876892 2022-08-12 01:19:18.527181
Epoch:[ 156 3 ] loss: 0.3560950458049774 2022-08-12 01:19:18.957487
Epoch:[ 156 4 ] loss: 0.35496601462364197 2022-08-12 01:19:19.373230
Epoch:[ 156 5 ] loss: 0.3540160357952118 2022-08-12 01:19:19.795127
Epoch:[ 156 6 ] loss: 0.3558516502380371 2022-08-12 01:19:20.219213
Epoch:[ 156 7 ] loss: 0.35620778799057007 2022-08-12 01:19:20.644690
Epoch:[ 156 8 ] loss: 0.3567467927932739 2022-08-12 01:19:21.064795
Epoch:[ 156 9 ] loss: 0.3560035824775696 2022-08-12 01:19:21.488422
Epoch:[ 156 10 ] loss: 0.35679617524147034 2022-08-12 01:19:21.917105
Epoch:[ 156 11 ] loss: 0.35574647784233093 2022-08-12 01:19:22.331591
Epoch:[ 156 12 ] loss: 0.357188880443573 2022-08-12 01:19:22.756624
Epoch:[ 156 13 ] loss: 0.35560938715934753 2022-08-12 01:19:23.184796
Epoch:[ 156 14 ] loss: 0.35723963379859924 2022-08-12 01:19:23.609740
Epoch:[ 156 15 ] loss: 0.3558597266674042 2022-08-12 01:19:24.030331
Epoch:[ 156 16 ] loss: 0.3560665249824524 2022-08-12 01:19:29.262591
Epoch:[ 156 17 ] loss: 0.3565823435783386 2022-08-12 01:19:29.681729
Epoch:[ 156 18 ] loss: 0.3567652106285095 2022-08-12 01:19:30.107637
Epoch:[ 156 19 ] loss: 0.35573136806488037 2022-08-12 01:19:30.527856
Training_Epoch:[ 156 ] Training_loss: 0.3558495968580246 2022-08-12 01:19:30.528505
learning rate:  0.00034941687640500663
val: 1 0.4010832607746124
val: 2 0.40208446979522705
val: 3 0.4085155427455902
val: 4 0.40473631024360657
val: 5 0.3962087333202362
val: 6 0.3955172598361969
val: 7 0.40471720695495605
val: 8 0.4058276116847992
val: 9 0.4037526249885559
val: 10 0.4063780903816223
val: 11 0.40482214093208313
val: 12 0.4040892422199249
val: 13 0.40319931507110596
val: 14 0.4023400545120239
val: 15 0.40279167890548706
val: 16 0.39980441331863403
val: 17 0.398406058549881
val: 18 0.4026862680912018
val: 19 0.4020267426967621
val: 20 0.3991917371749878
val_Epoch:[ 156 ] val_loss: 0.4024089381098747 2022-08-12 01:19:34.143609
start training 2022-08-12 01:19:34.244503
Epoch:[ 157 0 ] loss: 0.3578048050403595 2022-08-12 01:19:47.926978
Epoch:[ 157 1 ] loss: 0.3554655909538269 2022-08-12 01:19:48.887585
Epoch:[ 157 2 ] loss: 0.35518568754196167 2022-08-12 01:19:49.312984
Epoch:[ 157 3 ] loss: 0.35538098216056824 2022-08-12 01:19:49.730831
Epoch:[ 157 4 ] loss: 0.3567887246608734 2022-08-12 01:19:50.148725
Epoch:[ 157 5 ] loss: 0.3564313054084778 2022-08-12 01:19:50.568900
Epoch:[ 157 6 ] loss: 0.35542842745780945 2022-08-12 01:19:50.993367
Epoch:[ 157 7 ] loss: 0.3565814197063446 2022-08-12 01:19:51.415052
Epoch:[ 157 8 ] loss: 0.35502293705940247 2022-08-12 01:19:51.834292
Epoch:[ 157 9 ] loss: 0.35466429591178894 2022-08-12 01:19:52.257186
Epoch:[ 157 10 ] loss: 0.3549340069293976 2022-08-12 01:19:52.683358
Epoch:[ 157 11 ] loss: 0.35701054334640503 2022-08-12 01:19:53.105852
Epoch:[ 157 12 ] loss: 0.35487160086631775 2022-08-12 01:19:53.526290
Epoch:[ 157 13 ] loss: 0.35665658116340637 2022-08-12 01:19:53.949192
Epoch:[ 157 14 ] loss: 0.356569766998291 2022-08-12 01:19:54.373575
Epoch:[ 157 15 ] loss: 0.3554058074951172 2022-08-12 01:19:54.795912
Epoch:[ 157 16 ] loss: 0.3552829325199127 2022-08-12 01:20:00.398293
Epoch:[ 157 17 ] loss: 0.3560798466205597 2022-08-12 01:20:00.819876
Epoch:[ 157 18 ] loss: 0.3554191589355469 2022-08-12 01:20:01.245246
Epoch:[ 157 19 ] loss: 0.35555118322372437 2022-08-12 01:20:01.668662
Training_Epoch:[ 157 ] Training_loss: 0.3558267802000046 2022-08-12 01:20:01.669378
learning rate:  0.00034941687640500663
val: 1 0.3953544795513153
val: 2 0.4004703462123871
val: 3 0.40177860856056213
val: 4 0.41080161929130554
val: 5 0.4029470384120941
val: 6 0.3979455232620239
val: 7 0.39857473969459534
val: 8 0.4038863778114319
val: 9 0.40284159779548645
val: 10 0.40934327244758606
val: 11 0.3985898196697235
val: 12 0.4031113088130951
val: 13 0.4059712290763855
val: 14 0.4059487581253052
val: 15 0.4044419229030609
val: 16 0.40058842301368713
val: 17 0.398516446352005
val: 18 0.3998218774795532
val: 19 0.39876312017440796
val: 20 0.40679627656936646
val_Epoch:[ 157 ] val_loss: 0.4023246392607689 2022-08-12 01:20:05.337775
start training 2022-08-12 01:20:05.441536
Epoch:[ 158 0 ] loss: 0.354572594165802 2022-08-12 01:20:20.305455
Epoch:[ 158 1 ] loss: 0.3551374673843384 2022-08-12 01:20:20.727332
Epoch:[ 158 2 ] loss: 0.3547345697879791 2022-08-12 01:20:21.160759
Epoch:[ 158 3 ] loss: 0.35596442222595215 2022-08-12 01:20:21.587249
Epoch:[ 158 4 ] loss: 0.3558114171028137 2022-08-12 01:20:22.008473
Epoch:[ 158 5 ] loss: 0.3555464446544647 2022-08-12 01:20:22.430730
Epoch:[ 158 6 ] loss: 0.3561593294143677 2022-08-12 01:20:22.854421
Epoch:[ 158 7 ] loss: 0.35567641258239746 2022-08-12 01:20:23.274975
Epoch:[ 158 8 ] loss: 0.35482290387153625 2022-08-12 01:20:23.702361
Epoch:[ 158 9 ] loss: 0.35548239946365356 2022-08-12 01:20:24.128056
Epoch:[ 158 10 ] loss: 0.3564153015613556 2022-08-12 01:20:24.550149
Epoch:[ 158 11 ] loss: 0.35573628544807434 2022-08-12 01:20:24.964466
Epoch:[ 158 12 ] loss: 0.35478463768959045 2022-08-12 01:20:25.382342
Epoch:[ 158 13 ] loss: 0.3572927415370941 2022-08-12 01:20:25.806032
Epoch:[ 158 14 ] loss: 0.3553832769393921 2022-08-12 01:20:26.227663
Epoch:[ 158 15 ] loss: 0.3562281131744385 2022-08-12 01:20:26.646012
Epoch:[ 158 16 ] loss: 0.35719215869903564 2022-08-12 01:20:31.807106
Epoch:[ 158 17 ] loss: 0.3563104569911957 2022-08-12 01:20:32.230834
Epoch:[ 158 18 ] loss: 0.35652461647987366 2022-08-12 01:20:32.656448
Epoch:[ 158 19 ] loss: 0.3556591272354126 2022-08-12 01:20:33.075079
Training_Epoch:[ 158 ] Training_loss: 0.35577173382043836 2022-08-12 01:20:33.075750
learning rate:  0.00034941687640500663
val: 1 0.4030691385269165
val: 2 0.3982570469379425
val: 3 0.3997010588645935
val: 4 0.3999214470386505
val: 5 0.3951302170753479
val: 6 0.4017345905303955
val: 7 0.4037443697452545
val: 8 0.40414267778396606
val: 9 0.3910171687602997
val: 10 0.40161266922950745
val: 11 0.39672955870628357
val: 12 0.40346500277519226
val: 13 0.41025662422180176
val: 14 0.3966968357563019
val: 15 0.3967624008655548
val: 16 0.4040599465370178
val: 17 0.40234294533729553
val: 18 0.40587273240089417
val: 19 0.400113046169281
val: 20 0.3998584449291229
val_Epoch:[ 158 ] val_loss: 0.400724396109581 2022-08-12 01:20:36.636457
start training 2022-08-12 01:20:36.739386
Epoch:[ 159 0 ] loss: 0.3553158640861511 2022-08-12 01:20:50.890649
Epoch:[ 159 1 ] loss: 0.355284720659256 2022-08-12 01:20:51.319422
Epoch:[ 159 2 ] loss: 0.3546311557292938 2022-08-12 01:20:51.745896
Epoch:[ 159 3 ] loss: 0.3542138636112213 2022-08-12 01:20:52.173048
Epoch:[ 159 4 ] loss: 0.35529056191444397 2022-08-12 01:20:52.593394
Epoch:[ 159 5 ] loss: 0.3553612232208252 2022-08-12 01:20:53.015947
Epoch:[ 159 6 ] loss: 0.3549335300922394 2022-08-12 01:20:53.440786
Epoch:[ 159 7 ] loss: 0.3561458885669708 2022-08-12 01:20:53.867944
Epoch:[ 159 8 ] loss: 0.3561367690563202 2022-08-12 01:20:54.288473
Epoch:[ 159 9 ] loss: 0.35614627599716187 2022-08-12 01:20:54.713387
Epoch:[ 159 10 ] loss: 0.3557734191417694 2022-08-12 01:20:55.140831
Epoch:[ 159 11 ] loss: 0.35444536805152893 2022-08-12 01:20:55.568312
Epoch:[ 159 12 ] loss: 0.35556426644325256 2022-08-12 01:20:55.992569
Epoch:[ 159 13 ] loss: 0.3573245704174042 2022-08-12 01:20:56.414310
Epoch:[ 159 14 ] loss: 0.3542870283126831 2022-08-12 01:20:56.840307
Epoch:[ 159 15 ] loss: 0.35651278495788574 2022-08-12 01:20:57.264546
Epoch:[ 159 16 ] loss: 0.3555092513561249 2022-08-12 01:21:02.590364
Epoch:[ 159 17 ] loss: 0.35702580213546753 2022-08-12 01:21:03.065426
Epoch:[ 159 18 ] loss: 0.35624825954437256 2022-08-12 01:21:03.489398
Epoch:[ 159 19 ] loss: 0.3558330833911896 2022-08-12 01:21:03.905527
Training_Epoch:[ 159 ] Training_loss: 0.3555991843342781 2022-08-12 01:21:03.906201
learning rate:  0.00034941687640500663
val: 1 0.40404438972473145
val: 2 0.4021885395050049
val: 3 0.3988700211048126
val: 4 0.39623191952705383
val: 5 0.39449232816696167
val: 6 0.40328261256217957
val: 7 0.4012598693370819
val: 8 0.4011070728302002
val: 9 0.4001231789588928
val: 10 0.3974652588367462
val: 11 0.40094998478889465
val: 12 0.40505868196487427
val: 13 0.4070846736431122
val: 14 0.410042941570282
val: 15 0.4167669713497162
val: 16 0.39914265275001526
val: 17 0.3975127637386322
val: 18 0.3996652364730835
val: 19 0.39575013518333435
val: 20 0.4059908092021942
val_Epoch:[ 159 ] val_loss: 0.4018515020608902 2022-08-12 01:21:07.466401
start training 2022-08-12 01:21:07.567670
Epoch:[ 160 0 ] loss: 0.3553188741207123 2022-08-12 01:21:21.731423
Epoch:[ 160 1 ] loss: 0.35489919781684875 2022-08-12 01:21:22.369234
Epoch:[ 160 2 ] loss: 0.3548949956893921 2022-08-12 01:21:22.787866
Epoch:[ 160 3 ] loss: 0.3550962507724762 2022-08-12 01:21:23.211856
Epoch:[ 160 4 ] loss: 0.35686954855918884 2022-08-12 01:21:23.636717
Epoch:[ 160 5 ] loss: 0.3546057343482971 2022-08-12 01:21:24.060925
Epoch:[ 160 6 ] loss: 0.3552166819572449 2022-08-12 01:21:24.485732
Epoch:[ 160 7 ] loss: 0.35534244775772095 2022-08-12 01:21:24.904179
Epoch:[ 160 8 ] loss: 0.3555355370044708 2022-08-12 01:21:25.329692
Epoch:[ 160 9 ] loss: 0.3551000654697418 2022-08-12 01:21:25.746420
Epoch:[ 160 10 ] loss: 0.35584935545921326 2022-08-12 01:21:26.161574
Epoch:[ 160 11 ] loss: 0.3545633852481842 2022-08-12 01:21:26.589656
Epoch:[ 160 12 ] loss: 0.35635969042778015 2022-08-12 01:21:27.017650
Epoch:[ 160 13 ] loss: 0.35596293210983276 2022-08-12 01:21:27.443345
Epoch:[ 160 14 ] loss: 0.3553922176361084 2022-08-12 01:21:27.856949
Epoch:[ 160 15 ] loss: 0.35688573122024536 2022-08-12 01:21:28.278524
Epoch:[ 160 16 ] loss: 0.35671332478523254 2022-08-12 01:21:33.654161
Epoch:[ 160 17 ] loss: 0.3554787039756775 2022-08-12 01:21:34.074563
Epoch:[ 160 18 ] loss: 0.3569217622280121 2022-08-12 01:21:34.493480
Epoch:[ 160 19 ] loss: 0.3564460277557373 2022-08-12 01:21:34.918129
Training_Epoch:[ 160 ] Training_loss: 0.35567262321710585 2022-08-12 01:21:34.918849
learning rate:  0.00034941687640500663
netparams have been saved once 160
val: 1 0.4008217751979828
val: 2 0.39476388692855835
val: 3 0.4038984775543213
val: 4 0.40136033296585083
val: 5 0.3969964385032654
val: 6 0.40165722370147705
val: 7 0.40161436796188354
val: 8 0.4012100100517273
val: 9 0.3984008729457855
val: 10 0.4034270644187927
val: 11 0.4049939215183258
val: 12 0.4015769064426422
val: 13 0.4034070074558258
val: 14 0.3984493613243103
val: 15 0.4067423939704895
val: 16 0.40241003036499023
val: 17 0.40879520773887634
val: 18 0.40147069096565247
val: 19 0.40156394243240356
val: 20 0.4076302647590637
val_Epoch:[ 160 ] val_loss: 0.4020595088601112 2022-08-12 01:21:38.493458
start training 2022-08-12 01:21:38.594351
Epoch:[ 161 0 ] loss: 0.3556786775588989 2022-08-12 01:21:52.841164
Epoch:[ 161 1 ] loss: 0.3557771146297455 2022-08-12 01:21:53.275494
Epoch:[ 161 2 ] loss: 0.3557133674621582 2022-08-12 01:21:53.697337
Epoch:[ 161 3 ] loss: 0.35542798042297363 2022-08-12 01:21:54.117867
Epoch:[ 161 4 ] loss: 0.3552438020706177 2022-08-12 01:21:54.544178
Epoch:[ 161 5 ] loss: 0.3554593324661255 2022-08-12 01:21:54.972340
Epoch:[ 161 6 ] loss: 0.35533973574638367 2022-08-12 01:21:55.393287
Epoch:[ 161 7 ] loss: 0.35633915662765503 2022-08-12 01:21:55.820048
Epoch:[ 161 8 ] loss: 0.3550088107585907 2022-08-12 01:21:56.241366
Epoch:[ 161 9 ] loss: 0.35552525520324707 2022-08-12 01:21:56.665951
Epoch:[ 161 10 ] loss: 0.3548104763031006 2022-08-12 01:21:57.087577
Epoch:[ 161 11 ] loss: 0.35442984104156494 2022-08-12 01:21:57.512552
Epoch:[ 161 12 ] loss: 0.3548941910266876 2022-08-12 01:21:57.941866
Epoch:[ 161 13 ] loss: 0.35565584897994995 2022-08-12 01:21:58.363449
Epoch:[ 161 14 ] loss: 0.3543650805950165 2022-08-12 01:21:58.778102
Epoch:[ 161 15 ] loss: 0.35415637493133545 2022-08-12 01:21:59.202286
Epoch:[ 161 16 ] loss: 0.3549391031265259 2022-08-12 01:22:04.902673
Epoch:[ 161 17 ] loss: 0.35466939210891724 2022-08-12 01:22:05.318615
Epoch:[ 161 18 ] loss: 0.3561467230319977 2022-08-12 01:22:05.745199
Epoch:[ 161 19 ] loss: 0.3557390868663788 2022-08-12 01:22:06.170413
Training_Epoch:[ 161 ] Training_loss: 0.3552659675478935 2022-08-12 01:22:06.171216
learning rate:  0.00029700434494425563
val: 1 0.3987327516078949
val: 2 0.40721383690834045
val: 3 0.4079795181751251
val: 4 0.4050356447696686
val: 5 0.4024237096309662
val: 6 0.402322918176651
val: 7 0.4005450904369354
val: 8 0.4025628864765167
val: 9 0.39859461784362793
val: 10 0.40063488483428955
val: 11 0.40505251288414
val: 12 0.4013063609600067
val: 13 0.3982776403427124
val: 14 0.4042920470237732
val: 15 0.40536195039749146
val: 16 0.40305468440055847
val: 17 0.4055040776729584
val: 18 0.403792142868042
val: 19 0.4016883075237274
val: 20 0.40893593430519104
val_Epoch:[ 161 ] val_loss: 0.40316557586193086 2022-08-12 01:22:09.805447
start training 2022-08-12 01:22:09.910085
Epoch:[ 162 0 ] loss: 0.35374265909194946 2022-08-12 01:22:24.121293
Epoch:[ 162 1 ] loss: 0.35508251190185547 2022-08-12 01:22:24.563343
Epoch:[ 162 2 ] loss: 0.35367411375045776 2022-08-12 01:22:24.979689
Epoch:[ 162 3 ] loss: 0.35414934158325195 2022-08-12 01:22:25.404944
Epoch:[ 162 4 ] loss: 0.35402530431747437 2022-08-12 01:22:25.829675
Epoch:[ 162 5 ] loss: 0.3547648787498474 2022-08-12 01:22:26.254464
Epoch:[ 162 6 ] loss: 0.35523512959480286 2022-08-12 01:22:26.674538
Epoch:[ 162 7 ] loss: 0.3547333776950836 2022-08-12 01:22:27.091999
Epoch:[ 162 8 ] loss: 0.35353076457977295 2022-08-12 01:22:27.513353
Epoch:[ 162 9 ] loss: 0.35448211431503296 2022-08-12 01:22:27.938052
Epoch:[ 162 10 ] loss: 0.35384267568588257 2022-08-12 01:22:28.368754
Epoch:[ 162 11 ] loss: 0.3558999001979828 2022-08-12 01:22:28.786280
Epoch:[ 162 12 ] loss: 0.35419121384620667 2022-08-12 01:22:29.210916
Epoch:[ 162 13 ] loss: 0.35571059584617615 2022-08-12 01:22:29.640026
Epoch:[ 162 14 ] loss: 0.3544073700904846 2022-08-12 01:22:30.066122
Epoch:[ 162 15 ] loss: 0.3547968566417694 2022-08-12 01:22:30.488991
Epoch:[ 162 16 ] loss: 0.35482969880104065 2022-08-12 01:22:36.004193
Epoch:[ 162 17 ] loss: 0.3546127378940582 2022-08-12 01:22:36.429956
Epoch:[ 162 18 ] loss: 0.35516318678855896 2022-08-12 01:22:36.849242
Epoch:[ 162 19 ] loss: 0.3546012341976166 2022-08-12 01:22:37.273669
Training_Epoch:[ 162 ] Training_loss: 0.3545737832784653 2022-08-12 01:22:37.274428
learning rate:  0.00029700434494425563
val: 1 0.4027418792247772
val: 2 0.4030512571334839
val: 3 0.4125298857688904
val: 4 0.4030662775039673
val: 5 0.39571136236190796
val: 6 0.405161052942276
val: 7 0.4007816016674042
val: 8 0.40076759457588196
val: 9 0.4015600383281708
val: 10 0.4016868472099304
val: 11 0.4032781720161438
val: 12 0.3911038041114807
val: 13 0.3987790048122406
val: 14 0.39982694387435913
val: 15 0.40140074491500854
val: 16 0.4107283055782318
val: 17 0.40160518884658813
val: 18 0.41239434480667114
val: 19 0.40286484360694885
val: 20 0.398807168006897
val_Epoch:[ 162 ] val_loss: 0.402392315864563 2022-08-12 01:22:40.858599
start training 2022-08-12 01:22:40.959016
Epoch:[ 163 0 ] loss: 0.3548007905483246 2022-08-12 01:22:55.318184
Epoch:[ 163 1 ] loss: 0.3539177477359772 2022-08-12 01:22:55.765678
Epoch:[ 163 2 ] loss: 0.35376614332199097 2022-08-12 01:22:56.188249
Epoch:[ 163 3 ] loss: 0.35424211621284485 2022-08-12 01:22:56.608081
Epoch:[ 163 4 ] loss: 0.354656457901001 2022-08-12 01:22:57.031985
Epoch:[ 163 5 ] loss: 0.3537229299545288 2022-08-12 01:22:57.450983
Epoch:[ 163 6 ] loss: 0.3540506958961487 2022-08-12 01:22:57.875148
Epoch:[ 163 7 ] loss: 0.3545077443122864 2022-08-12 01:22:58.301316
Epoch:[ 163 8 ] loss: 0.35421231389045715 2022-08-12 01:22:58.725351
Epoch:[ 163 9 ] loss: 0.3540683686733246 2022-08-12 01:22:59.143564
Epoch:[ 163 10 ] loss: 0.35352808237075806 2022-08-12 01:22:59.559600
Epoch:[ 163 11 ] loss: 0.3541879653930664 2022-08-12 01:22:59.977666
Epoch:[ 163 12 ] loss: 0.3537682890892029 2022-08-12 01:23:00.404996
Epoch:[ 163 13 ] loss: 0.3540155589580536 2022-08-12 01:23:00.824915
Epoch:[ 163 14 ] loss: 0.3539915680885315 2022-08-12 01:23:01.246598
Epoch:[ 163 15 ] loss: 0.35601556301116943 2022-08-12 01:23:01.671703
Epoch:[ 163 16 ] loss: 0.3539307415485382 2022-08-12 01:23:07.204367
Epoch:[ 163 17 ] loss: 0.3540177047252655 2022-08-12 01:23:07.629141
Epoch:[ 163 18 ] loss: 0.35496875643730164 2022-08-12 01:23:08.056782
Epoch:[ 163 19 ] loss: 0.3535498380661011 2022-08-12 01:23:08.471180
Training_Epoch:[ 163 ] Training_loss: 0.35419596880674364 2022-08-12 01:23:08.471926
learning rate:  0.00029700434494425563
val: 1 0.39490678906440735
val: 2 0.4007118046283722
val: 3 0.4000698924064636
val: 4 0.4080478250980377
val: 5 0.402365505695343
val: 6 0.4027045965194702
val: 7 0.40225735306739807
val: 8 0.40124550461769104
val: 9 0.4043189287185669
val: 10 0.4007161557674408
val: 11 0.4035505950450897
val: 12 0.40465471148490906
val: 13 0.4109320640563965
val: 14 0.39882710576057434
val: 15 0.4090512692928314
val: 16 0.4031302034854889
val: 17 0.40407031774520874
val: 18 0.4030894339084625
val: 19 0.40359577536582947
val: 20 0.3991279602050781
val_Epoch:[ 163 ] val_loss: 0.402868689596653 2022-08-12 01:23:12.012046
start training 2022-08-12 01:23:12.114961
Epoch:[ 164 0 ] loss: 0.35431015491485596 2022-08-12 01:23:26.194237
Epoch:[ 164 1 ] loss: 0.354233056306839 2022-08-12 01:23:27.014886
Epoch:[ 164 2 ] loss: 0.3543877601623535 2022-08-12 01:23:27.436790
Epoch:[ 164 3 ] loss: 0.35412514209747314 2022-08-12 01:23:27.859858
Epoch:[ 164 4 ] loss: 0.3542846143245697 2022-08-12 01:23:28.271410
Epoch:[ 164 5 ] loss: 0.3528534471988678 2022-08-12 01:23:28.694645
Epoch:[ 164 6 ] loss: 0.3534984290599823 2022-08-12 01:23:29.117714
Epoch:[ 164 7 ] loss: 0.3527847230434418 2022-08-12 01:23:29.538421
Epoch:[ 164 8 ] loss: 0.3530161678791046 2022-08-12 01:23:29.955727
Epoch:[ 164 9 ] loss: 0.35401228070259094 2022-08-12 01:23:30.380970
Epoch:[ 164 10 ] loss: 0.3541381359100342 2022-08-12 01:23:30.807861
Epoch:[ 164 11 ] loss: 0.35420486330986023 2022-08-12 01:23:31.233154
Epoch:[ 164 12 ] loss: 0.3538243770599365 2022-08-12 01:23:31.654708
Epoch:[ 164 13 ] loss: 0.353528767824173 2022-08-12 01:23:32.076407
Epoch:[ 164 14 ] loss: 0.3553101420402527 2022-08-12 01:23:32.494878
Epoch:[ 164 15 ] loss: 0.35389798879623413 2022-08-12 01:23:32.920671
Epoch:[ 164 16 ] loss: 0.3542916774749756 2022-08-12 01:23:37.919031
Epoch:[ 164 17 ] loss: 0.35445380210876465 2022-08-12 01:23:38.341487
Epoch:[ 164 18 ] loss: 0.35417667031288147 2022-08-12 01:23:38.762493
Epoch:[ 164 19 ] loss: 0.35650569200515747 2022-08-12 01:23:39.186829
Training_Epoch:[ 164 ] Training_loss: 0.35409189462661744 2022-08-12 01:23:39.187525
learning rate:  0.00029700434494425563
val: 1 0.40520912408828735
val: 2 0.39603742957115173
val: 3 0.4058954417705536
val: 4 0.4048260748386383
val: 5 0.4036656320095062
val: 6 0.401529997587204
val: 7 0.4006154537200928
val: 8 0.39748936891555786
val: 9 0.4026302099227905
val: 10 0.4037921726703644
val: 11 0.39879506826400757
val: 12 0.40627655386924744
val: 13 0.3987703323364258
val: 14 0.3952230215072632
val: 15 0.4038492739200592
val: 16 0.3948245048522949
val: 17 0.40120548009872437
val: 18 0.4027731418609619
val: 19 0.40407639741897583
val: 20 0.40400129556655884
val_Epoch:[ 164 ] val_loss: 0.4015742987394333 2022-08-12 01:23:42.812967
start training 2022-08-12 01:23:42.913348
Epoch:[ 165 0 ] loss: 0.35377922654151917 2022-08-12 01:23:57.628742
Epoch:[ 165 1 ] loss: 0.3539145588874817 2022-08-12 01:23:58.050179
Epoch:[ 165 2 ] loss: 0.3548642098903656 2022-08-12 01:23:58.466156
Epoch:[ 165 3 ] loss: 0.3544548451900482 2022-08-12 01:23:58.892516
Epoch:[ 165 4 ] loss: 0.3534701466560364 2022-08-12 01:23:59.318776
Epoch:[ 165 5 ] loss: 0.35461288690567017 2022-08-12 01:23:59.742424
Epoch:[ 165 6 ] loss: 0.35532355308532715 2022-08-12 01:24:00.162764
Epoch:[ 165 7 ] loss: 0.3531976044178009 2022-08-12 01:24:00.586218
Epoch:[ 165 8 ] loss: 0.3543499708175659 2022-08-12 01:24:01.004692
Epoch:[ 165 9 ] loss: 0.3531543016433716 2022-08-12 01:24:01.429658
Epoch:[ 165 10 ] loss: 0.3535577356815338 2022-08-12 01:24:01.856285
Epoch:[ 165 11 ] loss: 0.3549026548862457 2022-08-12 01:24:02.284626
Epoch:[ 165 12 ] loss: 0.3533819317817688 2022-08-12 01:24:02.702152
Epoch:[ 165 13 ] loss: 0.35399213433265686 2022-08-12 01:24:03.121012
Epoch:[ 165 14 ] loss: 0.3532739579677582 2022-08-12 01:24:03.541143
Epoch:[ 165 15 ] loss: 0.3545922040939331 2022-08-12 01:24:03.967891
Epoch:[ 165 16 ] loss: 0.35447853803634644 2022-08-12 01:24:09.069717
Epoch:[ 165 17 ] loss: 0.3556841313838959 2022-08-12 01:24:09.484827
Epoch:[ 165 18 ] loss: 0.3545236587524414 2022-08-12 01:24:09.904987
Epoch:[ 165 19 ] loss: 0.3543913960456848 2022-08-12 01:24:10.327204
Training_Epoch:[ 165 ] Training_loss: 0.35419498234987257 2022-08-12 01:24:10.327967
learning rate:  0.00029700434494425563
val: 1 0.4056900143623352
val: 2 0.4007675349712372
val: 3 0.4020829200744629
val: 4 0.4018917679786682
val: 5 0.404313862323761
val: 6 0.40326058864593506
val: 7 0.3997824490070343
val: 8 0.4011872112751007
val: 9 0.4062790274620056
val: 10 0.4086088538169861
val: 11 0.40675610303878784
val: 12 0.39977145195007324
val: 13 0.40482375025749207
val: 14 0.40271472930908203
val: 15 0.39915359020233154
val: 16 0.39363622665405273
val: 17 0.4069189727306366
val: 18 0.39990949630737305
val: 19 0.4051436185836792
val: 20 0.4041171669960022
val_Epoch:[ 165 ] val_loss: 0.40284046679735186 2022-08-12 01:24:13.916753
start training 2022-08-12 01:24:14.015432
Epoch:[ 166 0 ] loss: 0.3548499345779419 2022-08-12 01:24:28.171377
Epoch:[ 166 1 ] loss: 0.3530355393886566 2022-08-12 01:24:28.802487
Epoch:[ 166 2 ] loss: 0.35422012209892273 2022-08-12 01:24:29.216795
Epoch:[ 166 3 ] loss: 0.3531394898891449 2022-08-12 01:24:29.640200
Epoch:[ 166 4 ] loss: 0.35372114181518555 2022-08-12 01:24:30.073754
Epoch:[ 166 5 ] loss: 0.35418227314949036 2022-08-12 01:24:30.497179
Epoch:[ 166 6 ] loss: 0.35393431782722473 2022-08-12 01:24:30.913095
Epoch:[ 166 7 ] loss: 0.35419315099716187 2022-08-12 01:24:31.338551
Epoch:[ 166 8 ] loss: 0.35402488708496094 2022-08-12 01:24:31.763851
Epoch:[ 166 9 ] loss: 0.35230445861816406 2022-08-12 01:24:32.187860
Epoch:[ 166 10 ] loss: 0.35388195514678955 2022-08-12 01:24:32.609342
Epoch:[ 166 11 ] loss: 0.3563380241394043 2022-08-12 01:24:33.032478
Epoch:[ 166 12 ] loss: 0.3546120524406433 2022-08-12 01:24:33.455570
Epoch:[ 166 13 ] loss: 0.3549621105194092 2022-08-12 01:24:33.876899
Epoch:[ 166 14 ] loss: 0.3536829948425293 2022-08-12 01:24:34.302416
Epoch:[ 166 15 ] loss: 0.35616251826286316 2022-08-12 01:24:34.726378
Epoch:[ 166 16 ] loss: 0.3532821536064148 2022-08-12 01:24:40.346851
Epoch:[ 166 17 ] loss: 0.35478028655052185 2022-08-12 01:24:40.772274
Epoch:[ 166 18 ] loss: 0.3543994724750519 2022-08-12 01:24:41.204725
Epoch:[ 166 19 ] loss: 0.35392290353775024 2022-08-12 01:24:41.622903
Training_Epoch:[ 166 ] Training_loss: 0.35418148934841154 2022-08-12 01:24:41.623688
learning rate:  0.00029700434494425563
val: 1 0.40314435958862305
val: 2 0.4057202637195587
val: 3 0.3976471424102783
val: 4 0.4013337194919586
val: 5 0.4074917435646057
val: 6 0.40967899560928345
val: 7 0.40264859795570374
val: 8 0.40885740518569946
val: 9 0.4043114185333252
val: 10 0.40900298953056335
val: 11 0.39876648783683777
val: 12 0.407233327627182
val: 13 0.3999793827533722
val: 14 0.39992237091064453
val: 15 0.4036353528499603
val: 16 0.40433478355407715
val: 17 0.39829549193382263
val: 18 0.4107552468776703
val: 19 0.4038461744785309
val: 20 0.4114662706851959
val_Epoch:[ 166 ] val_loss: 0.4044035762548447 2022-08-12 01:24:45.211417
start training 2022-08-12 01:24:45.309777
Epoch:[ 167 0 ] loss: 0.35448387265205383 2022-08-12 01:24:59.838858
Epoch:[ 167 1 ] loss: 0.3540566563606262 2022-08-12 01:25:00.265290
Epoch:[ 167 2 ] loss: 0.35338282585144043 2022-08-12 01:25:00.687263
Epoch:[ 167 3 ] loss: 0.3538808822631836 2022-08-12 01:25:01.109935
Epoch:[ 167 4 ] loss: 0.35349106788635254 2022-08-12 01:25:01.534468
Epoch:[ 167 5 ] loss: 0.3539050221443176 2022-08-12 01:25:01.955338
Epoch:[ 167 6 ] loss: 0.35369887948036194 2022-08-12 01:25:02.378279
Epoch:[ 167 7 ] loss: 0.354196697473526 2022-08-12 01:25:02.803109
Epoch:[ 167 8 ] loss: 0.3540818393230438 2022-08-12 01:25:03.228405
Epoch:[ 167 9 ] loss: 0.35305672883987427 2022-08-12 01:25:03.646991
Epoch:[ 167 10 ] loss: 0.354278564453125 2022-08-12 01:25:04.064587
Epoch:[ 167 11 ] loss: 0.35324034094810486 2022-08-12 01:25:04.485072
Epoch:[ 167 12 ] loss: 0.35371822118759155 2022-08-12 01:25:04.913342
Epoch:[ 167 13 ] loss: 0.3537901043891907 2022-08-12 01:25:05.333784
Epoch:[ 167 14 ] loss: 0.3537748157978058 2022-08-12 01:25:05.755454
Epoch:[ 167 15 ] loss: 0.3546399176120758 2022-08-12 01:25:06.181620
Epoch:[ 167 16 ] loss: 0.3547534942626953 2022-08-12 01:25:11.612636
Epoch:[ 167 17 ] loss: 0.35539865493774414 2022-08-12 01:25:12.441704
Epoch:[ 167 18 ] loss: 0.3550870716571808 2022-08-12 01:25:12.868095
Epoch:[ 167 19 ] loss: 0.3539036810398102 2022-08-12 01:25:13.293537
Training_Epoch:[ 167 ] Training_loss: 0.35404096692800524 2022-08-12 01:25:13.294255
learning rate:  0.00029700434494425563
val: 1 0.4058685898780823
val: 2 0.41301822662353516
val: 3 0.40565571188926697
val: 4 0.3938467800617218
val: 5 0.40230071544647217
val: 6 0.39856576919555664
val: 7 0.4071795344352722
val: 8 0.39629003405570984
val: 9 0.4060991406440735
val: 10 0.4020192623138428
val: 11 0.4070807695388794
val: 12 0.40657106041908264
val: 13 0.40074679255485535
val: 14 0.4008699655532837
val: 15 0.3968120813369751
val: 16 0.40071192383766174
val: 17 0.40060538053512573
val: 18 0.4195882976055145
val: 19 0.3929058313369751
val: 20 0.40520787239074707
val_Epoch:[ 167 ] val_loss: 0.4030971869826317 2022-08-12 01:25:16.853341
start training 2022-08-12 01:25:16.951865
Epoch:[ 168 0 ] loss: 0.3526221513748169 2022-08-12 01:25:31.403387
Epoch:[ 168 1 ] loss: 0.35372719168663025 2022-08-12 01:25:31.817281
Epoch:[ 168 2 ] loss: 0.3547448217868805 2022-08-12 01:25:32.241709
Epoch:[ 168 3 ] loss: 0.3544139564037323 2022-08-12 01:25:32.663224
Epoch:[ 168 4 ] loss: 0.35379335284233093 2022-08-12 01:25:33.088876
Epoch:[ 168 5 ] loss: 0.35412847995758057 2022-08-12 01:25:33.505183
Epoch:[ 168 6 ] loss: 0.3541558086872101 2022-08-12 01:25:33.929980
Epoch:[ 168 7 ] loss: 0.35387447476387024 2022-08-12 01:25:34.350961
Epoch:[ 168 8 ] loss: 0.35396817326545715 2022-08-12 01:25:34.775851
Epoch:[ 168 9 ] loss: 0.35356685519218445 2022-08-12 01:25:35.206333
Epoch:[ 168 10 ] loss: 0.3529737591743469 2022-08-12 01:25:35.628912
Epoch:[ 168 11 ] loss: 0.3534686863422394 2022-08-12 01:25:36.058496
Epoch:[ 168 12 ] loss: 0.3537994921207428 2022-08-12 01:25:36.474379
Epoch:[ 168 13 ] loss: 0.3536464273929596 2022-08-12 01:25:36.894664
Epoch:[ 168 14 ] loss: 0.3543063700199127 2022-08-12 01:25:37.325068
Epoch:[ 168 15 ] loss: 0.3544732630252838 2022-08-12 01:25:37.747680
Epoch:[ 168 16 ] loss: 0.3547249734401703 2022-08-12 01:25:42.992981
Epoch:[ 168 17 ] loss: 0.3535560369491577 2022-08-12 01:25:43.431905
Epoch:[ 168 18 ] loss: 0.3532942831516266 2022-08-12 01:25:43.862860
Epoch:[ 168 19 ] loss: 0.3557030260562897 2022-08-12 01:25:44.281456
Training_Epoch:[ 168 ] Training_loss: 0.3539470791816711 2022-08-12 01:25:44.282212
learning rate:  0.00029700434494425563
val: 1 0.40555694699287415
val: 2 0.4018391966819763
val: 3 0.4032783508300781
val: 4 0.3983060419559479
val: 5 0.4037023186683655
val: 6 0.40203621983528137
val: 7 0.39367610216140747
val: 8 0.40903007984161377
val: 9 0.40927034616470337
val: 10 0.4079856276512146
val: 11 0.40523162484169006
val: 12 0.39882636070251465
val: 13 0.4084571599960327
val: 14 0.40642020106315613
val: 15 0.40010175108909607
val: 16 0.4093681275844574
val: 17 0.3951593339443207
val: 18 0.3986372649669647
val: 19 0.39970967173576355
val: 20 0.40176984667778015
val_Epoch:[ 168 ] val_loss: 0.4029181286692619 2022-08-12 01:25:47.802474
start training 2022-08-12 01:25:47.902972
Epoch:[ 169 0 ] loss: 0.3524240553379059 2022-08-12 01:26:02.506561
Epoch:[ 169 1 ] loss: 0.35351428389549255 2022-08-12 01:26:02.924542
Epoch:[ 169 2 ] loss: 0.3537416160106659 2022-08-12 01:26:03.347205
Epoch:[ 169 3 ] loss: 0.35315263271331787 2022-08-12 01:26:03.772108
Epoch:[ 169 4 ] loss: 0.3544383943080902 2022-08-12 01:26:04.196404
Epoch:[ 169 5 ] loss: 0.35413432121276855 2022-08-12 01:26:04.616913
Epoch:[ 169 6 ] loss: 0.353696346282959 2022-08-12 01:26:05.040298
Epoch:[ 169 7 ] loss: 0.35305535793304443 2022-08-12 01:26:05.460283
Epoch:[ 169 8 ] loss: 0.35430529713630676 2022-08-12 01:26:05.885658
Epoch:[ 169 9 ] loss: 0.35474005341529846 2022-08-12 01:26:06.303823
Epoch:[ 169 10 ] loss: 0.35410794615745544 2022-08-12 01:26:06.725322
Epoch:[ 169 11 ] loss: 0.3537368178367615 2022-08-12 01:26:07.146360
Epoch:[ 169 12 ] loss: 0.35428279638290405 2022-08-12 01:26:07.573748
Epoch:[ 169 13 ] loss: 0.3546125888824463 2022-08-12 01:26:08.001315
Epoch:[ 169 14 ] loss: 0.3543541729450226 2022-08-12 01:26:08.423422
Epoch:[ 169 15 ] loss: 0.3537830412387848 2022-08-12 01:26:08.848094
Epoch:[ 169 16 ] loss: 0.35544463992118835 2022-08-12 01:26:13.989469
Epoch:[ 169 17 ] loss: 0.353971391916275 2022-08-12 01:26:14.414753
Epoch:[ 169 18 ] loss: 0.3547377586364746 2022-08-12 01:26:14.834501
Epoch:[ 169 19 ] loss: 0.35359862446784973 2022-08-12 01:26:15.260098
Training_Epoch:[ 169 ] Training_loss: 0.3539916068315506 2022-08-12 01:26:15.260968
learning rate:  0.00029700434494425563
val: 1 0.4006394147872925
val: 2 0.40858909487724304
val: 3 0.403438538312912
val: 4 0.4032151401042938
val: 5 0.41189777851104736
val: 6 0.4107460081577301
val: 7 0.4013592600822449
val: 8 0.4018782675266266
val: 9 0.3965490460395813
val: 10 0.40814319252967834
val: 11 0.40347820520401
val: 12 0.4011100232601166
val: 13 0.40713322162628174
val: 14 0.403727650642395
val: 15 0.39718466997146606
val: 16 0.40485262870788574
val: 17 0.4054126739501953
val: 18 0.4074347913265228
val: 19 0.40518102049827576
val: 20 0.40559402108192444
val_Epoch:[ 169 ] val_loss: 0.4043782323598862 2022-08-12 01:26:18.836746
start training 2022-08-12 01:26:18.935979
Epoch:[ 170 0 ] loss: 0.3541429936885834 2022-08-12 01:26:33.162068
Epoch:[ 170 1 ] loss: 0.353002667427063 2022-08-12 01:26:33.607163
Epoch:[ 170 2 ] loss: 0.3537949323654175 2022-08-12 01:26:34.033256
Epoch:[ 170 3 ] loss: 0.3526628911495209 2022-08-12 01:26:34.455687
Epoch:[ 170 4 ] loss: 0.35347890853881836 2022-08-12 01:26:34.881198
Epoch:[ 170 5 ] loss: 0.35411402583122253 2022-08-12 01:26:35.302137
Epoch:[ 170 6 ] loss: 0.35360124707221985 2022-08-12 01:26:35.725289
Epoch:[ 170 7 ] loss: 0.3534928262233734 2022-08-12 01:26:36.151861
Epoch:[ 170 8 ] loss: 0.3544098138809204 2022-08-12 01:26:36.576658
Epoch:[ 170 9 ] loss: 0.3532692492008209 2022-08-12 01:26:37.009167
Epoch:[ 170 10 ] loss: 0.3548201620578766 2022-08-12 01:26:37.425333
Epoch:[ 170 11 ] loss: 0.35274460911750793 2022-08-12 01:26:37.845790
Epoch:[ 170 12 ] loss: 0.35357964038848877 2022-08-12 01:26:38.272513
Epoch:[ 170 13 ] loss: 0.3538666367530823 2022-08-12 01:26:38.696249
Epoch:[ 170 14 ] loss: 0.3542764186859131 2022-08-12 01:26:39.116338
Epoch:[ 170 15 ] loss: 0.353556752204895 2022-08-12 01:26:39.535952
Epoch:[ 170 16 ] loss: 0.3534327447414398 2022-08-12 01:26:44.847103
Epoch:[ 170 17 ] loss: 0.3537795841693878 2022-08-12 01:26:45.270682
Epoch:[ 170 18 ] loss: 0.3535572290420532 2022-08-12 01:26:45.695823
Epoch:[ 170 19 ] loss: 0.3536853492259979 2022-08-12 01:26:46.111956
Training_Epoch:[ 170 ] Training_loss: 0.35366343408823014 2022-08-12 01:26:46.112665
learning rate:  0.00029700434494425563
netparams have been saved once 170
val: 1 0.4004257619380951
val: 2 0.41132789850234985
val: 3 0.406870573759079
val: 4 0.39290955662727356
val: 5 0.41102272272109985
val: 6 0.4013027846813202
val: 7 0.40357092022895813
val: 8 0.40213891863822937
val: 9 0.4056774377822876
val: 10 0.40184786915779114
val: 11 0.4059881567955017
val: 12 0.40509742498397827
val: 13 0.4064839780330658
val: 14 0.3962654769420624
val: 15 0.4024832248687744
val: 16 0.40041762590408325
val: 17 0.4032048285007477
val: 18 0.3998796343803406
val: 19 0.4056455194950104
val: 20 0.40885549783706665
val_Epoch:[ 170 ] val_loss: 0.40357079058885575 2022-08-12 01:26:49.711339
start training 2022-08-12 01:26:49.809490
Epoch:[ 171 0 ] loss: 0.35354605317115784 2022-08-12 01:27:04.620099
Epoch:[ 171 1 ] loss: 0.3531017005443573 2022-08-12 01:27:05.043139
Epoch:[ 171 2 ] loss: 0.35244083404541016 2022-08-12 01:27:05.465790
Epoch:[ 171 3 ] loss: 0.3524462878704071 2022-08-12 01:27:05.879750
Epoch:[ 171 4 ] loss: 0.3508509695529938 2022-08-12 01:27:06.298311
Epoch:[ 171 5 ] loss: 0.3528604805469513 2022-08-12 01:27:06.724345
Epoch:[ 171 6 ] loss: 0.3537139892578125 2022-08-12 01:27:07.148044
Epoch:[ 171 7 ] loss: 0.35372427105903625 2022-08-12 01:27:07.566448
Epoch:[ 171 8 ] loss: 0.3531681001186371 2022-08-12 01:27:07.991127
Epoch:[ 171 9 ] loss: 0.35353824496269226 2022-08-12 01:27:08.417087
Epoch:[ 171 10 ] loss: 0.35394054651260376 2022-08-12 01:27:08.842192
Epoch:[ 171 11 ] loss: 0.35397350788116455 2022-08-12 01:27:09.260318
Epoch:[ 171 12 ] loss: 0.354744553565979 2022-08-12 01:27:09.685572
Epoch:[ 171 13 ] loss: 0.3545704483985901 2022-08-12 01:27:10.106070
Epoch:[ 171 14 ] loss: 0.3544090986251831 2022-08-12 01:27:10.532852
Epoch:[ 171 15 ] loss: 0.3533298373222351 2022-08-12 01:27:10.962110
Epoch:[ 171 16 ] loss: 0.3525453805923462 2022-08-12 01:27:16.300102
Epoch:[ 171 17 ] loss: 0.3538076877593994 2022-08-12 01:27:16.723148
Epoch:[ 171 18 ] loss: 0.35372355580329895 2022-08-12 01:27:17.153198
Epoch:[ 171 19 ] loss: 0.3540865182876587 2022-08-12 01:27:17.580278
Training_Epoch:[ 171 ] Training_loss: 0.35342610329389573 2022-08-12 01:27:17.581067
learning rate:  0.0002524536932026173
val: 1 0.4042639136314392
val: 2 0.40313228964805603
val: 3 0.4025663733482361
val: 4 0.4015282392501831
val: 5 0.3956435024738312
val: 6 0.4038200080394745
val: 7 0.40811464190483093
val: 8 0.41394755244255066
val: 9 0.40929293632507324
val: 10 0.4036095440387726
val: 11 0.4061058759689331
val: 12 0.40334469079971313
val: 13 0.4037976562976837
val: 14 0.4067537784576416
val: 15 0.39695024490356445
val: 16 0.40228673815727234
val: 17 0.4030660092830658
val: 18 0.401302695274353
val: 19 0.40581783652305603
val: 20 0.4007597267627716
val_Epoch:[ 171 ] val_loss: 0.40380521267652514 2022-08-12 01:27:21.175519
start training 2022-08-12 01:27:21.275473
Epoch:[ 172 0 ] loss: 0.35379254817962646 2022-08-12 01:27:35.639952
Epoch:[ 172 1 ] loss: 0.353778600692749 2022-08-12 01:27:36.084021
Epoch:[ 172 2 ] loss: 0.35283344984054565 2022-08-12 01:27:36.506671
Epoch:[ 172 3 ] loss: 0.3526861369609833 2022-08-12 01:27:36.935016
Epoch:[ 172 4 ] loss: 0.35349562764167786 2022-08-12 01:27:37.361869
Epoch:[ 172 5 ] loss: 0.35240307450294495 2022-08-12 01:27:37.788167
Epoch:[ 172 6 ] loss: 0.352821409702301 2022-08-12 01:27:38.213679
Epoch:[ 172 7 ] loss: 0.35216066241264343 2022-08-12 01:27:38.631393
Epoch:[ 172 8 ] loss: 0.35280412435531616 2022-08-12 01:27:39.057184
Epoch:[ 172 9 ] loss: 0.35194018483161926 2022-08-12 01:27:39.486946
Epoch:[ 172 10 ] loss: 0.3536512553691864 2022-08-12 01:27:39.910308
Epoch:[ 172 11 ] loss: 0.3523922264575958 2022-08-12 01:27:40.334099
Epoch:[ 172 12 ] loss: 0.352242648601532 2022-08-12 01:27:40.757214
Epoch:[ 172 13 ] loss: 0.3521862030029297 2022-08-12 01:27:41.169910
Epoch:[ 172 14 ] loss: 0.35245805978775024 2022-08-12 01:27:41.592541
Epoch:[ 172 15 ] loss: 0.3529924750328064 2022-08-12 01:27:42.017780
Epoch:[ 172 16 ] loss: 0.3535260558128357 2022-08-12 01:27:47.262812
Epoch:[ 172 17 ] loss: 0.3537524938583374 2022-08-12 01:27:47.675596
Epoch:[ 172 18 ] loss: 0.35387149453163147 2022-08-12 01:27:48.107160
Epoch:[ 172 19 ] loss: 0.3543870747089386 2022-08-12 01:27:48.529519
Training_Epoch:[ 172 ] Training_loss: 0.3530087903141975 2022-08-12 01:27:48.530199
learning rate:  0.0002524536932026173
val: 1 0.4091641902923584
val: 2 0.3944830894470215
val: 3 0.3970967233181
val: 4 0.4002191424369812
val: 5 0.4008933901786804
val: 6 0.4094037115573883
val: 7 0.39527231454849243
val: 8 0.4100008010864258
val: 9 0.4030383825302124
val: 10 0.3983457684516907
val: 11 0.4006960690021515
val: 12 0.40374019742012024
val: 13 0.4081014096736908
val: 14 0.4002158045768738
val: 15 0.4029248058795929
val: 16 0.40799012780189514
val: 17 0.40339958667755127
val: 18 0.395094096660614
val: 19 0.40473535656929016
val: 20 0.4054969549179077
val_Epoch:[ 172 ] val_loss: 0.4025155961513519 2022-08-12 01:27:52.042212
start training 2022-08-12 01:27:52.142826
Epoch:[ 173 0 ] loss: 0.3519194722175598 2022-08-12 01:28:06.561307
Epoch:[ 173 1 ] loss: 0.35290661454200745 2022-08-12 01:28:06.977290
Epoch:[ 173 2 ] loss: 0.3529930114746094 2022-08-12 01:28:07.403868
Epoch:[ 173 3 ] loss: 0.35174229741096497 2022-08-12 01:28:07.833385
Epoch:[ 173 4 ] loss: 0.35288408398628235 2022-08-12 01:28:08.254034
Epoch:[ 173 5 ] loss: 0.35492226481437683 2022-08-12 01:28:08.675876
Epoch:[ 173 6 ] loss: 0.3531567454338074 2022-08-12 01:28:09.097789
Epoch:[ 173 7 ] loss: 0.35343682765960693 2022-08-12 01:28:09.523487
Epoch:[ 173 8 ] loss: 0.35408109426498413 2022-08-12 01:28:09.948518
Epoch:[ 173 9 ] loss: 0.3530108332633972 2022-08-12 01:28:10.367440
Epoch:[ 173 10 ] loss: 0.35303404927253723 2022-08-12 01:28:10.792629
Epoch:[ 173 11 ] loss: 0.35456404089927673 2022-08-12 01:28:11.217928
Epoch:[ 173 12 ] loss: 0.3536667227745056 2022-08-12 01:28:11.641463
Epoch:[ 173 13 ] loss: 0.3529754877090454 2022-08-12 01:28:12.065769
Epoch:[ 173 14 ] loss: 0.35342803597450256 2022-08-12 01:28:12.490776
Epoch:[ 173 15 ] loss: 0.35453733801841736 2022-08-12 01:28:12.910362
Epoch:[ 173 16 ] loss: 0.35451796650886536 2022-08-12 01:28:18.100057
Epoch:[ 173 17 ] loss: 0.35328540205955505 2022-08-12 01:28:18.523993
Epoch:[ 173 18 ] loss: 0.35291722416877747 2022-08-12 01:28:18.956232
Epoch:[ 173 19 ] loss: 0.3527425229549408 2022-08-12 01:28:19.379962
Training_Epoch:[ 173 ] Training_loss: 0.353336101770401 2022-08-12 01:28:19.380691
learning rate:  0.0002524536932026173
val: 1 0.3979087769985199
val: 2 0.4020487666130066
val: 3 0.3977360129356384
val: 4 0.4085640013217926
val: 5 0.39769765734672546
val: 6 0.3954539895057678
val: 7 0.40907222032546997
val: 8 0.3995041847229004
val: 9 0.4075758159160614
val: 10 0.3942866325378418
val: 11 0.408511221408844
val: 12 0.39722147583961487
val: 13 0.40788230299949646
val: 14 0.40058544278144836
val: 15 0.4037623405456543
val: 16 0.40499013662338257
val: 17 0.3997809588909149
val: 18 0.4001046419143677
val: 19 0.4034295380115509
val: 20 0.4083336889743805
val_Epoch:[ 173 ] val_loss: 0.4022224903106689 2022-08-12 01:28:22.943713
start training 2022-08-12 01:28:23.044461
Epoch:[ 174 0 ] loss: 0.3526807129383087 2022-08-12 01:28:37.794375
Epoch:[ 174 1 ] loss: 0.3524693250656128 2022-08-12 01:28:38.220337
Epoch:[ 174 2 ] loss: 0.35268744826316833 2022-08-12 01:28:38.644615
Epoch:[ 174 3 ] loss: 0.35263895988464355 2022-08-12 01:28:39.066490
Epoch:[ 174 4 ] loss: 0.3548944890499115 2022-08-12 01:28:39.492108
Epoch:[ 174 5 ] loss: 0.353586345911026 2022-08-12 01:28:39.909544
Epoch:[ 174 6 ] loss: 0.3528548777103424 2022-08-12 01:28:40.333592
Epoch:[ 174 7 ] loss: 0.3529350161552429 2022-08-12 01:28:40.758397
Epoch:[ 174 8 ] loss: 0.3535082936286926 2022-08-12 01:28:41.187676
Epoch:[ 174 9 ] loss: 0.3545166850090027 2022-08-12 01:28:41.604600
Epoch:[ 174 10 ] loss: 0.353518545627594 2022-08-12 01:28:42.022351
Epoch:[ 174 11 ] loss: 0.35346853733062744 2022-08-12 01:28:42.444570
Epoch:[ 174 12 ] loss: 0.35319197177886963 2022-08-12 01:28:42.870347
Epoch:[ 174 13 ] loss: 0.3530360460281372 2022-08-12 01:28:43.289704
Epoch:[ 174 14 ] loss: 0.3538714647293091 2022-08-12 01:28:43.709712
Epoch:[ 174 15 ] loss: 0.35282963514328003 2022-08-12 01:28:44.131335
Epoch:[ 174 16 ] loss: 0.3534172475337982 2022-08-12 01:28:49.257788
Epoch:[ 174 17 ] loss: 0.3527565896511078 2022-08-12 01:28:49.683035
Epoch:[ 174 18 ] loss: 0.3537987172603607 2022-08-12 01:28:50.113147
Epoch:[ 174 19 ] loss: 0.3534325957298279 2022-08-12 01:28:50.535238
Training_Epoch:[ 174 ] Training_loss: 0.35330467522144315 2022-08-12 01:28:50.536196
learning rate:  0.0002524536932026173
val: 1 0.4126157760620117
val: 2 0.3959888219833374
val: 3 0.4090942144393921
val: 4 0.40747398138046265
val: 5 0.39942845702171326
val: 6 0.402407705783844
val: 7 0.4099014401435852
val: 8 0.39601820707321167
val: 9 0.4008731544017792
val: 10 0.40415939688682556
val: 11 0.39976781606674194
val: 12 0.39983367919921875
val: 13 0.40024086833000183
val: 14 0.40320202708244324
val: 15 0.4051517844200134
val: 16 0.4085165560245514
val: 17 0.4066917896270752
val: 18 0.40323999524116516
val: 19 0.39881521463394165
val: 20 0.4117768108844757
val_Epoch:[ 174 ] val_loss: 0.40375988483428954 2022-08-12 01:28:54.351993
start training 2022-08-12 01:28:54.457284
Epoch:[ 175 0 ] loss: 0.35287657380104065 2022-08-12 01:29:09.053772
Epoch:[ 175 1 ] loss: 0.3529070317745209 2022-08-12 01:29:09.498125
Epoch:[ 175 2 ] loss: 0.35225605964660645 2022-08-12 01:29:09.915710
Epoch:[ 175 3 ] loss: 0.3529924750328064 2022-08-12 01:29:10.340582
Epoch:[ 175 4 ] loss: 0.35223811864852905 2022-08-12 01:29:10.767724
Epoch:[ 175 5 ] loss: 0.3524669408798218 2022-08-12 01:29:11.191800
Epoch:[ 175 6 ] loss: 0.35269516706466675 2022-08-12 01:29:11.616558
Epoch:[ 175 7 ] loss: 0.3524266481399536 2022-08-12 01:29:12.040320
Epoch:[ 175 8 ] loss: 0.3527181148529053 2022-08-12 01:29:12.463613
Epoch:[ 175 9 ] loss: 0.3536381423473358 2022-08-12 01:29:12.888015
Epoch:[ 175 10 ] loss: 0.3529451787471771 2022-08-12 01:29:13.307966
Epoch:[ 175 11 ] loss: 0.35420650243759155 2022-08-12 01:29:13.734138
Epoch:[ 175 12 ] loss: 0.351787269115448 2022-08-12 01:29:14.154661
Epoch:[ 175 13 ] loss: 0.35373255610466003 2022-08-12 01:29:14.569019
Epoch:[ 175 14 ] loss: 0.3538162410259247 2022-08-12 01:29:14.989869
Epoch:[ 175 15 ] loss: 0.3541605770587921 2022-08-12 01:29:15.424469
Epoch:[ 175 16 ] loss: 0.3531014621257782 2022-08-12 01:29:20.906977
Epoch:[ 175 17 ] loss: 0.35273221135139465 2022-08-12 01:29:21.325368
Epoch:[ 175 18 ] loss: 0.3528997302055359 2022-08-12 01:29:21.755352
Epoch:[ 175 19 ] loss: 0.35355544090270996 2022-08-12 01:29:22.179863
Training_Epoch:[ 175 ] Training_loss: 0.35300762206315994 2022-08-12 01:29:22.180547
learning rate:  0.0002524536932026173
val: 1 0.40582066774368286
val: 2 0.3994903862476349
val: 3 0.4024049937725067
val: 4 0.40220046043395996
val: 5 0.4023931324481964
val: 6 0.3951495885848999
val: 7 0.4002796411514282
val: 8 0.39876022934913635
val: 9 0.411851704120636
val: 10 0.4057145118713379
val: 11 0.39740610122680664
val: 12 0.4055377244949341
val: 13 0.3996495008468628
val: 14 0.40193745493888855
val: 15 0.4051150977611542
val: 16 0.40159252285957336
val: 17 0.40370848774909973
val: 18 0.4096192419528961
val: 19 0.39166077971458435
val: 20 0.4033084809780121
val_Epoch:[ 175 ] val_loss: 0.40218003541231157 2022-08-12 01:29:25.753304
start training 2022-08-12 01:29:25.855163
Epoch:[ 176 0 ] loss: 0.3529600501060486 2022-08-12 01:29:40.659632
Epoch:[ 176 1 ] loss: 0.3523024618625641 2022-08-12 01:29:41.085998
Epoch:[ 176 2 ] loss: 0.3528510332107544 2022-08-12 01:29:41.508455
Epoch:[ 176 3 ] loss: 0.3525013327598572 2022-08-12 01:29:41.931018
Epoch:[ 176 4 ] loss: 0.35269516706466675 2022-08-12 01:29:42.357624
Epoch:[ 176 5 ] loss: 0.352033406496048 2022-08-12 01:29:42.780733
Epoch:[ 176 6 ] loss: 0.35270562767982483 2022-08-12 01:29:43.195535
Epoch:[ 176 7 ] loss: 0.3529401421546936 2022-08-12 01:29:43.620002
Epoch:[ 176 8 ] loss: 0.3523954153060913 2022-08-12 01:29:44.045483
Epoch:[ 176 9 ] loss: 0.3518627882003784 2022-08-12 01:29:44.466962
Epoch:[ 176 10 ] loss: 0.3539080023765564 2022-08-12 01:29:44.883487
Epoch:[ 176 11 ] loss: 0.3530125021934509 2022-08-12 01:29:45.314408
Epoch:[ 176 12 ] loss: 0.35309773683547974 2022-08-12 01:29:45.740538
Epoch:[ 176 13 ] loss: 0.35488882660865784 2022-08-12 01:29:46.167332
Epoch:[ 176 14 ] loss: 0.3536832928657532 2022-08-12 01:29:46.589905
Epoch:[ 176 15 ] loss: 0.35299113392829895 2022-08-12 01:29:47.013454
Epoch:[ 176 16 ] loss: 0.3531920909881592 2022-08-12 01:29:52.260052
Epoch:[ 176 17 ] loss: 0.35289788246154785 2022-08-12 01:29:52.680947
Epoch:[ 176 18 ] loss: 0.35356175899505615 2022-08-12 01:29:53.103224
Epoch:[ 176 19 ] loss: 0.3545912802219391 2022-08-12 01:29:53.525862
Training_Epoch:[ 176 ] Training_loss: 0.35305359661579133 2022-08-12 01:29:53.526593
learning rate:  0.0002524536932026173
val: 1 0.4054255187511444
val: 2 0.40611428022384644
val: 3 0.4039607048034668
val: 4 0.4029965400695801
val: 5 0.40631231665611267
val: 6 0.40004149079322815
val: 7 0.4045940041542053
val: 8 0.40254563093185425
val: 9 0.39075496792793274
val: 10 0.3948540687561035
val: 11 0.40292415022850037
val: 12 0.39726799726486206
val: 13 0.3985576331615448
val: 14 0.4075792729854584
val: 15 0.3991983234882355
val: 16 0.4158819615840912
val: 17 0.4040580987930298
val: 18 0.4053134620189667
val: 19 0.3959050178527832
val: 20 0.4088132083415985
val_Epoch:[ 176 ] val_loss: 0.40265493243932726 2022-08-12 01:29:57.146399
start training 2022-08-12 01:29:57.245853
Epoch:[ 177 0 ] loss: 0.35264429450035095 2022-08-12 01:30:11.387734
Epoch:[ 177 1 ] loss: 0.3528572618961334 2022-08-12 01:30:12.213371
Epoch:[ 177 2 ] loss: 0.35300275683403015 2022-08-12 01:30:12.635532
Epoch:[ 177 3 ] loss: 0.3521207273006439 2022-08-12 01:30:13.058336
Epoch:[ 177 4 ] loss: 0.35287225246429443 2022-08-12 01:30:13.484360
Epoch:[ 177 5 ] loss: 0.3534948527812958 2022-08-12 01:30:13.906102
Epoch:[ 177 6 ] loss: 0.35224226117134094 2022-08-12 01:30:14.330948
Epoch:[ 177 7 ] loss: 0.3522973656654358 2022-08-12 01:30:14.754554
Epoch:[ 177 8 ] loss: 0.352673202753067 2022-08-12 01:30:15.176171
Epoch:[ 177 9 ] loss: 0.3533118665218353 2022-08-12 01:30:15.592151
Epoch:[ 177 10 ] loss: 0.3521327078342438 2022-08-12 01:30:16.015444
Epoch:[ 177 11 ] loss: 0.3529634177684784 2022-08-12 01:30:16.438397
Epoch:[ 177 12 ] loss: 0.35324549674987793 2022-08-12 01:30:16.855068
Epoch:[ 177 13 ] loss: 0.35350537300109863 2022-08-12 01:30:17.277198
Epoch:[ 177 14 ] loss: 0.35373300313949585 2022-08-12 01:30:17.701906
Epoch:[ 177 15 ] loss: 0.3526369631290436 2022-08-12 01:30:18.124960
Epoch:[ 177 16 ] loss: 0.3535681664943695 2022-08-12 01:30:23.128820
Epoch:[ 177 17 ] loss: 0.35302966833114624 2022-08-12 01:30:23.678562
Epoch:[ 177 18 ] loss: 0.3520449697971344 2022-08-12 01:30:24.098820
Epoch:[ 177 19 ] loss: 0.3537275195121765 2022-08-12 01:30:24.513280
Training_Epoch:[ 177 ] Training_loss: 0.3529052063822746 2022-08-12 01:30:24.513981
learning rate:  0.0002524536932026173
val: 1 0.4107849597930908
val: 2 0.40578022599220276
val: 3 0.3982700705528259
val: 4 0.39927831292152405
val: 5 0.4056054949760437
val: 6 0.4131416082382202
val: 7 0.4049522280693054
val: 8 0.4059663712978363
val: 9 0.40713736414909363
val: 10 0.40289533138275146
val: 11 0.39774057269096375
val: 12 0.39947637915611267
val: 13 0.3997110426425934
val: 14 0.397251695394516
val: 15 0.4064796268939972
val: 16 0.4126632809638977
val: 17 0.4072152078151703
val: 18 0.40188828110694885
val: 19 0.40776267647743225
val: 20 0.40468668937683105
val_Epoch:[ 177 ] val_loss: 0.40443437099456786 2022-08-12 01:30:28.039274
start training 2022-08-12 01:30:28.136259
Epoch:[ 178 0 ] loss: 0.35274752974510193 2022-08-12 01:30:42.745590
Epoch:[ 178 1 ] loss: 0.3522576093673706 2022-08-12 01:30:43.173634
Epoch:[ 178 2 ] loss: 0.35234391689300537 2022-08-12 01:30:43.596328
Epoch:[ 178 3 ] loss: 0.35233351588249207 2022-08-12 01:30:44.014886
Epoch:[ 178 4 ] loss: 0.3534652292728424 2022-08-12 01:30:44.434862
Epoch:[ 178 5 ] loss: 0.35315439105033875 2022-08-12 01:30:44.860853
Epoch:[ 178 6 ] loss: 0.35249999165534973 2022-08-12 01:30:45.285242
Epoch:[ 178 7 ] loss: 0.35296082496643066 2022-08-12 01:30:45.704771
Epoch:[ 178 8 ] loss: 0.3526996672153473 2022-08-12 01:30:46.128014
Epoch:[ 178 9 ] loss: 0.35159552097320557 2022-08-12 01:30:46.558519
Epoch:[ 178 10 ] loss: 0.35394829511642456 2022-08-12 01:30:46.985655
Epoch:[ 178 11 ] loss: 0.35253793001174927 2022-08-12 01:30:47.406856
Epoch:[ 178 12 ] loss: 0.35435599088668823 2022-08-12 01:30:47.830422
Epoch:[ 178 13 ] loss: 0.3530002534389496 2022-08-12 01:30:48.250723
Epoch:[ 178 14 ] loss: 0.35159021615982056 2022-08-12 01:30:48.671550
Epoch:[ 178 15 ] loss: 0.3524515628814697 2022-08-12 01:30:49.097868
Epoch:[ 178 16 ] loss: 0.3524225652217865 2022-08-12 01:30:54.746832
Epoch:[ 178 17 ] loss: 0.3534824550151825 2022-08-12 01:30:55.162143
Epoch:[ 178 18 ] loss: 0.3526618480682373 2022-08-12 01:30:55.585029
Epoch:[ 178 19 ] loss: 0.3531031906604767 2022-08-12 01:30:56.005442
Training_Epoch:[ 178 ] Training_loss: 0.35278062522411346 2022-08-12 01:30:56.006145
learning rate:  0.0002524536932026173
val: 1 0.4060244560241699
val: 2 0.40489527583122253
val: 3 0.4085288941860199
val: 4 0.40412798523902893
val: 5 0.41185855865478516
val: 6 0.40151041746139526
val: 7 0.40563061833381653
val: 8 0.4056742191314697
val: 9 0.4069129526615143
val: 10 0.3999871611595154
val: 11 0.39830482006073
val: 12 0.40206220746040344
val: 13 0.39819830656051636
val: 14 0.4008258879184723
val: 15 0.4011228680610657
val: 16 0.40081992745399475
val: 17 0.4085119962692261
val: 18 0.40595293045043945
val: 19 0.4085783064365387
val: 20 0.3997248411178589
val_Epoch:[ 178 ] val_loss: 0.4039626315236092 2022-08-12 01:30:59.623963
start training 2022-08-12 01:30:59.723108
Epoch:[ 179 0 ] loss: 0.3528338074684143 2022-08-12 01:31:13.631120
Epoch:[ 179 1 ] loss: 0.35396862030029297 2022-08-12 01:31:14.188774
Epoch:[ 179 2 ] loss: 0.3519049882888794 2022-08-12 01:31:14.631625
Epoch:[ 179 3 ] loss: 0.35245850682258606 2022-08-12 01:31:15.046625
Epoch:[ 179 4 ] loss: 0.35242727398872375 2022-08-12 01:31:15.466647
Epoch:[ 179 5 ] loss: 0.3522265553474426 2022-08-12 01:31:15.889436
Epoch:[ 179 6 ] loss: 0.352855384349823 2022-08-12 01:31:16.315254
Epoch:[ 179 7 ] loss: 0.3537936210632324 2022-08-12 01:31:16.737933
Epoch:[ 179 8 ] loss: 0.3539997935295105 2022-08-12 01:31:17.165311
Epoch:[ 179 9 ] loss: 0.3523634970188141 2022-08-12 01:31:17.586463
Epoch:[ 179 10 ] loss: 0.35312026739120483 2022-08-12 01:31:18.009041
Epoch:[ 179 11 ] loss: 0.35285866260528564 2022-08-12 01:31:18.432704
Epoch:[ 179 12 ] loss: 0.35375747084617615 2022-08-12 01:31:18.858524
Epoch:[ 179 13 ] loss: 0.35218313336372375 2022-08-12 01:31:19.274593
Epoch:[ 179 14 ] loss: 0.3534194529056549 2022-08-12 01:31:19.699023
Epoch:[ 179 15 ] loss: 0.35385826230049133 2022-08-12 01:31:20.121389
Epoch:[ 179 16 ] loss: 0.3534713387489319 2022-08-12 01:31:25.716495
Epoch:[ 179 17 ] loss: 0.35332274436950684 2022-08-12 01:31:26.141474
Epoch:[ 179 18 ] loss: 0.35389333963394165 2022-08-12 01:31:26.560312
Epoch:[ 179 19 ] loss: 0.3533163368701935 2022-08-12 01:31:26.984128
Training_Epoch:[ 179 ] Training_loss: 0.3531016528606415 2022-08-12 01:31:26.984863
learning rate:  0.0002524536932026173
val: 1 0.40385010838508606
val: 2 0.4073193073272705
val: 3 0.4041297435760498
val: 4 0.4004537761211395
val: 5 0.4064778685569763
val: 6 0.4049377143383026
val: 7 0.39788681268692017
val: 8 0.40686464309692383
val: 9 0.4039413630962372
val: 10 0.40355318784713745
val: 11 0.4028283357620239
val: 12 0.4010469615459442
val: 13 0.39970284700393677
val: 14 0.4058617055416107
val: 15 0.40648162364959717
val: 16 0.39755427837371826
val: 17 0.4034784734249115
val: 18 0.4046837091445923
val: 19 0.39869651198387146
val: 20 0.41375765204429626
val_Epoch:[ 179 ] val_loss: 0.4036753311753273 2022-08-12 01:31:30.560631
start training 2022-08-12 01:31:30.661173
Epoch:[ 180 0 ] loss: 0.3522052466869354 2022-08-12 01:31:45.547711
Epoch:[ 180 1 ] loss: 0.3525989353656769 2022-08-12 01:31:45.970294
Epoch:[ 180 2 ] loss: 0.35291770100593567 2022-08-12 01:31:46.396760
Epoch:[ 180 3 ] loss: 0.35257288813591003 2022-08-12 01:31:46.825480
Epoch:[ 180 4 ] loss: 0.354128897190094 2022-08-12 01:31:47.247658
Epoch:[ 180 5 ] loss: 0.3529126048088074 2022-08-12 01:31:47.674132
Epoch:[ 180 6 ] loss: 0.35242265462875366 2022-08-12 01:31:48.091616
Epoch:[ 180 7 ] loss: 0.3526725172996521 2022-08-12 01:31:48.506085
Epoch:[ 180 8 ] loss: 0.3528534770011902 2022-08-12 01:31:48.929111
Epoch:[ 180 9 ] loss: 0.35237768292427063 2022-08-12 01:31:49.361102
Epoch:[ 180 10 ] loss: 0.3526405096054077 2022-08-12 01:31:49.781746
Epoch:[ 180 11 ] loss: 0.3533278703689575 2022-08-12 01:31:50.197022
Epoch:[ 180 12 ] loss: 0.35250410437583923 2022-08-12 01:31:50.622007
Epoch:[ 180 13 ] loss: 0.3533320426940918 2022-08-12 01:31:51.046599
Epoch:[ 180 14 ] loss: 0.35301628708839417 2022-08-12 01:31:51.470265
Epoch:[ 180 15 ] loss: 0.35251614451408386 2022-08-12 01:31:51.888751
Epoch:[ 180 16 ] loss: 0.353289395570755 2022-08-12 01:31:57.183305
Epoch:[ 180 17 ] loss: 0.35377365350723267 2022-08-12 01:31:57.608298
Epoch:[ 180 18 ] loss: 0.3523094654083252 2022-08-12 01:31:58.043517
Epoch:[ 180 19 ] loss: 0.3529348075389862 2022-08-12 01:31:58.466152
Training_Epoch:[ 180 ] Training_loss: 0.35286534428596494 2022-08-12 01:31:58.466925
learning rate:  0.0002524536932026173
netparams have been saved once 180
val: 1 0.3969603180885315
val: 2 0.3991852104663849
val: 3 0.3989655077457428
val: 4 0.4104871451854706
val: 5 0.40683647990226746
val: 6 0.4083455502986908
val: 7 0.40044930577278137
val: 8 0.40257537364959717
val: 9 0.40624237060546875
val: 10 0.40264466404914856
val: 11 0.4018680453300476
val: 12 0.40285763144493103
val: 13 0.4077070653438568
val: 14 0.40752121806144714
val: 15 0.40691766142845154
val: 16 0.4027261734008789
val: 17 0.40891385078430176
val: 18 0.40183117985725403
val: 19 0.4017987847328186
val: 20 0.39738309383392334
val_Epoch:[ 180 ] val_loss: 0.4036108314990997 2022-08-12 01:32:02.097356
start training 2022-08-12 01:32:02.196103
Epoch:[ 181 0 ] loss: 0.35196593403816223 2022-08-12 01:32:16.218581
Epoch:[ 181 1 ] loss: 0.3525710999965668 2022-08-12 01:32:16.673516
Epoch:[ 181 2 ] loss: 0.3529048264026642 2022-08-12 01:32:17.171438
Epoch:[ 181 3 ] loss: 0.35208070278167725 2022-08-12 01:32:17.598280
Epoch:[ 181 4 ] loss: 0.35335445404052734 2022-08-12 01:32:18.023107
Epoch:[ 181 5 ] loss: 0.353331983089447 2022-08-12 01:32:18.446835
Epoch:[ 181 6 ] loss: 0.3537234365940094 2022-08-12 01:32:18.871115
Epoch:[ 181 7 ] loss: 0.3533685505390167 2022-08-12 01:32:19.297549
Epoch:[ 181 8 ] loss: 0.3521344065666199 2022-08-12 01:32:19.725314
Epoch:[ 181 9 ] loss: 0.3530386686325073 2022-08-12 01:32:20.149538
Epoch:[ 181 10 ] loss: 0.35372379422187805 2022-08-12 01:32:20.577088
Epoch:[ 181 11 ] loss: 0.3527289927005768 2022-08-12 01:32:20.998425
Epoch:[ 181 12 ] loss: 0.3524162471294403 2022-08-12 01:32:21.425838
Epoch:[ 181 13 ] loss: 0.3541160225868225 2022-08-12 01:32:21.849180
Epoch:[ 181 14 ] loss: 0.3534034192562103 2022-08-12 01:32:22.272445
Epoch:[ 181 15 ] loss: 0.35213711857795715 2022-08-12 01:32:22.696318
Epoch:[ 181 16 ] loss: 0.3532533645629883 2022-08-12 01:32:28.214480
Epoch:[ 181 17 ] loss: 0.3521769642829895 2022-08-12 01:32:28.636209
Epoch:[ 181 18 ] loss: 0.3528378903865814 2022-08-12 01:32:29.063753
Epoch:[ 181 19 ] loss: 0.3514592945575714 2022-08-12 01:32:29.485461
Training_Epoch:[ 181 ] Training_loss: 0.3528363585472107 2022-08-12 01:32:29.486191
learning rate:  0.0002145856392222247
val: 1 0.4073903262615204
val: 2 0.3988896608352661
val: 3 0.40464717149734497
val: 4 0.40512150526046753
val: 5 0.4079398214817047
val: 6 0.4078258275985718
val: 7 0.3984312117099762
val: 8 0.4064418077468872
val: 9 0.40553373098373413
val: 10 0.3993719220161438
val: 11 0.4019174873828888
val: 12 0.3999963104724884
val: 13 0.40387192368507385
val: 14 0.4012215733528137
val: 15 0.41083231568336487
val: 16 0.40476953983306885
val: 17 0.4014119505882263
val: 18 0.4048340320587158
val: 19 0.40087926387786865
val: 20 0.4081401824951172
val_Epoch:[ 181 ] val_loss: 0.40397337824106216 2022-08-12 01:32:33.141003
start training 2022-08-12 01:32:33.239339
Epoch:[ 182 0 ] loss: 0.3518470227718353 2022-08-12 01:32:47.471956
Epoch:[ 182 1 ] loss: 0.3532118797302246 2022-08-12 01:32:47.901557
Epoch:[ 182 2 ] loss: 0.3517310619354248 2022-08-12 01:32:48.325198
Epoch:[ 182 3 ] loss: 0.3517008423805237 2022-08-12 01:32:48.752244
Epoch:[ 182 4 ] loss: 0.3516393005847931 2022-08-12 01:32:49.171834
Epoch:[ 182 5 ] loss: 0.35196807980537415 2022-08-12 01:32:49.589770
Epoch:[ 182 6 ] loss: 0.3517332077026367 2022-08-12 01:32:50.014790
Epoch:[ 182 7 ] loss: 0.3525608777999878 2022-08-12 01:32:50.440507
Epoch:[ 182 8 ] loss: 0.35101667046546936 2022-08-12 01:32:50.856641
Epoch:[ 182 9 ] loss: 0.35287946462631226 2022-08-12 01:32:51.275053
Epoch:[ 182 10 ] loss: 0.3524658679962158 2022-08-12 01:32:51.696637
Epoch:[ 182 11 ] loss: 0.3508113622665405 2022-08-12 01:32:52.123703
Epoch:[ 182 12 ] loss: 0.3521548807621002 2022-08-12 01:32:52.543409
Epoch:[ 182 13 ] loss: 0.3526899218559265 2022-08-12 01:32:52.972140
Epoch:[ 182 14 ] loss: 0.3526425361633301 2022-08-12 01:32:53.396923
Epoch:[ 182 15 ] loss: 0.3520357608795166 2022-08-12 01:32:53.820919
Epoch:[ 182 16 ] loss: 0.3505024015903473 2022-08-12 01:32:59.425804
Epoch:[ 182 17 ] loss: 0.35245347023010254 2022-08-12 01:32:59.846067
Epoch:[ 182 18 ] loss: 0.35250040888786316 2022-08-12 01:33:00.268548
Epoch:[ 182 19 ] loss: 0.3536480665206909 2022-08-12 01:33:00.692514
Training_Epoch:[ 182 ] Training_loss: 0.35210965424776075 2022-08-12 01:33:00.693224
learning rate:  0.0002145856392222247
val: 1 0.3973865509033203
val: 2 0.40361011028289795
val: 3 0.3995803892612457
val: 4 0.4014122486114502
val: 5 0.3982499837875366
val: 6 0.4066491425037384
val: 7 0.4022617042064667
val: 8 0.4008156359195709
val: 9 0.4093923270702362
val: 10 0.3937637507915497
val: 11 0.4059174656867981
val: 12 0.4061526656150818
val: 13 0.41031259298324585
val: 14 0.4086604118347168
val: 15 0.4079413414001465
val: 16 0.4101797044277191
val: 17 0.40848225355148315
val: 18 0.40241286158561707
val: 19 0.4066533148288727
val: 20 0.3982062041759491
val_Epoch:[ 182 ] val_loss: 0.40390203297138216 2022-08-12 01:33:04.372593
start training 2022-08-12 01:33:04.469118
Epoch:[ 183 0 ] loss: 0.3523082137107849 2022-08-12 01:33:19.052434
Epoch:[ 183 1 ] loss: 0.35240527987480164 2022-08-12 01:33:19.471752
Epoch:[ 183 2 ] loss: 0.3518596887588501 2022-08-12 01:33:19.891730
Epoch:[ 183 3 ] loss: 0.35182157158851624 2022-08-12 01:33:20.317243
Epoch:[ 183 4 ] loss: 0.35197412967681885 2022-08-12 01:33:20.741578
Epoch:[ 183 5 ] loss: 0.35243719816207886 2022-08-12 01:33:21.173193
Epoch:[ 183 6 ] loss: 0.35122936964035034 2022-08-12 01:33:21.599523
Epoch:[ 183 7 ] loss: 0.3523121774196625 2022-08-12 01:33:22.019472
Epoch:[ 183 8 ] loss: 0.35204723477363586 2022-08-12 01:33:22.444069
Epoch:[ 183 9 ] loss: 0.35139018297195435 2022-08-12 01:33:22.866091
Epoch:[ 183 10 ] loss: 0.35139432549476624 2022-08-12 01:33:23.289143
Epoch:[ 183 11 ] loss: 0.3521149158477783 2022-08-12 01:33:23.713069
Epoch:[ 183 12 ] loss: 0.3519514799118042 2022-08-12 01:33:24.136658
Epoch:[ 183 13 ] loss: 0.35172122716903687 2022-08-12 01:33:24.549690
Epoch:[ 183 14 ] loss: 0.35167035460472107 2022-08-12 01:33:24.975606
Epoch:[ 183 15 ] loss: 0.35171470046043396 2022-08-12 01:33:25.400717
Epoch:[ 183 16 ] loss: 0.35262057185173035 2022-08-12 01:33:30.525284
Epoch:[ 183 17 ] loss: 0.35223954916000366 2022-08-12 01:33:30.939604
Epoch:[ 183 18 ] loss: 0.35270559787750244 2022-08-12 01:33:31.363020
Epoch:[ 183 19 ] loss: 0.35242459177970886 2022-08-12 01:33:31.792180
Training_Epoch:[ 183 ] Training_loss: 0.35201711803674696 2022-08-12 01:33:31.792891
learning rate:  0.0002145856392222247
val: 1 0.4007923901081085
val: 2 0.40186214447021484
val: 3 0.4015963077545166
val: 4 0.39772096276283264
val: 5 0.41505196690559387
val: 6 0.3998457193374634
val: 7 0.4078456461429596
val: 8 0.4044802784919739
val: 9 0.402828574180603
val: 10 0.40597426891326904
val: 11 0.40331676602363586
val: 12 0.404133141040802
val: 13 0.4065174162387848
val: 14 0.39369985461235046
val: 15 0.405499666929245
val: 16 0.4070660173892975
val: 17 0.40302932262420654
val: 18 0.3988976776599884
val: 19 0.4098626673221588
val: 20 0.4098840653896332
val_Epoch:[ 183 ] val_loss: 0.4039952427148819 2022-08-12 01:33:35.308891
start training 2022-08-12 01:33:35.407851
Epoch:[ 184 0 ] loss: 0.35089579224586487 2022-08-12 01:33:50.304213
Epoch:[ 184 1 ] loss: 0.35227423906326294 2022-08-12 01:33:50.723723
Epoch:[ 184 2 ] loss: 0.35209494829177856 2022-08-12 01:33:51.155014
Epoch:[ 184 3 ] loss: 0.3517420291900635 2022-08-12 01:33:51.575719
Epoch:[ 184 4 ] loss: 0.3527134656906128 2022-08-12 01:33:51.998111
Epoch:[ 184 5 ] loss: 0.3518645763397217 2022-08-12 01:33:52.417743
Epoch:[ 184 6 ] loss: 0.3515447676181793 2022-08-12 01:33:52.844134
Epoch:[ 184 7 ] loss: 0.35260528326034546 2022-08-12 01:33:53.272587
Epoch:[ 184 8 ] loss: 0.35106149315834045 2022-08-12 01:33:53.690475
Epoch:[ 184 9 ] loss: 0.35176602005958557 2022-08-12 01:33:54.114669
Epoch:[ 184 10 ] loss: 0.3529466390609741 2022-08-12 01:33:54.536272
Epoch:[ 184 11 ] loss: 0.3524763882160187 2022-08-12 01:33:54.960294
Epoch:[ 184 12 ] loss: 0.3518184423446655 2022-08-12 01:33:55.380759
Epoch:[ 184 13 ] loss: 0.35238736867904663 2022-08-12 01:33:55.803936
Epoch:[ 184 14 ] loss: 0.35235416889190674 2022-08-12 01:33:56.233951
Epoch:[ 184 15 ] loss: 0.3514569103717804 2022-08-12 01:33:56.656058
Epoch:[ 184 16 ] loss: 0.3526161313056946 2022-08-12 01:34:02.434963
Epoch:[ 184 17 ] loss: 0.3528359532356262 2022-08-12 01:34:02.853482
Epoch:[ 184 18 ] loss: 0.35202673077583313 2022-08-12 01:34:03.284558
Epoch:[ 184 19 ] loss: 0.35236895084381104 2022-08-12 01:34:03.705930
Training_Epoch:[ 184 ] Training_loss: 0.3520925149321556 2022-08-12 01:34:03.706635
learning rate:  0.0002145856392222247
val: 1 0.4054108262062073
val: 2 0.40310919284820557
val: 3 0.40364664793014526
val: 4 0.4114076793193817
val: 5 0.3992571234703064
val: 6 0.40781256556510925
val: 7 0.408324658870697
val: 8 0.40011581778526306
val: 9 0.4133571684360504
val: 10 0.40504953265190125
val: 11 0.4023025631904602
val: 12 0.3934561312198639
val: 13 0.4094398021697998
val: 14 0.40852606296539307
val: 15 0.3999483585357666
val: 16 0.39657214283943176
val: 17 0.4074368476867676
val: 18 0.3928852379322052
val: 19 0.41199228167533875
val: 20 0.40601852536201477
val_Epoch:[ 184 ] val_loss: 0.40430345833301545 2022-08-12 01:34:07.312554
start training 2022-08-12 01:34:07.450468
Epoch:[ 185 0 ] loss: 0.35273849964141846 2022-08-12 01:34:21.914255
Epoch:[ 185 1 ] loss: 0.35148802399635315 2022-08-12 01:34:22.334992
Epoch:[ 185 2 ] loss: 0.351773202419281 2022-08-12 01:34:22.761920
Epoch:[ 185 3 ] loss: 0.3509790599346161 2022-08-12 01:34:23.184812
Epoch:[ 185 4 ] loss: 0.3520691692829132 2022-08-12 01:34:23.609758
Epoch:[ 185 5 ] loss: 0.3516188859939575 2022-08-12 01:34:24.035685
Epoch:[ 185 6 ] loss: 0.35083916783332825 2022-08-12 01:34:24.459742
Epoch:[ 185 7 ] loss: 0.3512146472930908 2022-08-12 01:34:24.890687
Epoch:[ 185 8 ] loss: 0.3520888090133667 2022-08-12 01:34:25.306192
Epoch:[ 185 9 ] loss: 0.3530944883823395 2022-08-12 01:34:25.726248
Epoch:[ 185 10 ] loss: 0.35152071714401245 2022-08-12 01:34:26.156327
Epoch:[ 185 11 ] loss: 0.35209664702415466 2022-08-12 01:34:26.581273
Epoch:[ 185 12 ] loss: 0.35255786776542664 2022-08-12 01:34:27.002872
Epoch:[ 185 13 ] loss: 0.35091692209243774 2022-08-12 01:34:27.422869
Epoch:[ 185 14 ] loss: 0.352866530418396 2022-08-12 01:34:27.849969
Epoch:[ 185 15 ] loss: 0.35217025876045227 2022-08-12 01:34:28.283496
Epoch:[ 185 16 ] loss: 0.35186082124710083 2022-08-12 01:34:34.112927
Epoch:[ 185 17 ] loss: 0.3533032238483429 2022-08-12 01:34:34.539230
Epoch:[ 185 18 ] loss: 0.3517219126224518 2022-08-12 01:34:34.960016
Epoch:[ 185 19 ] loss: 0.3522145450115204 2022-08-12 01:34:35.379395
Training_Epoch:[ 185 ] Training_loss: 0.351956669986248 2022-08-12 01:34:35.380137
learning rate:  0.0002145856392222247
val: 1 0.40614235401153564
val: 2 0.402432918548584
val: 3 0.4062436521053314
val: 4 0.40919607877731323
val: 5 0.4007805287837982
val: 6 0.4093993008136749
val: 7 0.4019933044910431
val: 8 0.4007529020309448
val: 9 0.39772599935531616
val: 10 0.3975380063056946
val: 11 0.40399107336997986
val: 12 0.39960163831710815
val: 13 0.40414485335350037
val: 14 0.39338284730911255
val: 15 0.40540990233421326
val: 16 0.40443289279937744
val: 17 0.40138664841651917
val: 18 0.4056699573993683
val: 19 0.40179353952407837
val: 20 0.40652477741241455
val_Epoch:[ 185 ] val_loss: 0.4029271587729454 2022-08-12 01:34:38.975227
start training 2022-08-12 01:34:39.073551
Epoch:[ 186 0 ] loss: 0.35061120986938477 2022-08-12 01:34:53.447428
Epoch:[ 186 1 ] loss: 0.35198044776916504 2022-08-12 01:34:53.997824
Epoch:[ 186 2 ] loss: 0.3527894914150238 2022-08-12 01:34:54.419532
Epoch:[ 186 3 ] loss: 0.35145241022109985 2022-08-12 01:34:54.843565
Epoch:[ 186 4 ] loss: 0.3517994284629822 2022-08-12 01:34:55.265256
Epoch:[ 186 5 ] loss: 0.3505818843841553 2022-08-12 01:34:55.681617
Epoch:[ 186 6 ] loss: 0.35283222794532776 2022-08-12 01:34:56.104080
Epoch:[ 186 7 ] loss: 0.35144373774528503 2022-08-12 01:34:56.527789
Epoch:[ 186 8 ] loss: 0.3517822325229645 2022-08-12 01:34:56.953677
Epoch:[ 186 9 ] loss: 0.35145825147628784 2022-08-12 01:34:57.374563
Epoch:[ 186 10 ] loss: 0.3514903783798218 2022-08-12 01:34:57.800613
Epoch:[ 186 11 ] loss: 0.3526332378387451 2022-08-12 01:34:58.221480
Epoch:[ 186 12 ] loss: 0.35195815563201904 2022-08-12 01:34:58.646797
Epoch:[ 186 13 ] loss: 0.35145995020866394 2022-08-12 01:34:59.072590
Epoch:[ 186 14 ] loss: 0.35198378562927246 2022-08-12 01:34:59.494536
Epoch:[ 186 15 ] loss: 0.35287633538246155 2022-08-12 01:34:59.931330
Epoch:[ 186 16 ] loss: 0.35139328241348267 2022-08-12 01:35:05.124398
Epoch:[ 186 17 ] loss: 0.3535570502281189 2022-08-12 01:35:05.746238
Epoch:[ 186 18 ] loss: 0.3522573411464691 2022-08-12 01:35:06.172646
Epoch:[ 186 19 ] loss: 0.3518304228782654 2022-08-12 01:35:06.589935
Training_Epoch:[ 186 ] Training_loss: 0.3519085630774498 2022-08-12 01:35:06.590629
learning rate:  0.0002145856392222247
val: 1 0.40873003005981445
val: 2 0.3950103521347046
val: 3 0.4061875343322754
val: 4 0.40484386682510376
val: 5 0.3986935317516327
val: 6 0.40159550309181213
val: 7 0.4088802635669708
val: 8 0.4046606123447418
val: 9 0.4123789966106415
val: 10 0.4054010510444641
val: 11 0.40043702721595764
val: 12 0.3950132429599762
val: 13 0.4105404317378998
val: 14 0.40955668687820435
val: 15 0.4069681465625763
val: 16 0.40753281116485596
val: 17 0.40162405371665955
val: 18 0.40829554200172424
val: 19 0.4030422568321228
val: 20 0.4042625427246094
val_Epoch:[ 186 ] val_loss: 0.40468272417783735 2022-08-12 01:35:10.261205
start training 2022-08-12 01:35:10.362575
Epoch:[ 187 0 ] loss: 0.35174790024757385 2022-08-12 01:35:25.075436
Epoch:[ 187 1 ] loss: 0.3524855971336365 2022-08-12 01:35:25.497966
Epoch:[ 187 2 ] loss: 0.35292235016822815 2022-08-12 01:35:25.919124
Epoch:[ 187 3 ] loss: 0.3522391617298126 2022-08-12 01:35:26.335751
Epoch:[ 187 4 ] loss: 0.3528442978858948 2022-08-12 01:35:26.756066
Epoch:[ 187 5 ] loss: 0.3512878119945526 2022-08-12 01:35:27.182479
Epoch:[ 187 6 ] loss: 0.3528831899166107 2022-08-12 01:35:27.608787
Epoch:[ 187 7 ] loss: 0.3524675965309143 2022-08-12 01:35:28.026832
Epoch:[ 187 8 ] loss: 0.3521713316440582 2022-08-12 01:35:28.453826
Epoch:[ 187 9 ] loss: 0.3523136377334595 2022-08-12 01:35:28.879339
Epoch:[ 187 10 ] loss: 0.35116904973983765 2022-08-12 01:35:29.308327
Epoch:[ 187 11 ] loss: 0.3515625298023224 2022-08-12 01:35:29.735064
Epoch:[ 187 12 ] loss: 0.3526625335216522 2022-08-12 01:35:30.159906
Epoch:[ 187 13 ] loss: 0.35098400712013245 2022-08-12 01:35:30.578520
Epoch:[ 187 14 ] loss: 0.35282188653945923 2022-08-12 01:35:31.004069
Epoch:[ 187 15 ] loss: 0.3518291711807251 2022-08-12 01:35:31.425974
Epoch:[ 187 16 ] loss: 0.352368026971817 2022-08-12 01:35:36.629879
Epoch:[ 187 17 ] loss: 0.3523450493812561 2022-08-12 01:35:37.050850
Epoch:[ 187 18 ] loss: 0.3523634374141693 2022-08-12 01:35:37.477570
Epoch:[ 187 19 ] loss: 0.352117657661438 2022-08-12 01:35:37.900771
Training_Epoch:[ 187 ] Training_loss: 0.35217931121587753 2022-08-12 01:35:37.901480
learning rate:  0.0002145856392222247
val: 1 0.4069114327430725
val: 2 0.40151113271713257
val: 3 0.40590521693229675
val: 4 0.406480610370636
val: 5 0.39929288625717163
val: 6 0.40305274724960327
val: 7 0.4061416685581207
val: 8 0.4085807502269745
val: 9 0.4023342728614807
val: 10 0.4034348428249359
val: 11 0.40645459294319153
val: 12 0.3940735459327698
val: 13 0.4040508270263672
val: 14 0.3972299098968506
val: 15 0.40524256229400635
val: 16 0.3976838290691376
val: 17 0.4079974293708801
val: 18 0.41502854228019714
val: 19 0.4042539596557617
val: 20 0.3976905941963196
val_Epoch:[ 187 ] val_loss: 0.4036675676703453 2022-08-12 01:35:41.418114
start training 2022-08-12 01:35:41.520404
Epoch:[ 188 0 ] loss: 0.35230252146720886 2022-08-12 01:35:56.697761
Epoch:[ 188 1 ] loss: 0.3513132631778717 2022-08-12 01:35:57.121869
Epoch:[ 188 2 ] loss: 0.35194000601768494 2022-08-12 01:35:57.544061
Epoch:[ 188 3 ] loss: 0.35214242339134216 2022-08-12 01:35:57.969439
Epoch:[ 188 4 ] loss: 0.3524089455604553 2022-08-12 01:35:58.389898
Epoch:[ 188 5 ] loss: 0.35057955980300903 2022-08-12 01:35:58.814482
Epoch:[ 188 6 ] loss: 0.3520665764808655 2022-08-12 01:35:59.236064
Epoch:[ 188 7 ] loss: 0.35177314281463623 2022-08-12 01:35:59.660717
Epoch:[ 188 8 ] loss: 0.3523181676864624 2022-08-12 01:36:00.086201
Epoch:[ 188 9 ] loss: 0.35105100274086 2022-08-12 01:36:00.507611
Epoch:[ 188 10 ] loss: 0.3528585135936737 2022-08-12 01:36:00.936597
Epoch:[ 188 11 ] loss: 0.3511301875114441 2022-08-12 01:36:01.353573
Epoch:[ 188 12 ] loss: 0.35150644183158875 2022-08-12 01:36:01.780167
Epoch:[ 188 13 ] loss: 0.35253575444221497 2022-08-12 01:36:02.210185
Epoch:[ 188 14 ] loss: 0.3532394468784332 2022-08-12 01:36:02.635460
Epoch:[ 188 15 ] loss: 0.3511310815811157 2022-08-12 01:36:03.057148
Epoch:[ 188 16 ] loss: 0.3525328040122986 2022-08-12 01:36:08.288383
Epoch:[ 188 17 ] loss: 0.351908802986145 2022-08-12 01:36:08.717818
Epoch:[ 188 18 ] loss: 0.3520585298538208 2022-08-12 01:36:09.148878
Epoch:[ 188 19 ] loss: 0.3520146310329437 2022-08-12 01:36:09.570687
Training_Epoch:[ 188 ] Training_loss: 0.3519405901432037 2022-08-12 01:36:09.571388
learning rate:  0.0002145856392222247
val: 1 0.4047310948371887
val: 2 0.4105025827884674
val: 3 0.40568116307258606
val: 4 0.414533793926239
val: 5 0.39380505681037903
val: 6 0.4037873446941376
val: 7 0.40116891264915466
val: 8 0.4047968089580536
val: 9 0.40763142704963684
val: 10 0.40752938389778137
val: 11 0.41437286138534546
val: 12 0.40176382660865784
val: 13 0.4049609899520874
val: 14 0.40617644786834717
val: 15 0.4040735363960266
val: 16 0.40499407052993774
val: 17 0.40802937746047974
val: 18 0.40215882658958435
val: 19 0.3979838490486145
val: 20 0.40202319622039795
val_Epoch:[ 188 ] val_loss: 0.40503522753715515 2022-08-12 01:36:13.235680
start training 2022-08-12 01:36:13.332108
Epoch:[ 189 0 ] loss: 0.3509024679660797 2022-08-12 01:36:27.863760
Epoch:[ 189 1 ] loss: 0.35269826650619507 2022-08-12 01:36:28.285934
Epoch:[ 189 2 ] loss: 0.35185858607292175 2022-08-12 01:36:28.706900
Epoch:[ 189 3 ] loss: 0.3512752652168274 2022-08-12 01:36:29.121891
Epoch:[ 189 4 ] loss: 0.3529593348503113 2022-08-12 01:36:29.543894
Epoch:[ 189 5 ] loss: 0.351046085357666 2022-08-12 01:36:29.971568
Epoch:[ 189 6 ] loss: 0.3514028787612915 2022-08-12 01:36:30.397782
Epoch:[ 189 7 ] loss: 0.35291776061058044 2022-08-12 01:36:30.819336
Epoch:[ 189 8 ] loss: 0.3520798683166504 2022-08-12 01:36:31.242079
Epoch:[ 189 9 ] loss: 0.35084769129753113 2022-08-12 01:36:31.661907
Epoch:[ 189 10 ] loss: 0.35148870944976807 2022-08-12 01:36:32.082543
Epoch:[ 189 11 ] loss: 0.3522692024707794 2022-08-12 01:36:32.513875
Epoch:[ 189 12 ] loss: 0.35178831219673157 2022-08-12 01:36:32.937703
Epoch:[ 189 13 ] loss: 0.3518887162208557 2022-08-12 01:36:33.358515
Epoch:[ 189 14 ] loss: 0.35158678889274597 2022-08-12 01:36:33.772572
Epoch:[ 189 15 ] loss: 0.3516877591609955 2022-08-12 01:36:34.190825
Epoch:[ 189 16 ] loss: 0.35145002603530884 2022-08-12 01:36:39.437226
Epoch:[ 189 17 ] loss: 0.35312342643737793 2022-08-12 01:36:39.857212
Epoch:[ 189 18 ] loss: 0.35089847445487976 2022-08-12 01:36:40.275254
Epoch:[ 189 19 ] loss: 0.3517889380455017 2022-08-12 01:36:40.693364
Training_Epoch:[ 189 ] Training_loss: 0.35179792791604997 2022-08-12 01:36:40.694107
learning rate:  0.0002145856392222247
val: 1 0.4022740423679352
val: 2 0.4112791419029236
val: 3 0.404300719499588
val: 4 0.40729257464408875
val: 5 0.40462493896484375
val: 6 0.40781170129776
val: 7 0.41135159134864807
val: 8 0.40082019567489624
val: 9 0.40230488777160645
val: 10 0.4090174436569214
val: 11 0.40853673219680786
val: 12 0.3993048071861267
val: 13 0.4016369879245758
val: 14 0.40431949496269226
val: 15 0.4113646149635315
val: 16 0.4069367051124573
val: 17 0.41002538800239563
val: 18 0.39902740716934204
val: 19 0.39702990651130676
val: 20 0.3951435387134552
val_Epoch:[ 189 ] val_loss: 0.4047201409935951 2022-08-12 01:36:44.265033
start training 2022-08-12 01:36:44.365893
Epoch:[ 190 0 ] loss: 0.35220175981521606 2022-08-12 01:36:58.930146
Epoch:[ 190 1 ] loss: 0.35126981139183044 2022-08-12 01:36:59.369483
Epoch:[ 190 2 ] loss: 0.35069385170936584 2022-08-12 01:36:59.792665
Epoch:[ 190 3 ] loss: 0.3511142134666443 2022-08-12 01:37:00.215303
Epoch:[ 190 4 ] loss: 0.3514995276927948 2022-08-12 01:37:00.638434
Epoch:[ 190 5 ] loss: 0.3512986898422241 2022-08-12 01:37:01.063090
Epoch:[ 190 6 ] loss: 0.3502548933029175 2022-08-12 01:37:01.489730
Epoch:[ 190 7 ] loss: 0.35197964310646057 2022-08-12 01:37:01.911406
Epoch:[ 190 8 ] loss: 0.3515705168247223 2022-08-12 01:37:02.323510
Epoch:[ 190 9 ] loss: 0.3504974842071533 2022-08-12 01:37:02.742503
Epoch:[ 190 10 ] loss: 0.35200685262680054 2022-08-12 01:37:03.173924
Epoch:[ 190 11 ] loss: 0.3513396680355072 2022-08-12 01:37:03.597263
Epoch:[ 190 12 ] loss: 0.35071516036987305 2022-08-12 01:37:04.021774
Epoch:[ 190 13 ] loss: 0.35229599475860596 2022-08-12 01:37:04.448568
Epoch:[ 190 14 ] loss: 0.35188043117523193 2022-08-12 01:37:04.873891
Epoch:[ 190 15 ] loss: 0.35105177760124207 2022-08-12 01:37:05.300535
Epoch:[ 190 16 ] loss: 0.352803498506546 2022-08-12 01:37:10.498516
Epoch:[ 190 17 ] loss: 0.3513440191745758 2022-08-12 01:37:10.919064
Epoch:[ 190 18 ] loss: 0.35190942883491516 2022-08-12 01:37:11.343435
Epoch:[ 190 19 ] loss: 0.3524436950683594 2022-08-12 01:37:11.768143
Training_Epoch:[ 190 ] Training_loss: 0.3515085458755493 2022-08-12 01:37:11.768893
learning rate:  0.0002145856392222247
netparams have been saved once 190
val: 1 0.4117765426635742
val: 2 0.4092187285423279
val: 3 0.4074845314025879
val: 4 0.40939435362815857
val: 5 0.40274372696876526
val: 6 0.39889711141586304
val: 7 0.3970038592815399
val: 8 0.4084996283054352
val: 9 0.396653413772583
val: 10 0.40847766399383545
val: 11 0.39827245473861694
val: 12 0.4043199121952057
val: 13 0.4102308452129364
val: 14 0.4039129316806793
val: 15 0.40904179215431213
val: 16 0.4199158549308777
val: 17 0.40015608072280884
val: 18 0.4049074351787567
val: 19 0.40378299355506897
val: 20 0.4144672155380249
val_Epoch:[ 190 ] val_loss: 0.4059578537940979 2022-08-12 01:37:15.432599
start training 2022-08-12 01:37:15.530740
Epoch:[ 191 0 ] loss: 0.3509984612464905 2022-08-12 01:37:30.574648
Epoch:[ 191 1 ] loss: 0.3526943624019623 2022-08-12 01:37:30.999988
Epoch:[ 191 2 ] loss: 0.35077613592147827 2022-08-12 01:37:31.425513
Epoch:[ 191 3 ] loss: 0.35125303268432617 2022-08-12 01:37:31.844022
Epoch:[ 191 4 ] loss: 0.35152146220207214 2022-08-12 01:37:32.267892
Epoch:[ 191 5 ] loss: 0.35180336236953735 2022-08-12 01:37:32.694920
Epoch:[ 191 6 ] loss: 0.35057878494262695 2022-08-12 01:37:33.118372
Epoch:[ 191 7 ] loss: 0.351081907749176 2022-08-12 01:37:33.544482
Epoch:[ 191 8 ] loss: 0.3516121804714203 2022-08-12 01:37:33.970201
Epoch:[ 191 9 ] loss: 0.35137632489204407 2022-08-12 01:37:34.390482
Epoch:[ 191 10 ] loss: 0.35085996985435486 2022-08-12 01:37:34.803408
Epoch:[ 191 11 ] loss: 0.35195016860961914 2022-08-12 01:37:35.222142
Epoch:[ 191 12 ] loss: 0.35056328773498535 2022-08-12 01:37:35.651776
Epoch:[ 191 13 ] loss: 0.3509472608566284 2022-08-12 01:37:36.072266
Epoch:[ 191 14 ] loss: 0.35190820693969727 2022-08-12 01:37:36.492681
Epoch:[ 191 15 ] loss: 0.35076677799224854 2022-08-12 01:37:36.915141
Epoch:[ 191 16 ] loss: 0.35157930850982666 2022-08-12 01:37:42.640240
Epoch:[ 191 17 ] loss: 0.3512701392173767 2022-08-12 01:37:43.063843
Epoch:[ 191 18 ] loss: 0.35221824049949646 2022-08-12 01:37:43.483589
Epoch:[ 191 19 ] loss: 0.3511246144771576 2022-08-12 01:37:43.900174
Training_Epoch:[ 191 ] Training_loss: 0.3513441994786263 2022-08-12 01:37:43.900896
learning rate:  0.000182397793338891
val: 1 0.4071010947227478
val: 2 0.4016653895378113
val: 3 0.40009039640426636
val: 4 0.4081737697124481
val: 5 0.407499223947525
val: 6 0.4039001762866974
val: 7 0.4025113880634308
val: 8 0.39602580666542053
val: 9 0.40519586205482483
val: 10 0.4085516929626465
val: 11 0.40285953879356384
val: 12 0.40389180183410645
val: 13 0.4088292121887207
val: 14 0.4086097180843353
val: 15 0.4041869640350342
val: 16 0.4044535458087921
val: 17 0.4020371735095978
val: 18 0.39991265535354614
val: 19 0.40956875681877136
val: 20 0.411234587430954
val_Epoch:[ 191 ] val_loss: 0.40481493771076205 2022-08-12 01:37:47.429902
start training 2022-08-12 01:37:47.528614
Epoch:[ 192 0 ] loss: 0.351836621761322 2022-08-12 01:38:02.080160
Epoch:[ 192 1 ] loss: 0.3510702848434448 2022-08-12 01:38:02.730111
Epoch:[ 192 2 ] loss: 0.351738840341568 2022-08-12 01:38:03.151855
Epoch:[ 192 3 ] loss: 0.350590318441391 2022-08-12 01:38:03.564291
Epoch:[ 192 4 ] loss: 0.3519762456417084 2022-08-12 01:38:03.988161
Epoch:[ 192 5 ] loss: 0.3511410355567932 2022-08-12 01:38:04.414860
Epoch:[ 192 6 ] loss: 0.351677268743515 2022-08-12 01:38:04.834059
Epoch:[ 192 7 ] loss: 0.3511638343334198 2022-08-12 01:38:05.251702
Epoch:[ 192 8 ] loss: 0.3514201045036316 2022-08-12 01:38:05.678849
Epoch:[ 192 9 ] loss: 0.3520762622356415 2022-08-12 01:38:06.109737
Epoch:[ 192 10 ] loss: 0.3505042493343353 2022-08-12 01:38:06.532575
Epoch:[ 192 11 ] loss: 0.35109615325927734 2022-08-12 01:38:06.955132
Epoch:[ 192 12 ] loss: 0.35083842277526855 2022-08-12 01:38:07.377726
Epoch:[ 192 13 ] loss: 0.35168173909187317 2022-08-12 01:38:07.800847
Epoch:[ 192 14 ] loss: 0.35143131017684937 2022-08-12 01:38:08.226283
Epoch:[ 192 15 ] loss: 0.3517930209636688 2022-08-12 01:38:08.647231
Epoch:[ 192 16 ] loss: 0.3513505756855011 2022-08-12 01:38:13.819144
Epoch:[ 192 17 ] loss: 0.35144495964050293 2022-08-12 01:38:14.236754
Epoch:[ 192 18 ] loss: 0.35139915347099304 2022-08-12 01:38:14.660752
Epoch:[ 192 19 ] loss: 0.35192862153053284 2022-08-12 01:38:15.085387
Training_Epoch:[ 192 ] Training_loss: 0.35140795111656187 2022-08-12 01:38:15.086054
learning rate:  0.000182397793338891
val: 1 0.40324074029922485
val: 2 0.40302446484565735
val: 3 0.4151660203933716
val: 4 0.406266987323761
val: 5 0.399870365858078
val: 6 0.4006395637989044
val: 7 0.39769479632377625
val: 8 0.40578752756118774
val: 9 0.4119614064693451
val: 10 0.40603500604629517
val: 11 0.41251513361930847
val: 12 0.4035795032978058
val: 13 0.3981756269931793
val: 14 0.4086240231990814
val: 15 0.40744972229003906
val: 16 0.4029109477996826
val: 17 0.4077654778957367
val: 18 0.40941348671913147
val: 19 0.40758320689201355
val: 20 0.40842404961586
val_Epoch:[ 192 ] val_loss: 0.405806402862072 2022-08-12 01:38:18.653132
start training 2022-08-12 01:38:18.756834
Epoch:[ 193 0 ] loss: 0.3496306538581848 2022-08-12 01:38:33.272028
Epoch:[ 193 1 ] loss: 0.3509405553340912 2022-08-12 01:38:33.687674
Epoch:[ 193 2 ] loss: 0.35079726576805115 2022-08-12 01:38:34.114236
Epoch:[ 193 3 ] loss: 0.3515492081642151 2022-08-12 01:38:34.541341
Epoch:[ 193 4 ] loss: 0.3514392375946045 2022-08-12 01:38:34.964462
Epoch:[ 193 5 ] loss: 0.3528413474559784 2022-08-12 01:38:35.384525
Epoch:[ 193 6 ] loss: 0.35113760828971863 2022-08-12 01:38:35.808089
Epoch:[ 193 7 ] loss: 0.3520217835903168 2022-08-12 01:38:36.225479
Epoch:[ 193 8 ] loss: 0.35105934739112854 2022-08-12 01:38:36.650289
Epoch:[ 193 9 ] loss: 0.3517654836177826 2022-08-12 01:38:37.075468
Epoch:[ 193 10 ] loss: 0.35090139508247375 2022-08-12 01:38:37.500634
Epoch:[ 193 11 ] loss: 0.3510202467441559 2022-08-12 01:38:37.920317
Epoch:[ 193 12 ] loss: 0.3507239818572998 2022-08-12 01:38:38.335910
Epoch:[ 193 13 ] loss: 0.34995177388191223 2022-08-12 01:38:38.755418
Epoch:[ 193 14 ] loss: 0.35151952505111694 2022-08-12 01:38:39.184140
Epoch:[ 193 15 ] loss: 0.3510160446166992 2022-08-12 01:38:39.604996
Epoch:[ 193 16 ] loss: 0.35173264145851135 2022-08-12 01:38:44.939987
Epoch:[ 193 17 ] loss: 0.35178661346435547 2022-08-12 01:38:45.991719
Epoch:[ 193 18 ] loss: 0.3518765866756439 2022-08-12 01:38:46.418261
Epoch:[ 193 19 ] loss: 0.349980890750885 2022-08-12 01:38:46.837584
Training_Epoch:[ 193 ] Training_loss: 0.35118460953235625 2022-08-12 01:38:46.838300
learning rate:  0.000182397793338891
val: 1 0.4098072052001953
val: 2 0.4039551615715027
val: 3 0.40775349736213684
val: 4 0.4035501480102539
val: 5 0.39872032403945923
val: 6 0.4021023213863373
val: 7 0.409096360206604
val: 8 0.4070051610469818
val: 9 0.40917640924453735
val: 10 0.40009042620658875
val: 11 0.40112245082855225
val: 12 0.397104948759079
val: 13 0.39928099513053894
val: 14 0.4053664207458496
val: 15 0.3994857370853424
val: 16 0.4018668532371521
val: 17 0.4189385771751404
val: 18 0.41867706179618835
val: 19 0.40172335505485535
val: 20 0.4023817181587219
val_Epoch:[ 193 ] val_loss: 0.40486025661230085 2022-08-12 01:38:50.400559
start training 2022-08-12 01:38:50.501963
Epoch:[ 194 0 ] loss: 0.3515372574329376 2022-08-12 01:39:05.179056
Epoch:[ 194 1 ] loss: 0.35018643736839294 2022-08-12 01:39:05.598364
Epoch:[ 194 2 ] loss: 0.3519134223461151 2022-08-12 01:39:06.020312
Epoch:[ 194 3 ] loss: 0.35077017545700073 2022-08-12 01:39:06.443928
Epoch:[ 194 4 ] loss: 0.35062673687934875 2022-08-12 01:39:06.869886
Epoch:[ 194 5 ] loss: 0.3511313796043396 2022-08-12 01:39:07.299624
Epoch:[ 194 6 ] loss: 0.35105621814727783 2022-08-12 01:39:07.722074
Epoch:[ 194 7 ] loss: 0.35184186697006226 2022-08-12 01:39:08.146274
Epoch:[ 194 8 ] loss: 0.35120120644569397 2022-08-12 01:39:08.568365
Epoch:[ 194 9 ] loss: 0.35105791687965393 2022-08-12 01:39:08.989615
Epoch:[ 194 10 ] loss: 0.35081011056900024 2022-08-12 01:39:09.417218
Epoch:[ 194 11 ] loss: 0.3511402904987335 2022-08-12 01:39:09.843435
Epoch:[ 194 12 ] loss: 0.35162219405174255 2022-08-12 01:39:10.265669
Epoch:[ 194 13 ] loss: 0.3507862985134125 2022-08-12 01:39:10.680603
Epoch:[ 194 14 ] loss: 0.35115063190460205 2022-08-12 01:39:11.100263
Epoch:[ 194 15 ] loss: 0.34992504119873047 2022-08-12 01:39:11.523456
Epoch:[ 194 16 ] loss: 0.3510690927505493 2022-08-12 01:39:16.667916
Epoch:[ 194 17 ] loss: 0.35151830315589905 2022-08-12 01:39:17.088938
Epoch:[ 194 18 ] loss: 0.3507523238658905 2022-08-12 01:39:17.502918
Epoch:[ 194 19 ] loss: 0.35117870569229126 2022-08-12 01:39:17.925912
Training_Epoch:[ 194 ] Training_loss: 0.3510637804865837 2022-08-12 01:39:17.926581
learning rate:  0.000182397793338891
val: 1 0.40635013580322266
val: 2 0.4055970013141632
val: 3 0.41120025515556335
val: 4 0.40189120173454285
val: 5 0.3949461579322815
val: 6 0.42053842544555664
val: 7 0.40884721279144287
val: 8 0.4022250473499298
val: 9 0.39904478192329407
val: 10 0.4000279903411865
val: 11 0.4027779698371887
val: 12 0.40645718574523926
val: 13 0.40294668078422546
val: 14 0.4078882336616516
val: 15 0.40512749552726746
val: 16 0.3937820792198181
val: 17 0.39661338925361633
val: 18 0.41445162892341614
val: 19 0.3949308395385742
val: 20 0.4052111804485321
val_Epoch:[ 194 ] val_loss: 0.40404274463653567 2022-08-12 01:39:21.453803
start training 2022-08-12 01:39:21.552414
Epoch:[ 195 0 ] loss: 0.3513716161251068 2022-08-12 01:39:36.144231
Epoch:[ 195 1 ] loss: 0.3503094017505646 2022-08-12 01:39:36.573583
Epoch:[ 195 2 ] loss: 0.35185059905052185 2022-08-12 01:39:36.996001
Epoch:[ 195 3 ] loss: 0.350612998008728 2022-08-12 01:39:37.422239
Epoch:[ 195 4 ] loss: 0.3510047495365143 2022-08-12 01:39:37.846812
Epoch:[ 195 5 ] loss: 0.3518916070461273 2022-08-12 01:39:38.269959
Epoch:[ 195 6 ] loss: 0.3496739864349365 2022-08-12 01:39:38.693938
Epoch:[ 195 7 ] loss: 0.35180380940437317 2022-08-12 01:39:39.112243
Epoch:[ 195 8 ] loss: 0.35052040219306946 2022-08-12 01:39:39.528603
Epoch:[ 195 9 ] loss: 0.3515913486480713 2022-08-12 01:39:39.953085
Epoch:[ 195 10 ] loss: 0.350861132144928 2022-08-12 01:39:40.380985
Epoch:[ 195 11 ] loss: 0.3507736325263977 2022-08-12 01:39:40.800108
Epoch:[ 195 12 ] loss: 0.3520647883415222 2022-08-12 01:39:41.224118
Epoch:[ 195 13 ] loss: 0.3520885705947876 2022-08-12 01:39:41.648653
Epoch:[ 195 14 ] loss: 0.350273072719574 2022-08-12 01:39:42.076156
Epoch:[ 195 15 ] loss: 0.351749062538147 2022-08-12 01:39:42.497886
Epoch:[ 195 16 ] loss: 0.35112279653549194 2022-08-12 01:39:47.780486
Epoch:[ 195 17 ] loss: 0.351753294467926 2022-08-12 01:39:48.207132
Epoch:[ 195 18 ] loss: 0.35083428025245667 2022-08-12 01:39:48.635436
Epoch:[ 195 19 ] loss: 0.35107478499412537 2022-08-12 01:39:49.061156
Training_Epoch:[ 195 ] Training_loss: 0.3511612966656685 2022-08-12 01:39:49.061877
learning rate:  0.000182397793338891
val: 1 0.4041367769241333
val: 2 0.40007147192955017
val: 3 0.4008445739746094
val: 4 0.403825968503952
val: 5 0.3975003957748413
val: 6 0.4053524434566498
val: 7 0.40206655859947205
val: 8 0.40621599555015564
val: 9 0.41155582666397095
val: 10 0.41176068782806396
val: 11 0.4044594168663025
val: 12 0.40635034441947937
val: 13 0.4059833288192749
val: 14 0.41002169251441956
val: 15 0.39502424001693726
val: 16 0.39733365178108215
val: 17 0.3993675112724304
val: 18 0.40845900774002075
val: 19 0.4131379723548889
val: 20 0.39660075306892395
val_Epoch:[ 195 ] val_loss: 0.4040034309029579 2022-08-12 01:39:52.627963
start training 2022-08-12 01:39:52.724976
Epoch:[ 196 0 ] loss: 0.3506079912185669 2022-08-12 01:40:07.521022
Epoch:[ 196 1 ] loss: 0.3519337773323059 2022-08-12 01:40:07.946870
Epoch:[ 196 2 ] loss: 0.3509213924407959 2022-08-12 01:40:08.368303
Epoch:[ 196 3 ] loss: 0.3519904613494873 2022-08-12 01:40:08.788098
Epoch:[ 196 4 ] loss: 0.3510434627532959 2022-08-12 01:40:09.211774
Epoch:[ 196 5 ] loss: 0.35219845175743103 2022-08-12 01:40:09.632525
Epoch:[ 196 6 ] loss: 0.35072803497314453 2022-08-12 01:40:10.059962
Epoch:[ 196 7 ] loss: 0.3515322506427765 2022-08-12 01:40:10.486432
Epoch:[ 196 8 ] loss: 0.3513208329677582 2022-08-12 01:40:10.910826
Epoch:[ 196 9 ] loss: 0.35051271319389343 2022-08-12 01:40:11.328394
Epoch:[ 196 10 ] loss: 0.35052892565727234 2022-08-12 01:40:11.743994
Epoch:[ 196 11 ] loss: 0.3512760400772095 2022-08-12 01:40:12.165821
Epoch:[ 196 12 ] loss: 0.3503563106060028 2022-08-12 01:40:12.595487
Epoch:[ 196 13 ] loss: 0.3513031303882599 2022-08-12 01:40:13.015182
Epoch:[ 196 14 ] loss: 0.34951090812683105 2022-08-12 01:40:13.437978
Epoch:[ 196 15 ] loss: 0.3506355285644531 2022-08-12 01:40:13.859076
Epoch:[ 196 16 ] loss: 0.354072242975235 2022-08-12 01:40:19.322542
Epoch:[ 196 17 ] loss: 0.3520180583000183 2022-08-12 01:40:19.739095
Epoch:[ 196 18 ] loss: 0.352577269077301 2022-08-12 01:40:20.163074
Epoch:[ 196 19 ] loss: 0.3527665138244629 2022-08-12 01:40:20.584961
Training_Epoch:[ 196 ] Training_loss: 0.3513917148113251 2022-08-12 01:40:20.585631
learning rate:  0.000182397793338891
val: 1 0.4002746045589447
val: 2 0.3934991955757141
val: 3 0.4012223482131958
val: 4 0.4039915204048157
val: 5 0.4141508936882019
val: 6 0.40899619460105896
val: 7 0.4113895297050476
val: 8 0.3973098397254944
val: 9 0.4124065935611725
val: 10 0.3994051516056061
val: 11 0.40311095118522644
val: 12 0.39971622824668884
val: 13 0.41119077801704407
val: 14 0.40228283405303955
val: 15 0.40168556571006775
val: 16 0.40893083810806274
val: 17 0.4037511348724365
val: 18 0.4009445607662201
val: 19 0.406162828207016
val: 20 0.4078737199306488
val_Epoch:[ 196 ] val_loss: 0.4044147655367851 2022-08-12 01:40:24.083158
start training 2022-08-12 01:40:24.182787
Epoch:[ 197 0 ] loss: 0.35158464312553406 2022-08-12 01:40:38.469541
Epoch:[ 197 1 ] loss: 0.35119375586509705 2022-08-12 01:40:38.894110
Epoch:[ 197 2 ] loss: 0.35091203451156616 2022-08-12 01:40:39.334310
Epoch:[ 197 3 ] loss: 0.3521111309528351 2022-08-12 01:40:39.762690
Epoch:[ 197 4 ] loss: 0.35184940695762634 2022-08-12 01:40:40.175716
Epoch:[ 197 5 ] loss: 0.35160788893699646 2022-08-12 01:40:40.596799
Epoch:[ 197 6 ] loss: 0.3513406217098236 2022-08-12 01:40:41.028298
Epoch:[ 197 7 ] loss: 0.3505362868309021 2022-08-12 01:40:41.453902
Epoch:[ 197 8 ] loss: 0.3509902358055115 2022-08-12 01:40:41.875267
Epoch:[ 197 9 ] loss: 0.35061386227607727 2022-08-12 01:40:42.294947
Epoch:[ 197 10 ] loss: 0.35066136717796326 2022-08-12 01:40:42.719921
Epoch:[ 197 11 ] loss: 0.3511846959590912 2022-08-12 01:40:43.145101
Epoch:[ 197 12 ] loss: 0.3505572974681854 2022-08-12 01:40:43.576806
Epoch:[ 197 13 ] loss: 0.3513026237487793 2022-08-12 01:40:44.007552
Epoch:[ 197 14 ] loss: 0.35072749853134155 2022-08-12 01:40:44.429153
Epoch:[ 197 15 ] loss: 0.3517877161502838 2022-08-12 01:40:44.854732
Epoch:[ 197 16 ] loss: 0.35144880414009094 2022-08-12 01:40:50.312449
Epoch:[ 197 17 ] loss: 0.35111328959465027 2022-08-12 01:40:50.735020
Epoch:[ 197 18 ] loss: 0.3514602780342102 2022-08-12 01:40:51.153217
Epoch:[ 197 19 ] loss: 0.35181280970573425 2022-08-12 01:40:51.576827
Training_Epoch:[ 197 ] Training_loss: 0.351239812374115 2022-08-12 01:40:51.577588
learning rate:  0.000182397793338891
val: 1 0.40446120500564575
val: 2 0.3988698422908783
val: 3 0.40247467160224915
val: 4 0.41497868299484253
val: 5 0.3980035185813904
val: 6 0.3977435529232025
val: 7 0.4044557213783264
val: 8 0.3982490301132202
val: 9 0.4019051790237427
val: 10 0.4087148606777191
val: 11 0.413065105676651
val: 12 0.3993423581123352
val: 13 0.4056921899318695
val: 14 0.4137071371078491
val: 15 0.40411123633384705
val: 16 0.41144606471061707
val: 17 0.40850988030433655
val: 18 0.3979102671146393
val: 19 0.4054519832134247
val: 20 0.4038868844509125
val_Epoch:[ 197 ] val_loss: 0.40464896857738497 2022-08-12 01:40:55.224265
start training 2022-08-12 01:40:55.320165
Epoch:[ 198 0 ] loss: 0.3508138358592987 2022-08-12 01:41:10.136311
Epoch:[ 198 1 ] loss: 0.35094618797302246 2022-08-12 01:41:10.556592
Epoch:[ 198 2 ] loss: 0.3517288565635681 2022-08-12 01:41:10.981218
Epoch:[ 198 3 ] loss: 0.35097482800483704 2022-08-12 01:41:11.406275
Epoch:[ 198 4 ] loss: 0.3495464622974396 2022-08-12 01:41:11.829020
Epoch:[ 198 5 ] loss: 0.3515187203884125 2022-08-12 01:41:12.246652
Epoch:[ 198 6 ] loss: 0.3519001603126526 2022-08-12 01:41:12.661866
Epoch:[ 198 7 ] loss: 0.35259172320365906 2022-08-12 01:41:13.088685
Epoch:[ 198 8 ] loss: 0.35281580686569214 2022-08-12 01:41:13.516257
Epoch:[ 198 9 ] loss: 0.3521813750267029 2022-08-12 01:41:13.938368
Epoch:[ 198 10 ] loss: 0.351063996553421 2022-08-12 01:41:14.357051
Epoch:[ 198 11 ] loss: 0.3514736294746399 2022-08-12 01:41:14.775717
Epoch:[ 198 12 ] loss: 0.35162413120269775 2022-08-12 01:41:15.198322
Epoch:[ 198 13 ] loss: 0.3515576720237732 2022-08-12 01:41:15.620955
Epoch:[ 198 14 ] loss: 0.3502064347267151 2022-08-12 01:41:16.046517
Epoch:[ 198 15 ] loss: 0.35145077109336853 2022-08-12 01:41:16.470305
Epoch:[ 198 16 ] loss: 0.3517029881477356 2022-08-12 01:41:21.689498
Epoch:[ 198 17 ] loss: 0.3518618643283844 2022-08-12 01:41:22.107793
Epoch:[ 198 18 ] loss: 0.35064244270324707 2022-08-12 01:41:22.536851
Epoch:[ 198 19 ] loss: 0.3503810167312622 2022-08-12 01:41:22.960004
Training_Epoch:[ 198 ] Training_loss: 0.3513491451740265 2022-08-12 01:41:22.960686
learning rate:  0.000182397793338891
val: 1 0.40648332238197327
val: 2 0.409890741109848
val: 3 0.40410423278808594
val: 4 0.4116295278072357
val: 5 0.40311381220817566
val: 6 0.40245112776756287
val: 7 0.41207998991012573
val: 8 0.4026912748813629
val: 9 0.41064387559890747
val: 10 0.4065799117088318
val: 11 0.39777064323425293
val: 12 0.40591856837272644
val: 13 0.41210928559303284
val: 14 0.4061397314071655
val: 15 0.41273409128189087
val: 16 0.401620477437973
val: 17 0.40972062945365906
val: 18 0.40164294838905334
val: 19 0.3969168961048126
val: 20 0.40491533279418945
val_Epoch:[ 198 ] val_loss: 0.40595782101154326 2022-08-12 01:41:26.554719
start training 2022-08-12 01:41:26.659113
Epoch:[ 199 0 ] loss: 0.35137471556663513 2022-08-12 01:41:40.787233
Epoch:[ 199 1 ] loss: 0.3500434458255768 2022-08-12 01:41:41.221140
Epoch:[ 199 2 ] loss: 0.3514736592769623 2022-08-12 01:41:41.641177
Epoch:[ 199 3 ] loss: 0.35123583674430847 2022-08-12 01:41:42.071847
Epoch:[ 199 4 ] loss: 0.35057544708251953 2022-08-12 01:41:42.494935
Epoch:[ 199 5 ] loss: 0.35064688324928284 2022-08-12 01:41:42.920230
Epoch:[ 199 6 ] loss: 0.35076990723609924 2022-08-12 01:41:43.339796
Epoch:[ 199 7 ] loss: 0.3509482145309448 2022-08-12 01:41:43.765141
Epoch:[ 199 8 ] loss: 0.35139384865760803 2022-08-12 01:41:44.191990
Epoch:[ 199 9 ] loss: 0.35179245471954346 2022-08-12 01:41:44.609283
Epoch:[ 199 10 ] loss: 0.35039618611335754 2022-08-12 01:41:45.036212
Epoch:[ 199 11 ] loss: 0.3516616225242615 2022-08-12 01:41:45.458870
Epoch:[ 199 12 ] loss: 0.35076236724853516 2022-08-12 01:41:45.883120
Epoch:[ 199 13 ] loss: 0.3506663143634796 2022-08-12 01:41:46.305276
Epoch:[ 199 14 ] loss: 0.35128968954086304 2022-08-12 01:41:46.729480
Epoch:[ 199 15 ] loss: 0.3517274558544159 2022-08-12 01:41:47.153364
Epoch:[ 199 16 ] loss: 0.35027214884757996 2022-08-12 01:41:52.670332
Epoch:[ 199 17 ] loss: 0.35081759095191956 2022-08-12 01:41:53.089931
Epoch:[ 199 18 ] loss: 0.35073381662368774 2022-08-12 01:41:53.516152
Epoch:[ 199 19 ] loss: 0.3508291244506836 2022-08-12 01:41:53.932842
Training_Epoch:[ 199 ] Training_loss: 0.3509705364704132 2022-08-12 01:41:53.933530
learning rate:  0.000182397793338891
val: 1 0.39747709035873413
val: 2 0.40495726466178894
val: 3 0.40386393666267395
val: 4 0.403091698884964
val: 5 0.40983688831329346
val: 6 0.4092627465724945
val: 7 0.4139144718647003
val: 8 0.40164124965667725
val: 9 0.4036056697368622
val: 10 0.40352705121040344
val: 11 0.39886972308158875
val: 12 0.4047390818595886
val: 13 0.40082210302352905
val: 14 0.40949082374572754
val: 15 0.39740636944770813
val: 16 0.3984561562538147
val: 17 0.4060624837875366
val: 18 0.40471652150154114
val: 19 0.40525949001312256
val: 20 0.4100775122642517
val_Epoch:[ 199 ] val_loss: 0.40435391664505005 2022-08-12 01:41:57.478285
start training 2022-08-12 01:41:57.578762
Epoch:[ 200 0 ] loss: 0.350749671459198 2022-08-12 01:42:11.799847
Epoch:[ 200 1 ] loss: 0.35079532861709595 2022-08-12 01:42:12.232104
Epoch:[ 200 2 ] loss: 0.3500063419342041 2022-08-12 01:42:12.658623
Epoch:[ 200 3 ] loss: 0.35065436363220215 2022-08-12 01:42:13.084083
Epoch:[ 200 4 ] loss: 0.3504924476146698 2022-08-12 01:42:13.507366
Epoch:[ 200 5 ] loss: 0.35039621591567993 2022-08-12 01:42:13.924164
Epoch:[ 200 6 ] loss: 0.3512395918369293 2022-08-12 01:42:14.347909
Epoch:[ 200 7 ] loss: 0.3513871729373932 2022-08-12 01:42:14.770075
Epoch:[ 200 8 ] loss: 0.35086050629615784 2022-08-12 01:42:15.193103
Epoch:[ 200 9 ] loss: 0.35132545232772827 2022-08-12 01:42:15.614301
Epoch:[ 200 10 ] loss: 0.3505869209766388 2022-08-12 01:42:16.036502
Epoch:[ 200 11 ] loss: 0.3511142134666443 2022-08-12 01:42:16.448924
Epoch:[ 200 12 ] loss: 0.3514597415924072 2022-08-12 01:42:16.870551
Epoch:[ 200 13 ] loss: 0.3504907190799713 2022-08-12 01:42:17.299653
Epoch:[ 200 14 ] loss: 0.35051077604293823 2022-08-12 01:42:17.718586
Epoch:[ 200 15 ] loss: 0.35016101598739624 2022-08-12 01:42:18.140394
Epoch:[ 200 16 ] loss: 0.3511058986186981 2022-08-12 01:42:23.679853
Epoch:[ 200 17 ] loss: 0.34995734691619873 2022-08-12 01:42:24.101634
Epoch:[ 200 18 ] loss: 0.35140302777290344 2022-08-12 01:42:24.523181
Epoch:[ 200 19 ] loss: 0.35047125816345215 2022-08-12 01:42:24.945728
Training_Epoch:[ 200 ] Training_loss: 0.35075840055942537 2022-08-12 01:42:24.946467
learning rate:  0.000182397793338891
netparams have been saved once 200
val: 1 0.40966862440109253
val: 2 0.40761426091194153
val: 3 0.403193861246109
val: 4 0.40314823389053345
val: 5 0.406454861164093
val: 6 0.39846500754356384
val: 7 0.40064582228660583
val: 8 0.40019690990448
val: 9 0.4090651571750641
val: 10 0.4030735492706299
val: 11 0.4109998047351837
val: 12 0.399929404258728
val: 13 0.4038739502429962
val: 14 0.4100584089756012
val: 15 0.4102035164833069
val: 16 0.4052281379699707
val: 17 0.4136790633201599
val: 18 0.3999797999858856
val: 19 0.4061156213283539
val: 20 0.4092063903808594
val_Epoch:[ 200 ] val_loss: 0.40554001927375793 2022-08-12 01:42:28.553740
start training 2022-08-12 01:42:28.655699
Epoch:[ 201 0 ] loss: 0.3515804708003998 2022-08-12 01:42:43.288744
Epoch:[ 201 1 ] loss: 0.3496686518192291 2022-08-12 01:42:43.728971
Epoch:[ 201 2 ] loss: 0.3502209186553955 2022-08-12 01:42:44.153880
Epoch:[ 201 3 ] loss: 0.34952545166015625 2022-08-12 01:42:44.575958
Epoch:[ 201 4 ] loss: 0.3505632281303406 2022-08-12 01:42:45.001788
Epoch:[ 201 5 ] loss: 0.34986674785614014 2022-08-12 01:42:45.420052
Epoch:[ 201 6 ] loss: 0.35034382343292236 2022-08-12 01:42:45.836603
Epoch:[ 201 7 ] loss: 0.34885841608047485 2022-08-12 01:42:46.256530
Epoch:[ 201 8 ] loss: 0.35078373551368713 2022-08-12 01:42:46.679163
Epoch:[ 201 9 ] loss: 0.3516882359981537 2022-08-12 01:42:47.105081
Epoch:[ 201 10 ] loss: 0.35046496987342834 2022-08-12 01:42:47.523942
Epoch:[ 201 11 ] loss: 0.35106009244918823 2022-08-12 01:42:47.946377
Epoch:[ 201 12 ] loss: 0.35093414783477783 2022-08-12 01:42:48.371858
Epoch:[ 201 13 ] loss: 0.35050201416015625 2022-08-12 01:42:48.796997
Epoch:[ 201 14 ] loss: 0.35097992420196533 2022-08-12 01:42:49.220892
Epoch:[ 201 15 ] loss: 0.3496811091899872 2022-08-12 01:42:49.644188
Epoch:[ 201 16 ] loss: 0.351211816072464 2022-08-12 01:42:54.932816
Epoch:[ 201 17 ] loss: 0.3522266447544098 2022-08-12 01:42:55.356061
Epoch:[ 201 18 ] loss: 0.3501051664352417 2022-08-12 01:42:55.776636
Epoch:[ 201 19 ] loss: 0.3504212498664856 2022-08-12 01:42:56.200202
Training_Epoch:[ 201 ] Training_loss: 0.35053434073925016 2022-08-12 01:42:56.200917
learning rate:  0.00015503812433805735
val: 1 0.40713632106781006
val: 2 0.40208378434181213
val: 3 0.4049457609653473
val: 4 0.41214022040367126
val: 5 0.4056248962879181
val: 6 0.40109699964523315
val: 7 0.40687358379364014
val: 8 0.40292730927467346
val: 9 0.40852445363998413
val: 10 0.4037584364414215
val: 11 0.4024708569049835
val: 12 0.4001627266407013
val: 13 0.4188421368598938
val: 14 0.39526572823524475
val: 15 0.4005107283592224
val: 16 0.40605124831199646
val: 17 0.4153188169002533
val: 18 0.41903769969940186
val: 19 0.39660128951072693
val: 20 0.40060240030288696
val_Epoch:[ 201 ] val_loss: 0.40549876987934114 2022-08-12 01:42:59.779361
start training 2022-08-12 01:42:59.880943
Epoch:[ 202 0 ] loss: 0.3497054874897003 2022-08-12 01:43:14.422871
Epoch:[ 202 1 ] loss: 0.34902462363243103 2022-08-12 01:43:14.845687
Epoch:[ 202 2 ] loss: 0.351642906665802 2022-08-12 01:43:15.269595
Epoch:[ 202 3 ] loss: 0.350936621427536 2022-08-12 01:43:15.690578
Epoch:[ 202 4 ] loss: 0.34979042410850525 2022-08-12 01:43:16.107943
Epoch:[ 202 5 ] loss: 0.34977012872695923 2022-08-12 01:43:16.532915
Epoch:[ 202 6 ] loss: 0.350768506526947 2022-08-12 01:43:16.958177
Epoch:[ 202 7 ] loss: 0.3495733439922333 2022-08-12 01:43:17.384791
Epoch:[ 202 8 ] loss: 0.35139793157577515 2022-08-12 01:43:17.807248
Epoch:[ 202 9 ] loss: 0.35174238681793213 2022-08-12 01:43:18.232516
Epoch:[ 202 10 ] loss: 0.35084617137908936 2022-08-12 01:43:18.650208
Epoch:[ 202 11 ] loss: 0.35052865743637085 2022-08-12 01:43:19.076469
Epoch:[ 202 12 ] loss: 0.3520696759223938 2022-08-12 01:43:19.500593
Epoch:[ 202 13 ] loss: 0.3507421612739563 2022-08-12 01:43:19.926517
Epoch:[ 202 14 ] loss: 0.35240599513053894 2022-08-12 01:43:20.346600
Epoch:[ 202 15 ] loss: 0.3506212830543518 2022-08-12 01:43:20.762597
Epoch:[ 202 16 ] loss: 0.3509840965270996 2022-08-12 01:43:25.883994
Epoch:[ 202 17 ] loss: 0.3498276472091675 2022-08-12 01:43:26.307444
Epoch:[ 202 18 ] loss: 0.35190561413764954 2022-08-12 01:43:26.745383
Epoch:[ 202 19 ] loss: 0.3507460355758667 2022-08-12 01:43:27.157655
Training_Epoch:[ 202 ] Training_loss: 0.3507514849305153 2022-08-12 01:43:27.158407
learning rate:  0.00015503812433805735
val: 1 0.40014782547950745
val: 2 0.4134428799152374
val: 3 0.39486679434776306
val: 4 0.4179462194442749
val: 5 0.4062524139881134
val: 6 0.40840765833854675
val: 7 0.39779555797576904
val: 8 0.4068083167076111
val: 9 0.40366923809051514
val: 10 0.41215187311172485
val: 11 0.40428197383880615
val: 12 0.4044365882873535
val: 13 0.4068540632724762
val: 14 0.40860554575920105
val: 15 0.4114276170730591
val: 16 0.4034019708633423
val: 17 0.3985620141029358
val: 18 0.4006528854370117
val: 19 0.4041772186756134
val: 20 0.40465980768203735
val_Epoch:[ 202 ] val_loss: 0.405427423119545 2022-08-12 01:43:30.674803
start training 2022-08-12 01:43:30.776021
Epoch:[ 203 0 ] loss: 0.34981095790863037 2022-08-12 01:43:44.596752
Epoch:[ 203 1 ] loss: 0.3505431115627289 2022-08-12 01:43:45.042195
Epoch:[ 203 2 ] loss: 0.3504086136817932 2022-08-12 01:43:45.473275
Epoch:[ 203 3 ] loss: 0.35231590270996094 2022-08-12 01:43:45.897449
Epoch:[ 203 4 ] loss: 0.3508693277835846 2022-08-12 01:43:46.315284
Epoch:[ 203 5 ] loss: 0.3513633906841278 2022-08-12 01:43:46.733682
Epoch:[ 203 6 ] loss: 0.35167157649993896 2022-08-12 01:43:47.155123
Epoch:[ 203 7 ] loss: 0.3503476679325104 2022-08-12 01:43:47.578820
Epoch:[ 203 8 ] loss: 0.34960508346557617 2022-08-12 01:43:47.998208
Epoch:[ 203 9 ] loss: 0.3512573540210724 2022-08-12 01:43:48.415915
Epoch:[ 203 10 ] loss: 0.35053467750549316 2022-08-12 01:43:48.836435
Epoch:[ 203 11 ] loss: 0.3521273136138916 2022-08-12 01:43:49.267864
Epoch:[ 203 12 ] loss: 0.3507946729660034 2022-08-12 01:43:49.693775
Epoch:[ 203 13 ] loss: 0.34985262155532837 2022-08-12 01:43:50.115580
Epoch:[ 203 14 ] loss: 0.34974321722984314 2022-08-12 01:43:50.539788
Epoch:[ 203 15 ] loss: 0.35009506344795227 2022-08-12 01:43:50.960727
Epoch:[ 203 16 ] loss: 0.3508199155330658 2022-08-12 01:43:56.468917
Epoch:[ 203 17 ] loss: 0.3510964810848236 2022-08-12 01:43:56.987262
Epoch:[ 203 18 ] loss: 0.35165807604789734 2022-08-12 01:43:57.413194
Epoch:[ 203 19 ] loss: 0.3507331907749176 2022-08-12 01:43:57.838795
Training_Epoch:[ 203 ] Training_loss: 0.350782410800457 2022-08-12 01:43:57.839488
learning rate:  0.00015503812433805735
val: 1 0.4042867422103882
val: 2 0.40881088376045227
val: 3 0.3973967730998993
val: 4 0.3970908224582672
val: 5 0.40550917387008667
val: 6 0.40472203493118286
val: 7 0.40525534749031067
val: 8 0.402924120426178
val: 9 0.41146430373191833
val: 10 0.4073943793773651
val: 11 0.4046654999256134
val: 12 0.4163540303707123
val: 13 0.40570804476737976
val: 14 0.40092605352401733
val: 15 0.40563496947288513
val: 16 0.4056248366832733
val: 17 0.4097886085510254
val: 18 0.4021552503108978
val: 19 0.40554550290107727
val: 20 0.40262165665626526
val_Epoch:[ 203 ] val_loss: 0.4051939517259598 2022-08-12 01:44:01.446407
start training 2022-08-12 01:44:01.546128
Epoch:[ 204 0 ] loss: 0.3501165211200714 2022-08-12 01:44:16.173768
Epoch:[ 204 1 ] loss: 0.35041213035583496 2022-08-12 01:44:16.591630
Epoch:[ 204 2 ] loss: 0.34994301199913025 2022-08-12 01:44:17.006444
Epoch:[ 204 3 ] loss: 0.350742906332016 2022-08-12 01:44:17.431599
Epoch:[ 204 4 ] loss: 0.35186025500297546 2022-08-12 01:44:17.858124
Epoch:[ 204 5 ] loss: 0.35172322392463684 2022-08-12 01:44:18.288097
Epoch:[ 204 6 ] loss: 0.35052138566970825 2022-08-12 01:44:18.710921
Epoch:[ 204 7 ] loss: 0.35095301270484924 2022-08-12 01:44:19.135515
Epoch:[ 204 8 ] loss: 0.3501710593700409 2022-08-12 01:44:19.556383
Epoch:[ 204 9 ] loss: 0.3506787419319153 2022-08-12 01:44:19.980072
Epoch:[ 204 10 ] loss: 0.3503585159778595 2022-08-12 01:44:20.404869
Epoch:[ 204 11 ] loss: 0.349801629781723 2022-08-12 01:44:20.829247
Epoch:[ 204 12 ] loss: 0.3493984639644623 2022-08-12 01:44:21.249135
Epoch:[ 204 13 ] loss: 0.3509778380393982 2022-08-12 01:44:21.666345
Epoch:[ 204 14 ] loss: 0.3508279025554657 2022-08-12 01:44:22.088483
Epoch:[ 204 15 ] loss: 0.3512254059314728 2022-08-12 01:44:22.517233
Epoch:[ 204 16 ] loss: 0.35081160068511963 2022-08-12 01:44:27.767658
Epoch:[ 204 17 ] loss: 0.3507251441478729 2022-08-12 01:44:28.184389
Epoch:[ 204 18 ] loss: 0.3503498136997223 2022-08-12 01:44:28.604744
Epoch:[ 204 19 ] loss: 0.35068079829216003 2022-08-12 01:44:29.034077
Training_Epoch:[ 204 ] Training_loss: 0.35061396807432177 2022-08-12 01:44:29.034815
learning rate:  0.00015503812433805735
val: 1 0.41323092579841614
val: 2 0.4009639620780945
val: 3 0.3984040319919586
val: 4 0.4083615839481354
val: 5 0.40999558568000793
val: 6 0.3940626084804535
val: 7 0.4050959050655365
val: 8 0.4078943431377411
val: 9 0.40593037009239197
val: 10 0.40431922674179077
val: 11 0.4102762043476105
val: 12 0.4021233320236206
val: 13 0.4098324775695801
val: 14 0.4036967158317566
val: 15 0.40342196822166443
val: 16 0.4047643542289734
val: 17 0.396454393863678
val: 18 0.4122408926486969
val: 19 0.408612996339798
val: 20 0.4129762053489685
val_Epoch:[ 204 ] val_loss: 0.40563290417194364 2022-08-12 01:44:32.609955
start training 2022-08-12 01:44:32.708611
Epoch:[ 205 0 ] loss: 0.3501247465610504 2022-08-12 01:44:47.159148
Epoch:[ 205 1 ] loss: 0.3499721586704254 2022-08-12 01:44:47.579272
Epoch:[ 205 2 ] loss: 0.3498406708240509 2022-08-12 01:44:47.998433
Epoch:[ 205 3 ] loss: 0.3500944972038269 2022-08-12 01:44:48.424767
Epoch:[ 205 4 ] loss: 0.3508754074573517 2022-08-12 01:44:48.848900
Epoch:[ 205 5 ] loss: 0.35057204961776733 2022-08-12 01:44:49.266257
Epoch:[ 205 6 ] loss: 0.35082775354385376 2022-08-12 01:44:49.690264
Epoch:[ 205 7 ] loss: 0.3516165316104889 2022-08-12 01:44:50.118118
Epoch:[ 205 8 ] loss: 0.3500944674015045 2022-08-12 01:44:50.543303
Epoch:[ 205 9 ] loss: 0.35049912333488464 2022-08-12 01:44:50.968213
Epoch:[ 205 10 ] loss: 0.34973666071891785 2022-08-12 01:44:51.392141
Epoch:[ 205 11 ] loss: 0.3512202203273773 2022-08-12 01:44:51.811824
Epoch:[ 205 12 ] loss: 0.3506394028663635 2022-08-12 01:44:52.235184
Epoch:[ 205 13 ] loss: 0.35039910674095154 2022-08-12 01:44:52.659715
Epoch:[ 205 14 ] loss: 0.35092461109161377 2022-08-12 01:44:53.084988
Epoch:[ 205 15 ] loss: 0.35124266147613525 2022-08-12 01:44:53.508861
Epoch:[ 205 16 ] loss: 0.35053128004074097 2022-08-12 01:44:59.132055
Epoch:[ 205 17 ] loss: 0.3506651818752289 2022-08-12 01:44:59.555995
Epoch:[ 205 18 ] loss: 0.3506777286529541 2022-08-12 01:44:59.977672
Epoch:[ 205 19 ] loss: 0.34970855712890625 2022-08-12 01:45:00.400118
Training_Epoch:[ 205 ] Training_loss: 0.3505131408572197 2022-08-12 01:45:00.400763
learning rate:  0.00015503812433805735
val: 1 0.4051283895969391
val: 2 0.40484532713890076
val: 3 0.3994337320327759
val: 4 0.4042770564556122
val: 5 0.4041336476802826
val: 6 0.40270528197288513
val: 7 0.3987809419631958
val: 8 0.4076521098613739
val: 9 0.40484511852264404
val: 10 0.3964122533798218
val: 11 0.4027004539966583
val: 12 0.40525251626968384
val: 13 0.4073946475982666
val: 14 0.4093339443206787
val: 15 0.4027351140975952
val: 16 0.40082815289497375
val: 17 0.4057406187057495
val: 18 0.4152796268463135
val: 19 0.4083992540836334
val: 20 0.41084063053131104
val_Epoch:[ 205 ] val_loss: 0.4048359408974648 2022-08-12 01:45:03.960145
start training 2022-08-12 01:45:04.059177
Epoch:[ 206 0 ] loss: 0.35077884793281555 2022-08-12 01:45:18.194274
Epoch:[ 206 1 ] loss: 0.35094112157821655 2022-08-12 01:45:18.627579
Epoch:[ 206 2 ] loss: 0.3506549298763275 2022-08-12 01:45:19.055569
Epoch:[ 206 3 ] loss: 0.34956520795822144 2022-08-12 01:45:19.474447
Epoch:[ 206 4 ] loss: 0.350630521774292 2022-08-12 01:45:19.902578
Epoch:[ 206 5 ] loss: 0.35028138756752014 2022-08-12 01:45:20.324874
Epoch:[ 206 6 ] loss: 0.35072970390319824 2022-08-12 01:45:20.748207
Epoch:[ 206 7 ] loss: 0.35064995288848877 2022-08-12 01:45:21.170380
Epoch:[ 206 8 ] loss: 0.3496856391429901 2022-08-12 01:45:21.593930
Epoch:[ 206 9 ] loss: 0.35017430782318115 2022-08-12 01:45:22.014632
Epoch:[ 206 10 ] loss: 0.3499491512775421 2022-08-12 01:45:22.435164
Epoch:[ 206 11 ] loss: 0.34931284189224243 2022-08-12 01:45:22.847594
Epoch:[ 206 12 ] loss: 0.35065048933029175 2022-08-12 01:45:23.271550
Epoch:[ 206 13 ] loss: 0.34971341490745544 2022-08-12 01:45:23.695891
Epoch:[ 206 14 ] loss: 0.3508964478969574 2022-08-12 01:45:24.116177
Epoch:[ 206 15 ] loss: 0.3512289226055145 2022-08-12 01:45:24.531931
Epoch:[ 206 16 ] loss: 0.3499516546726227 2022-08-12 01:45:30.112566
Epoch:[ 206 17 ] loss: 0.3502752184867859 2022-08-12 01:45:30.529556
Epoch:[ 206 18 ] loss: 0.3495548665523529 2022-08-12 01:45:30.944137
Epoch:[ 206 19 ] loss: 0.34994783997535706 2022-08-12 01:45:31.367890
Training_Epoch:[ 206 ] Training_loss: 0.3502786234021187 2022-08-12 01:45:31.368585
learning rate:  0.00015503812433805735
val: 1 0.4015290141105652
val: 2 0.40153101086616516
val: 3 0.4018423557281494
val: 4 0.40559667348861694
val: 5 0.4058583974838257
val: 6 0.40681028366088867
val: 7 0.40658894181251526
val: 8 0.40862545371055603
val: 9 0.40595951676368713
val: 10 0.40482115745544434
val: 11 0.40904057025909424
val: 12 0.40933969616889954
val: 13 0.39928311109542847
val: 14 0.40605995059013367
val: 15 0.40818795561790466
val: 16 0.4051893651485443
val: 17 0.4023120105266571
val: 18 0.4012381434440613
val: 19 0.4044519066810608
val: 20 0.4058825373649597
val_Epoch:[ 206 ] val_loss: 0.40500740259885787 2022-08-12 01:45:34.999127
start training 2022-08-12 01:45:35.091497
Epoch:[ 207 0 ] loss: 0.34977009892463684 2022-08-12 01:45:49.795213
Epoch:[ 207 1 ] loss: 0.3504965603351593 2022-08-12 01:45:50.215838
Epoch:[ 207 2 ] loss: 0.3506443202495575 2022-08-12 01:45:50.639373
Epoch:[ 207 3 ] loss: 0.34961676597595215 2022-08-12 01:45:51.063317
Epoch:[ 207 4 ] loss: 0.3510330319404602 2022-08-12 01:45:51.483428
Epoch:[ 207 5 ] loss: 0.35044530034065247 2022-08-12 01:45:51.906106
Epoch:[ 207 6 ] loss: 0.35040077567100525 2022-08-12 01:45:52.336572
Epoch:[ 207 7 ] loss: 0.35069403052330017 2022-08-12 01:45:52.756434
Epoch:[ 207 8 ] loss: 0.3500699996948242 2022-08-12 01:45:53.180858
Epoch:[ 207 9 ] loss: 0.3492218255996704 2022-08-12 01:45:53.607249
Epoch:[ 207 10 ] loss: 0.35090523958206177 2022-08-12 01:45:54.033359
Epoch:[ 207 11 ] loss: 0.3499864339828491 2022-08-12 01:45:54.448743
Epoch:[ 207 12 ] loss: 0.3500833511352539 2022-08-12 01:45:54.873466
Epoch:[ 207 13 ] loss: 0.3497451841831207 2022-08-12 01:45:55.297707
Epoch:[ 207 14 ] loss: 0.35070112347602844 2022-08-12 01:45:55.726041
Epoch:[ 207 15 ] loss: 0.35054320096969604 2022-08-12 01:45:56.152760
Epoch:[ 207 16 ] loss: 0.350364089012146 2022-08-12 01:46:01.384787
Epoch:[ 207 17 ] loss: 0.3493185341358185 2022-08-12 01:46:02.016563
Epoch:[ 207 18 ] loss: 0.3493484556674957 2022-08-12 01:46:02.442530
Epoch:[ 207 19 ] loss: 0.35080957412719727 2022-08-12 01:46:02.865031
Training_Epoch:[ 207 ] Training_loss: 0.3502098947763443 2022-08-12 01:46:02.865769
learning rate:  0.00015503812433805735
val: 1 0.4061849117279053
val: 2 0.4099099040031433
val: 3 0.40519434213638306
val: 4 0.4092085063457489
val: 5 0.40447747707366943
val: 6 0.40852048993110657
val: 7 0.40748515725135803
val: 8 0.40010830760002136
val: 9 0.40773895382881165
val: 10 0.40183889865875244
val: 11 0.4066964387893677
val: 12 0.41198691725730896
val: 13 0.4080466628074646
val: 14 0.3981948792934418
val: 15 0.39827674627304077
val: 16 0.40274855494499207
val: 17 0.41013792157173157
val: 18 0.4040977358818054
val: 19 0.4028398096561432
val: 20 0.40201011300086975
val_Epoch:[ 207 ] val_loss: 0.4052851364016533 2022-08-12 01:46:06.536289
start training 2022-08-12 01:46:06.632353
Epoch:[ 208 0 ] loss: 0.3503086268901825 2022-08-12 01:46:21.247055
Epoch:[ 208 1 ] loss: 0.34991729259490967 2022-08-12 01:46:21.689745
Epoch:[ 208 2 ] loss: 0.3497166335582733 2022-08-12 01:46:22.114801
Epoch:[ 208 3 ] loss: 0.3497541546821594 2022-08-12 01:46:22.540202
Epoch:[ 208 4 ] loss: 0.35026201605796814 2022-08-12 01:46:22.966426
Epoch:[ 208 5 ] loss: 0.35026928782463074 2022-08-12 01:46:23.383654
Epoch:[ 208 6 ] loss: 0.3494924008846283 2022-08-12 01:46:23.799714
Epoch:[ 208 7 ] loss: 0.3499162495136261 2022-08-12 01:46:24.224306
Epoch:[ 208 8 ] loss: 0.3500702679157257 2022-08-12 01:46:24.649417
Epoch:[ 208 9 ] loss: 0.35073602199554443 2022-08-12 01:46:25.067037
Epoch:[ 208 10 ] loss: 0.3503226041793823 2022-08-12 01:46:25.487870
Epoch:[ 208 11 ] loss: 0.3502527177333832 2022-08-12 01:46:25.912192
Epoch:[ 208 12 ] loss: 0.3506908416748047 2022-08-12 01:46:26.339157
Epoch:[ 208 13 ] loss: 0.35066911578178406 2022-08-12 01:46:26.757402
Epoch:[ 208 14 ] loss: 0.3528507351875305 2022-08-12 01:46:27.180630
Epoch:[ 208 15 ] loss: 0.3515264689922333 2022-08-12 01:46:27.610056
Epoch:[ 208 16 ] loss: 0.3514878749847412 2022-08-12 01:46:32.882211
Epoch:[ 208 17 ] loss: 0.3495636582374573 2022-08-12 01:46:33.300737
Epoch:[ 208 18 ] loss: 0.35107097029685974 2022-08-12 01:46:33.733470
Epoch:[ 208 19 ] loss: 0.35065433382987976 2022-08-12 01:46:34.154070
Training_Epoch:[ 208 ] Training_loss: 0.3504766136407852 2022-08-12 01:46:34.154771
learning rate:  0.00015503812433805735
val: 1 0.40651464462280273
val: 2 0.41244637966156006
val: 3 0.4117349684238434
val: 4 0.4036063253879547
val: 5 0.4076135456562042
val: 6 0.4038183093070984
val: 7 0.39394497871398926
val: 8 0.40569359064102173
val: 9 0.4112946689128876
val: 10 0.4073634743690491
val: 11 0.39422911405563354
val: 12 0.4025425612926483
val: 13 0.4055138826370239
val: 14 0.40312373638153076
val: 15 0.4010302722454071
val: 16 0.4048902690410614
val: 17 0.41067129373550415
val: 18 0.41113168001174927
val: 19 0.40383824706077576
val: 20 0.4018191397190094
val_Epoch:[ 208 ] val_loss: 0.4051410540938377 2022-08-12 01:46:37.725414
start training 2022-08-12 01:46:37.819889
Epoch:[ 209 0 ] loss: 0.34963998198509216 2022-08-12 01:46:52.306335
Epoch:[ 209 1 ] loss: 0.3504122495651245 2022-08-12 01:46:52.731107
Epoch:[ 209 2 ] loss: 0.35018956661224365 2022-08-12 01:46:53.153930
Epoch:[ 209 3 ] loss: 0.3496023416519165 2022-08-12 01:46:53.573157
Epoch:[ 209 4 ] loss: 0.35105597972869873 2022-08-12 01:46:53.996489
Epoch:[ 209 5 ] loss: 0.350431889295578 2022-08-12 01:46:54.422017
Epoch:[ 209 6 ] loss: 0.35117173194885254 2022-08-12 01:46:54.847783
Epoch:[ 209 7 ] loss: 0.3507806956768036 2022-08-12 01:46:55.267069
Epoch:[ 209 8 ] loss: 0.34954774379730225 2022-08-12 01:46:55.689410
Epoch:[ 209 9 ] loss: 0.3501749634742737 2022-08-12 01:46:56.111948
Epoch:[ 209 10 ] loss: 0.3514208197593689 2022-08-12 01:46:56.539029
Epoch:[ 209 11 ] loss: 0.3504350781440735 2022-08-12 01:46:56.962574
Epoch:[ 209 12 ] loss: 0.3507498502731323 2022-08-12 01:46:57.385065
Epoch:[ 209 13 ] loss: 0.35152944922447205 2022-08-12 01:46:57.814965
Epoch:[ 209 14 ] loss: 0.3498225808143616 2022-08-12 01:46:58.236560
Epoch:[ 209 15 ] loss: 0.3500972390174866 2022-08-12 01:46:58.648818
Epoch:[ 209 16 ] loss: 0.3513788878917694 2022-08-12 01:47:03.837533
Epoch:[ 209 17 ] loss: 0.35015127062797546 2022-08-12 01:47:04.262762
Epoch:[ 209 18 ] loss: 0.3499344289302826 2022-08-12 01:47:04.681375
Epoch:[ 209 19 ] loss: 0.3504783809185028 2022-08-12 01:47:05.093280
Training_Epoch:[ 209 ] Training_loss: 0.35045025646686556 2022-08-12 01:47:05.093968
learning rate:  0.00015503812433805735
val: 1 0.40379971265792847
val: 2 0.41222262382507324
val: 3 0.4030372202396393
val: 4 0.4108450412750244
val: 5 0.40366530418395996
val: 6 0.40364399552345276
val: 7 0.40304380655288696
val: 8 0.41178080439567566
val: 9 0.40627163648605347
val: 10 0.4021483361721039
val: 11 0.4034269452095032
val: 12 0.40118151903152466
val: 13 0.40823131799697876
val: 14 0.3979560434818268
val: 15 0.4133806526660919
val: 16 0.4067142903804779
val: 17 0.40845987200737
val: 18 0.4041675329208374
val: 19 0.40875986218452454
val: 20 0.407112181186676
val_Epoch:[ 209 ] val_loss: 0.4059924349188805 2022-08-12 01:47:08.654333
start training 2022-08-12 01:47:08.748185
Epoch:[ 210 0 ] loss: 0.34986329078674316 2022-08-12 01:47:22.942512
Epoch:[ 210 1 ] loss: 0.35047245025634766 2022-08-12 01:47:23.378139
Epoch:[ 210 2 ] loss: 0.3502742350101471 2022-08-12 01:47:23.801507
Epoch:[ 210 3 ] loss: 0.350889652967453 2022-08-12 01:47:24.221729
Epoch:[ 210 4 ] loss: 0.3493577539920807 2022-08-12 01:47:24.634856
Epoch:[ 210 5 ] loss: 0.35100018978118896 2022-08-12 01:47:25.060508
Epoch:[ 210 6 ] loss: 0.3500918447971344 2022-08-12 01:47:25.486624
Epoch:[ 210 7 ] loss: 0.34998559951782227 2022-08-12 01:47:25.907236
Epoch:[ 210 8 ] loss: 0.3508475720882416 2022-08-12 01:47:26.322841
Epoch:[ 210 9 ] loss: 0.3503841459751129 2022-08-12 01:47:26.748118
Epoch:[ 210 10 ] loss: 0.3505922257900238 2022-08-12 01:47:27.172460
Epoch:[ 210 11 ] loss: 0.3495407700538635 2022-08-12 01:47:27.599036
Epoch:[ 210 12 ] loss: 0.35021674633026123 2022-08-12 01:47:28.022922
Epoch:[ 210 13 ] loss: 0.35007205605506897 2022-08-12 01:47:28.446126
Epoch:[ 210 14 ] loss: 0.3507394790649414 2022-08-12 01:47:28.873617
Epoch:[ 210 15 ] loss: 0.3496914505958557 2022-08-12 01:47:29.297605
Epoch:[ 210 16 ] loss: 0.3505513370037079 2022-08-12 01:47:34.992851
Epoch:[ 210 17 ] loss: 0.3499022126197815 2022-08-12 01:47:35.416195
Epoch:[ 210 18 ] loss: 0.35055023431777954 2022-08-12 01:47:35.845591
Epoch:[ 210 19 ] loss: 0.34997519850730896 2022-08-12 01:47:36.267492
Training_Epoch:[ 210 ] Training_loss: 0.3502499222755432 2022-08-12 01:47:36.268159
learning rate:  0.00015503812433805735
netparams have been saved once 210
val: 1 0.4063672721385956
val: 2 0.4026557207107544
val: 3 0.413458913564682
val: 4 0.39841702580451965
val: 5 0.40743133425712585
val: 6 0.3985573947429657
val: 7 0.4114651381969452
val: 8 0.39847540855407715
val: 9 0.4062676727771759
val: 10 0.40001797676086426
val: 11 0.4034591615200043
val: 12 0.41379326581954956
val: 13 0.4035797417163849
val: 14 0.40384340286254883
val: 15 0.40593013167381287
val: 16 0.40750205516815186
val: 17 0.40777388215065
val: 18 0.3977065086364746
val: 19 0.4108617901802063
val: 20 0.4069271981716156
val_Epoch:[ 210 ] val_loss: 0.4052245497703552 2022-08-12 01:47:39.831081
start training 2022-08-12 01:47:39.923954
Epoch:[ 211 0 ] loss: 0.34956762194633484 2022-08-12 01:47:54.262476
Epoch:[ 211 1 ] loss: 0.3501166105270386 2022-08-12 01:47:54.790396
Epoch:[ 211 2 ] loss: 0.3514500856399536 2022-08-12 01:47:55.214537
Epoch:[ 211 3 ] loss: 0.34944501519203186 2022-08-12 01:47:55.641105
Epoch:[ 211 4 ] loss: 0.3500857949256897 2022-08-12 01:47:56.064399
Epoch:[ 211 5 ] loss: 0.3481568396091461 2022-08-12 01:47:56.487621
Epoch:[ 211 6 ] loss: 0.3497561812400818 2022-08-12 01:47:56.911409
Epoch:[ 211 7 ] loss: 0.35029545426368713 2022-08-12 01:47:57.335164
Epoch:[ 211 8 ] loss: 0.3509483337402344 2022-08-12 01:47:57.760288
Epoch:[ 211 9 ] loss: 0.3510113060474396 2022-08-12 01:47:58.185351
Epoch:[ 211 10 ] loss: 0.3498462736606598 2022-08-12 01:47:58.610739
Epoch:[ 211 11 ] loss: 0.34973952174186707 2022-08-12 01:47:59.028411
Epoch:[ 211 12 ] loss: 0.35032954812049866 2022-08-12 01:47:59.443397
Epoch:[ 211 13 ] loss: 0.35083508491516113 2022-08-12 01:47:59.863473
Epoch:[ 211 14 ] loss: 0.35057222843170166 2022-08-12 01:48:00.287884
Epoch:[ 211 15 ] loss: 0.3508231043815613 2022-08-12 01:48:00.708858
Epoch:[ 211 16 ] loss: 0.3511096239089966 2022-08-12 01:48:05.929212
Epoch:[ 211 17 ] loss: 0.3502444624900818 2022-08-12 01:48:06.367709
Epoch:[ 211 18 ] loss: 0.34923985600471497 2022-08-12 01:48:06.794700
Epoch:[ 211 19 ] loss: 0.3497503399848938 2022-08-12 01:48:07.216232
Training_Epoch:[ 211 ] Training_loss: 0.3501661643385887 2022-08-12 01:48:07.216940
learning rate:  0.00013178240568734875
val: 1 0.4063732624053955
val: 2 0.4033782482147217
val: 3 0.4068031311035156
val: 4 0.40731605887413025
val: 5 0.40572836995124817
val: 6 0.41899365186691284
val: 7 0.4017343819141388
val: 8 0.4069274365901947
val: 9 0.4010317325592041
val: 10 0.3990592658519745
val: 11 0.40963393449783325
val: 12 0.40777432918548584
val: 13 0.4088779389858246
val: 14 0.40698039531707764
val: 15 0.40357527136802673
val: 16 0.4059445858001709
val: 17 0.4020497798919678
val: 18 0.3982592225074768
val: 19 0.4041077494621277
val: 20 0.40343132615089417
val_Epoch:[ 211 ] val_loss: 0.4053990036249161 2022-08-12 01:48:10.814139
start training 2022-08-12 01:48:10.908960
Epoch:[ 212 0 ] loss: 0.3488443195819855 2022-08-12 01:48:25.137793
Epoch:[ 212 1 ] loss: 0.3494546115398407 2022-08-12 01:48:25.577150
Epoch:[ 212 2 ] loss: 0.35067349672317505 2022-08-12 01:48:26.000280
Epoch:[ 212 3 ] loss: 0.35007593035697937 2022-08-12 01:48:26.424756
Epoch:[ 212 4 ] loss: 0.34798407554626465 2022-08-12 01:48:26.845290
Epoch:[ 212 5 ] loss: 0.3501599431037903 2022-08-12 01:48:27.260172
Epoch:[ 212 6 ] loss: 0.3494267463684082 2022-08-12 01:48:27.686854
Epoch:[ 212 7 ] loss: 0.34868425130844116 2022-08-12 01:48:28.112248
Epoch:[ 212 8 ] loss: 0.3503859341144562 2022-08-12 01:48:28.535230
Epoch:[ 212 9 ] loss: 0.34988582134246826 2022-08-12 01:48:28.958166
Epoch:[ 212 10 ] loss: 0.35027727484703064 2022-08-12 01:48:29.379107
Epoch:[ 212 11 ] loss: 0.3495282530784607 2022-08-12 01:48:29.803034
Epoch:[ 212 12 ] loss: 0.3517981469631195 2022-08-12 01:48:30.226710
Epoch:[ 212 13 ] loss: 0.3495992422103882 2022-08-12 01:48:30.645790
Epoch:[ 212 14 ] loss: 0.3507598042488098 2022-08-12 01:48:31.072038
Epoch:[ 212 15 ] loss: 0.3508587181568146 2022-08-12 01:48:31.498484
Epoch:[ 212 16 ] loss: 0.3495253920555115 2022-08-12 01:48:37.065029
Epoch:[ 212 17 ] loss: 0.35056209564208984 2022-08-12 01:48:37.486157
Epoch:[ 212 18 ] loss: 0.34978824853897095 2022-08-12 01:48:37.908265
Epoch:[ 212 19 ] loss: 0.3514445424079895 2022-08-12 01:48:38.329345
Training_Epoch:[ 212 ] Training_loss: 0.34998584240674974 2022-08-12 01:48:38.330094
learning rate:  0.00013178240568734875
val: 1 0.40730583667755127
val: 2 0.40347859263420105
val: 3 0.403167188167572
val: 4 0.40360790491104126
val: 5 0.403078556060791
val: 6 0.41338399052619934
val: 7 0.3987652063369751
val: 8 0.4138261079788208
val: 9 0.39892876148223877
val: 10 0.41972681879997253
val: 11 0.39989933371543884
val: 12 0.4147268533706665
val: 13 0.414745032787323
val: 14 0.40864983201026917
val: 15 0.40474027395248413
val: 16 0.4049786925315857
val: 17 0.40911710262298584
val: 18 0.4110448360443115
val: 19 0.3970002830028534
val: 20 0.41005051136016846
val_Epoch:[ 212 ] val_loss: 0.4070110857486725 2022-08-12 01:48:41.839558
start training 2022-08-12 01:48:41.931758
Epoch:[ 213 0 ] loss: 0.35042664408683777 2022-08-12 01:48:56.716664
Epoch:[ 213 1 ] loss: 0.3504650592803955 2022-08-12 01:48:57.142007
Epoch:[ 213 2 ] loss: 0.35040774941444397 2022-08-12 01:48:57.566022
Epoch:[ 213 3 ] loss: 0.3504805564880371 2022-08-12 01:48:57.985235
Epoch:[ 213 4 ] loss: 0.35028865933418274 2022-08-12 01:48:58.415596
Epoch:[ 213 5 ] loss: 0.35068538784980774 2022-08-12 01:48:58.838034
Epoch:[ 213 6 ] loss: 0.35003265738487244 2022-08-12 01:48:59.260314
Epoch:[ 213 7 ] loss: 0.34964463114738464 2022-08-12 01:48:59.685024
Epoch:[ 213 8 ] loss: 0.3507896661758423 2022-08-12 01:49:00.109035
Epoch:[ 213 9 ] loss: 0.34872639179229736 2022-08-12 01:49:00.520935
Epoch:[ 213 10 ] loss: 0.3488749563694 2022-08-12 01:49:00.945294
Epoch:[ 213 11 ] loss: 0.3505484461784363 2022-08-12 01:49:01.368935
Epoch:[ 213 12 ] loss: 0.3493446409702301 2022-08-12 01:49:01.789629
Epoch:[ 213 13 ] loss: 0.3499584197998047 2022-08-12 01:49:02.204809
Epoch:[ 213 14 ] loss: 0.34935858845710754 2022-08-12 01:49:02.630865
Epoch:[ 213 15 ] loss: 0.349409282207489 2022-08-12 01:49:03.058801
Epoch:[ 213 16 ] loss: 0.34991270303726196 2022-08-12 01:49:08.254594
Epoch:[ 213 17 ] loss: 0.35042712092399597 2022-08-12 01:49:08.772172
Epoch:[ 213 18 ] loss: 0.34894898533821106 2022-08-12 01:49:09.196030
Epoch:[ 213 19 ] loss: 0.35111692547798157 2022-08-12 01:49:09.620941
Training_Epoch:[ 213 ] Training_loss: 0.349992373585701 2022-08-12 01:49:09.621604
learning rate:  0.00013178240568734875
val: 1 0.40565571188926697
val: 2 0.40084606409072876
val: 3 0.4014628231525421
val: 4 0.4033101499080658
val: 5 0.40236005187034607
val: 6 0.40016770362854004
val: 7 0.40370315313339233
val: 8 0.40615031123161316
val: 9 0.40551304817199707
val: 10 0.4067099094390869
val: 11 0.4006796181201935
val: 12 0.4170592725276947
val: 13 0.4099574685096741
val: 14 0.41002005338668823
val: 15 0.40408438444137573
val: 16 0.4058080017566681
val: 17 0.40768909454345703
val: 18 0.40499168634414673
val: 19 0.4127230942249298
val: 20 0.40438783168792725
val_Epoch:[ 213 ] val_loss: 0.40566397160291673 2022-08-12 01:49:13.139691
start training 2022-08-12 01:49:13.233417
Epoch:[ 214 0 ] loss: 0.3493536412715912 2022-08-12 01:49:27.420988
Epoch:[ 214 1 ] loss: 0.34978029131889343 2022-08-12 01:49:27.932436
Epoch:[ 214 2 ] loss: 0.35120198130607605 2022-08-12 01:49:28.356059
Epoch:[ 214 3 ] loss: 0.3490520119667053 2022-08-12 01:49:28.781523
Epoch:[ 214 4 ] loss: 0.34994015097618103 2022-08-12 01:49:29.202328
Epoch:[ 214 5 ] loss: 0.3498819172382355 2022-08-12 01:49:29.622715
Epoch:[ 214 6 ] loss: 0.349137544631958 2022-08-12 01:49:30.051865
Epoch:[ 214 7 ] loss: 0.350952684879303 2022-08-12 01:49:30.471337
Epoch:[ 214 8 ] loss: 0.34882330894470215 2022-08-12 01:49:30.893381
Epoch:[ 214 9 ] loss: 0.3494180142879486 2022-08-12 01:49:31.319118
Epoch:[ 214 10 ] loss: 0.3498019278049469 2022-08-12 01:49:31.743837
Epoch:[ 214 11 ] loss: 0.3506682217121124 2022-08-12 01:49:32.163030
Epoch:[ 214 12 ] loss: 0.34918227791786194 2022-08-12 01:49:32.586064
Epoch:[ 214 13 ] loss: 0.3506876230239868 2022-08-12 01:49:33.009172
Epoch:[ 214 14 ] loss: 0.349519282579422 2022-08-12 01:49:33.435445
Epoch:[ 214 15 ] loss: 0.3501359522342682 2022-08-12 01:49:33.860624
Epoch:[ 214 16 ] loss: 0.3505404591560364 2022-08-12 01:49:39.113365
Epoch:[ 214 17 ] loss: 0.3506632149219513 2022-08-12 01:49:39.983682
Epoch:[ 214 18 ] loss: 0.34897512197494507 2022-08-12 01:49:40.409461
Epoch:[ 214 19 ] loss: 0.3503190875053406 2022-08-12 01:49:40.830427
Training_Epoch:[ 214 ] Training_loss: 0.3499017357826233 2022-08-12 01:49:40.831114
learning rate:  0.00013178240568734875
val: 1 0.39612218737602234
val: 2 0.4103127419948578
val: 3 0.40619146823883057
val: 4 0.4068753123283386
val: 5 0.40853917598724365
val: 6 0.40941911935806274
val: 7 0.40830132365226746
val: 8 0.4059694707393646
val: 9 0.40033861994743347
val: 10 0.4064140021800995
val: 11 0.39866533875465393
val: 12 0.39848509430885315
val: 13 0.40817752480506897
val: 14 0.39857763051986694
val: 15 0.41336962580680847
val: 16 0.41373541951179504
val: 17 0.40548190474510193
val: 18 0.40720003843307495
val: 19 0.41092246770858765
val: 20 0.40119773149490356
val_Epoch:[ 214 ] val_loss: 0.40571480989456177 2022-08-12 01:49:44.346366
start training 2022-08-12 01:49:44.440763
Epoch:[ 215 0 ] loss: 0.3508330285549164 2022-08-12 01:49:58.505093
Epoch:[ 215 1 ] loss: 0.35024353861808777 2022-08-12 01:49:58.927030
Epoch:[ 215 2 ] loss: 0.34957602620124817 2022-08-12 01:49:59.371321
Epoch:[ 215 3 ] loss: 0.3499704897403717 2022-08-12 01:49:59.795582
Epoch:[ 215 4 ] loss: 0.35007384419441223 2022-08-12 01:50:00.219314
Epoch:[ 215 5 ] loss: 0.3492724299430847 2022-08-12 01:50:00.641092
Epoch:[ 215 6 ] loss: 0.34941789507865906 2022-08-12 01:50:01.059657
Epoch:[ 215 7 ] loss: 0.3517404794692993 2022-08-12 01:50:01.474834
Epoch:[ 215 8 ] loss: 0.3486289083957672 2022-08-12 01:50:01.897819
Epoch:[ 215 9 ] loss: 0.35061535239219666 2022-08-12 01:50:02.324409
Epoch:[ 215 10 ] loss: 0.34967291355133057 2022-08-12 01:50:02.743534
Epoch:[ 215 11 ] loss: 0.35091036558151245 2022-08-12 01:50:03.161990
Epoch:[ 215 12 ] loss: 0.35017988085746765 2022-08-12 01:50:03.586195
Epoch:[ 215 13 ] loss: 0.34936806559562683 2022-08-12 01:50:04.016445
Epoch:[ 215 14 ] loss: 0.3505248427391052 2022-08-12 01:50:04.436608
Epoch:[ 215 15 ] loss: 0.35054919123649597 2022-08-12 01:50:04.858517
Epoch:[ 215 16 ] loss: 0.35002949833869934 2022-08-12 01:50:10.487665
Epoch:[ 215 17 ] loss: 0.3516388535499573 2022-08-12 01:50:10.910552
Epoch:[ 215 18 ] loss: 0.34977367520332336 2022-08-12 01:50:11.336131
Epoch:[ 215 19 ] loss: 0.34963592886924744 2022-08-12 01:50:11.758495
Training_Epoch:[ 215 ] Training_loss: 0.3501327604055405 2022-08-12 01:50:11.759189
learning rate:  0.00013178240568734875
val: 1 0.39904189109802246
val: 2 0.4059528112411499
val: 3 0.4129176735877991
val: 4 0.4070337116718292
val: 5 0.40033966302871704
val: 6 0.40401148796081543
val: 7 0.4123602509498596
val: 8 0.40745779871940613
val: 9 0.4081108272075653
val: 10 0.4035024046897888
val: 11 0.40079987049102783
val: 12 0.4052717685699463
val: 13 0.41317179799079895
val: 14 0.3983938694000244
val: 15 0.4061312675476074
val: 16 0.4079171419143677
val: 17 0.40034225583076477
val: 18 0.4187394678592682
val: 19 0.4050105810165405
val: 20 0.40755289793014526
val_Epoch:[ 215 ] val_loss: 0.4062029719352722 2022-08-12 01:50:15.310872
start training 2022-08-12 01:50:15.402973
Epoch:[ 216 0 ] loss: 0.3497041165828705 2022-08-12 01:50:30.101216
Epoch:[ 216 1 ] loss: 0.3489755094051361 2022-08-12 01:50:30.531300
Epoch:[ 216 2 ] loss: 0.34992292523384094 2022-08-12 01:50:30.955785
Epoch:[ 216 3 ] loss: 0.34936556220054626 2022-08-12 01:50:31.378561
Epoch:[ 216 4 ] loss: 0.34885546565055847 2022-08-12 01:50:31.801145
Epoch:[ 216 5 ] loss: 0.34997043013572693 2022-08-12 01:50:32.227081
Epoch:[ 216 6 ] loss: 0.35037940740585327 2022-08-12 01:50:32.653103
Epoch:[ 216 7 ] loss: 0.3503945767879486 2022-08-12 01:50:33.069078
Epoch:[ 216 8 ] loss: 0.35008129477500916 2022-08-12 01:50:33.492436
Epoch:[ 216 9 ] loss: 0.34944215416908264 2022-08-12 01:50:33.915755
Epoch:[ 216 10 ] loss: 0.35009413957595825 2022-08-12 01:50:34.341358
Epoch:[ 216 11 ] loss: 0.35027605295181274 2022-08-12 01:50:34.769561
Epoch:[ 216 12 ] loss: 0.34987732768058777 2022-08-12 01:50:35.194231
Epoch:[ 216 13 ] loss: 0.34986376762390137 2022-08-12 01:50:35.623860
Epoch:[ 216 14 ] loss: 0.3489472270011902 2022-08-12 01:50:36.041741
Epoch:[ 216 15 ] loss: 0.34988975524902344 2022-08-12 01:50:36.459254
Epoch:[ 216 16 ] loss: 0.3498506247997284 2022-08-12 01:50:41.876234
Epoch:[ 216 17 ] loss: 0.35053494572639465 2022-08-12 01:50:42.294752
Epoch:[ 216 18 ] loss: 0.35053175687789917 2022-08-12 01:50:42.713188
Epoch:[ 216 19 ] loss: 0.34933197498321533 2022-08-12 01:50:43.132285
Training_Epoch:[ 216 ] Training_loss: 0.3498144507408142 2022-08-12 01:50:43.132997
learning rate:  0.00013178240568734875
val: 1 0.4033752381801605
val: 2 0.40452712774276733
val: 3 0.4108913838863373
val: 4 0.39421385526657104
val: 5 0.40739530324935913
val: 6 0.40078526735305786
val: 7 0.4142480790615082
val: 8 0.4137270450592041
val: 9 0.39815035462379456
val: 10 0.4042266607284546
val: 11 0.40292227268218994
val: 12 0.4097498953342438
val: 13 0.40458500385284424
val: 14 0.41211581230163574
val: 15 0.4078975021839142
val: 16 0.4006594717502594
val: 17 0.40900588035583496
val: 18 0.40011048316955566
val: 19 0.41147586703300476
val: 20 0.40714535117149353
val_Epoch:[ 216 ] val_loss: 0.4058603927493095 2022-08-12 01:50:46.665075
start training 2022-08-12 01:50:46.760207
Epoch:[ 217 0 ] loss: 0.3498286008834839 2022-08-12 01:51:01.071607
Epoch:[ 217 1 ] loss: 0.34997257590293884 2022-08-12 01:51:01.508435
Epoch:[ 217 2 ] loss: 0.3502589762210846 2022-08-12 01:51:01.930005
Epoch:[ 217 3 ] loss: 0.3500494956970215 2022-08-12 01:51:02.344001
Epoch:[ 217 4 ] loss: 0.34948399662971497 2022-08-12 01:51:02.767496
Epoch:[ 217 5 ] loss: 0.34942659735679626 2022-08-12 01:51:03.192408
Epoch:[ 217 6 ] loss: 0.34895044565200806 2022-08-12 01:51:03.611984
Epoch:[ 217 7 ] loss: 0.35037413239479065 2022-08-12 01:51:04.024001
Epoch:[ 217 8 ] loss: 0.3489285111427307 2022-08-12 01:51:04.452912
Epoch:[ 217 9 ] loss: 0.3501991331577301 2022-08-12 01:51:04.877871
Epoch:[ 217 10 ] loss: 0.34901511669158936 2022-08-12 01:51:05.303465
Epoch:[ 217 11 ] loss: 0.3496231734752655 2022-08-12 01:51:05.724261
Epoch:[ 217 12 ] loss: 0.34945231676101685 2022-08-12 01:51:06.148936
Epoch:[ 217 13 ] loss: 0.34994885325431824 2022-08-12 01:51:06.567624
Epoch:[ 217 14 ] loss: 0.3494667708873749 2022-08-12 01:51:06.991373
Epoch:[ 217 15 ] loss: 0.34959807991981506 2022-08-12 01:51:07.413665
Epoch:[ 217 16 ] loss: 0.34981220960617065 2022-08-12 01:51:12.897393
Epoch:[ 217 17 ] loss: 0.35045602917671204 2022-08-12 01:51:13.315390
Epoch:[ 217 18 ] loss: 0.34895214438438416 2022-08-12 01:51:13.742534
Epoch:[ 217 19 ] loss: 0.3493010103702545 2022-08-12 01:51:14.167703
Training_Epoch:[ 217 ] Training_loss: 0.34965490847826003 2022-08-12 01:51:14.168397
learning rate:  0.00013178240568734875
val: 1 0.40553387999534607
val: 2 0.40871813893318176
val: 3 0.40887367725372314
val: 4 0.4014683663845062
val: 5 0.41064131259918213
val: 6 0.4055573344230652
val: 7 0.399375855922699
val: 8 0.40344810485839844
val: 9 0.40600112080574036
val: 10 0.4059038758277893
val: 11 0.4044821560382843
val: 12 0.40366071462631226
val: 13 0.41263219714164734
val: 14 0.4049384295940399
val: 15 0.41396811604499817
val: 16 0.40259939432144165
val: 17 0.40599149465560913
val: 18 0.401032418012619
val: 19 0.4029254615306854
val: 20 0.4050011932849884
val_Epoch:[ 217 ] val_loss: 0.40563766211271285 2022-08-12 01:51:17.703351
start training 2022-08-12 01:51:17.800297
Epoch:[ 218 0 ] loss: 0.3491772711277008 2022-08-12 01:51:32.425915
Epoch:[ 218 1 ] loss: 0.3497985005378723 2022-08-12 01:51:32.849719
Epoch:[ 218 2 ] loss: 0.3488902151584625 2022-08-12 01:51:33.272582
Epoch:[ 218 3 ] loss: 0.34907591342926025 2022-08-12 01:51:33.698469
Epoch:[ 218 4 ] loss: 0.3491019010543823 2022-08-12 01:51:34.117709
Epoch:[ 218 5 ] loss: 0.34984391927719116 2022-08-12 01:51:34.541994
Epoch:[ 218 6 ] loss: 0.3495447039604187 2022-08-12 01:51:34.965933
Epoch:[ 218 7 ] loss: 0.34958815574645996 2022-08-12 01:51:35.391196
Epoch:[ 218 8 ] loss: 0.3499457538127899 2022-08-12 01:51:35.820877
Epoch:[ 218 9 ] loss: 0.35043811798095703 2022-08-12 01:51:36.243025
Epoch:[ 218 10 ] loss: 0.34922894835472107 2022-08-12 01:51:36.664908
Epoch:[ 218 11 ] loss: 0.35039010643959045 2022-08-12 01:51:37.077718
Epoch:[ 218 12 ] loss: 0.34945064783096313 2022-08-12 01:51:37.497495
Epoch:[ 218 13 ] loss: 0.34865498542785645 2022-08-12 01:51:37.927309
Epoch:[ 218 14 ] loss: 0.3490760028362274 2022-08-12 01:51:38.351606
Epoch:[ 218 15 ] loss: 0.3501671552658081 2022-08-12 01:51:38.773494
Epoch:[ 218 16 ] loss: 0.3501524329185486 2022-08-12 01:51:44.077984
Epoch:[ 218 17 ] loss: 0.35026657581329346 2022-08-12 01:51:44.502176
Epoch:[ 218 18 ] loss: 0.34894442558288574 2022-08-12 01:51:45.176463
Epoch:[ 218 19 ] loss: 0.3494357764720917 2022-08-12 01:51:45.600823
Training_Epoch:[ 218 ] Training_loss: 0.34955857545137403 2022-08-12 01:51:45.601499
learning rate:  0.00013178240568734875
val: 1 0.4049546718597412
val: 2 0.40552401542663574
val: 3 0.4067387580871582
val: 4 0.40995725989341736
val: 5 0.4116021990776062
val: 6 0.40443968772888184
val: 7 0.40666094422340393
val: 8 0.40465879440307617
val: 9 0.40038710832595825
val: 10 0.40197649598121643
val: 11 0.40931791067123413
val: 12 0.40598833560943604
val: 13 0.40480783581733704
val: 14 0.4127073884010315
val: 15 0.40946969389915466
val: 16 0.4069393277168274
val: 17 0.41658446192741394
val: 18 0.4021148681640625
val: 19 0.4029839038848877
val: 20 0.40185385942459106
val_Epoch:[ 218 ] val_loss: 0.4064833760261536 2022-08-12 01:51:49.150623
start training 2022-08-12 01:51:49.250695
Epoch:[ 219 0 ] loss: 0.35011497139930725 2022-08-12 01:52:04.403575
Epoch:[ 219 1 ] loss: 0.34892603754997253 2022-08-12 01:52:04.824686
Epoch:[ 219 2 ] loss: 0.348833829164505 2022-08-12 01:52:05.246247
Epoch:[ 219 3 ] loss: 0.3505716323852539 2022-08-12 01:52:05.671735
Epoch:[ 219 4 ] loss: 0.3490125238895416 2022-08-12 01:52:06.098126
Epoch:[ 219 5 ] loss: 0.34982970356941223 2022-08-12 01:52:06.516926
Epoch:[ 219 6 ] loss: 0.34937018156051636 2022-08-12 01:52:06.941889
Epoch:[ 219 7 ] loss: 0.3487425446510315 2022-08-12 01:52:07.366279
Epoch:[ 219 8 ] loss: 0.3489070236682892 2022-08-12 01:52:07.788787
Epoch:[ 219 9 ] loss: 0.3501015603542328 2022-08-12 01:52:08.214197
Epoch:[ 219 10 ] loss: 0.3488157093524933 2022-08-12 01:52:08.638527
Epoch:[ 219 11 ] loss: 0.34899836778640747 2022-08-12 01:52:09.058585
Epoch:[ 219 12 ] loss: 0.3493809700012207 2022-08-12 01:52:09.473089
Epoch:[ 219 13 ] loss: 0.34901437163352966 2022-08-12 01:52:09.892758
Epoch:[ 219 14 ] loss: 0.35005900263786316 2022-08-12 01:52:10.318837
Epoch:[ 219 15 ] loss: 0.3484046459197998 2022-08-12 01:52:10.746671
Epoch:[ 219 16 ] loss: 0.3502437472343445 2022-08-12 01:52:16.329552
Epoch:[ 219 17 ] loss: 0.35026615858078003 2022-08-12 01:52:16.753327
Epoch:[ 219 18 ] loss: 0.34970399737358093 2022-08-12 01:52:17.186110
Epoch:[ 219 19 ] loss: 0.3486723005771637 2022-08-12 01:52:17.608017
Training_Epoch:[ 219 ] Training_loss: 0.3493984639644623 2022-08-12 01:52:17.608801
learning rate:  0.00013178240568734875
val: 1 0.4044386148452759
val: 2 0.4073624312877655
val: 3 0.4076925218105316
val: 4 0.4100643992424011
val: 5 0.4064902067184448
val: 6 0.39997678995132446
val: 7 0.4019980728626251
val: 8 0.392838716506958
val: 9 0.40068963170051575
val: 10 0.415786474943161
val: 11 0.4042145907878876
val: 12 0.4076157510280609
val: 13 0.4081774950027466
val: 14 0.39774641394615173
val: 15 0.4013066589832306
val: 16 0.39806437492370605
val: 17 0.4076627492904663
val: 18 0.41243818402290344
val: 19 0.4106050133705139
val: 20 0.4097695052623749
val_Epoch:[ 219 ] val_loss: 0.4052469298243523 2022-08-12 01:52:21.166003
start training 2022-08-12 01:52:21.262385
Epoch:[ 220 0 ] loss: 0.349103182554245 2022-08-12 01:52:35.901114
Epoch:[ 220 1 ] loss: 0.349555104970932 2022-08-12 01:52:36.322174
Epoch:[ 220 2 ] loss: 0.34915998578071594 2022-08-12 01:52:36.749568
Epoch:[ 220 3 ] loss: 0.3495723307132721 2022-08-12 01:52:37.171727
Epoch:[ 220 4 ] loss: 0.34908345341682434 2022-08-12 01:52:37.591143
Epoch:[ 220 5 ] loss: 0.3501696288585663 2022-08-12 01:52:38.006352
Epoch:[ 220 6 ] loss: 0.34999626874923706 2022-08-12 01:52:38.423763
Epoch:[ 220 7 ] loss: 0.34913280606269836 2022-08-12 01:52:38.848319
Epoch:[ 220 8 ] loss: 0.34832197427749634 2022-08-12 01:52:39.272627
Epoch:[ 220 9 ] loss: 0.34940463304519653 2022-08-12 01:52:39.691437
Epoch:[ 220 10 ] loss: 0.34990325570106506 2022-08-12 01:52:40.112618
Epoch:[ 220 11 ] loss: 0.34908434748649597 2022-08-12 01:52:40.537384
Epoch:[ 220 12 ] loss: 0.3516205847263336 2022-08-12 01:52:40.963029
Epoch:[ 220 13 ] loss: 0.3495699465274811 2022-08-12 01:52:41.392428
Epoch:[ 220 14 ] loss: 0.3497806787490845 2022-08-12 01:52:41.817191
Epoch:[ 220 15 ] loss: 0.34981635212898254 2022-08-12 01:52:42.239686
Epoch:[ 220 16 ] loss: 0.3493332266807556 2022-08-12 01:52:47.542579
Epoch:[ 220 17 ] loss: 0.3503333628177643 2022-08-12 01:52:47.965461
Epoch:[ 220 18 ] loss: 0.34994080662727356 2022-08-12 01:52:48.389714
Epoch:[ 220 19 ] loss: 0.3487587571144104 2022-08-12 01:52:48.810312
Training_Epoch:[ 220 ] Training_loss: 0.3495820343494415 2022-08-12 01:52:48.811070
learning rate:  0.00013178240568734875
netparams have been saved once 220
val: 1 0.40493711829185486
val: 2 0.4049273431301117
val: 3 0.40054765343666077
val: 4 0.40044716000556946
val: 5 0.4090593159198761
val: 6 0.40452975034713745
val: 7 0.40402713418006897
val: 8 0.41315898299217224
val: 9 0.40529853105545044
val: 10 0.4043123424053192
val: 11 0.40496838092803955
val: 12 0.40961581468582153
val: 13 0.4047042429447174
val: 14 0.40535324811935425
val: 15 0.4111175835132599
val: 16 0.40602827072143555
val: 17 0.40468528866767883
val: 18 0.4107467234134674
val: 19 0.4123412072658539
val: 20 0.40084201097488403
val_Epoch:[ 220 ] val_loss: 0.40608240514993665 2022-08-12 01:52:52.385838
start training 2022-08-12 01:52:52.484274
Epoch:[ 221 0 ] loss: 0.3484783470630646 2022-08-12 01:53:07.536742
Epoch:[ 221 1 ] loss: 0.3492829203605652 2022-08-12 01:53:07.961802
Epoch:[ 221 2 ] loss: 0.3493310213088989 2022-08-12 01:53:08.382960
Epoch:[ 221 3 ] loss: 0.34884291887283325 2022-08-12 01:53:08.806226
Epoch:[ 221 4 ] loss: 0.3500514328479767 2022-08-12 01:53:09.238189
Epoch:[ 221 5 ] loss: 0.3499651253223419 2022-08-12 01:53:09.664123
Epoch:[ 221 6 ] loss: 0.3482952415943146 2022-08-12 01:53:10.084987
Epoch:[ 221 7 ] loss: 0.3492386043071747 2022-08-12 01:53:10.508097
Epoch:[ 221 8 ] loss: 0.34879133105278015 2022-08-12 01:53:10.932892
Epoch:[ 221 9 ] loss: 0.35015010833740234 2022-08-12 01:53:11.355393
Epoch:[ 221 10 ] loss: 0.3490661084651947 2022-08-12 01:53:11.783849
Epoch:[ 221 11 ] loss: 0.35011807084083557 2022-08-12 01:53:12.210869
Epoch:[ 221 12 ] loss: 0.3492636978626251 2022-08-12 01:53:12.632120
Epoch:[ 221 13 ] loss: 0.35047876834869385 2022-08-12 01:53:13.047012
Epoch:[ 221 14 ] loss: 0.34880173206329346 2022-08-12 01:53:13.464067
Epoch:[ 221 15 ] loss: 0.3495107889175415 2022-08-12 01:53:13.890424
Epoch:[ 221 16 ] loss: 0.3499891459941864 2022-08-12 01:53:18.909684
Epoch:[ 221 17 ] loss: 0.3501623570919037 2022-08-12 01:53:19.326498
Epoch:[ 221 18 ] loss: 0.34877339005470276 2022-08-12 01:53:19.741671
Epoch:[ 221 19 ] loss: 0.3495735824108124 2022-08-12 01:53:20.160271
Training_Epoch:[ 221 ] Training_loss: 0.3494082346558571 2022-08-12 01:53:20.160945
learning rate:  0.00011201504483424644
val: 1 0.40366941690444946
val: 2 0.40259402990341187
val: 3 0.40396153926849365
val: 4 0.4058678150177002
val: 5 0.4086224138736725
val: 6 0.41093918681144714
val: 7 0.4068257808685303
val: 8 0.4088934063911438
val: 9 0.4039924144744873
val: 10 0.41041359305381775
val: 11 0.405160516500473
val: 12 0.40971729159355164
val: 13 0.41107529401779175
val: 14 0.40855279564857483
val: 15 0.4008721709251404
val: 16 0.4048563241958618
val: 17 0.39857372641563416
val: 18 0.40210482478141785
val: 19 0.4027910828590393
val: 20 0.4097982347011566
val_Epoch:[ 221 ] val_loss: 0.4059640929102898 2022-08-12 01:53:23.717812
start training 2022-08-12 01:53:23.812020
Epoch:[ 222 0 ] loss: 0.35092893242836 2022-08-12 01:53:38.684446
Epoch:[ 222 1 ] loss: 0.3493381440639496 2022-08-12 01:53:39.098991
Epoch:[ 222 2 ] loss: 0.34872934222221375 2022-08-12 01:53:39.519960
Epoch:[ 222 3 ] loss: 0.3492313623428345 2022-08-12 01:53:39.946344
Epoch:[ 222 4 ] loss: 0.3504771888256073 2022-08-12 01:53:40.375635
Epoch:[ 222 5 ] loss: 0.34878963232040405 2022-08-12 01:53:40.794268
Epoch:[ 222 6 ] loss: 0.34894853830337524 2022-08-12 01:53:41.214273
Epoch:[ 222 7 ] loss: 0.34925851225852966 2022-08-12 01:53:41.632837
Epoch:[ 222 8 ] loss: 0.34841257333755493 2022-08-12 01:53:42.051543
Epoch:[ 222 9 ] loss: 0.34989267587661743 2022-08-12 01:53:42.472218
Epoch:[ 222 10 ] loss: 0.34869876503944397 2022-08-12 01:53:42.894409
Epoch:[ 222 11 ] loss: 0.3496491312980652 2022-08-12 01:53:43.317298
Epoch:[ 222 12 ] loss: 0.34960368275642395 2022-08-12 01:53:43.743411
Epoch:[ 222 13 ] loss: 0.3490739166736603 2022-08-12 01:53:44.159939
Epoch:[ 222 14 ] loss: 0.35001665353775024 2022-08-12 01:53:44.574006
Epoch:[ 222 15 ] loss: 0.3493960499763489 2022-08-12 01:53:44.997631
Epoch:[ 222 16 ] loss: 0.3488866984844208 2022-08-12 01:53:50.424150
Epoch:[ 222 17 ] loss: 0.3487578332424164 2022-08-12 01:53:50.842328
Epoch:[ 222 18 ] loss: 0.3495430648326874 2022-08-12 01:53:51.264918
Epoch:[ 222 19 ] loss: 0.3488287329673767 2022-08-12 01:53:51.690821
Training_Epoch:[ 222 ] Training_loss: 0.349323071539402 2022-08-12 01:53:51.691498
learning rate:  0.00011201504483424644
val: 1 0.40832430124282837
val: 2 0.40173840522766113
val: 3 0.4046153128147125
val: 4 0.4058181345462799
val: 5 0.40558773279190063
val: 6 0.40902963280677795
val: 7 0.4113098978996277
val: 8 0.4076283276081085
val: 9 0.414244145154953
val: 10 0.40176916122436523
val: 11 0.41003870964050293
val: 12 0.4044395685195923
val: 13 0.4102548658847809
val: 14 0.4078116714954376
val: 15 0.4084513187408447
val: 16 0.40047574043273926
val: 17 0.40524372458457947
val: 18 0.4030013978481293
val: 19 0.4059927761554718
val: 20 0.4004303812980652
val_Epoch:[ 222 ] val_loss: 0.4063102602958679 2022-08-12 01:53:55.290165
start training 2022-08-12 01:53:55.386275
Epoch:[ 223 0 ] loss: 0.3485613763332367 2022-08-12 01:54:09.986106
Epoch:[ 223 1 ] loss: 0.34903615713119507 2022-08-12 01:54:10.428036
Epoch:[ 223 2 ] loss: 0.34984371066093445 2022-08-12 01:54:10.845971
Epoch:[ 223 3 ] loss: 0.34966763854026794 2022-08-12 01:54:11.262148
Epoch:[ 223 4 ] loss: 0.34981769323349 2022-08-12 01:54:11.682526
Epoch:[ 223 5 ] loss: 0.34887680411338806 2022-08-12 01:54:12.112284
Epoch:[ 223 6 ] loss: 0.34917768836021423 2022-08-12 01:54:12.532945
Epoch:[ 223 7 ] loss: 0.3488461673259735 2022-08-12 01:54:12.953326
Epoch:[ 223 8 ] loss: 0.3489689528942108 2022-08-12 01:54:13.374394
Epoch:[ 223 9 ] loss: 0.34852343797683716 2022-08-12 01:54:13.803327
Epoch:[ 223 10 ] loss: 0.34848877787590027 2022-08-12 01:54:14.230572
Epoch:[ 223 11 ] loss: 0.34911245107650757 2022-08-12 01:54:14.646651
Epoch:[ 223 12 ] loss: 0.3493330180644989 2022-08-12 01:54:15.071219
Epoch:[ 223 13 ] loss: 0.3501394987106323 2022-08-12 01:54:15.494953
Epoch:[ 223 14 ] loss: 0.3495009243488312 2022-08-12 01:54:15.919681
Epoch:[ 223 15 ] loss: 0.34869229793548584 2022-08-12 01:54:16.342717
Epoch:[ 223 16 ] loss: 0.35006460547447205 2022-08-12 01:54:21.519024
Epoch:[ 223 17 ] loss: 0.3493187129497528 2022-08-12 01:54:21.943363
Epoch:[ 223 18 ] loss: 0.3496348261833191 2022-08-12 01:54:22.370153
Epoch:[ 223 19 ] loss: 0.3488025367259979 2022-08-12 01:54:22.794211
Training_Epoch:[ 223 ] Training_loss: 0.34922036379575727 2022-08-12 01:54:22.794980
learning rate:  0.00011201504483424644
val: 1 0.4050125777721405
val: 2 0.4189917743206024
val: 3 0.40648916363716125
val: 4 0.40653109550476074
val: 5 0.403597354888916
val: 6 0.4106215238571167
val: 7 0.4063868820667267
val: 8 0.4062076807022095
val: 9 0.40709149837493896
val: 10 0.41072016954421997
val: 11 0.40230345726013184
val: 12 0.40290480852127075
val: 13 0.4059118926525116
val: 14 0.4192686080932617
val: 15 0.401873379945755
val: 16 0.4124999940395355
val: 17 0.40818578004837036
val: 18 0.4098357558250427
val: 19 0.4011535942554474
val: 20 0.4070189595222473
val_Epoch:[ 223 ] val_loss: 0.40763029754161834 2022-08-12 01:54:26.384938
start training 2022-08-12 01:54:26.478880
Epoch:[ 224 0 ] loss: 0.34871742129325867 2022-08-12 01:54:41.133234
Epoch:[ 224 1 ] loss: 0.349418967962265 2022-08-12 01:54:41.559728
Epoch:[ 224 2 ] loss: 0.34752339124679565 2022-08-12 01:54:41.981166
Epoch:[ 224 3 ] loss: 0.3480894863605499 2022-08-12 01:54:42.407346
Epoch:[ 224 4 ] loss: 0.34882494807243347 2022-08-12 01:54:42.832225
Epoch:[ 224 5 ] loss: 0.3484894037246704 2022-08-12 01:54:43.254577
Epoch:[ 224 6 ] loss: 0.34901589155197144 2022-08-12 01:54:43.670001
Epoch:[ 224 7 ] loss: 0.34933239221572876 2022-08-12 01:54:44.088576
Epoch:[ 224 8 ] loss: 0.34875646233558655 2022-08-12 01:54:44.514106
Epoch:[ 224 9 ] loss: 0.3492685556411743 2022-08-12 01:54:44.935997
Epoch:[ 224 10 ] loss: 0.34932392835617065 2022-08-12 01:54:45.352709
Epoch:[ 224 11 ] loss: 0.35091692209243774 2022-08-12 01:54:45.775629
Epoch:[ 224 12 ] loss: 0.34890350699424744 2022-08-12 01:54:46.202009
Epoch:[ 224 13 ] loss: 0.34909626841545105 2022-08-12 01:54:46.628286
Epoch:[ 224 14 ] loss: 0.3493969440460205 2022-08-12 01:54:47.048211
Epoch:[ 224 15 ] loss: 0.35001659393310547 2022-08-12 01:54:47.469672
Epoch:[ 224 16 ] loss: 0.3492460250854492 2022-08-12 01:54:52.742816
Epoch:[ 224 17 ] loss: 0.3488524258136749 2022-08-12 01:54:53.365441
Epoch:[ 224 18 ] loss: 0.3499004542827606 2022-08-12 01:54:53.787392
Epoch:[ 224 19 ] loss: 0.34956619143486023 2022-08-12 01:54:54.212270
Training_Epoch:[ 224 ] Training_loss: 0.3491328090429306 2022-08-12 01:54:54.212933
learning rate:  0.00011201504483424644
val: 1 0.4158794581890106
val: 2 0.40413084626197815
val: 3 0.40991970896720886
val: 4 0.4057626724243164
val: 5 0.401518315076828
val: 6 0.4092462360858917
val: 7 0.40547651052474976
val: 8 0.3985176980495453
val: 9 0.40295252203941345
val: 10 0.40467557311058044
val: 11 0.41472166776657104
val: 12 0.4056379497051239
val: 13 0.4060114622116089
val: 14 0.403729647397995
val: 15 0.40533286333084106
val: 16 0.40924516320228577
val: 17 0.40792739391326904
val: 18 0.40553826093673706
val: 19 0.3981616497039795
val: 20 0.40657803416252136
val_Epoch:[ 224 ] val_loss: 0.40604818165302276 2022-08-12 01:54:57.768159
start training 2022-08-12 01:54:57.861925
Epoch:[ 225 0 ] loss: 0.3490510880947113 2022-08-12 01:55:12.260677
Epoch:[ 225 1 ] loss: 0.348687082529068 2022-08-12 01:55:12.702979
Epoch:[ 225 2 ] loss: 0.34913986921310425 2022-08-12 01:55:13.130915
Epoch:[ 225 3 ] loss: 0.3490004241466522 2022-08-12 01:55:13.557573
Epoch:[ 225 4 ] loss: 0.34981003403663635 2022-08-12 01:55:13.978489
Epoch:[ 225 5 ] loss: 0.3495428264141083 2022-08-12 01:55:14.405673
Epoch:[ 225 6 ] loss: 0.3498484492301941 2022-08-12 01:55:14.831988
Epoch:[ 225 7 ] loss: 0.34997332096099854 2022-08-12 01:55:15.258789
Epoch:[ 225 8 ] loss: 0.34884363412857056 2022-08-12 01:55:15.685596
Epoch:[ 225 9 ] loss: 0.3490826189517975 2022-08-12 01:55:16.109043
Epoch:[ 225 10 ] loss: 0.34960559010505676 2022-08-12 01:55:16.529642
Epoch:[ 225 11 ] loss: 0.3497689664363861 2022-08-12 01:55:16.954179
Epoch:[ 225 12 ] loss: 0.34845322370529175 2022-08-12 01:55:17.379681
Epoch:[ 225 13 ] loss: 0.34909671545028687 2022-08-12 01:55:17.803704
Epoch:[ 225 14 ] loss: 0.3488234579563141 2022-08-12 01:55:18.229254
Epoch:[ 225 15 ] loss: 0.3495655655860901 2022-08-12 01:55:18.651896
Epoch:[ 225 16 ] loss: 0.349168062210083 2022-08-12 01:55:23.904535
Epoch:[ 225 17 ] loss: 0.3497765362262726 2022-08-12 01:55:24.328470
Epoch:[ 225 18 ] loss: 0.3497643768787384 2022-08-12 01:55:24.750687
Epoch:[ 225 19 ] loss: 0.34949690103530884 2022-08-12 01:55:25.173555
Training_Epoch:[ 225 ] Training_loss: 0.34932493716478347 2022-08-12 01:55:25.174250
learning rate:  0.00011201504483424644
val: 1 0.40658366680145264
val: 2 0.4061388373374939
val: 3 0.4074811637401581
val: 4 0.40479418635368347
val: 5 0.40279272198677063
val: 6 0.40463539958000183
val: 7 0.4162132143974304
val: 8 0.4032973349094391
val: 9 0.40537163615226746
val: 10 0.41015625
val: 11 0.4093022644519806
val: 12 0.40769848227500916
val: 13 0.4068785309791565
val: 14 0.40467479825019836
val: 15 0.40226829051971436
val: 16 0.4076538383960724
val: 17 0.4068986773490906
val: 18 0.4069076180458069
val: 19 0.4015571177005768
val: 20 0.40919432044029236
val_Epoch:[ 225 ] val_loss: 0.40652491748332975 2022-08-12 01:55:28.696394
start training 2022-08-12 01:55:28.792361
Epoch:[ 226 0 ] loss: 0.34959331154823303 2022-08-12 01:55:43.584280
Epoch:[ 226 1 ] loss: 0.3490259349346161 2022-08-12 01:55:44.011277
Epoch:[ 226 2 ] loss: 0.34898990392684937 2022-08-12 01:55:44.432249
Epoch:[ 226 3 ] loss: 0.3499162495136261 2022-08-12 01:55:44.846252
Epoch:[ 226 4 ] loss: 0.3492409884929657 2022-08-12 01:55:45.267356
Epoch:[ 226 5 ] loss: 0.3495132029056549 2022-08-12 01:55:45.697402
Epoch:[ 226 6 ] loss: 0.34999722242355347 2022-08-12 01:55:46.120437
Epoch:[ 226 7 ] loss: 0.34903475642204285 2022-08-12 01:55:46.543117
Epoch:[ 226 8 ] loss: 0.34898966550827026 2022-08-12 01:55:46.966042
Epoch:[ 226 9 ] loss: 0.34876108169555664 2022-08-12 01:55:47.389749
Epoch:[ 226 10 ] loss: 0.34941715002059937 2022-08-12 01:55:47.815439
Epoch:[ 226 11 ] loss: 0.34981051087379456 2022-08-12 01:55:48.232104
Epoch:[ 226 12 ] loss: 0.3497927188873291 2022-08-12 01:55:48.656358
Epoch:[ 226 13 ] loss: 0.3484588861465454 2022-08-12 01:55:49.080399
Epoch:[ 226 14 ] loss: 0.3488594591617584 2022-08-12 01:55:49.507651
Epoch:[ 226 15 ] loss: 0.349975049495697 2022-08-12 01:55:49.937131
Epoch:[ 226 16 ] loss: 0.34923526644706726 2022-08-12 01:55:55.182559
Epoch:[ 226 17 ] loss: 0.34832340478897095 2022-08-12 01:55:55.603318
Epoch:[ 226 18 ] loss: 0.3489038944244385 2022-08-12 01:55:56.025861
Epoch:[ 226 19 ] loss: 0.35013487935066223 2022-08-12 01:55:56.451249
Training_Epoch:[ 226 ] Training_loss: 0.34929867684841154 2022-08-12 01:55:56.451967
learning rate:  0.00011201504483424644
val: 1 0.4014328718185425
val: 2 0.40462803840637207
val: 3 0.4090595245361328
val: 4 0.4060601592063904
val: 5 0.4056985676288605
val: 6 0.4079686105251312
val: 7 0.41029873490333557
val: 8 0.4013935923576355
val: 9 0.40403199195861816
val: 10 0.4091550409793854
val: 11 0.40682533383369446
val: 12 0.40325286984443665
val: 13 0.40256747603416443
val: 14 0.399725079536438
val: 15 0.4044872224330902
val: 16 0.3999747335910797
val: 17 0.4087802469730377
val: 18 0.4091300368309021
val: 19 0.4075731933116913
val: 20 0.40890979766845703
val_Epoch:[ 226 ] val_loss: 0.4055476561188698 2022-08-12 01:55:59.948898
start training 2022-08-12 01:56:00.042071
Epoch:[ 227 0 ] loss: 0.34932512044906616 2022-08-12 01:56:14.994543
Epoch:[ 227 1 ] loss: 0.34931501746177673 2022-08-12 01:56:15.418620
Epoch:[ 227 2 ] loss: 0.3488121032714844 2022-08-12 01:56:15.845966
Epoch:[ 227 3 ] loss: 0.3488125205039978 2022-08-12 01:56:16.271849
Epoch:[ 227 4 ] loss: 0.34794914722442627 2022-08-12 01:56:16.694496
Epoch:[ 227 5 ] loss: 0.3486652672290802 2022-08-12 01:56:17.116986
Epoch:[ 227 6 ] loss: 0.34911006689071655 2022-08-12 01:56:17.539050
Epoch:[ 227 7 ] loss: 0.3505416214466095 2022-08-12 01:56:17.964866
Epoch:[ 227 8 ] loss: 0.3492014408111572 2022-08-12 01:56:18.387051
Epoch:[ 227 9 ] loss: 0.3500707149505615 2022-08-12 01:56:18.809780
Epoch:[ 227 10 ] loss: 0.34954988956451416 2022-08-12 01:56:19.234631
Epoch:[ 227 11 ] loss: 0.35020166635513306 2022-08-12 01:56:19.654835
Epoch:[ 227 12 ] loss: 0.3491988182067871 2022-08-12 01:56:20.067137
Epoch:[ 227 13 ] loss: 0.3496062159538269 2022-08-12 01:56:20.489716
Epoch:[ 227 14 ] loss: 0.34857138991355896 2022-08-12 01:56:20.919963
Epoch:[ 227 15 ] loss: 0.349717378616333 2022-08-12 01:56:21.339675
Epoch:[ 227 16 ] loss: 0.34876376390457153 2022-08-12 01:56:26.623156
Epoch:[ 227 17 ] loss: 0.35016676783561707 2022-08-12 01:56:27.045547
Epoch:[ 227 18 ] loss: 0.3496836721897125 2022-08-12 01:56:27.476945
Epoch:[ 227 19 ] loss: 0.34867164492607117 2022-08-12 01:56:27.897563
Training_Epoch:[ 227 ] Training_loss: 0.3492967113852501 2022-08-12 01:56:27.898293
learning rate:  0.00011201504483424644
val: 1 0.41222938895225525
val: 2 0.41003549098968506
val: 3 0.4128255248069763
val: 4 0.40054622292518616
val: 5 0.4022664725780487
val: 6 0.4042105972766876
val: 7 0.40656062960624695
val: 8 0.40612220764160156
val: 9 0.41006743907928467
val: 10 0.3993082046508789
val: 11 0.3999520540237427
val: 12 0.40764176845550537
val: 13 0.4046393036842346
val: 14 0.4149562120437622
val: 15 0.40678006410598755
val: 16 0.40948501229286194
val: 17 0.40128451585769653
val: 18 0.4018012285232544
val: 19 0.41026851534843445
val: 20 0.4094844460487366
val_Epoch:[ 227 ] val_loss: 0.4065232649445534 2022-08-12 01:56:31.476819
start training 2022-08-12 01:56:31.569721
Epoch:[ 228 0 ] loss: 0.3494868576526642 2022-08-12 01:56:46.022359
Epoch:[ 228 1 ] loss: 0.3490632474422455 2022-08-12 01:56:46.464438
Epoch:[ 228 2 ] loss: 0.34960636496543884 2022-08-12 01:56:46.896370
Epoch:[ 228 3 ] loss: 0.3496749699115753 2022-08-12 01:56:47.311480
Epoch:[ 228 4 ] loss: 0.350272536277771 2022-08-12 01:56:47.735623
Epoch:[ 228 5 ] loss: 0.34905606508255005 2022-08-12 01:56:48.156790
Epoch:[ 228 6 ] loss: 0.3488655686378479 2022-08-12 01:56:48.580731
Epoch:[ 228 7 ] loss: 0.35012197494506836 2022-08-12 01:56:49.000904
Epoch:[ 228 8 ] loss: 0.3491074740886688 2022-08-12 01:56:49.425472
Epoch:[ 228 9 ] loss: 0.3484298884868622 2022-08-12 01:56:49.855238
Epoch:[ 228 10 ] loss: 0.3492363393306732 2022-08-12 01:56:50.270082
Epoch:[ 228 11 ] loss: 0.34980687499046326 2022-08-12 01:56:50.701628
Epoch:[ 228 12 ] loss: 0.34909868240356445 2022-08-12 01:56:51.127042
Epoch:[ 228 13 ] loss: 0.34819260239601135 2022-08-12 01:56:51.552492
Epoch:[ 228 14 ] loss: 0.3495713770389557 2022-08-12 01:56:51.972401
Epoch:[ 228 15 ] loss: 0.34904494881629944 2022-08-12 01:56:52.398422
Epoch:[ 228 16 ] loss: 0.34927424788475037 2022-08-12 01:56:57.518266
Epoch:[ 228 17 ] loss: 0.34970545768737793 2022-08-12 01:56:57.943126
Epoch:[ 228 18 ] loss: 0.3489590585231781 2022-08-12 01:56:58.371570
Epoch:[ 228 19 ] loss: 0.3496900498867035 2022-08-12 01:56:58.794367
Training_Epoch:[ 228 ] Training_loss: 0.34931322932243347 2022-08-12 01:56:58.795054
learning rate:  0.00011201504483424644
val: 1 0.39700862765312195
val: 2 0.411614328622818
val: 3 0.40838494896888733
val: 4 0.400534451007843
val: 5 0.4083722233772278
val: 6 0.3983829617500305
val: 7 0.40508824586868286
val: 8 0.39837801456451416
val: 9 0.4072312116622925
val: 10 0.4091448485851288
val: 11 0.4070703983306885
val: 12 0.40277138352394104
val: 13 0.40589919686317444
val: 14 0.40676379203796387
val: 15 0.4081876575946808
val: 16 0.40088143944740295
val: 17 0.41324540972709656
val: 18 0.4106334447860718
val: 19 0.4101216793060303
val: 20 0.4106811285018921
val_Epoch:[ 228 ] val_loss: 0.40601976960897446 2022-08-12 01:57:02.309033
start training 2022-08-12 01:57:02.405013
Epoch:[ 229 0 ] loss: 0.34843212366104126 2022-08-12 01:57:17.196198
Epoch:[ 229 1 ] loss: 0.34966883063316345 2022-08-12 01:57:17.618532
Epoch:[ 229 2 ] loss: 0.34861838817596436 2022-08-12 01:57:18.041475
Epoch:[ 229 3 ] loss: 0.34943029284477234 2022-08-12 01:57:18.467278
Epoch:[ 229 4 ] loss: 0.34990471601486206 2022-08-12 01:57:18.891872
Epoch:[ 229 5 ] loss: 0.34886622428894043 2022-08-12 01:57:19.315727
Epoch:[ 229 6 ] loss: 0.3495023548603058 2022-08-12 01:57:19.741974
Epoch:[ 229 7 ] loss: 0.3487381637096405 2022-08-12 01:57:20.166944
Epoch:[ 229 8 ] loss: 0.3488216996192932 2022-08-12 01:57:20.584827
Epoch:[ 229 9 ] loss: 0.348029762506485 2022-08-12 01:57:21.001123
Epoch:[ 229 10 ] loss: 0.34865614771842957 2022-08-12 01:57:21.422589
Epoch:[ 229 11 ] loss: 0.3491792678833008 2022-08-12 01:57:21.853200
Epoch:[ 229 12 ] loss: 0.34930846095085144 2022-08-12 01:57:22.272032
Epoch:[ 229 13 ] loss: 0.34985607862472534 2022-08-12 01:57:22.693392
Epoch:[ 229 14 ] loss: 0.34895703196525574 2022-08-12 01:57:23.115390
Epoch:[ 229 15 ] loss: 0.34869951009750366 2022-08-12 01:57:23.540955
Epoch:[ 229 16 ] loss: 0.34917929768562317 2022-08-12 01:57:28.722300
Epoch:[ 229 17 ] loss: 0.34984099864959717 2022-08-12 01:57:29.144341
Epoch:[ 229 18 ] loss: 0.3481598496437073 2022-08-12 01:57:29.566307
Epoch:[ 229 19 ] loss: 0.34863826632499695 2022-08-12 01:57:29.990027
Training_Epoch:[ 229 ] Training_loss: 0.34902437329292296 2022-08-12 01:57:29.990722
learning rate:  0.00011201504483424644
val: 1 0.40496841073036194
val: 2 0.4073585569858551
val: 3 0.4015153646469116
val: 4 0.41210952401161194
val: 5 0.4099690914154053
val: 6 0.40286123752593994
val: 7 0.4045143127441406
val: 8 0.4071485996246338
val: 9 0.40626564621925354
val: 10 0.4078335464000702
val: 11 0.406784325838089
val: 12 0.412030428647995
val: 13 0.403543084859848
val: 14 0.41376590728759766
val: 15 0.4103088676929474
val: 16 0.40022480487823486
val: 17 0.40865036845207214
val: 18 0.4077325761318207
val: 19 0.40985026955604553
val: 20 0.4090631604194641
val_Epoch:[ 229 ] val_loss: 0.40732490420341494 2022-08-12 01:57:33.590941
start training 2022-08-12 01:57:33.683719
Epoch:[ 230 0 ] loss: 0.3490719199180603 2022-08-12 01:57:47.688417
Epoch:[ 230 1 ] loss: 0.34934690594673157 2022-08-12 01:57:48.364199
Epoch:[ 230 2 ] loss: 0.3480280935764313 2022-08-12 01:57:48.788255
Epoch:[ 230 3 ] loss: 0.34838026762008667 2022-08-12 01:57:49.208249
Epoch:[ 230 4 ] loss: 0.3498777151107788 2022-08-12 01:57:49.622410
Epoch:[ 230 5 ] loss: 0.3492119014263153 2022-08-12 01:57:50.044864
Epoch:[ 230 6 ] loss: 0.34869223833084106 2022-08-12 01:57:50.470296
Epoch:[ 230 7 ] loss: 0.34908631443977356 2022-08-12 01:57:50.890989
Epoch:[ 230 8 ] loss: 0.3490559458732605 2022-08-12 01:57:51.307075
Epoch:[ 230 9 ] loss: 0.34928128123283386 2022-08-12 01:57:51.725103
Epoch:[ 230 10 ] loss: 0.34794482588768005 2022-08-12 01:57:52.151197
Epoch:[ 230 11 ] loss: 0.3499034643173218 2022-08-12 01:57:52.578007
Epoch:[ 230 12 ] loss: 0.3489808142185211 2022-08-12 01:57:53.001327
Epoch:[ 230 13 ] loss: 0.35014960169792175 2022-08-12 01:57:53.423269
Epoch:[ 230 14 ] loss: 0.3491557538509369 2022-08-12 01:57:53.841838
Epoch:[ 230 15 ] loss: 0.3481713533401489 2022-08-12 01:57:54.261600
Epoch:[ 230 16 ] loss: 0.3497391641139984 2022-08-12 01:57:59.596383
Epoch:[ 230 17 ] loss: 0.34984996914863586 2022-08-12 01:58:00.021415
Epoch:[ 230 18 ] loss: 0.3492089807987213 2022-08-12 01:58:00.442631
Epoch:[ 230 19 ] loss: 0.34907227754592896 2022-08-12 01:58:00.865557
Training_Epoch:[ 230 ] Training_loss: 0.3491104394197464 2022-08-12 01:58:00.866289
learning rate:  0.00011201504483424644
netparams have been saved once 230
val: 1 0.4101948142051697
val: 2 0.40594008564949036
val: 3 0.39223936200141907
val: 4 0.40812018513679504
val: 5 0.4043422341346741
val: 6 0.4100189208984375
val: 7 0.4099358022212982
val: 8 0.40001049637794495
val: 9 0.4069105088710785
val: 10 0.39855870604515076
val: 11 0.41889896988868713
val: 12 0.40379390120506287
val: 13 0.4113955497741699
val: 14 0.405624657869339
val: 15 0.4098595380783081
val: 16 0.4186188876628876
val: 17 0.39983636140823364
val: 18 0.4107376039028168
val: 19 0.4066286087036133
val: 20 0.4043477475643158
val_Epoch:[ 230 ] val_loss: 0.4068006470799446 2022-08-12 01:58:04.529103
start training 2022-08-12 01:58:04.624670
Epoch:[ 231 0 ] loss: 0.3493771255016327 2022-08-12 01:58:19.439099
Epoch:[ 231 1 ] loss: 0.3489781320095062 2022-08-12 01:58:19.861153
Epoch:[ 231 2 ] loss: 0.3482821583747864 2022-08-12 01:58:20.282329
Epoch:[ 231 3 ] loss: 0.3495969772338867 2022-08-12 01:58:20.706781
Epoch:[ 231 4 ] loss: 0.3496101200580597 2022-08-12 01:58:21.133347
Epoch:[ 231 5 ] loss: 0.34930911660194397 2022-08-12 01:58:21.554892
Epoch:[ 231 6 ] loss: 0.3484940826892853 2022-08-12 01:58:21.970326
Epoch:[ 231 7 ] loss: 0.3480471670627594 2022-08-12 01:58:22.388870
Epoch:[ 231 8 ] loss: 0.348040372133255 2022-08-12 01:58:22.811747
Epoch:[ 231 9 ] loss: 0.3488883674144745 2022-08-12 01:58:23.233351
Epoch:[ 231 10 ] loss: 0.34917131066322327 2022-08-12 01:58:23.649198
Epoch:[ 231 11 ] loss: 0.34789955615997314 2022-08-12 01:58:24.072589
Epoch:[ 231 12 ] loss: 0.3492084741592407 2022-08-12 01:58:24.502762
Epoch:[ 231 13 ] loss: 0.34897610545158386 2022-08-12 01:58:24.929351
Epoch:[ 231 14 ] loss: 0.3496129810810089 2022-08-12 01:58:25.346060
Epoch:[ 231 15 ] loss: 0.3482886850833893 2022-08-12 01:58:25.766892
Epoch:[ 231 16 ] loss: 0.3489263355731964 2022-08-12 01:58:31.086744
Epoch:[ 231 17 ] loss: 0.3492242097854614 2022-08-12 01:58:31.511441
Epoch:[ 231 18 ] loss: 0.3488537073135376 2022-08-12 01:58:31.932669
Epoch:[ 231 19 ] loss: 0.34869012236595154 2022-08-12 01:58:32.359177
Training_Epoch:[ 231 ] Training_loss: 0.3488737553358078 2022-08-12 01:58:32.359896
learning rate:  9.521278810910948e-05
val: 1 0.4061737060546875
val: 2 0.40544530749320984
val: 3 0.3988577425479889
val: 4 0.4003385901451111
val: 5 0.40874457359313965
val: 6 0.41540563106536865
val: 7 0.408065527677536
val: 8 0.4071793258190155
val: 9 0.40704622864723206
val: 10 0.4104039967060089
val: 11 0.40349140763282776
val: 12 0.40633150935173035
val: 13 0.4069609045982361
val: 14 0.41285240650177
val: 15 0.4028472304344177
val: 16 0.40281376242637634
val: 17 0.41041186451911926
val: 18 0.41493281722068787
val: 19 0.40978750586509705
val: 20 0.40277352929115295
val_Epoch:[ 231 ] val_loss: 0.4070431783795357 2022-08-12 01:58:35.875562
start training 2022-08-12 01:58:35.969096
Epoch:[ 232 0 ] loss: 0.34902074933052063 2022-08-12 01:58:50.312061
Epoch:[ 232 1 ] loss: 0.34970781207084656 2022-08-12 01:58:51.059714
Epoch:[ 232 2 ] loss: 0.34961870312690735 2022-08-12 01:58:51.486865
Epoch:[ 232 3 ] loss: 0.3478933572769165 2022-08-12 01:58:51.906990
Epoch:[ 232 4 ] loss: 0.3485185205936432 2022-08-12 01:58:52.328538
Epoch:[ 232 5 ] loss: 0.3498140275478363 2022-08-12 01:58:52.751058
Epoch:[ 232 6 ] loss: 0.34888383746147156 2022-08-12 01:58:53.180272
Epoch:[ 232 7 ] loss: 0.34813714027404785 2022-08-12 01:58:53.605677
Epoch:[ 232 8 ] loss: 0.3481660783290863 2022-08-12 01:58:54.020619
Epoch:[ 232 9 ] loss: 0.3488214313983917 2022-08-12 01:58:54.444274
Epoch:[ 232 10 ] loss: 0.34853169322013855 2022-08-12 01:58:54.868030
Epoch:[ 232 11 ] loss: 0.34899047017097473 2022-08-12 01:58:55.291671
Epoch:[ 232 12 ] loss: 0.3491470515727997 2022-08-12 01:58:55.716943
Epoch:[ 232 13 ] loss: 0.34860825538635254 2022-08-12 01:58:56.141219
Epoch:[ 232 14 ] loss: 0.3488449156284332 2022-08-12 01:58:56.569147
Epoch:[ 232 15 ] loss: 0.3491847813129425 2022-08-12 01:58:56.991876
Epoch:[ 232 16 ] loss: 0.348846435546875 2022-08-12 01:59:02.102292
Epoch:[ 232 17 ] loss: 0.3492012917995453 2022-08-12 01:59:03.468513
Epoch:[ 232 18 ] loss: 0.34816789627075195 2022-08-12 01:59:03.889861
Epoch:[ 232 19 ] loss: 0.34814852476119995 2022-08-12 01:59:04.315019
Training_Epoch:[ 232 ] Training_loss: 0.3488126486539841 2022-08-12 01:59:04.315653
learning rate:  9.521278810910948e-05
val: 1 0.4151008427143097
val: 2 0.4062139689922333
val: 3 0.4060474932193756
val: 4 0.4038461744785309
val: 5 0.40470096468925476
val: 6 0.40630364418029785
val: 7 0.40963444113731384
val: 8 0.400638222694397
val: 9 0.40380460023880005
val: 10 0.40529564023017883
val: 11 0.41352152824401855
val: 12 0.4091951251029968
val: 13 0.4121149480342865
val: 14 0.41363582015037537
val: 15 0.41038209199905396
val: 16 0.4075661301612854
val: 17 0.40577811002731323
val: 18 0.40828195214271545
val: 19 0.4018505811691284
val: 20 0.41046759486198425
val_Epoch:[ 232 ] val_loss: 0.4077189937233925 2022-08-12 01:59:07.923578
start training 2022-08-12 01:59:08.020799
Epoch:[ 233 0 ] loss: 0.34933990240097046 2022-08-12 01:59:22.426371
Epoch:[ 233 1 ] loss: 0.3485212028026581 2022-08-12 01:59:22.859216
Epoch:[ 233 2 ] loss: 0.34854772686958313 2022-08-12 01:59:23.274144
Epoch:[ 233 3 ] loss: 0.34826382994651794 2022-08-12 01:59:23.695387
Epoch:[ 233 4 ] loss: 0.34943917393684387 2022-08-12 01:59:24.122635
Epoch:[ 233 5 ] loss: 0.34878551959991455 2022-08-12 01:59:24.542558
Epoch:[ 233 6 ] loss: 0.3494676947593689 2022-08-12 01:59:24.961541
Epoch:[ 233 7 ] loss: 0.348810076713562 2022-08-12 01:59:25.385380
Epoch:[ 233 8 ] loss: 0.348350465297699 2022-08-12 01:59:25.812013
Epoch:[ 233 9 ] loss: 0.34782591462135315 2022-08-12 01:59:26.238249
Epoch:[ 233 10 ] loss: 0.3487934470176697 2022-08-12 01:59:26.658883
Epoch:[ 233 11 ] loss: 0.34824228286743164 2022-08-12 01:59:27.082790
Epoch:[ 233 12 ] loss: 0.34913888573646545 2022-08-12 01:59:27.508635
Epoch:[ 233 13 ] loss: 0.34978824853897095 2022-08-12 01:59:27.934254
Epoch:[ 233 14 ] loss: 0.34863460063934326 2022-08-12 01:59:28.361935
Epoch:[ 233 15 ] loss: 0.3485834002494812 2022-08-12 01:59:28.784969
Epoch:[ 233 16 ] loss: 0.3491351306438446 2022-08-12 01:59:34.437885
Epoch:[ 233 17 ] loss: 0.349947452545166 2022-08-12 01:59:34.860956
Epoch:[ 233 18 ] loss: 0.3485546112060547 2022-08-12 01:59:35.293139
Epoch:[ 233 19 ] loss: 0.3483707308769226 2022-08-12 01:59:35.711960
Training_Epoch:[ 233 ] Training_loss: 0.34882701486349105 2022-08-12 01:59:35.712647
learning rate:  9.521278810910948e-05
val: 1 0.40851229429244995
val: 2 0.41668185591697693
val: 3 0.39879944920539856
val: 4 0.40592074394226074
val: 5 0.40147677063941956
val: 6 0.4095715582370758
val: 7 0.40922239422798157
val: 8 0.3982592225074768
val: 9 0.41212865710258484
val: 10 0.39978814125061035
val: 11 0.4083802103996277
val: 12 0.405953586101532
val: 13 0.4011533558368683
val: 14 0.40374648571014404
val: 15 0.4089938700199127
val: 16 0.40057072043418884
val: 17 0.40346863865852356
val: 18 0.4082346260547638
val: 19 0.40863052010536194
val: 20 0.41414347290992737
val_Epoch:[ 233 ] val_loss: 0.4061818286776543 2022-08-12 01:59:39.290503
start training 2022-08-12 01:59:39.386921
Epoch:[ 234 0 ] loss: 0.3474826514720917 2022-08-12 01:59:54.027565
Epoch:[ 234 1 ] loss: 0.3483215570449829 2022-08-12 01:59:54.553863
Epoch:[ 234 2 ] loss: 0.3485211730003357 2022-08-12 01:59:54.979294
Epoch:[ 234 3 ] loss: 0.3486112356185913 2022-08-12 01:59:55.401760
Epoch:[ 234 4 ] loss: 0.34924906492233276 2022-08-12 01:59:55.823129
Epoch:[ 234 5 ] loss: 0.3482459485530853 2022-08-12 01:59:56.241527
Epoch:[ 234 6 ] loss: 0.34800800681114197 2022-08-12 01:59:56.664341
Epoch:[ 234 7 ] loss: 0.3496013581752777 2022-08-12 01:59:57.089308
Epoch:[ 234 8 ] loss: 0.34916558861732483 2022-08-12 01:59:57.515499
Epoch:[ 234 9 ] loss: 0.3494577705860138 2022-08-12 01:59:57.933310
Epoch:[ 234 10 ] loss: 0.34912973642349243 2022-08-12 01:59:58.348957
Epoch:[ 234 11 ] loss: 0.34904199838638306 2022-08-12 01:59:58.767698
Epoch:[ 234 12 ] loss: 0.3496083915233612 2022-08-12 01:59:59.197062
Epoch:[ 234 13 ] loss: 0.35034388303756714 2022-08-12 01:59:59.621120
Epoch:[ 234 14 ] loss: 0.3486139178276062 2022-08-12 02:00:00.039420
Epoch:[ 234 15 ] loss: 0.3488123416900635 2022-08-12 02:00:00.462621
Epoch:[ 234 16 ] loss: 0.3487207591533661 2022-08-12 02:00:05.878044
Epoch:[ 234 17 ] loss: 0.34867027401924133 2022-08-12 02:00:06.509221
Epoch:[ 234 18 ] loss: 0.3489038646221161 2022-08-12 02:00:06.930222
Epoch:[ 234 19 ] loss: 0.3494178354740143 2022-08-12 02:00:07.353574
Training_Epoch:[ 234 ] Training_loss: 0.34889636784791944 2022-08-12 02:00:07.354276
learning rate:  9.521278810910948e-05
val: 1 0.40448135137557983
val: 2 0.4098135828971863
val: 3 0.41144639253616333
val: 4 0.40759679675102234
val: 5 0.4060992896556854
val: 6 0.4065289795398712
val: 7 0.4193405210971832
val: 8 0.40372124314308167
val: 9 0.40439245104789734
val: 10 0.40362367033958435
val: 11 0.41236940026283264
val: 12 0.4143913686275482
val: 13 0.40693730115890503
val: 14 0.415530264377594
val: 15 0.40161094069480896
val: 16 0.39990144968032837
val: 17 0.4025023877620697
val: 18 0.41540658473968506
val: 19 0.4009871184825897
val: 20 0.4018813967704773
val_Epoch:[ 234 ] val_loss: 0.4074281245470047 2022-08-12 02:00:10.955146
start training 2022-08-12 02:00:11.049502
Epoch:[ 235 0 ] loss: 0.34818246960639954 2022-08-12 02:00:25.978758
Epoch:[ 235 1 ] loss: 0.3483861982822418 2022-08-12 02:00:26.399298
Epoch:[ 235 2 ] loss: 0.3496595025062561 2022-08-12 02:00:26.824138
Epoch:[ 235 3 ] loss: 0.34883615374565125 2022-08-12 02:00:27.248444
Epoch:[ 235 4 ] loss: 0.34852319955825806 2022-08-12 02:00:27.673025
Epoch:[ 235 5 ] loss: 0.35047975182533264 2022-08-12 02:00:28.094907
Epoch:[ 235 6 ] loss: 0.349418580532074 2022-08-12 02:00:28.520577
Epoch:[ 235 7 ] loss: 0.35038381814956665 2022-08-12 02:00:28.941185
Epoch:[ 235 8 ] loss: 0.34848088026046753 2022-08-12 02:00:29.366775
Epoch:[ 235 9 ] loss: 0.34805965423583984 2022-08-12 02:00:29.794520
Epoch:[ 235 10 ] loss: 0.3496922254562378 2022-08-12 02:00:30.224234
Epoch:[ 235 11 ] loss: 0.3502637445926666 2022-08-12 02:00:30.649389
Epoch:[ 235 12 ] loss: 0.3481622338294983 2022-08-12 02:00:31.067460
Epoch:[ 235 13 ] loss: 0.3499959707260132 2022-08-12 02:00:31.490902
Epoch:[ 235 14 ] loss: 0.3493993580341339 2022-08-12 02:00:31.912413
Epoch:[ 235 15 ] loss: 0.3496306240558624 2022-08-12 02:00:32.335674
Epoch:[ 235 16 ] loss: 0.34887632727622986 2022-08-12 02:00:37.442491
Epoch:[ 235 17 ] loss: 0.34988051652908325 2022-08-12 02:00:37.862681
Epoch:[ 235 18 ] loss: 0.3497723937034607 2022-08-12 02:00:38.287064
Epoch:[ 235 19 ] loss: 0.3487198054790497 2022-08-12 02:00:38.707110
Training_Epoch:[ 235 ] Training_loss: 0.3492401704192162 2022-08-12 02:00:38.707812
learning rate:  9.521278810910948e-05
val: 1 0.3983754813671112
val: 2 0.4038558006286621
val: 3 0.4088716506958008
val: 4 0.41183042526245117
val: 5 0.41132885217666626
val: 6 0.4127650856971741
val: 7 0.4102221429347992
val: 8 0.40721938014030457
val: 9 0.4072791337966919
val: 10 0.4030894935131073
val: 11 0.41196396946907043
val: 12 0.39172500371932983
val: 13 0.4142457842826843
val: 14 0.41556471586227417
val: 15 0.40550562739372253
val: 16 0.4089754819869995
val: 17 0.40434756875038147
val: 18 0.4057326912879944
val: 19 0.40810054540634155
val: 20 0.3958742916584015
val_Epoch:[ 235 ] val_loss: 0.40684365630149844 2022-08-12 02:00:42.245950
start training 2022-08-12 02:00:42.337855
Epoch:[ 236 0 ] loss: 0.34960517287254333 2022-08-12 02:00:56.643691
Epoch:[ 236 1 ] loss: 0.349286288022995 2022-08-12 02:00:57.083188
Epoch:[ 236 2 ] loss: 0.3493373990058899 2022-08-12 02:00:57.509284
Epoch:[ 236 3 ] loss: 0.3493650257587433 2022-08-12 02:00:57.933997
Epoch:[ 236 4 ] loss: 0.3492335081100464 2022-08-12 02:00:58.358271
Epoch:[ 236 5 ] loss: 0.34988871216773987 2022-08-12 02:00:58.786666
Epoch:[ 236 6 ] loss: 0.34911566972732544 2022-08-12 02:00:59.209271
Epoch:[ 236 7 ] loss: 0.34892821311950684 2022-08-12 02:00:59.622468
Epoch:[ 236 8 ] loss: 0.3487835228443146 2022-08-12 02:01:00.045613
Epoch:[ 236 9 ] loss: 0.3489503860473633 2022-08-12 02:01:00.477806
Epoch:[ 236 10 ] loss: 0.34953737258911133 2022-08-12 02:01:00.898764
Epoch:[ 236 11 ] loss: 0.3494814932346344 2022-08-12 02:01:01.312474
Epoch:[ 236 12 ] loss: 0.34895771741867065 2022-08-12 02:01:01.736826
Epoch:[ 236 13 ] loss: 0.34877535700798035 2022-08-12 02:01:02.161846
Epoch:[ 236 14 ] loss: 0.3494308590888977 2022-08-12 02:01:02.585135
Epoch:[ 236 15 ] loss: 0.34887102246284485 2022-08-12 02:01:03.004511
Epoch:[ 236 16 ] loss: 0.34862610697746277 2022-08-12 02:01:08.244838
Epoch:[ 236 17 ] loss: 0.34856754541397095 2022-08-12 02:01:08.670316
Epoch:[ 236 18 ] loss: 0.3479875326156616 2022-08-12 02:01:09.096054
Epoch:[ 236 19 ] loss: 0.3476855754852295 2022-08-12 02:01:09.524570
Training_Epoch:[ 236 ] Training_loss: 0.3490207239985466 2022-08-12 02:01:09.525249
learning rate:  9.521278810910948e-05
val: 1 0.40583136677742004
val: 2 0.41260483860969543
val: 3 0.41158464550971985
val: 4 0.4077237844467163
val: 5 0.40499892830848694
val: 6 0.4014688730239868
val: 7 0.4012570381164551
val: 8 0.40472087264060974
val: 9 0.4033091068267822
val: 10 0.41328155994415283
val: 11 0.4088597297668457
val: 12 0.4059959650039673
val: 13 0.4126453399658203
val: 14 0.41257792711257935
val: 15 0.40622085332870483
val: 16 0.41019406914711
val: 17 0.40137436985969543
val: 18 0.4042525589466095
val: 19 0.4073505699634552
val: 20 0.4124153256416321
val_Epoch:[ 236 ] val_loss: 0.40743338614702224 2022-08-12 02:01:13.026582
start training 2022-08-12 02:01:13.120559
Epoch:[ 237 0 ] loss: 0.34936535358428955 2022-08-12 02:01:27.975491
Epoch:[ 237 1 ] loss: 0.34866100549697876 2022-08-12 02:01:28.395209
Epoch:[ 237 2 ] loss: 0.34806951880455017 2022-08-12 02:01:28.823074
Epoch:[ 237 3 ] loss: 0.3499554693698883 2022-08-12 02:01:29.247009
Epoch:[ 237 4 ] loss: 0.34854134917259216 2022-08-12 02:01:29.669801
Epoch:[ 237 5 ] loss: 0.3499261438846588 2022-08-12 02:01:30.090877
Epoch:[ 237 6 ] loss: 0.3487068712711334 2022-08-12 02:01:30.515431
Epoch:[ 237 7 ] loss: 0.3484702706336975 2022-08-12 02:01:30.939296
Epoch:[ 237 8 ] loss: 0.3499561846256256 2022-08-12 02:01:31.359107
Epoch:[ 237 9 ] loss: 0.34839028120040894 2022-08-12 02:01:31.781417
Epoch:[ 237 10 ] loss: 0.34927839040756226 2022-08-12 02:01:32.205411
Epoch:[ 237 11 ] loss: 0.348522424697876 2022-08-12 02:01:32.631268
Epoch:[ 237 12 ] loss: 0.3492744565010071 2022-08-12 02:01:33.053329
Epoch:[ 237 13 ] loss: 0.3487398028373718 2022-08-12 02:01:33.475811
Epoch:[ 237 14 ] loss: 0.3483000099658966 2022-08-12 02:01:33.897376
Epoch:[ 237 15 ] loss: 0.3491382896900177 2022-08-12 02:01:34.316815
Epoch:[ 237 16 ] loss: 0.3477955460548401 2022-08-12 02:01:39.418512
Epoch:[ 237 17 ] loss: 0.34984999895095825 2022-08-12 02:01:39.910164
Epoch:[ 237 18 ] loss: 0.347555935382843 2022-08-12 02:01:40.341401
Epoch:[ 237 19 ] loss: 0.34857624769210815 2022-08-12 02:01:40.763016
Training_Epoch:[ 237 ] Training_loss: 0.3488536775112152 2022-08-12 02:01:40.763699
learning rate:  9.521278810910948e-05
val: 1 0.4050077795982361
val: 2 0.4034667909145355
val: 3 0.4066568911075592
val: 4 0.4111831784248352
val: 5 0.41317179799079895
val: 6 0.40494680404663086
val: 7 0.40569332242012024
val: 8 0.4095447063446045
val: 9 0.4012710452079773
val: 10 0.4068523645401001
val: 11 0.41598162055015564
val: 12 0.41226494312286377
val: 13 0.40365859866142273
val: 14 0.40631628036499023
val: 15 0.41023629903793335
val: 16 0.41243669390678406
val: 17 0.401008665561676
val: 18 0.41055238246917725
val: 19 0.4093717038631439
val: 20 0.40837225317955017
val_Epoch:[ 237 ] val_loss: 0.40789970606565473 2022-08-12 02:01:44.367471
start training 2022-08-12 02:01:44.459887
Epoch:[ 238 0 ] loss: 0.3487354516983032 2022-08-12 02:01:58.943216
Epoch:[ 238 1 ] loss: 0.34947508573532104 2022-08-12 02:01:59.374207
Epoch:[ 238 2 ] loss: 0.34945276379585266 2022-08-12 02:01:59.799364
Epoch:[ 238 3 ] loss: 0.34930408000946045 2022-08-12 02:02:00.215896
Epoch:[ 238 4 ] loss: 0.3491702377796173 2022-08-12 02:02:00.631350
Epoch:[ 238 5 ] loss: 0.34883514046669006 2022-08-12 02:02:01.054106
Epoch:[ 238 6 ] loss: 0.3499426543712616 2022-08-12 02:02:01.478826
Epoch:[ 238 7 ] loss: 0.34889572858810425 2022-08-12 02:02:01.900064
Epoch:[ 238 8 ] loss: 0.34893399477005005 2022-08-12 02:02:02.315595
Epoch:[ 238 9 ] loss: 0.3477492034435272 2022-08-12 02:02:02.736194
Epoch:[ 238 10 ] loss: 0.348685085773468 2022-08-12 02:02:03.160632
Epoch:[ 238 11 ] loss: 0.3487589359283447 2022-08-12 02:02:03.587318
Epoch:[ 238 12 ] loss: 0.348547101020813 2022-08-12 02:02:04.010032
Epoch:[ 238 13 ] loss: 0.348722904920578 2022-08-12 02:02:04.434651
Epoch:[ 238 14 ] loss: 0.3483967185020447 2022-08-12 02:02:04.855763
Epoch:[ 238 15 ] loss: 0.3488105833530426 2022-08-12 02:02:05.281891
Epoch:[ 238 16 ] loss: 0.34896284341812134 2022-08-12 02:02:10.636275
Epoch:[ 238 17 ] loss: 0.3490421772003174 2022-08-12 02:02:11.058772
Epoch:[ 238 18 ] loss: 0.3494777977466583 2022-08-12 02:02:11.478713
Epoch:[ 238 19 ] loss: 0.3483647406101227 2022-08-12 02:02:11.905156
Training_Epoch:[ 238 ] Training_loss: 0.3489131614565849 2022-08-12 02:02:11.905817
learning rate:  9.521278810910948e-05
val: 1 0.4105049967765808
val: 2 0.4015674293041229
val: 3 0.40929460525512695
val: 4 0.411195307970047
val: 5 0.41353610157966614
val: 6 0.41549918055534363
val: 7 0.40654945373535156
val: 8 0.3967994749546051
val: 9 0.4051648676395416
val: 10 0.4105675220489502
val: 11 0.40745431184768677
val: 12 0.4042472243309021
val: 13 0.40705981850624084
val: 14 0.4025287926197052
val: 15 0.4053875505924225
val: 16 0.40422385931015015
val: 17 0.40765509009361267
val: 18 0.39989304542541504
val: 19 0.4130965769290924
val: 20 0.40943199396133423
val_Epoch:[ 238 ] val_loss: 0.4070828601717949 2022-08-12 02:02:15.469101
start training 2022-08-12 02:02:15.562545
Epoch:[ 239 0 ] loss: 0.34828507900238037 2022-08-12 02:02:29.618088
Epoch:[ 239 1 ] loss: 0.3474278450012207 2022-08-12 02:02:30.230888
Epoch:[ 239 2 ] loss: 0.3496171236038208 2022-08-12 02:02:30.649542
Epoch:[ 239 3 ] loss: 0.34797877073287964 2022-08-12 02:02:31.073417
Epoch:[ 239 4 ] loss: 0.34868323802948 2022-08-12 02:02:31.498549
Epoch:[ 239 5 ] loss: 0.34876325726509094 2022-08-12 02:02:31.924759
Epoch:[ 239 6 ] loss: 0.3489322364330292 2022-08-12 02:02:32.345709
Epoch:[ 239 7 ] loss: 0.3494410216808319 2022-08-12 02:02:32.771448
Epoch:[ 239 8 ] loss: 0.34816524386405945 2022-08-12 02:02:33.199121
Epoch:[ 239 9 ] loss: 0.3483622670173645 2022-08-12 02:02:33.625327
Epoch:[ 239 10 ] loss: 0.3486223816871643 2022-08-12 02:02:34.048911
Epoch:[ 239 11 ] loss: 0.34905287623405457 2022-08-12 02:02:34.472251
Epoch:[ 239 12 ] loss: 0.3490690290927887 2022-08-12 02:02:34.896827
Epoch:[ 239 13 ] loss: 0.34844034910202026 2022-08-12 02:02:35.319802
Epoch:[ 239 14 ] loss: 0.348886102437973 2022-08-12 02:02:35.733219
Epoch:[ 239 15 ] loss: 0.34857121109962463 2022-08-12 02:02:36.156075
Epoch:[ 239 16 ] loss: 0.34965965151786804 2022-08-12 02:02:41.438883
Epoch:[ 239 17 ] loss: 0.34833958745002747 2022-08-12 02:02:41.995725
Epoch:[ 239 18 ] loss: 0.34837421774864197 2022-08-12 02:02:42.414259
Epoch:[ 239 19 ] loss: 0.34792372584342957 2022-08-12 02:02:42.840729
Training_Epoch:[ 239 ] Training_loss: 0.3486297607421875 2022-08-12 02:02:42.841498
learning rate:  9.521278810910948e-05
val: 1 0.4107837975025177
val: 2 0.4133215844631195
val: 3 0.40239378809928894
val: 4 0.4125537574291229
val: 5 0.40737903118133545
val: 6 0.40463095903396606
val: 7 0.4073341488838196
val: 8 0.4128415286540985
val: 9 0.4075397551059723
val: 10 0.40463167428970337
val: 11 0.4081597924232483
val: 12 0.3950326144695282
val: 13 0.4155389368534088
val: 14 0.4115515351295471
val: 15 0.4077798128128052
val: 16 0.40026506781578064
val: 17 0.40563541650772095
val: 18 0.4109007716178894
val: 19 0.4050282835960388
val: 20 0.40767702460289
val_Epoch:[ 239 ] val_loss: 0.4075489640235901 2022-08-12 02:02:46.399726
start training 2022-08-12 02:02:46.497963
Epoch:[ 240 0 ] loss: 0.3485735058784485 2022-08-12 02:03:01.027914
Epoch:[ 240 1 ] loss: 0.3479416072368622 2022-08-12 02:03:01.467929
Epoch:[ 240 2 ] loss: 0.34869566559791565 2022-08-12 02:03:01.883342
Epoch:[ 240 3 ] loss: 0.34911197423934937 2022-08-12 02:03:02.306915
Epoch:[ 240 4 ] loss: 0.3493900001049042 2022-08-12 02:03:02.732910
Epoch:[ 240 5 ] loss: 0.3478403687477112 2022-08-12 02:03:03.149206
Epoch:[ 240 6 ] loss: 0.3484102189540863 2022-08-12 02:03:03.567150
Epoch:[ 240 7 ] loss: 0.3492424786090851 2022-08-12 02:03:03.991914
Epoch:[ 240 8 ] loss: 0.34879347681999207 2022-08-12 02:03:04.419813
Epoch:[ 240 9 ] loss: 0.3490211069583893 2022-08-12 02:03:04.848235
Epoch:[ 240 10 ] loss: 0.34801918268203735 2022-08-12 02:03:05.269870
Epoch:[ 240 11 ] loss: 0.3481970429420471 2022-08-12 02:03:05.693041
Epoch:[ 240 12 ] loss: 0.34951135516166687 2022-08-12 02:03:06.113626
Epoch:[ 240 13 ] loss: 0.3476785123348236 2022-08-12 02:03:06.537375
Epoch:[ 240 14 ] loss: 0.34761473536491394 2022-08-12 02:03:06.958961
Epoch:[ 240 15 ] loss: 0.3495464324951172 2022-08-12 02:03:07.384429
Epoch:[ 240 16 ] loss: 0.3484194278717041 2022-08-12 02:03:12.676781
Epoch:[ 240 17 ] loss: 0.3483395278453827 2022-08-12 02:03:13.100246
Epoch:[ 240 18 ] loss: 0.34865108132362366 2022-08-12 02:03:13.527386
Epoch:[ 240 19 ] loss: 0.34871906042099 2022-08-12 02:03:13.951748
Training_Epoch:[ 240 ] Training_loss: 0.34858583807945254 2022-08-12 02:03:13.952412
learning rate:  9.521278810910948e-05
netparams have been saved once 240
val: 1 0.39949169754981995
val: 2 0.40744340419769287
val: 3 0.4050195813179016
val: 4 0.41019999980926514
val: 5 0.4093977212905884
val: 6 0.40817272663116455
val: 7 0.40824949741363525
val: 8 0.40542879700660706
val: 9 0.4099397361278534
val: 10 0.400237113237381
val: 11 0.40632057189941406
val: 12 0.4094836115837097
val: 13 0.4024868607521057
val: 14 0.40695664286613464
val: 15 0.4029497504234314
val: 16 0.41246044635772705
val: 17 0.4050656259059906
val: 18 0.41097283363342285
val: 19 0.40258142352104187
val: 20 0.4089275300502777
val_Epoch:[ 240 ] val_loss: 0.40658927857875826 2022-08-12 02:03:17.567679
start training 2022-08-12 02:03:17.664066
Epoch:[ 241 0 ] loss: 0.3495793342590332 2022-08-12 02:03:32.790127
Epoch:[ 241 1 ] loss: 0.3481793701648712 2022-08-12 02:03:33.216222
Epoch:[ 241 2 ] loss: 0.34759053587913513 2022-08-12 02:03:33.642272
Epoch:[ 241 3 ] loss: 0.3481121063232422 2022-08-12 02:03:34.067743
Epoch:[ 241 4 ] loss: 0.3483954071998596 2022-08-12 02:03:34.488903
Epoch:[ 241 5 ] loss: 0.34885531663894653 2022-08-12 02:03:34.910139
Epoch:[ 241 6 ] loss: 0.3496990501880646 2022-08-12 02:03:35.335815
Epoch:[ 241 7 ] loss: 0.3481672406196594 2022-08-12 02:03:35.760738
Epoch:[ 241 8 ] loss: 0.34823229908943176 2022-08-12 02:03:36.183122
Epoch:[ 241 9 ] loss: 0.3486720621585846 2022-08-12 02:03:36.598005
Epoch:[ 241 10 ] loss: 0.3485686182975769 2022-08-12 02:03:37.017884
Epoch:[ 241 11 ] loss: 0.34775686264038086 2022-08-12 02:03:37.442354
Epoch:[ 241 12 ] loss: 0.3488712012767792 2022-08-12 02:03:37.865691
Epoch:[ 241 13 ] loss: 0.3487049639225006 2022-08-12 02:03:38.283057
Epoch:[ 241 14 ] loss: 0.34820324182510376 2022-08-12 02:03:38.707195
Epoch:[ 241 15 ] loss: 0.34899452328681946 2022-08-12 02:03:39.134494
Epoch:[ 241 16 ] loss: 0.3492010235786438 2022-08-12 02:03:44.323402
Epoch:[ 241 17 ] loss: 0.34825819730758667 2022-08-12 02:03:44.738720
Epoch:[ 241 18 ] loss: 0.3484216332435608 2022-08-12 02:03:45.156206
Epoch:[ 241 19 ] loss: 0.34904706478118896 2022-08-12 02:03:45.579019
Training_Epoch:[ 241 ] Training_loss: 0.34857550263404846 2022-08-12 02:03:45.579681
learning rate:  8.093086989274306e-05
val: 1 0.4004415273666382
val: 2 0.4115064740180969
val: 3 0.4050486981868744
val: 4 0.4043447971343994
val: 5 0.40383854508399963
val: 6 0.40593641996383667
val: 7 0.41189509630203247
val: 8 0.40843963623046875
val: 9 0.4098207950592041
val: 10 0.39811283349990845
val: 11 0.4100789427757263
val: 12 0.4011210501194
val: 13 0.4081234633922577
val: 14 0.4040181040763855
val: 15 0.3994607627391815
val: 16 0.4024299383163452
val: 17 0.4089101254940033
val: 18 0.408893346786499
val: 19 0.4142972528934479
val: 20 0.39906078577041626
val_Epoch:[ 241 ] val_loss: 0.4057889297604561 2022-08-12 02:03:49.153414
start training 2022-08-12 02:03:49.250043
Epoch:[ 242 0 ] loss: 0.3488464653491974 2022-08-12 02:04:03.705819
Epoch:[ 242 1 ] loss: 0.3494085371494293 2022-08-12 02:04:04.468176
Epoch:[ 242 2 ] loss: 0.34789732098579407 2022-08-12 02:04:04.891599
Epoch:[ 242 3 ] loss: 0.34851890802383423 2022-08-12 02:04:05.315523
Epoch:[ 242 4 ] loss: 0.34917107224464417 2022-08-12 02:04:05.735595
Epoch:[ 242 5 ] loss: 0.34784069657325745 2022-08-12 02:04:06.158484
Epoch:[ 242 6 ] loss: 0.3481871485710144 2022-08-12 02:04:06.583949
Epoch:[ 242 7 ] loss: 0.3474351465702057 2022-08-12 02:04:07.002576
Epoch:[ 242 8 ] loss: 0.34845027327537537 2022-08-12 02:04:07.425334
Epoch:[ 242 9 ] loss: 0.3490350544452667 2022-08-12 02:04:07.852984
Epoch:[ 242 10 ] loss: 0.34795117378234863 2022-08-12 02:04:08.281284
Epoch:[ 242 11 ] loss: 0.3485662639141083 2022-08-12 02:04:08.700691
Epoch:[ 242 12 ] loss: 0.3489404618740082 2022-08-12 02:04:09.125123
Epoch:[ 242 13 ] loss: 0.3479735553264618 2022-08-12 02:04:09.548640
Epoch:[ 242 14 ] loss: 0.34724071621894836 2022-08-12 02:04:09.969381
Epoch:[ 242 15 ] loss: 0.34990307688713074 2022-08-12 02:04:10.396558
Epoch:[ 242 16 ] loss: 0.3482944071292877 2022-08-12 02:04:15.561558
Epoch:[ 242 17 ] loss: 0.3492310047149658 2022-08-12 02:04:16.121393
Epoch:[ 242 18 ] loss: 0.34855887293815613 2022-08-12 02:04:16.547534
Epoch:[ 242 19 ] loss: 0.34881603717803955 2022-08-12 02:04:16.972230
Training_Epoch:[ 242 ] Training_loss: 0.3485133096575737 2022-08-12 02:04:16.972930
learning rate:  8.093086989274306e-05
val: 1 0.4079420268535614
val: 2 0.40166938304901123
val: 3 0.4044891893863678
val: 4 0.40248802304267883
val: 5 0.40945354104042053
val: 6 0.40617528557777405
val: 7 0.4046383202075958
val: 8 0.4013044536113739
val: 9 0.41055062413215637
val: 10 0.4089066982269287
val: 11 0.40212109684944153
val: 12 0.40377283096313477
val: 13 0.40379077196121216
val: 14 0.41392630338668823
val: 15 0.4135286509990692
val: 16 0.40029752254486084
val: 17 0.4036538004875183
val: 18 0.41333630681037903
val: 19 0.4102592468261719
val: 20 0.40760356187820435
val_Epoch:[ 242 ] val_loss: 0.40649538189172746 2022-08-12 02:04:20.606954
start training 2022-08-12 02:04:20.702427
Epoch:[ 243 0 ] loss: 0.34975776076316833 2022-08-12 02:04:35.120510
Epoch:[ 243 1 ] loss: 0.34781691431999207 2022-08-12 02:04:35.563004
Epoch:[ 243 2 ] loss: 0.3486965596675873 2022-08-12 02:04:35.989436
Epoch:[ 243 3 ] loss: 0.348117858171463 2022-08-12 02:04:36.415099
Epoch:[ 243 4 ] loss: 0.34789159893989563 2022-08-12 02:04:36.838438
Epoch:[ 243 5 ] loss: 0.348359614610672 2022-08-12 02:04:37.262226
Epoch:[ 243 6 ] loss: 0.348679780960083 2022-08-12 02:04:37.681910
Epoch:[ 243 7 ] loss: 0.34790706634521484 2022-08-12 02:04:38.095236
Epoch:[ 243 8 ] loss: 0.3480973541736603 2022-08-12 02:04:38.518788
Epoch:[ 243 9 ] loss: 0.34789928793907166 2022-08-12 02:04:38.945493
Epoch:[ 243 10 ] loss: 0.3478929400444031 2022-08-12 02:04:39.366795
Epoch:[ 243 11 ] loss: 0.3491727113723755 2022-08-12 02:04:39.784444
Epoch:[ 243 12 ] loss: 0.34840717911720276 2022-08-12 02:04:40.209728
Epoch:[ 243 13 ] loss: 0.3490753471851349 2022-08-12 02:04:40.640250
Epoch:[ 243 14 ] loss: 0.34815075993537903 2022-08-12 02:04:41.066153
Epoch:[ 243 15 ] loss: 0.34785592555999756 2022-08-12 02:04:41.488084
Epoch:[ 243 16 ] loss: 0.34865882992744446 2022-08-12 02:04:47.066519
Epoch:[ 243 17 ] loss: 0.34852278232574463 2022-08-12 02:04:47.490197
Epoch:[ 243 18 ] loss: 0.3484170436859131 2022-08-12 02:04:47.918670
Epoch:[ 243 19 ] loss: 0.34885475039482117 2022-08-12 02:04:48.343514
Training_Epoch:[ 243 ] Training_loss: 0.3484116032719612 2022-08-12 02:04:48.344257
learning rate:  8.093086989274306e-05
val: 1 0.4095100164413452
val: 2 0.4118736982345581
val: 3 0.41525930166244507
val: 4 0.4062846601009369
val: 5 0.41816961765289307
val: 6 0.3978590667247772
val: 7 0.4027383029460907
val: 8 0.4071793258190155
val: 9 0.39865121245384216
val: 10 0.4081944227218628
val: 11 0.40700095891952515
val: 12 0.3975173234939575
val: 13 0.40658220648765564
val: 14 0.39968255162239075
val: 15 0.4001961350440979
val: 16 0.41149407625198364
val: 17 0.4022512435913086
val: 18 0.41251400113105774
val: 19 0.4106483459472656
val: 20 0.4073454439640045
val_Epoch:[ 243 ] val_loss: 0.4065475955605507 2022-08-12 02:04:51.841286
start training 2022-08-12 02:04:51.934041
Epoch:[ 244 0 ] loss: 0.3473343253135681 2022-08-12 02:05:06.917844
Epoch:[ 244 1 ] loss: 0.3479936420917511 2022-08-12 02:05:07.343474
Epoch:[ 244 2 ] loss: 0.3486480414867401 2022-08-12 02:05:07.765099
Epoch:[ 244 3 ] loss: 0.3479904532432556 2022-08-12 02:05:08.190969
Epoch:[ 244 4 ] loss: 0.34712517261505127 2022-08-12 02:05:08.612331
Epoch:[ 244 5 ] loss: 0.3478057384490967 2022-08-12 02:05:09.032564
Epoch:[ 244 6 ] loss: 0.34798723459243774 2022-08-12 02:05:09.451653
Epoch:[ 244 7 ] loss: 0.3486352264881134 2022-08-12 02:05:09.870462
Epoch:[ 244 8 ] loss: 0.34664034843444824 2022-08-12 02:05:10.291308
Epoch:[ 244 9 ] loss: 0.34924381971359253 2022-08-12 02:05:10.709251
Epoch:[ 244 10 ] loss: 0.3480519950389862 2022-08-12 02:05:11.130818
Epoch:[ 244 11 ] loss: 0.34935814142227173 2022-08-12 02:05:11.552004
Epoch:[ 244 12 ] loss: 0.34932467341423035 2022-08-12 02:05:11.974050
Epoch:[ 244 13 ] loss: 0.3489381968975067 2022-08-12 02:05:12.392359
Epoch:[ 244 14 ] loss: 0.34788939356803894 2022-08-12 02:05:12.811797
Epoch:[ 244 15 ] loss: 0.3492594063282013 2022-08-12 02:05:13.229600
Epoch:[ 244 16 ] loss: 0.34847912192344666 2022-08-12 02:05:18.590315
Epoch:[ 244 17 ] loss: 0.3491995334625244 2022-08-12 02:05:19.015824
Epoch:[ 244 18 ] loss: 0.34867048263549805 2022-08-12 02:05:19.441874
Epoch:[ 244 19 ] loss: 0.34826627373695374 2022-08-12 02:05:19.868568
Training_Epoch:[ 244 ] Training_loss: 0.34834206104278564 2022-08-12 02:05:19.869248
learning rate:  8.093086989274306e-05
val: 1 0.4034504294395447
val: 2 0.4152461290359497
val: 3 0.40728089213371277
val: 4 0.40992313623428345
val: 5 0.40968042612075806
val: 6 0.40435394644737244
val: 7 0.40338796377182007
val: 8 0.4129800796508789
val: 9 0.4132263958454132
val: 10 0.40448474884033203
val: 11 0.40167856216430664
val: 12 0.4093712568283081
val: 13 0.4122401475906372
val: 14 0.4055442810058594
val: 15 0.41437995433807373
val: 16 0.4029354453086853
val: 17 0.404129296541214
val: 18 0.4031465947628021
val: 19 0.408968061208725
val: 20 0.40705564618110657
val_Epoch:[ 244 ] val_loss: 0.4076731696724892 2022-08-12 02:05:23.385672
start training 2022-08-12 02:05:23.484940
Epoch:[ 245 0 ] loss: 0.3482714295387268 2022-08-12 02:05:37.525471
Epoch:[ 245 1 ] loss: 0.3489176332950592 2022-08-12 02:05:37.959628
Epoch:[ 245 2 ] loss: 0.3478670120239258 2022-08-12 02:05:38.399731
Epoch:[ 245 3 ] loss: 0.34908735752105713 2022-08-12 02:05:38.822443
Epoch:[ 245 4 ] loss: 0.34830325841903687 2022-08-12 02:05:39.247115
Epoch:[ 245 5 ] loss: 0.3484952449798584 2022-08-12 02:05:39.668165
Epoch:[ 245 6 ] loss: 0.34820207953453064 2022-08-12 02:05:40.082083
Epoch:[ 245 7 ] loss: 0.3489416241645813 2022-08-12 02:05:40.505830
Epoch:[ 245 8 ] loss: 0.3482201099395752 2022-08-12 02:05:40.930288
Epoch:[ 245 9 ] loss: 0.3477250933647156 2022-08-12 02:05:41.353427
Epoch:[ 245 10 ] loss: 0.3486867845058441 2022-08-12 02:05:41.769022
Epoch:[ 245 11 ] loss: 0.3486098349094391 2022-08-12 02:05:42.194575
Epoch:[ 245 12 ] loss: 0.34851565957069397 2022-08-12 02:05:42.621414
Epoch:[ 245 13 ] loss: 0.347366601228714 2022-08-12 02:05:43.044219
Epoch:[ 245 14 ] loss: 0.3489646911621094 2022-08-12 02:05:43.465902
Epoch:[ 245 15 ] loss: 0.347730427980423 2022-08-12 02:05:43.887100
Epoch:[ 245 16 ] loss: 0.3494594693183899 2022-08-12 02:05:49.460553
Epoch:[ 245 17 ] loss: 0.34703320264816284 2022-08-12 02:05:49.879285
Epoch:[ 245 18 ] loss: 0.34724190831184387 2022-08-12 02:05:50.303969
Epoch:[ 245 19 ] loss: 0.34913498163223267 2022-08-12 02:05:50.726627
Training_Epoch:[ 245 ] Training_loss: 0.348338720202446 2022-08-12 02:05:50.727349
learning rate:  8.093086989274306e-05
val: 1 0.40929973125457764
val: 2 0.4068179130554199
val: 3 0.41095998883247375
val: 4 0.40818068385124207
val: 5 0.40445223450660706
val: 6 0.4073449671268463
val: 7 0.40277957916259766
val: 8 0.41583317518234253
val: 9 0.4061222970485687
val: 10 0.39557844400405884
val: 11 0.39966708421707153
val: 12 0.4019821882247925
val: 13 0.4073890447616577
val: 14 0.4044370949268341
val: 15 0.4099120497703552
val: 16 0.40886157751083374
val: 17 0.4133225381374359
val: 18 0.40815383195877075
val: 19 0.40874046087265015
val: 20 0.40410685539245605
val_Epoch:[ 245 ] val_loss: 0.4066970869898796 2022-08-12 02:05:54.341545
start training 2022-08-12 02:05:54.440819
Epoch:[ 246 0 ] loss: 0.3478034734725952 2022-08-12 02:06:09.294982
Epoch:[ 246 1 ] loss: 0.3491216003894806 2022-08-12 02:06:09.715708
Epoch:[ 246 2 ] loss: 0.3480827510356903 2022-08-12 02:06:10.134323
Epoch:[ 246 3 ] loss: 0.34808021783828735 2022-08-12 02:06:10.553635
Epoch:[ 246 4 ] loss: 0.34774458408355713 2022-08-12 02:06:10.977942
Epoch:[ 246 5 ] loss: 0.3488696813583374 2022-08-12 02:06:11.404818
Epoch:[ 246 6 ] loss: 0.34877991676330566 2022-08-12 02:06:11.825781
Epoch:[ 246 7 ] loss: 0.34924131631851196 2022-08-12 02:06:12.249205
Epoch:[ 246 8 ] loss: 0.3472345769405365 2022-08-12 02:06:12.671121
Epoch:[ 246 9 ] loss: 0.3486763834953308 2022-08-12 02:06:13.091770
Epoch:[ 246 10 ] loss: 0.34806159138679504 2022-08-12 02:06:13.517923
Epoch:[ 246 11 ] loss: 0.34867608547210693 2022-08-12 02:06:13.942457
Epoch:[ 246 12 ] loss: 0.3479517698287964 2022-08-12 02:06:14.364352
Epoch:[ 246 13 ] loss: 0.34848931431770325 2022-08-12 02:06:14.779640
Epoch:[ 246 14 ] loss: 0.34818118810653687 2022-08-12 02:06:15.198605
Epoch:[ 246 15 ] loss: 0.34864306449890137 2022-08-12 02:06:15.621933
Epoch:[ 246 16 ] loss: 0.3479779064655304 2022-08-12 02:06:20.716190
Epoch:[ 246 17 ] loss: 0.3488624393939972 2022-08-12 02:06:21.133330
Epoch:[ 246 18 ] loss: 0.34855321049690247 2022-08-12 02:06:21.545670
Epoch:[ 246 19 ] loss: 0.3479967415332794 2022-08-12 02:06:21.970101
Training_Epoch:[ 246 ] Training_loss: 0.34835139065980913 2022-08-12 02:06:21.970754
learning rate:  8.093086989274306e-05
val: 1 0.40777963399887085
val: 2 0.3982187509536743
val: 3 0.4103486239910126
val: 4 0.4061478078365326
val: 5 0.4044550955295563
val: 6 0.40229174494743347
val: 7 0.4141775667667389
val: 8 0.4112652540206909
val: 9 0.41012582182884216
val: 10 0.41887909173965454
val: 11 0.40424448251724243
val: 12 0.41158434748649597
val: 13 0.40796276926994324
val: 14 0.412799596786499
val: 15 0.4106327295303345
val: 16 0.4002577066421509
val: 17 0.4093109965324402
val: 18 0.41038092970848083
val: 19 0.4037915766239166
val: 20 0.404630184173584
val_Epoch:[ 246 ] val_loss: 0.4079642355442047 2022-08-12 02:06:25.571898
start training 2022-08-12 02:06:25.692023
Epoch:[ 247 0 ] loss: 0.34778037667274475 2022-08-12 02:06:40.896620
Epoch:[ 247 1 ] loss: 0.3481490910053253 2022-08-12 02:06:41.316744
Epoch:[ 247 2 ] loss: 0.34875208139419556 2022-08-12 02:06:41.746538
Epoch:[ 247 3 ] loss: 0.34848451614379883 2022-08-12 02:06:42.169608
Epoch:[ 247 4 ] loss: 0.3475736677646637 2022-08-12 02:06:42.590831
Epoch:[ 247 5 ] loss: 0.34923025965690613 2022-08-12 02:06:43.010242
Epoch:[ 247 6 ] loss: 0.3472766578197479 2022-08-12 02:06:43.435879
Epoch:[ 247 7 ] loss: 0.34744590520858765 2022-08-12 02:06:43.864340
Epoch:[ 247 8 ] loss: 0.3486919403076172 2022-08-12 02:06:44.280573
Epoch:[ 247 9 ] loss: 0.34870070219039917 2022-08-12 02:06:44.705127
Epoch:[ 247 10 ] loss: 0.34811025857925415 2022-08-12 02:06:45.130124
Epoch:[ 247 11 ] loss: 0.3483749330043793 2022-08-12 02:06:45.555198
Epoch:[ 247 12 ] loss: 0.34961095452308655 2022-08-12 02:06:45.977870
Epoch:[ 247 13 ] loss: 0.3482707738876343 2022-08-12 02:06:46.401939
Epoch:[ 247 14 ] loss: 0.34927719831466675 2022-08-12 02:06:46.827397
Epoch:[ 247 15 ] loss: 0.349040687084198 2022-08-12 02:06:47.248327
Epoch:[ 247 16 ] loss: 0.34881067276000977 2022-08-12 02:06:52.257822
Epoch:[ 247 17 ] loss: 0.3487030565738678 2022-08-12 02:06:52.681403
Epoch:[ 247 18 ] loss: 0.3474033772945404 2022-08-12 02:06:53.107266
Epoch:[ 247 19 ] loss: 0.3478555977344513 2022-08-12 02:06:53.524000
Training_Epoch:[ 247 ] Training_loss: 0.34837713539600373 2022-08-12 02:06:53.524732
learning rate:  8.093086989274306e-05
val: 1 0.4001401662826538
val: 2 0.4056682288646698
val: 3 0.40566593408584595
val: 4 0.40367206931114197
val: 5 0.4181493818759918
val: 6 0.4088890254497528
val: 7 0.40952444076538086
val: 8 0.4042561650276184
val: 9 0.414732426404953
val: 10 0.4053654372692108
val: 11 0.40712958574295044
val: 12 0.410552978515625
val: 13 0.40312179923057556
val: 14 0.4034934937953949
val: 15 0.4096585214138031
val: 16 0.39944490790367126
val: 17 0.4013364911079407
val: 18 0.40811723470687866
val: 19 0.40638554096221924
val: 20 0.4135249853134155
val_Epoch:[ 247 ] val_loss: 0.4069414407014847 2022-08-12 02:06:57.166756
start training 2022-08-12 02:06:57.262233
Epoch:[ 248 0 ] loss: 0.34805676341056824 2022-08-12 02:07:11.318416
Epoch:[ 248 1 ] loss: 0.34749141335487366 2022-08-12 02:07:11.756947
Epoch:[ 248 2 ] loss: 0.34890225529670715 2022-08-12 02:07:12.185387
Epoch:[ 248 3 ] loss: 0.3473711609840393 2022-08-12 02:07:12.605936
Epoch:[ 248 4 ] loss: 0.3485284447669983 2022-08-12 02:07:13.028157
Epoch:[ 248 5 ] loss: 0.34750092029571533 2022-08-12 02:07:13.451070
Epoch:[ 248 6 ] loss: 0.34832048416137695 2022-08-12 02:07:13.874430
Epoch:[ 248 7 ] loss: 0.34802210330963135 2022-08-12 02:07:14.299107
Epoch:[ 248 8 ] loss: 0.34863701462745667 2022-08-12 02:07:14.720188
Epoch:[ 248 9 ] loss: 0.34922945499420166 2022-08-12 02:07:15.147399
Epoch:[ 248 10 ] loss: 0.3474554717540741 2022-08-12 02:07:15.565713
Epoch:[ 248 11 ] loss: 0.348356693983078 2022-08-12 02:07:15.981163
Epoch:[ 248 12 ] loss: 0.34805798530578613 2022-08-12 02:07:16.405506
Epoch:[ 248 13 ] loss: 0.3491990566253662 2022-08-12 02:07:16.833131
Epoch:[ 248 14 ] loss: 0.3472520112991333 2022-08-12 02:07:17.255350
Epoch:[ 248 15 ] loss: 0.3479924201965332 2022-08-12 02:07:17.676123
Epoch:[ 248 16 ] loss: 0.34788501262664795 2022-08-12 02:07:23.173776
Epoch:[ 248 17 ] loss: 0.3483140468597412 2022-08-12 02:07:23.595117
Epoch:[ 248 18 ] loss: 0.3491916060447693 2022-08-12 02:07:24.396434
Epoch:[ 248 19 ] loss: 0.3487606644630432 2022-08-12 02:07:24.821062
Training_Epoch:[ 248 ] Training_loss: 0.34822624921798706 2022-08-12 02:07:24.821809
learning rate:  8.093086989274306e-05
val: 1 0.40550440549850464
val: 2 0.41114547848701477
val: 3 0.4151991605758667
val: 4 0.40113112330436707
val: 5 0.40528804063796997
val: 6 0.4039624333381653
val: 7 0.40518423914909363
val: 8 0.41828036308288574
val: 9 0.4089283347129822
val: 10 0.40865498781204224
val: 11 0.4047538638114929
val: 12 0.4065074920654297
val: 13 0.40819188952445984
val: 14 0.4099431037902832
val: 15 0.40756261348724365
val: 16 0.4072534441947937
val: 17 0.40644994378089905
val: 18 0.4092143774032593
val: 19 0.40006884932518005
val: 20 0.4051128625869751
val_Epoch:[ 248 ] val_loss: 0.40741685032844543 2022-08-12 02:07:28.325926
start training 2022-08-12 02:07:28.425461
Epoch:[ 249 0 ] loss: 0.3474563658237457 2022-08-12 02:07:42.978944
Epoch:[ 249 1 ] loss: 0.3468174636363983 2022-08-12 02:07:43.398920
Epoch:[ 249 2 ] loss: 0.3480152487754822 2022-08-12 02:07:43.822828
Epoch:[ 249 3 ] loss: 0.34795963764190674 2022-08-12 02:07:44.248852
Epoch:[ 249 4 ] loss: 0.3484087288379669 2022-08-12 02:07:44.673185
Epoch:[ 249 5 ] loss: 0.3484179973602295 2022-08-12 02:07:45.089820
Epoch:[ 249 6 ] loss: 0.34941643476486206 2022-08-12 02:07:45.511759
Epoch:[ 249 7 ] loss: 0.34891536831855774 2022-08-12 02:07:45.933321
Epoch:[ 249 8 ] loss: 0.34853819012641907 2022-08-12 02:07:46.360088
Epoch:[ 249 9 ] loss: 0.3476523458957672 2022-08-12 02:07:46.787740
Epoch:[ 249 10 ] loss: 0.34768205881118774 2022-08-12 02:07:47.211262
Epoch:[ 249 11 ] loss: 0.34872758388519287 2022-08-12 02:07:47.632195
Epoch:[ 249 12 ] loss: 0.34872061014175415 2022-08-12 02:07:48.053312
Epoch:[ 249 13 ] loss: 0.34827086329460144 2022-08-12 02:07:48.464816
Epoch:[ 249 14 ] loss: 0.34823688864707947 2022-08-12 02:07:48.885344
Epoch:[ 249 15 ] loss: 0.3486052453517914 2022-08-12 02:07:49.313161
Epoch:[ 249 16 ] loss: 0.3488316833972931 2022-08-12 02:07:54.643565
Epoch:[ 249 17 ] loss: 0.3498440682888031 2022-08-12 02:07:55.066758
Epoch:[ 249 18 ] loss: 0.34880563616752625 2022-08-12 02:07:55.490606
Epoch:[ 249 19 ] loss: 0.3481289744377136 2022-08-12 02:07:55.914875
Training_Epoch:[ 249 ] Training_loss: 0.3483725696802139 2022-08-12 02:07:55.915555
learning rate:  8.093086989274306e-05
val: 1 0.41629308462142944
val: 2 0.4112444221973419
val: 3 0.3984423875808716
val: 4 0.41362202167510986
val: 5 0.4061988592147827
val: 6 0.4038994312286377
val: 7 0.39687129855155945
val: 8 0.4087929129600525
val: 9 0.40904974937438965
val: 10 0.4080478250980377
val: 11 0.40692654252052307
val: 12 0.4133875370025635
val: 13 0.40225750207901
val: 14 0.40007323026657104
val: 15 0.4093831181526184
val: 16 0.4122806191444397
val: 17 0.40347129106521606
val: 18 0.41017580032348633
val: 19 0.410165399312973
val: 20 0.4115568995475769
val_Epoch:[ 249 ] val_loss: 0.4076069965958595 2022-08-12 02:07:59.414584
start training 2022-08-12 02:07:59.510153
Epoch:[ 250 0 ] loss: 0.34799712896347046 2022-08-12 02:08:14.191469
Epoch:[ 250 1 ] loss: 0.34790459275245667 2022-08-12 02:08:14.689563
Epoch:[ 250 2 ] loss: 0.34810003638267517 2022-08-12 02:08:15.115027
Epoch:[ 250 3 ] loss: 0.3486768305301666 2022-08-12 02:08:15.541661
Epoch:[ 250 4 ] loss: 0.34933415055274963 2022-08-12 02:08:15.965357
Epoch:[ 250 5 ] loss: 0.3497556149959564 2022-08-12 02:08:16.383416
Epoch:[ 250 6 ] loss: 0.3502364158630371 2022-08-12 02:08:16.799810
Epoch:[ 250 7 ] loss: 0.34857332706451416 2022-08-12 02:08:17.218857
Epoch:[ 250 8 ] loss: 0.34807953238487244 2022-08-12 02:08:17.643801
Epoch:[ 250 9 ] loss: 0.3487282991409302 2022-08-12 02:08:18.063169
Epoch:[ 250 10 ] loss: 0.34729671478271484 2022-08-12 02:08:18.485263
Epoch:[ 250 11 ] loss: 0.3485458195209503 2022-08-12 02:08:18.907830
Epoch:[ 250 12 ] loss: 0.34788209199905396 2022-08-12 02:08:19.338305
Epoch:[ 250 13 ] loss: 0.3484908938407898 2022-08-12 02:08:19.763545
Epoch:[ 250 14 ] loss: 0.3489671051502228 2022-08-12 02:08:20.185804
Epoch:[ 250 15 ] loss: 0.34821486473083496 2022-08-12 02:08:20.609467
Epoch:[ 250 16 ] loss: 0.3475330173969269 2022-08-12 02:08:26.372025
Epoch:[ 250 17 ] loss: 0.34781089425086975 2022-08-12 02:08:26.794052
Epoch:[ 250 18 ] loss: 0.349626362323761 2022-08-12 02:08:27.218167
Epoch:[ 250 19 ] loss: 0.34796592593193054 2022-08-12 02:08:27.636326
Training_Epoch:[ 250 ] Training_loss: 0.3484859809279442 2022-08-12 02:08:27.637048
learning rate:  8.093086989274306e-05
netparams have been saved once 250
val: 1 0.40663525462150574
val: 2 0.41146591305732727
val: 3 0.3968477249145508
val: 4 0.3974861204624176
val: 5 0.40783387422561646
val: 6 0.40295717120170593
val: 7 0.4075082540512085
val: 8 0.4097835123538971
val: 9 0.4065721333026886
val: 10 0.4197673499584198
val: 11 0.4050651788711548
val: 12 0.4115928113460541
val: 13 0.40453770756721497
val: 14 0.412049263715744
val: 15 0.4072670340538025
val: 16 0.40988215804100037
val: 17 0.405251681804657
val: 18 0.4092290699481964
val: 19 0.4058045446872711
val: 20 0.4046478271484375
val_Epoch:[ 250 ] val_loss: 0.4071092292666435 2022-08-12 02:08:31.288787
