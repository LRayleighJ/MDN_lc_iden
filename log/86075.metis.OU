GPU: True
80
start training 2022-05-30 01:08:05.661936
Epoch:[ 1 0 ] loss: 0.7163298726081848 2022-05-30 01:08:36.488152
Epoch:[ 1 1 ] loss: 0.7045238614082336 2022-05-30 01:08:37.334716
Epoch:[ 1 2 ] loss: 0.7001004815101624 2022-05-30 01:08:38.115398
Epoch:[ 1 3 ] loss: 0.689883828163147 2022-05-30 01:08:38.895507
Epoch:[ 1 4 ] loss: 0.6833961606025696 2022-05-30 01:08:39.677328
Epoch:[ 1 5 ] loss: 0.677666425704956 2022-05-30 01:08:40.457650
Epoch:[ 1 6 ] loss: 0.6736972332000732 2022-05-30 01:08:41.237032
Epoch:[ 1 7 ] loss: 0.6685557961463928 2022-05-30 01:08:42.013356
Epoch:[ 1 8 ] loss: 0.6652236580848694 2022-05-30 01:08:42.792130
Epoch:[ 1 9 ] loss: 0.6610797047615051 2022-05-30 01:08:43.567553
Epoch:[ 1 10 ] loss: 0.656650960445404 2022-05-30 01:08:44.341687
Epoch:[ 1 11 ] loss: 0.6532210111618042 2022-05-30 01:08:45.118399
Epoch:[ 1 12 ] loss: 0.6483649611473083 2022-05-30 01:08:45.894869
Epoch:[ 1 13 ] loss: 0.644541323184967 2022-05-30 01:08:46.675061
Epoch:[ 1 14 ] loss: 0.6407308578491211 2022-05-30 01:08:47.452944
Epoch:[ 1 15 ] loss: 0.6360981464385986 2022-05-30 01:08:48.230722
Epoch:[ 1 16 ] loss: 0.6315621733665466 2022-05-30 01:08:49.003420
Epoch:[ 1 17 ] loss: 0.6278022527694702 2022-05-30 01:08:49.779264
Epoch:[ 1 18 ] loss: 0.6237666606903076 2022-05-30 01:08:50.557214
Epoch:[ 1 19 ] loss: 0.6197687983512878 2022-05-30 01:08:51.333410
Training_Epoch:[ 1 ] Training_loss: 0.6611482083797455 2022-05-30 01:08:51.334016
learning rate:  0.005
val: 1 0.7019482254981995
val: 2 0.6961314082145691
val: 3 0.692406415939331
val: 4 0.6747323870658875
val: 5 0.7021668553352356
val: 6 0.6938759684562683
val: 7 0.6923485994338989
val: 8 0.6918987035751343
val: 9 0.6983761787414551
val: 10 0.6983135938644409
val: 11 0.6850614547729492
val: 12 0.7024857401847839
val: 13 0.6903024315834045
val: 14 0.6893394589424133
val: 15 0.6952446699142456
val: 16 0.6918336153030396
val: 17 0.6866512298583984
val: 18 0.6916339993476868
val: 19 0.6888337135314941
val: 20 0.6904661655426025
val_Epoch:[ 1 ] val_loss: 0.6927025407552719 2022-05-30 01:08:57.121542
start training 2022-05-30 01:08:57.219672
Epoch:[ 2 0 ] loss: 0.6165871024131775 2022-05-30 01:09:20.398483
Epoch:[ 2 1 ] loss: 0.611828625202179 2022-05-30 01:09:21.213833
Epoch:[ 2 2 ] loss: 0.6078696846961975 2022-05-30 01:09:21.990556
Epoch:[ 2 3 ] loss: 0.60692298412323 2022-05-30 01:09:22.769262
Epoch:[ 2 4 ] loss: 0.6020411849021912 2022-05-30 01:09:23.546439
Epoch:[ 2 5 ] loss: 0.602126955986023 2022-05-30 01:09:24.321303
Epoch:[ 2 6 ] loss: 0.5933687090873718 2022-05-30 01:09:25.101522
Epoch:[ 2 7 ] loss: 0.5937642455101013 2022-05-30 01:09:25.878286
Epoch:[ 2 8 ] loss: 0.5895627737045288 2022-05-30 01:09:26.656702
Epoch:[ 2 9 ] loss: 0.5859980583190918 2022-05-30 01:09:27.436828
Epoch:[ 2 10 ] loss: 0.58785080909729 2022-05-30 01:09:28.212937
Epoch:[ 2 11 ] loss: 0.5845569968223572 2022-05-30 01:09:28.990395
Epoch:[ 2 12 ] loss: 0.582885205745697 2022-05-30 01:09:29.765408
Epoch:[ 2 13 ] loss: 0.5775734782218933 2022-05-30 01:09:30.545048
Epoch:[ 2 14 ] loss: 0.5759649276733398 2022-05-30 01:09:31.323705
Epoch:[ 2 15 ] loss: 0.5747727751731873 2022-05-30 01:09:32.113187
Epoch:[ 2 16 ] loss: 0.5695132613182068 2022-05-30 01:09:39.598318
Epoch:[ 2 17 ] loss: 0.5712131857872009 2022-05-30 01:09:40.375092
Epoch:[ 2 18 ] loss: 0.5713889598846436 2022-05-30 01:09:41.168929
Epoch:[ 2 19 ] loss: 0.5685098767280579 2022-05-30 01:09:41.941779
Training_Epoch:[ 2 ] Training_loss: 0.5887149900197983 2022-05-30 01:09:41.942455
learning rate:  0.005
netparams have been saved once 2
val: 1 0.5777454376220703
val: 2 0.5661562085151672
val: 3 0.5630812644958496
val: 4 0.568571925163269
val: 5 0.5652158856391907
val: 6 0.5738441944122314
val: 7 0.5621416568756104
val: 8 0.5641728043556213
val: 9 0.5846571922302246
val: 10 0.5754795670509338
val: 11 0.5590547323226929
val: 12 0.5646390914916992
val: 13 0.5655480623245239
val: 14 0.556865394115448
val: 15 0.5661914944648743
val: 16 0.5559816956520081
val: 17 0.572147011756897
val: 18 0.5710363388061523
val: 19 0.5652864575386047
val: 20 0.5695603489875793
val_Epoch:[ 2 ] val_loss: 0.5673688381910325 2022-05-30 01:09:47.411632
start training 2022-05-30 01:09:47.503072
Epoch:[ 3 0 ] loss: 0.5663257241249084 2022-05-30 01:10:09.813507
Epoch:[ 3 1 ] loss: 0.5659149885177612 2022-05-30 01:10:10.860070
Epoch:[ 3 2 ] loss: 0.5646342635154724 2022-05-30 01:10:11.673480
Epoch:[ 3 3 ] loss: 0.5617392659187317 2022-05-30 01:10:12.451721
Epoch:[ 3 4 ] loss: 0.5652956366539001 2022-05-30 01:10:13.228768
Epoch:[ 3 5 ] loss: 0.5653538107872009 2022-05-30 01:10:14.004339
Epoch:[ 3 6 ] loss: 0.5652801990509033 2022-05-30 01:10:14.780015
Epoch:[ 3 7 ] loss: 0.5623995065689087 2022-05-30 01:10:15.558047
Epoch:[ 3 8 ] loss: 0.5614795088768005 2022-05-30 01:10:16.335720
Epoch:[ 3 9 ] loss: 0.560198187828064 2022-05-30 01:10:17.113249
Epoch:[ 3 10 ] loss: 0.5608240962028503 2022-05-30 01:10:17.891979
Epoch:[ 3 11 ] loss: 0.560701310634613 2022-05-30 01:10:18.667981
Epoch:[ 3 12 ] loss: 0.5575450658798218 2022-05-30 01:10:19.446589
Epoch:[ 3 13 ] loss: 0.5591461062431335 2022-05-30 01:10:20.223134
Epoch:[ 3 14 ] loss: 0.5554397106170654 2022-05-30 01:10:21.001997
Epoch:[ 3 15 ] loss: 0.5591204762458801 2022-05-30 01:10:21.779863
Epoch:[ 3 16 ] loss: 0.5592959523200989 2022-05-30 01:10:29.447014
Epoch:[ 3 17 ] loss: 0.5566884875297546 2022-05-30 01:10:30.225476
Epoch:[ 3 18 ] loss: 0.5545373558998108 2022-05-30 01:10:31.006526
Epoch:[ 3 19 ] loss: 0.551342785358429 2022-05-30 01:10:31.782915
Training_Epoch:[ 3 ] Training_loss: 0.5606631219387055 2022-05-30 01:10:31.783569
learning rate:  0.005
val: 1 0.6478094458580017
val: 2 0.649587869644165
val: 3 0.6458779573440552
val: 4 0.6451402306556702
val: 5 0.6461824774742126
val: 6 0.6435223817825317
val: 7 0.649551272392273
val: 8 0.644382655620575
val: 9 0.6441697478294373
val: 10 0.6472815871238708
val: 11 0.6485194563865662
val: 12 0.6478337049484253
val: 13 0.6524954438209534
val: 14 0.645830512046814
val: 15 0.6432214379310608
val: 16 0.648432195186615
val: 17 0.6468268036842346
val: 18 0.64532470703125
val: 19 0.6512212753295898
val: 20 0.6471896767616272
val_Epoch:[ 3 ] val_loss: 0.6470200419425964 2022-05-30 01:10:37.140902
start training 2022-05-30 01:10:37.246705
Epoch:[ 4 0 ] loss: 0.5567858815193176 2022-05-30 01:11:01.484694
Epoch:[ 4 1 ] loss: 0.5565683245658875 2022-05-30 01:11:02.263606
Epoch:[ 4 2 ] loss: 0.5529338717460632 2022-05-30 01:11:03.042801
Epoch:[ 4 3 ] loss: 0.5528339147567749 2022-05-30 01:11:03.821351
Epoch:[ 4 4 ] loss: 0.5542703866958618 2022-05-30 01:11:04.599522
Epoch:[ 4 5 ] loss: 0.5532333254814148 2022-05-30 01:11:05.376227
Epoch:[ 4 6 ] loss: 0.5524503588676453 2022-05-30 01:11:06.152716
Epoch:[ 4 7 ] loss: 0.5509852766990662 2022-05-30 01:11:06.929052
Epoch:[ 4 8 ] loss: 0.5512077212333679 2022-05-30 01:11:07.708816
Epoch:[ 4 9 ] loss: 0.5525141954421997 2022-05-30 01:11:08.488021
Epoch:[ 4 10 ] loss: 0.549474835395813 2022-05-30 01:11:09.277677
Epoch:[ 4 11 ] loss: 0.5539447069168091 2022-05-30 01:11:10.058443
Epoch:[ 4 12 ] loss: 0.552166223526001 2022-05-30 01:11:10.834473
Epoch:[ 4 13 ] loss: 0.5483015775680542 2022-05-30 01:11:11.613534
Epoch:[ 4 14 ] loss: 0.5486888289451599 2022-05-30 01:11:12.389081
Epoch:[ 4 15 ] loss: 0.5496582388877869 2022-05-30 01:11:13.168808
Epoch:[ 4 16 ] loss: 0.5484291315078735 2022-05-30 01:11:20.003032
Epoch:[ 4 17 ] loss: 0.541816771030426 2022-05-30 01:11:20.781723
Epoch:[ 4 18 ] loss: 0.5508091449737549 2022-05-30 01:11:21.564656
Epoch:[ 4 19 ] loss: 0.5520264506340027 2022-05-30 01:11:22.340535
Training_Epoch:[ 4 ] Training_loss: 0.551454958319664 2022-05-30 01:11:22.341186
learning rate:  0.005
netparams have been saved once 4
val: 1 0.594784140586853
val: 2 0.5749394297599792
val: 3 0.5732049942016602
val: 4 0.5737898349761963
val: 5 0.5738126635551453
val: 6 0.5942693948745728
val: 7 0.5902729034423828
val: 8 0.5835217833518982
val: 9 0.5889157056808472
val: 10 0.5871850848197937
val: 11 0.6036734580993652
val: 12 0.5904290080070496
val: 13 0.588997483253479
val: 14 0.5948162078857422
val: 15 0.5996822118759155
val: 16 0.5989732146263123
val: 17 0.583577036857605
val: 18 0.5863788723945618
val: 19 0.5847559571266174
val: 20 0.5784195065498352
val_Epoch:[ 4 ] val_loss: 0.5872199445962906 2022-05-30 01:11:27.796449
start training 2022-05-30 01:11:27.890929
Epoch:[ 5 0 ] loss: 0.5516251921653748 2022-05-30 01:11:50.789506
Epoch:[ 5 1 ] loss: 0.5432462692260742 2022-05-30 01:11:51.588633
Epoch:[ 5 2 ] loss: 0.5452821850776672 2022-05-30 01:11:52.368742
Epoch:[ 5 3 ] loss: 0.545409619808197 2022-05-30 01:11:53.146832
Epoch:[ 5 4 ] loss: 0.5471214652061462 2022-05-30 01:11:53.938074
Epoch:[ 5 5 ] loss: 0.5502521395683289 2022-05-30 01:11:54.715512
Epoch:[ 5 6 ] loss: 0.5511659979820251 2022-05-30 01:11:55.491010
Epoch:[ 5 7 ] loss: 0.5474036931991577 2022-05-30 01:11:56.269172
Epoch:[ 5 8 ] loss: 0.5452355146408081 2022-05-30 01:11:57.047057
Epoch:[ 5 9 ] loss: 0.5418996214866638 2022-05-30 01:11:57.823816
Epoch:[ 5 10 ] loss: 0.5435253381729126 2022-05-30 01:11:58.603437
Epoch:[ 5 11 ] loss: 0.5401255488395691 2022-05-30 01:11:59.380537
Epoch:[ 5 12 ] loss: 0.5443962216377258 2022-05-30 01:12:00.160323
Epoch:[ 5 13 ] loss: 0.5471962094306946 2022-05-30 01:12:00.935658
Epoch:[ 5 14 ] loss: 0.5481164455413818 2022-05-30 01:12:01.714447
Epoch:[ 5 15 ] loss: 0.5464490056037903 2022-05-30 01:12:02.489868
Epoch:[ 5 16 ] loss: 0.5493228435516357 2022-05-30 01:12:10.919406
Epoch:[ 5 17 ] loss: 0.5440900325775146 2022-05-30 01:12:11.695688
Epoch:[ 5 18 ] loss: 0.5485533475875854 2022-05-30 01:12:12.476042
Epoch:[ 5 19 ] loss: 0.5436702966690063 2022-05-30 01:12:13.251216
Training_Epoch:[ 5 ] Training_loss: 0.546204349398613 2022-05-30 01:12:13.251875
learning rate:  0.005
val: 1 0.6051413416862488
val: 2 0.5837582349777222
val: 3 0.5960659980773926
val: 4 0.5733581781387329
val: 5 0.5926965475082397
val: 6 0.6039761304855347
val: 7 0.5947000980377197
val: 8 0.562791109085083
val: 9 0.5804013609886169
val: 10 0.5983930230140686
val: 11 0.5861026644706726
val: 12 0.5934877991676331
val: 13 0.5986588597297668
val: 14 0.5711073875427246
val: 15 0.5886512994766235
val: 16 0.579430103302002
val: 17 0.5952496528625488
val: 18 0.5884966850280762
val: 19 0.609426736831665
val: 20 0.6007174849510193
val_Epoch:[ 5 ] val_loss: 0.5901305347681045 2022-05-30 01:12:18.711477
start training 2022-05-30 01:12:18.814000
Epoch:[ 6 0 ] loss: 0.5446950197219849 2022-05-30 01:12:41.890033
Epoch:[ 6 1 ] loss: 0.5440818071365356 2022-05-30 01:12:42.690609
Epoch:[ 6 2 ] loss: 0.5535011291503906 2022-05-30 01:12:43.465430
Epoch:[ 6 3 ] loss: 0.5435506105422974 2022-05-30 01:12:44.257126
Epoch:[ 6 4 ] loss: 0.5407810807228088 2022-05-30 01:12:45.035625
Epoch:[ 6 5 ] loss: 0.5435262322425842 2022-05-30 01:12:45.815550
Epoch:[ 6 6 ] loss: 0.545035183429718 2022-05-30 01:12:46.595760
Epoch:[ 6 7 ] loss: 0.5412637591362 2022-05-30 01:12:47.373273
Epoch:[ 6 8 ] loss: 0.5457202196121216 2022-05-30 01:12:48.151794
Epoch:[ 6 9 ] loss: 0.5419962406158447 2022-05-30 01:12:48.931274
Epoch:[ 6 10 ] loss: 0.5447720885276794 2022-05-30 01:12:49.712016
Epoch:[ 6 11 ] loss: 0.5412108302116394 2022-05-30 01:12:50.491057
Epoch:[ 6 12 ] loss: 0.5416950583457947 2022-05-30 01:12:51.270720
Epoch:[ 6 13 ] loss: 0.5419067144393921 2022-05-30 01:12:52.047238
Epoch:[ 6 14 ] loss: 0.541915774345398 2022-05-30 01:12:52.824354
Epoch:[ 6 15 ] loss: 0.5395599007606506 2022-05-30 01:12:53.601207
Epoch:[ 6 16 ] loss: 0.5393182635307312 2022-05-30 01:13:01.339789
Epoch:[ 6 17 ] loss: 0.5410321950912476 2022-05-30 01:13:02.117711
Epoch:[ 6 18 ] loss: 0.5421581864356995 2022-05-30 01:13:02.900966
Epoch:[ 6 19 ] loss: 0.5363094210624695 2022-05-30 01:13:03.678607
Training_Epoch:[ 6 ] Training_loss: 0.5427014857530594 2022-05-30 01:13:03.679272
learning rate:  0.005
netparams have been saved once 6
val: 1 0.5396165251731873
val: 2 0.5389822125434875
val: 3 0.539498507976532
val: 4 0.5375484824180603
val: 5 0.5215287208557129
val: 6 0.5428643226623535
val: 7 0.5339083075523376
val: 8 0.5426792502403259
val: 9 0.5449967384338379
val: 10 0.5318459272384644
val: 11 0.5467125773429871
val: 12 0.5427480936050415
val: 13 0.5496869087219238
val: 14 0.5597673654556274
val: 15 0.5534671545028687
val: 16 0.5480504631996155
val: 17 0.5366707444190979
val: 18 0.5535260438919067
val: 19 0.5494082570075989
val: 20 0.5559809803962708
val_Epoch:[ 6 ] val_loss: 0.5434743791818619 2022-05-30 01:13:09.240207
start training 2022-05-30 01:13:09.338137
Epoch:[ 7 0 ] loss: 0.5384193062782288 2022-05-30 01:13:33.434177
Epoch:[ 7 1 ] loss: 0.538013219833374 2022-05-30 01:13:34.210359
Epoch:[ 7 2 ] loss: 0.5397608876228333 2022-05-30 01:13:34.997449
Epoch:[ 7 3 ] loss: 0.5373305082321167 2022-05-30 01:13:35.772859
Epoch:[ 7 4 ] loss: 0.539565920829773 2022-05-30 01:13:36.553557
Epoch:[ 7 5 ] loss: 0.542465329170227 2022-05-30 01:13:37.333388
Epoch:[ 7 6 ] loss: 0.5412915945053101 2022-05-30 01:13:38.110176
Epoch:[ 7 7 ] loss: 0.5338485240936279 2022-05-30 01:13:38.889155
Epoch:[ 7 8 ] loss: 0.5399880409240723 2022-05-30 01:13:39.666251
Epoch:[ 7 9 ] loss: 0.5387071371078491 2022-05-30 01:13:40.444650
Epoch:[ 7 10 ] loss: 0.5364385843276978 2022-05-30 01:13:41.220248
Epoch:[ 7 11 ] loss: 0.5332721471786499 2022-05-30 01:13:41.997599
Epoch:[ 7 12 ] loss: 0.5372512340545654 2022-05-30 01:13:42.777485
Epoch:[ 7 13 ] loss: 0.538420557975769 2022-05-30 01:13:43.556597
Epoch:[ 7 14 ] loss: 0.5362696051597595 2022-05-30 01:13:44.335989
Epoch:[ 7 15 ] loss: 0.533116340637207 2022-05-30 01:13:45.112744
Epoch:[ 7 16 ] loss: 0.5388995409011841 2022-05-30 01:13:51.700386
Epoch:[ 7 17 ] loss: 0.5352959036827087 2022-05-30 01:13:52.513919
Epoch:[ 7 18 ] loss: 0.5373777151107788 2022-05-30 01:13:53.307964
Epoch:[ 7 19 ] loss: 0.5329529643058777 2022-05-30 01:13:54.085316
Training_Epoch:[ 7 ] Training_loss: 0.5374342530965805 2022-05-30 01:13:54.086017
learning rate:  0.005
val: 1 0.5427672863006592
val: 2 0.5421704649925232
val: 3 0.5358983874320984
val: 4 0.549572765827179
val: 5 0.5419831871986389
val: 6 0.5355914235115051
val: 7 0.5449014902114868
val: 8 0.5362676382064819
val: 9 0.5483826398849487
val: 10 0.5363451838493347
val: 11 0.544696033000946
val: 12 0.5430352687835693
val: 13 0.5363755822181702
val: 14 0.5462236404418945
val: 15 0.5499436855316162
val: 16 0.5364789366722107
val: 17 0.5363134741783142
val: 18 0.5644027590751648
val: 19 0.5450452566146851
val: 20 0.5327433347702026
val_Epoch:[ 7 ] val_loss: 0.5424569219350814 2022-05-30 01:13:59.391113
start training 2022-05-30 01:13:59.489982
Epoch:[ 8 0 ] loss: 0.5360727310180664 2022-05-30 01:14:23.434008
Epoch:[ 8 1 ] loss: 0.5318649411201477 2022-05-30 01:14:24.211050
Epoch:[ 8 2 ] loss: 0.5374265909194946 2022-05-30 01:14:24.986967
Epoch:[ 8 3 ] loss: 0.5325571298599243 2022-05-30 01:14:25.761093
Epoch:[ 8 4 ] loss: 0.5377374887466431 2022-05-30 01:14:26.535209
Epoch:[ 8 5 ] loss: 0.5312730669975281 2022-05-30 01:14:27.312824
Epoch:[ 8 6 ] loss: 0.5357536673545837 2022-05-30 01:14:28.093097
Epoch:[ 8 7 ] loss: 0.5382255911827087 2022-05-30 01:14:28.868195
Epoch:[ 8 8 ] loss: 0.5337767601013184 2022-05-30 01:14:29.644743
Epoch:[ 8 9 ] loss: 0.5391802191734314 2022-05-30 01:14:30.431587
Epoch:[ 8 10 ] loss: 0.5336436033248901 2022-05-30 01:14:31.208057
Epoch:[ 8 11 ] loss: 0.5321688652038574 2022-05-30 01:14:31.983951
Epoch:[ 8 12 ] loss: 0.5312787890434265 2022-05-30 01:14:32.762629
Epoch:[ 8 13 ] loss: 0.5332351922988892 2022-05-30 01:14:33.540612
Epoch:[ 8 14 ] loss: 0.533898651599884 2022-05-30 01:14:34.318462
Epoch:[ 8 15 ] loss: 0.5319634079933167 2022-05-30 01:14:35.094386
Epoch:[ 8 16 ] loss: 0.5393249988555908 2022-05-30 01:14:41.947401
Epoch:[ 8 17 ] loss: 0.53545081615448 2022-05-30 01:14:42.722019
Epoch:[ 8 18 ] loss: 0.5329341888427734 2022-05-30 01:14:43.499188
Epoch:[ 8 19 ] loss: 0.5282477736473083 2022-05-30 01:14:44.274943
Training_Epoch:[ 8 ] Training_loss: 0.5343007236719132 2022-05-30 01:14:44.275562
learning rate:  0.005
netparams have been saved once 8
val: 1 0.5490329265594482
val: 2 0.5411533117294312
val: 3 0.5390612483024597
val: 4 0.5302249789237976
val: 5 0.5264227390289307
val: 6 0.5554202795028687
val: 7 0.5202719569206238
val: 8 0.5354290008544922
val: 9 0.5266354084014893
val: 10 0.5282787084579468
val: 11 0.5401189923286438
val: 12 0.5408852696418762
val: 13 0.528343915939331
val: 14 0.5361373424530029
val: 15 0.5357605218887329
val: 16 0.5412915349006653
val: 17 0.5513184666633606
val: 18 0.5213430523872375
val: 19 0.5471900701522827
val: 20 0.5438535809516907
val_Epoch:[ 8 ] val_loss: 0.5369086652994156 2022-05-30 01:14:49.694689
start training 2022-05-30 01:14:49.795844
Epoch:[ 9 0 ] loss: 0.5311529040336609 2022-05-30 01:15:13.087397
Epoch:[ 9 1 ] loss: 0.5270724296569824 2022-05-30 01:15:13.867577
Epoch:[ 9 2 ] loss: 0.5292097926139832 2022-05-30 01:15:14.642931
Epoch:[ 9 3 ] loss: 0.5272900462150574 2022-05-30 01:15:15.418323
Epoch:[ 9 4 ] loss: 0.5241042971611023 2022-05-30 01:15:16.194897
Epoch:[ 9 5 ] loss: 0.5292304158210754 2022-05-30 01:15:16.971386
Epoch:[ 9 6 ] loss: 0.5256116986274719 2022-05-30 01:15:17.749256
Epoch:[ 9 7 ] loss: 0.5295463800430298 2022-05-30 01:15:18.527944
Epoch:[ 9 8 ] loss: 0.5253363847732544 2022-05-30 01:15:19.304461
Epoch:[ 9 9 ] loss: 0.5278809666633606 2022-05-30 01:15:20.079979
Epoch:[ 9 10 ] loss: 0.5253445506095886 2022-05-30 01:15:20.856433
Epoch:[ 9 11 ] loss: 0.5241507291793823 2022-05-30 01:15:21.630512
Epoch:[ 9 12 ] loss: 0.5213012099266052 2022-05-30 01:15:22.406167
Epoch:[ 9 13 ] loss: 0.5255314111709595 2022-05-30 01:15:23.196750
Epoch:[ 9 14 ] loss: 0.5227259993553162 2022-05-30 01:15:23.974169
Epoch:[ 9 15 ] loss: 0.5265600085258484 2022-05-30 01:15:24.754109
Epoch:[ 9 16 ] loss: 0.5261149406433105 2022-05-30 01:15:32.877815
Epoch:[ 9 17 ] loss: 0.5241124033927917 2022-05-30 01:15:33.651689
Epoch:[ 9 18 ] loss: 0.5287166237831116 2022-05-30 01:15:34.433668
Epoch:[ 9 19 ] loss: 0.5228385329246521 2022-05-30 01:15:35.207313
Training_Epoch:[ 9 ] Training_loss: 0.5261915862560272 2022-05-30 01:15:35.207944
learning rate:  0.005
val: 1 0.5589641332626343
val: 2 0.561705470085144
val: 3 0.5525653958320618
val: 4 0.5461537837982178
val: 5 0.556944727897644
val: 6 0.5501869916915894
val: 7 0.5435075759887695
val: 8 0.5445136427879333
val: 9 0.5529131889343262
val: 10 0.5533869862556458
val: 11 0.5398072004318237
val: 12 0.5721657276153564
val: 13 0.5622237920761108
val: 14 0.5429919958114624
val: 15 0.5587260127067566
val: 16 0.5517897605895996
val: 17 0.5462993383407593
val: 18 0.5648884773254395
val: 19 0.5503640174865723
val: 20 0.5508682727813721
val_Epoch:[ 9 ] val_loss: 0.5530483245849609 2022-05-30 01:15:40.615628
start training 2022-05-30 01:15:40.717643
Epoch:[ 10 0 ] loss: 0.5285985469818115 2022-05-30 01:16:03.614877
Epoch:[ 10 1 ] loss: 0.522685706615448 2022-05-30 01:16:05.166032
Epoch:[ 10 2 ] loss: 0.5199726223945618 2022-05-30 01:16:05.943945
Epoch:[ 10 3 ] loss: 0.5217923521995544 2022-05-30 01:16:06.721395
Epoch:[ 10 4 ] loss: 0.5188071727752686 2022-05-30 01:16:07.498396
Epoch:[ 10 5 ] loss: 0.5154320001602173 2022-05-30 01:16:08.289382
Epoch:[ 10 6 ] loss: 0.5184552669525146 2022-05-30 01:16:09.065799
Epoch:[ 10 7 ] loss: 0.5179475545883179 2022-05-30 01:16:09.845603
Epoch:[ 10 8 ] loss: 0.517479658126831 2022-05-30 01:16:10.625610
Epoch:[ 10 9 ] loss: 0.5098848938941956 2022-05-30 01:16:11.402238
Epoch:[ 10 10 ] loss: 0.5149697661399841 2022-05-30 01:16:12.182178
Epoch:[ 10 11 ] loss: 0.5073761940002441 2022-05-30 01:16:12.959037
Epoch:[ 10 12 ] loss: 0.5131979584693909 2022-05-30 01:16:13.737025
Epoch:[ 10 13 ] loss: 0.5060383081436157 2022-05-30 01:16:14.513605
Epoch:[ 10 14 ] loss: 0.503063440322876 2022-05-30 01:16:15.291703
Epoch:[ 10 15 ] loss: 0.5063409805297852 2022-05-30 01:16:16.072486
Epoch:[ 10 16 ] loss: 0.501842200756073 2022-05-30 01:16:23.631293
Epoch:[ 10 17 ] loss: 0.49928849935531616 2022-05-30 01:16:24.406378
Epoch:[ 10 18 ] loss: 0.5046547055244446 2022-05-30 01:16:25.184784
Epoch:[ 10 19 ] loss: 0.5023229122161865 2022-05-30 01:16:25.959888
Training_Epoch:[ 10 ] Training_loss: 0.5125075370073319 2022-05-30 01:16:25.960539
learning rate:  0.005
netparams have been saved once 10
val: 1 0.5459534525871277
val: 2 0.5508711338043213
val: 3 0.5485379695892334
val: 4 0.548697292804718
val: 5 0.5404770374298096
val: 6 0.5394760966300964
val: 7 0.5423028469085693
val: 8 0.5373166799545288
val: 9 0.5497651696205139
val: 10 0.5360938906669617
val: 11 0.5260628461837769
val: 12 0.5488872528076172
val: 13 0.5410922169685364
val: 14 0.5279718041419983
val: 15 0.5501104593276978
val: 16 0.5370354652404785
val: 17 0.5346845984458923
val: 18 0.543435275554657
val: 19 0.5341679453849792
val: 20 0.5276972055435181
val_Epoch:[ 10 ] val_loss: 0.5405318319797516 2022-05-30 01:16:31.482141
start training 2022-05-30 01:16:31.579280
Epoch:[ 11 0 ] loss: 0.5059342384338379 2022-05-30 01:16:55.464716
Epoch:[ 11 1 ] loss: 0.506755530834198 2022-05-30 01:16:56.242767
Epoch:[ 11 2 ] loss: 0.49970266222953796 2022-05-30 01:16:57.022241
Epoch:[ 11 3 ] loss: 0.4975966215133667 2022-05-30 01:16:57.799876
Epoch:[ 11 4 ] loss: 0.5061560869216919 2022-05-30 01:16:58.577308
Epoch:[ 11 5 ] loss: 0.5040925145149231 2022-05-30 01:16:59.353089
Epoch:[ 11 6 ] loss: 0.5059213638305664 2022-05-30 01:17:00.129348
Epoch:[ 11 7 ] loss: 0.5034850835800171 2022-05-30 01:17:00.903986
Epoch:[ 11 8 ] loss: 0.4955785274505615 2022-05-30 01:17:01.682363
Epoch:[ 11 9 ] loss: 0.4983808696269989 2022-05-30 01:17:02.471318
Epoch:[ 11 10 ] loss: 0.4963383972644806 2022-05-30 01:17:03.248095
Epoch:[ 11 11 ] loss: 0.4930737316608429 2022-05-30 01:17:04.027401
Epoch:[ 11 12 ] loss: 0.49902814626693726 2022-05-30 01:17:04.803030
Epoch:[ 11 13 ] loss: 0.49847400188446045 2022-05-30 01:17:05.581370
Epoch:[ 11 14 ] loss: 0.4912366569042206 2022-05-30 01:17:06.356775
Epoch:[ 11 15 ] loss: 0.4932369291782379 2022-05-30 01:17:07.134624
Epoch:[ 11 16 ] loss: 0.4971422851085663 2022-05-30 01:17:14.841662
Epoch:[ 11 17 ] loss: 0.4904068410396576 2022-05-30 01:17:15.616508
Epoch:[ 11 18 ] loss: 0.49359411001205444 2022-05-30 01:17:16.400401
Epoch:[ 11 19 ] loss: 0.49307307600975037 2022-05-30 01:17:17.175840
Training_Epoch:[ 11 ] Training_loss: 0.4984603837132454 2022-05-30 01:17:17.176489
learning rate:  0.004
val: 1 0.49823468923568726
val: 2 0.4916973412036896
val: 3 0.5055861473083496
val: 4 0.4963791072368622
val: 5 0.49565553665161133
val: 6 0.49458518624305725
val: 7 0.5013418793678284
val: 8 0.47042953968048096
val: 9 0.5035837888717651
val: 10 0.5086016654968262
val: 11 0.5044150352478027
val: 12 0.48642870783805847
val: 13 0.5013290047645569
val: 14 0.49664777517318726
val: 15 0.4925652742385864
val: 16 0.4998810291290283
val: 17 0.5042321085929871
val: 18 0.49303948879241943
val: 19 0.5033918619155884
val: 20 0.4934810698032379
val_Epoch:[ 11 ] val_loss: 0.49707531183958054 2022-05-30 01:17:22.537343
start training 2022-05-30 01:17:22.634644
Epoch:[ 12 0 ] loss: 0.492666095495224 2022-05-30 01:17:45.289433
Epoch:[ 12 1 ] loss: 0.4900696575641632 2022-05-30 01:17:46.240308
Epoch:[ 12 2 ] loss: 0.4879288077354431 2022-05-30 01:17:47.105401
Epoch:[ 12 3 ] loss: 0.49225932359695435 2022-05-30 01:17:47.882852
Epoch:[ 12 4 ] loss: 0.4886009395122528 2022-05-30 01:17:48.661373
Epoch:[ 12 5 ] loss: 0.4896414875984192 2022-05-30 01:17:49.439133
Epoch:[ 12 6 ] loss: 0.48737743496894836 2022-05-30 01:17:50.214661
Epoch:[ 12 7 ] loss: 0.48215657472610474 2022-05-30 01:17:50.993247
Epoch:[ 12 8 ] loss: 0.484994500875473 2022-05-30 01:17:51.768060
Epoch:[ 12 9 ] loss: 0.48720622062683105 2022-05-30 01:17:52.548369
Epoch:[ 12 10 ] loss: 0.48602092266082764 2022-05-30 01:17:53.329033
Epoch:[ 12 11 ] loss: 0.48729822039604187 2022-05-30 01:17:54.107844
Epoch:[ 12 12 ] loss: 0.4851411283016205 2022-05-30 01:17:54.884888
Epoch:[ 12 13 ] loss: 0.4812501072883606 2022-05-30 01:17:55.661078
Epoch:[ 12 14 ] loss: 0.4869159460067749 2022-05-30 01:17:56.440062
Epoch:[ 12 15 ] loss: 0.48601973056793213 2022-05-30 01:17:57.217952
Epoch:[ 12 16 ] loss: 0.48804590106010437 2022-05-30 01:18:05.647709
Epoch:[ 12 17 ] loss: 0.49206113815307617 2022-05-30 01:18:06.424709
Epoch:[ 12 18 ] loss: 0.4882429838180542 2022-05-30 01:18:07.207491
Epoch:[ 12 19 ] loss: 0.486676424741745 2022-05-30 01:18:07.985802
Training_Epoch:[ 12 ] Training_loss: 0.48752867728471755 2022-05-30 01:18:07.986503
learning rate:  0.004
netparams have been saved once 12
val: 1 0.4967863857746124
val: 2 0.48909005522727966
val: 3 0.48662519454956055
val: 4 0.4750385284423828
val: 5 0.4969422221183777
val: 6 0.5010371208190918
val: 7 0.48794981837272644
val: 8 0.5012580156326294
val: 9 0.49860936403274536
val: 10 0.4901233911514282
val: 11 0.5078768730163574
val: 12 0.4805476665496826
val: 13 0.48600441217422485
val: 14 0.491026371717453
val: 15 0.50010085105896
val: 16 0.49518296122550964
val: 17 0.4947921931743622
val: 18 0.5045427083969116
val: 19 0.48893868923187256
val: 20 0.48668089509010315
val_Epoch:[ 12 ] val_loss: 0.4929576858878136 2022-05-30 01:18:13.478899
start training 2022-05-30 01:18:13.571059
Epoch:[ 13 0 ] loss: 0.4841461181640625 2022-05-30 01:18:37.453230
Epoch:[ 13 1 ] loss: 0.4849048852920532 2022-05-30 01:18:38.228664
Epoch:[ 13 2 ] loss: 0.48645392060279846 2022-05-30 01:18:39.003168
Epoch:[ 13 3 ] loss: 0.48235952854156494 2022-05-30 01:18:39.780235
Epoch:[ 13 4 ] loss: 0.4890148937702179 2022-05-30 01:18:40.558690
Epoch:[ 13 5 ] loss: 0.48223376274108887 2022-05-30 01:18:41.335523
Epoch:[ 13 6 ] loss: 0.4846860468387604 2022-05-30 01:18:42.111279
Epoch:[ 13 7 ] loss: 0.4795951545238495 2022-05-30 01:18:42.885442
Epoch:[ 13 8 ] loss: 0.4819614887237549 2022-05-30 01:18:43.673181
Epoch:[ 13 9 ] loss: 0.48175036907196045 2022-05-30 01:18:44.447943
Epoch:[ 13 10 ] loss: 0.47923558950424194 2022-05-30 01:18:45.223326
Epoch:[ 13 11 ] loss: 0.47826501727104187 2022-05-30 01:18:46.001483
Epoch:[ 13 12 ] loss: 0.47901374101638794 2022-05-30 01:18:46.779500
Epoch:[ 13 13 ] loss: 0.47906431555747986 2022-05-30 01:18:47.554482
Epoch:[ 13 14 ] loss: 0.48019081354141235 2022-05-30 01:18:48.330494
Epoch:[ 13 15 ] loss: 0.4825475215911865 2022-05-30 01:18:49.104381
Epoch:[ 13 16 ] loss: 0.47867584228515625 2022-05-30 01:18:55.994559
Epoch:[ 13 17 ] loss: 0.47722288966178894 2022-05-30 01:18:56.771092
Epoch:[ 13 18 ] loss: 0.4781475067138672 2022-05-30 01:18:57.553146
Epoch:[ 13 19 ] loss: 0.4745457172393799 2022-05-30 01:18:58.329361
Training_Epoch:[ 13 ] Training_loss: 0.4812007561326027 2022-05-30 01:18:58.330041
learning rate:  0.004
val: 1 0.4889756441116333
val: 2 0.480586975812912
val: 3 0.5005841255187988
val: 4 0.48927122354507446
val: 5 0.47685834765434265
val: 6 0.4741286039352417
val: 7 0.4840857684612274
val: 8 0.4926474988460541
val: 9 0.4853544235229492
val: 10 0.48252159357070923
val: 11 0.4945950210094452
val: 12 0.48672136664390564
val: 13 0.485054075717926
val: 14 0.4886923134326935
val: 15 0.4780758321285248
val: 16 0.48041513562202454
val: 17 0.4745994508266449
val: 18 0.47642314434051514
val: 19 0.4867197275161743
val: 20 0.4834829270839691
val_Epoch:[ 13 ] val_loss: 0.4844896599650383 2022-05-30 01:19:03.735429
start training 2022-05-30 01:19:03.833104
Epoch:[ 14 0 ] loss: 0.4776594042778015 2022-05-30 01:19:26.317162
Epoch:[ 14 1 ] loss: 0.4679672420024872 2022-05-30 01:19:27.219325
Epoch:[ 14 2 ] loss: 0.47712981700897217 2022-05-30 01:19:28.351934
Epoch:[ 14 3 ] loss: 0.4742111563682556 2022-05-30 01:19:29.127196
Epoch:[ 14 4 ] loss: 0.47505390644073486 2022-05-30 01:19:29.906917
Epoch:[ 14 5 ] loss: 0.47508475184440613 2022-05-30 01:19:30.687416
Epoch:[ 14 6 ] loss: 0.4788370728492737 2022-05-30 01:19:31.467680
Epoch:[ 14 7 ] loss: 0.47837600111961365 2022-05-30 01:19:32.249188
Epoch:[ 14 8 ] loss: 0.4732950031757355 2022-05-30 01:19:33.026179
Epoch:[ 14 9 ] loss: 0.4792555570602417 2022-05-30 01:19:33.805198
Epoch:[ 14 10 ] loss: 0.4706781506538391 2022-05-30 01:19:34.584596
Epoch:[ 14 11 ] loss: 0.47160521149635315 2022-05-30 01:19:35.370184
Epoch:[ 14 12 ] loss: 0.47316065430641174 2022-05-30 01:19:36.150459
Epoch:[ 14 13 ] loss: 0.4709906280040741 2022-05-30 01:19:36.926407
Epoch:[ 14 14 ] loss: 0.4730799198150635 2022-05-30 01:19:37.703772
Epoch:[ 14 15 ] loss: 0.47306743264198303 2022-05-30 01:19:38.482165
Epoch:[ 14 16 ] loss: 0.4703206717967987 2022-05-30 01:19:45.882592
Epoch:[ 14 17 ] loss: 0.47296470403671265 2022-05-30 01:19:46.658655
Epoch:[ 14 18 ] loss: 0.46929192543029785 2022-05-30 01:19:47.442551
Epoch:[ 14 19 ] loss: 0.4683937132358551 2022-05-30 01:19:48.221553
Training_Epoch:[ 14 ] Training_loss: 0.47352114617824553 2022-05-30 01:19:48.222287
learning rate:  0.004
netparams have been saved once 14
val: 1 0.49394965171813965
val: 2 0.4895446002483368
val: 3 0.48779937624931335
val: 4 0.49249082803726196
val: 5 0.4928878843784332
val: 6 0.4943183660507202
val: 7 0.4940037429332733
val: 8 0.49623820185661316
val: 9 0.4937092363834381
val: 10 0.496890127658844
val: 11 0.4886056184768677
val: 12 0.48518240451812744
val: 13 0.48368629813194275
val: 14 0.4993850290775299
val: 15 0.48650896549224854
val: 16 0.48693719506263733
val: 17 0.4867938756942749
val: 18 0.4925963878631592
val: 19 0.5086471438407898
val: 20 0.4921252429485321
val_Epoch:[ 14 ] val_loss: 0.49211500883102416 2022-05-30 01:19:53.672203
start training 2022-05-30 01:19:53.766762
Epoch:[ 15 0 ] loss: 0.4725630581378937 2022-05-30 01:20:16.035322
Epoch:[ 15 1 ] loss: 0.4707297384738922 2022-05-30 01:20:16.865966
Epoch:[ 15 2 ] loss: 0.46550771594047546 2022-05-30 01:20:17.882588
Epoch:[ 15 3 ] loss: 0.4683510959148407 2022-05-30 01:20:18.658727
Epoch:[ 15 4 ] loss: 0.46918559074401855 2022-05-30 01:20:19.434341
Epoch:[ 15 5 ] loss: 0.4722585380077362 2022-05-30 01:20:20.214505
Epoch:[ 15 6 ] loss: 0.4646095931529999 2022-05-30 01:20:20.992998
Epoch:[ 15 7 ] loss: 0.4697268605232239 2022-05-30 01:20:21.774561
Epoch:[ 15 8 ] loss: 0.4638848900794983 2022-05-30 01:20:22.551984
Epoch:[ 15 9 ] loss: 0.4676540195941925 2022-05-30 01:20:23.329283
Epoch:[ 15 10 ] loss: 0.46792253851890564 2022-05-30 01:20:24.106959
Epoch:[ 15 11 ] loss: 0.4654271900653839 2022-05-30 01:20:24.882235
Epoch:[ 15 12 ] loss: 0.47461050748825073 2022-05-30 01:20:25.660942
Epoch:[ 15 13 ] loss: 0.4652039110660553 2022-05-30 01:20:26.438564
Epoch:[ 15 14 ] loss: 0.46586689352989197 2022-05-30 01:20:27.218057
Epoch:[ 15 15 ] loss: 0.4749283492565155 2022-05-30 01:20:27.996115
Epoch:[ 15 16 ] loss: 0.4759611487388611 2022-05-30 01:20:36.122085
Epoch:[ 15 17 ] loss: 0.46568652987480164 2022-05-30 01:20:36.896566
Epoch:[ 15 18 ] loss: 0.4714829921722412 2022-05-30 01:20:37.686924
Epoch:[ 15 19 ] loss: 0.4666517674922943 2022-05-30 01:20:38.465187
Training_Epoch:[ 15 ] Training_loss: 0.46891064643859864 2022-05-30 01:20:38.466000
learning rate:  0.004
val: 1 0.5119549632072449
val: 2 0.5042051672935486
val: 3 0.5091398358345032
val: 4 0.5131658315658569
val: 5 0.5217174887657166
val: 6 0.4993886351585388
val: 7 0.5069235563278198
val: 8 0.5150208473205566
val: 9 0.5121369361877441
val: 10 0.5010982155799866
val: 11 0.5006604194641113
val: 12 0.5032207369804382
val: 13 0.5032554268836975
val: 14 0.51871657371521
val: 15 0.5047789812088013
val: 16 0.5003319382667542
val: 17 0.5016266703605652
val: 18 0.5103210210800171
val: 19 0.5068140029907227
val: 20 0.5114079713821411
val_Epoch:[ 15 ] val_loss: 0.5077942609786987 2022-05-30 01:20:43.868460
start training 2022-05-30 01:20:43.961871
Epoch:[ 16 0 ] loss: 0.47337478399276733 2022-05-30 01:21:07.170215
Epoch:[ 16 1 ] loss: 0.47056499123573303 2022-05-30 01:21:07.947889
Epoch:[ 16 2 ] loss: 0.4737629294395447 2022-05-30 01:21:08.723820
Epoch:[ 16 3 ] loss: 0.47513440251350403 2022-05-30 01:21:09.497809
Epoch:[ 16 4 ] loss: 0.47185999155044556 2022-05-30 01:21:10.273945
Epoch:[ 16 5 ] loss: 0.46541568636894226 2022-05-30 01:21:11.048065
Epoch:[ 16 6 ] loss: 0.46658316254615784 2022-05-30 01:21:11.826120
Epoch:[ 16 7 ] loss: 0.46543368697166443 2022-05-30 01:21:12.601175
Epoch:[ 16 8 ] loss: 0.46533825993537903 2022-05-30 01:21:13.377493
Epoch:[ 16 9 ] loss: 0.4685180187225342 2022-05-30 01:21:14.153968
Epoch:[ 16 10 ] loss: 0.46425458788871765 2022-05-30 01:21:14.940754
Epoch:[ 16 11 ] loss: 0.4670465290546417 2022-05-30 01:21:15.714395
Epoch:[ 16 12 ] loss: 0.46971601247787476 2022-05-30 01:21:16.489115
Epoch:[ 16 13 ] loss: 0.46102175116539 2022-05-30 01:21:17.265028
Epoch:[ 16 14 ] loss: 0.4661148190498352 2022-05-30 01:21:18.043542
Epoch:[ 16 15 ] loss: 0.4633350670337677 2022-05-30 01:21:18.819277
Epoch:[ 16 16 ] loss: 0.4638787806034088 2022-05-30 01:21:27.023624
Epoch:[ 16 17 ] loss: 0.46440789103507996 2022-05-30 01:21:27.797416
Epoch:[ 16 18 ] loss: 0.45895877480506897 2022-05-30 01:21:28.591467
Epoch:[ 16 19 ] loss: 0.4578414261341095 2022-05-30 01:21:29.363780
Training_Epoch:[ 16 ] Training_loss: 0.4666280776262283 2022-05-30 01:21:29.364487
learning rate:  0.004
netparams have been saved once 16
val: 1 0.46145257353782654
val: 2 0.46454864740371704
val: 3 0.46275565028190613
val: 4 0.4757016897201538
val: 5 0.4641903340816498
val: 6 0.46858710050582886
val: 7 0.46947726607322693
val: 8 0.47577276825904846
val: 9 0.466085821390152
val: 10 0.47881367802619934
val: 11 0.4665706753730774
val: 12 0.46346983313560486
val: 13 0.4570336937904358
val: 14 0.46819356083869934
val: 15 0.46917587518692017
val: 16 0.4906468391418457
val: 17 0.4759884178638458
val: 18 0.4682424068450928
val: 19 0.4734232425689697
val: 20 0.4694523513317108
val_Epoch:[ 16 ] val_loss: 0.46947912126779556 2022-05-30 01:21:34.855778
start training 2022-05-30 01:21:34.952556
Epoch:[ 17 0 ] loss: 0.4635260999202728 2022-05-30 01:21:58.455931
Epoch:[ 17 1 ] loss: 0.4617938995361328 2022-05-30 01:21:59.267441
Epoch:[ 17 2 ] loss: 0.4574221074581146 2022-05-30 01:22:00.045906
Epoch:[ 17 3 ] loss: 0.46182382106781006 2022-05-30 01:22:00.820445
Epoch:[ 17 4 ] loss: 0.46033522486686707 2022-05-30 01:22:01.595608
Epoch:[ 17 5 ] loss: 0.46109122037887573 2022-05-30 01:22:02.371763
Epoch:[ 17 6 ] loss: 0.45710837841033936 2022-05-30 01:22:03.146765
Epoch:[ 17 7 ] loss: 0.4588583707809448 2022-05-30 01:22:03.925357
Epoch:[ 17 8 ] loss: 0.45791876316070557 2022-05-30 01:22:04.702685
Epoch:[ 17 9 ] loss: 0.45688503980636597 2022-05-30 01:22:05.479344
Epoch:[ 17 10 ] loss: 0.4557592272758484 2022-05-30 01:22:06.257477
Epoch:[ 17 11 ] loss: 0.45636093616485596 2022-05-30 01:22:07.033701
Epoch:[ 17 12 ] loss: 0.4555149972438812 2022-05-30 01:22:07.812352
Epoch:[ 17 13 ] loss: 0.4618200361728668 2022-05-30 01:22:08.586609
Epoch:[ 17 14 ] loss: 0.45811399817466736 2022-05-30 01:22:09.366360
Epoch:[ 17 15 ] loss: 0.46167802810668945 2022-05-30 01:22:10.144798
Epoch:[ 17 16 ] loss: 0.4590153992176056 2022-05-30 01:22:17.482628
Epoch:[ 17 17 ] loss: 0.46088963747024536 2022-05-30 01:22:18.258559
Epoch:[ 17 18 ] loss: 0.4587847590446472 2022-05-30 01:22:19.037721
Epoch:[ 17 19 ] loss: 0.4610915780067444 2022-05-30 01:22:19.814880
Training_Epoch:[ 17 ] Training_loss: 0.459289576113224 2022-05-30 01:22:19.815574
learning rate:  0.004
val: 1 0.45016905665397644
val: 2 0.46241432428359985
val: 3 0.478380411863327
val: 4 0.4633485972881317
val: 5 0.46799179911613464
val: 6 0.4703105390071869
val: 7 0.464707612991333
val: 8 0.46066099405288696
val: 9 0.45988336205482483
val: 10 0.46713709831237793
val: 11 0.4646758437156677
val: 12 0.4725334048271179
val: 13 0.45742928981781006
val: 14 0.465006947517395
val: 15 0.45884835720062256
val: 16 0.46946361660957336
val: 17 0.45372244715690613
val: 18 0.45116522908210754
val: 19 0.46127232909202576
val: 20 0.46133074164390564
val_Epoch:[ 17 ] val_loss: 0.46302260011434554 2022-05-30 01:22:25.169935
start training 2022-05-30 01:22:25.270301
Epoch:[ 18 0 ] loss: 0.45709139108657837 2022-05-30 01:22:48.033667
Epoch:[ 18 1 ] loss: 0.46037757396698 2022-05-30 01:22:48.881023
Epoch:[ 18 2 ] loss: 0.4532413184642792 2022-05-30 01:22:49.660384
Epoch:[ 18 3 ] loss: 0.45421168208122253 2022-05-30 01:22:50.436909
Epoch:[ 18 4 ] loss: 0.4565828740596771 2022-05-30 01:22:51.215961
Epoch:[ 18 5 ] loss: 0.4518660306930542 2022-05-30 01:22:51.990550
Epoch:[ 18 6 ] loss: 0.45405781269073486 2022-05-30 01:22:52.768689
Epoch:[ 18 7 ] loss: 0.4572530686855316 2022-05-30 01:22:53.542756
Epoch:[ 18 8 ] loss: 0.452384352684021 2022-05-30 01:22:54.322176
Epoch:[ 18 9 ] loss: 0.45723918080329895 2022-05-30 01:22:55.098140
Epoch:[ 18 10 ] loss: 0.4532061517238617 2022-05-30 01:22:55.877748
Epoch:[ 18 11 ] loss: 0.45186305046081543 2022-05-30 01:22:56.656004
Epoch:[ 18 12 ] loss: 0.45686158537864685 2022-05-30 01:22:57.432258
Epoch:[ 18 13 ] loss: 0.4521920680999756 2022-05-30 01:22:58.208946
Epoch:[ 18 14 ] loss: 0.4490428566932678 2022-05-30 01:22:58.984102
Epoch:[ 18 15 ] loss: 0.4504019021987915 2022-05-30 01:22:59.763901
Epoch:[ 18 16 ] loss: 0.45059502124786377 2022-05-30 01:23:08.015371
Epoch:[ 18 17 ] loss: 0.4502003490924835 2022-05-30 01:23:08.792694
Epoch:[ 18 18 ] loss: 0.45447197556495667 2022-05-30 01:23:09.574742
Epoch:[ 18 19 ] loss: 0.4501499831676483 2022-05-30 01:23:10.350381
Training_Epoch:[ 18 ] Training_loss: 0.45366451144218445 2022-05-30 01:23:10.351039
learning rate:  0.004
netparams have been saved once 18
val: 1 0.4646349251270294
val: 2 0.4512568414211273
val: 3 0.4583272933959961
val: 4 0.4505699574947357
val: 5 0.4649524390697479
val: 6 0.453915536403656
val: 7 0.4635700583457947
val: 8 0.4546588361263275
val: 9 0.4599653482437134
val: 10 0.46284353733062744
val: 11 0.4434109628200531
val: 12 0.462609201669693
val: 13 0.4577063322067261
val: 14 0.47538942098617554
val: 15 0.45751479268074036
val: 16 0.46333256363868713
val: 17 0.46339526772499084
val: 18 0.45684945583343506
val: 19 0.45123985409736633
val: 20 0.4470914900302887
val_Epoch:[ 18 ] val_loss: 0.4581617057323456 2022-05-30 01:23:15.907842
start training 2022-05-30 01:23:16.008676
Epoch:[ 19 0 ] loss: 0.4485478699207306 2022-05-30 01:23:38.354047
Epoch:[ 19 1 ] loss: 0.45061877369880676 2022-05-30 01:23:39.282596
Epoch:[ 19 2 ] loss: 0.45183515548706055 2022-05-30 01:23:40.100612
Epoch:[ 19 3 ] loss: 0.4501980245113373 2022-05-30 01:23:40.879504
Epoch:[ 19 4 ] loss: 0.44510239362716675 2022-05-30 01:23:41.659963
Epoch:[ 19 5 ] loss: 0.4491608738899231 2022-05-30 01:23:42.438497
Epoch:[ 19 6 ] loss: 0.4502671957015991 2022-05-30 01:23:43.213787
Epoch:[ 19 7 ] loss: 0.44942668080329895 2022-05-30 01:23:43.992363
Epoch:[ 19 8 ] loss: 0.44648319482803345 2022-05-30 01:23:44.766710
Epoch:[ 19 9 ] loss: 0.4484281837940216 2022-05-30 01:23:45.545075
Epoch:[ 19 10 ] loss: 0.4512983560562134 2022-05-30 01:23:46.324315
Epoch:[ 19 11 ] loss: 0.45355767011642456 2022-05-30 01:23:47.103879
Epoch:[ 19 12 ] loss: 0.44999223947525024 2022-05-30 01:23:47.882130
Epoch:[ 19 13 ] loss: 0.44780850410461426 2022-05-30 01:23:48.658729
Epoch:[ 19 14 ] loss: 0.4555482268333435 2022-05-30 01:23:49.433384
Epoch:[ 19 15 ] loss: 0.45490574836730957 2022-05-30 01:23:50.210304
Epoch:[ 19 16 ] loss: 0.45868030190467834 2022-05-30 01:23:58.034648
Epoch:[ 19 17 ] loss: 0.46045324206352234 2022-05-30 01:23:58.811728
Epoch:[ 19 18 ] loss: 0.4605177044868469 2022-05-30 01:23:59.592530
Epoch:[ 19 19 ] loss: 0.45453009009361267 2022-05-30 01:24:00.368103
Training_Epoch:[ 19 ] Training_loss: 0.4518680214881897 2022-05-30 01:24:00.368806
learning rate:  0.004
val: 1 0.444623738527298
val: 2 0.4544749855995178
val: 3 0.45822227001190186
val: 4 0.45801621675491333
val: 5 0.45821648836135864
val: 6 0.4588417112827301
val: 7 0.44201046228408813
val: 8 0.4648815095424652
val: 9 0.4584808945655823
val: 10 0.46314841508865356
val: 11 0.45953133702278137
val: 12 0.45636945962905884
val: 13 0.46127915382385254
val: 14 0.4541054368019104
val: 15 0.46174106001853943
val: 16 0.4511321187019348
val: 17 0.4580123722553253
val: 18 0.4622158408164978
val: 19 0.4580056071281433
val: 20 0.4614279568195343
val_Epoch:[ 19 ] val_loss: 0.45723685175180434 2022-05-30 01:24:05.678933
start training 2022-05-30 01:24:05.778343
Epoch:[ 20 0 ] loss: 0.45139312744140625 2022-05-30 01:24:29.481712
Epoch:[ 20 1 ] loss: 0.45465919375419617 2022-05-30 01:24:30.257995
Epoch:[ 20 2 ] loss: 0.4577428996562958 2022-05-30 01:24:31.034860
Epoch:[ 20 3 ] loss: 0.45188432931900024 2022-05-30 01:24:31.813501
Epoch:[ 20 4 ] loss: 0.45014527440071106 2022-05-30 01:24:32.593197
Epoch:[ 20 5 ] loss: 0.45213985443115234 2022-05-30 01:24:33.369978
Epoch:[ 20 6 ] loss: 0.450947642326355 2022-05-30 01:24:34.146641
Epoch:[ 20 7 ] loss: 0.4522598683834076 2022-05-30 01:24:34.934481
Epoch:[ 20 8 ] loss: 0.4475230872631073 2022-05-30 01:24:35.711091
Epoch:[ 20 9 ] loss: 0.4488332271575928 2022-05-30 01:24:36.487470
Epoch:[ 20 10 ] loss: 0.4495123028755188 2022-05-30 01:24:37.265984
Epoch:[ 20 11 ] loss: 0.4491439163684845 2022-05-30 01:24:38.044820
Epoch:[ 20 12 ] loss: 0.44489842653274536 2022-05-30 01:24:38.822019
Epoch:[ 20 13 ] loss: 0.44792985916137695 2022-05-30 01:24:39.601230
Epoch:[ 20 14 ] loss: 0.4480942189693451 2022-05-30 01:24:40.377085
Epoch:[ 20 15 ] loss: 0.4501223862171173 2022-05-30 01:24:41.152544
Epoch:[ 20 16 ] loss: 0.44767293334007263 2022-05-30 01:24:48.124935
Epoch:[ 20 17 ] loss: 0.4513190984725952 2022-05-30 01:24:48.902528
Epoch:[ 20 18 ] loss: 0.45059195160865784 2022-05-30 01:24:49.685696
Epoch:[ 20 19 ] loss: 0.4424838721752167 2022-05-30 01:24:50.462969
Training_Epoch:[ 20 ] Training_loss: 0.44996487349271774 2022-05-30 01:24:50.463656
learning rate:  0.004
netparams have been saved once 20
val: 1 0.4616953134536743
val: 2 0.4560569226741791
val: 3 0.4435376226902008
val: 4 0.4484657347202301
val: 5 0.4427574872970581
val: 6 0.4480626583099365
val: 7 0.4444434940814972
val: 8 0.4485629200935364
val: 9 0.44488465785980225
val: 10 0.45472997426986694
val: 11 0.45028820633888245
val: 12 0.4303528368473053
val: 13 0.43619322776794434
val: 14 0.44776326417922974
val: 15 0.45668911933898926
val: 16 0.46869876980781555
val: 17 0.4527222216129303
val: 18 0.44748473167419434
val: 19 0.4643295407295227
val: 20 0.45352110266685486
val_Epoch:[ 20 ] val_loss: 0.4500619903206825 2022-05-30 01:24:55.934500
start training 2022-05-30 01:24:56.035039
Epoch:[ 21 0 ] loss: 0.44289538264274597 2022-05-30 01:25:19.392731
Epoch:[ 21 1 ] loss: 0.44749656319618225 2022-05-30 01:25:20.168386
Epoch:[ 21 2 ] loss: 0.44681063294410706 2022-05-30 01:25:20.943966
Epoch:[ 21 3 ] loss: 0.43964385986328125 2022-05-30 01:25:21.719387
Epoch:[ 21 4 ] loss: 0.44420456886291504 2022-05-30 01:25:22.496305
Epoch:[ 21 5 ] loss: 0.4450600743293762 2022-05-30 01:25:23.271959
Epoch:[ 21 6 ] loss: 0.44288939237594604 2022-05-30 01:25:24.048858
Epoch:[ 21 7 ] loss: 0.4437817931175232 2022-05-30 01:25:24.824894
Epoch:[ 21 8 ] loss: 0.4422413408756256 2022-05-30 01:25:25.600273
Epoch:[ 21 9 ] loss: 0.44257408380508423 2022-05-30 01:25:26.376960
Epoch:[ 21 10 ] loss: 0.43865203857421875 2022-05-30 01:25:27.150371
Epoch:[ 21 11 ] loss: 0.4420120120048523 2022-05-30 01:25:27.927945
Epoch:[ 21 12 ] loss: 0.4417990446090698 2022-05-30 01:25:28.705653
Epoch:[ 21 13 ] loss: 0.444866806268692 2022-05-30 01:25:29.483320
Epoch:[ 21 14 ] loss: 0.4436336159706116 2022-05-30 01:25:30.257765
Epoch:[ 21 15 ] loss: 0.4406749904155731 2022-05-30 01:25:31.033479
Epoch:[ 21 16 ] loss: 0.44771531224250793 2022-05-30 01:25:38.590108
Epoch:[ 21 17 ] loss: 0.4456336200237274 2022-05-30 01:25:39.363423
Epoch:[ 21 18 ] loss: 0.438078373670578 2022-05-30 01:25:40.144907
Epoch:[ 21 19 ] loss: 0.4400400221347809 2022-05-30 01:25:40.920176
Training_Epoch:[ 21 ] Training_loss: 0.4430351763963699 2022-05-30 01:25:40.920937
learning rate:  0.0032
val: 1 0.45115312933921814
val: 2 0.45599114894866943
val: 3 0.44374722242355347
val: 4 0.44831550121307373
val: 5 0.4339064657688141
val: 6 0.4472748637199402
val: 7 0.4434428811073303
val: 8 0.46095624566078186
val: 9 0.4395628571510315
val: 10 0.4505305886268616
val: 11 0.43998047709465027
val: 12 0.44024375081062317
val: 13 0.4580429196357727
val: 14 0.43979784846305847
val: 15 0.4412101209163666
val: 16 0.45699405670166016
val: 17 0.4428452253341675
val: 18 0.45062655210494995
val: 19 0.45496490597724915
val: 20 0.43922099471092224
val_Epoch:[ 21 ] val_loss: 0.4469403877854347 2022-05-30 01:25:46.308143
start training 2022-05-30 01:25:46.409294
Epoch:[ 22 0 ] loss: 0.44158923625946045 2022-05-30 01:26:10.801316
Epoch:[ 22 1 ] loss: 0.4393919110298157 2022-05-30 01:26:11.579900
Epoch:[ 22 2 ] loss: 0.44210442900657654 2022-05-30 01:26:12.354752
Epoch:[ 22 3 ] loss: 0.43739205598831177 2022-05-30 01:26:13.129105
Epoch:[ 22 4 ] loss: 0.43900009989738464 2022-05-30 01:26:13.903480
Epoch:[ 22 5 ] loss: 0.4425927400588989 2022-05-30 01:26:14.682213
Epoch:[ 22 6 ] loss: 0.43832284212112427 2022-05-30 01:26:15.459267
Epoch:[ 22 7 ] loss: 0.44153499603271484 2022-05-30 01:26:16.236247
Epoch:[ 22 8 ] loss: 0.4384530484676361 2022-05-30 01:26:17.025407
Epoch:[ 22 9 ] loss: 0.43693459033966064 2022-05-30 01:26:17.800946
Epoch:[ 22 10 ] loss: 0.4407658874988556 2022-05-30 01:26:18.578673
Epoch:[ 22 11 ] loss: 0.44267845153808594 2022-05-30 01:26:19.353386
Epoch:[ 22 12 ] loss: 0.4407617747783661 2022-05-30 01:26:20.131425
Epoch:[ 22 13 ] loss: 0.4388839304447174 2022-05-30 01:26:20.908994
Epoch:[ 22 14 ] loss: 0.44245445728302 2022-05-30 01:26:21.688131
Epoch:[ 22 15 ] loss: 0.4426093101501465 2022-05-30 01:26:22.465344
Epoch:[ 22 16 ] loss: 0.4421786665916443 2022-05-30 01:26:30.321546
Epoch:[ 22 17 ] loss: 0.4409744441509247 2022-05-30 01:26:31.095051
Epoch:[ 22 18 ] loss: 0.4424430727958679 2022-05-30 01:26:31.872096
Epoch:[ 22 19 ] loss: 0.4408085346221924 2022-05-30 01:26:32.648981
Training_Epoch:[ 22 ] Training_loss: 0.44059372395277024 2022-05-30 01:26:32.649694
learning rate:  0.0032
netparams have been saved once 22
val: 1 0.452074259519577
val: 2 0.44579800963401794
val: 3 0.43901556730270386
val: 4 0.4315245449542999
val: 5 0.43940067291259766
val: 6 0.4584087133407593
val: 7 0.4427294433116913
val: 8 0.43230095505714417
val: 9 0.4503580927848816
val: 10 0.45717379450798035
val: 11 0.4481079876422882
val: 12 0.4575158953666687
val: 13 0.44217556715011597
val: 14 0.4429292678833008
val: 15 0.44942617416381836
val: 16 0.44204121828079224
val: 17 0.45066896080970764
val: 18 0.4737135171890259
val: 19 0.4460609555244446
val: 20 0.4495975375175476
val_Epoch:[ 22 ] val_loss: 0.44755105674266815 2022-05-30 01:26:38.140721
start training 2022-05-30 01:26:38.234727
Epoch:[ 23 0 ] loss: 0.43873894214630127 2022-05-30 01:27:01.921974
Epoch:[ 23 1 ] loss: 0.43611833453178406 2022-05-30 01:27:02.697035
Epoch:[ 23 2 ] loss: 0.44083279371261597 2022-05-30 01:27:03.475888
Epoch:[ 23 3 ] loss: 0.44176599383354187 2022-05-30 01:27:04.250247
Epoch:[ 23 4 ] loss: 0.43506646156311035 2022-05-30 01:27:05.025980
Epoch:[ 23 5 ] loss: 0.4417213797569275 2022-05-30 01:27:05.800020
Epoch:[ 23 6 ] loss: 0.43829017877578735 2022-05-30 01:27:06.577580
Epoch:[ 23 7 ] loss: 0.4402749836444855 2022-05-30 01:27:07.354706
Epoch:[ 23 8 ] loss: 0.4410496950149536 2022-05-30 01:27:08.131713
Epoch:[ 23 9 ] loss: 0.43991050124168396 2022-05-30 01:27:08.907806
Epoch:[ 23 10 ] loss: 0.435651570558548 2022-05-30 01:27:09.682467
Epoch:[ 23 11 ] loss: 0.4357145428657532 2022-05-30 01:27:10.457047
Epoch:[ 23 12 ] loss: 0.4359900653362274 2022-05-30 01:27:11.232132
Epoch:[ 23 13 ] loss: 0.4362340271472931 2022-05-30 01:27:12.008836
Epoch:[ 23 14 ] loss: 0.4347577393054962 2022-05-30 01:27:12.786958
Epoch:[ 23 15 ] loss: 0.43788066506385803 2022-05-30 01:27:13.563470
Epoch:[ 23 16 ] loss: 0.44013795256614685 2022-05-30 01:27:20.825648
Epoch:[ 23 17 ] loss: 0.4351285398006439 2022-05-30 01:27:21.600090
Epoch:[ 23 18 ] loss: 0.43914371728897095 2022-05-30 01:27:22.378502
Epoch:[ 23 19 ] loss: 0.4423137307167053 2022-05-30 01:27:23.153030
Training_Epoch:[ 23 ] Training_loss: 0.43833609074354174 2022-05-30 01:27:23.153710
learning rate:  0.0032
val: 1 0.4343714416027069
val: 2 0.43550121784210205
val: 3 0.4593113362789154
val: 4 0.4500446021556854
val: 5 0.44638708233833313
val: 6 0.44982385635375977
val: 7 0.4420621395111084
val: 8 0.43620121479034424
val: 9 0.44010043144226074
val: 10 0.4659861922264099
val: 11 0.44563767313957214
val: 12 0.4469480514526367
val: 13 0.43118107318878174
val: 14 0.45782846212387085
val: 15 0.4452102482318878
val: 16 0.4289472699165344
val: 17 0.454476922750473
val: 18 0.44909459352493286
val: 19 0.4387034475803375
val: 20 0.4463731348514557
val_Epoch:[ 23 ] val_loss: 0.44520951956510546 2022-05-30 01:27:28.545672
start training 2022-05-30 01:27:28.638349
Epoch:[ 24 0 ] loss: 0.44065532088279724 2022-05-30 01:27:52.775145
Epoch:[ 24 1 ] loss: 0.4386278986930847 2022-05-30 01:27:53.552278
Epoch:[ 24 2 ] loss: 0.4334698021411896 2022-05-30 01:27:54.327616
Epoch:[ 24 3 ] loss: 0.4356013834476471 2022-05-30 01:27:55.106299
Epoch:[ 24 4 ] loss: 0.43981263041496277 2022-05-30 01:27:55.880297
Epoch:[ 24 5 ] loss: 0.4352007210254669 2022-05-30 01:27:56.657975
Epoch:[ 24 6 ] loss: 0.4362611770629883 2022-05-30 01:27:57.431847
Epoch:[ 24 7 ] loss: 0.438752681016922 2022-05-30 01:27:58.209050
Epoch:[ 24 8 ] loss: 0.4321567714214325 2022-05-30 01:27:58.987975
Epoch:[ 24 9 ] loss: 0.4377228319644928 2022-05-30 01:27:59.763342
Epoch:[ 24 10 ] loss: 0.43585291504859924 2022-05-30 01:28:00.541647
Epoch:[ 24 11 ] loss: 0.4387796223163605 2022-05-30 01:28:01.316583
Epoch:[ 24 12 ] loss: 0.43696215748786926 2022-05-30 01:28:02.091499
Epoch:[ 24 13 ] loss: 0.4351615905761719 2022-05-30 01:28:02.865883
Epoch:[ 24 14 ] loss: 0.44195157289505005 2022-05-30 01:28:03.642815
Epoch:[ 24 15 ] loss: 0.4346051812171936 2022-05-30 01:28:04.421958
Epoch:[ 24 16 ] loss: 0.437511146068573 2022-05-30 01:28:11.512220
Epoch:[ 24 17 ] loss: 0.4368811547756195 2022-05-30 01:28:12.287579
Epoch:[ 24 18 ] loss: 0.434292197227478 2022-05-30 01:28:13.065811
Epoch:[ 24 19 ] loss: 0.4368809163570404 2022-05-30 01:28:13.842706
Training_Epoch:[ 24 ] Training_loss: 0.43685698360204694 2022-05-30 01:28:13.843391
learning rate:  0.0032
netparams have been saved once 24
val: 1 0.4462924599647522
val: 2 0.4402763545513153
val: 3 0.42643308639526367
val: 4 0.4392780363559723
val: 5 0.45536863803863525
val: 6 0.43480128049850464
val: 7 0.4478355646133423
val: 8 0.4511840343475342
val: 9 0.45221951603889465
val: 10 0.4481410086154938
val: 11 0.4512675106525421
val: 12 0.4543459117412567
val: 13 0.4527473747730255
val: 14 0.4523408114910126
val: 15 0.4468799829483032
val: 16 0.4532170593738556
val: 17 0.4276152551174164
val: 18 0.4466192424297333
val: 19 0.4434436559677124
val: 20 0.4444948136806488
val_Epoch:[ 24 ] val_loss: 0.4457400798797607 2022-05-30 01:28:19.283422
start training 2022-05-30 01:28:19.378909
Epoch:[ 25 0 ] loss: 0.4352075457572937 2022-05-30 01:28:42.990052
Epoch:[ 25 1 ] loss: 0.4352634847164154 2022-05-30 01:28:43.767181
Epoch:[ 25 2 ] loss: 0.4378606379032135 2022-05-30 01:28:44.546187
Epoch:[ 25 3 ] loss: 0.43897294998168945 2022-05-30 01:28:45.321767
Epoch:[ 25 4 ] loss: 0.4380868077278137 2022-05-30 01:28:46.098276
Epoch:[ 25 5 ] loss: 0.43901365995407104 2022-05-30 01:28:46.873445
Epoch:[ 25 6 ] loss: 0.44000136852264404 2022-05-30 01:28:47.648106
Epoch:[ 25 7 ] loss: 0.4395274221897125 2022-05-30 01:28:48.423069
Epoch:[ 25 8 ] loss: 0.43744200468063354 2022-05-30 01:28:49.203075
Epoch:[ 25 9 ] loss: 0.43916574120521545 2022-05-30 01:28:49.982712
Epoch:[ 25 10 ] loss: 0.43619975447654724 2022-05-30 01:28:50.762259
Epoch:[ 25 11 ] loss: 0.4358941316604614 2022-05-30 01:28:51.538605
Epoch:[ 25 12 ] loss: 0.43850553035736084 2022-05-30 01:28:52.314425
Epoch:[ 25 13 ] loss: 0.4397013783454895 2022-05-30 01:28:53.090925
Epoch:[ 25 14 ] loss: 0.4373263120651245 2022-05-30 01:28:53.866515
Epoch:[ 25 15 ] loss: 0.434390664100647 2022-05-30 01:28:54.642184
Epoch:[ 25 16 ] loss: 0.4372870922088623 2022-05-30 01:29:02.638365
Epoch:[ 25 17 ] loss: 0.43787190318107605 2022-05-30 01:29:03.417913
Epoch:[ 25 18 ] loss: 0.4355863034725189 2022-05-30 01:29:04.197556
Epoch:[ 25 19 ] loss: 0.43715715408325195 2022-05-30 01:29:04.971586
Training_Epoch:[ 25 ] Training_loss: 0.4375230923295021 2022-05-30 01:29:04.972266
learning rate:  0.0032
val: 1 0.4278194308280945
val: 2 0.4493561089038849
val: 3 0.43291863799095154
val: 4 0.4552868902683258
val: 5 0.4560016691684723
val: 6 0.44827306270599365
val: 7 0.4373303949832916
val: 8 0.4434051215648651
val: 9 0.44024330377578735
val: 10 0.4498944580554962
val: 11 0.45639052987098694
val: 12 0.44241341948509216
val: 13 0.44978097081184387
val: 14 0.4492408037185669
val: 15 0.44290032982826233
val: 16 0.43305882811546326
val: 17 0.4390278458595276
val: 18 0.4394349753856659
val: 19 0.43550315499305725
val: 20 0.4408165514469147
val_Epoch:[ 25 ] val_loss: 0.4434548243880272 2022-05-30 01:29:10.437549
start training 2022-05-30 01:29:10.535614
Epoch:[ 26 0 ] loss: 0.43252116441726685 2022-05-30 01:29:33.354478
Epoch:[ 26 1 ] loss: 0.43400838971138 2022-05-30 01:29:34.223514
Epoch:[ 26 2 ] loss: 0.4350092113018036 2022-05-30 01:29:35.051535
Epoch:[ 26 3 ] loss: 0.43193361163139343 2022-05-30 01:29:35.829766
Epoch:[ 26 4 ] loss: 0.4336525499820709 2022-05-30 01:29:36.606837
Epoch:[ 26 5 ] loss: 0.4369940161705017 2022-05-30 01:29:37.383168
Epoch:[ 26 6 ] loss: 0.43286484479904175 2022-05-30 01:29:38.158010
Epoch:[ 26 7 ] loss: 0.4319605827331543 2022-05-30 01:29:38.932307
Epoch:[ 26 8 ] loss: 0.4311721622943878 2022-05-30 01:29:39.706672
Epoch:[ 26 9 ] loss: 0.43338507413864136 2022-05-30 01:29:40.483000
Epoch:[ 26 10 ] loss: 0.4314522445201874 2022-05-30 01:29:41.261535
Epoch:[ 26 11 ] loss: 0.4315505027770996 2022-05-30 01:29:42.039471
Epoch:[ 26 12 ] loss: 0.4268968105316162 2022-05-30 01:29:42.814725
Epoch:[ 26 13 ] loss: 0.4372011125087738 2022-05-30 01:29:43.589492
Epoch:[ 26 14 ] loss: 0.43729862570762634 2022-05-30 01:29:44.364014
Epoch:[ 26 15 ] loss: 0.43339940905570984 2022-05-30 01:29:45.139295
Epoch:[ 26 16 ] loss: 0.43252328038215637 2022-05-30 01:29:52.973791
Epoch:[ 26 17 ] loss: 0.4355904459953308 2022-05-30 01:29:53.886804
Epoch:[ 26 18 ] loss: 0.4334985017776489 2022-05-30 01:29:54.667950
Epoch:[ 26 19 ] loss: 0.436431884765625 2022-05-30 01:29:55.444446
Training_Epoch:[ 26 ] Training_loss: 0.4334672212600708 2022-05-30 01:29:55.445168
learning rate:  0.0032
netparams have been saved once 26
val: 1 0.4486103653907776
val: 2 0.44928139448165894
val: 3 0.4375930726528168
val: 4 0.4404692053794861
val: 5 0.4409070312976837
val: 6 0.4351483881473541
val: 7 0.44100913405418396
val: 8 0.44836974143981934
val: 9 0.4492131173610687
val: 10 0.45347970724105835
val: 11 0.4431828558444977
val: 12 0.442606657743454
val: 13 0.4421171545982361
val: 14 0.4356220066547394
val: 15 0.4544200897216797
val: 16 0.43789997696876526
val: 17 0.44433730840682983
val: 18 0.44876161217689514
val: 19 0.454459547996521
val: 20 0.4495862126350403
val_Epoch:[ 26 ] val_loss: 0.4448537290096283 2022-05-30 01:30:00.939096
start training 2022-05-30 01:30:01.034958
Epoch:[ 27 0 ] loss: 0.4322963356971741 2022-05-30 01:30:23.462283
Epoch:[ 27 1 ] loss: 0.43636733293533325 2022-05-30 01:30:24.315373
Epoch:[ 27 2 ] loss: 0.431731641292572 2022-05-30 01:30:25.138227
Epoch:[ 27 3 ] loss: 0.4344514310359955 2022-05-30 01:30:25.916422
Epoch:[ 27 4 ] loss: 0.4354388117790222 2022-05-30 01:30:26.696310
Epoch:[ 27 5 ] loss: 0.4295002818107605 2022-05-30 01:30:27.473794
Epoch:[ 27 6 ] loss: 0.43387213349342346 2022-05-30 01:30:28.253426
Epoch:[ 27 7 ] loss: 0.4289734363555908 2022-05-30 01:30:29.030998
Epoch:[ 27 8 ] loss: 0.42521151900291443 2022-05-30 01:30:29.807384
Epoch:[ 27 9 ] loss: 0.43356579542160034 2022-05-30 01:30:30.586158
Epoch:[ 27 10 ] loss: 0.42773914337158203 2022-05-30 01:30:31.365963
Epoch:[ 27 11 ] loss: 0.4314297139644623 2022-05-30 01:30:32.145925
Epoch:[ 27 12 ] loss: 0.42965763807296753 2022-05-30 01:30:32.924856
Epoch:[ 27 13 ] loss: 0.43355807662010193 2022-05-30 01:30:33.702252
Epoch:[ 27 14 ] loss: 0.4286264181137085 2022-05-30 01:30:34.478576
Epoch:[ 27 15 ] loss: 0.42933154106140137 2022-05-30 01:30:35.256116
Epoch:[ 27 16 ] loss: 0.43029317259788513 2022-05-30 01:30:43.090095
Epoch:[ 27 17 ] loss: 0.43106964230537415 2022-05-30 01:30:43.867408
Epoch:[ 27 18 ] loss: 0.4309787452220917 2022-05-30 01:30:44.665795
Epoch:[ 27 19 ] loss: 0.4308345913887024 2022-05-30 01:30:45.445427
Training_Epoch:[ 27 ] Training_loss: 0.4312463700771332 2022-05-30 01:30:45.446120
learning rate:  0.0032
val: 1 0.43505623936653137
val: 2 0.4424869120121002
val: 3 0.4374994933605194
val: 4 0.44513070583343506
val: 5 0.4396480619907379
val: 6 0.4503905177116394
val: 7 0.4433528184890747
val: 8 0.4373997449874878
val: 9 0.4517606198787689
val: 10 0.44398099184036255
val: 11 0.44968536496162415
val: 12 0.44538938999176025
val: 13 0.4437214136123657
val: 14 0.4474266767501831
val: 15 0.4352317750453949
val: 16 0.44167762994766235
val: 17 0.4433270990848541
val: 18 0.44474685192108154
val: 19 0.44371965527534485
val: 20 0.4505227506160736
val_Epoch:[ 27 ] val_loss: 0.4436077356338501 2022-05-30 01:30:50.792922
start training 2022-05-30 01:30:50.888469
Epoch:[ 28 0 ] loss: 0.42963361740112305 2022-05-30 01:31:14.643947
Epoch:[ 28 1 ] loss: 0.4275825023651123 2022-05-30 01:31:15.419773
Epoch:[ 28 2 ] loss: 0.42938539385795593 2022-05-30 01:31:16.198023
Epoch:[ 28 3 ] loss: 0.4270278513431549 2022-05-30 01:31:16.974604
Epoch:[ 28 4 ] loss: 0.4303540885448456 2022-05-30 01:31:17.754319
Epoch:[ 28 5 ] loss: 0.42842090129852295 2022-05-30 01:31:18.531984
Epoch:[ 28 6 ] loss: 0.42991864681243896 2022-05-30 01:31:19.311503
Epoch:[ 28 7 ] loss: 0.4266456067562103 2022-05-30 01:31:20.089977
Epoch:[ 28 8 ] loss: 0.4293975830078125 2022-05-30 01:31:20.864653
Epoch:[ 28 9 ] loss: 0.4283434748649597 2022-05-30 01:31:21.641658
Epoch:[ 28 10 ] loss: 0.4278169274330139 2022-05-30 01:31:22.415740
Epoch:[ 28 11 ] loss: 0.4288741648197174 2022-05-30 01:31:23.194520
Epoch:[ 28 12 ] loss: 0.43349114060401917 2022-05-30 01:31:23.972503
Epoch:[ 28 13 ] loss: 0.43034809827804565 2022-05-30 01:31:24.747753
Epoch:[ 28 14 ] loss: 0.42762407660484314 2022-05-30 01:31:25.526405
Epoch:[ 28 15 ] loss: 0.42657288908958435 2022-05-30 01:31:26.302406
Epoch:[ 28 16 ] loss: 0.428358256816864 2022-05-30 01:31:34.067205
Epoch:[ 28 17 ] loss: 0.43279656767845154 2022-05-30 01:31:34.842422
Epoch:[ 28 18 ] loss: 0.42819294333457947 2022-05-30 01:31:35.625183
Epoch:[ 28 19 ] loss: 0.4295758903026581 2022-05-30 01:31:36.403206
Training_Epoch:[ 28 ] Training_loss: 0.42901803106069564 2022-05-30 01:31:36.403864
learning rate:  0.0032
netparams have been saved once 28
val: 1 0.43175625801086426
val: 2 0.4342613220214844
val: 3 0.43886610865592957
val: 4 0.43289780616760254
val: 5 0.4415762424468994
val: 6 0.4450170695781708
val: 7 0.43971681594848633
val: 8 0.4440048635005951
val: 9 0.451595664024353
val: 10 0.4478472173213959
val: 11 0.4367287755012512
val: 12 0.44815078377723694
val: 13 0.43509310483932495
val: 14 0.44490793347358704
val: 15 0.43744924664497375
val: 16 0.4431849718093872
val: 17 0.4462912678718567
val: 18 0.44587433338165283
val: 19 0.4513140916824341
val: 20 0.4433008134365082
val_Epoch:[ 28 ] val_loss: 0.4419917345046997 2022-05-30 01:31:41.947964
start training 2022-05-30 01:31:42.044451
Epoch:[ 29 0 ] loss: 0.4252432584762573 2022-05-30 01:32:05.038498
Epoch:[ 29 1 ] loss: 0.43185126781463623 2022-05-30 01:32:06.462872
Epoch:[ 29 2 ] loss: 0.42533984780311584 2022-05-30 01:32:07.238191
Epoch:[ 29 3 ] loss: 0.4251006543636322 2022-05-30 01:32:08.012946
Epoch:[ 29 4 ] loss: 0.4271746575832367 2022-05-30 01:32:08.786382
Epoch:[ 29 5 ] loss: 0.4269509017467499 2022-05-30 01:32:09.563256
Epoch:[ 29 6 ] loss: 0.4298548996448517 2022-05-30 01:32:10.340033
Epoch:[ 29 7 ] loss: 0.42669960856437683 2022-05-30 01:32:11.117927
Epoch:[ 29 8 ] loss: 0.4295804500579834 2022-05-30 01:32:11.895627
Epoch:[ 29 9 ] loss: 0.42743176221847534 2022-05-30 01:32:12.670337
Epoch:[ 29 10 ] loss: 0.43042808771133423 2022-05-30 01:32:13.447773
Epoch:[ 29 11 ] loss: 0.4294949769973755 2022-05-30 01:32:14.223577
Epoch:[ 29 12 ] loss: 0.4323088526725769 2022-05-30 01:32:15.001311
Epoch:[ 29 13 ] loss: 0.43245217204093933 2022-05-30 01:32:15.777142
Epoch:[ 29 14 ] loss: 0.4277918040752411 2022-05-30 01:32:16.554701
Epoch:[ 29 15 ] loss: 0.42625144124031067 2022-05-30 01:32:17.331714
Epoch:[ 29 16 ] loss: 0.42261236906051636 2022-05-30 01:32:24.290832
Epoch:[ 29 17 ] loss: 0.42358553409576416 2022-05-30 01:32:25.520566
Epoch:[ 29 18 ] loss: 0.4308253228664398 2022-05-30 01:32:26.298677
Epoch:[ 29 19 ] loss: 0.42768508195877075 2022-05-30 01:32:27.074449
Training_Epoch:[ 29 ] Training_loss: 0.4279331475496292 2022-05-30 01:32:27.075092
learning rate:  0.0032
val: 1 0.4409424960613251
val: 2 0.43968120217323303
val: 3 0.4301931858062744
val: 4 0.4509369730949402
val: 5 0.42995068430900574
val: 6 0.43437767028808594
val: 7 0.43648761510849
val: 8 0.4408453702926636
val: 9 0.4293202757835388
val: 10 0.44599899649620056
val: 11 0.4415566325187683
val: 12 0.4357839524745941
val: 13 0.43716153502464294
val: 14 0.4430674910545349
val: 15 0.42723792791366577
val: 16 0.4461513161659241
val: 17 0.4409787356853485
val: 18 0.4431298077106476
val: 19 0.45287057757377625
val: 20 0.43015825748443604
val_Epoch:[ 29 ] val_loss: 0.43884153515100477 2022-05-30 01:32:32.471932
start training 2022-05-30 01:32:32.569839
Epoch:[ 30 0 ] loss: 0.42427945137023926 2022-05-30 01:32:56.622158
Epoch:[ 30 1 ] loss: 0.42008280754089355 2022-05-30 01:32:57.399619
Epoch:[ 30 2 ] loss: 0.4267350733280182 2022-05-30 01:32:58.175907
Epoch:[ 30 3 ] loss: 0.42736032605171204 2022-05-30 01:32:58.950725
Epoch:[ 30 4 ] loss: 0.4221911132335663 2022-05-30 01:32:59.726639
Epoch:[ 30 5 ] loss: 0.4217407703399658 2022-05-30 01:33:00.502487
Epoch:[ 30 6 ] loss: 0.4253784418106079 2022-05-30 01:33:01.279971
Epoch:[ 30 7 ] loss: 0.4279787242412567 2022-05-30 01:33:02.057860
Epoch:[ 30 8 ] loss: 0.4233187437057495 2022-05-30 01:33:02.834192
Epoch:[ 30 9 ] loss: 0.4233006536960602 2022-05-30 01:33:03.609256
Epoch:[ 30 10 ] loss: 0.42556458711624146 2022-05-30 01:33:04.384620
Epoch:[ 30 11 ] loss: 0.4233793318271637 2022-05-30 01:33:05.159420
Epoch:[ 30 12 ] loss: 0.4285643696784973 2022-05-30 01:33:05.933515
Epoch:[ 30 13 ] loss: 0.42176392674446106 2022-05-30 01:33:06.710049
Epoch:[ 30 14 ] loss: 0.4252782166004181 2022-05-30 01:33:07.486824
Epoch:[ 30 15 ] loss: 0.4251474142074585 2022-05-30 01:33:08.265013
Epoch:[ 30 16 ] loss: 0.4241572916507721 2022-05-30 01:33:16.019633
Epoch:[ 30 17 ] loss: 0.42880332469940186 2022-05-30 01:33:16.793194
Epoch:[ 30 18 ] loss: 0.42771437764167786 2022-05-30 01:33:17.571372
Epoch:[ 30 19 ] loss: 0.42697328329086304 2022-05-30 01:33:18.344881
Training_Epoch:[ 30 ] Training_loss: 0.42498561143875124 2022-05-30 01:33:18.345508
learning rate:  0.0032
netparams have been saved once 30
val: 1 0.4417358934879303
val: 2 0.44138404726982117
val: 3 0.43723687529563904
val: 4 0.43958449363708496
val: 5 0.43115630745887756
val: 6 0.4271472692489624
val: 7 0.4348536729812622
val: 8 0.43887045979499817
val: 9 0.43890127539634705
val: 10 0.4469361901283264
val: 11 0.43725836277008057
val: 12 0.443080335855484
val: 13 0.43487823009490967
val: 14 0.42377129197120667
val: 15 0.4411052167415619
val: 16 0.430867075920105
val: 17 0.4299297630786896
val: 18 0.42410916090011597
val: 19 0.44591253995895386
val: 20 0.4427092373371124
val_Epoch:[ 30 ] val_loss: 0.43657138496637343 2022-05-30 01:33:23.823799
start training 2022-05-30 01:33:23.914340
Epoch:[ 31 0 ] loss: 0.42203089594841003 2022-05-30 01:33:47.959073
Epoch:[ 31 1 ] loss: 0.42228594422340393 2022-05-30 01:33:48.737598
Epoch:[ 31 2 ] loss: 0.4226287603378296 2022-05-30 01:33:49.515932
Epoch:[ 31 3 ] loss: 0.4211960732936859 2022-05-30 01:33:50.294572
Epoch:[ 31 4 ] loss: 0.42156580090522766 2022-05-30 01:33:51.069978
Epoch:[ 31 5 ] loss: 0.4239947497844696 2022-05-30 01:33:51.847837
Epoch:[ 31 6 ] loss: 0.4216822385787964 2022-05-30 01:33:52.622527
Epoch:[ 31 7 ] loss: 0.4234286844730377 2022-05-30 01:33:53.400603
Epoch:[ 31 8 ] loss: 0.4190761148929596 2022-05-30 01:33:54.179433
Epoch:[ 31 9 ] loss: 0.4240463674068451 2022-05-30 01:33:54.954362
Epoch:[ 31 10 ] loss: 0.42022305727005005 2022-05-30 01:33:55.730820
Epoch:[ 31 11 ] loss: 0.4229225218296051 2022-05-30 01:33:56.506580
Epoch:[ 31 12 ] loss: 0.42047834396362305 2022-05-30 01:33:57.282650
Epoch:[ 31 13 ] loss: 0.41836005449295044 2022-05-30 01:33:58.059010
Epoch:[ 31 14 ] loss: 0.42139801383018494 2022-05-30 01:33:58.837836
Epoch:[ 31 15 ] loss: 0.4213363230228424 2022-05-30 01:33:59.615024
Epoch:[ 31 16 ] loss: 0.42673686146736145 2022-05-30 01:34:06.993225
Epoch:[ 31 17 ] loss: 0.42003750801086426 2022-05-30 01:34:07.768213
Epoch:[ 31 18 ] loss: 0.42380616068840027 2022-05-30 01:34:08.548061
Epoch:[ 31 19 ] loss: 0.42057135701179504 2022-05-30 01:34:09.323812
Training_Epoch:[ 31 ] Training_loss: 0.4218902915716171 2022-05-30 01:34:09.324527
learning rate:  0.00256
val: 1 0.43266645073890686
val: 2 0.43104612827301025
val: 3 0.4304838180541992
val: 4 0.43683484196662903
val: 5 0.44265222549438477
val: 6 0.43383824825286865
val: 7 0.45633846521377563
val: 8 0.44259917736053467
val: 9 0.43712836503982544
val: 10 0.4263076186180115
val: 11 0.434195876121521
val: 12 0.4428298771381378
val: 13 0.4466952383518219
val: 14 0.4340093731880188
val: 15 0.4347376823425293
val: 16 0.4247460961341858
val: 17 0.4481189250946045
val: 18 0.43134620785713196
val: 19 0.4320041239261627
val: 20 0.44527655839920044
val_Epoch:[ 31 ] val_loss: 0.437192764878273 2022-05-30 01:34:14.689136
start training 2022-05-30 01:34:14.788723
Epoch:[ 32 0 ] loss: 0.4189286231994629 2022-05-30 01:34:37.226249
Epoch:[ 32 1 ] loss: 0.4192057251930237 2022-05-30 01:34:38.597668
Epoch:[ 32 2 ] loss: 0.4169541895389557 2022-05-30 01:34:39.375750
Epoch:[ 32 3 ] loss: 0.4238354563713074 2022-05-30 01:34:40.154473
Epoch:[ 32 4 ] loss: 0.4196317791938782 2022-05-30 01:34:40.930281
Epoch:[ 32 5 ] loss: 0.41785728931427 2022-05-30 01:34:41.705721
Epoch:[ 32 6 ] loss: 0.4179933965206146 2022-05-30 01:34:42.481474
Epoch:[ 32 7 ] loss: 0.4227966070175171 2022-05-30 01:34:43.257038
Epoch:[ 32 8 ] loss: 0.419186532497406 2022-05-30 01:34:44.033121
Epoch:[ 32 9 ] loss: 0.41872918605804443 2022-05-30 01:34:44.811740
Epoch:[ 32 10 ] loss: 0.4196162819862366 2022-05-30 01:34:45.587173
Epoch:[ 32 11 ] loss: 0.4223451614379883 2022-05-30 01:34:46.364477
Epoch:[ 32 12 ] loss: 0.4185616672039032 2022-05-30 01:34:47.141643
Epoch:[ 32 13 ] loss: 0.415105938911438 2022-05-30 01:34:47.918136
Epoch:[ 32 14 ] loss: 0.419411838054657 2022-05-30 01:34:48.694034
Epoch:[ 32 15 ] loss: 0.4181666076183319 2022-05-30 01:34:49.472384
Epoch:[ 32 16 ] loss: 0.42115455865859985 2022-05-30 01:34:57.174427
Epoch:[ 32 17 ] loss: 0.4199799597263336 2022-05-30 01:34:57.951786
Epoch:[ 32 18 ] loss: 0.42232072353363037 2022-05-30 01:34:58.733901
Epoch:[ 32 19 ] loss: 0.4201793372631073 2022-05-30 01:34:59.507561
Training_Epoch:[ 32 ] Training_loss: 0.4195980429649353 2022-05-30 01:34:59.508265
learning rate:  0.00256
netparams have been saved once 32
val: 1 0.4274701774120331
val: 2 0.43774187564849854
val: 3 0.4525095224380493
val: 4 0.43390414118766785
val: 5 0.42404481768608093
val: 6 0.43951544165611267
val: 7 0.43246224522590637
val: 8 0.44528236985206604
val: 9 0.4393991231918335
val: 10 0.4368448555469513
val: 11 0.4307887554168701
val: 12 0.43275752663612366
val: 13 0.4452749192714691
val: 14 0.43408557772636414
val: 15 0.4370814263820648
val: 16 0.42527148127555847
val: 17 0.43378764390945435
val: 18 0.4441527724266052
val: 19 0.43682482838630676
val: 20 0.4413869082927704
val_Epoch:[ 32 ] val_loss: 0.43652932047843934 2022-05-30 01:35:04.963441
start training 2022-05-30 01:35:05.061328
Epoch:[ 33 0 ] loss: 0.4221036434173584 2022-05-30 01:35:28.713707
Epoch:[ 33 1 ] loss: 0.4206879138946533 2022-05-30 01:35:29.488965
Epoch:[ 33 2 ] loss: 0.4189709722995758 2022-05-30 01:35:30.267726
Epoch:[ 33 3 ] loss: 0.41741788387298584 2022-05-30 01:35:31.045668
Epoch:[ 33 4 ] loss: 0.4183894991874695 2022-05-30 01:35:31.822008
Epoch:[ 33 5 ] loss: 0.41740578413009644 2022-05-30 01:35:32.597914
Epoch:[ 33 6 ] loss: 0.41842707991600037 2022-05-30 01:35:33.374227
Epoch:[ 33 7 ] loss: 0.4186675548553467 2022-05-30 01:35:34.149871
Epoch:[ 33 8 ] loss: 0.4199814796447754 2022-05-30 01:35:34.924186
Epoch:[ 33 9 ] loss: 0.4160930812358856 2022-05-30 01:35:35.700212
Epoch:[ 33 10 ] loss: 0.41726014018058777 2022-05-30 01:35:36.479610
Epoch:[ 33 11 ] loss: 0.4199252724647522 2022-05-30 01:35:37.254519
Epoch:[ 33 12 ] loss: 0.42175132036209106 2022-05-30 01:35:38.029449
Epoch:[ 33 13 ] loss: 0.4193933606147766 2022-05-30 01:35:38.805206
Epoch:[ 33 14 ] loss: 0.4162713885307312 2022-05-30 01:35:39.580833
Epoch:[ 33 15 ] loss: 0.4185762405395508 2022-05-30 01:35:40.355784
Epoch:[ 33 16 ] loss: 0.41705837845802307 2022-05-30 01:35:47.515715
Epoch:[ 33 17 ] loss: 0.4175781011581421 2022-05-30 01:35:48.290782
Epoch:[ 33 18 ] loss: 0.41943880915641785 2022-05-30 01:35:49.070889
Epoch:[ 33 19 ] loss: 0.41746753454208374 2022-05-30 01:35:49.845393
Training_Epoch:[ 33 ] Training_loss: 0.41864327192306516 2022-05-30 01:35:49.846052
learning rate:  0.00256
val: 1 0.4294500946998596
val: 2 0.4355616867542267
val: 3 0.4432954788208008
val: 4 0.4284226596355438
val: 5 0.43471792340278625
val: 6 0.4448626637458801
val: 7 0.4319498538970947
val: 8 0.4368523955345154
val: 9 0.44480836391448975
val: 10 0.44241073727607727
val: 11 0.4410923719406128
val: 12 0.4443809986114502
val: 13 0.4459342956542969
val: 14 0.4353049099445343
val: 15 0.43840301036834717
val: 16 0.43478924036026
val: 17 0.42857930064201355
val: 18 0.43300217390060425
val: 19 0.4361804723739624
val: 20 0.4416183531284332
val_Epoch:[ 33 ] val_loss: 0.43758084923028945 2022-05-30 01:35:55.202684
start training 2022-05-30 01:35:55.298830
Epoch:[ 34 0 ] loss: 0.4173038899898529 2022-05-30 01:36:19.268135
Epoch:[ 34 1 ] loss: 0.41565409302711487 2022-05-30 01:36:20.042917
Epoch:[ 34 2 ] loss: 0.413597047328949 2022-05-30 01:36:20.817870
Epoch:[ 34 3 ] loss: 0.41507643461227417 2022-05-30 01:36:21.596237
Epoch:[ 34 4 ] loss: 0.4154420495033264 2022-05-30 01:36:22.374061
Epoch:[ 34 5 ] loss: 0.4161089062690735 2022-05-30 01:36:23.151299
Epoch:[ 34 6 ] loss: 0.4165005683898926 2022-05-30 01:36:23.926817
Epoch:[ 34 7 ] loss: 0.4203830659389496 2022-05-30 01:36:24.703090
Epoch:[ 34 8 ] loss: 0.41746219992637634 2022-05-30 01:36:25.478466
Epoch:[ 34 9 ] loss: 0.416719526052475 2022-05-30 01:36:26.253095
Epoch:[ 34 10 ] loss: 0.4178794324398041 2022-05-30 01:36:27.031199
Epoch:[ 34 11 ] loss: 0.42069754004478455 2022-05-30 01:36:27.809097
Epoch:[ 34 12 ] loss: 0.41753634810447693 2022-05-30 01:36:28.588955
Epoch:[ 34 13 ] loss: 0.41537362337112427 2022-05-30 01:36:29.365986
Epoch:[ 34 14 ] loss: 0.4132631719112396 2022-05-30 01:36:30.140399
Epoch:[ 34 15 ] loss: 0.41606444120407104 2022-05-30 01:36:30.917797
Epoch:[ 34 16 ] loss: 0.4181901812553406 2022-05-30 01:36:38.092021
Epoch:[ 34 17 ] loss: 0.41517138481140137 2022-05-30 01:36:38.869266
Epoch:[ 34 18 ] loss: 0.4170244336128235 2022-05-30 01:36:39.650392
Epoch:[ 34 19 ] loss: 0.4194338619709015 2022-05-30 01:36:40.427122
Training_Epoch:[ 34 ] Training_loss: 0.4167441099882126 2022-05-30 01:36:40.427857
learning rate:  0.00256
netparams have been saved once 34
val: 1 0.455233097076416
val: 2 0.43876147270202637
val: 3 0.4233262240886688
val: 4 0.4285842180252075
val: 5 0.4360188841819763
val: 6 0.4336382746696472
val: 7 0.43203240633010864
val: 8 0.44172483682632446
val: 9 0.4326469302177429
val: 10 0.4424077868461609
val: 11 0.4324001669883728
val: 12 0.44688764214515686
val: 13 0.45138290524482727
val: 14 0.42301592230796814
val: 15 0.4328973591327667
val: 16 0.43603116273880005
val: 17 0.451621949672699
val: 18 0.4317139685153961
val: 19 0.4256404936313629
val: 20 0.42896270751953125
val_Epoch:[ 34 ] val_loss: 0.436246420443058 2022-05-30 01:36:45.864814
start training 2022-05-30 01:36:45.961867
Epoch:[ 35 0 ] loss: 0.414324551820755 2022-05-30 01:37:09.509681
Epoch:[ 35 1 ] loss: 0.4178647994995117 2022-05-30 01:37:10.284727
Epoch:[ 35 2 ] loss: 0.41601231694221497 2022-05-30 01:37:11.061183
Epoch:[ 35 3 ] loss: 0.42076772451400757 2022-05-30 01:37:11.834804
Epoch:[ 35 4 ] loss: 0.41404157876968384 2022-05-30 01:37:12.612979
Epoch:[ 35 5 ] loss: 0.41550835967063904 2022-05-30 01:37:13.391805
Epoch:[ 35 6 ] loss: 0.4097656011581421 2022-05-30 01:37:14.168167
Epoch:[ 35 7 ] loss: 0.4177035093307495 2022-05-30 01:37:14.944460
Epoch:[ 35 8 ] loss: 0.41381609439849854 2022-05-30 01:37:15.717660
Epoch:[ 35 9 ] loss: 0.41536036133766174 2022-05-30 01:37:16.492201
Epoch:[ 35 10 ] loss: 0.4149283766746521 2022-05-30 01:37:17.266902
Epoch:[ 35 11 ] loss: 0.41584664583206177 2022-05-30 01:37:18.045895
Epoch:[ 35 12 ] loss: 0.41301873326301575 2022-05-30 01:37:18.823635
Epoch:[ 35 13 ] loss: 0.4130485951900482 2022-05-30 01:37:19.599425
Epoch:[ 35 14 ] loss: 0.41737714409828186 2022-05-30 01:37:20.375764
Epoch:[ 35 15 ] loss: 0.41557756066322327 2022-05-30 01:37:21.151271
Epoch:[ 35 16 ] loss: 0.41458502411842346 2022-05-30 01:37:28.618198
Epoch:[ 35 17 ] loss: 0.42024490237236023 2022-05-30 01:37:29.393613
Epoch:[ 35 18 ] loss: 0.41225045919418335 2022-05-30 01:37:30.174335
Epoch:[ 35 19 ] loss: 0.41786137223243713 2022-05-30 01:37:30.950797
Training_Epoch:[ 35 ] Training_loss: 0.41549518555402754 2022-05-30 01:37:30.951454
learning rate:  0.00256
val: 1 0.4381183385848999
val: 2 0.4342462718486786
val: 3 0.43737074732780457
val: 4 0.4386080205440521
val: 5 0.41684460639953613
val: 6 0.4359683394432068
val: 7 0.44400259852409363
val: 8 0.42972201108932495
val: 9 0.4288637638092041
val: 10 0.4289734363555908
val: 11 0.44017916917800903
val: 12 0.4186129570007324
val: 13 0.44983214139938354
val: 14 0.43987223505973816
val: 15 0.4354219138622284
val: 16 0.43461042642593384
val: 17 0.4438140094280243
val: 18 0.43753185868263245
val: 19 0.44246554374694824
val: 20 0.43194466829299927
val_Epoch:[ 35 ] val_loss: 0.43535015285015105 2022-05-30 01:37:36.348871
start training 2022-05-30 01:37:36.448629
Epoch:[ 36 0 ] loss: 0.41125810146331787 2022-05-30 01:37:59.306820
Epoch:[ 36 1 ] loss: 0.41485580801963806 2022-05-30 01:38:00.572201
Epoch:[ 36 2 ] loss: 0.41351133584976196 2022-05-30 01:38:01.348908
Epoch:[ 36 3 ] loss: 0.414290189743042 2022-05-30 01:38:02.126301
Epoch:[ 36 4 ] loss: 0.41263681650161743 2022-05-30 01:38:02.903160
Epoch:[ 36 5 ] loss: 0.4158414900302887 2022-05-30 01:38:03.683154
Epoch:[ 36 6 ] loss: 0.41801902651786804 2022-05-30 01:38:04.463215
Epoch:[ 36 7 ] loss: 0.41578465700149536 2022-05-30 01:38:05.239918
Epoch:[ 36 8 ] loss: 0.41448870301246643 2022-05-30 01:38:06.019187
Epoch:[ 36 9 ] loss: 0.4153016209602356 2022-05-30 01:38:06.796684
Epoch:[ 36 10 ] loss: 0.416410893201828 2022-05-30 01:38:07.576378
Epoch:[ 36 11 ] loss: 0.4161536991596222 2022-05-30 01:38:08.353982
Epoch:[ 36 12 ] loss: 0.42049047350883484 2022-05-30 01:38:09.133598
Epoch:[ 36 13 ] loss: 0.4212498664855957 2022-05-30 01:38:09.911889
Epoch:[ 36 14 ] loss: 0.4148901104927063 2022-05-30 01:38:10.689258
Epoch:[ 36 15 ] loss: 0.4158465564250946 2022-05-30 01:38:11.465835
Epoch:[ 36 16 ] loss: 0.417449951171875 2022-05-30 01:38:19.356356
Epoch:[ 36 17 ] loss: 0.41694098711013794 2022-05-30 01:38:20.132622
Epoch:[ 36 18 ] loss: 0.41885021328926086 2022-05-30 01:38:20.911285
Epoch:[ 36 19 ] loss: 0.42041727900505066 2022-05-30 01:38:21.689627
Training_Epoch:[ 36 ] Training_loss: 0.4162343889474869 2022-05-30 01:38:21.690277
learning rate:  0.00256
netparams have been saved once 36
val: 1 0.436401903629303
val: 2 0.43498876690864563
val: 3 0.44045138359069824
val: 4 0.4462834298610687
val: 5 0.44783979654312134
val: 6 0.44227927923202515
val: 7 0.4309666156768799
val: 8 0.4354401230812073
val: 9 0.4505328834056854
val: 10 0.4395345449447632
val: 11 0.43530094623565674
val: 12 0.4492797255516052
val: 13 0.4388557970523834
val: 14 0.4440454840660095
val: 15 0.4452761709690094
val: 16 0.4553629755973816
val: 17 0.4388429522514343
val: 18 0.4314708709716797
val: 19 0.4416215717792511
val: 20 0.43324193358421326
val_Epoch:[ 36 ] val_loss: 0.4409008577466011 2022-05-30 01:38:27.248002
start training 2022-05-30 01:38:27.346238
Epoch:[ 37 0 ] loss: 0.4213853180408478 2022-05-30 01:38:49.970960
Epoch:[ 37 1 ] loss: 0.415863960981369 2022-05-30 01:38:51.809534
Epoch:[ 37 2 ] loss: 0.41581204533576965 2022-05-30 01:38:52.587136
Epoch:[ 37 3 ] loss: 0.4161214232444763 2022-05-30 01:38:53.362278
Epoch:[ 37 4 ] loss: 0.41359782218933105 2022-05-30 01:38:54.139681
Epoch:[ 37 5 ] loss: 0.4172948896884918 2022-05-30 01:38:54.914147
Epoch:[ 37 6 ] loss: 0.4180525839328766 2022-05-30 01:38:55.695091
Epoch:[ 37 7 ] loss: 0.41402384638786316 2022-05-30 01:38:56.474621
Epoch:[ 37 8 ] loss: 0.4164426028728485 2022-05-30 01:38:57.251616
Epoch:[ 37 9 ] loss: 0.4190473258495331 2022-05-30 01:38:58.026826
Epoch:[ 37 10 ] loss: 0.4143387973308563 2022-05-30 01:38:58.803360
Epoch:[ 37 11 ] loss: 0.41331666707992554 2022-05-30 01:38:59.580134
Epoch:[ 37 12 ] loss: 0.4161009192466736 2022-05-30 01:39:00.355291
Epoch:[ 37 13 ] loss: 0.4149473309516907 2022-05-30 01:39:01.133919
Epoch:[ 37 14 ] loss: 0.4148060083389282 2022-05-30 01:39:01.913436
Epoch:[ 37 15 ] loss: 0.41568347811698914 2022-05-30 01:39:02.690234
Epoch:[ 37 16 ] loss: 0.415382981300354 2022-05-30 01:39:09.411324
Epoch:[ 37 17 ] loss: 0.4155431091785431 2022-05-30 01:39:10.428432
Epoch:[ 37 18 ] loss: 0.41054123640060425 2022-05-30 01:39:11.209963
Epoch:[ 37 19 ] loss: 0.4125294089317322 2022-05-30 01:39:11.984167
Training_Epoch:[ 37 ] Training_loss: 0.4155415877699852 2022-05-30 01:39:11.984868
learning rate:  0.00256
val: 1 0.43971750140190125
val: 2 0.43774616718292236
val: 3 0.4368881285190582
val: 4 0.42988109588623047
val: 5 0.42575791478157043
val: 6 0.4266219139099121
val: 7 0.43709278106689453
val: 8 0.44512438774108887
val: 9 0.4316216707229614
val: 10 0.4384961724281311
val: 11 0.4307045340538025
val: 12 0.4503183662891388
val: 13 0.4383595287799835
val: 14 0.4428699314594269
val: 15 0.4284542202949524
val: 16 0.43447378277778625
val: 17 0.42998746037483215
val: 18 0.42744845151901245
val: 19 0.4259893298149109
val: 20 0.4443037211894989
val_Epoch:[ 37 ] val_loss: 0.4350928530097008 2022-05-30 01:39:17.381879
start training 2022-05-30 01:39:17.483129
Epoch:[ 38 0 ] loss: 0.41400346159935 2022-05-30 01:39:41.231832
Epoch:[ 38 1 ] loss: 0.4150716960430145 2022-05-30 01:39:42.009800
Epoch:[ 38 2 ] loss: 0.4114060699939728 2022-05-30 01:39:42.787783
Epoch:[ 38 3 ] loss: 0.4136697053909302 2022-05-30 01:39:43.565628
Epoch:[ 38 4 ] loss: 0.41362980008125305 2022-05-30 01:39:44.340438
Epoch:[ 38 5 ] loss: 0.4123193025588989 2022-05-30 01:39:45.115512
Epoch:[ 38 6 ] loss: 0.4126306474208832 2022-05-30 01:39:45.889651
Epoch:[ 38 7 ] loss: 0.41268467903137207 2022-05-30 01:39:46.666645
Epoch:[ 38 8 ] loss: 0.41237249970436096 2022-05-30 01:39:47.444978
Epoch:[ 38 9 ] loss: 0.4180706739425659 2022-05-30 01:39:48.221643
Epoch:[ 38 10 ] loss: 0.4092216193675995 2022-05-30 01:39:48.997085
Epoch:[ 38 11 ] loss: 0.41278770565986633 2022-05-30 01:39:49.772811
Epoch:[ 38 12 ] loss: 0.4126463234424591 2022-05-30 01:39:50.548733
Epoch:[ 38 13 ] loss: 0.41260263323783875 2022-05-30 01:39:51.324412
Epoch:[ 38 14 ] loss: 0.41410914063453674 2022-05-30 01:39:52.102951
Epoch:[ 38 15 ] loss: 0.41324564814567566 2022-05-30 01:39:52.882446
Epoch:[ 38 16 ] loss: 0.41167372465133667 2022-05-30 01:40:00.196541
Epoch:[ 38 17 ] loss: 0.41225466132164 2022-05-30 01:40:00.974146
Epoch:[ 38 18 ] loss: 0.41308578848838806 2022-05-30 01:40:01.753824
Epoch:[ 38 19 ] loss: 0.4135093092918396 2022-05-30 01:40:02.528538
Training_Epoch:[ 38 ] Training_loss: 0.4130497545003891 2022-05-30 01:40:02.529287
learning rate:  0.00256
netparams have been saved once 38
val: 1 0.44523587822914124
val: 2 0.44052013754844666
val: 3 0.4439389109611511
val: 4 0.41822803020477295
val: 5 0.4282309412956238
val: 6 0.42451855540275574
val: 7 0.43702611327171326
val: 8 0.4377002716064453
val: 9 0.4335508942604065
val: 10 0.43080204725265503
val: 11 0.4235261380672455
val: 12 0.4407464861869812
val: 13 0.44966384768486023
val: 14 0.4369444251060486
val: 15 0.42986077070236206
val: 16 0.43497803807258606
val: 17 0.42247700691223145
val: 18 0.444180428981781
val: 19 0.43953073024749756
val: 20 0.4337012767791748
val_Epoch:[ 38 ] val_loss: 0.434768046438694 2022-05-30 01:40:08.069511
start training 2022-05-30 01:40:08.171617
Epoch:[ 39 0 ] loss: 0.4104424715042114 2022-05-30 01:40:30.666866
Epoch:[ 39 1 ] loss: 0.41593748331069946 2022-05-30 01:40:31.618489
Epoch:[ 39 2 ] loss: 0.413449227809906 2022-05-30 01:40:32.396842
Epoch:[ 39 3 ] loss: 0.410121351480484 2022-05-30 01:40:33.171786
Epoch:[ 39 4 ] loss: 0.411545068025589 2022-05-30 01:40:33.949923
Epoch:[ 39 5 ] loss: 0.4092681407928467 2022-05-30 01:40:34.724532
Epoch:[ 39 6 ] loss: 0.41502317786216736 2022-05-30 01:40:35.499833
Epoch:[ 39 7 ] loss: 0.40900567173957825 2022-05-30 01:40:36.274401
Epoch:[ 39 8 ] loss: 0.4110119342803955 2022-05-30 01:40:37.051946
Epoch:[ 39 9 ] loss: 0.41112762689590454 2022-05-30 01:40:37.832410
Epoch:[ 39 10 ] loss: 0.4099498689174652 2022-05-30 01:40:38.608740
Epoch:[ 39 11 ] loss: 0.4097207188606262 2022-05-30 01:40:39.383501
Epoch:[ 39 12 ] loss: 0.4071149528026581 2022-05-30 01:40:40.158955
Epoch:[ 39 13 ] loss: 0.41084179282188416 2022-05-30 01:40:40.933708
Epoch:[ 39 14 ] loss: 0.41197535395622253 2022-05-30 01:40:41.706935
Epoch:[ 39 15 ] loss: 0.4091813266277313 2022-05-30 01:40:42.483424
Epoch:[ 39 16 ] loss: 0.4110351800918579 2022-05-30 01:40:50.177032
Epoch:[ 39 17 ] loss: 0.4108927547931671 2022-05-30 01:40:50.955314
Epoch:[ 39 18 ] loss: 0.41241052746772766 2022-05-30 01:40:51.735119
Epoch:[ 39 19 ] loss: 0.411971777677536 2022-05-30 01:40:52.509041
Training_Epoch:[ 39 ] Training_loss: 0.41110132038593294 2022-05-30 01:40:52.509794
learning rate:  0.00256
val: 1 0.4487435817718506
val: 2 0.4411223530769348
val: 3 0.44660472869873047
val: 4 0.4383363723754883
val: 5 0.43331363797187805
val: 6 0.4202323853969574
val: 7 0.4285791516304016
val: 8 0.4333617389202118
val: 9 0.446860671043396
val: 10 0.4431803822517395
val: 11 0.43102192878723145
val: 12 0.4258304536342621
val: 13 0.44012120366096497
val: 14 0.4252322316169739
val: 15 0.42146340012550354
val: 16 0.4375874102115631
val: 17 0.430528849363327
val: 18 0.43018442392349243
val: 19 0.42026883363723755
val: 20 0.4387519359588623
val_Epoch:[ 39 ] val_loss: 0.43406628370285033 2022-05-30 01:40:57.857308
start training 2022-05-30 01:40:57.961031
Epoch:[ 40 0 ] loss: 0.40930140018463135 2022-05-30 01:41:21.788253
Epoch:[ 40 1 ] loss: 0.4078674614429474 2022-05-30 01:41:22.563219
Epoch:[ 40 2 ] loss: 0.4048427641391754 2022-05-30 01:41:23.341736
Epoch:[ 40 3 ] loss: 0.4073375463485718 2022-05-30 01:41:24.121959
Epoch:[ 40 4 ] loss: 0.40605077147483826 2022-05-30 01:41:24.900129
Epoch:[ 40 5 ] loss: 0.411175400018692 2022-05-30 01:41:25.677532
Epoch:[ 40 6 ] loss: 0.4074607193470001 2022-05-30 01:41:26.456105
Epoch:[ 40 7 ] loss: 0.41366228461265564 2022-05-30 01:41:27.237113
Epoch:[ 40 8 ] loss: 0.4107201099395752 2022-05-30 01:41:28.011821
Epoch:[ 40 9 ] loss: 0.40878191590309143 2022-05-30 01:41:28.790745
Epoch:[ 40 10 ] loss: 0.4146476686000824 2022-05-30 01:41:29.569928
Epoch:[ 40 11 ] loss: 0.4087790548801422 2022-05-30 01:41:30.345967
Epoch:[ 40 12 ] loss: 0.4082294702529907 2022-05-30 01:41:31.121525
Epoch:[ 40 13 ] loss: 0.4112313389778137 2022-05-30 01:41:31.896655
Epoch:[ 40 14 ] loss: 0.4107529819011688 2022-05-30 01:41:32.674361
Epoch:[ 40 15 ] loss: 0.4071446359157562 2022-05-30 01:41:33.449954
Epoch:[ 40 16 ] loss: 0.4120663106441498 2022-05-30 01:41:40.555888
Epoch:[ 40 17 ] loss: 0.41164395213127136 2022-05-30 01:41:41.332323
Epoch:[ 40 18 ] loss: 0.4122370779514313 2022-05-30 01:41:42.113943
Epoch:[ 40 19 ] loss: 0.4140864610671997 2022-05-30 01:41:42.892573
Training_Epoch:[ 40 ] Training_loss: 0.40990096628665923 2022-05-30 01:41:42.893319
learning rate:  0.00256
netparams have been saved once 40
val: 1 0.43248751759529114
val: 2 0.4434345066547394
val: 3 0.4404447376728058
val: 4 0.431111216545105
val: 5 0.4293994605541229
val: 6 0.4514527916908264
val: 7 0.43906423449516296
val: 8 0.41759759187698364
val: 9 0.4422079920768738
val: 10 0.4370703101158142
val: 11 0.44061851501464844
val: 12 0.42818745970726013
val: 13 0.42743948101997375
val: 14 0.43504324555397034
val: 15 0.4409736394882202
val: 16 0.4444807767868042
val: 17 0.4261895418167114
val: 18 0.44264423847198486
val: 19 0.43435484170913696
val: 20 0.43347832560539246
val_Epoch:[ 40 ] val_loss: 0.4358840212225914 2022-05-30 01:41:48.399618
start training 2022-05-30 01:41:48.499443
Epoch:[ 41 0 ] loss: 0.4092187285423279 2022-05-30 01:42:12.701028
Epoch:[ 41 1 ] loss: 0.4069434702396393 2022-05-30 01:42:13.476907
Epoch:[ 41 2 ] loss: 0.4092552363872528 2022-05-30 01:42:14.250973
Epoch:[ 41 3 ] loss: 0.41022735834121704 2022-05-30 01:42:15.029637
Epoch:[ 41 4 ] loss: 0.40974363684654236 2022-05-30 01:42:15.807990
Epoch:[ 41 5 ] loss: 0.40652376413345337 2022-05-30 01:42:16.587653
Epoch:[ 41 6 ] loss: 0.4058082103729248 2022-05-30 01:42:17.362739
Epoch:[ 41 7 ] loss: 0.4092162251472473 2022-05-30 01:42:18.138460
Epoch:[ 41 8 ] loss: 0.40858596563339233 2022-05-30 01:42:18.915928
Epoch:[ 41 9 ] loss: 0.4073949158191681 2022-05-30 01:42:19.690121
Epoch:[ 41 10 ] loss: 0.404355525970459 2022-05-30 01:42:20.467788
Epoch:[ 41 11 ] loss: 0.4057277739048004 2022-05-30 01:42:21.246807
Epoch:[ 41 12 ] loss: 0.40841177105903625 2022-05-30 01:42:22.026253
Epoch:[ 41 13 ] loss: 0.40733590722084045 2022-05-30 01:42:22.802302
Epoch:[ 41 14 ] loss: 0.40865013003349304 2022-05-30 01:42:23.577078
Epoch:[ 41 15 ] loss: 0.40723785758018494 2022-05-30 01:42:24.350849
Epoch:[ 41 16 ] loss: 0.4072178304195404 2022-05-30 01:42:32.074234
Epoch:[ 41 17 ] loss: 0.4083527624607086 2022-05-30 01:42:32.849159
Epoch:[ 41 18 ] loss: 0.40554511547088623 2022-05-30 01:42:33.631445
Epoch:[ 41 19 ] loss: 0.4083190858364105 2022-05-30 01:42:34.407298
Training_Epoch:[ 41 ] Training_loss: 0.40770356357097626 2022-05-30 01:42:34.407968
learning rate:  0.0020480000000000003
val: 1 0.4316942095756531
val: 2 0.43654224276542664
val: 3 0.4480782449245453
val: 4 0.42797425389289856
val: 5 0.4425050914287567
val: 6 0.4469940662384033
val: 7 0.43205273151397705
val: 8 0.43417805433273315
val: 9 0.44011640548706055
val: 10 0.4439036548137665
val: 11 0.4396531581878662
val: 12 0.4182436764240265
val: 13 0.45199915766716003
val: 14 0.436704158782959
val: 15 0.42387259006500244
val: 16 0.42434293031692505
val: 17 0.43732041120529175
val: 18 0.4236801564693451
val: 19 0.4315343499183655
val: 20 0.4423050582408905
val_Epoch:[ 41 ] val_loss: 0.43568473011255265 2022-05-30 01:42:39.767131
start training 2022-05-30 01:42:39.865278
Epoch:[ 42 0 ] loss: 0.40559113025665283 2022-05-30 01:43:02.169109
Epoch:[ 42 1 ] loss: 0.40682363510131836 2022-05-30 01:43:03.642858
Epoch:[ 42 2 ] loss: 0.40580353140830994 2022-05-30 01:43:04.420297
Epoch:[ 42 3 ] loss: 0.40725767612457275 2022-05-30 01:43:05.195728
Epoch:[ 42 4 ] loss: 0.40303078293800354 2022-05-30 01:43:05.972868
Epoch:[ 42 5 ] loss: 0.4053974449634552 2022-05-30 01:43:06.750680
Epoch:[ 42 6 ] loss: 0.4088803827762604 2022-05-30 01:43:07.529500
Epoch:[ 42 7 ] loss: 0.4057293236255646 2022-05-30 01:43:08.306448
Epoch:[ 42 8 ] loss: 0.4033336341381073 2022-05-30 01:43:09.081477
Epoch:[ 42 9 ] loss: 0.4033118188381195 2022-05-30 01:43:09.859897
Epoch:[ 42 10 ] loss: 0.4112136960029602 2022-05-30 01:43:10.634857
Epoch:[ 42 11 ] loss: 0.40554606914520264 2022-05-30 01:43:11.413745
Epoch:[ 42 12 ] loss: 0.40814992785453796 2022-05-30 01:43:12.192127
Epoch:[ 42 13 ] loss: 0.40402641892433167 2022-05-30 01:43:12.972799
Epoch:[ 42 14 ] loss: 0.40625935792922974 2022-05-30 01:43:13.751876
Epoch:[ 42 15 ] loss: 0.40695077180862427 2022-05-30 01:43:14.528593
Epoch:[ 42 16 ] loss: 0.40726956725120544 2022-05-30 01:43:21.688354
Epoch:[ 42 17 ] loss: 0.40837955474853516 2022-05-30 01:43:22.533716
Epoch:[ 42 18 ] loss: 0.407149076461792 2022-05-30 01:43:23.316023
Epoch:[ 42 19 ] loss: 0.4039578437805176 2022-05-30 01:43:24.093298
Training_Epoch:[ 42 ] Training_loss: 0.40620308220386503 2022-05-30 01:43:24.094008
learning rate:  0.0020480000000000003
netparams have been saved once 42
val: 1 0.42978736758232117
val: 2 0.41905683279037476
val: 3 0.4365277886390686
val: 4 0.43293145298957825
val: 5 0.43050989508628845
val: 6 0.4426567852497101
val: 7 0.44324398040771484
val: 8 0.43646982312202454
val: 9 0.4396403133869171
val: 10 0.43423202633857727
val: 11 0.43960604071617126
val: 12 0.42511239647865295
val: 13 0.43727970123291016
val: 14 0.4420759081840515
val: 15 0.4315333664417267
val: 16 0.42798739671707153
val: 17 0.4347447156906128
val: 18 0.4321940839290619
val: 19 0.4427671730518341
val: 20 0.4364831745624542
val_Epoch:[ 42 ] val_loss: 0.4347420111298561 2022-05-30 01:43:29.582595
start training 2022-05-30 01:43:29.680093
Epoch:[ 43 0 ] loss: 0.40430447459220886 2022-05-30 01:43:52.276719
Epoch:[ 43 1 ] loss: 0.4033917486667633 2022-05-30 01:43:53.166350
Epoch:[ 43 2 ] loss: 0.40489211678504944 2022-05-30 01:43:53.942344
Epoch:[ 43 3 ] loss: 0.4027427136898041 2022-05-30 01:43:54.719305
Epoch:[ 43 4 ] loss: 0.404788076877594 2022-05-30 01:43:55.493906
Epoch:[ 43 5 ] loss: 0.39957234263420105 2022-05-30 01:43:56.273010
Epoch:[ 43 6 ] loss: 0.40410083532333374 2022-05-30 01:43:57.052233
Epoch:[ 43 7 ] loss: 0.40289410948753357 2022-05-30 01:43:57.831941
Epoch:[ 43 8 ] loss: 0.4059062600135803 2022-05-30 01:43:58.607775
Epoch:[ 43 9 ] loss: 0.4057116210460663 2022-05-30 01:43:59.383992
Epoch:[ 43 10 ] loss: 0.40389472246170044 2022-05-30 01:44:00.162701
Epoch:[ 43 11 ] loss: 0.40594226121902466 2022-05-30 01:44:00.938048
Epoch:[ 43 12 ] loss: 0.40686023235321045 2022-05-30 01:44:01.716684
Epoch:[ 43 13 ] loss: 0.40453511476516724 2022-05-30 01:44:02.493253
Epoch:[ 43 14 ] loss: 0.40639111399650574 2022-05-30 01:44:03.271315
Epoch:[ 43 15 ] loss: 0.4045053720474243 2022-05-30 01:44:04.047788
Epoch:[ 43 16 ] loss: 0.405159592628479 2022-05-30 01:44:11.611083
Epoch:[ 43 17 ] loss: 0.40884801745414734 2022-05-30 01:44:12.388236
Epoch:[ 43 18 ] loss: 0.4036201536655426 2022-05-30 01:44:13.165652
Epoch:[ 43 19 ] loss: 0.4033207595348358 2022-05-30 01:44:13.942021
Training_Epoch:[ 43 ] Training_loss: 0.4045690819621086 2022-05-30 01:44:13.942641
learning rate:  0.0020480000000000003
val: 1 0.45570942759513855
val: 2 0.43809738755226135
val: 3 0.4344518184661865
val: 4 0.4315115213394165
val: 5 0.433275043964386
val: 6 0.4300448000431061
val: 7 0.441130131483078
val: 8 0.43711337447166443
val: 9 0.43104150891304016
val: 10 0.432969331741333
val: 11 0.4373410642147064
val: 12 0.4258147180080414
val: 13 0.4380623996257782
val: 14 0.4326040744781494
val: 15 0.4310084879398346
val: 16 0.4355500638484955
val: 17 0.4221750795841217
val: 18 0.43387606739997864
val: 19 0.43106985092163086
val: 20 0.42937126755714417
val_Epoch:[ 43 ] val_loss: 0.43411087095737455 2022-05-30 01:44:19.469234
start training 2022-05-30 01:44:19.561695
Epoch:[ 44 0 ] loss: 0.40447211265563965 2022-05-30 01:44:43.803943
Epoch:[ 44 1 ] loss: 0.4036066234111786 2022-05-30 01:44:44.581270
Epoch:[ 44 2 ] loss: 0.40348324179649353 2022-05-30 01:44:45.357641
Epoch:[ 44 3 ] loss: 0.4039996862411499 2022-05-30 01:44:46.134108
Epoch:[ 44 4 ] loss: 0.40085428953170776 2022-05-30 01:44:46.911208
Epoch:[ 44 5 ] loss: 0.40776535868644714 2022-05-30 01:44:47.687229
Epoch:[ 44 6 ] loss: 0.404169499874115 2022-05-30 01:44:48.466028
Epoch:[ 44 7 ] loss: 0.39958861470222473 2022-05-30 01:44:49.244666
Epoch:[ 44 8 ] loss: 0.40264198184013367 2022-05-30 01:44:50.021324
Epoch:[ 44 9 ] loss: 0.40253177285194397 2022-05-30 01:44:50.796089
Epoch:[ 44 10 ] loss: 0.40148743987083435 2022-05-30 01:44:51.571577
Epoch:[ 44 11 ] loss: 0.39916151762008667 2022-05-30 01:44:52.347786
Epoch:[ 44 12 ] loss: 0.4037380814552307 2022-05-30 01:44:53.122777
Epoch:[ 44 13 ] loss: 0.4012182652950287 2022-05-30 01:44:53.901929
Epoch:[ 44 14 ] loss: 0.4052952527999878 2022-05-30 01:44:54.681923
Epoch:[ 44 15 ] loss: 0.4068967401981354 2022-05-30 01:44:55.461275
Epoch:[ 44 16 ] loss: 0.40828457474708557 2022-05-30 01:45:03.084378
Epoch:[ 44 17 ] loss: 0.4062249958515167 2022-05-30 01:45:03.860938
Epoch:[ 44 18 ] loss: 0.40361490845680237 2022-05-30 01:45:04.641154
Epoch:[ 44 19 ] loss: 0.4058992266654968 2022-05-30 01:45:05.419593
Training_Epoch:[ 44 ] Training_loss: 0.40374670922756195 2022-05-30 01:45:05.420267
learning rate:  0.0020480000000000003
netparams have been saved once 44
val: 1 0.43337106704711914
val: 2 0.4416632354259491
val: 3 0.4419133961200714
val: 4 0.42526307702064514
val: 5 0.4432511329650879
val: 6 0.4455472528934479
val: 7 0.41642463207244873
val: 8 0.42623230814933777
val: 9 0.4374767541885376
val: 10 0.43126949667930603
val: 11 0.43284350633621216
val: 12 0.43137580156326294
val: 13 0.4347008466720581
val: 14 0.42682090401649475
val: 15 0.43935880064964294
val: 16 0.43192872405052185
val: 17 0.42962560057640076
val: 18 0.4203065037727356
val: 19 0.4538913071155548
val: 20 0.4398666024208069
val_Epoch:[ 44 ] val_loss: 0.43415654748678206 2022-05-30 01:45:10.971688
start training 2022-05-30 01:45:11.069127
Epoch:[ 45 0 ] loss: 0.40336984395980835 2022-05-30 01:45:35.169443
Epoch:[ 45 1 ] loss: 0.40179163217544556 2022-05-30 01:45:35.948170
Epoch:[ 45 2 ] loss: 0.4035021662712097 2022-05-30 01:45:36.724964
Epoch:[ 45 3 ] loss: 0.40078842639923096 2022-05-30 01:45:37.503121
Epoch:[ 45 4 ] loss: 0.4014083743095398 2022-05-30 01:45:38.281300
Epoch:[ 45 5 ] loss: 0.4030293822288513 2022-05-30 01:45:39.057959
Epoch:[ 45 6 ] loss: 0.3996206521987915 2022-05-30 01:45:39.833816
Epoch:[ 45 7 ] loss: 0.40460842847824097 2022-05-30 01:45:40.611890
Epoch:[ 45 8 ] loss: 0.4054024815559387 2022-05-30 01:45:41.391303
Epoch:[ 45 9 ] loss: 0.40172427892684937 2022-05-30 01:45:42.168846
Epoch:[ 45 10 ] loss: 0.4038115441799164 2022-05-30 01:45:42.947650
Epoch:[ 45 11 ] loss: 0.40333089232444763 2022-05-30 01:45:43.724935
Epoch:[ 45 12 ] loss: 0.4044906795024872 2022-05-30 01:45:44.501529
Epoch:[ 45 13 ] loss: 0.40496787428855896 2022-05-30 01:45:45.278819
Epoch:[ 45 14 ] loss: 0.40606459975242615 2022-05-30 01:45:46.058074
Epoch:[ 45 15 ] loss: 0.39932867884635925 2022-05-30 01:45:46.837642
Epoch:[ 45 16 ] loss: 0.40258848667144775 2022-05-30 01:45:54.031759
Epoch:[ 45 17 ] loss: 0.40217629075050354 2022-05-30 01:45:54.810161
Epoch:[ 45 18 ] loss: 0.4030141532421112 2022-05-30 01:45:55.588691
Epoch:[ 45 19 ] loss: 0.40204352140426636 2022-05-30 01:45:56.363837
Training_Epoch:[ 45 ] Training_loss: 0.4028531193733215 2022-05-30 01:45:56.364654
learning rate:  0.0020480000000000003
val: 1 0.4131591320037842
val: 2 0.4378432035446167
val: 3 0.43154284358024597
val: 4 0.43441352248191833
val: 5 0.42604726552963257
val: 6 0.43879464268684387
val: 7 0.43118521571159363
val: 8 0.44136589765548706
val: 9 0.4450470805168152
val: 10 0.4380740225315094
val: 11 0.45216408371925354
val: 12 0.44282016158103943
val: 13 0.4416395425796509
val: 14 0.429609090089798
val: 15 0.4243605136871338
val: 16 0.4393434226512909
val: 17 0.4442327618598938
val: 18 0.417143315076828
val: 19 0.4321305751800537
val: 20 0.44218674302101135
val_Epoch:[ 45 ] val_loss: 0.43515515178442 2022-05-30 01:46:01.812733
start training 2022-05-30 01:46:01.908017
Epoch:[ 46 0 ] loss: 0.4016960859298706 2022-05-30 01:46:25.465879
Epoch:[ 46 1 ] loss: 0.39952409267425537 2022-05-30 01:46:26.245504
Epoch:[ 46 2 ] loss: 0.4004575312137604 2022-05-30 01:46:27.022585
Epoch:[ 46 3 ] loss: 0.4021177291870117 2022-05-30 01:46:27.799839
Epoch:[ 46 4 ] loss: 0.40198856592178345 2022-05-30 01:46:28.578197
Epoch:[ 46 5 ] loss: 0.40185779333114624 2022-05-30 01:46:29.353010
Epoch:[ 46 6 ] loss: 0.39900556206703186 2022-05-30 01:46:30.129315
Epoch:[ 46 7 ] loss: 0.4045085310935974 2022-05-30 01:46:30.904130
Epoch:[ 46 8 ] loss: 0.3978928029537201 2022-05-30 01:46:31.682869
Epoch:[ 46 9 ] loss: 0.39941421151161194 2022-05-30 01:46:32.458233
Epoch:[ 46 10 ] loss: 0.40705206990242004 2022-05-30 01:46:33.238589
Epoch:[ 46 11 ] loss: 0.40274977684020996 2022-05-30 01:46:34.015463
Epoch:[ 46 12 ] loss: 0.4024145305156708 2022-05-30 01:46:34.790996
Epoch:[ 46 13 ] loss: 0.40338608622550964 2022-05-30 01:46:35.567420
Epoch:[ 46 14 ] loss: 0.40080952644348145 2022-05-30 01:46:36.343218
Epoch:[ 46 15 ] loss: 0.4014979600906372 2022-05-30 01:46:37.121505
Epoch:[ 46 16 ] loss: 0.40273013710975647 2022-05-30 01:46:44.235076
Epoch:[ 46 17 ] loss: 0.4049452543258667 2022-05-30 01:46:45.012051
Epoch:[ 46 18 ] loss: 0.4056859314441681 2022-05-30 01:46:45.791981
Epoch:[ 46 19 ] loss: 0.40278100967407227 2022-05-30 01:46:46.566755
Training_Epoch:[ 46 ] Training_loss: 0.40212575942277906 2022-05-30 01:46:46.567455
learning rate:  0.0020480000000000003
netparams have been saved once 46
val: 1 0.44887351989746094
val: 2 0.42035728693008423
val: 3 0.4353751838207245
val: 4 0.442219078540802
val: 5 0.42584192752838135
val: 6 0.43628349900245667
val: 7 0.4284104108810425
val: 8 0.441314697265625
val: 9 0.4450359642505646
val: 10 0.4258957505226135
val: 11 0.43061479926109314
val: 12 0.4217923879623413
val: 13 0.43197906017303467
val: 14 0.4297129213809967
val: 15 0.43888819217681885
val: 16 0.42700889706611633
val: 17 0.4405243694782257
val: 18 0.4287317991256714
val: 19 0.4374661147594452
val: 20 0.4309579133987427
val_Epoch:[ 46 ] val_loss: 0.43336418867111204 2022-05-30 01:46:52.022214
start training 2022-05-30 01:46:52.119289
Epoch:[ 47 0 ] loss: 0.40205466747283936 2022-05-30 01:47:15.355010
Epoch:[ 47 1 ] loss: 0.40100353956222534 2022-05-30 01:47:16.266820
Epoch:[ 47 2 ] loss: 0.40345463156700134 2022-05-30 01:47:17.045575
Epoch:[ 47 3 ] loss: 0.40363645553588867 2022-05-30 01:47:17.825008
Epoch:[ 47 4 ] loss: 0.4016203284263611 2022-05-30 01:47:18.605404
Epoch:[ 47 5 ] loss: 0.40045371651649475 2022-05-30 01:47:19.383197
Epoch:[ 47 6 ] loss: 0.40266865491867065 2022-05-30 01:47:20.158884
Epoch:[ 47 7 ] loss: 0.40006962418556213 2022-05-30 01:47:20.934971
Epoch:[ 47 8 ] loss: 0.4021769165992737 2022-05-30 01:47:21.708825
Epoch:[ 47 9 ] loss: 0.4014030992984772 2022-05-30 01:47:22.486712
Epoch:[ 47 10 ] loss: 0.4038791060447693 2022-05-30 01:47:23.261411
Epoch:[ 47 11 ] loss: 0.39972907304763794 2022-05-30 01:47:24.040504
Epoch:[ 47 12 ] loss: 0.4082615375518799 2022-05-30 01:47:24.816634
Epoch:[ 47 13 ] loss: 0.4051382541656494 2022-05-30 01:47:25.591852
Epoch:[ 47 14 ] loss: 0.4064487814903259 2022-05-30 01:47:26.367927
Epoch:[ 47 15 ] loss: 0.407743364572525 2022-05-30 01:47:27.143636
Epoch:[ 47 16 ] loss: 0.40182316303253174 2022-05-30 01:47:34.556722
Epoch:[ 47 17 ] loss: 0.40287160873413086 2022-05-30 01:47:35.334287
Epoch:[ 47 18 ] loss: 0.40451958775520325 2022-05-30 01:47:36.117180
Epoch:[ 47 19 ] loss: 0.4052697718143463 2022-05-30 01:47:36.910963
Training_Epoch:[ 47 ] Training_loss: 0.40321129411458967 2022-05-30 01:47:36.911768
learning rate:  0.0020480000000000003
val: 1 0.44770774245262146
val: 2 0.43324601650238037
val: 3 0.4459005296230316
val: 4 0.42826908826828003
val: 5 0.4266568422317505
val: 6 0.44266676902770996
val: 7 0.43837666511535645
val: 8 0.4547243118286133
val: 9 0.4398233890533447
val: 10 0.4494327902793884
val: 11 0.4367694854736328
val: 12 0.45392942428588867
val: 13 0.43167465925216675
val: 14 0.44192877411842346
val: 15 0.4321148991584778
val: 16 0.4473668336868286
val: 17 0.43745315074920654
val: 18 0.4450521469116211
val: 19 0.4319876730442047
val: 20 0.43888381123542786
val_Epoch:[ 47 ] val_loss: 0.44019825011491776 2022-05-30 01:47:42.270024
start training 2022-05-30 01:47:42.369809
Epoch:[ 48 0 ] loss: 0.4009518027305603 2022-05-30 01:48:04.700941
Epoch:[ 48 1 ] loss: 0.40106528997421265 2022-05-30 01:48:05.562069
Epoch:[ 48 2 ] loss: 0.4030137360095978 2022-05-30 01:48:06.376633
Epoch:[ 48 3 ] loss: 0.4016609191894531 2022-05-30 01:48:07.154375
Epoch:[ 48 4 ] loss: 0.3982027471065521 2022-05-30 01:48:07.933184
Epoch:[ 48 5 ] loss: 0.40390852093696594 2022-05-30 01:48:08.708958
Epoch:[ 48 6 ] loss: 0.40403154492378235 2022-05-30 01:48:09.485992
Epoch:[ 48 7 ] loss: 0.39919939637184143 2022-05-30 01:48:10.262305
Epoch:[ 48 8 ] loss: 0.40028589963912964 2022-05-30 01:48:11.040476
Epoch:[ 48 9 ] loss: 0.40121734142303467 2022-05-30 01:48:11.816937
Epoch:[ 48 10 ] loss: 0.40240150690078735 2022-05-30 01:48:12.594833
Epoch:[ 48 11 ] loss: 0.40541213750839233 2022-05-30 01:48:13.373621
Epoch:[ 48 12 ] loss: 0.4019496440887451 2022-05-30 01:48:14.151542
Epoch:[ 48 13 ] loss: 0.4004913866519928 2022-05-30 01:48:14.928936
Epoch:[ 48 14 ] loss: 0.4030149579048157 2022-05-30 01:48:15.705306
Epoch:[ 48 15 ] loss: 0.40014883875846863 2022-05-30 01:48:16.481517
Epoch:[ 48 16 ] loss: 0.4048093259334564 2022-05-30 01:48:24.472561
Epoch:[ 48 17 ] loss: 0.401720255613327 2022-05-30 01:48:25.287203
Epoch:[ 48 18 ] loss: 0.3976242244243622 2022-05-30 01:48:26.066934
Epoch:[ 48 19 ] loss: 0.39892905950546265 2022-05-30 01:48:26.843192
Training_Epoch:[ 48 ] Training_loss: 0.401501926779747 2022-05-30 01:48:26.843915
learning rate:  0.0020480000000000003
netparams have been saved once 48
val: 1 0.44085201621055603
val: 2 0.4385014772415161
val: 3 0.4414615333080292
val: 4 0.43583863973617554
val: 5 0.4460057020187378
val: 6 0.4316117465496063
val: 7 0.41976386308670044
val: 8 0.44100967049598694
val: 9 0.43425506353378296
val: 10 0.42932164669036865
val: 11 0.4314554035663605
val: 12 0.43495142459869385
val: 13 0.4278046190738678
val: 14 0.44209229946136475
val: 15 0.43802833557128906
val: 16 0.4289312958717346
val: 17 0.43119338154792786
val: 18 0.4262141287326813
val: 19 0.43088796734809875
val: 20 0.43408459424972534
val_Epoch:[ 48 ] val_loss: 0.4342132404446602 2022-05-30 01:48:32.378746
start training 2022-05-30 01:48:32.477054
Epoch:[ 49 0 ] loss: 0.39982983469963074 2022-05-30 01:48:54.992177
Epoch:[ 49 1 ] loss: 0.3974737823009491 2022-05-30 01:48:55.768593
Epoch:[ 49 2 ] loss: 0.4008224606513977 2022-05-30 01:48:56.576953
Epoch:[ 49 3 ] loss: 0.3962286412715912 2022-05-30 01:48:57.352923
Epoch:[ 49 4 ] loss: 0.39840540289878845 2022-05-30 01:48:58.131173
Epoch:[ 49 5 ] loss: 0.39719486236572266 2022-05-30 01:48:58.907995
Epoch:[ 49 6 ] loss: 0.3995809853076935 2022-05-30 01:48:59.685263
Epoch:[ 49 7 ] loss: 0.3999044597148895 2022-05-30 01:49:00.460134
Epoch:[ 49 8 ] loss: 0.3972073197364807 2022-05-30 01:49:01.234658
Epoch:[ 49 9 ] loss: 0.398196280002594 2022-05-30 01:49:02.012271
Epoch:[ 49 10 ] loss: 0.399127334356308 2022-05-30 01:49:02.786250
Epoch:[ 49 11 ] loss: 0.4025636613368988 2022-05-30 01:49:03.566053
Epoch:[ 49 12 ] loss: 0.3989213705062866 2022-05-30 01:49:04.343596
Epoch:[ 49 13 ] loss: 0.4009563624858856 2022-05-30 01:49:05.120531
Epoch:[ 49 14 ] loss: 0.404450386762619 2022-05-30 01:49:05.897943
Epoch:[ 49 15 ] loss: 0.3996027708053589 2022-05-30 01:49:06.673956
Epoch:[ 49 16 ] loss: 0.3994612991809845 2022-05-30 01:49:14.665724
Epoch:[ 49 17 ] loss: 0.40261703729629517 2022-05-30 01:49:15.439073
Epoch:[ 49 18 ] loss: 0.3993751108646393 2022-05-30 01:49:16.231733
Epoch:[ 49 19 ] loss: 0.3997920751571655 2022-05-30 01:49:17.010935
Training_Epoch:[ 49 ] Training_loss: 0.39958557188510896 2022-05-30 01:49:17.011613
learning rate:  0.0020480000000000003
val: 1 0.44563058018684387
val: 2 0.44264012575149536
val: 3 0.4208880364894867
val: 4 0.4340853691101074
val: 5 0.4492437243461609
val: 6 0.4235156774520874
val: 7 0.4347516894340515
val: 8 0.4378482699394226
val: 9 0.4268142580986023
val: 10 0.4310683310031891
val: 11 0.43923449516296387
val: 12 0.43726402521133423
val: 13 0.4361421763896942
val: 14 0.4369732439517975
val: 15 0.43633052706718445
val: 16 0.42589351534843445
val: 17 0.43229007720947266
val: 18 0.43341001868247986
val: 19 0.43716737627983093
val: 20 0.41970095038414
val_Epoch:[ 49 ] val_loss: 0.434044623374939 2022-05-30 01:49:22.387613
start training 2022-05-30 01:49:22.486851
Epoch:[ 50 0 ] loss: 0.3955223858356476 2022-05-30 01:49:46.623382
Epoch:[ 50 1 ] loss: 0.3949793577194214 2022-05-30 01:49:47.399041
Epoch:[ 50 2 ] loss: 0.4002337157726288 2022-05-30 01:49:48.174892
Epoch:[ 50 3 ] loss: 0.3974027633666992 2022-05-30 01:49:48.952197
Epoch:[ 50 4 ] loss: 0.3956407904624939 2022-05-30 01:49:49.727660
Epoch:[ 50 5 ] loss: 0.39945292472839355 2022-05-30 01:49:50.507369
Epoch:[ 50 6 ] loss: 0.40040796995162964 2022-05-30 01:49:51.286321
Epoch:[ 50 7 ] loss: 0.3992858827114105 2022-05-30 01:49:52.061911
Epoch:[ 50 8 ] loss: 0.40236905217170715 2022-05-30 01:49:52.840429
Epoch:[ 50 9 ] loss: 0.39751625061035156 2022-05-30 01:49:53.616774
Epoch:[ 50 10 ] loss: 0.4031350612640381 2022-05-30 01:49:54.392186
Epoch:[ 50 11 ] loss: 0.40209102630615234 2022-05-30 01:49:55.167900
Epoch:[ 50 12 ] loss: 0.39791762828826904 2022-05-30 01:49:55.947657
Epoch:[ 50 13 ] loss: 0.3996654748916626 2022-05-30 01:49:56.726497
Epoch:[ 50 14 ] loss: 0.3997337520122528 2022-05-30 01:49:57.504452
Epoch:[ 50 15 ] loss: 0.40005049109458923 2022-05-30 01:49:58.281322
Epoch:[ 50 16 ] loss: 0.4013689458370209 2022-05-30 01:50:05.899974
Epoch:[ 50 17 ] loss: 0.3978499174118042 2022-05-30 01:50:06.676944
Epoch:[ 50 18 ] loss: 0.40194886922836304 2022-05-30 01:50:07.455531
Epoch:[ 50 19 ] loss: 0.40027177333831787 2022-05-30 01:50:08.233559
Training_Epoch:[ 50 ] Training_loss: 0.39934220165014267 2022-05-30 01:50:08.234350
learning rate:  0.0020480000000000003
netparams have been saved once 50
val: 1 0.43584123253822327
val: 2 0.4364447295665741
val: 3 0.44033917784690857
val: 4 0.4444601237773895
val: 5 0.4376052916049957
val: 6 0.4355038106441498
val: 7 0.4213073253631592
val: 8 0.4419344365596771
val: 9 0.42657163739204407
val: 10 0.4321199953556061
val: 11 0.44577857851982117
val: 12 0.44268491864204407
val: 13 0.43247371912002563
val: 14 0.4279417395591736
val: 15 0.4272822439670563
val: 16 0.448608934879303
val: 17 0.433830589056015
val: 18 0.42838531732559204
val: 19 0.432782381772995
val: 20 0.429642915725708
val_Epoch:[ 50 ] val_loss: 0.43507695496082305 2022-05-30 01:50:13.697317
start training 2022-05-30 01:50:13.790526
Epoch:[ 51 0 ] loss: 0.39753004908561707 2022-05-30 01:50:36.846378
Epoch:[ 51 1 ] loss: 0.397381991147995 2022-05-30 01:50:38.113769
Epoch:[ 51 2 ] loss: 0.3975560665130615 2022-05-30 01:50:38.892996
Epoch:[ 51 3 ] loss: 0.39611658453941345 2022-05-30 01:50:39.668140
Epoch:[ 51 4 ] loss: 0.39872458577156067 2022-05-30 01:50:40.443049
Epoch:[ 51 5 ] loss: 0.3958612382411957 2022-05-30 01:50:41.218676
Epoch:[ 51 6 ] loss: 0.39194390177726746 2022-05-30 01:50:41.997481
Epoch:[ 51 7 ] loss: 0.39541250467300415 2022-05-30 01:50:42.774877
Epoch:[ 51 8 ] loss: 0.39761948585510254 2022-05-30 01:50:43.555221
Epoch:[ 51 9 ] loss: 0.39616093039512634 2022-05-30 01:50:44.333314
Epoch:[ 51 10 ] loss: 0.39636629819869995 2022-05-30 01:50:45.109530
Epoch:[ 51 11 ] loss: 0.39681321382522583 2022-05-30 01:50:45.887093
Epoch:[ 51 12 ] loss: 0.397237092256546 2022-05-30 01:50:46.662194
Epoch:[ 51 13 ] loss: 0.39666861295700073 2022-05-30 01:50:47.441619
Epoch:[ 51 14 ] loss: 0.3965012729167938 2022-05-30 01:50:48.221309
Epoch:[ 51 15 ] loss: 0.39653781056404114 2022-05-30 01:50:49.000164
Epoch:[ 51 16 ] loss: 0.3975447714328766 2022-05-30 01:50:56.061913
Epoch:[ 51 17 ] loss: 0.3976577818393707 2022-05-30 01:50:57.397102
Epoch:[ 51 18 ] loss: 0.39986565709114075 2022-05-30 01:50:58.176962
Epoch:[ 51 19 ] loss: 0.3948197364807129 2022-05-30 01:50:58.952189
Training_Epoch:[ 51 ] Training_loss: 0.3967159792780876 2022-05-30 01:50:58.953131
learning rate:  0.0016384000000000004
val: 1 0.44030508399009705
val: 2 0.4339577555656433
val: 3 0.4232226610183716
val: 4 0.41670241951942444
val: 5 0.4517374634742737
val: 6 0.42669883370399475
val: 7 0.4361092746257782
val: 8 0.4312809705734253
val: 9 0.43496328592300415
val: 10 0.4327458441257477
val: 11 0.4396393597126007
val: 12 0.43241655826568604
val: 13 0.4319010376930237
val: 14 0.43981295824050903
val: 15 0.43283888697624207
val: 16 0.4366203844547272
val: 17 0.45416945219039917
val: 18 0.42571306228637695
val: 19 0.4336186349391937
val: 20 0.4471634030342102
val_Epoch:[ 51 ] val_loss: 0.43508086651563643 2022-05-30 01:51:04.431177
start training 2022-05-30 01:51:04.527087
Epoch:[ 52 0 ] loss: 0.3925861716270447 2022-05-30 01:51:27.396685
Epoch:[ 52 1 ] loss: 0.39333751797676086 2022-05-30 01:51:28.214218
Epoch:[ 52 2 ] loss: 0.39672014117240906 2022-05-30 01:51:29.022945
Epoch:[ 52 3 ] loss: 0.3944263160228729 2022-05-30 01:51:29.800362
Epoch:[ 52 4 ] loss: 0.3958076536655426 2022-05-30 01:51:30.575233
Epoch:[ 52 5 ] loss: 0.3945543169975281 2022-05-30 01:51:31.351133
Epoch:[ 52 6 ] loss: 0.3967493176460266 2022-05-30 01:51:32.124991
Epoch:[ 52 7 ] loss: 0.39524754881858826 2022-05-30 01:51:32.903393
Epoch:[ 52 8 ] loss: 0.392718106508255 2022-05-30 01:51:33.682440
Epoch:[ 52 9 ] loss: 0.3943745493888855 2022-05-30 01:51:34.457585
Epoch:[ 52 10 ] loss: 0.3967238962650299 2022-05-30 01:51:35.234600
Epoch:[ 52 11 ] loss: 0.396312952041626 2022-05-30 01:51:36.010799
Epoch:[ 52 12 ] loss: 0.39448413252830505 2022-05-30 01:51:36.789621
Epoch:[ 52 13 ] loss: 0.3982681632041931 2022-05-30 01:51:37.566299
Epoch:[ 52 14 ] loss: 0.393380343914032 2022-05-30 01:51:38.345257
Epoch:[ 52 15 ] loss: 0.39577344059944153 2022-05-30 01:51:39.123999
Epoch:[ 52 16 ] loss: 0.40039339661598206 2022-05-30 01:51:47.818258
Epoch:[ 52 17 ] loss: 0.3998122215270996 2022-05-30 01:51:48.595593
Epoch:[ 52 18 ] loss: 0.39578771591186523 2022-05-30 01:51:49.382926
Epoch:[ 52 19 ] loss: 0.39701005816459656 2022-05-30 01:51:50.163581
Training_Epoch:[ 52 ] Training_loss: 0.3957233980298042 2022-05-30 01:51:50.164554
learning rate:  0.0016384000000000004
netparams have been saved once 52
val: 1 0.4261440932750702
val: 2 0.4244631230831146
val: 3 0.4294768273830414
val: 4 0.4333617687225342
val: 5 0.4523731470108032
val: 6 0.4372616708278656
val: 7 0.4492955803871155
val: 8 0.42082780599594116
val: 9 0.4311065077781677
val: 10 0.43074578046798706
val: 11 0.44355762004852295
val: 12 0.4404813051223755
val: 13 0.44628390669822693
val: 14 0.42975082993507385
val: 15 0.4384825527667999
val: 16 0.44095250964164734
val: 17 0.4509449601173401
val: 18 0.44460099935531616
val: 19 0.4332486093044281
val: 20 0.4427036941051483
val_Epoch:[ 52 ] val_loss: 0.437303164601326 2022-05-30 01:51:55.845878
start training 2022-05-30 01:51:55.945801
Epoch:[ 53 0 ] loss: 0.39772146940231323 2022-05-30 01:52:20.200784
Epoch:[ 53 1 ] loss: 0.3958289623260498 2022-05-30 01:52:20.979102
Epoch:[ 53 2 ] loss: 0.3968398869037628 2022-05-30 01:52:21.759062
Epoch:[ 53 3 ] loss: 0.3929831385612488 2022-05-30 01:52:22.540467
Epoch:[ 53 4 ] loss: 0.39517372846603394 2022-05-30 01:52:23.321067
Epoch:[ 53 5 ] loss: 0.39359650015830994 2022-05-30 01:52:24.099445
Epoch:[ 53 6 ] loss: 0.39699435234069824 2022-05-30 01:52:24.880748
Epoch:[ 53 7 ] loss: 0.3960507810115814 2022-05-30 01:52:25.657833
Epoch:[ 53 8 ] loss: 0.3949253559112549 2022-05-30 01:52:26.438913
Epoch:[ 53 9 ] loss: 0.39867106080055237 2022-05-30 01:52:27.220755
Epoch:[ 53 10 ] loss: 0.39299115538597107 2022-05-30 01:52:28.000522
Epoch:[ 53 11 ] loss: 0.39484506845474243 2022-05-30 01:52:28.778228
Epoch:[ 53 12 ] loss: 0.3957716226577759 2022-05-30 01:52:29.554646
Epoch:[ 53 13 ] loss: 0.39952901005744934 2022-05-30 01:52:30.333682
Epoch:[ 53 14 ] loss: 0.39493775367736816 2022-05-30 01:52:31.110987
Epoch:[ 53 15 ] loss: 0.3939315676689148 2022-05-30 01:52:31.891548
Epoch:[ 53 16 ] loss: 0.39372190833091736 2022-05-30 01:52:39.127573
Epoch:[ 53 17 ] loss: 0.39584267139434814 2022-05-30 01:52:39.905818
Epoch:[ 53 18 ] loss: 0.3945724666118622 2022-05-30 01:52:40.702344
Epoch:[ 53 19 ] loss: 0.39402204751968384 2022-05-30 01:52:41.478648
Training_Epoch:[ 53 ] Training_loss: 0.3954475253820419 2022-05-30 01:52:41.479753
learning rate:  0.0016384000000000004
val: 1 0.4423568844795227
val: 2 0.43383970856666565
val: 3 0.4283444881439209
val: 4 0.43157994747161865
val: 5 0.43590763211250305
val: 6 0.44092750549316406
val: 7 0.43177229166030884
val: 8 0.42677760124206543
val: 9 0.4352520704269409
val: 10 0.441499799489975
val: 11 0.4297679364681244
val: 12 0.43134334683418274
val: 13 0.4341714382171631
val: 14 0.43378832936286926
val: 15 0.4360065758228302
val: 16 0.43605276942253113
val: 17 0.4361485242843628
val: 18 0.44101932644844055
val: 19 0.43947547674179077
val: 20 0.4442952573299408
val_Epoch:[ 53 ] val_loss: 0.43551634550094603 2022-05-30 01:52:46.841848
start training 2022-05-30 01:52:46.941395
Epoch:[ 54 0 ] loss: 0.39325910806655884 2022-05-30 01:53:11.432738
Epoch:[ 54 1 ] loss: 0.39515450596809387 2022-05-30 01:53:12.208400
Epoch:[ 54 2 ] loss: 0.3922056257724762 2022-05-30 01:53:12.986937
Epoch:[ 54 3 ] loss: 0.3930746018886566 2022-05-30 01:53:13.764768
Epoch:[ 54 4 ] loss: 0.393169105052948 2022-05-30 01:53:14.545020
Epoch:[ 54 5 ] loss: 0.39483723044395447 2022-05-30 01:53:15.323485
Epoch:[ 54 6 ] loss: 0.3939673602581024 2022-05-30 01:53:16.102215
Epoch:[ 54 7 ] loss: 0.3932134509086609 2022-05-30 01:53:16.882488
Epoch:[ 54 8 ] loss: 0.3962627649307251 2022-05-30 01:53:17.659025
Epoch:[ 54 9 ] loss: 0.3951025903224945 2022-05-30 01:53:18.438573
Epoch:[ 54 10 ] loss: 0.39599424600601196 2022-05-30 01:53:19.219881
Epoch:[ 54 11 ] loss: 0.39302322268486023 2022-05-30 01:53:19.998148
Epoch:[ 54 12 ] loss: 0.3936461806297302 2022-05-30 01:53:20.776178
Epoch:[ 54 13 ] loss: 0.3953953683376312 2022-05-30 01:53:21.552513
Epoch:[ 54 14 ] loss: 0.39549824595451355 2022-05-30 01:53:22.330945
Epoch:[ 54 15 ] loss: 0.3917555510997772 2022-05-30 01:53:23.106978
Epoch:[ 54 16 ] loss: 0.3947792053222656 2022-05-30 01:53:30.799167
Epoch:[ 54 17 ] loss: 0.3932724893093109 2022-05-30 01:53:31.580929
Epoch:[ 54 18 ] loss: 0.39446815848350525 2022-05-30 01:53:32.360750
Epoch:[ 54 19 ] loss: 0.39162570238113403 2022-05-30 01:53:33.139273
Training_Epoch:[ 54 ] Training_loss: 0.3939852356910706 2022-05-30 01:53:33.140130
learning rate:  0.0016384000000000004
netparams have been saved once 54
val: 1 0.4455113112926483
val: 2 0.42814406752586365
val: 3 0.4382537305355072
val: 4 0.4365496337413788
val: 5 0.42319735884666443
val: 6 0.44680845737457275
val: 7 0.44486916065216064
val: 8 0.4369759261608124
val: 9 0.43572723865509033
val: 10 0.4347061812877655
val: 11 0.4271693825721741
val: 12 0.4249710738658905
val: 13 0.443831205368042
val: 14 0.43710118532180786
val: 15 0.4289296567440033
val: 16 0.4414171874523163
val: 17 0.43458789587020874
val: 18 0.4327738583087921
val: 19 0.4391145706176758
val: 20 0.41214653849601746
val_Epoch:[ 54 ] val_loss: 0.4346392810344696 2022-05-30 01:53:38.737522
start training 2022-05-30 01:53:38.837007
Epoch:[ 55 0 ] loss: 0.39239218831062317 2022-05-30 01:54:03.270665
Epoch:[ 55 1 ] loss: 0.3935580551624298 2022-05-30 01:54:04.046735
Epoch:[ 55 2 ] loss: 0.39419248700141907 2022-05-30 01:54:04.821886
Epoch:[ 55 3 ] loss: 0.39429771900177 2022-05-30 01:54:05.600737
Epoch:[ 55 4 ] loss: 0.3910204768180847 2022-05-30 01:54:06.379734
Epoch:[ 55 5 ] loss: 0.3912212550640106 2022-05-30 01:54:07.156104
Epoch:[ 55 6 ] loss: 0.39834845066070557 2022-05-30 01:54:07.935265
Epoch:[ 55 7 ] loss: 0.39354708790779114 2022-05-30 01:54:08.710081
Epoch:[ 55 8 ] loss: 0.3942508101463318 2022-05-30 01:54:09.487313
Epoch:[ 55 9 ] loss: 0.3935973346233368 2022-05-30 01:54:10.262005
Epoch:[ 55 10 ] loss: 0.3893451690673828 2022-05-30 01:54:11.042034
Epoch:[ 55 11 ] loss: 0.3973981738090515 2022-05-30 01:54:11.819472
Epoch:[ 55 12 ] loss: 0.3948976993560791 2022-05-30 01:54:12.597380
Epoch:[ 55 13 ] loss: 0.3943871259689331 2022-05-30 01:54:13.372885
Epoch:[ 55 14 ] loss: 0.3953911364078522 2022-05-30 01:54:14.146883
Epoch:[ 55 15 ] loss: 0.3941347301006317 2022-05-30 01:54:14.923466
Epoch:[ 55 16 ] loss: 0.39543426036834717 2022-05-30 01:54:22.314453
Epoch:[ 55 17 ] loss: 0.39578646421432495 2022-05-30 01:54:23.091524
Epoch:[ 55 18 ] loss: 0.3978152871131897 2022-05-30 01:54:23.874492
Epoch:[ 55 19 ] loss: 0.39705440402030945 2022-05-30 01:54:24.650377
Training_Epoch:[ 55 ] Training_loss: 0.3944035157561302 2022-05-30 01:54:24.651079
learning rate:  0.0016384000000000004
val: 1 0.42658552527427673
val: 2 0.4545586109161377
val: 3 0.42834529280662537
val: 4 0.45090362429618835
val: 5 0.4355866312980652
val: 6 0.43399256467819214
val: 7 0.44332194328308105
val: 8 0.4312607944011688
val: 9 0.43123745918273926
val: 10 0.4364108145236969
val: 11 0.43639716506004333
val: 12 0.43477046489715576
val: 13 0.435896098613739
val: 14 0.42778292298316956
val: 15 0.42748773097991943
val: 16 0.44016122817993164
val: 17 0.4278879165649414
val: 18 0.4251555800437927
val: 19 0.4430142343044281
val: 20 0.42829445004463196
val_Epoch:[ 55 ] val_loss: 0.4349525526165962 2022-05-30 01:54:30.115691
start training 2022-05-30 01:54:30.215116
Epoch:[ 56 0 ] loss: 0.39574211835861206 2022-05-30 01:54:53.515639
Epoch:[ 56 1 ] loss: 0.39661604166030884 2022-05-30 01:54:54.563078
Epoch:[ 56 2 ] loss: 0.39197349548339844 2022-05-30 01:54:55.340286
Epoch:[ 56 3 ] loss: 0.3927196264266968 2022-05-30 01:54:56.113523
Epoch:[ 56 4 ] loss: 0.3921458125114441 2022-05-30 01:54:56.891815
Epoch:[ 56 5 ] loss: 0.38958311080932617 2022-05-30 01:54:57.669943
Epoch:[ 56 6 ] loss: 0.3925411105155945 2022-05-30 01:54:58.446050
Epoch:[ 56 7 ] loss: 0.3896948993206024 2022-05-30 01:54:59.224455
Epoch:[ 56 8 ] loss: 0.3930265009403229 2022-05-30 01:55:00.000126
Epoch:[ 56 9 ] loss: 0.39383965730667114 2022-05-30 01:55:00.776747
Epoch:[ 56 10 ] loss: 0.3935597538948059 2022-05-30 01:55:01.550821
Epoch:[ 56 11 ] loss: 0.3955191373825073 2022-05-30 01:55:02.327433
Epoch:[ 56 12 ] loss: 0.392457515001297 2022-05-30 01:55:03.103568
Epoch:[ 56 13 ] loss: 0.3971247375011444 2022-05-30 01:55:03.881362
Epoch:[ 56 14 ] loss: 0.39695000648498535 2022-05-30 01:55:04.657511
Epoch:[ 56 15 ] loss: 0.39469802379608154 2022-05-30 01:55:05.432281
Epoch:[ 56 16 ] loss: 0.3971792757511139 2022-05-30 01:55:13.176594
Epoch:[ 56 17 ] loss: 0.3990829885005951 2022-05-30 01:55:13.950823
Epoch:[ 56 18 ] loss: 0.3939324915409088 2022-05-30 01:55:14.731869
Epoch:[ 56 19 ] loss: 0.3938181698322296 2022-05-30 01:55:15.509324
Training_Epoch:[ 56 ] Training_loss: 0.3941102236509323 2022-05-30 01:55:15.510015
learning rate:  0.0016384000000000004
netparams have been saved once 56
val: 1 0.44696488976478577
val: 2 0.42766907811164856
val: 3 0.4354838728904724
val: 4 0.4397207200527191
val: 5 0.4432804584503174
val: 6 0.43217816948890686
val: 7 0.43478623032569885
val: 8 0.42850354313850403
val: 9 0.44150418043136597
val: 10 0.4420691132545471
val: 11 0.43196040391921997
val: 12 0.4418608546257019
val: 13 0.43261605501174927
val: 14 0.4311508536338806
val: 15 0.43444475531578064
val: 16 0.43535110354423523
val: 17 0.43507668375968933
val: 18 0.4294692277908325
val: 19 0.43519851565361023
val: 20 0.4367595911026001
val_Epoch:[ 56 ] val_loss: 0.4358024150133133 2022-05-30 01:55:20.907450
start training 2022-05-30 01:55:21.007229
Epoch:[ 57 0 ] loss: 0.3950372636318207 2022-05-30 01:55:43.689081
Epoch:[ 57 1 ] loss: 0.39076656103134155 2022-05-30 01:55:44.520784
Epoch:[ 57 2 ] loss: 0.39466503262519836 2022-05-30 01:55:45.347114
Epoch:[ 57 3 ] loss: 0.3899320960044861 2022-05-30 01:55:46.123529
Epoch:[ 57 4 ] loss: 0.3927929103374481 2022-05-30 01:55:46.898802
Epoch:[ 57 5 ] loss: 0.3945012092590332 2022-05-30 01:55:47.676580
Epoch:[ 57 6 ] loss: 0.3947007358074188 2022-05-30 01:55:48.455569
Epoch:[ 57 7 ] loss: 0.39489370584487915 2022-05-30 01:55:49.235403
Epoch:[ 57 8 ] loss: 0.39206215739250183 2022-05-30 01:55:50.013774
Epoch:[ 57 9 ] loss: 0.39239388704299927 2022-05-30 01:55:50.791496
Epoch:[ 57 10 ] loss: 0.39320072531700134 2022-05-30 01:55:51.567577
Epoch:[ 57 11 ] loss: 0.3942515254020691 2022-05-30 01:55:52.342198
Epoch:[ 57 12 ] loss: 0.39209696650505066 2022-05-30 01:55:53.121236
Epoch:[ 57 13 ] loss: 0.3905072510242462 2022-05-30 01:55:53.900499
Epoch:[ 57 14 ] loss: 0.3929772973060608 2022-05-30 01:55:54.680878
Epoch:[ 57 15 ] loss: 0.39361730217933655 2022-05-30 01:55:55.460530
Epoch:[ 57 16 ] loss: 0.39251068234443665 2022-05-30 01:56:03.476106
Epoch:[ 57 17 ] loss: 0.39375507831573486 2022-05-30 01:56:04.253361
Epoch:[ 57 18 ] loss: 0.3948172628879547 2022-05-30 01:56:05.032639
Epoch:[ 57 19 ] loss: 0.3956605792045593 2022-05-30 01:56:05.810035
Training_Epoch:[ 57 ] Training_loss: 0.3932570114731789 2022-05-30 01:56:05.810730
learning rate:  0.0016384000000000004
val: 1 0.4406507611274719
val: 2 0.437746524810791
val: 3 0.42946815490722656
val: 4 0.4419153928756714
val: 5 0.44525203108787537
val: 6 0.4369122087955475
val: 7 0.43534958362579346
val: 8 0.4301983118057251
val: 9 0.44296807050704956
val: 10 0.4283084571361542
val: 11 0.43719482421875
val: 12 0.4361037313938141
val: 13 0.43327876925468445
val: 14 0.42691582441329956
val: 15 0.44245943427085876
val: 16 0.4342404305934906
val: 17 0.421782523393631
val: 18 0.426443487405777
val: 19 0.4481985569000244
val: 20 0.4426719844341278
val_Epoch:[ 57 ] val_loss: 0.4359029531478882 2022-05-30 01:56:11.161316
start training 2022-05-30 01:56:11.257097
Epoch:[ 58 0 ] loss: 0.390135258436203 2022-05-30 01:56:33.792944
Epoch:[ 58 1 ] loss: 0.3918510973453522 2022-05-30 01:56:35.334543
Epoch:[ 58 2 ] loss: 0.3901134133338928 2022-05-30 01:56:36.112109
Epoch:[ 58 3 ] loss: 0.3920153081417084 2022-05-30 01:56:36.886278
Epoch:[ 58 4 ] loss: 0.38846489787101746 2022-05-30 01:56:37.664211
Epoch:[ 58 5 ] loss: 0.39257287979125977 2022-05-30 01:56:38.439479
Epoch:[ 58 6 ] loss: 0.39076563715934753 2022-05-30 01:56:39.218279
Epoch:[ 58 7 ] loss: 0.3933110237121582 2022-05-30 01:56:39.997038
Epoch:[ 58 8 ] loss: 0.3904076814651489 2022-05-30 01:56:40.772204
Epoch:[ 58 9 ] loss: 0.39382752776145935 2022-05-30 01:56:41.548174
Epoch:[ 58 10 ] loss: 0.392060786485672 2022-05-30 01:56:42.323850
Epoch:[ 58 11 ] loss: 0.3938673734664917 2022-05-30 01:56:43.101387
Epoch:[ 58 12 ] loss: 0.3933916985988617 2022-05-30 01:56:43.876075
Epoch:[ 58 13 ] loss: 0.3953326642513275 2022-05-30 01:56:44.652986
Epoch:[ 58 14 ] loss: 0.3945647180080414 2022-05-30 01:56:45.430855
Epoch:[ 58 15 ] loss: 0.3931378424167633 2022-05-30 01:56:46.208526
Epoch:[ 58 16 ] loss: 0.3946913778781891 2022-05-30 01:56:53.120011
Epoch:[ 58 17 ] loss: 0.3928867280483246 2022-05-30 01:56:54.686622
Epoch:[ 58 18 ] loss: 0.3931458592414856 2022-05-30 01:56:55.468089
Epoch:[ 58 19 ] loss: 0.39094576239585876 2022-05-30 01:56:56.241646
Training_Epoch:[ 58 ] Training_loss: 0.39237447679042814 2022-05-30 01:56:56.242277
learning rate:  0.0016384000000000004
netparams have been saved once 58
val: 1 0.44637784361839294
val: 2 0.43677768111228943
val: 3 0.4383489787578583
val: 4 0.43802425265312195
val: 5 0.4394785165786743
val: 6 0.4303106665611267
val: 7 0.42699241638183594
val: 8 0.45064684748649597
val: 9 0.4307490587234497
val: 10 0.42621910572052
val: 11 0.4343595504760742
val: 12 0.4349885582923889
val: 13 0.4361097812652588
val: 14 0.43124520778656006
val: 15 0.4445568919181824
val: 16 0.4458314776420593
val: 17 0.43550774455070496
val: 18 0.43194976449012756
val: 19 0.4267089068889618
val: 20 0.4260523319244385
val_Epoch:[ 58 ] val_loss: 0.4355617791414261 2022-05-30 01:57:01.871228
start training 2022-05-30 01:57:01.972258
Epoch:[ 59 0 ] loss: 0.3907221555709839 2022-05-30 01:57:26.096324
Epoch:[ 59 1 ] loss: 0.38823428750038147 2022-05-30 01:57:26.873893
Epoch:[ 59 2 ] loss: 0.39214953780174255 2022-05-30 01:57:27.649713
Epoch:[ 59 3 ] loss: 0.38888368010520935 2022-05-30 01:57:28.427065
Epoch:[ 59 4 ] loss: 0.3904835283756256 2022-05-30 01:57:29.201166
Epoch:[ 59 5 ] loss: 0.39203789830207825 2022-05-30 01:57:29.978143
Epoch:[ 59 6 ] loss: 0.390826553106308 2022-05-30 01:57:30.753656
Epoch:[ 59 7 ] loss: 0.39330247044563293 2022-05-30 01:57:31.532740
Epoch:[ 59 8 ] loss: 0.39060166478157043 2022-05-30 01:57:32.310087
Epoch:[ 59 9 ] loss: 0.3902665078639984 2022-05-30 01:57:33.088509
Epoch:[ 59 10 ] loss: 0.3908151090145111 2022-05-30 01:57:33.864759
Epoch:[ 59 11 ] loss: 0.392436683177948 2022-05-30 01:57:34.639937
Epoch:[ 59 12 ] loss: 0.38918182253837585 2022-05-30 01:57:35.416843
Epoch:[ 59 13 ] loss: 0.3916245400905609 2022-05-30 01:57:36.192262
Epoch:[ 59 14 ] loss: 0.39041030406951904 2022-05-30 01:57:36.970487
Epoch:[ 59 15 ] loss: 0.3918503224849701 2022-05-30 01:57:37.747918
Epoch:[ 59 16 ] loss: 0.39096635580062866 2022-05-30 01:57:45.648906
Epoch:[ 59 17 ] loss: 0.3925107419490814 2022-05-30 01:57:46.426153
Epoch:[ 59 18 ] loss: 0.3900066614151001 2022-05-30 01:57:47.217658
Epoch:[ 59 19 ] loss: 0.3922102749347687 2022-05-30 01:57:47.995182
Training_Epoch:[ 59 ] Training_loss: 0.3909760549664497 2022-05-30 01:57:47.995930
learning rate:  0.0016384000000000004
val: 1 0.43722406029701233
val: 2 0.45500504970550537
val: 3 0.44506481289863586
val: 4 0.44887858629226685
val: 5 0.43725115060806274
val: 6 0.44058752059936523
val: 7 0.4360462427139282
val: 8 0.4287993609905243
val: 9 0.443202942609787
val: 10 0.4315240681171417
val: 11 0.4387850761413574
val: 12 0.43758633732795715
val: 13 0.4377461075782776
val: 14 0.4491877257823944
val: 15 0.43675312399864197
val: 16 0.44471123814582825
val: 17 0.44209161400794983
val: 18 0.43550869822502136
val: 19 0.43744468688964844
val: 20 0.44798699021339417
val_Epoch:[ 59 ] val_loss: 0.440569269657135 2022-05-30 01:57:53.293388
start training 2022-05-30 01:57:53.396458
Epoch:[ 60 0 ] loss: 0.38781097531318665 2022-05-30 01:58:16.956015
Epoch:[ 60 1 ] loss: 0.3891441226005554 2022-05-30 01:58:17.783410
Epoch:[ 60 2 ] loss: 0.3941483795642853 2022-05-30 01:58:18.561215
Epoch:[ 60 3 ] loss: 0.3901780843734741 2022-05-30 01:58:19.339645
Epoch:[ 60 4 ] loss: 0.3863646388053894 2022-05-30 01:58:20.115306
Epoch:[ 60 5 ] loss: 0.38720184564590454 2022-05-30 01:58:20.892803
Epoch:[ 60 6 ] loss: 0.3901688754558563 2022-05-30 01:58:21.668306
Epoch:[ 60 7 ] loss: 0.3888876736164093 2022-05-30 01:58:22.445699
Epoch:[ 60 8 ] loss: 0.3914622962474823 2022-05-30 01:58:23.224369
Epoch:[ 60 9 ] loss: 0.391236275434494 2022-05-30 01:58:24.002504
Epoch:[ 60 10 ] loss: 0.38990095257759094 2022-05-30 01:58:24.780533
Epoch:[ 60 11 ] loss: 0.3894175887107849 2022-05-30 01:58:25.556763
Epoch:[ 60 12 ] loss: 0.38852939009666443 2022-05-30 01:58:26.333033
Epoch:[ 60 13 ] loss: 0.38794413208961487 2022-05-30 01:58:27.112185
Epoch:[ 60 14 ] loss: 0.39070844650268555 2022-05-30 01:58:27.887545
Epoch:[ 60 15 ] loss: 0.39063483476638794 2022-05-30 01:58:28.665873
Epoch:[ 60 16 ] loss: 0.3926295042037964 2022-05-30 01:58:36.064956
Epoch:[ 60 17 ] loss: 0.3903915286064148 2022-05-30 01:58:36.840286
Epoch:[ 60 18 ] loss: 0.38943761587142944 2022-05-30 01:58:37.620677
Epoch:[ 60 19 ] loss: 0.39358437061309814 2022-05-30 01:58:38.396050
Training_Epoch:[ 60 ] Training_loss: 0.3899890765547752 2022-05-30 01:58:38.396703
learning rate:  0.0016384000000000004
netparams have been saved once 60
val: 1 0.4516580402851105
val: 2 0.43497005105018616
val: 3 0.4365863800048828
val: 4 0.4284822344779968
val: 5 0.44453561305999756
val: 6 0.4430678188800812
val: 7 0.447265625
val: 8 0.4462852478027344
val: 9 0.4325329661369324
val: 10 0.438590943813324
val: 11 0.4327176511287689
val: 12 0.4295075535774231
val: 13 0.4344342052936554
val: 14 0.4411821663379669
val: 15 0.44233793020248413
val: 16 0.43370112776756287
val: 17 0.44473081827163696
val: 18 0.43671852350234985
val: 19 0.43309858441352844
val: 20 0.4394264817237854
val_Epoch:[ 60 ] val_loss: 0.4385914981365204 2022-05-30 01:58:43.855555
start training 2022-05-30 01:58:43.950624
Epoch:[ 61 0 ] loss: 0.395929217338562 2022-05-30 01:59:06.635069
Epoch:[ 61 1 ] loss: 0.39026936888694763 2022-05-30 01:59:07.443146
Epoch:[ 61 2 ] loss: 0.38922592997550964 2022-05-30 01:59:08.220735
Epoch:[ 61 3 ] loss: 0.3917432725429535 2022-05-30 01:59:08.998505
Epoch:[ 61 4 ] loss: 0.39233607053756714 2022-05-30 01:59:09.777904
Epoch:[ 61 5 ] loss: 0.38918179273605347 2022-05-30 01:59:10.557428
Epoch:[ 61 6 ] loss: 0.3896197974681854 2022-05-30 01:59:11.331689
Epoch:[ 61 7 ] loss: 0.39156782627105713 2022-05-30 01:59:12.107303
Epoch:[ 61 8 ] loss: 0.38626930117607117 2022-05-30 01:59:12.883099
Epoch:[ 61 9 ] loss: 0.3875054121017456 2022-05-30 01:59:13.660930
Epoch:[ 61 10 ] loss: 0.38872694969177246 2022-05-30 01:59:14.441049
Epoch:[ 61 11 ] loss: 0.38794904947280884 2022-05-30 01:59:15.218290
Epoch:[ 61 12 ] loss: 0.3880568742752075 2022-05-30 01:59:15.997949
Epoch:[ 61 13 ] loss: 0.3887311518192291 2022-05-30 01:59:16.773935
Epoch:[ 61 14 ] loss: 0.389606237411499 2022-05-30 01:59:17.550873
Epoch:[ 61 15 ] loss: 0.389850378036499 2022-05-30 01:59:18.326355
Epoch:[ 61 16 ] loss: 0.3895072340965271 2022-05-30 01:59:25.883139
Epoch:[ 61 17 ] loss: 0.3890780806541443 2022-05-30 01:59:26.661921
Epoch:[ 61 18 ] loss: 0.3892105221748352 2022-05-30 01:59:27.442221
Epoch:[ 61 19 ] loss: 0.3881206810474396 2022-05-30 01:59:28.219731
Training_Epoch:[ 61 ] Training_loss: 0.38962425738573075 2022-05-30 01:59:28.220464
learning rate:  0.0013107200000000005
val: 1 0.4451022148132324
val: 2 0.4303767681121826
val: 3 0.4247693121433258
val: 4 0.4383086860179901
val: 5 0.4364238977432251
val: 6 0.43685051798820496
val: 7 0.4452987313270569
val: 8 0.44022372364997864
val: 9 0.4325244724750519
val: 10 0.43330779671669006
val: 11 0.42632660269737244
val: 12 0.428397536277771
val: 13 0.4328257441520691
val: 14 0.44496285915374756
val: 15 0.4336635172367096
val: 16 0.45081159472465515
val: 17 0.4220089912414551
val: 18 0.44239646196365356
val: 19 0.4503890573978424
val: 20 0.43919047713279724
val_Epoch:[ 61 ] val_loss: 0.4367079481482506 2022-05-30 01:59:33.572893
start training 2022-05-30 01:59:33.671491
Epoch:[ 62 0 ] loss: 0.3870123624801636 2022-05-30 01:59:57.001890
Epoch:[ 62 1 ] loss: 0.38775086402893066 2022-05-30 01:59:58.069703
Epoch:[ 62 2 ] loss: 0.3873802423477173 2022-05-30 01:59:58.844080
Epoch:[ 62 3 ] loss: 0.3886263072490692 2022-05-30 01:59:59.623290
Epoch:[ 62 4 ] loss: 0.3850390911102295 2022-05-30 02:00:00.399089
Epoch:[ 62 5 ] loss: 0.38979142904281616 2022-05-30 02:00:01.174395
Epoch:[ 62 6 ] loss: 0.39022669196128845 2022-05-30 02:00:01.951516
Epoch:[ 62 7 ] loss: 0.38936862349510193 2022-05-30 02:00:02.727640
Epoch:[ 62 8 ] loss: 0.3862873613834381 2022-05-30 02:00:03.505075
Epoch:[ 62 9 ] loss: 0.3907482326030731 2022-05-30 02:00:04.279110
Epoch:[ 62 10 ] loss: 0.38887137174606323 2022-05-30 02:00:05.057403
Epoch:[ 62 11 ] loss: 0.38570863008499146 2022-05-30 02:00:05.835813
Epoch:[ 62 12 ] loss: 0.3890922963619232 2022-05-30 02:00:06.612863
Epoch:[ 62 13 ] loss: 0.3847157657146454 2022-05-30 02:00:07.388850
Epoch:[ 62 14 ] loss: 0.3903225362300873 2022-05-30 02:00:08.165132
Epoch:[ 62 15 ] loss: 0.38705354928970337 2022-05-30 02:00:08.941039
Epoch:[ 62 16 ] loss: 0.3879718780517578 2022-05-30 02:00:15.938552
Epoch:[ 62 17 ] loss: 0.3877222537994385 2022-05-30 02:00:17.713042
Epoch:[ 62 18 ] loss: 0.39306655526161194 2022-05-30 02:00:18.494541
Epoch:[ 62 19 ] loss: 0.38724926114082336 2022-05-30 02:00:19.273044
Training_Epoch:[ 62 ] Training_loss: 0.3882002651691437 2022-05-30 02:00:19.273735
learning rate:  0.0013107200000000005
netparams have been saved once 62
val: 1 0.4362369179725647
val: 2 0.4404931366443634
val: 3 0.43392133712768555
val: 4 0.44385579228401184
val: 5 0.4392054080963135
val: 6 0.43935102224349976
val: 7 0.4521154761314392
val: 8 0.42110002040863037
val: 9 0.4373292624950409
val: 10 0.4383748769760132
val: 11 0.42688342928886414
val: 12 0.4443065822124481
val: 13 0.4285053014755249
val: 14 0.4364842176437378
val: 15 0.43986669182777405
val: 16 0.4475301206111908
val: 17 0.4391717314720154
val: 18 0.44621312618255615
val: 19 0.4229743778705597
val: 20 0.4347628057003021
val_Epoch:[ 62 ] val_loss: 0.4374340817332268 2022-05-30 02:00:24.762175
start training 2022-05-30 02:00:24.862310
Epoch:[ 63 0 ] loss: 0.3862607777118683 2022-05-30 02:00:48.980184
Epoch:[ 63 1 ] loss: 0.38703322410583496 2022-05-30 02:00:49.754677
Epoch:[ 63 2 ] loss: 0.3869771957397461 2022-05-30 02:00:50.530519
Epoch:[ 63 3 ] loss: 0.3832803964614868 2022-05-30 02:00:51.304996
Epoch:[ 63 4 ] loss: 0.38299760222435 2022-05-30 02:00:52.086236
Epoch:[ 63 5 ] loss: 0.38494110107421875 2022-05-30 02:00:52.864962
Epoch:[ 63 6 ] loss: 0.38965317606925964 2022-05-30 02:00:53.641804
Epoch:[ 63 7 ] loss: 0.38738518953323364 2022-05-30 02:00:54.421022
Epoch:[ 63 8 ] loss: 0.3923278748989105 2022-05-30 02:00:55.197409
Epoch:[ 63 9 ] loss: 0.3882855176925659 2022-05-30 02:00:55.973709
Epoch:[ 63 10 ] loss: 0.38653162121772766 2022-05-30 02:00:56.748839
Epoch:[ 63 11 ] loss: 0.3874627351760864 2022-05-30 02:00:57.525126
Epoch:[ 63 12 ] loss: 0.38578492403030396 2022-05-30 02:00:58.305980
Epoch:[ 63 13 ] loss: 0.38850927352905273 2022-05-30 02:00:59.084473
Epoch:[ 63 14 ] loss: 0.38426148891448975 2022-05-30 02:00:59.860416
Epoch:[ 63 15 ] loss: 0.39175403118133545 2022-05-30 02:01:00.636138
Epoch:[ 63 16 ] loss: 0.3910316526889801 2022-05-30 02:01:08.246773
Epoch:[ 63 17 ] loss: 0.38727113604545593 2022-05-30 02:01:09.021193
Epoch:[ 63 18 ] loss: 0.38947927951812744 2022-05-30 02:01:09.802321
Epoch:[ 63 19 ] loss: 0.38698214292526245 2022-05-30 02:01:10.580944
Training_Epoch:[ 63 ] Training_loss: 0.3874105170369148 2022-05-30 02:01:10.581665
learning rate:  0.0013107200000000005
val: 1 0.44408851861953735
val: 2 0.44501811265945435
val: 3 0.4375167489051819
val: 4 0.44133543968200684
val: 5 0.439272940158844
val: 6 0.42749592661857605
val: 7 0.4313599765300751
val: 8 0.43414145708084106
val: 9 0.4316859245300293
val: 10 0.43321216106414795
val: 11 0.43264350295066833
val: 12 0.4430934488773346
val: 13 0.44625023007392883
val: 14 0.4371148645877838
val: 15 0.4483133554458618
val: 16 0.44586458802223206
val: 17 0.4363565146923065
val: 18 0.428497850894928
val: 19 0.4300318658351898
val: 20 0.43778693675994873
val_Epoch:[ 63 ] val_loss: 0.43755401819944384 2022-05-30 02:01:15.952212
start training 2022-05-30 02:01:16.047149
Epoch:[ 64 0 ] loss: 0.3832569122314453 2022-05-30 02:01:40.467982
Epoch:[ 64 1 ] loss: 0.3843532204627991 2022-05-30 02:01:41.247434
Epoch:[ 64 2 ] loss: 0.3874388039112091 2022-05-30 02:01:42.025735
Epoch:[ 64 3 ] loss: 0.38479092717170715 2022-05-30 02:01:42.802223
Epoch:[ 64 4 ] loss: 0.3827398419380188 2022-05-30 02:01:43.577083
Epoch:[ 64 5 ] loss: 0.3880273699760437 2022-05-30 02:01:44.354777
Epoch:[ 64 6 ] loss: 0.3905487060546875 2022-05-30 02:01:45.134001
Epoch:[ 64 7 ] loss: 0.3877521753311157 2022-05-30 02:01:45.910601
Epoch:[ 64 8 ] loss: 0.3891792595386505 2022-05-30 02:01:46.686497
Epoch:[ 64 9 ] loss: 0.3870563209056854 2022-05-30 02:01:47.461220
Epoch:[ 64 10 ] loss: 0.3914683759212494 2022-05-30 02:01:48.240328
Epoch:[ 64 11 ] loss: 0.3847687542438507 2022-05-30 02:01:49.015809
Epoch:[ 64 12 ] loss: 0.39042630791664124 2022-05-30 02:01:49.795076
Epoch:[ 64 13 ] loss: 0.38976770639419556 2022-05-30 02:01:50.574974
Epoch:[ 64 14 ] loss: 0.38906240463256836 2022-05-30 02:01:51.354511
Epoch:[ 64 15 ] loss: 0.3876160979270935 2022-05-30 02:01:52.131643
Epoch:[ 64 16 ] loss: 0.38661810755729675 2022-05-30 02:02:00.235641
Epoch:[ 64 17 ] loss: 0.38685551285743713 2022-05-30 02:02:01.011237
Epoch:[ 64 18 ] loss: 0.3876667618751526 2022-05-30 02:02:01.788632
Epoch:[ 64 19 ] loss: 0.38781315088272095 2022-05-30 02:02:02.566173
Training_Epoch:[ 64 ] Training_loss: 0.38736033588647845 2022-05-30 02:02:02.566909
learning rate:  0.0013107200000000005
netparams have been saved once 64
val: 1 0.4450550973415375
val: 2 0.4342975318431854
val: 3 0.449190229177475
val: 4 0.44463831186294556
val: 5 0.4448385238647461
val: 6 0.44017598032951355
val: 7 0.4364526569843292
val: 8 0.4583553671836853
val: 9 0.4390554428100586
val: 10 0.439196914434433
val: 11 0.4277462363243103
val: 12 0.4465535879135132
val: 13 0.4451277554035187
val: 14 0.4204694330692291
val: 15 0.44080719351768494
val: 16 0.42053139209747314
val: 17 0.44620221853256226
val: 18 0.4372693598270416
val: 19 0.4331936240196228
val: 20 0.4451743960380554
val_Epoch:[ 64 ] val_loss: 0.43971656262874603 2022-05-30 02:02:08.055680
start training 2022-05-30 02:02:08.153607
Epoch:[ 65 0 ] loss: 0.38407614827156067 2022-05-30 02:02:31.609884
Epoch:[ 65 1 ] loss: 0.3852449357509613 2022-05-30 02:02:32.432669
Epoch:[ 65 2 ] loss: 0.39043715596199036 2022-05-30 02:02:33.211604
Epoch:[ 65 3 ] loss: 0.38802239298820496 2022-05-30 02:02:33.986621
Epoch:[ 65 4 ] loss: 0.3857662081718445 2022-05-30 02:02:34.762693
Epoch:[ 65 5 ] loss: 0.3877410590648651 2022-05-30 02:02:35.539006
Epoch:[ 65 6 ] loss: 0.38601601123809814 2022-05-30 02:02:36.317442
Epoch:[ 65 7 ] loss: 0.38450270891189575 2022-05-30 02:02:37.096312
Epoch:[ 65 8 ] loss: 0.3878311514854431 2022-05-30 02:02:37.875034
Epoch:[ 65 9 ] loss: 0.3865048289299011 2022-05-30 02:02:38.655142
Epoch:[ 65 10 ] loss: 0.3834897577762604 2022-05-30 02:02:39.432081
Epoch:[ 65 11 ] loss: 0.384745329618454 2022-05-30 02:02:40.207657
Epoch:[ 65 12 ] loss: 0.3877679109573364 2022-05-30 02:02:40.983119
Epoch:[ 65 13 ] loss: 0.3872603476047516 2022-05-30 02:02:41.761208
Epoch:[ 65 14 ] loss: 0.3848276436328888 2022-05-30 02:02:42.540943
Epoch:[ 65 15 ] loss: 0.38650786876678467 2022-05-30 02:02:43.318230
Epoch:[ 65 16 ] loss: 0.388152152299881 2022-05-30 02:02:50.596650
Epoch:[ 65 17 ] loss: 0.38620561361312866 2022-05-30 02:02:51.372108
Epoch:[ 65 18 ] loss: 0.38460347056388855 2022-05-30 02:02:52.152402
Epoch:[ 65 19 ] loss: 0.3858010172843933 2022-05-30 02:02:52.926704
Training_Epoch:[ 65 ] Training_loss: 0.3862751856446266 2022-05-30 02:02:52.927377
learning rate:  0.0013107200000000005
val: 1 0.4317503869533539
val: 2 0.4392921030521393
val: 3 0.4497010111808777
val: 4 0.4194791316986084
val: 5 0.42254096269607544
val: 6 0.4366450905799866
val: 7 0.43493545055389404
val: 8 0.4514763653278351
val: 9 0.4525042474269867
val: 10 0.4345760643482208
val: 11 0.43386057019233704
val: 12 0.44605934619903564
val: 13 0.44441407918930054
val: 14 0.44921189546585083
val: 15 0.4408681392669678
val: 16 0.44519492983818054
val: 17 0.44135501980781555
val: 18 0.4256945252418518
val: 19 0.4391409456729889
val: 20 0.45219331979751587
val_Epoch:[ 65 ] val_loss: 0.43954467922449114 2022-05-30 02:02:58.243763
start training 2022-05-30 02:02:58.340465
Epoch:[ 66 0 ] loss: 0.3866138160228729 2022-05-30 02:03:21.127165
Epoch:[ 66 1 ] loss: 0.3852780759334564 2022-05-30 02:03:23.064165
Epoch:[ 66 2 ] loss: 0.3889845907688141 2022-05-30 02:03:23.843064
Epoch:[ 66 3 ] loss: 0.38340824842453003 2022-05-30 02:03:24.619486
Epoch:[ 66 4 ] loss: 0.3835483193397522 2022-05-30 02:03:25.395993
Epoch:[ 66 5 ] loss: 0.3858487010002136 2022-05-30 02:03:26.170901
Epoch:[ 66 6 ] loss: 0.3875696361064911 2022-05-30 02:03:26.948023
Epoch:[ 66 7 ] loss: 0.38486766815185547 2022-05-30 02:03:27.727892
Epoch:[ 66 8 ] loss: 0.3824259340763092 2022-05-30 02:03:28.506743
Epoch:[ 66 9 ] loss: 0.3884904384613037 2022-05-30 02:03:29.284335
Epoch:[ 66 10 ] loss: 0.38439100980758667 2022-05-30 02:03:30.060267
Epoch:[ 66 11 ] loss: 0.38653817772865295 2022-05-30 02:03:30.836995
Epoch:[ 66 12 ] loss: 0.38492318987846375 2022-05-30 02:03:31.615096
Epoch:[ 66 13 ] loss: 0.3832489848136902 2022-05-30 02:03:32.389678
Epoch:[ 66 14 ] loss: 0.3891485333442688 2022-05-30 02:03:33.167512
Epoch:[ 66 15 ] loss: 0.38533517718315125 2022-05-30 02:03:33.945938
Epoch:[ 66 16 ] loss: 0.38759279251098633 2022-05-30 02:03:40.477523
Epoch:[ 66 17 ] loss: 0.384890079498291 2022-05-30 02:03:42.151385
Epoch:[ 66 18 ] loss: 0.3898625373840332 2022-05-30 02:03:42.930205
Epoch:[ 66 19 ] loss: 0.38673001527786255 2022-05-30 02:03:43.705436
Training_Epoch:[ 66 ] Training_loss: 0.38598479628562926 2022-05-30 02:03:43.706102
learning rate:  0.0013107200000000005
netparams have been saved once 66
val: 1 0.44146957993507385
val: 2 0.44570884108543396
val: 3 0.45562100410461426
val: 4 0.4297126829624176
val: 5 0.4366418123245239
val: 6 0.4333913028240204
val: 7 0.4322839677333832
val: 8 0.4333804249763489
val: 9 0.44069454073905945
val: 10 0.436423659324646
val: 11 0.4333592653274536
val: 12 0.4408565163612366
val: 13 0.4365496337413788
val: 14 0.43394899368286133
val: 15 0.4332444369792938
val: 16 0.43212154507637024
val: 17 0.43621599674224854
val: 18 0.44567298889160156
val: 19 0.44690242409706116
val: 20 0.4454858899116516
val_Epoch:[ 66 ] val_loss: 0.43848427534103396 2022-05-30 02:03:49.201329
start training 2022-05-30 02:03:49.299272
Epoch:[ 67 0 ] loss: 0.3835314214229584 2022-05-30 02:04:12.567240
Epoch:[ 67 1 ] loss: 0.383222371339798 2022-05-30 02:04:13.385137
Epoch:[ 67 2 ] loss: 0.3838232457637787 2022-05-30 02:04:14.164682
Epoch:[ 67 3 ] loss: 0.3843730390071869 2022-05-30 02:04:14.940372
Epoch:[ 67 4 ] loss: 0.38641342520713806 2022-05-30 02:04:15.718846
Epoch:[ 67 5 ] loss: 0.38339129090309143 2022-05-30 02:04:16.495029
Epoch:[ 67 6 ] loss: 0.38630855083465576 2022-05-30 02:04:17.269753
Epoch:[ 67 7 ] loss: 0.38523584604263306 2022-05-30 02:04:18.044227
Epoch:[ 67 8 ] loss: 0.38404580950737 2022-05-30 02:04:18.822685
Epoch:[ 67 9 ] loss: 0.38502374291419983 2022-05-30 02:04:19.601819
Epoch:[ 67 10 ] loss: 0.3890058696269989 2022-05-30 02:04:20.379732
Epoch:[ 67 11 ] loss: 0.3840671181678772 2022-05-30 02:04:21.156046
Epoch:[ 67 12 ] loss: 0.3861484229564667 2022-05-30 02:04:21.930786
Epoch:[ 67 13 ] loss: 0.38861921429634094 2022-05-30 02:04:22.707068
Epoch:[ 67 14 ] loss: 0.38737374544143677 2022-05-30 02:04:23.481821
Epoch:[ 67 15 ] loss: 0.38682425022125244 2022-05-30 02:04:24.257768
Epoch:[ 67 16 ] loss: 0.3877476453781128 2022-05-30 02:04:31.699771
Epoch:[ 67 17 ] loss: 0.385647714138031 2022-05-30 02:04:32.474712
Epoch:[ 67 18 ] loss: 0.3843354880809784 2022-05-30 02:04:33.253806
Epoch:[ 67 19 ] loss: 0.38346514105796814 2022-05-30 02:04:34.026233
Training_Epoch:[ 67 ] Training_loss: 0.38543016761541365 2022-05-30 02:04:34.026916
learning rate:  0.0013107200000000005
val: 1 0.4393048882484436
val: 2 0.4352419376373291
val: 3 0.4491967558860779
val: 4 0.4294218420982361
val: 5 0.4375292658805847
val: 6 0.4279839098453522
val: 7 0.4324016273021698
val: 8 0.4371589422225952
val: 9 0.451736181974411
val: 10 0.4308091700077057
val: 11 0.4281253218650818
val: 12 0.45938974618911743
val: 13 0.4460088312625885
val: 14 0.4407651424407959
val: 15 0.453134149312973
val: 16 0.42636269330978394
val: 17 0.42775702476501465
val: 18 0.4526256024837494
val: 19 0.44596362113952637
val: 20 0.45117324590682983
val_Epoch:[ 67 ] val_loss: 0.4401044949889183 2022-05-30 02:04:39.304708
start training 2022-05-30 02:04:39.406907
Epoch:[ 68 0 ] loss: 0.38412758708000183 2022-05-30 02:05:01.983495
Epoch:[ 68 1 ] loss: 0.3862030804157257 2022-05-30 02:05:02.775448
Epoch:[ 68 2 ] loss: 0.3832274377346039 2022-05-30 02:05:03.567495
Epoch:[ 68 3 ] loss: 0.383305162191391 2022-05-30 02:05:04.347100
Epoch:[ 68 4 ] loss: 0.3881216049194336 2022-05-30 02:05:05.124105
Epoch:[ 68 5 ] loss: 0.3825927972793579 2022-05-30 02:05:05.902006
Epoch:[ 68 6 ] loss: 0.38265201449394226 2022-05-30 02:05:06.677854
Epoch:[ 68 7 ] loss: 0.38667628169059753 2022-05-30 02:05:07.454557
Epoch:[ 68 8 ] loss: 0.3846223056316376 2022-05-30 02:05:08.230661
Epoch:[ 68 9 ] loss: 0.3853425979614258 2022-05-30 02:05:09.008938
Epoch:[ 68 10 ] loss: 0.3828642964363098 2022-05-30 02:05:09.786934
Epoch:[ 68 11 ] loss: 0.38319137692451477 2022-05-30 02:05:10.564498
Epoch:[ 68 12 ] loss: 0.3828413784503937 2022-05-30 02:05:11.340398
Epoch:[ 68 13 ] loss: 0.3828282654285431 2022-05-30 02:05:12.117134
Epoch:[ 68 14 ] loss: 0.38590437173843384 2022-05-30 02:05:12.893464
Epoch:[ 68 15 ] loss: 0.38370949029922485 2022-05-30 02:05:13.667244
Epoch:[ 68 16 ] loss: 0.386549711227417 2022-05-30 02:05:22.039304
Epoch:[ 68 17 ] loss: 0.3824369013309479 2022-05-30 02:05:22.817535
Epoch:[ 68 18 ] loss: 0.3847302794456482 2022-05-30 02:05:23.597464
Epoch:[ 68 19 ] loss: 0.3864508867263794 2022-05-30 02:05:24.373590
Training_Epoch:[ 68 ] Training_loss: 0.3844188913702965 2022-05-30 02:05:24.374266
learning rate:  0.0013107200000000005
netparams have been saved once 68
val: 1 0.46513697504997253
val: 2 0.4364572763442993
val: 3 0.4440195560455322
val: 4 0.4442676305770874
val: 5 0.43594279885292053
val: 6 0.4431227445602417
val: 7 0.43692582845687866
val: 8 0.4164225459098816
val: 9 0.44231122732162476
val: 10 0.4315481185913086
val: 11 0.4422075152397156
val: 12 0.44077199697494507
val: 13 0.43426600098609924
val: 14 0.45151716470718384
val: 15 0.4387444853782654
val: 16 0.43177270889282227
val: 17 0.44956833124160767
val: 18 0.4383409917354584
val: 19 0.44524773955345154
val: 20 0.4408585727214813
val_Epoch:[ 68 ] val_loss: 0.4404725104570389 2022-05-30 02:05:29.815737
start training 2022-05-30 02:05:29.915245
Epoch:[ 69 0 ] loss: 0.38502469658851624 2022-05-30 02:05:53.508670
Epoch:[ 69 1 ] loss: 0.3843361437320709 2022-05-30 02:05:54.285379
Epoch:[ 69 2 ] loss: 0.3849412798881531 2022-05-30 02:05:55.061110
Epoch:[ 69 3 ] loss: 0.38254398107528687 2022-05-30 02:05:55.840472
Epoch:[ 69 4 ] loss: 0.3851163685321808 2022-05-30 02:05:56.619211
Epoch:[ 69 5 ] loss: 0.3841715455055237 2022-05-30 02:05:57.396881
Epoch:[ 69 6 ] loss: 0.3837801516056061 2022-05-30 02:05:58.175049
Epoch:[ 69 7 ] loss: 0.38299137353897095 2022-05-30 02:05:58.949951
Epoch:[ 69 8 ] loss: 0.38432443141937256 2022-05-30 02:05:59.724184
Epoch:[ 69 9 ] loss: 0.3812146782875061 2022-05-30 02:06:00.499993
Epoch:[ 69 10 ] loss: 0.3859698474407196 2022-05-30 02:06:01.278090
Epoch:[ 69 11 ] loss: 0.38305118680000305 2022-05-30 02:06:02.056425
Epoch:[ 69 12 ] loss: 0.38387545943260193 2022-05-30 02:06:02.832971
Epoch:[ 69 13 ] loss: 0.3861647844314575 2022-05-30 02:06:03.607412
Epoch:[ 69 14 ] loss: 0.3880281150341034 2022-05-30 02:06:04.383399
Epoch:[ 69 15 ] loss: 0.38385018706321716 2022-05-30 02:06:05.160503
Epoch:[ 69 16 ] loss: 0.385947585105896 2022-05-30 02:06:12.504629
Epoch:[ 69 17 ] loss: 0.38351115584373474 2022-05-30 02:06:13.873988
Epoch:[ 69 18 ] loss: 0.38215869665145874 2022-05-30 02:06:14.668742
Epoch:[ 69 19 ] loss: 0.384790301322937 2022-05-30 02:06:15.444325
Training_Epoch:[ 69 ] Training_loss: 0.3842895984649658 2022-05-30 02:06:15.445073
learning rate:  0.0013107200000000005
val: 1 0.44678205251693726
val: 2 0.4382949471473694
val: 3 0.4616508185863495
val: 4 0.4256296157836914
val: 5 0.442457914352417
val: 6 0.43773236870765686
val: 7 0.45207300782203674
val: 8 0.4409879744052887
val: 9 0.44056016206741333
val: 10 0.44603702425956726
val: 11 0.4394703507423401
val: 12 0.44743165373802185
val: 13 0.44908273220062256
val: 14 0.4432104527950287
val: 15 0.43755292892456055
val: 16 0.44948557019233704
val: 17 0.43593135476112366
val: 18 0.4407442510128021
val: 19 0.4542046785354614
val: 20 0.4320649802684784
val_Epoch:[ 69 ] val_loss: 0.4430692419409752 2022-05-30 02:06:20.738755
start training 2022-05-30 02:06:20.832908
Epoch:[ 70 0 ] loss: 0.3825041353702545 2022-05-30 02:06:44.107363
Epoch:[ 70 1 ] loss: 0.38334500789642334 2022-05-30 02:06:44.884191
Epoch:[ 70 2 ] loss: 0.3825911283493042 2022-05-30 02:06:45.659234
Epoch:[ 70 3 ] loss: 0.38440564274787903 2022-05-30 02:06:46.435033
Epoch:[ 70 4 ] loss: 0.38250091671943665 2022-05-30 02:06:47.214091
Epoch:[ 70 5 ] loss: 0.38625451922416687 2022-05-30 02:06:47.993698
Epoch:[ 70 6 ] loss: 0.380562961101532 2022-05-30 02:06:48.773860
Epoch:[ 70 7 ] loss: 0.3832454979419708 2022-05-30 02:06:49.550554
Epoch:[ 70 8 ] loss: 0.3820813000202179 2022-05-30 02:06:50.326767
Epoch:[ 70 9 ] loss: 0.3829115629196167 2022-05-30 02:06:51.102106
Epoch:[ 70 10 ] loss: 0.38503843545913696 2022-05-30 02:06:51.877412
Epoch:[ 70 11 ] loss: 0.38346248865127563 2022-05-30 02:06:52.656082
Epoch:[ 70 12 ] loss: 0.3836050033569336 2022-05-30 02:06:53.435070
Epoch:[ 70 13 ] loss: 0.38399648666381836 2022-05-30 02:06:54.212724
Epoch:[ 70 14 ] loss: 0.384433388710022 2022-05-30 02:06:54.989825
Epoch:[ 70 15 ] loss: 0.3878622055053711 2022-05-30 02:06:55.766091
Epoch:[ 70 16 ] loss: 0.38192418217658997 2022-05-30 02:07:03.200758
Epoch:[ 70 17 ] loss: 0.3878909647464752 2022-05-30 02:07:03.977201
Epoch:[ 70 18 ] loss: 0.3838880658149719 2022-05-30 02:07:04.760389
Epoch:[ 70 19 ] loss: 0.3885262608528137 2022-05-30 02:07:05.537957
Training_Epoch:[ 70 ] Training_loss: 0.3840515077114105 2022-05-30 02:07:05.538618
learning rate:  0.0013107200000000005
netparams have been saved once 70
val: 1 0.4433422386646271
val: 2 0.4389866292476654
val: 3 0.430270791053772
val: 4 0.4493963122367859
val: 5 0.4532042443752289
val: 6 0.4308847188949585
val: 7 0.44883623719215393
val: 8 0.43732354044914246
val: 9 0.43771716952323914
val: 10 0.44260749220848083
val: 11 0.44656801223754883
val: 12 0.4319702088832855
val: 13 0.4346369504928589
val: 14 0.42408618330955505
val: 15 0.4589942991733551
val: 16 0.43328195810317993
val: 17 0.4416062533855438
val: 18 0.4516487717628479
val: 19 0.4409313201904297
val: 20 0.44529667496681213
val_Epoch:[ 70 ] val_loss: 0.44107950031757354 2022-05-30 02:07:11.005329
start training 2022-05-30 02:07:11.107061
Epoch:[ 71 0 ] loss: 0.38194212317466736 2022-05-30 02:07:34.279648
Epoch:[ 71 1 ] loss: 0.3822832703590393 2022-05-30 02:07:35.105997
Epoch:[ 71 2 ] loss: 0.38315197825431824 2022-05-30 02:07:35.882020
Epoch:[ 71 3 ] loss: 0.3857162892818451 2022-05-30 02:07:36.660070
Epoch:[ 71 4 ] loss: 0.38405296206474304 2022-05-30 02:07:37.433522
Epoch:[ 71 5 ] loss: 0.385719358921051 2022-05-30 02:07:38.213089
Epoch:[ 71 6 ] loss: 0.3815905749797821 2022-05-30 02:07:38.992902
Epoch:[ 71 7 ] loss: 0.38138890266418457 2022-05-30 02:07:39.773020
Epoch:[ 71 8 ] loss: 0.3836180567741394 2022-05-30 02:07:40.552042
Epoch:[ 71 9 ] loss: 0.3828926682472229 2022-05-30 02:07:41.328281
Epoch:[ 71 10 ] loss: 0.383172869682312 2022-05-30 02:07:42.107277
Epoch:[ 71 11 ] loss: 0.38447293639183044 2022-05-30 02:07:42.882768
Epoch:[ 71 12 ] loss: 0.3834327459335327 2022-05-30 02:07:43.661285
Epoch:[ 71 13 ] loss: 0.3849047124385834 2022-05-30 02:07:44.439858
Epoch:[ 71 14 ] loss: 0.3841566741466522 2022-05-30 02:07:45.219891
Epoch:[ 71 15 ] loss: 0.3798220753669739 2022-05-30 02:07:46.000127
Epoch:[ 71 16 ] loss: 0.38351115584373474 2022-05-30 02:07:53.507805
Epoch:[ 71 17 ] loss: 0.38591036200523376 2022-05-30 02:07:54.284392
Epoch:[ 71 18 ] loss: 0.3837224245071411 2022-05-30 02:07:55.061576
Epoch:[ 71 19 ] loss: 0.38347357511520386 2022-05-30 02:07:55.838656
Training_Epoch:[ 71 ] Training_loss: 0.38344678580760955 2022-05-30 02:07:55.839285
learning rate:  0.0010485760000000005
val: 1 0.44324785470962524
val: 2 0.4312041699886322
val: 3 0.4550102651119232
val: 4 0.4413137435913086
val: 5 0.43190017342567444
val: 6 0.43692469596862793
val: 7 0.4460911154747009
val: 8 0.4440944790840149
val: 9 0.43805354833602905
val: 10 0.4372953772544861
val: 11 0.4464705288410187
val: 12 0.4460553824901581
val: 13 0.42718738317489624
val: 14 0.43709808588027954
val: 15 0.44569894671440125
val: 16 0.442746102809906
val: 17 0.4461720883846283
val: 18 0.4376913905143738
val: 19 0.445109099149704
val: 20 0.4447336494922638
val_Epoch:[ 71 ] val_loss: 0.4412049040198326 2022-05-30 02:08:01.275906
start training 2022-05-30 02:08:01.378491
Epoch:[ 72 0 ] loss: 0.38086286187171936 2022-05-30 02:08:25.365046
Epoch:[ 72 1 ] loss: 0.3844034671783447 2022-05-30 02:08:26.141137
Epoch:[ 72 2 ] loss: 0.3832346498966217 2022-05-30 02:08:26.917570
Epoch:[ 72 3 ] loss: 0.3831402361392975 2022-05-30 02:08:27.692590
Epoch:[ 72 4 ] loss: 0.3802553117275238 2022-05-30 02:08:28.471310
Epoch:[ 72 5 ] loss: 0.3817192018032074 2022-05-30 02:08:29.246444
Epoch:[ 72 6 ] loss: 0.3816024959087372 2022-05-30 02:08:30.025536
Epoch:[ 72 7 ] loss: 0.3826218247413635 2022-05-30 02:08:30.804080
Epoch:[ 72 8 ] loss: 0.3843351900577545 2022-05-30 02:08:31.581066
Epoch:[ 72 9 ] loss: 0.3858848512172699 2022-05-30 02:08:32.357345
Epoch:[ 72 10 ] loss: 0.38281819224357605 2022-05-30 02:08:33.132652
Epoch:[ 72 11 ] loss: 0.38408806920051575 2022-05-30 02:08:33.911854
Epoch:[ 72 12 ] loss: 0.38008883595466614 2022-05-30 02:08:34.687382
Epoch:[ 72 13 ] loss: 0.3834085166454315 2022-05-30 02:08:35.466658
Epoch:[ 72 14 ] loss: 0.38182011246681213 2022-05-30 02:08:36.246656
Epoch:[ 72 15 ] loss: 0.37913593649864197 2022-05-30 02:08:37.026781
Epoch:[ 72 16 ] loss: 0.3809332847595215 2022-05-30 02:08:44.933867
Epoch:[ 72 17 ] loss: 0.38268622756004333 2022-05-30 02:08:45.710113
Epoch:[ 72 18 ] loss: 0.38247019052505493 2022-05-30 02:08:46.491388
Epoch:[ 72 19 ] loss: 0.38100025057792664 2022-05-30 02:08:47.268072
Training_Epoch:[ 72 ] Training_loss: 0.3823254853487015 2022-05-30 02:08:47.268703
learning rate:  0.0010485760000000005
netparams have been saved once 72
val: 1 0.44953757524490356
val: 2 0.4432049095630646
val: 3 0.4361037313938141
val: 4 0.45587316155433655
val: 5 0.4418816566467285
val: 6 0.4364035129547119
val: 7 0.4442168176174164
val: 8 0.433008074760437
val: 9 0.44920265674591064
val: 10 0.4230905771255493
val: 11 0.423977255821228
val: 12 0.4473694860935211
val: 13 0.44440966844558716
val: 14 0.44032102823257446
val: 15 0.440921425819397
val: 16 0.4383470118045807
val: 17 0.43602898716926575
val: 18 0.4414588212966919
val: 19 0.44946786761283875
val: 20 0.4355742335319519
val_Epoch:[ 72 ] val_loss: 0.4405199229717255 2022-05-30 02:08:52.713159
start training 2022-05-30 02:08:52.808186
Epoch:[ 73 0 ] loss: 0.38178008794784546 2022-05-30 02:09:15.856495
Epoch:[ 73 1 ] loss: 0.38031044602394104 2022-05-30 02:09:16.669413
Epoch:[ 73 2 ] loss: 0.38314566016197205 2022-05-30 02:09:17.447805
Epoch:[ 73 3 ] loss: 0.38028356432914734 2022-05-30 02:09:18.222997
Epoch:[ 73 4 ] loss: 0.38430240750312805 2022-05-30 02:09:18.996844
Epoch:[ 73 5 ] loss: 0.37862271070480347 2022-05-30 02:09:19.771763
Epoch:[ 73 6 ] loss: 0.38076502084732056 2022-05-30 02:09:20.546700
Epoch:[ 73 7 ] loss: 0.38146090507507324 2022-05-30 02:09:21.323344
Epoch:[ 73 8 ] loss: 0.3814822733402252 2022-05-30 02:09:22.100568
Epoch:[ 73 9 ] loss: 0.38199949264526367 2022-05-30 02:09:22.877600
Epoch:[ 73 10 ] loss: 0.37964004278182983 2022-05-30 02:09:23.653439
Epoch:[ 73 11 ] loss: 0.3785157799720764 2022-05-30 02:09:24.428130
Epoch:[ 73 12 ] loss: 0.38126233220100403 2022-05-30 02:09:25.205645
Epoch:[ 73 13 ] loss: 0.3806525766849518 2022-05-30 02:09:25.978765
Epoch:[ 73 14 ] loss: 0.3831457495689392 2022-05-30 02:09:26.756872
Epoch:[ 73 15 ] loss: 0.38142186403274536 2022-05-30 02:09:27.534925
Epoch:[ 73 16 ] loss: 0.38163116574287415 2022-05-30 02:09:35.422021
Epoch:[ 73 17 ] loss: 0.38278645277023315 2022-05-30 02:09:36.198198
Epoch:[ 73 18 ] loss: 0.38160401582717896 2022-05-30 02:09:36.975895
Epoch:[ 73 19 ] loss: 0.3798178732395172 2022-05-30 02:09:37.751195
Training_Epoch:[ 73 ] Training_loss: 0.3812315210700035 2022-05-30 02:09:37.751859
learning rate:  0.0010485760000000005
val: 1 0.439951092004776
val: 2 0.4420930743217468
val: 3 0.4392347037792206
val: 4 0.44827425479888916
val: 5 0.44615882635116577
val: 6 0.4507547914981842
val: 7 0.4331902265548706
val: 8 0.455465167760849
val: 9 0.4281129837036133
val: 10 0.4346926212310791
val: 11 0.45955711603164673
val: 12 0.43671825528144836
val: 13 0.4505508840084076
val: 14 0.43726810812950134
val: 15 0.42670518159866333
val: 16 0.440655916929245
val: 17 0.4353736639022827
val: 18 0.45506107807159424
val: 19 0.44683557748794556
val: 20 0.4634806215763092
val_Epoch:[ 73 ] val_loss: 0.44350670725107194 2022-05-30 02:09:43.090446
start training 2022-05-30 02:09:43.192986
Epoch:[ 74 0 ] loss: 0.3807871341705322 2022-05-30 02:10:05.493782
Epoch:[ 74 1 ] loss: 0.37977135181427 2022-05-30 02:10:06.289884
Epoch:[ 74 2 ] loss: 0.3806031048297882 2022-05-30 02:10:07.090599
Epoch:[ 74 3 ] loss: 0.37876954674720764 2022-05-30 02:10:07.866313
Epoch:[ 74 4 ] loss: 0.38059136271476746 2022-05-30 02:10:08.644443
Epoch:[ 74 5 ] loss: 0.3787762522697449 2022-05-30 02:10:09.420609
Epoch:[ 74 6 ] loss: 0.38298657536506653 2022-05-30 02:10:10.199381
Epoch:[ 74 7 ] loss: 0.3814353048801422 2022-05-30 02:10:10.973974
Epoch:[ 74 8 ] loss: 0.3802900016307831 2022-05-30 02:10:11.752952
Epoch:[ 74 9 ] loss: 0.38033443689346313 2022-05-30 02:10:12.532797
Epoch:[ 74 10 ] loss: 0.37941470742225647 2022-05-30 02:10:13.309821
Epoch:[ 74 11 ] loss: 0.3834487497806549 2022-05-30 02:10:14.086616
Epoch:[ 74 12 ] loss: 0.3791176974773407 2022-05-30 02:10:14.863167
Epoch:[ 74 13 ] loss: 0.38253411650657654 2022-05-30 02:10:15.638316
Epoch:[ 74 14 ] loss: 0.38286423683166504 2022-05-30 02:10:16.414325
Epoch:[ 74 15 ] loss: 0.3809525966644287 2022-05-30 02:10:17.192019
Epoch:[ 74 16 ] loss: 0.38186147809028625 2022-05-30 02:10:25.348418
Epoch:[ 74 17 ] loss: 0.3818592429161072 2022-05-30 02:10:26.126666
Epoch:[ 74 18 ] loss: 0.3786492347717285 2022-05-30 02:10:26.906581
Epoch:[ 74 19 ] loss: 0.3818691670894623 2022-05-30 02:10:27.680527
Training_Epoch:[ 74 ] Training_loss: 0.3808458149433136 2022-05-30 02:10:27.681156
learning rate:  0.0010485760000000005
netparams have been saved once 74
val: 1 0.4446001648902893
val: 2 0.4381801187992096
val: 3 0.43563321232795715
val: 4 0.43831855058670044
val: 5 0.4436302185058594
val: 6 0.4341813921928406
val: 7 0.4386368691921234
val: 8 0.44384104013442993
val: 9 0.45729348063468933
val: 10 0.4559880793094635
val: 11 0.43777620792388916
val: 12 0.42799112200737
val: 13 0.44251105189323425
val: 14 0.4328120946884155
val: 15 0.4524998962879181
val: 16 0.4591972231864929
val: 17 0.4478911757469177
val: 18 0.44044995307922363
val: 19 0.4389233887195587
val: 20 0.4492785334587097
val_Epoch:[ 74 ] val_loss: 0.4429816886782646 2022-05-30 02:10:33.144462
start training 2022-05-30 02:10:33.249340
Epoch:[ 75 0 ] loss: 0.3776315152645111 2022-05-30 02:10:56.148843
Epoch:[ 75 1 ] loss: 0.37916842103004456 2022-05-30 02:10:56.955055
Epoch:[ 75 2 ] loss: 0.37879034876823425 2022-05-30 02:10:57.733161
Epoch:[ 75 3 ] loss: 0.38069474697113037 2022-05-30 02:10:58.511683
Epoch:[ 75 4 ] loss: 0.38105884194374084 2022-05-30 02:10:59.288418
Epoch:[ 75 5 ] loss: 0.3787551522254944 2022-05-30 02:11:00.065343
Epoch:[ 75 6 ] loss: 0.38132205605506897 2022-05-30 02:11:00.840606
Epoch:[ 75 7 ] loss: 0.37930071353912354 2022-05-30 02:11:01.618047
Epoch:[ 75 8 ] loss: 0.3808692991733551 2022-05-30 02:11:02.392753
Epoch:[ 75 9 ] loss: 0.38235434889793396 2022-05-30 02:11:03.170362
Epoch:[ 75 10 ] loss: 0.3815350830554962 2022-05-30 02:11:03.947698
Epoch:[ 75 11 ] loss: 0.3802011013031006 2022-05-30 02:11:04.723865
Epoch:[ 75 12 ] loss: 0.38425102829933167 2022-05-30 02:11:05.501397
Epoch:[ 75 13 ] loss: 0.38353431224823 2022-05-30 02:11:06.277900
Epoch:[ 75 14 ] loss: 0.3802184462547302 2022-05-30 02:11:07.053354
Epoch:[ 75 15 ] loss: 0.3813217580318451 2022-05-30 02:11:07.827592
Epoch:[ 75 16 ] loss: 0.37759271264076233 2022-05-30 02:11:15.253138
Epoch:[ 75 17 ] loss: 0.3787437379360199 2022-05-30 02:11:16.030916
Epoch:[ 75 18 ] loss: 0.38233309984207153 2022-05-30 02:11:16.810624
Epoch:[ 75 19 ] loss: 0.3823506832122803 2022-05-30 02:11:17.586858
Training_Epoch:[ 75 ] Training_loss: 0.38060137033462527 2022-05-30 02:11:17.587635
learning rate:  0.0010485760000000005
val: 1 0.4331493675708771
val: 2 0.4339330196380615
val: 3 0.4394804537296295
val: 4 0.44444766640663147
val: 5 0.4434073865413666
val: 6 0.43389642238616943
val: 7 0.44831976294517517
val: 8 0.43284153938293457
val: 9 0.4551618993282318
val: 10 0.43930014967918396
val: 11 0.4444293677806854
val: 12 0.455473393201828
val: 13 0.4321117103099823
val: 14 0.4288523197174072
val: 15 0.43359455466270447
val: 16 0.44271063804626465
val: 17 0.44029298424720764
val: 18 0.45886334776878357
val: 19 0.43555116653442383
val: 20 0.4549131691455841
val_Epoch:[ 75 ] val_loss: 0.4415365159511566 2022-05-30 02:11:22.890803
start training 2022-05-30 02:11:22.991882
Epoch:[ 76 0 ] loss: 0.37865710258483887 2022-05-30 02:11:45.117404
Epoch:[ 76 1 ] loss: 0.3800771236419678 2022-05-30 02:11:46.302128
Epoch:[ 76 2 ] loss: 0.3826431632041931 2022-05-30 02:11:47.078095
Epoch:[ 76 3 ] loss: 0.3790571093559265 2022-05-30 02:11:47.854051
Epoch:[ 76 4 ] loss: 0.37767407298088074 2022-05-30 02:11:48.631864
Epoch:[ 76 5 ] loss: 0.38078975677490234 2022-05-30 02:11:49.408810
Epoch:[ 76 6 ] loss: 0.3777914047241211 2022-05-30 02:11:50.185090
Epoch:[ 76 7 ] loss: 0.38235408067703247 2022-05-30 02:11:50.960696
Epoch:[ 76 8 ] loss: 0.3827212154865265 2022-05-30 02:11:51.738612
Epoch:[ 76 9 ] loss: 0.3792024254798889 2022-05-30 02:11:52.515697
Epoch:[ 76 10 ] loss: 0.38169896602630615 2022-05-30 02:11:53.296594
Epoch:[ 76 11 ] loss: 0.3797365128993988 2022-05-30 02:11:54.078299
Epoch:[ 76 12 ] loss: 0.378775417804718 2022-05-30 02:11:54.856161
Epoch:[ 76 13 ] loss: 0.3828173279762268 2022-05-30 02:11:55.634040
Epoch:[ 76 14 ] loss: 0.3794187903404236 2022-05-30 02:11:56.412067
Epoch:[ 76 15 ] loss: 0.38282737135887146 2022-05-30 02:11:57.187856
Epoch:[ 76 16 ] loss: 0.3830893635749817 2022-05-30 02:12:04.621220
Epoch:[ 76 17 ] loss: 0.38013899326324463 2022-05-30 02:12:05.561692
Epoch:[ 76 18 ] loss: 0.3825736939907074 2022-05-30 02:12:06.344360
Epoch:[ 76 19 ] loss: 0.3779837191104889 2022-05-30 02:12:07.122647
Training_Epoch:[ 76 ] Training_loss: 0.38050138056278227 2022-05-30 02:12:07.123353
learning rate:  0.0010485760000000005
netparams have been saved once 76
val: 1 0.42947372794151306
val: 2 0.4432293176651001
val: 3 0.4413796067237854
val: 4 0.4404018223285675
val: 5 0.4365842640399933
val: 6 0.4451938271522522
val: 7 0.44013500213623047
val: 8 0.4494066834449768
val: 9 0.43867382407188416
val: 10 0.4390720725059509
val: 11 0.43530842661857605
val: 12 0.44855254888534546
val: 13 0.43105533719062805
val: 14 0.4448809027671814
val: 15 0.4477221667766571
val: 16 0.4491194486618042
val: 17 0.43031033873558044
val: 18 0.42864298820495605
val: 19 0.4440249502658844
val: 20 0.44224855303764343
val_Epoch:[ 76 ] val_loss: 0.44027079045772555 2022-05-30 02:12:12.542838
start training 2022-05-30 02:12:12.642278
Epoch:[ 77 0 ] loss: 0.38140347599983215 2022-05-30 02:12:36.692528
Epoch:[ 77 1 ] loss: 0.3781764805316925 2022-05-30 02:12:37.468996
Epoch:[ 77 2 ] loss: 0.3822583854198456 2022-05-30 02:12:38.248105
Epoch:[ 77 3 ] loss: 0.38060981035232544 2022-05-30 02:12:39.024264
Epoch:[ 77 4 ] loss: 0.37840643525123596 2022-05-30 02:12:39.802965
Epoch:[ 77 5 ] loss: 0.37943315505981445 2022-05-30 02:12:40.580813
Epoch:[ 77 6 ] loss: 0.3819965124130249 2022-05-30 02:12:41.358676
Epoch:[ 77 7 ] loss: 0.38141676783561707 2022-05-30 02:12:42.135933
Epoch:[ 77 8 ] loss: 0.3804548680782318 2022-05-30 02:12:42.911552
Epoch:[ 77 9 ] loss: 0.37845224142074585 2022-05-30 02:12:43.691323
Epoch:[ 77 10 ] loss: 0.3780997395515442 2022-05-30 02:12:44.466663
Epoch:[ 77 11 ] loss: 0.3785984516143799 2022-05-30 02:12:45.246067
Epoch:[ 77 12 ] loss: 0.3803810179233551 2022-05-30 02:12:46.025279
Epoch:[ 77 13 ] loss: 0.38122066855430603 2022-05-30 02:12:46.802217
Epoch:[ 77 14 ] loss: 0.38070064783096313 2022-05-30 02:12:47.581839
Epoch:[ 77 15 ] loss: 0.3819001019001007 2022-05-30 02:12:48.356038
Epoch:[ 77 16 ] loss: 0.3810758888721466 2022-05-30 02:12:56.388852
Epoch:[ 77 17 ] loss: 0.3787292242050171 2022-05-30 02:12:57.161751
Epoch:[ 77 18 ] loss: 0.3792036473751068 2022-05-30 02:12:57.944902
Epoch:[ 77 19 ] loss: 0.38365352153778076 2022-05-30 02:12:58.721490
Training_Epoch:[ 77 ] Training_loss: 0.3803085520863533 2022-05-30 02:12:58.722213
learning rate:  0.0010485760000000005
val: 1 0.45164352655410767
val: 2 0.44775739312171936
val: 3 0.4456019103527069
val: 4 0.46012982726097107
val: 5 0.4396844804286957
val: 6 0.4320513904094696
val: 7 0.42483317852020264
val: 8 0.4403098523616791
val: 9 0.448487251996994
val: 10 0.4381984770298004
val: 11 0.43350037932395935
val: 12 0.43538907170295715
val: 13 0.42097073793411255
val: 14 0.4302426874637604
val: 15 0.4453012943267822
val: 16 0.4303954541683197
val: 17 0.4403524398803711
val: 18 0.4503478407859802
val: 19 0.43846210837364197
val: 20 0.4526454508304596
val_Epoch:[ 77 ] val_loss: 0.4403152376413345 2022-05-30 02:13:04.137165
start training 2022-05-30 02:13:04.232383
Epoch:[ 78 0 ] loss: 0.37956100702285767 2022-05-30 02:13:26.560861
Epoch:[ 78 1 ] loss: 0.37857702374458313 2022-05-30 02:13:27.716537
Epoch:[ 78 2 ] loss: 0.37784239649772644 2022-05-30 02:13:28.491483
Epoch:[ 78 3 ] loss: 0.3791908025741577 2022-05-30 02:13:29.265534
Epoch:[ 78 4 ] loss: 0.38033998012542725 2022-05-30 02:13:30.039063
Epoch:[ 78 5 ] loss: 0.3786655068397522 2022-05-30 02:13:30.815799
Epoch:[ 78 6 ] loss: 0.37925925850868225 2022-05-30 02:13:31.593768
Epoch:[ 78 7 ] loss: 0.3808356523513794 2022-05-30 02:13:32.368570
Epoch:[ 78 8 ] loss: 0.3829720616340637 2022-05-30 02:13:33.142958
Epoch:[ 78 9 ] loss: 0.3805069923400879 2022-05-30 02:13:33.918896
Epoch:[ 78 10 ] loss: 0.3845197558403015 2022-05-30 02:13:34.694048
Epoch:[ 78 11 ] loss: 0.38215428590774536 2022-05-30 02:13:35.467934
Epoch:[ 78 12 ] loss: 0.38167229294776917 2022-05-30 02:13:36.246589
Epoch:[ 78 13 ] loss: 0.3780496120452881 2022-05-30 02:13:37.025261
Epoch:[ 78 14 ] loss: 0.37881046533584595 2022-05-30 02:13:37.801305
Epoch:[ 78 15 ] loss: 0.3805188536643982 2022-05-30 02:13:38.578384
Epoch:[ 78 16 ] loss: 0.37824487686157227 2022-05-30 02:13:46.199985
Epoch:[ 78 17 ] loss: 0.37780246138572693 2022-05-30 02:13:46.973111
Epoch:[ 78 18 ] loss: 0.3775218725204468 2022-05-30 02:13:47.766800
Epoch:[ 78 19 ] loss: 0.3777599632740021 2022-05-30 02:13:48.542918
Training_Epoch:[ 78 ] Training_loss: 0.3797402560710907 2022-05-30 02:13:48.543636
learning rate:  0.0010485760000000005
netparams have been saved once 78
val: 1 0.44873297214508057
val: 2 0.4335588812828064
val: 3 0.43865811824798584
val: 4 0.4470413625240326
val: 5 0.44539743661880493
val: 6 0.4471845030784607
val: 7 0.4470871686935425
val: 8 0.4544126093387604
val: 9 0.4327442944049835
val: 10 0.43788987398147583
val: 11 0.43506884574890137
val: 12 0.4436436891555786
val: 13 0.4366585612297058
val: 14 0.4447000026702881
val: 15 0.4337044358253479
val: 16 0.43900325894355774
val: 17 0.4330444037914276
val: 18 0.4640160799026489
val: 19 0.4546501636505127
val: 20 0.4417889714241028
val_Epoch:[ 78 ] val_loss: 0.44294928163290026 2022-05-30 02:13:54.042157
start training 2022-05-30 02:13:54.143832
Epoch:[ 79 0 ] loss: 0.3803563714027405 2022-05-30 02:14:17.776966
Epoch:[ 79 1 ] loss: 0.3775410056114197 2022-05-30 02:14:18.594897
Epoch:[ 79 2 ] loss: 0.3839416205883026 2022-05-30 02:14:19.370283
Epoch:[ 79 3 ] loss: 0.3815651834011078 2022-05-30 02:14:20.145826
Epoch:[ 79 4 ] loss: 0.37828513979911804 2022-05-30 02:14:20.924843
Epoch:[ 79 5 ] loss: 0.3772851526737213 2022-05-30 02:14:21.699050
Epoch:[ 79 6 ] loss: 0.37866565585136414 2022-05-30 02:14:22.477338
Epoch:[ 79 7 ] loss: 0.37754154205322266 2022-05-30 02:14:23.255784
Epoch:[ 79 8 ] loss: 0.37776559591293335 2022-05-30 02:14:24.033131
Epoch:[ 79 9 ] loss: 0.3785804510116577 2022-05-30 02:14:24.811117
Epoch:[ 79 10 ] loss: 0.3789557218551636 2022-05-30 02:14:25.588287
Epoch:[ 79 11 ] loss: 0.3807130753993988 2022-05-30 02:14:26.365061
Epoch:[ 79 12 ] loss: 0.3835165500640869 2022-05-30 02:14:27.138342
Epoch:[ 79 13 ] loss: 0.3754101097583771 2022-05-30 02:14:27.917305
Epoch:[ 79 14 ] loss: 0.37756410241127014 2022-05-30 02:14:28.695099
Epoch:[ 79 15 ] loss: 0.3790155053138733 2022-05-30 02:14:29.469985
Epoch:[ 79 16 ] loss: 0.3795119822025299 2022-05-30 02:14:37.006508
Epoch:[ 79 17 ] loss: 0.3795081377029419 2022-05-30 02:14:37.780588
Epoch:[ 79 18 ] loss: 0.3807835876941681 2022-05-30 02:14:38.560987
Epoch:[ 79 19 ] loss: 0.3765171766281128 2022-05-30 02:14:39.334532
Training_Epoch:[ 79 ] Training_loss: 0.3791511833667755 2022-05-30 02:14:39.335267
learning rate:  0.0010485760000000005
val: 1 0.42110130190849304
val: 2 0.4396900236606598
val: 3 0.44804564118385315
val: 4 0.4300197660923004
val: 5 0.42900294065475464
val: 6 0.45489150285720825
val: 7 0.4472362995147705
val: 8 0.45022499561309814
val: 9 0.44717875123023987
val: 10 0.43490731716156006
val: 11 0.4413492977619171
val: 12 0.4456997215747833
val: 13 0.4480014443397522
val: 14 0.4375546872615814
val: 15 0.44488686323165894
val: 16 0.4336998462677002
val: 17 0.4277036190032959
val: 18 0.4512905478477478
val: 19 0.44571322202682495
val: 20 0.45254480838775635
val_Epoch:[ 79 ] val_loss: 0.4415371298789978 2022-05-30 02:14:44.627640
start training 2022-05-30 02:14:44.730433
Epoch:[ 80 0 ] loss: 0.378243088722229 2022-05-30 02:15:08.686571
Epoch:[ 80 1 ] loss: 0.3794810473918915 2022-05-30 02:15:09.463399
Epoch:[ 80 2 ] loss: 0.37813600897789 2022-05-30 02:15:10.243220
Epoch:[ 80 3 ] loss: 0.37955614924430847 2022-05-30 02:15:11.019704
Epoch:[ 80 4 ] loss: 0.3800276219844818 2022-05-30 02:15:11.796380
Epoch:[ 80 5 ] loss: 0.38077837228775024 2022-05-30 02:15:12.572619
Epoch:[ 80 6 ] loss: 0.3803682029247284 2022-05-30 02:15:13.347603
Epoch:[ 80 7 ] loss: 0.3797128200531006 2022-05-30 02:15:14.125390
Epoch:[ 80 8 ] loss: 0.38144683837890625 2022-05-30 02:15:14.903535
Epoch:[ 80 9 ] loss: 0.3830113112926483 2022-05-30 02:15:15.678838
Epoch:[ 80 10 ] loss: 0.3787626624107361 2022-05-30 02:15:16.456007
Epoch:[ 80 11 ] loss: 0.37756603956222534 2022-05-30 02:15:17.231904
Epoch:[ 80 12 ] loss: 0.3790944218635559 2022-05-30 02:15:18.006964
Epoch:[ 80 13 ] loss: 0.3813212513923645 2022-05-30 02:15:18.781342
Epoch:[ 80 14 ] loss: 0.37578198313713074 2022-05-30 02:15:19.559850
Epoch:[ 80 15 ] loss: 0.37938669323921204 2022-05-30 02:15:20.337678
Epoch:[ 80 16 ] loss: 0.3771876394748688 2022-05-30 02:15:28.378717
Epoch:[ 80 17 ] loss: 0.37963423132896423 2022-05-30 02:15:29.155562
Epoch:[ 80 18 ] loss: 0.3818027675151825 2022-05-30 02:15:29.935284
Epoch:[ 80 19 ] loss: 0.37801650166511536 2022-05-30 02:15:30.711880
Training_Epoch:[ 80 ] Training_loss: 0.3794657826423645 2022-05-30 02:15:30.712581
learning rate:  0.0010485760000000005
netparams have been saved once 80
val: 1 0.43571898341178894
val: 2 0.44252508878707886
val: 3 0.4380626678466797
val: 4 0.44700807332992554
val: 5 0.447414368391037
val: 6 0.4345947206020355
val: 7 0.43648436665534973
val: 8 0.44840872287750244
val: 9 0.43754419684410095
val: 10 0.4426068365573883
val: 11 0.4352162182331085
val: 12 0.42841964960098267
val: 13 0.43122297525405884
val: 14 0.4488385021686554
val: 15 0.4432941973209381
val: 16 0.4495048522949219
val: 17 0.443995863199234
val: 18 0.45494958758354187
val: 19 0.43914636969566345
val: 20 0.4365783631801605
val_Epoch:[ 80 ] val_loss: 0.4410767301917076 2022-05-30 02:15:36.157622
start training 2022-05-30 02:15:36.260032
