GPU: True
80
start training 2022-07-20 00:18:34.389118
Epoch:[ 1 0 ] loss: 0.6990602612495422 2022-07-20 00:19:06.452166
Epoch:[ 1 1 ] loss: 0.6839731335639954 2022-07-20 00:19:06.933561
Epoch:[ 1 2 ] loss: 0.6825166940689087 2022-07-20 00:19:07.357999
Epoch:[ 1 3 ] loss: 0.6797693967819214 2022-07-20 00:19:07.779075
Epoch:[ 1 4 ] loss: 0.671262264251709 2022-07-20 00:19:08.194938
Epoch:[ 1 5 ] loss: 0.6675639152526855 2022-07-20 00:19:08.611557
Epoch:[ 1 6 ] loss: 0.661605179309845 2022-07-20 00:19:09.028893
Epoch:[ 1 7 ] loss: 0.6528365015983582 2022-07-20 00:19:09.449890
Epoch:[ 1 8 ] loss: 0.6481291055679321 2022-07-20 00:19:09.863352
Epoch:[ 1 9 ] loss: 0.6418756246566772 2022-07-20 00:19:10.277261
Epoch:[ 1 10 ] loss: 0.6384324431419373 2022-07-20 00:19:10.690547
Epoch:[ 1 11 ] loss: 0.6361947655677795 2022-07-20 00:19:11.103588
Epoch:[ 1 12 ] loss: 0.631122887134552 2022-07-20 00:19:11.516915
Epoch:[ 1 13 ] loss: 0.6284570693969727 2022-07-20 00:19:11.933781
Epoch:[ 1 14 ] loss: 0.6255257725715637 2022-07-20 00:19:12.350611
Epoch:[ 1 15 ] loss: 0.6240485310554504 2022-07-20 00:19:12.765831
Epoch:[ 1 16 ] loss: 0.6217296719551086 2022-07-20 00:19:14.252661
Epoch:[ 1 17 ] loss: 0.617928683757782 2022-07-20 00:19:14.665134
Epoch:[ 1 18 ] loss: 0.6172330975532532 2022-07-20 00:19:15.079466
Epoch:[ 1 19 ] loss: 0.6136600971221924 2022-07-20 00:19:15.493430
Training_Epoch:[ 1 ] Training_loss: 0.6471462547779083 2022-07-20 00:19:15.494037
learning rate:  0.001
val: 1 0.6807254552841187
val: 2 0.679916262626648
val: 3 0.6797412633895874
val: 4 0.678655207157135
val: 5 0.6792330145835876
val: 6 0.679637610912323
val: 7 0.6795148253440857
val: 8 0.679465115070343
val: 9 0.6794817447662354
val: 10 0.6789475679397583
val: 11 0.6801533699035645
val: 12 0.6805031895637512
val: 13 0.6795545220375061
val: 14 0.679538905620575
val: 15 0.6799032092094421
val: 16 0.6793739199638367
val: 17 0.6801557540893555
val: 18 0.6799616813659668
val: 19 0.6798610687255859
val: 20 0.6795856356620789
val_Epoch:[ 1 ] val_loss: 0.6796954661607743 2022-07-20 00:19:19.220958
start training 2022-07-20 00:19:19.323824
Epoch:[ 2 0 ] loss: 0.6141015887260437 2022-07-20 00:19:33.249803
Epoch:[ 2 1 ] loss: 0.6116212606430054 2022-07-20 00:19:33.661642
Epoch:[ 2 2 ] loss: 0.607071578502655 2022-07-20 00:19:34.075375
Epoch:[ 2 3 ] loss: 0.606147050857544 2022-07-20 00:19:34.490898
Epoch:[ 2 4 ] loss: 0.6038202047348022 2022-07-20 00:19:34.904566
Epoch:[ 2 5 ] loss: 0.6033534407615662 2022-07-20 00:19:35.318311
Epoch:[ 2 6 ] loss: 0.6020890474319458 2022-07-20 00:19:35.734476
Epoch:[ 2 7 ] loss: 0.6015110611915588 2022-07-20 00:19:36.150070
Epoch:[ 2 8 ] loss: 0.6001182198524475 2022-07-20 00:19:36.562535
Epoch:[ 2 9 ] loss: 0.5989055037498474 2022-07-20 00:19:36.974190
Epoch:[ 2 10 ] loss: 0.5979894399642944 2022-07-20 00:19:37.388062
Epoch:[ 2 11 ] loss: 0.5959912538528442 2022-07-20 00:19:37.801670
Epoch:[ 2 12 ] loss: 0.5947182178497314 2022-07-20 00:19:38.220829
Epoch:[ 2 13 ] loss: 0.5928601622581482 2022-07-20 00:19:38.641294
Epoch:[ 2 14 ] loss: 0.5916689038276672 2022-07-20 00:19:39.062228
Epoch:[ 2 15 ] loss: 0.5909374952316284 2022-07-20 00:19:39.475131
Epoch:[ 2 16 ] loss: 0.5890927910804749 2022-07-20 00:19:44.573126
Epoch:[ 2 17 ] loss: 0.5871949791908264 2022-07-20 00:19:44.984015
Epoch:[ 2 18 ] loss: 0.5856732726097107 2022-07-20 00:19:45.398847
Epoch:[ 2 19 ] loss: 0.5872492790222168 2022-07-20 00:19:45.815187
Training_Epoch:[ 2 ] Training_loss: 0.598105737566948 2022-07-20 00:19:45.815826
learning rate:  0.001
netparams have been saved once 2
val: 1 0.6604728102684021
val: 2 0.6574342250823975
val: 3 0.6584469676017761
val: 4 0.6587159633636475
val: 5 0.6606125831604004
val: 6 0.6590725779533386
val: 7 0.6578210592269897
val: 8 0.6591485142707825
val: 9 0.6598027944564819
val: 10 0.6598384380340576
val: 11 0.6603695154190063
val: 12 0.6591155529022217
val: 13 0.6602869033813477
val: 14 0.6616454124450684
val: 15 0.6614006161689758
val: 16 0.659771740436554
val: 17 0.6621418595314026
val: 18 0.6627748608589172
val: 19 0.6614136695861816
val: 20 0.6591236591339111
val_Epoch:[ 2 ] val_loss: 0.659970486164093 2022-07-20 00:19:48.954739
start training 2022-07-20 00:19:49.054264
Epoch:[ 3 0 ] loss: 0.5835179090499878 2022-07-20 00:20:03.186110
Epoch:[ 3 1 ] loss: 0.5838924646377563 2022-07-20 00:20:03.601189
Epoch:[ 3 2 ] loss: 0.5790539383888245 2022-07-20 00:20:04.013776
Epoch:[ 3 3 ] loss: 0.5803338289260864 2022-07-20 00:20:04.427097
Epoch:[ 3 4 ] loss: 0.5781592726707458 2022-07-20 00:20:04.840286
Epoch:[ 3 5 ] loss: 0.5743262767791748 2022-07-20 00:20:05.253636
Epoch:[ 3 6 ] loss: 0.5772954821586609 2022-07-20 00:20:05.671011
Epoch:[ 3 7 ] loss: 0.5790712833404541 2022-07-20 00:20:06.086229
Epoch:[ 3 8 ] loss: 0.5743096470832825 2022-07-20 00:20:06.500581
Epoch:[ 3 9 ] loss: 0.5736650228500366 2022-07-20 00:20:06.914076
Epoch:[ 3 10 ] loss: 0.5707780122756958 2022-07-20 00:20:07.326754
Epoch:[ 3 11 ] loss: 0.5707430243492126 2022-07-20 00:20:07.739259
Epoch:[ 3 12 ] loss: 0.5685303211212158 2022-07-20 00:20:08.151363
Epoch:[ 3 13 ] loss: 0.5700682401657104 2022-07-20 00:20:08.569461
Epoch:[ 3 14 ] loss: 0.5685652494430542 2022-07-20 00:20:08.983905
Epoch:[ 3 15 ] loss: 0.5661066174507141 2022-07-20 00:20:09.398068
Epoch:[ 3 16 ] loss: 0.5650470852851868 2022-07-20 00:20:14.763391
Epoch:[ 3 17 ] loss: 0.5663332939147949 2022-07-20 00:20:15.177019
Epoch:[ 3 18 ] loss: 0.5640627145767212 2022-07-20 00:20:15.592238
Epoch:[ 3 19 ] loss: 0.5618661046028137 2022-07-20 00:20:16.010131
Training_Epoch:[ 3 ] Training_loss: 0.5727862894535065 2022-07-20 00:20:16.010802
learning rate:  0.001
val: 1 0.5771073698997498
val: 2 0.5796302556991577
val: 3 0.5797616243362427
val: 4 0.5741744637489319
val: 5 0.5757471323013306
val: 6 0.5773151516914368
val: 7 0.5773959755897522
val: 8 0.574669361114502
val: 9 0.5753479599952698
val: 10 0.5760762691497803
val: 11 0.5726248025894165
val: 12 0.5862235426902771
val: 13 0.5769095420837402
val: 14 0.5793907046318054
val: 15 0.5719298720359802
val: 16 0.5789757370948792
val: 17 0.5688784122467041
val: 18 0.5781073570251465
val: 19 0.5724984407424927
val: 20 0.5727742910385132
val_Epoch:[ 3 ] val_loss: 0.5762769132852554 2022-07-20 00:20:19.066086
start training 2022-07-20 00:20:19.169857
Epoch:[ 4 0 ] loss: 0.5610756278038025 2022-07-20 00:20:33.119150
Epoch:[ 4 1 ] loss: 0.5596802234649658 2022-07-20 00:20:33.539247
Epoch:[ 4 2 ] loss: 0.5585548877716064 2022-07-20 00:20:33.954850
Epoch:[ 4 3 ] loss: 0.5606924295425415 2022-07-20 00:20:34.367183
Epoch:[ 4 4 ] loss: 0.5577170252799988 2022-07-20 00:20:34.786577
Epoch:[ 4 5 ] loss: 0.5570853352546692 2022-07-20 00:20:35.205493
Epoch:[ 4 6 ] loss: 0.5582433938980103 2022-07-20 00:20:35.618364
Epoch:[ 4 7 ] loss: 0.5580472350120544 2022-07-20 00:20:36.033619
Epoch:[ 4 8 ] loss: 0.557493269443512 2022-07-20 00:20:36.446749
Epoch:[ 4 9 ] loss: 0.5563864707946777 2022-07-20 00:20:36.860547
Epoch:[ 4 10 ] loss: 0.5557276606559753 2022-07-20 00:20:37.273586
Epoch:[ 4 11 ] loss: 0.553182065486908 2022-07-20 00:20:37.686250
Epoch:[ 4 12 ] loss: 0.553555965423584 2022-07-20 00:20:38.098572
Epoch:[ 4 13 ] loss: 0.5532484650611877 2022-07-20 00:20:38.510818
Epoch:[ 4 14 ] loss: 0.5509207844734192 2022-07-20 00:20:38.924019
Epoch:[ 4 15 ] loss: 0.5512663125991821 2022-07-20 00:20:39.339596
Epoch:[ 4 16 ] loss: 0.5473341345787048 2022-07-20 00:20:44.598086
Epoch:[ 4 17 ] loss: 0.5481098890304565 2022-07-20 00:20:45.013578
Epoch:[ 4 18 ] loss: 0.5496905446052551 2022-07-20 00:20:45.435054
Epoch:[ 4 19 ] loss: 0.5471683740615845 2022-07-20 00:20:45.849721
Training_Epoch:[ 4 ] Training_loss: 0.5547590047121048 2022-07-20 00:20:45.850379
learning rate:  0.001
netparams have been saved once 4
val: 1 0.5713199377059937
val: 2 0.5724528431892395
val: 3 0.5653735399246216
val: 4 0.576800525188446
val: 5 0.566646158695221
val: 6 0.5765672326087952
val: 7 0.5714191794395447
val: 8 0.5686297416687012
val: 9 0.5735088586807251
val: 10 0.5725600123405457
val: 11 0.577512800693512
val: 12 0.5710781216621399
val: 13 0.570432722568512
val: 14 0.5667685270309448
val: 15 0.5608786940574646
val: 16 0.5718139410018921
val: 17 0.5647282004356384
val: 18 0.5671048164367676
val: 19 0.5710190534591675
val: 20 0.5701369047164917
val_Epoch:[ 4 ] val_loss: 0.5703375905752182 2022-07-20 00:20:49.000630
start training 2022-07-20 00:20:49.100476
Epoch:[ 5 0 ] loss: 0.5469687581062317 2022-07-20 00:21:02.373477
Epoch:[ 5 1 ] loss: 0.5424811840057373 2022-07-20 00:21:03.034686
Epoch:[ 5 2 ] loss: 0.5475868582725525 2022-07-20 00:21:03.455665
Epoch:[ 5 3 ] loss: 0.5446343421936035 2022-07-20 00:21:03.869840
Epoch:[ 5 4 ] loss: 0.5448063611984253 2022-07-20 00:21:04.282527
Epoch:[ 5 5 ] loss: 0.5455852150917053 2022-07-20 00:21:04.695281
Epoch:[ 5 6 ] loss: 0.5469367504119873 2022-07-20 00:21:05.109988
Epoch:[ 5 7 ] loss: 0.5457749962806702 2022-07-20 00:21:05.523302
Epoch:[ 5 8 ] loss: 0.544333279132843 2022-07-20 00:21:05.936666
Epoch:[ 5 9 ] loss: 0.5437266826629639 2022-07-20 00:21:06.352720
Epoch:[ 5 10 ] loss: 0.5426514148712158 2022-07-20 00:21:06.767351
Epoch:[ 5 11 ] loss: 0.5402085781097412 2022-07-20 00:21:07.179582
Epoch:[ 5 12 ] loss: 0.5405357480049133 2022-07-20 00:21:07.593068
Epoch:[ 5 13 ] loss: 0.5412867069244385 2022-07-20 00:21:08.006496
Epoch:[ 5 14 ] loss: 0.5392374396324158 2022-07-20 00:21:08.424806
Epoch:[ 5 15 ] loss: 0.5365619659423828 2022-07-20 00:21:08.837324
Epoch:[ 5 16 ] loss: 0.5410221219062805 2022-07-20 00:21:13.943414
Epoch:[ 5 17 ] loss: 0.5403731465339661 2022-07-20 00:21:14.477091
Epoch:[ 5 18 ] loss: 0.5367822647094727 2022-07-20 00:21:14.890232
Epoch:[ 5 19 ] loss: 0.5398700833320618 2022-07-20 00:21:15.302561
Training_Epoch:[ 5 ] Training_loss: 0.5425681948661805 2022-07-20 00:21:15.303174
learning rate:  0.001
val: 1 0.6341999173164368
val: 2 0.6435269117355347
val: 3 0.6427107453346252
val: 4 0.6433073878288269
val: 5 0.6321951746940613
val: 6 0.6346621513366699
val: 7 0.639664888381958
val: 8 0.6432197093963623
val: 9 0.6401581764221191
val: 10 0.6347604990005493
val: 11 0.6393446922302246
val: 12 0.6417170763015747
val: 13 0.6492252349853516
val: 14 0.6493225693702698
val: 15 0.6484874486923218
val: 16 0.6487945318222046
val: 17 0.6391962170600891
val: 18 0.6411831974983215
val: 19 0.6442784667015076
val: 20 0.6339700818061829
val_Epoch:[ 5 ] val_loss: 0.6411962538957596 2022-07-20 00:21:18.418902
start training 2022-07-20 00:21:18.527340
Epoch:[ 6 0 ] loss: 0.5394839644432068 2022-07-20 00:21:32.207958
Epoch:[ 6 1 ] loss: 0.5364456176757812 2022-07-20 00:21:32.637229
Epoch:[ 6 2 ] loss: 0.531886100769043 2022-07-20 00:21:33.049489
Epoch:[ 6 3 ] loss: 0.5344265699386597 2022-07-20 00:21:33.469704
Epoch:[ 6 4 ] loss: 0.5342593789100647 2022-07-20 00:21:33.890642
Epoch:[ 6 5 ] loss: 0.5322539806365967 2022-07-20 00:21:34.303812
Epoch:[ 6 6 ] loss: 0.5313810706138611 2022-07-20 00:21:34.718503
Epoch:[ 6 7 ] loss: 0.5307494401931763 2022-07-20 00:21:35.132232
Epoch:[ 6 8 ] loss: 0.5283277034759521 2022-07-20 00:21:35.544972
Epoch:[ 6 9 ] loss: 0.5317730903625488 2022-07-20 00:21:35.958210
Epoch:[ 6 10 ] loss: 0.5282304883003235 2022-07-20 00:21:36.372010
Epoch:[ 6 11 ] loss: 0.5301195979118347 2022-07-20 00:21:36.788274
Epoch:[ 6 12 ] loss: 0.528110146522522 2022-07-20 00:21:37.201104
Epoch:[ 6 13 ] loss: 0.5336858630180359 2022-07-20 00:21:37.612582
Epoch:[ 6 14 ] loss: 0.531808614730835 2022-07-20 00:21:38.026741
Epoch:[ 6 15 ] loss: 0.5351975560188293 2022-07-20 00:21:38.440028
Epoch:[ 6 16 ] loss: 0.5304811000823975 2022-07-20 00:21:43.846250
Epoch:[ 6 17 ] loss: 0.5296247601509094 2022-07-20 00:21:44.259159
Epoch:[ 6 18 ] loss: 0.5222343802452087 2022-07-20 00:21:44.685644
Epoch:[ 6 19 ] loss: 0.525436282157898 2022-07-20 00:21:45.097757
Training_Epoch:[ 6 ] Training_loss: 0.5312957853078842 2022-07-20 00:21:45.098362
learning rate:  0.001
netparams have been saved once 6
val: 1 0.7153687477111816
val: 2 0.7211267352104187
val: 3 0.7210410237312317
val: 4 0.7194399833679199
val: 5 0.7204189896583557
val: 6 0.7175488471984863
val: 7 0.7254596948623657
val: 8 0.7249659299850464
val: 9 0.726942241191864
val: 10 0.7191857695579529
val: 11 0.7204427123069763
val: 12 0.7148947715759277
val: 13 0.715907871723175
val: 14 0.722135066986084
val: 15 0.7160254120826721
val: 16 0.7220700979232788
val: 17 0.7144644260406494
val: 18 0.7237182855606079
val: 19 0.7187827229499817
val: 20 0.7123217582702637
val_Epoch:[ 6 ] val_loss: 0.719613054394722 2022-07-20 00:21:48.262342
start training 2022-07-20 00:21:48.362119
Epoch:[ 7 0 ] loss: 0.5214164853096008 2022-07-20 00:22:02.471168
Epoch:[ 7 1 ] loss: 0.5223278403282166 2022-07-20 00:22:02.890602
Epoch:[ 7 2 ] loss: 0.5219705700874329 2022-07-20 00:22:03.304032
Epoch:[ 7 3 ] loss: 0.5258288979530334 2022-07-20 00:22:03.718884
Epoch:[ 7 4 ] loss: 0.5271419286727905 2022-07-20 00:22:04.133286
Epoch:[ 7 5 ] loss: 0.5265253186225891 2022-07-20 00:22:04.547334
Epoch:[ 7 6 ] loss: 0.5239192247390747 2022-07-20 00:22:04.961255
Epoch:[ 7 7 ] loss: 0.525202751159668 2022-07-20 00:22:05.375337
Epoch:[ 7 8 ] loss: 0.5183566808700562 2022-07-20 00:22:05.789918
Epoch:[ 7 9 ] loss: 0.5227484107017517 2022-07-20 00:22:06.204900
Epoch:[ 7 10 ] loss: 0.5202043056488037 2022-07-20 00:22:06.621177
Epoch:[ 7 11 ] loss: 0.518051266670227 2022-07-20 00:22:07.036406
Epoch:[ 7 12 ] loss: 0.5151948928833008 2022-07-20 00:22:07.451530
Epoch:[ 7 13 ] loss: 0.5173601508140564 2022-07-20 00:22:07.866208
Epoch:[ 7 14 ] loss: 0.5125263333320618 2022-07-20 00:22:08.278431
Epoch:[ 7 15 ] loss: 0.516042947769165 2022-07-20 00:22:08.696932
Epoch:[ 7 16 ] loss: 0.5140477418899536 2022-07-20 00:22:13.699508
Epoch:[ 7 17 ] loss: 0.5136752724647522 2022-07-20 00:22:14.112054
Epoch:[ 7 18 ] loss: 0.5174527764320374 2022-07-20 00:22:14.530085
Epoch:[ 7 19 ] loss: 0.5133864283561707 2022-07-20 00:22:14.941152
Training_Epoch:[ 7 ] Training_loss: 0.5196690112352371 2022-07-20 00:22:14.941935
learning rate:  0.001
val: 1 0.7389174699783325
val: 2 0.7270955443382263
val: 3 0.7336943745613098
val: 4 0.7422061562538147
val: 5 0.7361505627632141
val: 6 0.7190626263618469
val: 7 0.7391822338104248
val: 8 0.7419342398643494
val: 9 0.7415575385093689
val: 10 0.72821044921875
val: 11 0.7291715145111084
val: 12 0.7379949688911438
val: 13 0.7347769141197205
val: 14 0.7287564873695374
val: 15 0.7379822134971619
val: 16 0.7317618131637573
val: 17 0.7448612451553345
val: 18 0.7426520586013794
val: 19 0.7321149110794067
val: 20 0.739224910736084
val_Epoch:[ 7 ] val_loss: 0.7353654116392135 2022-07-20 00:22:18.121660
start training 2022-07-20 00:22:18.211993
Epoch:[ 8 0 ] loss: 0.5120157599449158 2022-07-20 00:22:31.655818
Epoch:[ 8 1 ] loss: 0.5109025239944458 2022-07-20 00:22:32.120524
Epoch:[ 8 2 ] loss: 0.5103015303611755 2022-07-20 00:22:32.535731
Epoch:[ 8 3 ] loss: 0.5143777132034302 2022-07-20 00:22:32.954460
Epoch:[ 8 4 ] loss: 0.508750855922699 2022-07-20 00:22:33.367524
Epoch:[ 8 5 ] loss: 0.5070461630821228 2022-07-20 00:22:33.782560
Epoch:[ 8 6 ] loss: 0.5074337124824524 2022-07-20 00:22:34.198836
Epoch:[ 8 7 ] loss: 0.5062299370765686 2022-07-20 00:22:34.611667
Epoch:[ 8 8 ] loss: 0.5055660009384155 2022-07-20 00:22:35.023097
Epoch:[ 8 9 ] loss: 0.5067295432090759 2022-07-20 00:22:35.438245
Epoch:[ 8 10 ] loss: 0.5021087527275085 2022-07-20 00:22:35.852717
Epoch:[ 8 11 ] loss: 0.5042368173599243 2022-07-20 00:22:36.267755
Epoch:[ 8 12 ] loss: 0.5061397552490234 2022-07-20 00:22:36.682140
Epoch:[ 8 13 ] loss: 0.49976322054862976 2022-07-20 00:22:37.097697
Epoch:[ 8 14 ] loss: 0.5026658177375793 2022-07-20 00:22:37.511446
Epoch:[ 8 15 ] loss: 0.5028261542320251 2022-07-20 00:22:37.929236
Epoch:[ 8 16 ] loss: 0.4996880292892456 2022-07-20 00:22:43.500376
Epoch:[ 8 17 ] loss: 0.4980732500553131 2022-07-20 00:22:43.918687
Epoch:[ 8 18 ] loss: 0.5000367164611816 2022-07-20 00:22:44.333921
Epoch:[ 8 19 ] loss: 0.5022976994514465 2022-07-20 00:22:44.748481
Training_Epoch:[ 8 ] Training_loss: 0.5053594976663589 2022-07-20 00:22:44.749163
learning rate:  0.001
netparams have been saved once 8
val: 1 0.6269881129264832
val: 2 0.623144268989563
val: 3 0.6232708096504211
val: 4 0.6218312978744507
val: 5 0.6213459372520447
val: 6 0.6269720792770386
val: 7 0.6244778633117676
val: 8 0.6401311159133911
val: 9 0.630073070526123
val: 10 0.6322144865989685
val: 11 0.6249983310699463
val: 12 0.62227863073349
val: 13 0.6168676018714905
val: 14 0.625979483127594
val: 15 0.6180098652839661
val: 16 0.6274159550666809
val: 17 0.6256697773933411
val: 18 0.6258665919303894
val: 19 0.6268445253372192
val: 20 0.6314442157745361
val_Epoch:[ 8 ] val_loss: 0.6257912009954453 2022-07-20 00:22:47.913864
start training 2022-07-20 00:22:48.011990
Epoch:[ 9 0 ] loss: 0.5049250721931458 2022-07-20 00:23:01.909559
Epoch:[ 9 1 ] loss: 0.499172180891037 2022-07-20 00:23:02.328063
Epoch:[ 9 2 ] loss: 0.5001877546310425 2022-07-20 00:23:02.741386
Epoch:[ 9 3 ] loss: 0.49942460656166077 2022-07-20 00:23:03.154310
Epoch:[ 9 4 ] loss: 0.4982038736343384 2022-07-20 00:23:03.566782
Epoch:[ 9 5 ] loss: 0.49577489495277405 2022-07-20 00:23:03.979181
Epoch:[ 9 6 ] loss: 0.4975324869155884 2022-07-20 00:23:04.394772
Epoch:[ 9 7 ] loss: 0.493799090385437 2022-07-20 00:23:04.809111
Epoch:[ 9 8 ] loss: 0.49464350938796997 2022-07-20 00:23:05.222821
Epoch:[ 9 9 ] loss: 0.4913313388824463 2022-07-20 00:23:05.638045
Epoch:[ 9 10 ] loss: 0.4925297796726227 2022-07-20 00:23:06.057637
Epoch:[ 9 11 ] loss: 0.49088290333747864 2022-07-20 00:23:06.470289
Epoch:[ 9 12 ] loss: 0.48860955238342285 2022-07-20 00:23:06.883373
Epoch:[ 9 13 ] loss: 0.4880334436893463 2022-07-20 00:23:07.303246
Epoch:[ 9 14 ] loss: 0.486049085855484 2022-07-20 00:23:07.720917
Epoch:[ 9 15 ] loss: 0.48739784955978394 2022-07-20 00:23:08.136011
Epoch:[ 9 16 ] loss: 0.4872264266014099 2022-07-20 00:23:13.169529
Epoch:[ 9 17 ] loss: 0.4844188094139099 2022-07-20 00:23:13.756756
Epoch:[ 9 18 ] loss: 0.4867512285709381 2022-07-20 00:23:14.170969
Epoch:[ 9 19 ] loss: 0.48435717821121216 2022-07-20 00:23:14.583252
Training_Epoch:[ 9 ] Training_loss: 0.4925625532865524 2022-07-20 00:23:14.583899
learning rate:  0.001
val: 1 0.587801992893219
val: 2 0.5910866260528564
val: 3 0.5825567841529846
val: 4 0.5843470096588135
val: 5 0.6027856469154358
val: 6 0.5911632180213928
val: 7 0.5884913802146912
val: 8 0.5861144661903381
val: 9 0.581354558467865
val: 10 0.5803143978118896
val: 11 0.585472822189331
val: 12 0.5898845791816711
val: 13 0.6054684519767761
val: 14 0.5776596069335938
val: 15 0.5869549512863159
val: 16 0.5885940790176392
val: 17 0.5860819816589355
val: 18 0.5863932371139526
val: 19 0.5795003175735474
val: 20 0.5930647850036621
val_Epoch:[ 9 ] val_loss: 0.5877545446157455 2022-07-20 00:23:17.711994
start training 2022-07-20 00:23:17.815192
Epoch:[ 10 0 ] loss: 0.48158976435661316 2022-07-20 00:23:31.313562
Epoch:[ 10 1 ] loss: 0.48244428634643555 2022-07-20 00:23:31.977377
Epoch:[ 10 2 ] loss: 0.48517727851867676 2022-07-20 00:23:32.390359
Epoch:[ 10 3 ] loss: 0.48288494348526 2022-07-20 00:23:32.805540
Epoch:[ 10 4 ] loss: 0.48279017210006714 2022-07-20 00:23:33.218037
Epoch:[ 10 5 ] loss: 0.48265984654426575 2022-07-20 00:23:33.631259
Epoch:[ 10 6 ] loss: 0.4816293716430664 2022-07-20 00:23:34.045682
Epoch:[ 10 7 ] loss: 0.49263155460357666 2022-07-20 00:23:34.465020
Epoch:[ 10 8 ] loss: 0.4916759133338928 2022-07-20 00:23:34.878072
Epoch:[ 10 9 ] loss: 0.4885781407356262 2022-07-20 00:23:35.291092
Epoch:[ 10 10 ] loss: 0.4955194890499115 2022-07-20 00:23:35.706049
Epoch:[ 10 11 ] loss: 0.4942789375782013 2022-07-20 00:23:36.120595
Epoch:[ 10 12 ] loss: 0.4873890280723572 2022-07-20 00:23:36.534027
Epoch:[ 10 13 ] loss: 0.4889408051967621 2022-07-20 00:23:36.949411
Epoch:[ 10 14 ] loss: 0.48764660954475403 2022-07-20 00:23:37.365124
Epoch:[ 10 15 ] loss: 0.4907393455505371 2022-07-20 00:23:37.779881
Epoch:[ 10 16 ] loss: 0.485442191362381 2022-07-20 00:23:42.922711
Epoch:[ 10 17 ] loss: 0.4871419370174408 2022-07-20 00:23:43.337037
Epoch:[ 10 18 ] loss: 0.4838842749595642 2022-07-20 00:23:43.757270
Epoch:[ 10 19 ] loss: 0.48553839325904846 2022-07-20 00:23:44.170817
Training_Epoch:[ 10 ] Training_loss: 0.4869291141629219 2022-07-20 00:23:44.171442
learning rate:  0.001
netparams have been saved once 10
val: 1 0.5027273297309875
val: 2 0.49726349115371704
val: 3 0.49316728115081787
val: 4 0.4981508255004883
val: 5 0.4909912645816803
val: 6 0.5012155175209045
val: 7 0.5045987963676453
val: 8 0.5044475197792053
val: 9 0.49782395362854004
val: 10 0.49991166591644287
val: 11 0.5000660419464111
val: 12 0.502653181552887
val: 13 0.5071268677711487
val: 14 0.49975141882896423
val: 15 0.5011743903160095
val: 16 0.4972565770149231
val: 17 0.5010151863098145
val: 18 0.5103890299797058
val: 19 0.501280665397644
val: 20 0.49556872248649597
val_Epoch:[ 10 ] val_loss: 0.5003289863467216 2022-07-20 00:23:47.339865
start training 2022-07-20 00:23:47.434683
Epoch:[ 11 0 ] loss: 0.4860374927520752 2022-07-20 00:24:01.336579
Epoch:[ 11 1 ] loss: 0.48233744502067566 2022-07-20 00:24:01.749774
Epoch:[ 11 2 ] loss: 0.4780881106853485 2022-07-20 00:24:02.163612
Epoch:[ 11 3 ] loss: 0.4791642129421234 2022-07-20 00:24:02.579931
Epoch:[ 11 4 ] loss: 0.47924357652664185 2022-07-20 00:24:02.998997
Epoch:[ 11 5 ] loss: 0.48108556866645813 2022-07-20 00:24:03.417723
Epoch:[ 11 6 ] loss: 0.4759272634983063 2022-07-20 00:24:03.832127
Epoch:[ 11 7 ] loss: 0.47519510984420776 2022-07-20 00:24:04.244846
Epoch:[ 11 8 ] loss: 0.48047125339508057 2022-07-20 00:24:04.659025
Epoch:[ 11 9 ] loss: 0.4750380516052246 2022-07-20 00:24:05.072269
Epoch:[ 11 10 ] loss: 0.47993436455726624 2022-07-20 00:24:05.490450
Epoch:[ 11 11 ] loss: 0.48201119899749756 2022-07-20 00:24:05.904482
Epoch:[ 11 12 ] loss: 0.47835513949394226 2022-07-20 00:24:06.316308
Epoch:[ 11 13 ] loss: 0.48084384202957153 2022-07-20 00:24:06.728640
Epoch:[ 11 14 ] loss: 0.4778745472431183 2022-07-20 00:24:07.144015
Epoch:[ 11 15 ] loss: 0.48006343841552734 2022-07-20 00:24:07.558162
Epoch:[ 11 16 ] loss: 0.47768640518188477 2022-07-20 00:24:12.653510
Epoch:[ 11 17 ] loss: 0.4768439829349518 2022-07-20 00:24:13.069687
Epoch:[ 11 18 ] loss: 0.47472885251045227 2022-07-20 00:24:13.482972
Epoch:[ 11 19 ] loss: 0.47470608353614807 2022-07-20 00:24:13.896683
Training_Epoch:[ 11 ] Training_loss: 0.4787817969918251 2022-07-20 00:24:13.897308
learning rate:  0.00085
val: 1 0.5001764297485352
val: 2 0.4949304759502411
val: 3 0.49094250798225403
val: 4 0.5053837895393372
val: 5 0.496797114610672
val: 6 0.5036410689353943
val: 7 0.5003040432929993
val: 8 0.505545437335968
val: 9 0.5046023726463318
val: 10 0.49038976430892944
val: 11 0.5031769871711731
val: 12 0.5008432865142822
val: 13 0.5098288655281067
val: 14 0.5014725923538208
val: 15 0.4976976215839386
val: 16 0.48409050703048706
val: 17 0.4967566430568695
val: 18 0.5008679628372192
val: 19 0.4937339127063751
val: 20 0.5028950572013855
val_Epoch:[ 11 ] val_loss: 0.499203822016716 2022-07-20 00:24:17.004303
start training 2022-07-20 00:24:17.098947
Epoch:[ 12 0 ] loss: 0.4741525948047638 2022-07-20 00:24:30.632135
Epoch:[ 12 1 ] loss: 0.47515061497688293 2022-07-20 00:24:31.053817
Epoch:[ 12 2 ] loss: 0.47133585810661316 2022-07-20 00:24:31.472639
Epoch:[ 12 3 ] loss: 0.4730025827884674 2022-07-20 00:24:31.888173
Epoch:[ 12 4 ] loss: 0.4718969166278839 2022-07-20 00:24:32.300454
Epoch:[ 12 5 ] loss: 0.4701603651046753 2022-07-20 00:24:32.713611
Epoch:[ 12 6 ] loss: 0.4780380427837372 2022-07-20 00:24:33.126371
Epoch:[ 12 7 ] loss: 0.47233086824417114 2022-07-20 00:24:33.537281
Epoch:[ 12 8 ] loss: 0.4748607873916626 2022-07-20 00:24:33.948730
Epoch:[ 12 9 ] loss: 0.4695034325122833 2022-07-20 00:24:34.362224
Epoch:[ 12 10 ] loss: 0.47249719500541687 2022-07-20 00:24:34.775705
Epoch:[ 12 11 ] loss: 0.4698757827281952 2022-07-20 00:24:35.187760
Epoch:[ 12 12 ] loss: 0.47178778052330017 2022-07-20 00:24:35.604727
Epoch:[ 12 13 ] loss: 0.4671747386455536 2022-07-20 00:24:36.016243
Epoch:[ 12 14 ] loss: 0.46404731273651123 2022-07-20 00:24:36.428236
Epoch:[ 12 15 ] loss: 0.46392837166786194 2022-07-20 00:24:36.839713
Epoch:[ 12 16 ] loss: 0.46510612964630127 2022-07-20 00:24:42.205477
Epoch:[ 12 17 ] loss: 0.46292075514793396 2022-07-20 00:24:42.617687
Epoch:[ 12 18 ] loss: 0.463985800743103 2022-07-20 00:24:43.031390
Epoch:[ 12 19 ] loss: 0.465023398399353 2022-07-20 00:24:43.441737
Training_Epoch:[ 12 ] Training_loss: 0.46983896642923356 2022-07-20 00:24:43.442343
learning rate:  0.00085
netparams have been saved once 12
val: 1 0.4715331792831421
val: 2 0.47103169560432434
val: 3 0.4661913514137268
val: 4 0.4666273295879364
val: 5 0.4728103280067444
val: 6 0.4766283631324768
val: 7 0.47092965245246887
val: 8 0.47237032651901245
val: 9 0.45896050333976746
val: 10 0.47991886734962463
val: 11 0.4661880135536194
val: 12 0.4684593677520752
val: 13 0.4654398262500763
val: 14 0.4676036834716797
val: 15 0.45949938893318176
val: 16 0.465564101934433
val: 17 0.4781349301338196
val: 18 0.47427019476890564
val: 19 0.469573050737381
val: 20 0.46417227387428284
val_Epoch:[ 12 ] val_loss: 0.4692953214049339 2022-07-20 00:24:46.627328
start training 2022-07-20 00:24:46.722263
Epoch:[ 13 0 ] loss: 0.46055105328559875 2022-07-20 00:25:00.610382
Epoch:[ 13 1 ] loss: 0.4628056585788727 2022-07-20 00:25:01.027952
Epoch:[ 13 2 ] loss: 0.46319159865379333 2022-07-20 00:25:01.442420
Epoch:[ 13 3 ] loss: 0.4596763551235199 2022-07-20 00:25:01.862249
Epoch:[ 13 4 ] loss: 0.4619184732437134 2022-07-20 00:25:02.275431
Epoch:[ 13 5 ] loss: 0.4631248116493225 2022-07-20 00:25:02.687929
Epoch:[ 13 6 ] loss: 0.4615086019039154 2022-07-20 00:25:03.102804
Epoch:[ 13 7 ] loss: 0.4576338231563568 2022-07-20 00:25:03.516642
Epoch:[ 13 8 ] loss: 0.45918381214141846 2022-07-20 00:25:03.936257
Epoch:[ 13 9 ] loss: 0.4608699679374695 2022-07-20 00:25:04.347723
Epoch:[ 13 10 ] loss: 0.45894554257392883 2022-07-20 00:25:04.762319
Epoch:[ 13 11 ] loss: 0.4601272642612457 2022-07-20 00:25:05.177300
Epoch:[ 13 12 ] loss: 0.45828375220298767 2022-07-20 00:25:05.588176
Epoch:[ 13 13 ] loss: 0.45814359188079834 2022-07-20 00:25:06.003693
Epoch:[ 13 14 ] loss: 0.4534507691860199 2022-07-20 00:25:06.416813
Epoch:[ 13 15 ] loss: 0.45679983496665955 2022-07-20 00:25:06.830365
Epoch:[ 13 16 ] loss: 0.4555394947528839 2022-07-20 00:25:11.647631
Epoch:[ 13 17 ] loss: 0.4539368748664856 2022-07-20 00:25:12.081174
Epoch:[ 13 18 ] loss: 0.45904895663261414 2022-07-20 00:25:12.499379
Epoch:[ 13 19 ] loss: 0.45602768659591675 2022-07-20 00:25:12.911213
Training_Epoch:[ 13 ] Training_loss: 0.45903839617967607 2022-07-20 00:25:12.911892
learning rate:  0.00085
val: 1 0.46490412950515747
val: 2 0.46992284059524536
val: 3 0.4633268713951111
val: 4 0.4650746285915375
val: 5 0.46230843663215637
val: 6 0.4687032103538513
val: 7 0.46011093258857727
val: 8 0.46367618441581726
val: 9 0.469867467880249
val: 10 0.46696868538856506
val: 11 0.46909603476524353
val: 12 0.4563107192516327
val: 13 0.47302839159965515
val: 14 0.46817338466644287
val: 15 0.4690048396587372
val: 16 0.4628598988056183
val: 17 0.4677361249923706
val: 18 0.4648612141609192
val: 19 0.4634414613246918
val: 20 0.4677218794822693
val_Epoch:[ 13 ] val_loss: 0.4658548668026924 2022-07-20 00:25:16.051321
start training 2022-07-20 00:25:16.149625
Epoch:[ 14 0 ] loss: 0.4557988941669464 2022-07-20 00:25:29.732336
Epoch:[ 14 1 ] loss: 0.4585103988647461 2022-07-20 00:25:30.167604
Epoch:[ 14 2 ] loss: 0.4572013020515442 2022-07-20 00:25:30.580930
Epoch:[ 14 3 ] loss: 0.4573325216770172 2022-07-20 00:25:30.992839
Epoch:[ 14 4 ] loss: 0.4539622366428375 2022-07-20 00:25:31.406555
Epoch:[ 14 5 ] loss: 0.4522964060306549 2022-07-20 00:25:31.823395
Epoch:[ 14 6 ] loss: 0.45517146587371826 2022-07-20 00:25:32.240185
Epoch:[ 14 7 ] loss: 0.4554642140865326 2022-07-20 00:25:32.654327
Epoch:[ 14 8 ] loss: 0.45224058628082275 2022-07-20 00:25:33.067190
Epoch:[ 14 9 ] loss: 0.4524645507335663 2022-07-20 00:25:33.481214
Epoch:[ 14 10 ] loss: 0.45397961139678955 2022-07-20 00:25:33.893545
Epoch:[ 14 11 ] loss: 0.45367366075515747 2022-07-20 00:25:34.307294
Epoch:[ 14 12 ] loss: 0.4523463249206543 2022-07-20 00:25:34.721672
Epoch:[ 14 13 ] loss: 0.4542340934276581 2022-07-20 00:25:35.139590
Epoch:[ 14 14 ] loss: 0.45110538601875305 2022-07-20 00:25:35.558907
Epoch:[ 14 15 ] loss: 0.45415037870407104 2022-07-20 00:25:35.972541
Epoch:[ 14 16 ] loss: 0.4536246657371521 2022-07-20 00:25:41.055428
Epoch:[ 14 17 ] loss: 0.452129602432251 2022-07-20 00:25:41.489090
Epoch:[ 14 18 ] loss: 0.4558790326118469 2022-07-20 00:25:41.909870
Epoch:[ 14 19 ] loss: 0.4559090733528137 2022-07-20 00:25:42.324589
Training_Epoch:[ 14 ] Training_loss: 0.45437372028827666 2022-07-20 00:25:42.325201
learning rate:  0.00085
netparams have been saved once 14
val: 1 0.46738654375076294
val: 2 0.4566457271575928
val: 3 0.4632708728313446
val: 4 0.46168768405914307
val: 5 0.45860058069229126
val: 6 0.45642462372779846
val: 7 0.46297121047973633
val: 8 0.45492273569107056
val: 9 0.4595579206943512
val: 10 0.46266332268714905
val: 11 0.4589860737323761
val: 12 0.4581146538257599
val: 13 0.4568069577217102
val: 14 0.45422378182411194
val: 15 0.4626941978931427
val: 16 0.45864272117614746
val: 17 0.4567766785621643
val: 18 0.4579624533653259
val: 19 0.4548749327659607
val: 20 0.4628887474536896
val_Epoch:[ 14 ] val_loss: 0.45930512100458143 2022-07-20 00:25:45.538699
start training 2022-07-20 00:25:45.637951
Epoch:[ 15 0 ] loss: 0.4531896412372589 2022-07-20 00:25:59.323983
Epoch:[ 15 1 ] loss: 0.45547130703926086 2022-07-20 00:25:59.943726
Epoch:[ 15 2 ] loss: 0.4486023187637329 2022-07-20 00:26:00.356056
Epoch:[ 15 3 ] loss: 0.4531007707118988 2022-07-20 00:26:00.773331
Epoch:[ 15 4 ] loss: 0.4510786831378937 2022-07-20 00:26:01.185210
Epoch:[ 15 5 ] loss: 0.4503210186958313 2022-07-20 00:26:01.598776
Epoch:[ 15 6 ] loss: 0.4517684578895569 2022-07-20 00:26:02.013881
Epoch:[ 15 7 ] loss: 0.44754543900489807 2022-07-20 00:26:02.427432
Epoch:[ 15 8 ] loss: 0.4505580961704254 2022-07-20 00:26:02.840172
Epoch:[ 15 9 ] loss: 0.4465875029563904 2022-07-20 00:26:03.257924
Epoch:[ 15 10 ] loss: 0.45076197385787964 2022-07-20 00:26:03.670981
Epoch:[ 15 11 ] loss: 0.4498741328716278 2022-07-20 00:26:04.082745
Epoch:[ 15 12 ] loss: 0.45060163736343384 2022-07-20 00:26:04.495705
Epoch:[ 15 13 ] loss: 0.4511938691139221 2022-07-20 00:26:04.908571
Epoch:[ 15 14 ] loss: 0.4487290382385254 2022-07-20 00:26:05.320716
Epoch:[ 15 15 ] loss: 0.44772425293922424 2022-07-20 00:26:05.735363
Epoch:[ 15 16 ] loss: 0.44750848412513733 2022-07-20 00:26:10.928102
Epoch:[ 15 17 ] loss: 0.4494248330593109 2022-07-20 00:26:11.341053
Epoch:[ 15 18 ] loss: 0.44896218180656433 2022-07-20 00:26:11.754132
Epoch:[ 15 19 ] loss: 0.44887611269950867 2022-07-20 00:26:12.171714
Training_Epoch:[ 15 ] Training_loss: 0.45009398758411406 2022-07-20 00:26:12.172372
learning rate:  0.00085
val: 1 0.4415701925754547
val: 2 0.4491126239299774
val: 3 0.45422041416168213
val: 4 0.4580128490924835
val: 5 0.4582531154155731
val: 6 0.45001792907714844
val: 7 0.447599321603775
val: 8 0.4568719267845154
val: 9 0.44798192381858826
val: 10 0.44765570759773254
val: 11 0.4510943293571472
val: 12 0.45308929681777954
val: 13 0.45562076568603516
val: 14 0.45641371607780457
val: 15 0.4464510381221771
val: 16 0.4496641159057617
val: 17 0.4479605257511139
val: 18 0.45605239272117615
val: 19 0.4549887478351593
val: 20 0.4458284378051758
val_Epoch:[ 15 ] val_loss: 0.45142296850681307 2022-07-20 00:26:15.253174
start training 2022-07-20 00:26:15.349673
Epoch:[ 16 0 ] loss: 0.4483417272567749 2022-07-20 00:26:29.331600
Epoch:[ 16 1 ] loss: 0.44529691338539124 2022-07-20 00:26:29.743804
Epoch:[ 16 2 ] loss: 0.44695597887039185 2022-07-20 00:26:30.156291
Epoch:[ 16 3 ] loss: 0.445841908454895 2022-07-20 00:26:30.575866
Epoch:[ 16 4 ] loss: 0.4464927613735199 2022-07-20 00:26:30.988358
Epoch:[ 16 5 ] loss: 0.44471657276153564 2022-07-20 00:26:31.402692
Epoch:[ 16 6 ] loss: 0.44122594594955444 2022-07-20 00:26:31.816970
Epoch:[ 16 7 ] loss: 0.4454246461391449 2022-07-20 00:26:32.230119
Epoch:[ 16 8 ] loss: 0.44820085167884827 2022-07-20 00:26:32.642314
Epoch:[ 16 9 ] loss: 0.4456350803375244 2022-07-20 00:26:33.054449
Epoch:[ 16 10 ] loss: 0.4453658163547516 2022-07-20 00:26:33.467849
Epoch:[ 16 11 ] loss: 0.4436967670917511 2022-07-20 00:26:33.880282
Epoch:[ 16 12 ] loss: 0.4427871108055115 2022-07-20 00:26:34.298948
Epoch:[ 16 13 ] loss: 0.4453834891319275 2022-07-20 00:26:34.718824
Epoch:[ 16 14 ] loss: 0.44227051734924316 2022-07-20 00:26:35.134352
Epoch:[ 16 15 ] loss: 0.445727676153183 2022-07-20 00:26:35.547336
Epoch:[ 16 16 ] loss: 0.4444839358329773 2022-07-20 00:26:40.443688
Epoch:[ 16 17 ] loss: 0.44430920481681824 2022-07-20 00:26:40.855373
Epoch:[ 16 18 ] loss: 0.44543492794036865 2022-07-20 00:26:41.270293
Epoch:[ 16 19 ] loss: 0.442929744720459 2022-07-20 00:26:41.685495
Training_Epoch:[ 16 ] Training_loss: 0.4450260788202286 2022-07-20 00:26:41.686176
learning rate:  0.00085
netparams have been saved once 16
val: 1 0.4589574337005615
val: 2 0.46497443318367004
val: 3 0.45888522267341614
val: 4 0.4590994417667389
val: 5 0.46536824107170105
val: 6 0.45911240577697754
val: 7 0.454520046710968
val: 8 0.45885029435157776
val: 9 0.45571306347846985
val: 10 0.46761655807495117
val: 11 0.4560011923313141
val: 12 0.4571869373321533
val: 13 0.4563307464122772
val: 14 0.4607875943183899
val: 15 0.45490893721580505
val: 16 0.45434847474098206
val: 17 0.4591319262981415
val: 18 0.4635734260082245
val: 19 0.46440088748931885
val: 20 0.46454742550849915
val_Epoch:[ 16 ] val_loss: 0.45971573442220687 2022-07-20 00:26:44.913692
start training 2022-07-20 00:26:45.012460
Epoch:[ 17 0 ] loss: 0.4432147443294525 2022-07-20 00:26:58.921972
Epoch:[ 17 1 ] loss: 0.44254225492477417 2022-07-20 00:26:59.335633
Epoch:[ 17 2 ] loss: 0.4435446560382843 2022-07-20 00:26:59.749270
Epoch:[ 17 3 ] loss: 0.44037291407585144 2022-07-20 00:27:00.167685
Epoch:[ 17 4 ] loss: 0.4419977068901062 2022-07-20 00:27:00.585689
Epoch:[ 17 5 ] loss: 0.44227397441864014 2022-07-20 00:27:00.999235
Epoch:[ 17 6 ] loss: 0.43952247500419617 2022-07-20 00:27:01.412598
Epoch:[ 17 7 ] loss: 0.441254198551178 2022-07-20 00:27:01.834117
Epoch:[ 17 8 ] loss: 0.4419940710067749 2022-07-20 00:27:02.248504
Epoch:[ 17 9 ] loss: 0.44623565673828125 2022-07-20 00:27:02.663621
Epoch:[ 17 10 ] loss: 0.44339683651924133 2022-07-20 00:27:03.079544
Epoch:[ 17 11 ] loss: 0.4465961456298828 2022-07-20 00:27:03.494155
Epoch:[ 17 12 ] loss: 0.4431368410587311 2022-07-20 00:27:03.908262
Epoch:[ 17 13 ] loss: 0.445077121257782 2022-07-20 00:27:04.321348
Epoch:[ 17 14 ] loss: 0.44535568356513977 2022-07-20 00:27:04.735211
Epoch:[ 17 15 ] loss: 0.44080108404159546 2022-07-20 00:27:05.152409
Epoch:[ 17 16 ] loss: 0.4449993669986725 2022-07-20 00:27:10.821548
Epoch:[ 17 17 ] loss: 0.4433321952819824 2022-07-20 00:27:11.238434
Epoch:[ 17 18 ] loss: 0.44211629033088684 2022-07-20 00:27:11.654488
Epoch:[ 17 19 ] loss: 0.4447006583213806 2022-07-20 00:27:12.067274
Training_Epoch:[ 17 ] Training_loss: 0.4431232437491417 2022-07-20 00:27:12.067933
learning rate:  0.00085
val: 1 0.45266610383987427
val: 2 0.45782920718193054
val: 3 0.43971583247184753
val: 4 0.4608396291732788
val: 5 0.4492707848548889
val: 6 0.45466217398643494
val: 7 0.4536168873310089
val: 8 0.46530598402023315
val: 9 0.4554675817489624
val: 10 0.45354756712913513
val: 11 0.452867329120636
val: 12 0.4574660360813141
val: 13 0.46061524748802185
val: 14 0.45741117000579834
val: 15 0.44807252287864685
val: 16 0.4494650065898895
val: 17 0.4590075612068176
val: 18 0.4547305405139923
val: 19 0.4533211290836334
val: 20 0.45595288276672363
val_Epoch:[ 17 ] val_loss: 0.45459155887365343 2022-07-20 00:27:15.157903
start training 2022-07-20 00:27:15.258841
Epoch:[ 18 0 ] loss: 0.44123169779777527 2022-07-20 00:27:28.770223
Epoch:[ 18 1 ] loss: 0.4422760009765625 2022-07-20 00:27:29.186394
Epoch:[ 18 2 ] loss: 0.44312483072280884 2022-07-20 00:27:29.604619
Epoch:[ 18 3 ] loss: 0.439050555229187 2022-07-20 00:27:30.016646
Epoch:[ 18 4 ] loss: 0.4438633620738983 2022-07-20 00:27:30.429342
Epoch:[ 18 5 ] loss: 0.44047999382019043 2022-07-20 00:27:30.841563
Epoch:[ 18 6 ] loss: 0.44229578971862793 2022-07-20 00:27:31.258660
Epoch:[ 18 7 ] loss: 0.44023141264915466 2022-07-20 00:27:31.671819
Epoch:[ 18 8 ] loss: 0.4407694637775421 2022-07-20 00:27:32.085372
Epoch:[ 18 9 ] loss: 0.44121992588043213 2022-07-20 00:27:32.499941
Epoch:[ 18 10 ] loss: 0.4383765757083893 2022-07-20 00:27:32.911597
Epoch:[ 18 11 ] loss: 0.43837645649909973 2022-07-20 00:27:33.325423
Epoch:[ 18 12 ] loss: 0.43841353058815 2022-07-20 00:27:33.737148
Epoch:[ 18 13 ] loss: 0.43571409583091736 2022-07-20 00:27:34.149536
Epoch:[ 18 14 ] loss: 0.4414079189300537 2022-07-20 00:27:34.562084
Epoch:[ 18 15 ] loss: 0.4378690719604492 2022-07-20 00:27:34.976484
Epoch:[ 18 16 ] loss: 0.4389532804489136 2022-07-20 00:27:40.185168
Epoch:[ 18 17 ] loss: 0.4384399354457855 2022-07-20 00:27:40.629383
Epoch:[ 18 18 ] loss: 0.43641799688339233 2022-07-20 00:27:41.046100
Epoch:[ 18 19 ] loss: 0.4362837076187134 2022-07-20 00:27:41.459496
Training_Epoch:[ 18 ] Training_loss: 0.4397397801280022 2022-07-20 00:27:41.460149
learning rate:  0.00085
netparams have been saved once 18
val: 1 0.44291356205940247
val: 2 0.44098109006881714
val: 3 0.4440874457359314
val: 4 0.4456750452518463
val: 5 0.44473811984062195
val: 6 0.4374057948589325
val: 7 0.4439607560634613
val: 8 0.4453178942203522
val: 9 0.44328078627586365
val: 10 0.4442628026008606
val: 11 0.4437919855117798
val: 12 0.4482050836086273
val: 13 0.4484746754169464
val: 14 0.44922536611557007
val: 15 0.43804773688316345
val: 16 0.4512464106082916
val: 17 0.4397552013397217
val: 18 0.44697341322898865
val: 19 0.4483173191547394
val: 20 0.4512406289577484
val_Epoch:[ 18 ] val_loss: 0.4448950558900833 2022-07-20 00:27:44.668500
start training 2022-07-20 00:27:44.768094
Epoch:[ 19 0 ] loss: 0.43961620330810547 2022-07-20 00:27:58.036750
Epoch:[ 19 1 ] loss: 0.4337432086467743 2022-07-20 00:27:58.994188
Epoch:[ 19 2 ] loss: 0.43983006477355957 2022-07-20 00:27:59.408229
Epoch:[ 19 3 ] loss: 0.43614158034324646 2022-07-20 00:27:59.822475
Epoch:[ 19 4 ] loss: 0.43781083822250366 2022-07-20 00:28:00.234939
Epoch:[ 19 5 ] loss: 0.4338752031326294 2022-07-20 00:28:00.647314
Epoch:[ 19 6 ] loss: 0.43771785497665405 2022-07-20 00:28:01.060945
Epoch:[ 19 7 ] loss: 0.4355681836605072 2022-07-20 00:28:01.475413
Epoch:[ 19 8 ] loss: 0.4364371597766876 2022-07-20 00:28:01.887338
Epoch:[ 19 9 ] loss: 0.4360896050930023 2022-07-20 00:28:02.300894
Epoch:[ 19 10 ] loss: 0.4364793598651886 2022-07-20 00:28:02.714785
Epoch:[ 19 11 ] loss: 0.4372783601284027 2022-07-20 00:28:03.128166
Epoch:[ 19 12 ] loss: 0.4363972842693329 2022-07-20 00:28:03.539468
Epoch:[ 19 13 ] loss: 0.43335649371147156 2022-07-20 00:28:03.954263
Epoch:[ 19 14 ] loss: 0.436775803565979 2022-07-20 00:28:04.367586
Epoch:[ 19 15 ] loss: 0.4385245442390442 2022-07-20 00:28:04.784887
Epoch:[ 19 16 ] loss: 0.4339922070503235 2022-07-20 00:28:10.029181
Epoch:[ 19 17 ] loss: 0.43548163771629333 2022-07-20 00:28:10.450765
Epoch:[ 19 18 ] loss: 0.43856972455978394 2022-07-20 00:28:10.866465
Epoch:[ 19 19 ] loss: 0.4381294548511505 2022-07-20 00:28:11.280482
Training_Epoch:[ 19 ] Training_loss: 0.436590738594532 2022-07-20 00:28:11.281153
learning rate:  0.00085
val: 1 0.43883463740348816
val: 2 0.4467862546443939
val: 3 0.44688916206359863
val: 4 0.4401894807815552
val: 5 0.4422658383846283
val: 6 0.4458620250225067
val: 7 0.44028517603874207
val: 8 0.44296184182167053
val: 9 0.44008180499076843
val: 10 0.4417424201965332
val: 11 0.446069598197937
val: 12 0.44394877552986145
val: 13 0.44060924649238586
val: 14 0.43566593527793884
val: 15 0.4439869523048401
val: 16 0.44089242815971375
val: 17 0.44597509503364563
val: 18 0.44883057475090027
val: 19 0.44414860010147095
val: 20 0.45089781284332275
val_Epoch:[ 19 ] val_loss: 0.4433461830019951 2022-07-20 00:28:14.338004
start training 2022-07-20 00:28:14.437685
Epoch:[ 20 0 ] loss: 0.4350150525569916 2022-07-20 00:28:28.391662
Epoch:[ 20 1 ] loss: 0.43424662947654724 2022-07-20 00:28:28.806284
Epoch:[ 20 2 ] loss: 0.4341493248939514 2022-07-20 00:28:29.218570
Epoch:[ 20 3 ] loss: 0.4344851076602936 2022-07-20 00:28:29.632995
Epoch:[ 20 4 ] loss: 0.43392398953437805 2022-07-20 00:28:30.048263
Epoch:[ 20 5 ] loss: 0.43515506386756897 2022-07-20 00:28:30.460680
Epoch:[ 20 6 ] loss: 0.435543417930603 2022-07-20 00:28:30.876361
Epoch:[ 20 7 ] loss: 0.4331747591495514 2022-07-20 00:28:31.290307
Epoch:[ 20 8 ] loss: 0.436428964138031 2022-07-20 00:28:31.702905
Epoch:[ 20 9 ] loss: 0.43386322259902954 2022-07-20 00:28:32.115572
Epoch:[ 20 10 ] loss: 0.4372149109840393 2022-07-20 00:28:32.530366
Epoch:[ 20 11 ] loss: 0.43357595801353455 2022-07-20 00:28:32.951030
Epoch:[ 20 12 ] loss: 0.4327950179576874 2022-07-20 00:28:33.369805
Epoch:[ 20 13 ] loss: 0.43404901027679443 2022-07-20 00:28:33.787581
Epoch:[ 20 14 ] loss: 0.430692195892334 2022-07-20 00:28:34.201839
Epoch:[ 20 15 ] loss: 0.4307982325553894 2022-07-20 00:28:34.615028
Epoch:[ 20 16 ] loss: 0.4359184205532074 2022-07-20 00:28:39.740212
Epoch:[ 20 17 ] loss: 0.43116867542266846 2022-07-20 00:28:40.152797
Epoch:[ 20 18 ] loss: 0.4330361783504486 2022-07-20 00:28:40.569354
Epoch:[ 20 19 ] loss: 0.43251028656959534 2022-07-20 00:28:40.986962
Training_Epoch:[ 20 ] Training_loss: 0.43388722091913223 2022-07-20 00:28:40.987606
learning rate:  0.00085
netparams have been saved once 20
val: 1 0.44087034463882446
val: 2 0.43685582280158997
val: 3 0.43410056829452515
val: 4 0.4327750504016876
val: 5 0.4401358366012573
val: 6 0.4434322714805603
val: 7 0.4467651844024658
val: 8 0.4420243501663208
val: 9 0.4414220154285431
val: 10 0.43619126081466675
val: 11 0.4351073205471039
val: 12 0.4380277395248413
val: 13 0.43287211656570435
val: 14 0.4384690821170807
val: 15 0.43841126561164856
val: 16 0.43618181347846985
val: 17 0.43195006251335144
val: 18 0.4342081844806671
val: 19 0.43869853019714355
val: 20 0.4364446997642517
val_Epoch:[ 20 ] val_loss: 0.4377471759915352 2022-07-20 00:28:44.181626
start training 2022-07-20 00:28:44.282969
Epoch:[ 21 0 ] loss: 0.4314194619655609 2022-07-20 00:28:57.539483
Epoch:[ 21 1 ] loss: 0.43219318985939026 2022-07-20 00:28:57.977018
Epoch:[ 21 2 ] loss: 0.4307515323162079 2022-07-20 00:28:58.410711
Epoch:[ 21 3 ] loss: 0.42941394448280334 2022-07-20 00:28:58.828467
Epoch:[ 21 4 ] loss: 0.43016481399536133 2022-07-20 00:28:59.242486
Epoch:[ 21 5 ] loss: 0.430450439453125 2022-07-20 00:28:59.656060
Epoch:[ 21 6 ] loss: 0.42915016412734985 2022-07-20 00:29:00.068201
Epoch:[ 21 7 ] loss: 0.43149882555007935 2022-07-20 00:29:00.481046
Epoch:[ 21 8 ] loss: 0.4304591417312622 2022-07-20 00:29:00.894791
Epoch:[ 21 9 ] loss: 0.43084967136383057 2022-07-20 00:29:01.312282
Epoch:[ 21 10 ] loss: 0.4288404881954193 2022-07-20 00:29:01.727179
Epoch:[ 21 11 ] loss: 0.4289696216583252 2022-07-20 00:29:02.141086
Epoch:[ 21 12 ] loss: 0.4310401678085327 2022-07-20 00:29:02.555717
Epoch:[ 21 13 ] loss: 0.4292832016944885 2022-07-20 00:29:02.970375
Epoch:[ 21 14 ] loss: 0.4272208511829376 2022-07-20 00:29:03.385256
Epoch:[ 21 15 ] loss: 0.4315255880355835 2022-07-20 00:29:03.797102
Epoch:[ 21 16 ] loss: 0.43205171823501587 2022-07-20 00:29:09.604624
Epoch:[ 21 17 ] loss: 0.4317750334739685 2022-07-20 00:29:10.016679
Epoch:[ 21 18 ] loss: 0.43143248558044434 2022-07-20 00:29:10.433540
Epoch:[ 21 19 ] loss: 0.43194010853767395 2022-07-20 00:29:10.854695
Training_Epoch:[ 21 ] Training_loss: 0.430521522462368 2022-07-20 00:29:10.855392
learning rate:  0.0007224999999999999
val: 1 0.4426153004169464
val: 2 0.4436078667640686
val: 3 0.4332301616668701
val: 4 0.43565279245376587
val: 5 0.4446280002593994
val: 6 0.431226521730423
val: 7 0.44614270329475403
val: 8 0.43281877040863037
val: 9 0.4402136206626892
val: 10 0.4363401234149933
val: 11 0.435533732175827
val: 12 0.4366734027862549
val: 13 0.4373322129249573
val: 14 0.42838504910469055
val: 15 0.4402937889099121
val: 16 0.43674543499946594
val: 17 0.43204736709594727
val: 18 0.4409787058830261
val: 19 0.4402524530887604
val: 20 0.43426042795181274
val_Epoch:[ 21 ] val_loss: 0.4374489217996597 2022-07-20 00:29:14.003765
start training 2022-07-20 00:29:14.106468
Epoch:[ 22 0 ] loss: 0.4295542538166046 2022-07-20 00:29:27.402432
Epoch:[ 22 1 ] loss: 0.4291374683380127 2022-07-20 00:29:28.049629
Epoch:[ 22 2 ] loss: 0.4296042323112488 2022-07-20 00:29:28.463615
Epoch:[ 22 3 ] loss: 0.4327273666858673 2022-07-20 00:29:28.875558
Epoch:[ 22 4 ] loss: 0.43111324310302734 2022-07-20 00:29:29.287906
Epoch:[ 22 5 ] loss: 0.4307691156864166 2022-07-20 00:29:29.707984
Epoch:[ 22 6 ] loss: 0.43016642332077026 2022-07-20 00:29:30.121453
Epoch:[ 22 7 ] loss: 0.42942866683006287 2022-07-20 00:29:30.534722
Epoch:[ 22 8 ] loss: 0.4319504201412201 2022-07-20 00:29:30.946060
Epoch:[ 22 9 ] loss: 0.42618948221206665 2022-07-20 00:29:31.358206
Epoch:[ 22 10 ] loss: 0.43356236815452576 2022-07-20 00:29:31.772517
Epoch:[ 22 11 ] loss: 0.43121665716171265 2022-07-20 00:29:32.187928
Epoch:[ 22 12 ] loss: 0.4271625876426697 2022-07-20 00:29:32.601368
Epoch:[ 22 13 ] loss: 0.42720088362693787 2022-07-20 00:29:33.020166
Epoch:[ 22 14 ] loss: 0.43024641275405884 2022-07-20 00:29:33.432464
Epoch:[ 22 15 ] loss: 0.42855650186538696 2022-07-20 00:29:33.845074
Epoch:[ 22 16 ] loss: 0.43051454424858093 2022-07-20 00:29:38.977978
Epoch:[ 22 17 ] loss: 0.43208274245262146 2022-07-20 00:29:39.391182
Epoch:[ 22 18 ] loss: 0.42901483178138733 2022-07-20 00:29:39.804391
Epoch:[ 22 19 ] loss: 0.4330301284790039 2022-07-20 00:29:40.224211
Training_Epoch:[ 22 ] Training_loss: 0.43016141653060913 2022-07-20 00:29:40.224862
learning rate:  0.0007224999999999999
netparams have been saved once 22
val: 1 0.44000083208084106
val: 2 0.4382273256778717
val: 3 0.4402432441711426
val: 4 0.43397271633148193
val: 5 0.44385603070259094
val: 6 0.4264422059059143
val: 7 0.4422236979007721
val: 8 0.44205644726753235
val: 9 0.4418734014034271
val: 10 0.4351816475391388
val: 11 0.4384690225124359
val: 12 0.4411797523498535
val: 13 0.4339434802532196
val: 14 0.4337162375450134
val: 15 0.43927237391471863
val: 16 0.44226765632629395
val: 17 0.4357345998287201
val: 18 0.4359179139137268
val: 19 0.4407232105731964
val: 20 0.43886464834213257
val_Epoch:[ 22 ] val_loss: 0.4382083222270012 2022-07-20 00:29:43.400095
start training 2022-07-20 00:29:43.496092
Epoch:[ 23 0 ] loss: 0.4305587410926819 2022-07-20 00:29:57.619832
Epoch:[ 23 1 ] loss: 0.42860278487205505 2022-07-20 00:29:58.033581
Epoch:[ 23 2 ] loss: 0.4317931532859802 2022-07-20 00:29:58.447225
Epoch:[ 23 3 ] loss: 0.42592257261276245 2022-07-20 00:29:58.860975
Epoch:[ 23 4 ] loss: 0.42917802929878235 2022-07-20 00:29:59.274730
Epoch:[ 23 5 ] loss: 0.4283994436264038 2022-07-20 00:29:59.686176
Epoch:[ 23 6 ] loss: 0.43053486943244934 2022-07-20 00:30:00.101684
Epoch:[ 23 7 ] loss: 0.4269125461578369 2022-07-20 00:30:00.516896
Epoch:[ 23 8 ] loss: 0.4261398911476135 2022-07-20 00:30:00.932319
Epoch:[ 23 9 ] loss: 0.42715248465538025 2022-07-20 00:30:01.343795
Epoch:[ 23 10 ] loss: 0.4252283573150635 2022-07-20 00:30:01.757841
Epoch:[ 23 11 ] loss: 0.4297889769077301 2022-07-20 00:30:02.171131
Epoch:[ 23 12 ] loss: 0.4283135235309601 2022-07-20 00:30:02.584613
Epoch:[ 23 13 ] loss: 0.42834174633026123 2022-07-20 00:30:02.995591
Epoch:[ 23 14 ] loss: 0.42689788341522217 2022-07-20 00:30:03.413386
Epoch:[ 23 15 ] loss: 0.4270404279232025 2022-07-20 00:30:03.831587
Epoch:[ 23 16 ] loss: 0.42558807134628296 2022-07-20 00:30:09.009448
Epoch:[ 23 17 ] loss: 0.42639511823654175 2022-07-20 00:30:09.423688
Epoch:[ 23 18 ] loss: 0.42513832449913025 2022-07-20 00:30:09.838895
Epoch:[ 23 19 ] loss: 0.42511266469955444 2022-07-20 00:30:10.247227
Training_Epoch:[ 23 ] Training_loss: 0.42765198051929476 2022-07-20 00:30:10.248113
learning rate:  0.0007224999999999999
val: 1 0.4302118122577667
val: 2 0.4236511290073395
val: 3 0.43243592977523804
val: 4 0.43539103865623474
val: 5 0.4393152892589569
val: 6 0.4332432150840759
val: 7 0.4249221384525299
val: 8 0.43177857995033264
val: 9 0.42376962304115295
val: 10 0.43121621012687683
val: 11 0.42562875151634216
val: 12 0.44069990515708923
val: 13 0.4369222819805145
val: 14 0.4254900813102722
val: 15 0.4335954785346985
val: 16 0.43196040391921997
val: 17 0.4345092475414276
val: 18 0.4379124641418457
val: 19 0.4312828481197357
val: 20 0.4331265985965729
val_Epoch:[ 23 ] val_loss: 0.4318531513214111 2022-07-20 00:30:13.494869
start training 2022-07-20 00:30:13.593150
Epoch:[ 24 0 ] loss: 0.4215870499610901 2022-07-20 00:30:27.232131
Epoch:[ 24 1 ] loss: 0.4279392957687378 2022-07-20 00:30:27.729167
Epoch:[ 24 2 ] loss: 0.42356443405151367 2022-07-20 00:30:28.143734
Epoch:[ 24 3 ] loss: 0.42694708704948425 2022-07-20 00:30:28.558295
Epoch:[ 24 4 ] loss: 0.4286342263221741 2022-07-20 00:30:28.973409
Epoch:[ 24 5 ] loss: 0.4269636273384094 2022-07-20 00:30:29.386902
Epoch:[ 24 6 ] loss: 0.4243403971195221 2022-07-20 00:30:29.798435
Epoch:[ 24 7 ] loss: 0.42764249444007874 2022-07-20 00:30:30.213324
Epoch:[ 24 8 ] loss: 0.42780205607414246 2022-07-20 00:30:30.629437
Epoch:[ 24 9 ] loss: 0.42427128553390503 2022-07-20 00:30:31.042837
Epoch:[ 24 10 ] loss: 0.428206205368042 2022-07-20 00:30:31.456534
Epoch:[ 24 11 ] loss: 0.4236472547054291 2022-07-20 00:30:31.871100
Epoch:[ 24 12 ] loss: 0.42680367827415466 2022-07-20 00:30:32.286410
Epoch:[ 24 13 ] loss: 0.42624160647392273 2022-07-20 00:30:32.703238
Epoch:[ 24 14 ] loss: 0.4262504577636719 2022-07-20 00:30:33.120044
Epoch:[ 24 15 ] loss: 0.4258969724178314 2022-07-20 00:30:33.531397
Epoch:[ 24 16 ] loss: 0.4248284697532654 2022-07-20 00:30:38.929320
Epoch:[ 24 17 ] loss: 0.4278985559940338 2022-07-20 00:30:39.340905
Epoch:[ 24 18 ] loss: 0.4262657165527344 2022-07-20 00:30:39.756361
Epoch:[ 24 19 ] loss: 0.4234374761581421 2022-07-20 00:30:40.170293
Training_Epoch:[ 24 ] Training_loss: 0.42595841735601425 2022-07-20 00:30:40.171084
learning rate:  0.0007224999999999999
netparams have been saved once 24
val: 1 0.44478312134742737
val: 2 0.4321546256542206
val: 3 0.44533777236938477
val: 4 0.42968660593032837
val: 5 0.430717796087265
val: 6 0.4363243281841278
val: 7 0.4358387589454651
val: 8 0.4356650412082672
val: 9 0.4369644522666931
val: 10 0.43695390224456787
val: 11 0.4268161952495575
val: 12 0.4252144992351532
val: 13 0.4388584494590759
val: 14 0.4352165758609772
val: 15 0.4315745234489441
val: 16 0.4354073107242584
val: 17 0.4286764860153198
val: 18 0.43495476245880127
val: 19 0.43067219853401184
val: 20 0.4332117438316345
val_Epoch:[ 24 ] val_loss: 0.43425145745277405 2022-07-20 00:30:43.400757
start training 2022-07-20 00:30:43.500939
Epoch:[ 25 0 ] loss: 0.42470866441726685 2022-07-20 00:30:57.979924
Epoch:[ 25 1 ] loss: 0.424317330121994 2022-07-20 00:30:58.391884
Epoch:[ 25 2 ] loss: 0.42565470933914185 2022-07-20 00:30:58.807539
Epoch:[ 25 3 ] loss: 0.4233410656452179 2022-07-20 00:30:59.224001
Epoch:[ 25 4 ] loss: 0.42408737540245056 2022-07-20 00:30:59.638314
Epoch:[ 25 5 ] loss: 0.42251408100128174 2022-07-20 00:31:00.052402
Epoch:[ 25 6 ] loss: 0.4236273467540741 2022-07-20 00:31:00.466790
Epoch:[ 25 7 ] loss: 0.4222927689552307 2022-07-20 00:31:00.879952
Epoch:[ 25 8 ] loss: 0.4232625365257263 2022-07-20 00:31:01.295216
Epoch:[ 25 9 ] loss: 0.4235228896141052 2022-07-20 00:31:01.706759
Epoch:[ 25 10 ] loss: 0.42383483052253723 2022-07-20 00:31:02.122090
Epoch:[ 25 11 ] loss: 0.4236554801464081 2022-07-20 00:31:02.538219
Epoch:[ 25 12 ] loss: 0.4213941991329193 2022-07-20 00:31:02.953132
Epoch:[ 25 13 ] loss: 0.42230287194252014 2022-07-20 00:31:03.363202
Epoch:[ 25 14 ] loss: 0.42143741250038147 2022-07-20 00:31:03.779711
Epoch:[ 25 15 ] loss: 0.42437943816185 2022-07-20 00:31:04.195621
Epoch:[ 25 16 ] loss: 0.4188859164714813 2022-07-20 00:31:09.311532
Epoch:[ 25 17 ] loss: 0.4235994815826416 2022-07-20 00:31:09.724747
Epoch:[ 25 18 ] loss: 0.4201345145702362 2022-07-20 00:31:10.134578
Epoch:[ 25 19 ] loss: 0.42473503947257996 2022-07-20 00:31:10.549121
Training_Epoch:[ 25 ] Training_loss: 0.42308439761400224 2022-07-20 00:31:10.549834
learning rate:  0.0007224999999999999
val: 1 0.430364191532135
val: 2 0.4335179924964905
val: 3 0.42692381143569946
val: 4 0.4300023317337036
val: 5 0.43629464507102966
val: 6 0.41945353150367737
val: 7 0.4254869222640991
val: 8 0.4384625256061554
val: 9 0.4336293935775757
val: 10 0.42813101410865784
val: 11 0.4270257353782654
val: 12 0.4216485917568207
val: 13 0.4240407645702362
val: 14 0.4358863830566406
val: 15 0.43734875321388245
val: 16 0.4300706088542938
val: 17 0.4314478635787964
val: 18 0.43551310896873474
val: 19 0.42962390184402466
val: 20 0.42890554666519165
val_Epoch:[ 25 ] val_loss: 0.43018888086080553 2022-07-20 00:31:13.754138
start training 2022-07-20 00:31:13.854875
Epoch:[ 26 0 ] loss: 0.420843243598938 2022-07-20 00:31:27.483558
Epoch:[ 26 1 ] loss: 0.4204199016094208 2022-07-20 00:31:27.897670
Epoch:[ 26 2 ] loss: 0.4197904169559479 2022-07-20 00:31:28.313471
Epoch:[ 26 3 ] loss: 0.4212345480918884 2022-07-20 00:31:28.726187
Epoch:[ 26 4 ] loss: 0.4188617467880249 2022-07-20 00:31:29.139917
Epoch:[ 26 5 ] loss: 0.42235279083251953 2022-07-20 00:31:29.552697
Epoch:[ 26 6 ] loss: 0.42085903882980347 2022-07-20 00:31:29.964444
Epoch:[ 26 7 ] loss: 0.4196062982082367 2022-07-20 00:31:30.377237
Epoch:[ 26 8 ] loss: 0.42012059688568115 2022-07-20 00:31:30.791980
Epoch:[ 26 9 ] loss: 0.42311811447143555 2022-07-20 00:31:31.206746
Epoch:[ 26 10 ] loss: 0.4185165464878082 2022-07-20 00:31:31.622150
Epoch:[ 26 11 ] loss: 0.4195311963558197 2022-07-20 00:31:32.035521
Epoch:[ 26 12 ] loss: 0.4206804931163788 2022-07-20 00:31:32.448204
Epoch:[ 26 13 ] loss: 0.419528990983963 2022-07-20 00:31:32.864199
Epoch:[ 26 14 ] loss: 0.4204954206943512 2022-07-20 00:31:33.279082
Epoch:[ 26 15 ] loss: 0.42163732647895813 2022-07-20 00:31:33.695014
Epoch:[ 26 16 ] loss: 0.42034390568733215 2022-07-20 00:31:39.271455
Epoch:[ 26 17 ] loss: 0.41994261741638184 2022-07-20 00:31:39.685089
Epoch:[ 26 18 ] loss: 0.4217008054256439 2022-07-20 00:31:40.099960
Epoch:[ 26 19 ] loss: 0.4209537208080292 2022-07-20 00:31:40.510499
Training_Epoch:[ 26 ] Training_loss: 0.42052688598632815 2022-07-20 00:31:40.511198
learning rate:  0.0007224999999999999
netparams have been saved once 26
val: 1 0.4377644658088684
val: 2 0.4327148497104645
val: 3 0.42342132329940796
val: 4 0.4313402473926544
val: 5 0.4279257357120514
val: 6 0.43996354937553406
val: 7 0.4357319474220276
val: 8 0.4295152723789215
val: 9 0.4332186281681061
val: 10 0.4202828109264374
val: 11 0.428115576505661
val: 12 0.4268191158771515
val: 13 0.43885350227355957
val: 14 0.43263161182403564
val: 15 0.44074323773384094
val: 16 0.4299929141998291
val: 17 0.4260171055793762
val: 18 0.4351399838924408
val: 19 0.4292709529399872
val: 20 0.43801450729370117
val_Epoch:[ 26 ] val_loss: 0.43187386691570284 2022-07-20 00:31:43.716093
start training 2022-07-20 00:31:43.812773
Epoch:[ 27 0 ] loss: 0.42022523283958435 2022-07-20 00:31:57.533627
Epoch:[ 27 1 ] loss: 0.41731300950050354 2022-07-20 00:31:57.953906
Epoch:[ 27 2 ] loss: 0.41939982771873474 2022-07-20 00:31:58.371200
Epoch:[ 27 3 ] loss: 0.4159736633300781 2022-07-20 00:31:58.787975
Epoch:[ 27 4 ] loss: 0.4186972677707672 2022-07-20 00:31:59.204432
Epoch:[ 27 5 ] loss: 0.4196162819862366 2022-07-20 00:31:59.618156
Epoch:[ 27 6 ] loss: 0.42173048853874207 2022-07-20 00:32:00.028386
Epoch:[ 27 7 ] loss: 0.4229389429092407 2022-07-20 00:32:00.442273
Epoch:[ 27 8 ] loss: 0.42181864380836487 2022-07-20 00:32:00.858108
Epoch:[ 27 9 ] loss: 0.4199985861778259 2022-07-20 00:32:01.270520
Epoch:[ 27 10 ] loss: 0.42285585403442383 2022-07-20 00:32:01.682102
Epoch:[ 27 11 ] loss: 0.41814079880714417 2022-07-20 00:32:02.096767
Epoch:[ 27 12 ] loss: 0.4185546934604645 2022-07-20 00:32:02.509834
Epoch:[ 27 13 ] loss: 0.4213055670261383 2022-07-20 00:32:02.925311
Epoch:[ 27 14 ] loss: 0.4187719523906708 2022-07-20 00:32:03.339842
Epoch:[ 27 15 ] loss: 0.4197494387626648 2022-07-20 00:32:03.754149
Epoch:[ 27 16 ] loss: 0.4194469153881073 2022-07-20 00:32:09.269356
Epoch:[ 27 17 ] loss: 0.41658830642700195 2022-07-20 00:32:09.683646
Epoch:[ 27 18 ] loss: 0.42114776372909546 2022-07-20 00:32:10.102594
Epoch:[ 27 19 ] loss: 0.4203420579433441 2022-07-20 00:32:10.512815
Training_Epoch:[ 27 ] Training_loss: 0.4197307646274567 2022-07-20 00:32:10.513505
learning rate:  0.0007224999999999999
val: 1 0.4241360127925873
val: 2 0.42053675651550293
val: 3 0.4293310344219208
val: 4 0.4234905540943146
val: 5 0.42795059084892273
val: 6 0.4196682274341583
val: 7 0.4206281304359436
val: 8 0.4293452799320221
val: 9 0.42375054955482483
val: 10 0.42754071950912476
val: 11 0.4255397617816925
val: 12 0.4202931821346283
val: 13 0.4276633858680725
val: 14 0.4251736104488373
val: 15 0.42306697368621826
val: 16 0.4284784495830536
val: 17 0.42472904920578003
val: 18 0.42834192514419556
val: 19 0.4232234060764313
val: 20 0.42605385184288025
val_Epoch:[ 27 ] val_loss: 0.4249470725655556 2022-07-20 00:32:13.718115
start training 2022-07-20 00:32:13.815849
Epoch:[ 28 0 ] loss: 0.4182949364185333 2022-07-20 00:32:27.398343
Epoch:[ 28 1 ] loss: 0.4203486144542694 2022-07-20 00:32:27.828557
Epoch:[ 28 2 ] loss: 0.4148193895816803 2022-07-20 00:32:28.243078
Epoch:[ 28 3 ] loss: 0.4194174110889435 2022-07-20 00:32:28.654517
Epoch:[ 28 4 ] loss: 0.4173595607280731 2022-07-20 00:32:29.067570
Epoch:[ 28 5 ] loss: 0.4172206223011017 2022-07-20 00:32:29.482933
Epoch:[ 28 6 ] loss: 0.41610464453697205 2022-07-20 00:32:29.900932
Epoch:[ 28 7 ] loss: 0.4201923608779907 2022-07-20 00:32:30.315309
Epoch:[ 28 8 ] loss: 0.4183257818222046 2022-07-20 00:32:30.726457
Epoch:[ 28 9 ] loss: 0.4170800447463989 2022-07-20 00:32:31.138447
Epoch:[ 28 10 ] loss: 0.41764363646507263 2022-07-20 00:32:31.550266
Epoch:[ 28 11 ] loss: 0.41567105054855347 2022-07-20 00:32:31.964292
Epoch:[ 28 12 ] loss: 0.4141194522380829 2022-07-20 00:32:32.383571
Epoch:[ 28 13 ] loss: 0.4194120168685913 2022-07-20 00:32:32.796996
Epoch:[ 28 14 ] loss: 0.42094895243644714 2022-07-20 00:32:33.208589
Epoch:[ 28 15 ] loss: 0.4182543158531189 2022-07-20 00:32:33.627353
Epoch:[ 28 16 ] loss: 0.4142497777938843 2022-07-20 00:32:38.690895
Epoch:[ 28 17 ] loss: 0.41799649596214294 2022-07-20 00:32:39.410699
Epoch:[ 28 18 ] loss: 0.4192659258842468 2022-07-20 00:32:39.827730
Epoch:[ 28 19 ] loss: 0.4143536388874054 2022-07-20 00:32:40.238833
Training_Epoch:[ 28 ] Training_loss: 0.41755393147468567 2022-07-20 00:32:40.239620
learning rate:  0.0007224999999999999
netparams have been saved once 28
val: 1 0.42304450273513794
val: 2 0.4263197183609009
val: 3 0.42503219842910767
val: 4 0.4204966723918915
val: 5 0.42663145065307617
val: 6 0.421916127204895
val: 7 0.4214155673980713
val: 8 0.4314459562301636
val: 9 0.43088117241859436
val: 10 0.42372164130210876
val: 11 0.4168573319911957
val: 12 0.42282751202583313
val: 13 0.42395371198654175
val: 14 0.43587979674339294
val: 15 0.4211563467979431
val: 16 0.43007126450538635
val: 17 0.4270586371421814
val: 18 0.42641177773475647
val: 19 0.42827677726745605
val: 20 0.42657312750816345
val_Epoch:[ 28 ] val_loss: 0.4254985645413399 2022-07-20 00:32:43.511560
start training 2022-07-20 00:32:43.611484
Epoch:[ 29 0 ] loss: 0.41297173500061035 2022-07-20 00:32:57.086438
Epoch:[ 29 1 ] loss: 0.41575849056243896 2022-07-20 00:32:57.650178
Epoch:[ 29 2 ] loss: 0.41495200991630554 2022-07-20 00:32:58.065585
Epoch:[ 29 3 ] loss: 0.41570577025413513 2022-07-20 00:32:58.478806
Epoch:[ 29 4 ] loss: 0.41405975818634033 2022-07-20 00:32:58.892368
Epoch:[ 29 5 ] loss: 0.4140636920928955 2022-07-20 00:32:59.307511
Epoch:[ 29 6 ] loss: 0.41353049874305725 2022-07-20 00:32:59.720246
Epoch:[ 29 7 ] loss: 0.4158066511154175 2022-07-20 00:33:00.135032
Epoch:[ 29 8 ] loss: 0.41107141971588135 2022-07-20 00:33:00.544555
Epoch:[ 29 9 ] loss: 0.41890352964401245 2022-07-20 00:33:00.958832
Epoch:[ 29 10 ] loss: 0.4172394871711731 2022-07-20 00:33:01.372226
Epoch:[ 29 11 ] loss: 0.4134998023509979 2022-07-20 00:33:01.784851
Epoch:[ 29 12 ] loss: 0.4177573323249817 2022-07-20 00:33:02.199343
Epoch:[ 29 13 ] loss: 0.4158352017402649 2022-07-20 00:33:02.614408
Epoch:[ 29 14 ] loss: 0.41914093494415283 2022-07-20 00:33:03.028594
Epoch:[ 29 15 ] loss: 0.41488900780677795 2022-07-20 00:33:03.444339
Epoch:[ 29 16 ] loss: 0.414030522108078 2022-07-20 00:33:09.051856
Epoch:[ 29 17 ] loss: 0.4180009365081787 2022-07-20 00:33:09.464706
Epoch:[ 29 18 ] loss: 0.41529178619384766 2022-07-20 00:33:09.878372
Epoch:[ 29 19 ] loss: 0.41780149936676025 2022-07-20 00:33:10.287174
Training_Epoch:[ 29 ] Training_loss: 0.41551550328731535 2022-07-20 00:33:10.287863
learning rate:  0.0007224999999999999
val: 1 0.4294014871120453
val: 2 0.4241969883441925
val: 3 0.4324033558368683
val: 4 0.42847001552581787
val: 5 0.42568767070770264
val: 6 0.43227237462997437
val: 7 0.4312359094619751
val: 8 0.42102503776550293
val: 9 0.4253894090652466
val: 10 0.42399340867996216
val: 11 0.435985267162323
val: 12 0.42261171340942383
val: 13 0.4204186499118805
val: 14 0.43331384658813477
val: 15 0.4385705292224884
val: 16 0.4305283725261688
val: 17 0.4335898756980896
val: 18 0.42777812480926514
val: 19 0.43152424693107605
val: 20 0.41796088218688965
val_Epoch:[ 29 ] val_loss: 0.42831785827875135 2022-07-20 00:33:13.511745
start training 2022-07-20 00:33:13.611603
Epoch:[ 30 0 ] loss: 0.41207075119018555 2022-07-20 00:33:27.991032
Epoch:[ 30 1 ] loss: 0.41498398780822754 2022-07-20 00:33:28.404652
Epoch:[ 30 2 ] loss: 0.4169155955314636 2022-07-20 00:33:28.818332
Epoch:[ 30 3 ] loss: 0.41754788160324097 2022-07-20 00:33:29.234050
Epoch:[ 30 4 ] loss: 0.41577979922294617 2022-07-20 00:33:29.648189
Epoch:[ 30 5 ] loss: 0.41945406794548035 2022-07-20 00:33:30.063880
Epoch:[ 30 6 ] loss: 0.41597744822502136 2022-07-20 00:33:30.480205
Epoch:[ 30 7 ] loss: 0.4154305160045624 2022-07-20 00:33:30.896140
Epoch:[ 30 8 ] loss: 0.41341349482536316 2022-07-20 00:33:31.309750
Epoch:[ 30 9 ] loss: 0.4160318970680237 2022-07-20 00:33:31.717720
Epoch:[ 30 10 ] loss: 0.4142197370529175 2022-07-20 00:33:32.132698
Epoch:[ 30 11 ] loss: 0.41600924730300903 2022-07-20 00:33:32.546734
Epoch:[ 30 12 ] loss: 0.41430386900901794 2022-07-20 00:33:32.960982
Epoch:[ 30 13 ] loss: 0.41656434535980225 2022-07-20 00:33:33.376402
Epoch:[ 30 14 ] loss: 0.4135180711746216 2022-07-20 00:33:33.788817
Epoch:[ 30 15 ] loss: 0.4150502383708954 2022-07-20 00:33:34.203029
Epoch:[ 30 16 ] loss: 0.41326889395713806 2022-07-20 00:33:39.428366
Epoch:[ 30 17 ] loss: 0.4148729741573334 2022-07-20 00:33:39.839309
Epoch:[ 30 18 ] loss: 0.41498664021492004 2022-07-20 00:33:40.255668
Epoch:[ 30 19 ] loss: 0.41383108496665955 2022-07-20 00:33:40.669638
Training_Epoch:[ 30 ] Training_loss: 0.41521152704954145 2022-07-20 00:33:40.670311
learning rate:  0.0007224999999999999
netparams have been saved once 30
val: 1 0.425713449716568
val: 2 0.4199645221233368
val: 3 0.4165135622024536
val: 4 0.42031121253967285
val: 5 0.41945990920066833
val: 6 0.4212518632411957
val: 7 0.4196030795574188
val: 8 0.4163331985473633
val: 9 0.41956913471221924
val: 10 0.42127496004104614
val: 11 0.4225853383541107
val: 12 0.4156329035758972
val: 13 0.4289509654045105
val: 14 0.42660874128341675
val: 15 0.4276781678199768
val: 16 0.4243623614311218
val: 17 0.4174761474132538
val: 18 0.42334383726119995
val: 19 0.4200230538845062
val: 20 0.4310488998889923
val_Epoch:[ 30 ] val_loss: 0.4218852654099464 2022-07-20 00:33:43.967091
start training 2022-07-20 00:33:44.069642
Epoch:[ 31 0 ] loss: 0.41175398230552673 2022-07-20 00:33:57.835243
Epoch:[ 31 1 ] loss: 0.41203758120536804 2022-07-20 00:33:58.267970
Epoch:[ 31 2 ] loss: 0.41321709752082825 2022-07-20 00:33:58.682081
Epoch:[ 31 3 ] loss: 0.41037943959236145 2022-07-20 00:33:59.095316
Epoch:[ 31 4 ] loss: 0.413199245929718 2022-07-20 00:33:59.507916
Epoch:[ 31 5 ] loss: 0.4121479094028473 2022-07-20 00:33:59.917110
Epoch:[ 31 6 ] loss: 0.4088629186153412 2022-07-20 00:34:00.329942
Epoch:[ 31 7 ] loss: 0.4132733941078186 2022-07-20 00:34:00.745993
Epoch:[ 31 8 ] loss: 0.410045862197876 2022-07-20 00:34:01.161127
Epoch:[ 31 9 ] loss: 0.4128771722316742 2022-07-20 00:34:01.576935
Epoch:[ 31 10 ] loss: 0.4113643765449524 2022-07-20 00:34:01.992464
Epoch:[ 31 11 ] loss: 0.4127267897129059 2022-07-20 00:34:02.404033
Epoch:[ 31 12 ] loss: 0.41307926177978516 2022-07-20 00:34:02.818547
Epoch:[ 31 13 ] loss: 0.41145506501197815 2022-07-20 00:34:03.232488
Epoch:[ 31 14 ] loss: 0.41152530908584595 2022-07-20 00:34:03.648855
Epoch:[ 31 15 ] loss: 0.41318824887275696 2022-07-20 00:34:04.065915
Epoch:[ 31 16 ] loss: 0.41128844022750854 2022-07-20 00:34:09.457206
Epoch:[ 31 17 ] loss: 0.4093109369277954 2022-07-20 00:34:09.870375
Epoch:[ 31 18 ] loss: 0.4099779725074768 2022-07-20 00:34:10.286140
Epoch:[ 31 19 ] loss: 0.41397425532341003 2022-07-20 00:34:10.699268
Training_Epoch:[ 31 ] Training_loss: 0.4117842629551888 2022-07-20 00:34:10.699979
learning rate:  0.000614125
val: 1 0.4268808960914612
val: 2 0.4304272532463074
val: 3 0.4308607876300812
val: 4 0.4288170337677002
val: 5 0.4279738664627075
val: 6 0.4227455258369446
val: 7 0.4268512427806854
val: 8 0.4278724491596222
val: 9 0.42951440811157227
val: 10 0.43293288350105286
val: 11 0.42406517267227173
val: 12 0.4333201050758362
val: 13 0.42230355739593506
val: 14 0.4289805591106415
val: 15 0.4351468086242676
val: 16 0.4242631793022156
val: 17 0.42503631114959717
val: 18 0.42362281680107117
val: 19 0.4182146191596985
val: 20 0.4314366281032562
val_Epoch:[ 31 ] val_loss: 0.42756330519914626 2022-07-20 00:34:13.837348
start training 2022-07-20 00:34:13.939393
Epoch:[ 32 0 ] loss: 0.4095223844051361 2022-07-20 00:34:27.442250
Epoch:[ 32 1 ] loss: 0.4106774628162384 2022-07-20 00:34:28.332245
Epoch:[ 32 2 ] loss: 0.4073687195777893 2022-07-20 00:34:28.750426
Epoch:[ 32 3 ] loss: 0.41082578897476196 2022-07-20 00:34:29.162129
Epoch:[ 32 4 ] loss: 0.41069889068603516 2022-07-20 00:34:29.573360
Epoch:[ 32 5 ] loss: 0.4118873178958893 2022-07-20 00:34:29.986033
Epoch:[ 32 6 ] loss: 0.4096805453300476 2022-07-20 00:34:30.398503
Epoch:[ 32 7 ] loss: 0.41132381558418274 2022-07-20 00:34:30.814699
Epoch:[ 32 8 ] loss: 0.411688894033432 2022-07-20 00:34:31.228342
Epoch:[ 32 9 ] loss: 0.41044944524765015 2022-07-20 00:34:31.642544
Epoch:[ 32 10 ] loss: 0.4089794158935547 2022-07-20 00:34:32.056065
Epoch:[ 32 11 ] loss: 0.41044190526008606 2022-07-20 00:34:32.469590
Epoch:[ 32 12 ] loss: 0.4094085097312927 2022-07-20 00:34:32.882218
Epoch:[ 32 13 ] loss: 0.4126189351081848 2022-07-20 00:34:33.297245
Epoch:[ 32 14 ] loss: 0.4150625765323639 2022-07-20 00:34:33.710975
Epoch:[ 32 15 ] loss: 0.4119820296764374 2022-07-20 00:34:34.128030
Epoch:[ 32 16 ] loss: 0.4098021686077118 2022-07-20 00:34:39.419447
Epoch:[ 32 17 ] loss: 0.4119080901145935 2022-07-20 00:34:39.832328
Epoch:[ 32 18 ] loss: 0.41060322523117065 2022-07-20 00:34:40.250103
Epoch:[ 32 19 ] loss: 0.41253358125686646 2022-07-20 00:34:40.660214
Training_Epoch:[ 32 ] Training_loss: 0.4108731850981712 2022-07-20 00:34:40.660970
learning rate:  0.000614125
netparams have been saved once 32
val: 1 0.42240917682647705
val: 2 0.422100305557251
val: 3 0.4185618460178375
val: 4 0.41764116287231445
val: 5 0.4224567711353302
val: 6 0.41998255252838135
val: 7 0.4202006459236145
val: 8 0.42453551292419434
val: 9 0.4266544580459595
val: 10 0.41854628920555115
val: 11 0.43131449818611145
val: 12 0.41614338755607605
val: 13 0.4177546501159668
val: 14 0.427761435508728
val: 15 0.42376038432121277
val: 16 0.421725332736969
val: 17 0.4234163463115692
val: 18 0.41808369755744934
val: 19 0.42952215671539307
val: 20 0.4186550974845886
val_Epoch:[ 32 ] val_loss: 0.42206128537654874 2022-07-20 00:34:43.895336
start training 2022-07-20 00:34:43.998260
Epoch:[ 33 0 ] loss: 0.41165342926979065 2022-07-20 00:34:57.483961
Epoch:[ 33 1 ] loss: 0.4099023640155792 2022-07-20 00:34:57.893725
Epoch:[ 33 2 ] loss: 0.4097852110862732 2022-07-20 00:34:58.309083
Epoch:[ 33 3 ] loss: 0.41319170594215393 2022-07-20 00:34:58.726059
Epoch:[ 33 4 ] loss: 0.41065946221351624 2022-07-20 00:34:59.138623
Epoch:[ 33 5 ] loss: 0.4075685143470764 2022-07-20 00:34:59.552384
Epoch:[ 33 6 ] loss: 0.41113147139549255 2022-07-20 00:34:59.966874
Epoch:[ 33 7 ] loss: 0.41088443994522095 2022-07-20 00:35:00.380217
Epoch:[ 33 8 ] loss: 0.4087613523006439 2022-07-20 00:35:00.791916
Epoch:[ 33 9 ] loss: 0.40963438153266907 2022-07-20 00:35:01.205688
Epoch:[ 33 10 ] loss: 0.4130527377128601 2022-07-20 00:35:01.624396
Epoch:[ 33 11 ] loss: 0.40958404541015625 2022-07-20 00:35:02.037003
Epoch:[ 33 12 ] loss: 0.41035446524620056 2022-07-20 00:35:02.451081
Epoch:[ 33 13 ] loss: 0.40840160846710205 2022-07-20 00:35:02.864234
Epoch:[ 33 14 ] loss: 0.4105026423931122 2022-07-20 00:35:03.277544
Epoch:[ 33 15 ] loss: 0.4108238220214844 2022-07-20 00:35:03.689236
Epoch:[ 33 16 ] loss: 0.4082379937171936 2022-07-20 00:35:09.359405
Epoch:[ 33 17 ] loss: 0.4093608260154724 2022-07-20 00:35:09.775068
Epoch:[ 33 18 ] loss: 0.40870386362075806 2022-07-20 00:35:10.192500
Epoch:[ 33 19 ] loss: 0.40913766622543335 2022-07-20 00:35:10.607737
Training_Epoch:[ 33 ] Training_loss: 0.41006660014390944 2022-07-20 00:35:10.608533
learning rate:  0.000614125
val: 1 0.4165627360343933
val: 2 0.41807788610458374
val: 3 0.4178908169269562
val: 4 0.4217351973056793
val: 5 0.41901203989982605
val: 6 0.4119987487792969
val: 7 0.41831105947494507
val: 8 0.41675275564193726
val: 9 0.4187949597835541
val: 10 0.41476204991340637
val: 11 0.42856475710868835
val: 12 0.41568323969841003
val: 13 0.4219484031200409
val: 14 0.41602417826652527
val: 15 0.4202614426612854
val: 16 0.4185956120491028
val: 17 0.42197322845458984
val: 18 0.4144957661628723
val: 19 0.41711145639419556
val: 20 0.41507670283317566
val_Epoch:[ 33 ] val_loss: 0.41818165183067324 2022-07-20 00:35:13.811441
start training 2022-07-20 00:35:13.911162
Epoch:[ 34 0 ] loss: 0.4106315076351166 2022-07-20 00:35:27.361477
Epoch:[ 34 1 ] loss: 0.41066253185272217 2022-07-20 00:35:27.884558
Epoch:[ 34 2 ] loss: 0.4084089994430542 2022-07-20 00:35:28.297556
Epoch:[ 34 3 ] loss: 0.40692219138145447 2022-07-20 00:35:28.713752
Epoch:[ 34 4 ] loss: 0.4079322814941406 2022-07-20 00:35:29.128720
Epoch:[ 34 5 ] loss: 0.408018559217453 2022-07-20 00:35:29.541809
Epoch:[ 34 6 ] loss: 0.40815824270248413 2022-07-20 00:35:29.959121
Epoch:[ 34 7 ] loss: 0.40995070338249207 2022-07-20 00:35:30.373460
Epoch:[ 34 8 ] loss: 0.40986719727516174 2022-07-20 00:35:30.787555
Epoch:[ 34 9 ] loss: 0.4070611596107483 2022-07-20 00:35:31.197564
Epoch:[ 34 10 ] loss: 0.4073401987552643 2022-07-20 00:35:31.612502
Epoch:[ 34 11 ] loss: 0.4069575071334839 2022-07-20 00:35:32.028052
Epoch:[ 34 12 ] loss: 0.4091021418571472 2022-07-20 00:35:32.441642
Epoch:[ 34 13 ] loss: 0.40756258368492126 2022-07-20 00:35:32.851083
Epoch:[ 34 14 ] loss: 0.4079820513725281 2022-07-20 00:35:33.265695
Epoch:[ 34 15 ] loss: 0.41012880206108093 2022-07-20 00:35:33.679431
Epoch:[ 34 16 ] loss: 0.4108467698097229 2022-07-20 00:35:39.357526
Epoch:[ 34 17 ] loss: 0.40668994188308716 2022-07-20 00:35:39.772481
Epoch:[ 34 18 ] loss: 0.40665197372436523 2022-07-20 00:35:40.183504
Epoch:[ 34 19 ] loss: 0.40816888213157654 2022-07-20 00:35:40.597061
Training_Epoch:[ 34 ] Training_loss: 0.4084522113204002 2022-07-20 00:35:40.597818
learning rate:  0.000614125
netparams have been saved once 34
val: 1 0.4220833480358124
val: 2 0.4241001307964325
val: 3 0.42083102464675903
val: 4 0.4197476804256439
val: 5 0.4124707281589508
val: 6 0.43010905385017395
val: 7 0.41345709562301636
val: 8 0.41810086369514465
val: 9 0.4192620515823364
val: 10 0.4167400598526001
val: 11 0.4197055697441101
val: 12 0.4140995442867279
val: 13 0.4163931608200073
val: 14 0.41955137252807617
val: 15 0.4165123999118805
val: 16 0.4087054133415222
val: 17 0.41431522369384766
val: 18 0.4179413616657257
val: 19 0.4106082022190094
val: 20 0.42056727409362793
val_Epoch:[ 34 ] val_loss: 0.41776507794857026 2022-07-20 00:35:43.828971
start training 2022-07-20 00:35:43.931784
Epoch:[ 35 0 ] loss: 0.40885311365127563 2022-07-20 00:35:57.760537
Epoch:[ 35 1 ] loss: 0.40968644618988037 2022-07-20 00:35:58.274639
Epoch:[ 35 2 ] loss: 0.4069373607635498 2022-07-20 00:35:58.688354
Epoch:[ 35 3 ] loss: 0.4081652760505676 2022-07-20 00:35:59.103181
Epoch:[ 35 4 ] loss: 0.40993034839630127 2022-07-20 00:35:59.516832
Epoch:[ 35 5 ] loss: 0.4122188687324524 2022-07-20 00:35:59.930329
Epoch:[ 35 6 ] loss: 0.4051584005355835 2022-07-20 00:36:00.343932
Epoch:[ 35 7 ] loss: 0.4065612852573395 2022-07-20 00:36:00.756898
Epoch:[ 35 8 ] loss: 0.40618348121643066 2022-07-20 00:36:01.171226
Epoch:[ 35 9 ] loss: 0.408073753118515 2022-07-20 00:36:01.583979
Epoch:[ 35 10 ] loss: 0.4127598702907562 2022-07-20 00:36:01.996931
Epoch:[ 35 11 ] loss: 0.40746426582336426 2022-07-20 00:36:02.412160
Epoch:[ 35 12 ] loss: 0.4078785181045532 2022-07-20 00:36:02.826535
Epoch:[ 35 13 ] loss: 0.40806713700294495 2022-07-20 00:36:03.236451
Epoch:[ 35 14 ] loss: 0.408256471157074 2022-07-20 00:36:03.645971
Epoch:[ 35 15 ] loss: 0.40813305974006653 2022-07-20 00:36:04.060254
Epoch:[ 35 16 ] loss: 0.4104138910770416 2022-07-20 00:36:09.165106
Epoch:[ 35 17 ] loss: 0.4076642394065857 2022-07-20 00:36:09.582320
Epoch:[ 35 18 ] loss: 0.4072226583957672 2022-07-20 00:36:09.997586
Epoch:[ 35 19 ] loss: 0.40907469391822815 2022-07-20 00:36:10.411431
Training_Epoch:[ 35 ] Training_loss: 0.40843515694141386 2022-07-20 00:36:10.412399
learning rate:  0.000614125
val: 1 0.4221803545951843
val: 2 0.4169619679450989
val: 3 0.41407468914985657
val: 4 0.4173451364040375
val: 5 0.4218810200691223
val: 6 0.4186778962612152
val: 7 0.4219212830066681
val: 8 0.42093321681022644
val: 9 0.4175354242324829
val: 10 0.4179173409938812
val: 11 0.41864967346191406
val: 12 0.42622655630111694
val: 13 0.41919174790382385
val: 14 0.41769546270370483
val: 15 0.427497535943985
val: 16 0.42096009850502014
val: 17 0.419642835855484
val: 18 0.42629414796829224
val: 19 0.4208439290523529
val: 20 0.4106121063232422
val_Epoch:[ 35 ] val_loss: 0.41985212117433546 2022-07-20 00:36:13.591248
start training 2022-07-20 00:36:13.691539
Epoch:[ 36 0 ] loss: 0.4060058891773224 2022-07-20 00:36:27.122505
Epoch:[ 36 1 ] loss: 0.40683114528656006 2022-07-20 00:36:27.563603
Epoch:[ 36 2 ] loss: 0.40775954723358154 2022-07-20 00:36:27.981817
Epoch:[ 36 3 ] loss: 0.40411806106567383 2022-07-20 00:36:28.395188
Epoch:[ 36 4 ] loss: 0.4050087332725525 2022-07-20 00:36:28.807789
Epoch:[ 36 5 ] loss: 0.40556928515434265 2022-07-20 00:36:29.222844
Epoch:[ 36 6 ] loss: 0.40526875853538513 2022-07-20 00:36:29.636704
Epoch:[ 36 7 ] loss: 0.40595799684524536 2022-07-20 00:36:30.054340
Epoch:[ 36 8 ] loss: 0.4045836925506592 2022-07-20 00:36:30.465635
Epoch:[ 36 9 ] loss: 0.4043748378753662 2022-07-20 00:36:30.876352
Epoch:[ 36 10 ] loss: 0.40663570165634155 2022-07-20 00:36:31.289194
Epoch:[ 36 11 ] loss: 0.4057183861732483 2022-07-20 00:36:31.703662
Epoch:[ 36 12 ] loss: 0.40713146328926086 2022-07-20 00:36:32.116640
Epoch:[ 36 13 ] loss: 0.4058733880519867 2022-07-20 00:36:32.530669
Epoch:[ 36 14 ] loss: 0.40304675698280334 2022-07-20 00:36:32.943350
Epoch:[ 36 15 ] loss: 0.40705054998397827 2022-07-20 00:36:33.354801
Epoch:[ 36 16 ] loss: 0.4075984060764313 2022-07-20 00:36:39.104465
Epoch:[ 36 17 ] loss: 0.40732628107070923 2022-07-20 00:36:39.515761
Epoch:[ 36 18 ] loss: 0.40500444173812866 2022-07-20 00:36:39.933639
Epoch:[ 36 19 ] loss: 0.40966498851776123 2022-07-20 00:36:40.348023
Training_Epoch:[ 36 ] Training_loss: 0.4060264155268669 2022-07-20 00:36:40.348700
learning rate:  0.000614125
netparams have been saved once 36
val: 1 0.4224238693714142
val: 2 0.42943713068962097
val: 3 0.41535302996635437
val: 4 0.4263916313648224
val: 5 0.4210331439971924
val: 6 0.42843905091285706
val: 7 0.4212379455566406
val: 8 0.41824471950531006
val: 9 0.42249929904937744
val: 10 0.430311381816864
val: 11 0.42521700263023376
val: 12 0.4232806861400604
val: 13 0.4344528913497925
val: 14 0.42825427651405334
val: 15 0.42106741666793823
val: 16 0.4186709523200989
val: 17 0.43319401144981384
val: 18 0.4207625687122345
val: 19 0.42325448989868164
val: 20 0.42117294669151306
val_Epoch:[ 36 ] val_loss: 0.42423492223024367 2022-07-20 00:36:43.519712
start training 2022-07-20 00:36:43.623078
Epoch:[ 37 0 ] loss: 0.40798240900039673 2022-07-20 00:36:57.385366
Epoch:[ 37 1 ] loss: 0.4060105085372925 2022-07-20 00:36:57.797644
Epoch:[ 37 2 ] loss: 0.40805017948150635 2022-07-20 00:36:58.211535
Epoch:[ 37 3 ] loss: 0.412380576133728 2022-07-20 00:36:58.623865
Epoch:[ 37 4 ] loss: 0.410322368144989 2022-07-20 00:36:59.036207
Epoch:[ 37 5 ] loss: 0.4074198305606842 2022-07-20 00:36:59.448353
Epoch:[ 37 6 ] loss: 0.4101356267929077 2022-07-20 00:36:59.863233
Epoch:[ 37 7 ] loss: 0.4077107608318329 2022-07-20 00:37:00.277535
Epoch:[ 37 8 ] loss: 0.40584465861320496 2022-07-20 00:37:00.690410
Epoch:[ 37 9 ] loss: 0.4077925980091095 2022-07-20 00:37:01.104389
Epoch:[ 37 10 ] loss: 0.40383338928222656 2022-07-20 00:37:01.523663
Epoch:[ 37 11 ] loss: 0.40683382749557495 2022-07-20 00:37:01.935510
Epoch:[ 37 12 ] loss: 0.40568047761917114 2022-07-20 00:37:02.348248
Epoch:[ 37 13 ] loss: 0.40734392404556274 2022-07-20 00:37:02.768726
Epoch:[ 37 14 ] loss: 0.40462997555732727 2022-07-20 00:37:03.188279
Epoch:[ 37 15 ] loss: 0.4076317548751831 2022-07-20 00:37:03.600897
Epoch:[ 37 16 ] loss: 0.40729236602783203 2022-07-20 00:37:08.757225
Epoch:[ 37 17 ] loss: 0.40572383999824524 2022-07-20 00:37:09.169493
Epoch:[ 37 18 ] loss: 0.40272268652915955 2022-07-20 00:37:09.582394
Epoch:[ 37 19 ] loss: 0.4045245051383972 2022-07-20 00:37:09.999422
Training_Epoch:[ 37 ] Training_loss: 0.40699331313371656 2022-07-20 00:37:10.000064
learning rate:  0.000614125
val: 1 0.42044883966445923
val: 2 0.42110657691955566
val: 3 0.41866356134414673
val: 4 0.41844457387924194
val: 5 0.42216143012046814
val: 6 0.4217412769794464
val: 7 0.4313860237598419
val: 8 0.42175525426864624
val: 9 0.4194200336933136
val: 10 0.4165438413619995
val: 11 0.41636279225349426
val: 12 0.42332586646080017
val: 13 0.4184034466743469
val: 14 0.41828998923301697
val: 15 0.42562800645828247
val: 16 0.42305704951286316
val: 17 0.4227457344532013
val: 18 0.41628366708755493
val: 19 0.4168901741504669
val: 20 0.42482078075408936
val_Epoch:[ 37 ] val_loss: 0.42087394595146177 2022-07-20 00:37:13.127755
start training 2022-07-20 00:37:13.228234
Epoch:[ 38 0 ] loss: 0.40308651328086853 2022-07-20 00:37:27.110441
Epoch:[ 38 1 ] loss: 0.40707889199256897 2022-07-20 00:37:27.524469
Epoch:[ 38 2 ] loss: 0.40213945508003235 2022-07-20 00:37:27.945052
Epoch:[ 38 3 ] loss: 0.402556836605072 2022-07-20 00:37:28.358950
Epoch:[ 38 4 ] loss: 0.40430334210395813 2022-07-20 00:37:28.771423
Epoch:[ 38 5 ] loss: 0.4040195941925049 2022-07-20 00:37:29.183688
Epoch:[ 38 6 ] loss: 0.4053359925746918 2022-07-20 00:37:29.598849
Epoch:[ 38 7 ] loss: 0.40332257747650146 2022-07-20 00:37:30.013957
Epoch:[ 38 8 ] loss: 0.40315526723861694 2022-07-20 00:37:30.428191
Epoch:[ 38 9 ] loss: 0.4061831831932068 2022-07-20 00:37:30.841249
Epoch:[ 38 10 ] loss: 0.40041714906692505 2022-07-20 00:37:31.250869
Epoch:[ 38 11 ] loss: 0.4038338363170624 2022-07-20 00:37:31.666126
Epoch:[ 38 12 ] loss: 0.40389585494995117 2022-07-20 00:37:32.081032
Epoch:[ 38 13 ] loss: 0.40608248114585876 2022-07-20 00:37:32.494621
Epoch:[ 38 14 ] loss: 0.4034782350063324 2022-07-20 00:37:32.910718
Epoch:[ 38 15 ] loss: 0.4019958972930908 2022-07-20 00:37:33.325418
Epoch:[ 38 16 ] loss: 0.40196532011032104 2022-07-20 00:37:38.480488
Epoch:[ 38 17 ] loss: 0.40145400166511536 2022-07-20 00:37:38.893588
Epoch:[ 38 18 ] loss: 0.40263816714286804 2022-07-20 00:37:39.570588
Epoch:[ 38 19 ] loss: 0.40348920226097107 2022-07-20 00:37:39.984267
Training_Epoch:[ 38 ] Training_loss: 0.4035215899348259 2022-07-20 00:37:39.985034
learning rate:  0.000614125
netparams have been saved once 38
val: 1 0.41970881819725037
val: 2 0.4335201382637024
val: 3 0.42385759949684143
val: 4 0.42264798283576965
val: 5 0.4188576340675354
val: 6 0.4212801456451416
val: 7 0.42586565017700195
val: 8 0.42044326663017273
val: 9 0.424290269613266
val: 10 0.4188433587551117
val: 11 0.43223199248313904
val: 12 0.4168463349342346
val: 13 0.42295026779174805
val: 14 0.42600369453430176
val: 15 0.42151084542274475
val: 16 0.4138902723789215
val: 17 0.41180533170700073
val: 18 0.4153665006160736
val: 19 0.4222503900527954
val: 20 0.42392033338546753
val_Epoch:[ 38 ] val_loss: 0.42180454134941103 2022-07-20 00:37:43.187314
start training 2022-07-20 00:37:43.288191
Epoch:[ 39 0 ] loss: 0.40247631072998047 2022-07-20 00:37:56.879619
Epoch:[ 39 1 ] loss: 0.4020432233810425 2022-07-20 00:37:57.314012
Epoch:[ 39 2 ] loss: 0.40148621797561646 2022-07-20 00:37:57.733561
Epoch:[ 39 3 ] loss: 0.40009063482284546 2022-07-20 00:37:58.145941
Epoch:[ 39 4 ] loss: 0.4040297865867615 2022-07-20 00:37:58.564686
Epoch:[ 39 5 ] loss: 0.4033300280570984 2022-07-20 00:37:58.977909
Epoch:[ 39 6 ] loss: 0.402021586894989 2022-07-20 00:37:59.390090
Epoch:[ 39 7 ] loss: 0.40544936060905457 2022-07-20 00:37:59.802771
Epoch:[ 39 8 ] loss: 0.40449270606040955 2022-07-20 00:38:00.216413
Epoch:[ 39 9 ] loss: 0.4068619906902313 2022-07-20 00:38:00.630620
Epoch:[ 39 10 ] loss: 0.40411657094955444 2022-07-20 00:38:01.043723
Epoch:[ 39 11 ] loss: 0.40460267663002014 2022-07-20 00:38:01.456096
Epoch:[ 39 12 ] loss: 0.40196114778518677 2022-07-20 00:38:01.868795
Epoch:[ 39 13 ] loss: 0.40379834175109863 2022-07-20 00:38:02.282292
Epoch:[ 39 14 ] loss: 0.4008280336856842 2022-07-20 00:38:02.696728
Epoch:[ 39 15 ] loss: 0.405643492937088 2022-07-20 00:38:03.110991
Epoch:[ 39 16 ] loss: 0.4051706790924072 2022-07-20 00:38:08.630304
Epoch:[ 39 17 ] loss: 0.4019160866737366 2022-07-20 00:38:09.042706
Epoch:[ 39 18 ] loss: 0.4020824432373047 2022-07-20 00:38:09.456716
Epoch:[ 39 19 ] loss: 0.40487971901893616 2022-07-20 00:38:09.873608
Training_Epoch:[ 39 ] Training_loss: 0.4033640518784523 2022-07-20 00:38:09.874292
learning rate:  0.000614125
val: 1 0.4083518087863922
val: 2 0.4119267165660858
val: 3 0.4236486852169037
val: 4 0.4159492254257202
val: 5 0.404555082321167
val: 6 0.4100410044193268
val: 7 0.41072291135787964
val: 8 0.4119400084018707
val: 9 0.4058806002140045
val: 10 0.41645246744155884
val: 11 0.41292062401771545
val: 12 0.42210209369659424
val: 13 0.41515323519706726
val: 14 0.4133667051792145
val: 15 0.4120272696018219
val: 16 0.41096508502960205
val: 17 0.40783169865608215
val: 18 0.41910088062286377
val: 19 0.41323429346084595
val: 20 0.4113432765007019
val_Epoch:[ 39 ] val_loss: 0.41287568360567095 2022-07-20 00:38:12.997973
start training 2022-07-20 00:38:13.101408
Epoch:[ 40 0 ] loss: 0.4011058509349823 2022-07-20 00:38:26.378395
Epoch:[ 40 1 ] loss: 0.4032829701900482 2022-07-20 00:38:26.816567
Epoch:[ 40 2 ] loss: 0.40292587876319885 2022-07-20 00:38:27.237308
Epoch:[ 40 3 ] loss: 0.39956986904144287 2022-07-20 00:38:27.651531
Epoch:[ 40 4 ] loss: 0.40111812949180603 2022-07-20 00:38:28.069410
Epoch:[ 40 5 ] loss: 0.40134087204933167 2022-07-20 00:38:28.480375
Epoch:[ 40 6 ] loss: 0.4030742943286896 2022-07-20 00:38:28.892983
Epoch:[ 40 7 ] loss: 0.40349823236465454 2022-07-20 00:38:29.305362
Epoch:[ 40 8 ] loss: 0.404579222202301 2022-07-20 00:38:29.718158
Epoch:[ 40 9 ] loss: 0.40357261896133423 2022-07-20 00:38:30.132553
Epoch:[ 40 10 ] loss: 0.4041304886341095 2022-07-20 00:38:30.546245
Epoch:[ 40 11 ] loss: 0.404972642660141 2022-07-20 00:38:30.957951
Epoch:[ 40 12 ] loss: 0.40368756651878357 2022-07-20 00:38:31.369297
Epoch:[ 40 13 ] loss: 0.4015484154224396 2022-07-20 00:38:31.782274
Epoch:[ 40 14 ] loss: 0.40456104278564453 2022-07-20 00:38:32.193870
Epoch:[ 40 15 ] loss: 0.4023779034614563 2022-07-20 00:38:32.607035
Epoch:[ 40 16 ] loss: 0.40119192004203796 2022-07-20 00:38:38.536649
Epoch:[ 40 17 ] loss: 0.4043097496032715 2022-07-20 00:38:38.949312
Epoch:[ 40 18 ] loss: 0.4013799726963043 2022-07-20 00:38:39.365975
Epoch:[ 40 19 ] loss: 0.4049166738986969 2022-07-20 00:38:39.777553
Training_Epoch:[ 40 ] Training_loss: 0.40285721570253374 2022-07-20 00:38:39.778213
learning rate:  0.000614125
netparams have been saved once 40
val: 1 0.4123378098011017
val: 2 0.40989193320274353
val: 3 0.4089593291282654
val: 4 0.4270227253437042
val: 5 0.41480326652526855
val: 6 0.4219304323196411
val: 7 0.41275614500045776
val: 8 0.4087463915348053
val: 9 0.41652610898017883
val: 10 0.41644155979156494
val: 11 0.4159843325614929
val: 12 0.4180113673210144
val: 13 0.4134044349193573
val: 14 0.4209177792072296
val: 15 0.41845381259918213
val: 16 0.4208355247974396
val: 17 0.41545242071151733
val: 18 0.4118347465991974
val: 19 0.40911874175071716
val: 20 0.4200171232223511
val_Epoch:[ 40 ] val_loss: 0.4156722992658615 2022-07-20 00:38:43.017851
start training 2022-07-20 00:38:43.121423
Epoch:[ 41 0 ] loss: 0.40207403898239136 2022-07-20 00:38:57.293413
Epoch:[ 41 1 ] loss: 0.40170708298683167 2022-07-20 00:38:57.705454
Epoch:[ 41 2 ] loss: 0.40119317173957825 2022-07-20 00:38:58.120152
Epoch:[ 41 3 ] loss: 0.39828404784202576 2022-07-20 00:38:58.539678
Epoch:[ 41 4 ] loss: 0.40246617794036865 2022-07-20 00:38:58.954242
Epoch:[ 41 5 ] loss: 0.39846137166023254 2022-07-20 00:38:59.365672
Epoch:[ 41 6 ] loss: 0.40157413482666016 2022-07-20 00:38:59.777388
Epoch:[ 41 7 ] loss: 0.4009459614753723 2022-07-20 00:39:00.189749
Epoch:[ 41 8 ] loss: 0.401495099067688 2022-07-20 00:39:00.603617
Epoch:[ 41 9 ] loss: 0.39895278215408325 2022-07-20 00:39:01.015859
Epoch:[ 41 10 ] loss: 0.39964574575424194 2022-07-20 00:39:01.429830
Epoch:[ 41 11 ] loss: 0.40010908246040344 2022-07-20 00:39:01.845024
Epoch:[ 41 12 ] loss: 0.40132981538772583 2022-07-20 00:39:02.256663
Epoch:[ 41 13 ] loss: 0.400166779756546 2022-07-20 00:39:02.671269
Epoch:[ 41 14 ] loss: 0.40159860253334045 2022-07-20 00:39:03.089823
Epoch:[ 41 15 ] loss: 0.3988793194293976 2022-07-20 00:39:03.501921
Epoch:[ 41 16 ] loss: 0.4012022614479065 2022-07-20 00:39:08.571444
Epoch:[ 41 17 ] loss: 0.39965471625328064 2022-07-20 00:39:08.984531
Epoch:[ 41 18 ] loss: 0.39937373995780945 2022-07-20 00:39:09.400339
Epoch:[ 41 19 ] loss: 0.40040579438209534 2022-07-20 00:39:09.818092
Training_Epoch:[ 41 ] Training_loss: 0.40047598630189896 2022-07-20 00:39:09.818858
learning rate:  0.00052200625
val: 1 0.4219135642051697
val: 2 0.42068880796432495
val: 3 0.4126075804233551
val: 4 0.40996670722961426
val: 5 0.4170937240123749
val: 6 0.4119795262813568
val: 7 0.4150666892528534
val: 8 0.41434359550476074
val: 9 0.42154842615127563
val: 10 0.4180736839771271
val: 11 0.40962424874305725
val: 12 0.41647428274154663
val: 13 0.420772910118103
val: 14 0.42187947034835815
val: 15 0.41744884848594666
val: 16 0.41443756222724915
val: 17 0.42225655913352966
val: 18 0.4135964512825012
val: 19 0.4165930449962616
val: 20 0.4228605628013611
val_Epoch:[ 41 ] val_loss: 0.41696131229400635 2022-07-20 00:39:13.020085
start training 2022-07-20 00:39:13.124553
Epoch:[ 42 0 ] loss: 0.39952361583709717 2022-07-20 00:39:26.767233
Epoch:[ 42 1 ] loss: 0.39899587631225586 2022-07-20 00:39:27.194461
Epoch:[ 42 2 ] loss: 0.4006689190864563 2022-07-20 00:39:27.606629
Epoch:[ 42 3 ] loss: 0.3995875120162964 2022-07-20 00:39:28.018090
Epoch:[ 42 4 ] loss: 0.3984127342700958 2022-07-20 00:39:28.431226
Epoch:[ 42 5 ] loss: 0.3983791470527649 2022-07-20 00:39:28.843973
Epoch:[ 42 6 ] loss: 0.3984059989452362 2022-07-20 00:39:29.262123
Epoch:[ 42 7 ] loss: 0.3977247178554535 2022-07-20 00:39:29.676569
Epoch:[ 42 8 ] loss: 0.39886364340782166 2022-07-20 00:39:30.088749
Epoch:[ 42 9 ] loss: 0.39896970987319946 2022-07-20 00:39:30.501929
Epoch:[ 42 10 ] loss: 0.39851459860801697 2022-07-20 00:39:30.914223
Epoch:[ 42 11 ] loss: 0.39801886677742004 2022-07-20 00:39:31.326572
Epoch:[ 42 12 ] loss: 0.39777788519859314 2022-07-20 00:39:31.739306
Epoch:[ 42 13 ] loss: 0.39700841903686523 2022-07-20 00:39:32.151468
Epoch:[ 42 14 ] loss: 0.39746585488319397 2022-07-20 00:39:32.563137
Epoch:[ 42 15 ] loss: 0.40051883459091187 2022-07-20 00:39:32.975790
Epoch:[ 42 16 ] loss: 0.3983047604560852 2022-07-20 00:39:38.383737
Epoch:[ 42 17 ] loss: 0.3978896737098694 2022-07-20 00:39:38.802597
Epoch:[ 42 18 ] loss: 0.3993050754070282 2022-07-20 00:39:39.218707
Epoch:[ 42 19 ] loss: 0.39772844314575195 2022-07-20 00:39:39.631919
Training_Epoch:[ 42 ] Training_loss: 0.39860321432352064 2022-07-20 00:39:39.632589
learning rate:  0.00052200625
netparams have been saved once 42
val: 1 0.42635419964790344
val: 2 0.42120254039764404
val: 3 0.413591206073761
val: 4 0.4117346704006195
val: 5 0.425834059715271
val: 6 0.4241892993450165
val: 7 0.42945417761802673
val: 8 0.4213075041770935
val: 9 0.4168316721916199
val: 10 0.4217405319213867
val: 11 0.42216041684150696
val: 12 0.41148996353149414
val: 13 0.42523542046546936
val: 14 0.4239395558834076
val: 15 0.4192442297935486
val: 16 0.41901522874832153
val: 17 0.42264413833618164
val: 18 0.4125213921070099
val: 19 0.41405773162841797
val: 20 0.41651585698127747
val_Epoch:[ 42 ] val_loss: 0.41995318979024887 2022-07-20 00:39:42.881279
start training 2022-07-20 00:39:42.980768
Epoch:[ 43 0 ] loss: 0.4007002115249634 2022-07-20 00:39:56.637486
Epoch:[ 43 1 ] loss: 0.3968951106071472 2022-07-20 00:39:57.052813
Epoch:[ 43 2 ] loss: 0.3986923396587372 2022-07-20 00:39:57.465725
Epoch:[ 43 3 ] loss: 0.3983277678489685 2022-07-20 00:39:57.877573
Epoch:[ 43 4 ] loss: 0.3983142673969269 2022-07-20 00:39:58.290525
Epoch:[ 43 5 ] loss: 0.3967881500720978 2022-07-20 00:39:58.702707
Epoch:[ 43 6 ] loss: 0.3979494571685791 2022-07-20 00:39:59.118786
Epoch:[ 43 7 ] loss: 0.39715829491615295 2022-07-20 00:39:59.534457
Epoch:[ 43 8 ] loss: 0.39662355184555054 2022-07-20 00:39:59.949132
Epoch:[ 43 9 ] loss: 0.3993512690067291 2022-07-20 00:40:00.361820
Epoch:[ 43 10 ] loss: 0.3980337679386139 2022-07-20 00:40:00.781621
Epoch:[ 43 11 ] loss: 0.39701133966445923 2022-07-20 00:40:01.194305
Epoch:[ 43 12 ] loss: 0.39705660939216614 2022-07-20 00:40:01.607525
Epoch:[ 43 13 ] loss: 0.396217405796051 2022-07-20 00:40:02.027310
Epoch:[ 43 14 ] loss: 0.3960689306259155 2022-07-20 00:40:02.439491
Epoch:[ 43 15 ] loss: 0.39995571970939636 2022-07-20 00:40:02.852286
Epoch:[ 43 16 ] loss: 0.39700382947921753 2022-07-20 00:40:08.321714
Epoch:[ 43 17 ] loss: 0.3957812190055847 2022-07-20 00:40:08.733806
Epoch:[ 43 18 ] loss: 0.39769551157951355 2022-07-20 00:40:09.147767
Epoch:[ 43 19 ] loss: 0.39614593982696533 2022-07-20 00:40:09.568051
Training_Epoch:[ 43 ] Training_loss: 0.3975885346531868 2022-07-20 00:40:09.568721
learning rate:  0.00052200625
val: 1 0.418511301279068
val: 2 0.4138648509979248
val: 3 0.41792190074920654
val: 4 0.4109745919704437
val: 5 0.40846338868141174
val: 6 0.4106839597225189
val: 7 0.40672942996025085
val: 8 0.41491907835006714
val: 9 0.4192339777946472
val: 10 0.4195217192173004
val: 11 0.41561299562454224
val: 12 0.42001843452453613
val: 13 0.41416555643081665
val: 14 0.416309118270874
val: 15 0.4127154052257538
val: 16 0.4206836521625519
val: 17 0.41774895787239075
val: 18 0.41507232189178467
val: 19 0.417427122592926
val: 20 0.41938328742980957
val_Epoch:[ 43 ] val_loss: 0.41549805253744126 2022-07-20 00:40:12.678673
start training 2022-07-20 00:40:12.776728
Epoch:[ 44 0 ] loss: 0.39575645327568054 2022-07-20 00:40:26.347217
Epoch:[ 44 1 ] loss: 0.3976663053035736 2022-07-20 00:40:26.782719
Epoch:[ 44 2 ] loss: 0.3956359028816223 2022-07-20 00:40:27.195830
Epoch:[ 44 3 ] loss: 0.39453214406967163 2022-07-20 00:40:27.609500
Epoch:[ 44 4 ] loss: 0.3958818316459656 2022-07-20 00:40:28.024021
Epoch:[ 44 5 ] loss: 0.3944382667541504 2022-07-20 00:40:28.442964
Epoch:[ 44 6 ] loss: 0.3958002030849457 2022-07-20 00:40:28.858639
Epoch:[ 44 7 ] loss: 0.3947198688983917 2022-07-20 00:40:29.272411
Epoch:[ 44 8 ] loss: 0.39729586243629456 2022-07-20 00:40:29.681987
Epoch:[ 44 9 ] loss: 0.39566531777381897 2022-07-20 00:40:30.094279
Epoch:[ 44 10 ] loss: 0.39685553312301636 2022-07-20 00:40:30.509239
Epoch:[ 44 11 ] loss: 0.3970192074775696 2022-07-20 00:40:30.923218
Epoch:[ 44 12 ] loss: 0.39767682552337646 2022-07-20 00:40:31.336988
Epoch:[ 44 13 ] loss: 0.3980123698711395 2022-07-20 00:40:31.751169
Epoch:[ 44 14 ] loss: 0.3952023684978485 2022-07-20 00:40:32.166423
Epoch:[ 44 15 ] loss: 0.3976973295211792 2022-07-20 00:40:32.580490
Epoch:[ 44 16 ] loss: 0.39922136068344116 2022-07-20 00:40:38.087799
Epoch:[ 44 17 ] loss: 0.39610448479652405 2022-07-20 00:40:38.496218
Epoch:[ 44 18 ] loss: 0.39898499846458435 2022-07-20 00:40:38.911416
Epoch:[ 44 19 ] loss: 0.39688149094581604 2022-07-20 00:40:39.324932
Training_Epoch:[ 44 ] Training_loss: 0.3965524062514305 2022-07-20 00:40:39.325824
learning rate:  0.00052200625
netparams have been saved once 44
val: 1 0.4060359001159668
val: 2 0.41024065017700195
val: 3 0.4107350707054138
val: 4 0.41185230016708374
val: 5 0.4125022888183594
val: 6 0.40220439434051514
val: 7 0.41654494404792786
val: 8 0.4127303957939148
val: 9 0.41056588292121887
val: 10 0.41417303681373596
val: 11 0.4055043160915375
val: 12 0.41039466857910156
val: 13 0.4130968451499939
val: 14 0.403208464384079
val: 15 0.4110852777957916
val: 16 0.40538227558135986
val: 17 0.41229692101478577
val: 18 0.41336098313331604
val: 19 0.40833771228790283
val: 20 0.4061020612716675
val_Epoch:[ 44 ] val_loss: 0.4098177194595337 2022-07-20 00:40:42.587557
start training 2022-07-20 00:40:42.688913
Epoch:[ 45 0 ] loss: 0.3955719769001007 2022-07-20 00:40:56.856599
Epoch:[ 45 1 ] loss: 0.3981539309024811 2022-07-20 00:40:57.272801
Epoch:[ 45 2 ] loss: 0.3976358473300934 2022-07-20 00:40:57.686208
Epoch:[ 45 3 ] loss: 0.3982914984226227 2022-07-20 00:40:58.099398
Epoch:[ 45 4 ] loss: 0.3966200053691864 2022-07-20 00:40:58.517403
Epoch:[ 45 5 ] loss: 0.3971642255783081 2022-07-20 00:40:58.930131
Epoch:[ 45 6 ] loss: 0.3960968255996704 2022-07-20 00:40:59.342789
Epoch:[ 45 7 ] loss: 0.39533907175064087 2022-07-20 00:40:59.758332
Epoch:[ 45 8 ] loss: 0.3954716622829437 2022-07-20 00:41:00.173600
Epoch:[ 45 9 ] loss: 0.3969331979751587 2022-07-20 00:41:00.592681
Epoch:[ 45 10 ] loss: 0.39823341369628906 2022-07-20 00:41:01.007600
Epoch:[ 45 11 ] loss: 0.3935847282409668 2022-07-20 00:41:01.420607
Epoch:[ 45 12 ] loss: 0.3967883288860321 2022-07-20 00:41:01.833713
Epoch:[ 45 13 ] loss: 0.3976019024848938 2022-07-20 00:41:02.246401
Epoch:[ 45 14 ] loss: 0.39473700523376465 2022-07-20 00:41:02.660678
Epoch:[ 45 15 ] loss: 0.39666831493377686 2022-07-20 00:41:03.082221
Epoch:[ 45 16 ] loss: 0.39793825149536133 2022-07-20 00:41:08.132117
Epoch:[ 45 17 ] loss: 0.3935817778110504 2022-07-20 00:41:08.542911
Epoch:[ 45 18 ] loss: 0.3966600298881531 2022-07-20 00:41:08.963635
Epoch:[ 45 19 ] loss: 0.396476149559021 2022-07-20 00:41:09.377862
Training_Epoch:[ 45 ] Training_loss: 0.39647740721702573 2022-07-20 00:41:09.378734
learning rate:  0.00052200625
val: 1 0.40517789125442505
val: 2 0.413290798664093
val: 3 0.42026665806770325
val: 4 0.41460591554641724
val: 5 0.4125176966190338
val: 6 0.4111543595790863
val: 7 0.4071849584579468
val: 8 0.41376516222953796
val: 9 0.4104310870170593
val: 10 0.4074850082397461
val: 11 0.4090941846370697
val: 12 0.4015553593635559
val: 13 0.4101802408695221
val: 14 0.4089142084121704
val: 15 0.4021286368370056
val: 16 0.4188310205936432
val: 17 0.40686672925949097
val: 18 0.40692776441574097
val: 19 0.40619686245918274
val: 20 0.4160292446613312
val_Epoch:[ 45 ] val_loss: 0.4101301893591881 2022-07-20 00:41:12.570453
start training 2022-07-20 00:41:12.669043
Epoch:[ 46 0 ] loss: 0.3977543115615845 2022-07-20 00:41:26.577210
Epoch:[ 46 1 ] loss: 0.3969608545303345 2022-07-20 00:41:26.991022
Epoch:[ 46 2 ] loss: 0.39443185925483704 2022-07-20 00:41:27.405120
Epoch:[ 46 3 ] loss: 0.396621972322464 2022-07-20 00:41:27.817082
Epoch:[ 46 4 ] loss: 0.394555002450943 2022-07-20 00:41:28.233802
Epoch:[ 46 5 ] loss: 0.3944835960865021 2022-07-20 00:41:28.646607
Epoch:[ 46 6 ] loss: 0.3945869207382202 2022-07-20 00:41:29.058576
Epoch:[ 46 7 ] loss: 0.39603191614151 2022-07-20 00:41:29.475946
Epoch:[ 46 8 ] loss: 0.39872685074806213 2022-07-20 00:41:29.889285
Epoch:[ 46 9 ] loss: 0.3993530571460724 2022-07-20 00:41:30.304958
Epoch:[ 46 10 ] loss: 0.3955174684524536 2022-07-20 00:41:30.719389
Epoch:[ 46 11 ] loss: 0.39760005474090576 2022-07-20 00:41:31.138810
Epoch:[ 46 12 ] loss: 0.3939563035964966 2022-07-20 00:41:31.551899
Epoch:[ 46 13 ] loss: 0.3967401683330536 2022-07-20 00:41:31.964892
Epoch:[ 46 14 ] loss: 0.3949824869632721 2022-07-20 00:41:32.376752
Epoch:[ 46 15 ] loss: 0.3969612419605255 2022-07-20 00:41:32.790398
Epoch:[ 46 16 ] loss: 0.3968992531299591 2022-07-20 00:41:37.823384
Epoch:[ 46 17 ] loss: 0.3931109607219696 2022-07-20 00:41:38.236076
Epoch:[ 46 18 ] loss: 0.3983295261859894 2022-07-20 00:41:38.652774
Epoch:[ 46 19 ] loss: 0.3956508934497833 2022-07-20 00:41:39.066891
Training_Epoch:[ 46 ] Training_loss: 0.39616273492574694 2022-07-20 00:41:39.067585
learning rate:  0.00052200625
netparams have been saved once 46
val: 1 0.40608179569244385
val: 2 0.40575289726257324
val: 3 0.40754926204681396
val: 4 0.4066096246242523
val: 5 0.40505731105804443
val: 6 0.40490204095840454
val: 7 0.40788668394088745
val: 8 0.4112966060638428
val: 9 0.4176008999347687
val: 10 0.40404778718948364
val: 11 0.4158422350883484
val: 12 0.4115872383117676
val: 13 0.4089711606502533
val: 14 0.40814709663391113
val: 15 0.4056786596775055
val: 16 0.4121568500995636
val: 17 0.4117116332054138
val: 18 0.4070846736431122
val: 19 0.4132692515850067
val: 20 0.41375985741615295
val_Epoch:[ 46 ] val_loss: 0.4092496782541275 2022-07-20 00:41:42.265575
start training 2022-07-20 00:41:42.363213
Epoch:[ 47 0 ] loss: 0.39553579688072205 2022-07-20 00:41:55.808849
Epoch:[ 47 1 ] loss: 0.3960777819156647 2022-07-20 00:41:56.462037
Epoch:[ 47 2 ] loss: 0.3928144872188568 2022-07-20 00:41:56.876813
Epoch:[ 47 3 ] loss: 0.3941599726676941 2022-07-20 00:41:57.289739
Epoch:[ 47 4 ] loss: 0.39443787932395935 2022-07-20 00:41:57.701128
Epoch:[ 47 5 ] loss: 0.3941623270511627 2022-07-20 00:41:58.116382
Epoch:[ 47 6 ] loss: 0.39264723658561707 2022-07-20 00:41:58.528003
Epoch:[ 47 7 ] loss: 0.3964254856109619 2022-07-20 00:41:58.940657
Epoch:[ 47 8 ] loss: 0.3927760124206543 2022-07-20 00:41:59.351917
Epoch:[ 47 9 ] loss: 0.39502277970314026 2022-07-20 00:41:59.766328
Epoch:[ 47 10 ] loss: 0.3947206735610962 2022-07-20 00:42:00.181397
Epoch:[ 47 11 ] loss: 0.39529019594192505 2022-07-20 00:42:00.593109
Epoch:[ 47 12 ] loss: 0.3934347927570343 2022-07-20 00:42:01.006713
Epoch:[ 47 13 ] loss: 0.39523303508758545 2022-07-20 00:42:01.419178
Epoch:[ 47 14 ] loss: 0.39728930592536926 2022-07-20 00:42:01.837353
Epoch:[ 47 15 ] loss: 0.39628365635871887 2022-07-20 00:42:02.254451
Epoch:[ 47 16 ] loss: 0.39482948184013367 2022-07-20 00:42:07.769072
Epoch:[ 47 17 ] loss: 0.3968466520309448 2022-07-20 00:42:08.183457
Epoch:[ 47 18 ] loss: 0.3957448899745941 2022-07-20 00:42:08.601600
Epoch:[ 47 19 ] loss: 0.3927205801010132 2022-07-20 00:42:09.022018
Training_Epoch:[ 47 ] Training_loss: 0.39482265114784243 2022-07-20 00:42:09.022641
learning rate:  0.00052200625
val: 1 0.40376022458076477
val: 2 0.4059709906578064
val: 3 0.407918244600296
val: 4 0.4072533845901489
val: 5 0.4187318980693817
val: 6 0.4054051339626312
val: 7 0.4111066460609436
val: 8 0.4048175513744354
val: 9 0.41419199109077454
val: 10 0.4055006206035614
val: 11 0.4092693626880646
val: 12 0.41361796855926514
val: 13 0.40917131304740906
val: 14 0.4050809442996979
val: 15 0.41366755962371826
val: 16 0.4103109538555145
val: 17 0.40276235342025757
val: 18 0.4046024680137634
val: 19 0.4150243401527405
val: 20 0.4032672643661499
val_Epoch:[ 47 ] val_loss: 0.40857156068086625 2022-07-20 00:42:12.150464
start training 2022-07-20 00:42:12.247648
Epoch:[ 48 0 ] loss: 0.3938787877559662 2022-07-20 00:42:26.218738
Epoch:[ 48 1 ] loss: 0.3930494487285614 2022-07-20 00:42:26.631928
Epoch:[ 48 2 ] loss: 0.3935818076133728 2022-07-20 00:42:27.042163
Epoch:[ 48 3 ] loss: 0.39239999651908875 2022-07-20 00:42:27.454514
Epoch:[ 48 4 ] loss: 0.3913835287094116 2022-07-20 00:42:27.872884
Epoch:[ 48 5 ] loss: 0.3927905261516571 2022-07-20 00:42:28.283049
Epoch:[ 48 6 ] loss: 0.39188554883003235 2022-07-20 00:42:28.694040
Epoch:[ 48 7 ] loss: 0.3930109143257141 2022-07-20 00:42:29.106421
Epoch:[ 48 8 ] loss: 0.3937329351902008 2022-07-20 00:42:29.523245
Epoch:[ 48 9 ] loss: 0.39163529872894287 2022-07-20 00:42:29.934981
Epoch:[ 48 10 ] loss: 0.3932894468307495 2022-07-20 00:42:30.348677
Epoch:[ 48 11 ] loss: 0.39385393261909485 2022-07-20 00:42:30.766786
Epoch:[ 48 12 ] loss: 0.39346837997436523 2022-07-20 00:42:31.177897
Epoch:[ 48 13 ] loss: 0.3944587707519531 2022-07-20 00:42:31.589355
Epoch:[ 48 14 ] loss: 0.39161908626556396 2022-07-20 00:42:32.001023
Epoch:[ 48 15 ] loss: 0.3954460024833679 2022-07-20 00:42:32.411713
Epoch:[ 48 16 ] loss: 0.3935145437717438 2022-07-20 00:42:37.865554
Epoch:[ 48 17 ] loss: 0.3935726583003998 2022-07-20 00:42:38.283874
Epoch:[ 48 18 ] loss: 0.3937528133392334 2022-07-20 00:42:38.705020
Epoch:[ 48 19 ] loss: 0.3942626118659973 2022-07-20 00:42:39.116680
Training_Epoch:[ 48 ] Training_loss: 0.39322935193777087 2022-07-20 00:42:39.117342
learning rate:  0.00052200625
netparams have been saved once 48
val: 1 0.41017159819602966
val: 2 0.4101867377758026
val: 3 0.41564321517944336
val: 4 0.4087561070919037
val: 5 0.40979060530662537
val: 6 0.4066646993160248
val: 7 0.40775781869888306
val: 8 0.40519091486930847
val: 9 0.40388110280036926
val: 10 0.40736228227615356
val: 11 0.40858030319213867
val: 12 0.40861061215400696
val: 13 0.4111497104167938
val: 14 0.41425254940986633
val: 15 0.4005672037601471
val: 16 0.40573880076408386
val: 17 0.41124117374420166
val: 18 0.41182518005371094
val: 19 0.4083084464073181
val: 20 0.4103972017765045
val_Epoch:[ 48 ] val_loss: 0.4088038131594658 2022-07-20 00:42:42.295563
start training 2022-07-20 00:42:42.393486
Epoch:[ 49 0 ] loss: 0.39226847887039185 2022-07-20 00:42:56.384903
Epoch:[ 49 1 ] loss: 0.39337992668151855 2022-07-20 00:42:56.796085
Epoch:[ 49 2 ] loss: 0.3948744833469391 2022-07-20 00:42:57.211100
Epoch:[ 49 3 ] loss: 0.393884539604187 2022-07-20 00:42:57.625823
Epoch:[ 49 4 ] loss: 0.39253002405166626 2022-07-20 00:42:58.045838
Epoch:[ 49 5 ] loss: 0.393311470746994 2022-07-20 00:42:58.459870
Epoch:[ 49 6 ] loss: 0.39364033937454224 2022-07-20 00:42:58.878370
Epoch:[ 49 7 ] loss: 0.39458176493644714 2022-07-20 00:42:59.290701
Epoch:[ 49 8 ] loss: 0.3932885527610779 2022-07-20 00:42:59.704346
Epoch:[ 49 9 ] loss: 0.39332664012908936 2022-07-20 00:43:00.116788
Epoch:[ 49 10 ] loss: 0.3912312686443329 2022-07-20 00:43:00.535893
Epoch:[ 49 11 ] loss: 0.39660242199897766 2022-07-20 00:43:00.950900
Epoch:[ 49 12 ] loss: 0.39570868015289307 2022-07-20 00:43:01.365767
Epoch:[ 49 13 ] loss: 0.3948744237422943 2022-07-20 00:43:01.779167
Epoch:[ 49 14 ] loss: 0.3947957158088684 2022-07-20 00:43:02.192182
Epoch:[ 49 15 ] loss: 0.3917921781539917 2022-07-20 00:43:02.605577
Epoch:[ 49 16 ] loss: 0.3944198489189148 2022-07-20 00:43:07.662333
Epoch:[ 49 17 ] loss: 0.39517882466316223 2022-07-20 00:43:08.079718
Epoch:[ 49 18 ] loss: 0.393662691116333 2022-07-20 00:43:08.494970
Epoch:[ 49 19 ] loss: 0.3949218988418579 2022-07-20 00:43:08.909385
Training_Epoch:[ 49 ] Training_loss: 0.39391370862722397 2022-07-20 00:43:08.910062
learning rate:  0.00052200625
val: 1 0.4243800938129425
val: 2 0.41541609168052673
val: 3 0.41699501872062683
val: 4 0.3989926278591156
val: 5 0.41368409991264343
val: 6 0.4118395447731018
val: 7 0.41869354248046875
val: 8 0.41271325945854187
val: 9 0.4068033695220947
val: 10 0.40812984108924866
val: 11 0.41067513823509216
val: 12 0.4190427362918854
val: 13 0.4129675626754761
val: 14 0.4144957363605499
val: 15 0.4047643840312958
val: 16 0.41772258281707764
val: 17 0.40637654066085815
val: 18 0.4156734049320221
val: 19 0.4176013469696045
val: 20 0.4152870178222656
val_Epoch:[ 49 ] val_loss: 0.4131126970052719 2022-07-20 00:43:12.093260
start training 2022-07-20 00:43:12.194170
Epoch:[ 50 0 ] loss: 0.3922029733657837 2022-07-20 00:43:25.933504
Epoch:[ 50 1 ] loss: 0.3933173418045044 2022-07-20 00:43:26.349071
Epoch:[ 50 2 ] loss: 0.39107808470726013 2022-07-20 00:43:26.761703
Epoch:[ 50 3 ] loss: 0.3929242491722107 2022-07-20 00:43:27.179045
Epoch:[ 50 4 ] loss: 0.3906491994857788 2022-07-20 00:43:27.591064
Epoch:[ 50 5 ] loss: 0.3926098346710205 2022-07-20 00:43:28.004825
Epoch:[ 50 6 ] loss: 0.39116358757019043 2022-07-20 00:43:28.419595
Epoch:[ 50 7 ] loss: 0.3913792073726654 2022-07-20 00:43:28.831579
Epoch:[ 50 8 ] loss: 0.39023610949516296 2022-07-20 00:43:29.243090
Epoch:[ 50 9 ] loss: 0.393167108297348 2022-07-20 00:43:29.660627
Epoch:[ 50 10 ] loss: 0.3943864405155182 2022-07-20 00:43:30.072826
Epoch:[ 50 11 ] loss: 0.39244958758354187 2022-07-20 00:43:30.486013
Epoch:[ 50 12 ] loss: 0.391830176115036 2022-07-20 00:43:30.899759
Epoch:[ 50 13 ] loss: 0.3906339704990387 2022-07-20 00:43:31.318615
Epoch:[ 50 14 ] loss: 0.3936629891395569 2022-07-20 00:43:31.730300
Epoch:[ 50 15 ] loss: 0.3934321403503418 2022-07-20 00:43:32.142378
Epoch:[ 50 16 ] loss: 0.3933621048927307 2022-07-20 00:43:37.382408
Epoch:[ 50 17 ] loss: 0.3939860165119171 2022-07-20 00:43:37.794582
Epoch:[ 50 18 ] loss: 0.3921844959259033 2022-07-20 00:43:38.208634
Epoch:[ 50 19 ] loss: 0.39165517687797546 2022-07-20 00:43:38.627670
Training_Epoch:[ 50 ] Training_loss: 0.39231553971767424 2022-07-20 00:43:38.628364
learning rate:  0.00052200625
netparams have been saved once 50
val: 1 0.40432003140449524
val: 2 0.4067293107509613
val: 3 0.4100871980190277
val: 4 0.41828086972236633
val: 5 0.4043639898300171
val: 6 0.39987391233444214
val: 7 0.40375468134880066
val: 8 0.4115898013114929
val: 9 0.408613383769989
val: 10 0.4079371392726898
val: 11 0.4042304754257202
val: 12 0.4051668047904968
val: 13 0.40771588683128357
val: 14 0.4145266115665436
val: 15 0.4114178717136383
val: 16 0.40635359287261963
val: 17 0.40762844681739807
val: 18 0.4020056426525116
val: 19 0.40353360772132874
val: 20 0.40751004219055176
val_Epoch:[ 50 ] val_loss: 0.4072819650173187 2022-07-20 00:43:41.766237
start training 2022-07-20 00:43:41.867673
Epoch:[ 51 0 ] loss: 0.3910210132598877 2022-07-20 00:43:55.808266
Epoch:[ 51 1 ] loss: 0.3910004496574402 2022-07-20 00:43:56.224073
Epoch:[ 51 2 ] loss: 0.390225350856781 2022-07-20 00:43:56.638157
Epoch:[ 51 3 ] loss: 0.38929417729377747 2022-07-20 00:43:57.051280
Epoch:[ 51 4 ] loss: 0.3886966109275818 2022-07-20 00:43:57.463657
Epoch:[ 51 5 ] loss: 0.3891773223876953 2022-07-20 00:43:57.881545
Epoch:[ 51 6 ] loss: 0.3905923664569855 2022-07-20 00:43:58.295425
Epoch:[ 51 7 ] loss: 0.3908204138278961 2022-07-20 00:43:58.711812
Epoch:[ 51 8 ] loss: 0.38965314626693726 2022-07-20 00:43:59.124387
Epoch:[ 51 9 ] loss: 0.3909606635570526 2022-07-20 00:43:59.537364
Epoch:[ 51 10 ] loss: 0.39005911350250244 2022-07-20 00:43:59.951102
Epoch:[ 51 11 ] loss: 0.39261123538017273 2022-07-20 00:44:00.369262
Epoch:[ 51 12 ] loss: 0.39121657609939575 2022-07-20 00:44:00.781556
Epoch:[ 51 13 ] loss: 0.3907281756401062 2022-07-20 00:44:01.195498
Epoch:[ 51 14 ] loss: 0.39056459069252014 2022-07-20 00:44:01.609270
Epoch:[ 51 15 ] loss: 0.39455100893974304 2022-07-20 00:44:02.022109
Epoch:[ 51 16 ] loss: 0.3907276391983032 2022-07-20 00:44:07.114141
Epoch:[ 51 17 ] loss: 0.3923983871936798 2022-07-20 00:44:07.531396
Epoch:[ 51 18 ] loss: 0.393532931804657 2022-07-20 00:44:07.944618
Epoch:[ 51 19 ] loss: 0.39347800612449646 2022-07-20 00:44:08.356462
Training_Epoch:[ 51 ] Training_loss: 0.3910654589533806 2022-07-20 00:44:08.357175
learning rate:  0.00044370531249999997
val: 1 0.40634095668792725
val: 2 0.4069483280181885
val: 3 0.404070109128952
val: 4 0.40340274572372437
val: 5 0.4146011471748352
val: 6 0.4011118710041046
val: 7 0.4073016345500946
val: 8 0.41765519976615906
val: 9 0.4083957374095917
val: 10 0.4023837149143219
val: 11 0.4150266647338867
val: 12 0.40541785955429077
val: 13 0.4041077792644501
val: 14 0.41315194964408875
val: 15 0.4074121415615082
val: 16 0.40483325719833374
val: 17 0.408378928899765
val: 18 0.40132051706314087
val: 19 0.4098270535469055
val: 20 0.4109710454940796
val_Epoch:[ 51 ] val_loss: 0.4076329320669174 2022-07-20 00:44:11.515431
start training 2022-07-20 00:44:11.616124
Epoch:[ 52 0 ] loss: 0.39052194356918335 2022-07-20 00:44:25.017821
Epoch:[ 52 1 ] loss: 0.3917907774448395 2022-07-20 00:44:25.548333
Epoch:[ 52 2 ] loss: 0.39479875564575195 2022-07-20 00:44:25.966928
Epoch:[ 52 3 ] loss: 0.3956376314163208 2022-07-20 00:44:26.382620
Epoch:[ 52 4 ] loss: 0.3915213346481323 2022-07-20 00:44:26.799374
Epoch:[ 52 5 ] loss: 0.39195168018341064 2022-07-20 00:44:27.213898
Epoch:[ 52 6 ] loss: 0.39253878593444824 2022-07-20 00:44:27.629408
Epoch:[ 52 7 ] loss: 0.3941073417663574 2022-07-20 00:44:28.044553
Epoch:[ 52 8 ] loss: 0.390287309885025 2022-07-20 00:44:28.459483
Epoch:[ 52 9 ] loss: 0.3939443528652191 2022-07-20 00:44:28.872403
Epoch:[ 52 10 ] loss: 0.3922523558139801 2022-07-20 00:44:29.285999
Epoch:[ 52 11 ] loss: 0.39168408513069153 2022-07-20 00:44:29.701407
Epoch:[ 52 12 ] loss: 0.3933965563774109 2022-07-20 00:44:30.115550
Epoch:[ 52 13 ] loss: 0.38978731632232666 2022-07-20 00:44:30.529239
Epoch:[ 52 14 ] loss: 0.3932427763938904 2022-07-20 00:44:30.945728
Epoch:[ 52 15 ] loss: 0.3912222981452942 2022-07-20 00:44:31.357580
Epoch:[ 52 16 ] loss: 0.38947001099586487 2022-07-20 00:44:36.751530
Epoch:[ 52 17 ] loss: 0.3903741240501404 2022-07-20 00:44:37.164491
Epoch:[ 52 18 ] loss: 0.3912806808948517 2022-07-20 00:44:37.585132
Epoch:[ 52 19 ] loss: 0.3917669951915741 2022-07-20 00:44:38.000154
Training_Epoch:[ 52 ] Training_loss: 0.3920788556337357 2022-07-20 00:44:38.000927
learning rate:  0.00044370531249999997
netparams have been saved once 52
val: 1 0.40083926916122437
val: 2 0.4075903296470642
val: 3 0.4101105332374573
val: 4 0.4019352197647095
val: 5 0.40001413226127625
val: 6 0.40964701771736145
val: 7 0.4059469997882843
val: 8 0.3984254002571106
val: 9 0.4087538719177246
val: 10 0.40421223640441895
val: 11 0.4028869867324829
val: 12 0.4015922546386719
val: 13 0.4108511209487915
val: 14 0.40011218190193176
val: 15 0.4072840213775635
val: 16 0.39982420206069946
val: 17 0.40143388509750366
val: 18 0.4089699685573578
val: 19 0.3992142081260681
val: 20 0.3997145891189575
val_Epoch:[ 52 ] val_loss: 0.403967921435833 2022-07-20 00:44:41.298588
start training 2022-07-20 00:44:41.402585
Epoch:[ 53 0 ] loss: 0.3880327641963959 2022-07-20 00:44:55.235160
Epoch:[ 53 1 ] loss: 0.3885129392147064 2022-07-20 00:44:55.668108
Epoch:[ 53 2 ] loss: 0.3904905915260315 2022-07-20 00:44:56.082555
Epoch:[ 53 3 ] loss: 0.388159841299057 2022-07-20 00:44:56.495006
Epoch:[ 53 4 ] loss: 0.3877829611301422 2022-07-20 00:44:56.911740
Epoch:[ 53 5 ] loss: 0.3882461190223694 2022-07-20 00:44:57.323848
Epoch:[ 53 6 ] loss: 0.38828426599502563 2022-07-20 00:44:57.736369
Epoch:[ 53 7 ] loss: 0.3901309072971344 2022-07-20 00:44:58.150868
Epoch:[ 53 8 ] loss: 0.39028996229171753 2022-07-20 00:44:58.565042
Epoch:[ 53 9 ] loss: 0.3909614384174347 2022-07-20 00:44:58.978890
Epoch:[ 53 10 ] loss: 0.38886621594429016 2022-07-20 00:44:59.397491
Epoch:[ 53 11 ] loss: 0.3901221454143524 2022-07-20 00:44:59.809053
Epoch:[ 53 12 ] loss: 0.3917856812477112 2022-07-20 00:45:00.221936
Epoch:[ 53 13 ] loss: 0.39121490716934204 2022-07-20 00:45:00.634233
Epoch:[ 53 14 ] loss: 0.39259985089302063 2022-07-20 00:45:01.048842
Epoch:[ 53 15 ] loss: 0.3898288309574127 2022-07-20 00:45:01.463927
Epoch:[ 53 16 ] loss: 0.3925767242908478 2022-07-20 00:45:06.655537
Epoch:[ 53 17 ] loss: 0.3921518325805664 2022-07-20 00:45:07.069534
Epoch:[ 53 18 ] loss: 0.39089685678482056 2022-07-20 00:45:07.481899
Epoch:[ 53 19 ] loss: 0.3908067047595978 2022-07-20 00:45:07.893985
Training_Epoch:[ 53 ] Training_loss: 0.39008707702159884 2022-07-20 00:45:07.894835
learning rate:  0.00044370531249999997
val: 1 0.4011459946632385
val: 2 0.40658804774284363
val: 3 0.4061979055404663
val: 4 0.39954331517219543
val: 5 0.4019935429096222
val: 6 0.40145552158355713
val: 7 0.4050372540950775
val: 8 0.4011639356613159
val: 9 0.40542298555374146
val: 10 0.3995049297809601
val: 11 0.40437090396881104
val: 12 0.40124598145484924
val: 13 0.41197943687438965
val: 14 0.41018933057785034
val: 15 0.3952914774417877
val: 16 0.4025671184062958
val: 17 0.4055057466030121
val: 18 0.4040820002555847
val: 19 0.407545268535614
val: 20 0.41410428285598755
val_Epoch:[ 53 ] val_loss: 0.40424674898386004 2022-07-20 00:45:11.031392
start training 2022-07-20 00:45:11.131545
Epoch:[ 54 0 ] loss: 0.3878665864467621 2022-07-20 00:45:25.082484
Epoch:[ 54 1 ] loss: 0.3893190920352936 2022-07-20 00:45:25.497161
Epoch:[ 54 2 ] loss: 0.388067364692688 2022-07-20 00:45:25.917869
Epoch:[ 54 3 ] loss: 0.3870072364807129 2022-07-20 00:45:26.331396
Epoch:[ 54 4 ] loss: 0.3886929154396057 2022-07-20 00:45:26.744705
Epoch:[ 54 5 ] loss: 0.3885040581226349 2022-07-20 00:45:27.159095
Epoch:[ 54 6 ] loss: 0.38996103405952454 2022-07-20 00:45:27.572804
Epoch:[ 54 7 ] loss: 0.38973745703697205 2022-07-20 00:45:27.985137
Epoch:[ 54 8 ] loss: 0.388783723115921 2022-07-20 00:45:28.403508
Epoch:[ 54 9 ] loss: 0.3893151581287384 2022-07-20 00:45:28.817758
Epoch:[ 54 10 ] loss: 0.3893609344959259 2022-07-20 00:45:29.232840
Epoch:[ 54 11 ] loss: 0.38800299167633057 2022-07-20 00:45:29.645867
Epoch:[ 54 12 ] loss: 0.3887408971786499 2022-07-20 00:45:30.057938
Epoch:[ 54 13 ] loss: 0.3891162574291229 2022-07-20 00:45:30.478304
Epoch:[ 54 14 ] loss: 0.39236587285995483 2022-07-20 00:45:30.891924
Epoch:[ 54 15 ] loss: 0.38807791471481323 2022-07-20 00:45:31.306050
Epoch:[ 54 16 ] loss: 0.38856062293052673 2022-07-20 00:45:36.597830
Epoch:[ 54 17 ] loss: 0.38960322737693787 2022-07-20 00:45:37.010448
Epoch:[ 54 18 ] loss: 0.3894348442554474 2022-07-20 00:45:37.424221
Epoch:[ 54 19 ] loss: 0.3896902799606323 2022-07-20 00:45:37.842570
Training_Epoch:[ 54 ] Training_loss: 0.38901042342185976 2022-07-20 00:45:37.843292
learning rate:  0.00044370531249999997
netparams have been saved once 54
val: 1 0.4030410647392273
val: 2 0.4078201651573181
val: 3 0.40026775002479553
val: 4 0.4039057493209839
val: 5 0.3986130356788635
val: 6 0.41209718585014343
val: 7 0.41040799021720886
val: 8 0.39526087045669556
val: 9 0.4120456874370575
val: 10 0.41162022948265076
val: 11 0.3996278643608093
val: 12 0.4012984037399292
val: 13 0.4015365540981293
val: 14 0.4080754816532135
val: 15 0.40339818596839905
val: 16 0.39911171793937683
val: 17 0.4041879177093506
val: 18 0.40907374024391174
val: 19 0.40440833568573
val: 20 0.4044785499572754
val_Epoch:[ 54 ] val_loss: 0.40451382398605346 2022-07-20 00:45:41.030695
start training 2022-07-20 00:45:41.134614
Epoch:[ 55 0 ] loss: 0.3879930377006531 2022-07-20 00:45:55.206564
Epoch:[ 55 1 ] loss: 0.38922640681266785 2022-07-20 00:45:55.619094
Epoch:[ 55 2 ] loss: 0.388392835855484 2022-07-20 00:45:56.032953
Epoch:[ 55 3 ] loss: 0.3891628384590149 2022-07-20 00:45:56.446725
Epoch:[ 55 4 ] loss: 0.38825926184654236 2022-07-20 00:45:56.860602
Epoch:[ 55 5 ] loss: 0.3891499936580658 2022-07-20 00:45:57.277937
Epoch:[ 55 6 ] loss: 0.3888024091720581 2022-07-20 00:45:57.690872
Epoch:[ 55 7 ] loss: 0.38778772950172424 2022-07-20 00:45:58.104629
Epoch:[ 55 8 ] loss: 0.3864000737667084 2022-07-20 00:45:58.517661
Epoch:[ 55 9 ] loss: 0.38649192452430725 2022-07-20 00:45:58.930553
Epoch:[ 55 10 ] loss: 0.3874146342277527 2022-07-20 00:45:59.344670
Epoch:[ 55 11 ] loss: 0.3878668248653412 2022-07-20 00:45:59.758665
Epoch:[ 55 12 ] loss: 0.39026278257369995 2022-07-20 00:46:00.170666
Epoch:[ 55 13 ] loss: 0.38885459303855896 2022-07-20 00:46:00.584723
Epoch:[ 55 14 ] loss: 0.38950568437576294 2022-07-20 00:46:00.998877
Epoch:[ 55 15 ] loss: 0.38707491755485535 2022-07-20 00:46:01.415981
Epoch:[ 55 16 ] loss: 0.38942646980285645 2022-07-20 00:46:06.450025
Epoch:[ 55 17 ] loss: 0.3884529769420624 2022-07-20 00:46:06.862756
Epoch:[ 55 18 ] loss: 0.38921093940734863 2022-07-20 00:46:07.280189
Epoch:[ 55 19 ] loss: 0.38982170820236206 2022-07-20 00:46:07.699654
Training_Epoch:[ 55 ] Training_loss: 0.3884779021143913 2022-07-20 00:46:07.700346
learning rate:  0.00044370531249999997
val: 1 0.4080236554145813
val: 2 0.41304725408554077
val: 3 0.41112449765205383
val: 4 0.4085890054702759
val: 5 0.41046014428138733
val: 6 0.41360336542129517
val: 7 0.4129139184951782
val: 8 0.4024469554424286
val: 9 0.4179219603538513
val: 10 0.4078846275806427
val: 11 0.41030603647232056
val: 12 0.4048682451248169
val: 13 0.4062943458557129
val: 14 0.4076204001903534
val: 15 0.4093295931816101
val: 16 0.40682125091552734
val: 17 0.40762925148010254
val: 18 0.41101372241973877
val: 19 0.4014483690261841
val: 20 0.41008272767066956
val_Epoch:[ 55 ] val_loss: 0.40907146632671354 2022-07-20 00:46:10.797985
start training 2022-07-20 00:46:10.896532
Epoch:[ 56 0 ] loss: 0.3892257511615753 2022-07-20 00:46:24.656730
Epoch:[ 56 1 ] loss: 0.3883167505264282 2022-07-20 00:46:25.071239
Epoch:[ 56 2 ] loss: 0.3863496482372284 2022-07-20 00:46:25.485224
Epoch:[ 56 3 ] loss: 0.38866734504699707 2022-07-20 00:46:25.897475
Epoch:[ 56 4 ] loss: 0.3880239427089691 2022-07-20 00:46:26.311270
Epoch:[ 56 5 ] loss: 0.3860246539115906 2022-07-20 00:46:26.723816
Epoch:[ 56 6 ] loss: 0.3896324038505554 2022-07-20 00:46:27.137617
Epoch:[ 56 7 ] loss: 0.3864654302597046 2022-07-20 00:46:27.552295
Epoch:[ 56 8 ] loss: 0.38913509249687195 2022-07-20 00:46:27.969459
Epoch:[ 56 9 ] loss: 0.38746416568756104 2022-07-20 00:46:28.381398
Epoch:[ 56 10 ] loss: 0.38841578364372253 2022-07-20 00:46:28.793588
Epoch:[ 56 11 ] loss: 0.3881050944328308 2022-07-20 00:46:29.208123
Epoch:[ 56 12 ] loss: 0.3877706229686737 2022-07-20 00:46:29.622872
Epoch:[ 56 13 ] loss: 0.3865940570831299 2022-07-20 00:46:30.035388
Epoch:[ 56 14 ] loss: 0.3879134953022003 2022-07-20 00:46:30.448606
Epoch:[ 56 15 ] loss: 0.3870769441127777 2022-07-20 00:46:30.867016
Epoch:[ 56 16 ] loss: 0.38649144768714905 2022-07-20 00:46:35.982527
Epoch:[ 56 17 ] loss: 0.38521671295166016 2022-07-20 00:46:36.397604
Epoch:[ 56 18 ] loss: 0.38659214973449707 2022-07-20 00:46:36.814179
Epoch:[ 56 19 ] loss: 0.38741785287857056 2022-07-20 00:46:37.227758
Training_Epoch:[ 56 ] Training_loss: 0.3875449672341347 2022-07-20 00:46:37.228441
learning rate:  0.00044370531249999997
netparams have been saved once 56
val: 1 0.40547052025794983
val: 2 0.4035160541534424
val: 3 0.4016813039779663
val: 4 0.4075480103492737
val: 5 0.4012460708618164
val: 6 0.40193238854408264
val: 7 0.40762606263160706
val: 8 0.40328407287597656
val: 9 0.4062442183494568
val: 10 0.39994218945503235
val: 11 0.4069761037826538
val: 12 0.40473437309265137
val: 13 0.4032791554927826
val: 14 0.39990630745887756
val: 15 0.4034229815006256
val: 16 0.4104623794555664
val: 17 0.4044795334339142
val: 18 0.3998544216156006
val: 19 0.4124062657356262
val: 20 0.4055978059768677
val_Epoch:[ 56 ] val_loss: 0.4044805109500885 2022-07-20 00:46:40.409681
start training 2022-07-20 00:46:40.509671
Epoch:[ 57 0 ] loss: 0.3879702389240265 2022-07-20 00:46:53.855548
Epoch:[ 57 1 ] loss: 0.38624683022499084 2022-07-20 00:46:54.590193
Epoch:[ 57 2 ] loss: 0.3862890601158142 2022-07-20 00:46:55.002508
Epoch:[ 57 3 ] loss: 0.38760536909103394 2022-07-20 00:46:55.419451
Epoch:[ 57 4 ] loss: 0.3844870626926422 2022-07-20 00:46:55.831558
Epoch:[ 57 5 ] loss: 0.3845270574092865 2022-07-20 00:46:56.245030
Epoch:[ 57 6 ] loss: 0.3858489394187927 2022-07-20 00:46:56.659004
Epoch:[ 57 7 ] loss: 0.3861725628376007 2022-07-20 00:46:57.072517
Epoch:[ 57 8 ] loss: 0.3867449462413788 2022-07-20 00:46:57.485290
Epoch:[ 57 9 ] loss: 0.38752511143684387 2022-07-20 00:46:57.897611
Epoch:[ 57 10 ] loss: 0.38875290751457214 2022-07-20 00:46:58.309275
Epoch:[ 57 11 ] loss: 0.3855489194393158 2022-07-20 00:46:58.721015
Epoch:[ 57 12 ] loss: 0.38662222027778625 2022-07-20 00:46:59.134425
Epoch:[ 57 13 ] loss: 0.38565492630004883 2022-07-20 00:46:59.548048
Epoch:[ 57 14 ] loss: 0.3857265114784241 2022-07-20 00:46:59.960234
Epoch:[ 57 15 ] loss: 0.3887503743171692 2022-07-20 00:47:00.373657
Epoch:[ 57 16 ] loss: 0.3868131935596466 2022-07-20 00:47:05.390239
Epoch:[ 57 17 ] loss: 0.3855554461479187 2022-07-20 00:47:05.885012
Epoch:[ 57 18 ] loss: 0.38510560989379883 2022-07-20 00:47:06.300147
Epoch:[ 57 19 ] loss: 0.3894966244697571 2022-07-20 00:47:06.712615
Training_Epoch:[ 57 ] Training_loss: 0.38657219558954237 2022-07-20 00:47:06.713282
learning rate:  0.00044370531249999997
val: 1 0.4015096426010132
val: 2 0.4089687168598175
val: 3 0.4017080068588257
val: 4 0.3992597460746765
val: 5 0.4129272401332855
val: 6 0.3982054591178894
val: 7 0.40371671319007874
val: 8 0.4064434766769409
val: 9 0.402841180562973
val: 10 0.406404972076416
val: 11 0.39768660068511963
val: 12 0.4063623249530792
val: 13 0.41304513812065125
val: 14 0.4099404513835907
val: 15 0.40671810507774353
val: 16 0.401858389377594
val: 17 0.4018499553203583
val: 18 0.4149130880832672
val: 19 0.40200960636138916
val: 20 0.4079224467277527
val_Epoch:[ 57 ] val_loss: 0.4052145630121231 2022-07-20 00:47:09.898825
start training 2022-07-20 00:47:09.997466
Epoch:[ 58 0 ] loss: 0.38636940717697144 2022-07-20 00:47:23.661265
Epoch:[ 58 1 ] loss: 0.3862878680229187 2022-07-20 00:47:24.079499
Epoch:[ 58 2 ] loss: 0.3856695592403412 2022-07-20 00:47:24.492656
Epoch:[ 58 3 ] loss: 0.38442888855934143 2022-07-20 00:47:24.905882
Epoch:[ 58 4 ] loss: 0.3883649706840515 2022-07-20 00:47:25.318966
Epoch:[ 58 5 ] loss: 0.38565537333488464 2022-07-20 00:47:25.731456
Epoch:[ 58 6 ] loss: 0.38810253143310547 2022-07-20 00:47:26.145812
Epoch:[ 58 7 ] loss: 0.38669079542160034 2022-07-20 00:47:26.565999
Epoch:[ 58 8 ] loss: 0.3882012963294983 2022-07-20 00:47:26.978662
Epoch:[ 58 9 ] loss: 0.3878178596496582 2022-07-20 00:47:27.391344
Epoch:[ 58 10 ] loss: 0.38771331310272217 2022-07-20 00:47:27.809925
Epoch:[ 58 11 ] loss: 0.3879925608634949 2022-07-20 00:47:28.223258
Epoch:[ 58 12 ] loss: 0.3869539499282837 2022-07-20 00:47:28.635902
Epoch:[ 58 13 ] loss: 0.38735508918762207 2022-07-20 00:47:29.049526
Epoch:[ 58 14 ] loss: 0.3886929452419281 2022-07-20 00:47:29.463363
Epoch:[ 58 15 ] loss: 0.38511714339256287 2022-07-20 00:47:29.876102
Epoch:[ 58 16 ] loss: 0.39022549986839294 2022-07-20 00:47:35.016817
Epoch:[ 58 17 ] loss: 0.38849905133247375 2022-07-20 00:47:35.479494
Epoch:[ 58 18 ] loss: 0.38570454716682434 2022-07-20 00:47:35.898274
Epoch:[ 58 19 ] loss: 0.39014753699302673 2022-07-20 00:47:36.310599
Training_Epoch:[ 58 ] Training_loss: 0.38729950934648516 2022-07-20 00:47:36.311285
learning rate:  0.00044370531249999997
netparams have been saved once 58
val: 1 0.40659666061401367
val: 2 0.4055677354335785
val: 3 0.4047889709472656
val: 4 0.39947056770324707
val: 5 0.40938669443130493
val: 6 0.4004198908805847
val: 7 0.4034141004085541
val: 8 0.4112193286418915
val: 9 0.4031432271003723
val: 10 0.39959517121315
val: 11 0.4052201807498932
val: 12 0.408483624458313
val: 13 0.4079403579235077
val: 14 0.3986516296863556
val: 15 0.4059719741344452
val: 16 0.40764185786247253
val: 17 0.40088728070259094
val: 18 0.40497657656669617
val: 19 0.4030631184577942
val: 20 0.4091925323009491
val_Epoch:[ 58 ] val_loss: 0.404781574010849 2022-07-20 00:47:39.532340
start training 2022-07-20 00:47:39.634456
Epoch:[ 59 0 ] loss: 0.3875114321708679 2022-07-20 00:47:53.386256
Epoch:[ 59 1 ] loss: 0.3864293396472931 2022-07-20 00:47:53.819138
Epoch:[ 59 2 ] loss: 0.38710111379623413 2022-07-20 00:47:54.233803
Epoch:[ 59 3 ] loss: 0.3865688443183899 2022-07-20 00:47:54.646797
Epoch:[ 59 4 ] loss: 0.38677310943603516 2022-07-20 00:47:55.065195
Epoch:[ 59 5 ] loss: 0.387190043926239 2022-07-20 00:47:55.476791
Epoch:[ 59 6 ] loss: 0.38720691204071045 2022-07-20 00:47:55.889372
Epoch:[ 59 7 ] loss: 0.3865281939506531 2022-07-20 00:47:56.304163
Epoch:[ 59 8 ] loss: 0.38665345311164856 2022-07-20 00:47:56.717711
Epoch:[ 59 9 ] loss: 0.38654711842536926 2022-07-20 00:47:57.129875
Epoch:[ 59 10 ] loss: 0.386396586894989 2022-07-20 00:47:57.544989
Epoch:[ 59 11 ] loss: 0.38809069991111755 2022-07-20 00:47:57.958408
Epoch:[ 59 12 ] loss: 0.3863506615161896 2022-07-20 00:47:58.373258
Epoch:[ 59 13 ] loss: 0.3873007297515869 2022-07-20 00:47:58.781746
Epoch:[ 59 14 ] loss: 0.38835152983665466 2022-07-20 00:47:59.196952
Epoch:[ 59 15 ] loss: 0.3881154954433441 2022-07-20 00:47:59.613323
Epoch:[ 59 16 ] loss: 0.3850848376750946 2022-07-20 00:48:04.376010
Epoch:[ 59 17 ] loss: 0.3883714973926544 2022-07-20 00:48:05.156422
Epoch:[ 59 18 ] loss: 0.38591328263282776 2022-07-20 00:48:05.572606
Epoch:[ 59 19 ] loss: 0.3883626163005829 2022-07-20 00:48:05.985438
Training_Epoch:[ 59 ] Training_loss: 0.3870423749089241 2022-07-20 00:48:05.986269
learning rate:  0.00044370531249999997
val: 1 0.4054647386074066
val: 2 0.39920774102211
val: 3 0.4042958915233612
val: 4 0.40503042936325073
val: 5 0.40215378999710083
val: 6 0.39930862188339233
val: 7 0.4054713845252991
val: 8 0.41194477677345276
val: 9 0.3997485935688019
val: 10 0.4241369962692261
val: 11 0.408751904964447
val: 12 0.40091589093208313
val: 13 0.4152955710887909
val: 14 0.4124024510383606
val: 15 0.41195592284202576
val: 16 0.4029249846935272
val: 17 0.4110623002052307
val: 18 0.39982283115386963
val: 19 0.3970126807689667
val: 20 0.39940693974494934
val_Epoch:[ 59 ] val_loss: 0.40581572204828265 2022-07-20 00:48:09.255839
start training 2022-07-20 00:48:09.355765
Epoch:[ 60 0 ] loss: 0.3836626410484314 2022-07-20 00:48:23.216389
Epoch:[ 60 1 ] loss: 0.385246217250824 2022-07-20 00:48:23.658414
Epoch:[ 60 2 ] loss: 0.3863883912563324 2022-07-20 00:48:24.074115
Epoch:[ 60 3 ] loss: 0.3865516781806946 2022-07-20 00:48:24.486729
Epoch:[ 60 4 ] loss: 0.3866226077079773 2022-07-20 00:48:24.899227
Epoch:[ 60 5 ] loss: 0.38633817434310913 2022-07-20 00:48:25.312071
Epoch:[ 60 6 ] loss: 0.3868255913257599 2022-07-20 00:48:25.724103
Epoch:[ 60 7 ] loss: 0.38648587465286255 2022-07-20 00:48:26.135785
Epoch:[ 60 8 ] loss: 0.38666483759880066 2022-07-20 00:48:26.547849
Epoch:[ 60 9 ] loss: 0.3863840103149414 2022-07-20 00:48:26.961992
Epoch:[ 60 10 ] loss: 0.38478341698646545 2022-07-20 00:48:27.377076
Epoch:[ 60 11 ] loss: 0.3875144124031067 2022-07-20 00:48:27.796207
Epoch:[ 60 12 ] loss: 0.3856443762779236 2022-07-20 00:48:28.208221
Epoch:[ 60 13 ] loss: 0.3872251808643341 2022-07-20 00:48:28.622196
Epoch:[ 60 14 ] loss: 0.3874691128730774 2022-07-20 00:48:29.035476
Epoch:[ 60 15 ] loss: 0.38436752557754517 2022-07-20 00:48:29.449304
Epoch:[ 60 16 ] loss: 0.3854881823062897 2022-07-20 00:48:34.696968
Epoch:[ 60 17 ] loss: 0.38889551162719727 2022-07-20 00:48:35.109154
Epoch:[ 60 18 ] loss: 0.3861217796802521 2022-07-20 00:48:35.524658
Epoch:[ 60 19 ] loss: 0.38804659247398376 2022-07-20 00:48:35.938605
Training_Epoch:[ 60 ] Training_loss: 0.38633630573749544 2022-07-20 00:48:35.939387
learning rate:  0.00044370531249999997
netparams have been saved once 60
val: 1 0.4073238968849182
val: 2 0.4015848934650421
val: 3 0.4026557207107544
val: 4 0.40569329261779785
val: 5 0.4042217433452606
val: 6 0.4134041368961334
val: 7 0.4039020240306854
val: 8 0.40340834856033325
val: 9 0.4128815829753876
val: 10 0.40707632899284363
val: 11 0.402668833732605
val: 12 0.4021703004837036
val: 13 0.40347975492477417
val: 14 0.4087478816509247
val: 15 0.4112713932991028
val: 16 0.404185950756073
val: 17 0.41043221950531006
val: 18 0.4028189778327942
val: 19 0.40306034684181213
val: 20 0.40577974915504456
val_Epoch:[ 60 ] val_loss: 0.405838368833065 2022-07-20 00:48:39.169078
start training 2022-07-20 00:48:39.272959
Epoch:[ 61 0 ] loss: 0.38500988483428955 2022-07-20 00:48:53.415340
Epoch:[ 61 1 ] loss: 0.3854266405105591 2022-07-20 00:48:53.828502
Epoch:[ 61 2 ] loss: 0.384872704744339 2022-07-20 00:48:54.244964
Epoch:[ 61 3 ] loss: 0.385164350271225 2022-07-20 00:48:54.661212
Epoch:[ 61 4 ] loss: 0.38439926505088806 2022-07-20 00:48:55.074575
Epoch:[ 61 5 ] loss: 0.3859677016735077 2022-07-20 00:48:55.489610
Epoch:[ 61 6 ] loss: 0.3856971859931946 2022-07-20 00:48:55.902695
Epoch:[ 61 7 ] loss: 0.3857751488685608 2022-07-20 00:48:56.316439
Epoch:[ 61 8 ] loss: 0.3833397626876831 2022-07-20 00:48:56.729315
Epoch:[ 61 9 ] loss: 0.3847256302833557 2022-07-20 00:48:57.144214
Epoch:[ 61 10 ] loss: 0.3857724666595459 2022-07-20 00:48:57.557670
Epoch:[ 61 11 ] loss: 0.38495200872421265 2022-07-20 00:48:57.968019
Epoch:[ 61 12 ] loss: 0.3863338232040405 2022-07-20 00:48:58.382689
Epoch:[ 61 13 ] loss: 0.3848755955696106 2022-07-20 00:48:58.797595
Epoch:[ 61 14 ] loss: 0.38411745429039 2022-07-20 00:48:59.212529
Epoch:[ 61 15 ] loss: 0.38443493843078613 2022-07-20 00:48:59.625277
Epoch:[ 61 16 ] loss: 0.3868253529071808 2022-07-20 00:49:04.896019
Epoch:[ 61 17 ] loss: 0.3829103112220764 2022-07-20 00:49:05.309893
Epoch:[ 61 18 ] loss: 0.383811354637146 2022-07-20 00:49:05.720417
Epoch:[ 61 19 ] loss: 0.38532859086990356 2022-07-20 00:49:06.135787
Training_Epoch:[ 61 ] Training_loss: 0.38498700857162477 2022-07-20 00:49:06.136485
learning rate:  0.00037714951562499996
val: 1 0.4095926582813263
val: 2 0.41132116317749023
val: 3 0.40296801924705505
val: 4 0.3999113440513611
val: 5 0.4125896990299225
val: 6 0.40294960141181946
val: 7 0.400821715593338
val: 8 0.4099282920360565
val: 9 0.4097220301628113
val: 10 0.4100008010864258
val: 11 0.4044782221317291
val: 12 0.40699106454849243
val: 13 0.4025043249130249
val: 14 0.4022188186645508
val: 15 0.3982464373111725
val: 16 0.40803903341293335
val: 17 0.3957769572734833
val: 18 0.40409985184669495
val: 19 0.40230825543403625
val: 20 0.4138560891151428
val_Epoch:[ 61 ] val_loss: 0.4054162189364433 2022-07-20 00:49:09.339059
start training 2022-07-20 00:49:09.442041
Epoch:[ 62 0 ] loss: 0.3840976357460022 2022-07-20 00:49:23.594967
Epoch:[ 62 1 ] loss: 0.38202765583992004 2022-07-20 00:49:24.010539
Epoch:[ 62 2 ] loss: 0.38531485199928284 2022-07-20 00:49:24.424863
Epoch:[ 62 3 ] loss: 0.38309693336486816 2022-07-20 00:49:24.838781
Epoch:[ 62 4 ] loss: 0.3835681974887848 2022-07-20 00:49:25.253937
Epoch:[ 62 5 ] loss: 0.3830071687698364 2022-07-20 00:49:25.669460
Epoch:[ 62 6 ] loss: 0.3846225142478943 2022-07-20 00:49:26.083409
Epoch:[ 62 7 ] loss: 0.38322141766548157 2022-07-20 00:49:26.494484
Epoch:[ 62 8 ] loss: 0.38372087478637695 2022-07-20 00:49:26.907199
Epoch:[ 62 9 ] loss: 0.3836803138256073 2022-07-20 00:49:27.320945
Epoch:[ 62 10 ] loss: 0.384509414434433 2022-07-20 00:49:27.736127
Epoch:[ 62 11 ] loss: 0.38332921266555786 2022-07-20 00:49:28.150924
Epoch:[ 62 12 ] loss: 0.3846248388290405 2022-07-20 00:49:28.564432
Epoch:[ 62 13 ] loss: 0.3854076564311981 2022-07-20 00:49:28.974230
Epoch:[ 62 14 ] loss: 0.38631200790405273 2022-07-20 00:49:29.389470
Epoch:[ 62 15 ] loss: 0.38342010974884033 2022-07-20 00:49:29.799065
Epoch:[ 62 16 ] loss: 0.3844865560531616 2022-07-20 00:49:34.978356
Epoch:[ 62 17 ] loss: 0.38213202357292175 2022-07-20 00:49:35.392901
Epoch:[ 62 18 ] loss: 0.38309526443481445 2022-07-20 00:49:35.808401
Epoch:[ 62 19 ] loss: 0.38456302881240845 2022-07-20 00:49:36.221204
Training_Epoch:[ 62 ] Training_loss: 0.38391188383102415 2022-07-20 00:49:36.221907
learning rate:  0.00037714951562499996
netparams have been saved once 62
val: 1 0.4065568149089813
val: 2 0.39880889654159546
val: 3 0.4074023962020874
val: 4 0.40495744347572327
val: 5 0.39688482880592346
val: 6 0.40223097801208496
val: 7 0.4051423966884613
val: 8 0.40740713477134705
val: 9 0.40550026297569275
val: 10 0.4044862687587738
val: 11 0.4106716215610504
val: 12 0.39909660816192627
val: 13 0.3973327577114105
val: 14 0.4011596441268921
val: 15 0.40714699029922485
val: 16 0.39926108717918396
val: 17 0.39667344093322754
val: 18 0.41322222352027893
val: 19 0.4002760350704193
val: 20 0.4045655429363251
val_Epoch:[ 62 ] val_loss: 0.4034391686320305 2022-07-20 00:49:39.484392
start training 2022-07-20 00:49:39.585853
Epoch:[ 63 0 ] loss: 0.382377952337265 2022-07-20 00:49:52.785017
Epoch:[ 63 1 ] loss: 0.384708970785141 2022-07-20 00:49:53.837124
Epoch:[ 63 2 ] loss: 0.3811133801937103 2022-07-20 00:49:54.250249
Epoch:[ 63 3 ] loss: 0.38594555854797363 2022-07-20 00:49:54.665107
Epoch:[ 63 4 ] loss: 0.38295963406562805 2022-07-20 00:49:55.078574
Epoch:[ 63 5 ] loss: 0.3850640654563904 2022-07-20 00:49:55.492893
Epoch:[ 63 6 ] loss: 0.38354575634002686 2022-07-20 00:49:55.905786
Epoch:[ 63 7 ] loss: 0.3829319477081299 2022-07-20 00:49:56.318608
Epoch:[ 63 8 ] loss: 0.3881772756576538 2022-07-20 00:49:56.730458
Epoch:[ 63 9 ] loss: 0.3832622766494751 2022-07-20 00:49:57.142812
Epoch:[ 63 10 ] loss: 0.3863464891910553 2022-07-20 00:49:57.554997
Epoch:[ 63 11 ] loss: 0.3841325044631958 2022-07-20 00:49:57.969240
Epoch:[ 63 12 ] loss: 0.38672780990600586 2022-07-20 00:49:58.383196
Epoch:[ 63 13 ] loss: 0.38486751914024353 2022-07-20 00:49:58.804244
Epoch:[ 63 14 ] loss: 0.3855028748512268 2022-07-20 00:49:59.221636
Epoch:[ 63 15 ] loss: 0.3844469487667084 2022-07-20 00:49:59.635308
Epoch:[ 63 16 ] loss: 0.38345542550086975 2022-07-20 00:50:04.401294
Epoch:[ 63 17 ] loss: 0.3859138786792755 2022-07-20 00:50:05.062905
Epoch:[ 63 18 ] loss: 0.3838251829147339 2022-07-20 00:50:05.477166
Epoch:[ 63 19 ] loss: 0.3845926523208618 2022-07-20 00:50:05.892193
Training_Epoch:[ 63 ] Training_loss: 0.38449490517377855 2022-07-20 00:50:05.893068
learning rate:  0.00037714951562499996
val: 1 0.397963285446167
val: 2 0.4123833477497101
val: 3 0.40337124466896057
val: 4 0.39844444394111633
val: 5 0.40008288621902466
val: 6 0.4095483124256134
val: 7 0.40061572194099426
val: 8 0.40695908665657043
val: 9 0.39642319083213806
val: 10 0.40176379680633545
val: 11 0.4095197319984436
val: 12 0.4000951051712036
val: 13 0.40661075711250305
val: 14 0.4076690673828125
val: 15 0.4131826162338257
val: 16 0.40714386105537415
val: 17 0.40669381618499756
val: 18 0.39662057161331177
val: 19 0.39658403396606445
val: 20 0.3984892666339874
val_Epoch:[ 63 ] val_loss: 0.4035082072019577 2022-07-20 00:50:09.194296
start training 2022-07-20 00:50:09.294086
Epoch:[ 64 0 ] loss: 0.38464784622192383 2022-07-20 00:50:23.078425
Epoch:[ 64 1 ] loss: 0.3843142092227936 2022-07-20 00:50:23.622763
Epoch:[ 64 2 ] loss: 0.3853094279766083 2022-07-20 00:50:24.032939
Epoch:[ 64 3 ] loss: 0.3828769624233246 2022-07-20 00:50:24.446810
Epoch:[ 64 4 ] loss: 0.3860780596733093 2022-07-20 00:50:24.860378
Epoch:[ 64 5 ] loss: 0.3833642899990082 2022-07-20 00:50:25.276575
Epoch:[ 64 6 ] loss: 0.38659238815307617 2022-07-20 00:50:25.691395
Epoch:[ 64 7 ] loss: 0.38159143924713135 2022-07-20 00:50:26.104364
Epoch:[ 64 8 ] loss: 0.3831667900085449 2022-07-20 00:50:26.516727
Epoch:[ 64 9 ] loss: 0.38225245475769043 2022-07-20 00:50:26.928936
Epoch:[ 64 10 ] loss: 0.3847872316837311 2022-07-20 00:50:27.343697
Epoch:[ 64 11 ] loss: 0.3822420537471771 2022-07-20 00:50:27.758751
Epoch:[ 64 12 ] loss: 0.38310515880584717 2022-07-20 00:50:28.172467
Epoch:[ 64 13 ] loss: 0.3824009597301483 2022-07-20 00:50:28.588256
Epoch:[ 64 14 ] loss: 0.38308587670326233 2022-07-20 00:50:29.001988
Epoch:[ 64 15 ] loss: 0.3844064772129059 2022-07-20 00:50:29.415195
Epoch:[ 64 16 ] loss: 0.3814890682697296 2022-07-20 00:50:34.554973
Epoch:[ 64 17 ] loss: 0.38418927788734436 2022-07-20 00:50:34.967886
Epoch:[ 64 18 ] loss: 0.384198933839798 2022-07-20 00:50:35.382732
Epoch:[ 64 19 ] loss: 0.3818506896495819 2022-07-20 00:50:35.793705
Training_Epoch:[ 64 ] Training_loss: 0.38359747976064684 2022-07-20 00:50:35.794358
learning rate:  0.00037714951562499996
netparams have been saved once 64
val: 1 0.40453964471817017
val: 2 0.40238532423973083
val: 3 0.39975669980049133
val: 4 0.4098779857158661
val: 5 0.4060363471508026
val: 6 0.4162987172603607
val: 7 0.39738327264785767
val: 8 0.4048548638820648
val: 9 0.40848150849342346
val: 10 0.4035164713859558
val: 11 0.4036663770675659
val: 12 0.3986114263534546
val: 13 0.40136510133743286
val: 14 0.4101189374923706
val: 15 0.4064309298992157
val: 16 0.40310683846473694
val: 17 0.4021441340446472
val: 18 0.3975845277309418
val: 19 0.40311604738235474
val: 20 0.4044400453567505
val_Epoch:[ 64 ] val_loss: 0.4041857600212097 2022-07-20 00:50:39.049533
start training 2022-07-20 00:50:39.150427
Epoch:[ 65 0 ] loss: 0.38386234641075134 2022-07-20 00:50:52.954743
Epoch:[ 65 1 ] loss: 0.38202184438705444 2022-07-20 00:50:53.374845
Epoch:[ 65 2 ] loss: 0.38419976830482483 2022-07-20 00:50:53.790863
Epoch:[ 65 3 ] loss: 0.3815898299217224 2022-07-20 00:50:54.205839
Epoch:[ 65 4 ] loss: 0.38268953561782837 2022-07-20 00:50:54.620468
Epoch:[ 65 5 ] loss: 0.38149914145469666 2022-07-20 00:50:55.034575
Epoch:[ 65 6 ] loss: 0.3824038803577423 2022-07-20 00:50:55.450159
Epoch:[ 65 7 ] loss: 0.3837430775165558 2022-07-20 00:50:55.867404
Epoch:[ 65 8 ] loss: 0.38196825981140137 2022-07-20 00:50:56.277703
Epoch:[ 65 9 ] loss: 0.38445791602134705 2022-07-20 00:50:56.690594
Epoch:[ 65 10 ] loss: 0.3810955286026001 2022-07-20 00:50:57.101648
Epoch:[ 65 11 ] loss: 0.3825356364250183 2022-07-20 00:50:57.515871
Epoch:[ 65 12 ] loss: 0.3828262388706207 2022-07-20 00:50:57.929721
Epoch:[ 65 13 ] loss: 0.3829936683177948 2022-07-20 00:50:58.344465
Epoch:[ 65 14 ] loss: 0.38127291202545166 2022-07-20 00:50:58.760198
Epoch:[ 65 15 ] loss: 0.38579511642456055 2022-07-20 00:50:59.174268
Epoch:[ 65 16 ] loss: 0.3820197284221649 2022-07-20 00:51:04.596163
Epoch:[ 65 17 ] loss: 0.3819279968738556 2022-07-20 00:51:05.005937
Epoch:[ 65 18 ] loss: 0.38201725482940674 2022-07-20 00:51:05.419757
Epoch:[ 65 19 ] loss: 0.38214612007141113 2022-07-20 00:51:05.834434
Training_Epoch:[ 65 ] Training_loss: 0.3826532900333405 2022-07-20 00:51:05.835235
learning rate:  0.00037714951562499996
val: 1 0.3990604281425476
val: 2 0.4096226692199707
val: 3 0.41173291206359863
val: 4 0.40530040860176086
val: 5 0.39905357360839844
val: 6 0.40281134843826294
val: 7 0.4001736342906952
val: 8 0.4089578688144684
val: 9 0.40577495098114014
val: 10 0.40126413106918335
val: 11 0.4018590450286865
val: 12 0.4010474979877472
val: 13 0.399242103099823
val: 14 0.40309345722198486
val: 15 0.39659157395362854
val: 16 0.40264472365379333
val: 17 0.40302684903144836
val: 18 0.40080541372299194
val: 19 0.40837377309799194
val: 20 0.40989094972610474
val_Epoch:[ 65 ] val_loss: 0.4035163655877113 2022-07-20 00:51:09.011789
start training 2022-07-20 00:51:09.113417
Epoch:[ 66 0 ] loss: 0.3813677132129669 2022-07-20 00:51:23.057832
Epoch:[ 66 1 ] loss: 0.3806035816669464 2022-07-20 00:51:23.505554
Epoch:[ 66 2 ] loss: 0.38111355900764465 2022-07-20 00:51:23.924920
Epoch:[ 66 3 ] loss: 0.3812500536441803 2022-07-20 00:51:24.336949
Epoch:[ 66 4 ] loss: 0.38260766863822937 2022-07-20 00:51:24.749567
Epoch:[ 66 5 ] loss: 0.3792118728160858 2022-07-20 00:51:25.163103
Epoch:[ 66 6 ] loss: 0.3808955252170563 2022-07-20 00:51:25.577707
Epoch:[ 66 7 ] loss: 0.3804716467857361 2022-07-20 00:51:25.997502
Epoch:[ 66 8 ] loss: 0.38101285696029663 2022-07-20 00:51:26.415134
Epoch:[ 66 9 ] loss: 0.3826836943626404 2022-07-20 00:51:26.826374
Epoch:[ 66 10 ] loss: 0.38274022936820984 2022-07-20 00:51:27.238627
Epoch:[ 66 11 ] loss: 0.38201600313186646 2022-07-20 00:51:27.651432
Epoch:[ 66 12 ] loss: 0.3805115818977356 2022-07-20 00:51:28.063748
Epoch:[ 66 13 ] loss: 0.3798929452896118 2022-07-20 00:51:28.476209
Epoch:[ 66 14 ] loss: 0.38201025128364563 2022-07-20 00:51:28.897741
Epoch:[ 66 15 ] loss: 0.3807261884212494 2022-07-20 00:51:29.310710
Epoch:[ 66 16 ] loss: 0.38149356842041016 2022-07-20 00:51:34.471679
Epoch:[ 66 17 ] loss: 0.38384899497032166 2022-07-20 00:51:34.884465
Epoch:[ 66 18 ] loss: 0.3814126253128052 2022-07-20 00:51:35.297606
Epoch:[ 66 19 ] loss: 0.38306087255477905 2022-07-20 00:51:35.715719
Training_Epoch:[ 66 ] Training_loss: 0.3814465716481209 2022-07-20 00:51:35.716509
learning rate:  0.00037714951562499996
netparams have been saved once 66
val: 1 0.4026317894458771
val: 2 0.4007863998413086
val: 3 0.398294597864151
val: 4 0.4018029570579529
val: 5 0.4084772765636444
val: 6 0.40601447224617004
val: 7 0.40122318267822266
val: 8 0.4040925204753876
val: 9 0.39582493901252747
val: 10 0.40795937180519104
val: 11 0.4044211506843567
val: 12 0.4070379436016083
val: 13 0.40922269225120544
val: 14 0.39933398365974426
val: 15 0.39250683784484863
val: 16 0.40218669176101685
val: 17 0.3976534903049469
val: 18 0.4032878577709198
val: 19 0.40490153431892395
val: 20 0.4002389907836914
val_Epoch:[ 66 ] val_loss: 0.4023949339985847 2022-07-20 00:51:38.986677
start training 2022-07-20 00:51:39.088400
Epoch:[ 67 0 ] loss: 0.37902000546455383 2022-07-20 00:51:53.258049
Epoch:[ 67 1 ] loss: 0.3811168968677521 2022-07-20 00:51:53.672736
Epoch:[ 67 2 ] loss: 0.38178035616874695 2022-07-20 00:51:54.086808
Epoch:[ 67 3 ] loss: 0.38148409128189087 2022-07-20 00:51:54.499316
Epoch:[ 67 4 ] loss: 0.38181281089782715 2022-07-20 00:51:54.916008
Epoch:[ 67 5 ] loss: 0.38054460287094116 2022-07-20 00:51:55.328384
Epoch:[ 67 6 ] loss: 0.3838791251182556 2022-07-20 00:51:55.741446
Epoch:[ 67 7 ] loss: 0.3803353011608124 2022-07-20 00:51:56.154991
Epoch:[ 67 8 ] loss: 0.38165852427482605 2022-07-20 00:51:56.569792
Epoch:[ 67 9 ] loss: 0.3809545040130615 2022-07-20 00:51:56.981633
Epoch:[ 67 10 ] loss: 0.3823353946208954 2022-07-20 00:51:57.394138
Epoch:[ 67 11 ] loss: 0.38090434670448303 2022-07-20 00:51:57.811135
Epoch:[ 67 12 ] loss: 0.3812582492828369 2022-07-20 00:51:58.223394
Epoch:[ 67 13 ] loss: 0.38398027420043945 2022-07-20 00:51:58.635790
Epoch:[ 67 14 ] loss: 0.3818119168281555 2022-07-20 00:51:59.056762
Epoch:[ 67 15 ] loss: 0.3800724744796753 2022-07-20 00:51:59.472344
Epoch:[ 67 16 ] loss: 0.38141798973083496 2022-07-20 00:52:04.492798
Epoch:[ 67 17 ] loss: 0.38101232051849365 2022-07-20 00:52:04.908357
Epoch:[ 67 18 ] loss: 0.38206619024276733 2022-07-20 00:52:05.321810
Epoch:[ 67 19 ] loss: 0.38147440552711487 2022-07-20 00:52:05.733164
Training_Epoch:[ 67 ] Training_loss: 0.3814459890127182 2022-07-20 00:52:05.733870
learning rate:  0.00037714951562499996
val: 1 0.40148335695266724
val: 2 0.40522679686546326
val: 3 0.3947902321815491
val: 4 0.4084007441997528
val: 5 0.4139159619808197
val: 6 0.4010455012321472
val: 7 0.40011802315711975
val: 8 0.4056030809879303
val: 9 0.4078396260738373
val: 10 0.4025319516658783
val: 11 0.40366029739379883
val: 12 0.40211230516433716
val: 13 0.4093334376811981
val: 14 0.39950621128082275
val: 15 0.40420079231262207
val: 16 0.4102683365345001
val: 17 0.4001826047897339
val: 18 0.39807501435279846
val: 19 0.3976316750049591
val: 20 0.39606866240501404
val_Epoch:[ 67 ] val_loss: 0.4030997306108475 2022-07-20 00:52:08.957328
start training 2022-07-20 00:52:09.061857
Epoch:[ 68 0 ] loss: 0.38070330023765564 2022-07-20 00:52:22.767864
Epoch:[ 68 1 ] loss: 0.38119176030158997 2022-07-20 00:52:23.195751
Epoch:[ 68 2 ] loss: 0.37946364283561707 2022-07-20 00:52:23.609046
Epoch:[ 68 3 ] loss: 0.38217201828956604 2022-07-20 00:52:24.021341
Epoch:[ 68 4 ] loss: 0.3804505169391632 2022-07-20 00:52:24.431958
Epoch:[ 68 5 ] loss: 0.38320913910865784 2022-07-20 00:52:24.844511
Epoch:[ 68 6 ] loss: 0.3832659423351288 2022-07-20 00:52:25.262932
Epoch:[ 68 7 ] loss: 0.38220643997192383 2022-07-20 00:52:25.673703
Epoch:[ 68 8 ] loss: 0.38332000374794006 2022-07-20 00:52:26.090843
Epoch:[ 68 9 ] loss: 0.3813024163246155 2022-07-20 00:52:26.503085
Epoch:[ 68 10 ] loss: 0.3830373287200928 2022-07-20 00:52:26.915889
Epoch:[ 68 11 ] loss: 0.38223758339881897 2022-07-20 00:52:27.326281
Epoch:[ 68 12 ] loss: 0.38244494795799255 2022-07-20 00:52:27.738002
Epoch:[ 68 13 ] loss: 0.38108354806900024 2022-07-20 00:52:28.148996
Epoch:[ 68 14 ] loss: 0.3808209002017975 2022-07-20 00:52:28.561259
Epoch:[ 68 15 ] loss: 0.3811168372631073 2022-07-20 00:52:28.974901
Epoch:[ 68 16 ] loss: 0.37806838750839233 2022-07-20 00:52:34.102499
Epoch:[ 68 17 ] loss: 0.38128381967544556 2022-07-20 00:52:34.728660
Epoch:[ 68 18 ] loss: 0.3798636198043823 2022-07-20 00:52:35.140701
Epoch:[ 68 19 ] loss: 0.3812611401081085 2022-07-20 00:52:35.551809
Training_Epoch:[ 68 ] Training_loss: 0.3814251646399498 2022-07-20 00:52:35.552496
learning rate:  0.00037714951562499996
netparams have been saved once 68
val: 1 0.39587485790252686
val: 2 0.3995111286640167
val: 3 0.40183502435684204
val: 4 0.41317659616470337
val: 5 0.4027867019176483
val: 6 0.3996032178401947
val: 7 0.3997609317302704
val: 8 0.4017272889614105
val: 9 0.3988054096698761
val: 10 0.400166779756546
val: 11 0.40144166350364685
val: 12 0.3989684581756592
val: 13 0.4026350677013397
val: 14 0.39743533730506897
val: 15 0.4001352787017822
val: 16 0.409962922334671
val: 17 0.4010697603225708
val: 18 0.3990870714187622
val: 19 0.39838582277297974
val: 20 0.40254852175712585
val_Epoch:[ 68 ] val_loss: 0.4012458920478821 2022-07-20 00:52:38.742710
start training 2022-07-20 00:52:38.846481
Epoch:[ 69 0 ] loss: 0.37843194603919983 2022-07-20 00:52:52.779839
Epoch:[ 69 1 ] loss: 0.38235923647880554 2022-07-20 00:52:53.193578
Epoch:[ 69 2 ] loss: 0.38121283054351807 2022-07-20 00:52:53.605914
Epoch:[ 69 3 ] loss: 0.3813371956348419 2022-07-20 00:52:54.026138
Epoch:[ 69 4 ] loss: 0.3797208070755005 2022-07-20 00:52:54.441405
Epoch:[ 69 5 ] loss: 0.3813134431838989 2022-07-20 00:52:54.855888
Epoch:[ 69 6 ] loss: 0.3792908489704132 2022-07-20 00:52:55.274998
Epoch:[ 69 7 ] loss: 0.3799540102481842 2022-07-20 00:52:55.688320
Epoch:[ 69 8 ] loss: 0.38096460700035095 2022-07-20 00:52:56.101217
Epoch:[ 69 9 ] loss: 0.37811845541000366 2022-07-20 00:52:56.513483
Epoch:[ 69 10 ] loss: 0.3825838565826416 2022-07-20 00:52:56.928700
Epoch:[ 69 11 ] loss: 0.3797470033168793 2022-07-20 00:52:57.339738
Epoch:[ 69 12 ] loss: 0.3810247480869293 2022-07-20 00:52:57.753263
Epoch:[ 69 13 ] loss: 0.3799055516719818 2022-07-20 00:52:58.168793
Epoch:[ 69 14 ] loss: 0.38040459156036377 2022-07-20 00:52:58.584098
Epoch:[ 69 15 ] loss: 0.38082215189933777 2022-07-20 00:52:58.998188
Epoch:[ 69 16 ] loss: 0.38067805767059326 2022-07-20 00:53:04.191586
Epoch:[ 69 17 ] loss: 0.38033363223075867 2022-07-20 00:53:04.605815
Epoch:[ 69 18 ] loss: 0.38127583265304565 2022-07-20 00:53:05.023513
Epoch:[ 69 19 ] loss: 0.37963593006134033 2022-07-20 00:53:05.445536
Training_Epoch:[ 69 ] Training_loss: 0.3804557368159294 2022-07-20 00:53:05.446330
learning rate:  0.00037714951562499996
val: 1 0.3930623531341553
val: 2 0.40754398703575134
val: 3 0.4004296064376831
val: 4 0.3982122242450714
val: 5 0.40169692039489746
val: 6 0.4048381745815277
val: 7 0.4128929376602173
val: 8 0.40139853954315186
val: 9 0.401190847158432
val: 10 0.4016474783420563
val: 11 0.4010675847530365
val: 12 0.3999626040458679
val: 13 0.4081122875213623
val: 14 0.4025192856788635
val: 15 0.39231574535369873
val: 16 0.4041983485221863
val: 17 0.40770748257637024
val: 18 0.4063302278518677
val: 19 0.4009680449962616
val: 20 0.3924529254436493
val_Epoch:[ 69 ] val_loss: 0.40192738026380537 2022-07-20 00:53:08.649153
start training 2022-07-20 00:53:08.751809
Epoch:[ 70 0 ] loss: 0.37909793853759766 2022-07-20 00:53:23.326734
Epoch:[ 70 1 ] loss: 0.37941721081733704 2022-07-20 00:53:23.745412
Epoch:[ 70 2 ] loss: 0.3783836364746094 2022-07-20 00:53:24.158050
Epoch:[ 70 3 ] loss: 0.3794223964214325 2022-07-20 00:53:24.570736
Epoch:[ 70 4 ] loss: 0.3785533905029297 2022-07-20 00:53:24.984821
Epoch:[ 70 5 ] loss: 0.38066864013671875 2022-07-20 00:53:25.400144
Epoch:[ 70 6 ] loss: 0.37966182827949524 2022-07-20 00:53:25.812366
Epoch:[ 70 7 ] loss: 0.38066962361335754 2022-07-20 00:53:26.226984
Epoch:[ 70 8 ] loss: 0.3816207945346832 2022-07-20 00:53:26.639370
Epoch:[ 70 9 ] loss: 0.378573477268219 2022-07-20 00:53:27.052273
Epoch:[ 70 10 ] loss: 0.38336890935897827 2022-07-20 00:53:27.468170
Epoch:[ 70 11 ] loss: 0.3800613284111023 2022-07-20 00:53:27.879125
Epoch:[ 70 12 ] loss: 0.38066229224205017 2022-07-20 00:53:28.294116
Epoch:[ 70 13 ] loss: 0.38056033849716187 2022-07-20 00:53:28.708382
Epoch:[ 70 14 ] loss: 0.3825288712978363 2022-07-20 00:53:29.122117
Epoch:[ 70 15 ] loss: 0.3807359039783478 2022-07-20 00:53:29.537057
Epoch:[ 70 16 ] loss: 0.38027849793434143 2022-07-20 00:53:34.335271
Epoch:[ 70 17 ] loss: 0.3793599307537079 2022-07-20 00:53:34.750758
Epoch:[ 70 18 ] loss: 0.3806036114692688 2022-07-20 00:53:35.168578
Epoch:[ 70 19 ] loss: 0.38079890608787537 2022-07-20 00:53:35.583501
Training_Epoch:[ 70 ] Training_loss: 0.3802513763308525 2022-07-20 00:53:35.584375
learning rate:  0.00037714951562499996
netparams have been saved once 70
val: 1 0.40834733843803406
val: 2 0.40708401799201965
val: 3 0.4051985442638397
val: 4 0.40789616107940674
val: 5 0.39541009068489075
val: 6 0.410917729139328
val: 7 0.4110235571861267
val: 8 0.409747451543808
val: 9 0.4006631076335907
val: 10 0.40194812417030334
val: 11 0.3954315185546875
val: 12 0.39604565501213074
val: 13 0.40453657507896423
val: 14 0.40697529911994934
val: 15 0.4021260440349579
val: 16 0.4063652455806732
val: 17 0.4029635787010193
val: 18 0.4014231860637665
val: 19 0.4010551869869232
val: 20 0.39679253101348877
val_Epoch:[ 70 ] val_loss: 0.4035975471138954 2022-07-20 00:53:38.811162
start training 2022-07-20 00:53:38.911074
Epoch:[ 71 0 ] loss: 0.3780796229839325 2022-07-20 00:53:53.072414
Epoch:[ 71 1 ] loss: 0.37669333815574646 2022-07-20 00:53:53.486725
Epoch:[ 71 2 ] loss: 0.3784906268119812 2022-07-20 00:53:53.902320
Epoch:[ 71 3 ] loss: 0.37835389375686646 2022-07-20 00:53:54.314884
Epoch:[ 71 4 ] loss: 0.3796756863594055 2022-07-20 00:53:54.728930
Epoch:[ 71 5 ] loss: 0.3784635663032532 2022-07-20 00:53:55.143837
Epoch:[ 71 6 ] loss: 0.37823376059532166 2022-07-20 00:53:55.558917
Epoch:[ 71 7 ] loss: 0.3790397644042969 2022-07-20 00:53:55.974664
Epoch:[ 71 8 ] loss: 0.37752771377563477 2022-07-20 00:53:56.387688
Epoch:[ 71 9 ] loss: 0.3782099187374115 2022-07-20 00:53:56.801942
Epoch:[ 71 10 ] loss: 0.379770964384079 2022-07-20 00:53:57.212207
Epoch:[ 71 11 ] loss: 0.38096311688423157 2022-07-20 00:53:57.629986
Epoch:[ 71 12 ] loss: 0.3773532211780548 2022-07-20 00:53:58.043314
Epoch:[ 71 13 ] loss: 0.37735751271247864 2022-07-20 00:53:58.457702
Epoch:[ 71 14 ] loss: 0.3801611363887787 2022-07-20 00:53:58.876234
Epoch:[ 71 15 ] loss: 0.38013944029808044 2022-07-20 00:53:59.289083
Epoch:[ 71 16 ] loss: 0.3809325397014618 2022-07-20 00:54:04.038349
Epoch:[ 71 17 ] loss: 0.37827640771865845 2022-07-20 00:54:04.456730
Epoch:[ 71 18 ] loss: 0.38213860988616943 2022-07-20 00:54:04.873952
Epoch:[ 71 19 ] loss: 0.3797788619995117 2022-07-20 00:54:05.288425
Training_Epoch:[ 71 ] Training_loss: 0.37898198515176773 2022-07-20 00:54:05.289131
learning rate:  0.00032057708828124994
val: 1 0.4083828628063202
val: 2 0.41056978702545166
val: 3 0.39727166295051575
val: 4 0.41011667251586914
val: 5 0.40280234813690186
val: 6 0.4039516746997833
val: 7 0.4038275182247162
val: 8 0.40328213572502136
val: 9 0.407780259847641
val: 10 0.39739179611206055
val: 11 0.4029650390148163
val: 12 0.4112953245639801
val: 13 0.40877342224121094
val: 14 0.3988510072231293
val: 15 0.4016246497631073
val: 16 0.40107041597366333
val: 17 0.4035242795944214
val: 18 0.40571144223213196
val: 19 0.4006873369216919
val: 20 0.41036394238471985
val_Epoch:[ 71 ] val_loss: 0.4045121788978577 2022-07-20 00:54:08.519783
start training 2022-07-20 00:54:08.625393
Epoch:[ 72 0 ] loss: 0.3782827854156494 2022-07-20 00:54:22.416185
Epoch:[ 72 1 ] loss: 0.3770592510700226 2022-07-20 00:54:22.846039
Epoch:[ 72 2 ] loss: 0.38014012575149536 2022-07-20 00:54:23.255405
Epoch:[ 72 3 ] loss: 0.37890204787254333 2022-07-20 00:54:23.670300
Epoch:[ 72 4 ] loss: 0.37856778502464294 2022-07-20 00:54:24.084831
Epoch:[ 72 5 ] loss: 0.3778105080127716 2022-07-20 00:54:24.498258
Epoch:[ 72 6 ] loss: 0.3763645887374878 2022-07-20 00:54:24.914117
Epoch:[ 72 7 ] loss: 0.3796912729740143 2022-07-20 00:54:25.328808
Epoch:[ 72 8 ] loss: 0.37862417101860046 2022-07-20 00:54:25.742751
Epoch:[ 72 9 ] loss: 0.37968316674232483 2022-07-20 00:54:26.154747
Epoch:[ 72 10 ] loss: 0.37848761677742004 2022-07-20 00:54:26.568979
Epoch:[ 72 11 ] loss: 0.3767395317554474 2022-07-20 00:54:26.982542
Epoch:[ 72 12 ] loss: 0.3792222738265991 2022-07-20 00:54:27.395931
Epoch:[ 72 13 ] loss: 0.37831446528434753 2022-07-20 00:54:27.807382
Epoch:[ 72 14 ] loss: 0.37773874402046204 2022-07-20 00:54:28.221906
Epoch:[ 72 15 ] loss: 0.3797694146633148 2022-07-20 00:54:28.635237
Epoch:[ 72 16 ] loss: 0.3793514370918274 2022-07-20 00:54:34.045965
Epoch:[ 72 17 ] loss: 0.37903448939323425 2022-07-20 00:54:34.454664
Epoch:[ 72 18 ] loss: 0.37831512093544006 2022-07-20 00:54:34.869725
Epoch:[ 72 19 ] loss: 0.38069412112236023 2022-07-20 00:54:35.283094
Training_Epoch:[ 72 ] Training_loss: 0.3786396458745003 2022-07-20 00:54:35.283750
learning rate:  0.00032057708828124994
netparams have been saved once 72
val: 1 0.39929482340812683
val: 2 0.40064340829849243
val: 3 0.39829176664352417
val: 4 0.3959866464138031
val: 5 0.3961089253425598
val: 6 0.4009031057357788
val: 7 0.41040459275245667
val: 8 0.40450364351272583
val: 9 0.4144481420516968
val: 10 0.40223759412765503
val: 11 0.3968738913536072
val: 12 0.40137606859207153
val: 13 0.4035786986351013
val: 14 0.40340861678123474
val: 15 0.3972229063510895
val: 16 0.40680456161499023
val: 17 0.39692413806915283
val: 18 0.40656861662864685
val: 19 0.4033445715904236
val: 20 0.3993667960166931
val_Epoch:[ 72 ] val_loss: 0.40191457569599154 2022-07-20 00:54:38.566940
start training 2022-07-20 00:54:38.668889
Epoch:[ 73 0 ] loss: 0.3781299591064453 2022-07-20 00:54:52.650727
Epoch:[ 73 1 ] loss: 0.3767632842063904 2022-07-20 00:54:53.068308
Epoch:[ 73 2 ] loss: 0.37821316719055176 2022-07-20 00:54:53.485247
Epoch:[ 73 3 ] loss: 0.37780454754829407 2022-07-20 00:54:53.900005
Epoch:[ 73 4 ] loss: 0.3797934651374817 2022-07-20 00:54:54.313979
Epoch:[ 73 5 ] loss: 0.3764606714248657 2022-07-20 00:54:54.727231
Epoch:[ 73 6 ] loss: 0.37976935505867004 2022-07-20 00:54:55.139367
Epoch:[ 73 7 ] loss: 0.3763309717178345 2022-07-20 00:54:55.555335
Epoch:[ 73 8 ] loss: 0.3759653866291046 2022-07-20 00:54:55.970891
Epoch:[ 73 9 ] loss: 0.3769834339618683 2022-07-20 00:54:56.384627
Epoch:[ 73 10 ] loss: 0.37869492173194885 2022-07-20 00:54:56.801326
Epoch:[ 73 11 ] loss: 0.3766463100910187 2022-07-20 00:54:57.215754
Epoch:[ 73 12 ] loss: 0.37777525186538696 2022-07-20 00:54:57.626142
Epoch:[ 73 13 ] loss: 0.3786480128765106 2022-07-20 00:54:58.036490
Epoch:[ 73 14 ] loss: 0.3800145089626312 2022-07-20 00:54:58.452073
Epoch:[ 73 15 ] loss: 0.3768480718135834 2022-07-20 00:54:58.866431
Epoch:[ 73 16 ] loss: 0.3771454691886902 2022-07-20 00:55:04.229286
Epoch:[ 73 17 ] loss: 0.378553569316864 2022-07-20 00:55:04.638016
Epoch:[ 73 18 ] loss: 0.37791040539741516 2022-07-20 00:55:05.052808
Epoch:[ 73 19 ] loss: 0.3784969747066498 2022-07-20 00:55:05.465969
Training_Epoch:[ 73 ] Training_loss: 0.37784738689661024 2022-07-20 00:55:05.466715
learning rate:  0.00032057708828124994
val: 1 0.40256527066230774
val: 2 0.3911508321762085
val: 3 0.41137856245040894
val: 4 0.396408349275589
val: 5 0.3989267349243164
val: 6 0.40864700078964233
val: 7 0.40705347061157227
val: 8 0.4007932245731354
val: 9 0.4020765721797943
val: 10 0.4054073691368103
val: 11 0.40992483496665955
val: 12 0.3979736566543579
val: 13 0.4059232473373413
val: 14 0.4091947376728058
val: 15 0.401395708322525
val: 16 0.4055333733558655
val: 17 0.410359263420105
val: 18 0.4002077877521515
val: 19 0.40134555101394653
val: 20 0.4002965986728668
val_Epoch:[ 73 ] val_loss: 0.4033281072974205 2022-07-20 00:55:08.674120
start training 2022-07-20 00:55:08.778236
Epoch:[ 74 0 ] loss: 0.37584981322288513 2022-07-20 00:55:23.018729
Epoch:[ 74 1 ] loss: 0.3769717216491699 2022-07-20 00:55:23.434411
Epoch:[ 74 2 ] loss: 0.3775944113731384 2022-07-20 00:55:23.851253
Epoch:[ 74 3 ] loss: 0.3758803606033325 2022-07-20 00:55:24.261926
Epoch:[ 74 4 ] loss: 0.3753376603126526 2022-07-20 00:55:24.676185
Epoch:[ 74 5 ] loss: 0.3778446614742279 2022-07-20 00:55:25.091516
Epoch:[ 74 6 ] loss: 0.3779727816581726 2022-07-20 00:55:25.504514
Epoch:[ 74 7 ] loss: 0.37605610489845276 2022-07-20 00:55:25.917132
Epoch:[ 74 8 ] loss: 0.37735897302627563 2022-07-20 00:55:26.331932
Epoch:[ 74 9 ] loss: 0.37650081515312195 2022-07-20 00:55:26.748286
Epoch:[ 74 10 ] loss: 0.3791525959968567 2022-07-20 00:55:27.164943
Epoch:[ 74 11 ] loss: 0.37764912843704224 2022-07-20 00:55:27.581265
Epoch:[ 74 12 ] loss: 0.3775642514228821 2022-07-20 00:55:27.991865
Epoch:[ 74 13 ] loss: 0.3783281147480011 2022-07-20 00:55:28.406947
Epoch:[ 74 14 ] loss: 0.37756454944610596 2022-07-20 00:55:28.820547
Epoch:[ 74 15 ] loss: 0.37964773178100586 2022-07-20 00:55:29.236542
Epoch:[ 74 16 ] loss: 0.3770778179168701 2022-07-20 00:55:34.297388
Epoch:[ 74 17 ] loss: 0.3783670961856842 2022-07-20 00:55:34.705380
Epoch:[ 74 18 ] loss: 0.3781062066555023 2022-07-20 00:55:35.121180
Epoch:[ 74 19 ] loss: 0.3789781928062439 2022-07-20 00:55:35.535882
Training_Epoch:[ 74 ] Training_loss: 0.3774901494383812 2022-07-20 00:55:35.536596
learning rate:  0.00032057708828124994
netparams have been saved once 74
val: 1 0.39993834495544434
val: 2 0.4036634862422943
val: 3 0.39315104484558105
val: 4 0.39617738127708435
val: 5 0.4065811038017273
val: 6 0.4009789228439331
val: 7 0.39841753244400024
val: 8 0.4025607109069824
val: 9 0.4021405279636383
val: 10 0.40366989374160767
val: 11 0.4068821370601654
val: 12 0.4035041332244873
val: 13 0.3986056447029114
val: 14 0.40493521094322205
val: 15 0.40046587586402893
val: 16 0.4023602306842804
val: 17 0.39894768595695496
val: 18 0.40180447697639465
val: 19 0.3941557705402374
val: 20 0.4069204032421112
val_Epoch:[ 74 ] val_loss: 0.40129302591085436 2022-07-20 00:55:38.774458
start training 2022-07-20 00:55:38.878378
Epoch:[ 75 0 ] loss: 0.37787339091300964 2022-07-20 00:55:52.972192
Epoch:[ 75 1 ] loss: 0.3762207329273224 2022-07-20 00:55:53.381919
Epoch:[ 75 2 ] loss: 0.37717926502227783 2022-07-20 00:55:53.799128
Epoch:[ 75 3 ] loss: 0.37609022855758667 2022-07-20 00:55:54.214221
Epoch:[ 75 4 ] loss: 0.3758351504802704 2022-07-20 00:55:54.628102
Epoch:[ 75 5 ] loss: 0.37663739919662476 2022-07-20 00:55:55.043692
Epoch:[ 75 6 ] loss: 0.3767533004283905 2022-07-20 00:55:55.458028
Epoch:[ 75 7 ] loss: 0.37705886363983154 2022-07-20 00:55:55.866996
Epoch:[ 75 8 ] loss: 0.37743961811065674 2022-07-20 00:55:56.281478
Epoch:[ 75 9 ] loss: 0.3783378005027771 2022-07-20 00:55:56.697016
Epoch:[ 75 10 ] loss: 0.37664616107940674 2022-07-20 00:55:57.113948
Epoch:[ 75 11 ] loss: 0.37650546431541443 2022-07-20 00:55:57.529657
Epoch:[ 75 12 ] loss: 0.3789024353027344 2022-07-20 00:55:57.944541
Epoch:[ 75 13 ] loss: 0.3782721161842346 2022-07-20 00:55:58.354042
Epoch:[ 75 14 ] loss: 0.3780311346054077 2022-07-20 00:55:58.768887
Epoch:[ 75 15 ] loss: 0.3794773817062378 2022-07-20 00:55:59.182801
Epoch:[ 75 16 ] loss: 0.3775584101676941 2022-07-20 00:56:04.322186
Epoch:[ 75 17 ] loss: 0.37684959173202515 2022-07-20 00:56:04.735569
Epoch:[ 75 18 ] loss: 0.3764411509037018 2022-07-20 00:56:05.150515
Epoch:[ 75 19 ] loss: 0.37869274616241455 2022-07-20 00:56:05.566130
Training_Epoch:[ 75 ] Training_loss: 0.37734011709690096 2022-07-20 00:56:05.566837
learning rate:  0.00032057708828124994
val: 1 0.39392176270484924
val: 2 0.40008822083473206
val: 3 0.402639240026474
val: 4 0.40759941935539246
val: 5 0.4010232090950012
val: 6 0.41010987758636475
val: 7 0.4029981791973114
val: 8 0.39699864387512207
val: 9 0.39752474427223206
val: 10 0.4049813151359558
val: 11 0.4012475907802582
val: 12 0.3915356397628784
val: 13 0.39922860264778137
val: 14 0.3986404538154602
val: 15 0.40100201964378357
val: 16 0.4064803421497345
val: 17 0.40614205598831177
val: 18 0.39714518189430237
val: 19 0.4017665386199951
val: 20 0.4074195921421051
val_Epoch:[ 75 ] val_loss: 0.4014246314764023 2022-07-20 00:56:08.734182
start training 2022-07-20 00:56:08.836604
Epoch:[ 76 0 ] loss: 0.37661173939704895 2022-07-20 00:56:22.928748
Epoch:[ 76 1 ] loss: 0.376181036233902 2022-07-20 00:56:23.341789
Epoch:[ 76 2 ] loss: 0.37610748410224915 2022-07-20 00:56:23.755547
Epoch:[ 76 3 ] loss: 0.37696516513824463 2022-07-20 00:56:24.168533
Epoch:[ 76 4 ] loss: 0.37660831212997437 2022-07-20 00:56:24.582075
Epoch:[ 76 5 ] loss: 0.37568238377571106 2022-07-20 00:56:24.993395
Epoch:[ 76 6 ] loss: 0.3769352436065674 2022-07-20 00:56:25.407679
Epoch:[ 76 7 ] loss: 0.374785840511322 2022-07-20 00:56:25.818013
Epoch:[ 76 8 ] loss: 0.3754138946533203 2022-07-20 00:56:26.233433
Epoch:[ 76 9 ] loss: 0.37498465180397034 2022-07-20 00:56:26.647004
Epoch:[ 76 10 ] loss: 0.37631550431251526 2022-07-20 00:56:27.062546
Epoch:[ 76 11 ] loss: 0.3768348693847656 2022-07-20 00:56:27.476339
Epoch:[ 76 12 ] loss: 0.37699276208877563 2022-07-20 00:56:27.890622
Epoch:[ 76 13 ] loss: 0.3770885467529297 2022-07-20 00:56:28.309267
Epoch:[ 76 14 ] loss: 0.37578320503234863 2022-07-20 00:56:28.728049
Epoch:[ 76 15 ] loss: 0.3771008849143982 2022-07-20 00:56:29.141402
Epoch:[ 76 16 ] loss: 0.37790364027023315 2022-07-20 00:56:34.423690
Epoch:[ 76 17 ] loss: 0.3770367205142975 2022-07-20 00:56:34.838539
Epoch:[ 76 18 ] loss: 0.3761557936668396 2022-07-20 00:56:35.255874
Epoch:[ 76 19 ] loss: 0.37611955404281616 2022-07-20 00:56:35.664287
Training_Epoch:[ 76 ] Training_loss: 0.3763803616166115 2022-07-20 00:56:35.665201
learning rate:  0.00032057708828124994
netparams have been saved once 76
val: 1 0.4021928906440735
val: 2 0.4060586094856262
val: 3 0.41273728013038635
val: 4 0.40221408009529114
val: 5 0.4028913974761963
val: 6 0.4048117995262146
val: 7 0.3981412351131439
val: 8 0.40267473459243774
val: 9 0.40309247374534607
val: 10 0.4022436738014221
val: 11 0.3968898355960846
val: 12 0.4021269381046295
val: 13 0.3948778212070465
val: 14 0.40449827909469604
val: 15 0.40386244654655457
val: 16 0.3926553428173065
val: 17 0.4031372666358948
val: 18 0.39900922775268555
val: 19 0.39881303906440735
val: 20 0.4001302421092987
val_Epoch:[ 76 ] val_loss: 0.4016529306769371 2022-07-20 00:56:38.852390
start training 2022-07-20 00:56:38.952229
Epoch:[ 77 0 ] loss: 0.37738898396492004 2022-07-20 00:56:52.718391
Epoch:[ 77 1 ] loss: 0.37520334124565125 2022-07-20 00:56:53.135702
Epoch:[ 77 2 ] loss: 0.3756895959377289 2022-07-20 00:56:53.548099
Epoch:[ 77 3 ] loss: 0.37616246938705444 2022-07-20 00:56:53.959845
Epoch:[ 77 4 ] loss: 0.3766629099845886 2022-07-20 00:56:54.372361
Epoch:[ 77 5 ] loss: 0.3792051672935486 2022-07-20 00:56:54.786917
Epoch:[ 77 6 ] loss: 0.37731167674064636 2022-07-20 00:56:55.199942
Epoch:[ 77 7 ] loss: 0.3772743344306946 2022-07-20 00:56:55.610804
Epoch:[ 77 8 ] loss: 0.37614771723747253 2022-07-20 00:56:56.023566
Epoch:[ 77 9 ] loss: 0.37689515948295593 2022-07-20 00:56:56.441237
Epoch:[ 77 10 ] loss: 0.37766173481941223 2022-07-20 00:56:56.855107
Epoch:[ 77 11 ] loss: 0.37661102414131165 2022-07-20 00:56:57.270152
Epoch:[ 77 12 ] loss: 0.37757736444473267 2022-07-20 00:56:57.690773
Epoch:[ 77 13 ] loss: 0.37778154015541077 2022-07-20 00:56:58.105406
Epoch:[ 77 14 ] loss: 0.37876999378204346 2022-07-20 00:56:58.522180
Epoch:[ 77 15 ] loss: 0.3756420612335205 2022-07-20 00:56:58.937718
Epoch:[ 77 16 ] loss: 0.37857189774513245 2022-07-20 00:57:04.225486
Epoch:[ 77 17 ] loss: 0.37561947107315063 2022-07-20 00:57:04.638475
Epoch:[ 77 18 ] loss: 0.37636712193489075 2022-07-20 00:57:05.054624
Epoch:[ 77 19 ] loss: 0.37702372670173645 2022-07-20 00:57:05.467183
Training_Epoch:[ 77 ] Training_loss: 0.37697836458683015 2022-07-20 00:57:05.468032
learning rate:  0.00032057708828124994
val: 1 0.3953704535961151
val: 2 0.3978614807128906
val: 3 0.4070768356323242
val: 4 0.39737531542778015
val: 5 0.393367737531662
val: 6 0.402150422334671
val: 7 0.3917926847934723
val: 8 0.4008518159389496
val: 9 0.39721179008483887
val: 10 0.4017958343029022
val: 11 0.40121668577194214
val: 12 0.39633047580718994
val: 13 0.4024461805820465
val: 14 0.3945237994194031
val: 15 0.39837801456451416
val: 16 0.4026089310646057
val: 17 0.40875953435897827
val: 18 0.39943793416023254
val: 19 0.39514532685279846
val: 20 0.4060148000717163
val_Epoch:[ 77 ] val_loss: 0.39948580265045164 2022-07-20 00:57:08.690157
start training 2022-07-20 00:57:08.795203
Epoch:[ 78 0 ] loss: 0.37519729137420654 2022-07-20 00:57:22.824262
Epoch:[ 78 1 ] loss: 0.3758011758327484 2022-07-20 00:57:23.237377
Epoch:[ 78 2 ] loss: 0.37674322724342346 2022-07-20 00:57:23.647395
Epoch:[ 78 3 ] loss: 0.37494421005249023 2022-07-20 00:57:24.062440
Epoch:[ 78 4 ] loss: 0.37605807185173035 2022-07-20 00:57:24.475786
Epoch:[ 78 5 ] loss: 0.37795642018318176 2022-07-20 00:57:24.887106
Epoch:[ 78 6 ] loss: 0.37712645530700684 2022-07-20 00:57:25.302310
Epoch:[ 78 7 ] loss: 0.37538647651672363 2022-07-20 00:57:25.716123
Epoch:[ 78 8 ] loss: 0.37574347853660583 2022-07-20 00:57:26.131014
Epoch:[ 78 9 ] loss: 0.37508106231689453 2022-07-20 00:57:26.544820
Epoch:[ 78 10 ] loss: 0.3761403262615204 2022-07-20 00:57:26.958901
Epoch:[ 78 11 ] loss: 0.3763453960418701 2022-07-20 00:57:27.372252
Epoch:[ 78 12 ] loss: 0.37548723816871643 2022-07-20 00:57:27.788203
Epoch:[ 78 13 ] loss: 0.3760812282562256 2022-07-20 00:57:28.204748
Epoch:[ 78 14 ] loss: 0.375810444355011 2022-07-20 00:57:28.620357
Epoch:[ 78 15 ] loss: 0.37501999735832214 2022-07-20 00:57:29.030765
Epoch:[ 78 16 ] loss: 0.37605950236320496 2022-07-20 00:57:34.311126
Epoch:[ 78 17 ] loss: 0.37735921144485474 2022-07-20 00:57:34.724569
Epoch:[ 78 18 ] loss: 0.37654873728752136 2022-07-20 00:57:35.133894
Epoch:[ 78 19 ] loss: 0.3772965371608734 2022-07-20 00:57:35.549409
Training_Epoch:[ 78 ] Training_loss: 0.3761093243956566 2022-07-20 00:57:35.550158
learning rate:  0.00032057708828124994
netparams have been saved once 78
val: 1 0.4074499309062958
val: 2 0.40446361899375916
val: 3 0.4032968282699585
val: 4 0.40560734272003174
val: 5 0.3994129002094269
val: 6 0.3981808125972748
val: 7 0.39863649010658264
val: 8 0.39601507782936096
val: 9 0.40651485323905945
val: 10 0.40398216247558594
val: 11 0.4032287299633026
val: 12 0.40833553671836853
val: 13 0.4095934331417084
val: 14 0.3957802355289459
val: 15 0.40690717101097107
val: 16 0.40331560373306274
val: 17 0.41650116443634033
val: 18 0.3965194523334503
val: 19 0.40076205134391785
val: 20 0.39885616302490234
val_Epoch:[ 78 ] val_loss: 0.4031679779291153 2022-07-20 00:57:38.838302
start training 2022-07-20 00:57:38.940390
Epoch:[ 79 0 ] loss: 0.3758331835269928 2022-07-20 00:57:52.711843
Epoch:[ 79 1 ] loss: 0.37534254789352417 2022-07-20 00:57:53.127053
Epoch:[ 79 2 ] loss: 0.37646055221557617 2022-07-20 00:57:53.543242
Epoch:[ 79 3 ] loss: 0.3768056631088257 2022-07-20 00:57:53.956937
Epoch:[ 79 4 ] loss: 0.37537646293640137 2022-07-20 00:57:54.370826
Epoch:[ 79 5 ] loss: 0.37751874327659607 2022-07-20 00:57:54.785601
Epoch:[ 79 6 ] loss: 0.3763686418533325 2022-07-20 00:57:55.201667
Epoch:[ 79 7 ] loss: 0.37757936120033264 2022-07-20 00:57:55.618326
Epoch:[ 79 8 ] loss: 0.3784140944480896 2022-07-20 00:57:56.032643
Epoch:[ 79 9 ] loss: 0.3760945200920105 2022-07-20 00:57:56.446776
Epoch:[ 79 10 ] loss: 0.37712886929512024 2022-07-20 00:57:56.858038
Epoch:[ 79 11 ] loss: 0.3754658102989197 2022-07-20 00:57:57.271600
Epoch:[ 79 12 ] loss: 0.37639451026916504 2022-07-20 00:57:57.688126
Epoch:[ 79 13 ] loss: 0.37606266140937805 2022-07-20 00:57:58.102168
Epoch:[ 79 14 ] loss: 0.3760760426521301 2022-07-20 00:57:58.516045
Epoch:[ 79 15 ] loss: 0.3775550425052643 2022-07-20 00:57:58.928748
Epoch:[ 79 16 ] loss: 0.37902384996414185 2022-07-20 00:58:04.340254
Epoch:[ 79 17 ] loss: 0.37718841433525085 2022-07-20 00:58:04.753412
Epoch:[ 79 18 ] loss: 0.3781394064426422 2022-07-20 00:58:05.163668
Epoch:[ 79 19 ] loss: 0.37763726711273193 2022-07-20 00:58:05.579508
Training_Epoch:[ 79 ] Training_loss: 0.37682328224182127 2022-07-20 00:58:05.580218
learning rate:  0.00032057708828124994
val: 1 0.4101826548576355
val: 2 0.40788576006889343
val: 3 0.4042390286922455
val: 4 0.4003162384033203
val: 5 0.4002338647842407
val: 6 0.40751203894615173
val: 7 0.39830389618873596
val: 8 0.4058459401130676
val: 9 0.40844598412513733
val: 10 0.4124852120876312
val: 11 0.39902156591415405
val: 12 0.40282362699508667
val: 13 0.40249747037887573
val: 14 0.4000040590763092
val: 15 0.39188021421432495
val: 16 0.40218642354011536
val: 17 0.39991462230682373
val: 18 0.4013236463069916
val: 19 0.4053264558315277
val: 20 0.4068322479724884
val_Epoch:[ 79 ] val_loss: 0.4033630475401878 2022-07-20 00:58:08.777151
start training 2022-07-20 00:58:08.881740
Epoch:[ 80 0 ] loss: 0.37617239356040955 2022-07-20 00:58:22.598941
Epoch:[ 80 1 ] loss: 0.37663665413856506 2022-07-20 00:58:23.027479
Epoch:[ 80 2 ] loss: 0.37552669644355774 2022-07-20 00:58:23.441353
Epoch:[ 80 3 ] loss: 0.3760272264480591 2022-07-20 00:58:23.854985
Epoch:[ 80 4 ] loss: 0.3752635717391968 2022-07-20 00:58:24.268731
Epoch:[ 80 5 ] loss: 0.37538808584213257 2022-07-20 00:58:24.683458
Epoch:[ 80 6 ] loss: 0.3757055997848511 2022-07-20 00:58:25.099862
Epoch:[ 80 7 ] loss: 0.37486717104911804 2022-07-20 00:58:25.515147
Epoch:[ 80 8 ] loss: 0.37594151496887207 2022-07-20 00:58:25.930488
Epoch:[ 80 9 ] loss: 0.3766433000564575 2022-07-20 00:58:26.339670
Epoch:[ 80 10 ] loss: 0.3757058084011078 2022-07-20 00:58:26.752974
Epoch:[ 80 11 ] loss: 0.3768617808818817 2022-07-20 00:58:27.162935
Epoch:[ 80 12 ] loss: 0.3766816556453705 2022-07-20 00:58:27.576653
Epoch:[ 80 13 ] loss: 0.3754374384880066 2022-07-20 00:58:27.990397
Epoch:[ 80 14 ] loss: 0.3760838508605957 2022-07-20 00:58:28.406335
Epoch:[ 80 15 ] loss: 0.3780260682106018 2022-07-20 00:58:28.820769
Epoch:[ 80 16 ] loss: 0.37661731243133545 2022-07-20 00:58:34.517838
Epoch:[ 80 17 ] loss: 0.37702107429504395 2022-07-20 00:58:34.933414
Epoch:[ 80 18 ] loss: 0.377134770154953 2022-07-20 00:58:35.345024
Epoch:[ 80 19 ] loss: 0.3754066228866577 2022-07-20 00:58:35.758865
Training_Epoch:[ 80 ] Training_loss: 0.3761574298143387 2022-07-20 00:58:35.759611
learning rate:  0.00032057708828124994
netparams have been saved once 80
val: 1 0.4028102457523346
val: 2 0.40776458382606506
val: 3 0.39894551038742065
val: 4 0.39414864778518677
val: 5 0.41296207904815674
val: 6 0.4043664336204529
val: 7 0.4058237373828888
val: 8 0.400526762008667
val: 9 0.404652863740921
val: 10 0.3995659351348877
val: 11 0.4026624262332916
val: 12 0.4041233956813812
val: 13 0.4139389991760254
val: 14 0.40419864654541016
val: 15 0.41211438179016113
val: 16 0.4031415581703186
val: 17 0.3974142372608185
val: 18 0.39420458674430847
val: 19 0.4049122631549835
val: 20 0.40239545702934265
val_Epoch:[ 80 ] val_loss: 0.4035336375236511 2022-07-20 00:58:38.971256
start training 2022-07-20 00:58:39.075422
Epoch:[ 81 0 ] loss: 0.3756438195705414 2022-07-20 00:58:53.418403
Epoch:[ 81 1 ] loss: 0.3730545938014984 2022-07-20 00:58:53.828883
Epoch:[ 81 2 ] loss: 0.37635740637779236 2022-07-20 00:58:54.243078
Epoch:[ 81 3 ] loss: 0.37322935461997986 2022-07-20 00:58:54.655283
Epoch:[ 81 4 ] loss: 0.37446269392967224 2022-07-20 00:58:55.066006
Epoch:[ 81 5 ] loss: 0.37281253933906555 2022-07-20 00:58:55.479445
Epoch:[ 81 6 ] loss: 0.37278902530670166 2022-07-20 00:58:55.893048
Epoch:[ 81 7 ] loss: 0.37399712204933167 2022-07-20 00:58:56.307576
Epoch:[ 81 8 ] loss: 0.3744952082633972 2022-07-20 00:58:56.722818
Epoch:[ 81 9 ] loss: 0.37433022260665894 2022-07-20 00:58:57.136895
Epoch:[ 81 10 ] loss: 0.3742332458496094 2022-07-20 00:58:57.550892
Epoch:[ 81 11 ] loss: 0.37338635325431824 2022-07-20 00:58:57.964817
Epoch:[ 81 12 ] loss: 0.37304767966270447 2022-07-20 00:58:58.376263
Epoch:[ 81 13 ] loss: 0.37281548976898193 2022-07-20 00:58:58.790271
Epoch:[ 81 14 ] loss: 0.3744339048862457 2022-07-20 00:58:59.204263
Epoch:[ 81 15 ] loss: 0.37358763813972473 2022-07-20 00:58:59.620130
Epoch:[ 81 16 ] loss: 0.37331706285476685 2022-07-20 00:59:04.490796
Epoch:[ 81 17 ] loss: 0.37268075346946716 2022-07-20 00:59:04.899607
Epoch:[ 81 18 ] loss: 0.374625563621521 2022-07-20 00:59:05.315360
Epoch:[ 81 19 ] loss: 0.3739858567714691 2022-07-20 00:59:05.728504
Training_Epoch:[ 81 ] Training_loss: 0.37386427670717237 2022-07-20 00:59:05.729232
learning rate:  0.0002724905250390624
val: 1 0.39611566066741943
val: 2 0.4055386185646057
val: 3 0.39953726530075073
val: 4 0.3998219072818756
val: 5 0.39906617999076843
val: 6 0.4116308093070984
val: 7 0.4159056842327118
val: 8 0.4020313322544098
val: 9 0.40305882692337036
val: 10 0.3974159061908722
val: 11 0.40068140625953674
val: 12 0.3983781635761261
val: 13 0.40454667806625366
val: 14 0.4067704975605011
val: 15 0.4075565040111542
val: 16 0.39918801188468933
val: 17 0.4029330909252167
val: 18 0.3987293243408203
val: 19 0.40500327944755554
val: 20 0.40764763951301575
val_Epoch:[ 81 ] val_loss: 0.40307783931493757 2022-07-20 00:59:08.972445
start training 2022-07-20 00:59:09.075873
Epoch:[ 82 0 ] loss: 0.37293654680252075 2022-07-20 00:59:22.841139
Epoch:[ 82 1 ] loss: 0.37511515617370605 2022-07-20 00:59:23.281564
Epoch:[ 82 2 ] loss: 0.37177321314811707 2022-07-20 00:59:23.697847
Epoch:[ 82 3 ] loss: 0.37320587038993835 2022-07-20 00:59:24.112801
Epoch:[ 82 4 ] loss: 0.37305209040641785 2022-07-20 00:59:24.526511
Epoch:[ 82 5 ] loss: 0.37395361065864563 2022-07-20 00:59:24.941148
Epoch:[ 82 6 ] loss: 0.3722282350063324 2022-07-20 00:59:25.352188
Epoch:[ 82 7 ] loss: 0.3737737834453583 2022-07-20 00:59:25.764737
Epoch:[ 82 8 ] loss: 0.3738970160484314 2022-07-20 00:59:26.178521
Epoch:[ 82 9 ] loss: 0.3717270791530609 2022-07-20 00:59:26.589019
Epoch:[ 82 10 ] loss: 0.3740515112876892 2022-07-20 00:59:27.005033
Epoch:[ 82 11 ] loss: 0.37298619747161865 2022-07-20 00:59:27.418902
Epoch:[ 82 12 ] loss: 0.3737125098705292 2022-07-20 00:59:27.833296
Epoch:[ 82 13 ] loss: 0.37461206316947937 2022-07-20 00:59:28.246751
Epoch:[ 82 14 ] loss: 0.37465256452560425 2022-07-20 00:59:28.660717
Epoch:[ 82 15 ] loss: 0.3738142251968384 2022-07-20 00:59:29.076979
Epoch:[ 82 16 ] loss: 0.373867928981781 2022-07-20 00:59:34.476470
Epoch:[ 82 17 ] loss: 0.37650278210639954 2022-07-20 00:59:34.886257
Epoch:[ 82 18 ] loss: 0.37336042523384094 2022-07-20 00:59:35.301857
Epoch:[ 82 19 ] loss: 0.37377506494522095 2022-07-20 00:59:35.711329
Training_Epoch:[ 82 ] Training_loss: 0.3736498937010765 2022-07-20 00:59:35.712010
learning rate:  0.0002724905250390624
netparams have been saved once 82
val: 1 0.398644357919693
val: 2 0.3974151313304901
val: 3 0.40768808126449585
val: 4 0.40398213267326355
val: 5 0.4018658399581909
val: 6 0.3984014093875885
val: 7 0.4058701992034912
val: 8 0.3989228308200836
val: 9 0.40363723039627075
val: 10 0.4015500843524933
val: 11 0.4123768210411072
val: 12 0.4016898274421692
val: 13 0.41278836131095886
val: 14 0.39946526288986206
val: 15 0.40360012650489807
val: 16 0.4085771441459656
val: 17 0.3986772894859314
val: 18 0.39895227551460266
val: 19 0.4086421728134155
val: 20 0.39952489733695984
val_Epoch:[ 82 ] val_loss: 0.40311357378959656 2022-07-20 00:59:38.925765
start training 2022-07-20 00:59:39.028067
Epoch:[ 83 0 ] loss: 0.37356820702552795 2022-07-20 00:59:52.701860
Epoch:[ 83 1 ] loss: 0.3740070164203644 2022-07-20 00:59:53.126852
Epoch:[ 83 2 ] loss: 0.37492284178733826 2022-07-20 00:59:53.540665
Epoch:[ 83 3 ] loss: 0.3730708956718445 2022-07-20 00:59:53.956032
Epoch:[ 83 4 ] loss: 0.3737151324748993 2022-07-20 00:59:54.366919
Epoch:[ 83 5 ] loss: 0.3725842237472534 2022-07-20 00:59:54.781970
Epoch:[ 83 6 ] loss: 0.37351083755493164 2022-07-20 00:59:55.197657
Epoch:[ 83 7 ] loss: 0.37457728385925293 2022-07-20 00:59:55.611333
Epoch:[ 83 8 ] loss: 0.3728850483894348 2022-07-20 00:59:56.025172
Epoch:[ 83 9 ] loss: 0.3726641535758972 2022-07-20 00:59:56.438172
Epoch:[ 83 10 ] loss: 0.3720189332962036 2022-07-20 00:59:56.853947
Epoch:[ 83 11 ] loss: 0.3730374574661255 2022-07-20 00:59:57.266028
Epoch:[ 83 12 ] loss: 0.37290677428245544 2022-07-20 00:59:57.680119
Epoch:[ 83 13 ] loss: 0.37546950578689575 2022-07-20 00:59:58.094987
Epoch:[ 83 14 ] loss: 0.374218612909317 2022-07-20 00:59:58.509323
Epoch:[ 83 15 ] loss: 0.37412527203559875 2022-07-20 00:59:58.923513
Epoch:[ 83 16 ] loss: 0.37427347898483276 2022-07-20 01:00:04.347829
Epoch:[ 83 17 ] loss: 0.3727629482746124 2022-07-20 01:00:04.757081
Epoch:[ 83 18 ] loss: 0.3745240867137909 2022-07-20 01:00:05.172514
Epoch:[ 83 19 ] loss: 0.3737446367740631 2022-07-20 01:00:05.587313
Training_Epoch:[ 83 ] Training_loss: 0.37362936735153196 2022-07-20 01:00:05.588030
learning rate:  0.0002724905250390624
val: 1 0.40200403332710266
val: 2 0.4069192111492157
val: 3 0.4017704725265503
val: 4 0.4026457667350769
val: 5 0.40525293350219727
val: 6 0.40691161155700684
val: 7 0.4091379940509796
val: 8 0.40830814838409424
val: 9 0.4022139608860016
val: 10 0.4035349190235138
val: 11 0.4052959680557251
val: 12 0.40618860721588135
val: 13 0.39695417881011963
val: 14 0.39351117610931396
val: 15 0.40684518218040466
val: 16 0.40199899673461914
val: 17 0.40346476435661316
val: 18 0.40529024600982666
val: 19 0.39316779375076294
val: 20 0.39455747604370117
val_Epoch:[ 83 ] val_loss: 0.40279867202043534 2022-07-20 01:00:08.716361
start training 2022-07-20 01:00:08.814536
Epoch:[ 84 0 ] loss: 0.37396669387817383 2022-07-20 01:00:23.080193
Epoch:[ 84 1 ] loss: 0.37546607851982117 2022-07-20 01:00:23.493763
Epoch:[ 84 2 ] loss: 0.3748546242713928 2022-07-20 01:00:23.907489
Epoch:[ 84 3 ] loss: 0.3751559853553772 2022-07-20 01:00:24.321022
Epoch:[ 84 4 ] loss: 0.37198662757873535 2022-07-20 01:00:24.736328
Epoch:[ 84 5 ] loss: 0.37379297614097595 2022-07-20 01:00:25.147152
Epoch:[ 84 6 ] loss: 0.3742371201515198 2022-07-20 01:00:25.557428
Epoch:[ 84 7 ] loss: 0.3751409351825714 2022-07-20 01:00:25.973516
Epoch:[ 84 8 ] loss: 0.3749502897262573 2022-07-20 01:00:26.386834
Epoch:[ 84 9 ] loss: 0.37273871898651123 2022-07-20 01:00:26.800672
Epoch:[ 84 10 ] loss: 0.3750341236591339 2022-07-20 01:00:27.216860
Epoch:[ 84 11 ] loss: 0.37309157848358154 2022-07-20 01:00:27.632306
Epoch:[ 84 12 ] loss: 0.37487906217575073 2022-07-20 01:00:28.047987
Epoch:[ 84 13 ] loss: 0.37457555532455444 2022-07-20 01:00:28.463858
Epoch:[ 84 14 ] loss: 0.37345218658447266 2022-07-20 01:00:28.874007
Epoch:[ 84 15 ] loss: 0.3742372691631317 2022-07-20 01:00:29.289464
Epoch:[ 84 16 ] loss: 0.3728731870651245 2022-07-20 01:00:34.232376
Epoch:[ 84 17 ] loss: 0.3749128580093384 2022-07-20 01:00:34.645335
Epoch:[ 84 18 ] loss: 0.3749715983867645 2022-07-20 01:00:35.058153
Epoch:[ 84 19 ] loss: 0.3753979802131653 2022-07-20 01:00:35.473029
Training_Epoch:[ 84 ] Training_loss: 0.3742857724428177 2022-07-20 01:00:35.473788
learning rate:  0.0002724905250390624
netparams have been saved once 84
val: 1 0.40843892097473145
val: 2 0.40861839056015015
val: 3 0.4065893888473511
val: 4 0.41084858775138855
val: 5 0.4144640862941742
val: 6 0.4131256639957428
val: 7 0.4031406342983246
val: 8 0.4020960032939911
val: 9 0.41180962324142456
val: 10 0.4016250669956207
val: 11 0.40793371200561523
val: 12 0.40168994665145874
val: 13 0.41220149397850037
val: 14 0.40342697501182556
val: 15 0.40304458141326904
val: 16 0.41279861330986023
val: 17 0.40445640683174133
val: 18 0.40794044733047485
val: 19 0.4124060273170471
val: 20 0.41179022192955017
val_Epoch:[ 84 ] val_loss: 0.4079222396016121 2022-07-20 01:00:38.693306
start training 2022-07-20 01:00:38.789114
Epoch:[ 85 0 ] loss: 0.37378084659576416 2022-07-20 01:00:52.195322
Epoch:[ 85 1 ] loss: 0.3733512759208679 2022-07-20 01:00:52.895374
Epoch:[ 85 2 ] loss: 0.37572649121284485 2022-07-20 01:00:53.310380
Epoch:[ 85 3 ] loss: 0.3725707530975342 2022-07-20 01:00:53.722306
Epoch:[ 85 4 ] loss: 0.37452802062034607 2022-07-20 01:00:54.135637
Epoch:[ 85 5 ] loss: 0.37233904004096985 2022-07-20 01:00:54.550476
Epoch:[ 85 6 ] loss: 0.37284916639328003 2022-07-20 01:00:54.964751
Epoch:[ 85 7 ] loss: 0.37334880232810974 2022-07-20 01:00:55.377516
Epoch:[ 85 8 ] loss: 0.375702440738678 2022-07-20 01:00:55.789696
Epoch:[ 85 9 ] loss: 0.37297171354293823 2022-07-20 01:00:56.200896
Epoch:[ 85 10 ] loss: 0.3720950782299042 2022-07-20 01:00:56.614962
Epoch:[ 85 11 ] loss: 0.37595564126968384 2022-07-20 01:00:57.024591
Epoch:[ 85 12 ] loss: 0.37210026383399963 2022-07-20 01:00:57.439683
Epoch:[ 85 13 ] loss: 0.3729274272918701 2022-07-20 01:00:57.855067
Epoch:[ 85 14 ] loss: 0.37586474418640137 2022-07-20 01:00:58.269273
Epoch:[ 85 15 ] loss: 0.37364402413368225 2022-07-20 01:00:58.683472
Epoch:[ 85 16 ] loss: 0.3743455111980438 2022-07-20 01:01:04.133494
Epoch:[ 85 17 ] loss: 0.37453123927116394 2022-07-20 01:01:04.547409
Epoch:[ 85 18 ] loss: 0.37544146180152893 2022-07-20 01:01:04.958916
Epoch:[ 85 19 ] loss: 0.3741225302219391 2022-07-20 01:01:05.369622
Training_Epoch:[ 85 ] Training_loss: 0.3739098235964775 2022-07-20 01:01:05.370311
learning rate:  0.0002724905250390624
val: 1 0.4070509970188141
val: 2 0.3980041742324829
val: 3 0.4106893837451935
val: 4 0.4074012041091919
val: 5 0.39902397990226746
val: 6 0.4003273844718933
val: 7 0.4032924771308899
val: 8 0.4042186141014099
val: 9 0.39702919125556946
val: 10 0.4098900854587555
val: 11 0.40695399045944214
val: 12 0.39500313997268677
val: 13 0.3990612328052521
val: 14 0.3972207009792328
val: 15 0.40565788745880127
val: 16 0.40457984805107117
val: 17 0.4093758761882782
val: 18 0.40133339166641235
val: 19 0.39793938398361206
val: 20 0.4067029356956482
val_Epoch:[ 85 ] val_loss: 0.40303779393434525 2022-07-20 01:01:08.613615
start training 2022-07-20 01:01:08.712116
Epoch:[ 86 0 ] loss: 0.37253960967063904 2022-07-20 01:01:22.310632
Epoch:[ 86 1 ] loss: 0.37277206778526306 2022-07-20 01:01:22.934930
Epoch:[ 86 2 ] loss: 0.37427282333374023 2022-07-20 01:01:23.348515
Epoch:[ 86 3 ] loss: 0.37352415919303894 2022-07-20 01:01:23.762616
Epoch:[ 86 4 ] loss: 0.37432578206062317 2022-07-20 01:01:24.178126
Epoch:[ 86 5 ] loss: 0.3732895255088806 2022-07-20 01:01:24.591721
Epoch:[ 86 6 ] loss: 0.37279027700424194 2022-07-20 01:01:25.008261
Epoch:[ 86 7 ] loss: 0.3722594678401947 2022-07-20 01:01:25.422535
Epoch:[ 86 8 ] loss: 0.37127697467803955 2022-07-20 01:01:25.836032
Epoch:[ 86 9 ] loss: 0.37367069721221924 2022-07-20 01:01:26.250207
Epoch:[ 86 10 ] loss: 0.37353378534317017 2022-07-20 01:01:26.664919
Epoch:[ 86 11 ] loss: 0.37274545431137085 2022-07-20 01:01:27.080274
Epoch:[ 86 12 ] loss: 0.37240999937057495 2022-07-20 01:01:27.492252
Epoch:[ 86 13 ] loss: 0.3726690709590912 2022-07-20 01:01:27.908492
Epoch:[ 86 14 ] loss: 0.374735951423645 2022-07-20 01:01:28.321943
Epoch:[ 86 15 ] loss: 0.3725794553756714 2022-07-20 01:01:28.734787
Epoch:[ 86 16 ] loss: 0.3728424608707428 2022-07-20 01:01:34.000075
Epoch:[ 86 17 ] loss: 0.3747602105140686 2022-07-20 01:01:34.414273
Epoch:[ 86 18 ] loss: 0.37230217456817627 2022-07-20 01:01:34.829125
Epoch:[ 86 19 ] loss: 0.3739006221294403 2022-07-20 01:01:35.237663
Training_Epoch:[ 86 ] Training_loss: 0.3731600284576416 2022-07-20 01:01:35.238342
learning rate:  0.0002724905250390624
netparams have been saved once 86
val: 1 0.40790268778800964
val: 2 0.39582154154777527
val: 3 0.40399307012557983
val: 4 0.3993212878704071
val: 5 0.3989048898220062
val: 6 0.39863064885139465
val: 7 0.4124588668346405
val: 8 0.4012513756752014
val: 9 0.40803709626197815
val: 10 0.408462792634964
val: 11 0.4067487120628357
val: 12 0.4045647978782654
val: 13 0.4013148844242096
val: 14 0.3977586030960083
val: 15 0.4032387137413025
val: 16 0.40271812677383423
val: 17 0.39906248450279236
val: 18 0.4021790027618408
val: 19 0.40260380506515503
val: 20 0.40278303623199463
val_Epoch:[ 86 ] val_loss: 0.40288782119750977 2022-07-20 01:01:38.442109
start training 2022-07-20 01:01:38.538437
Epoch:[ 87 0 ] loss: 0.37058085203170776 2022-07-20 01:01:52.886531
Epoch:[ 87 1 ] loss: 0.3720090091228485 2022-07-20 01:01:53.304149
Epoch:[ 87 2 ] loss: 0.3731520473957062 2022-07-20 01:01:53.722494
Epoch:[ 87 3 ] loss: 0.3728206753730774 2022-07-20 01:01:54.138130
Epoch:[ 87 4 ] loss: 0.37325072288513184 2022-07-20 01:01:54.552952
Epoch:[ 87 5 ] loss: 0.3713534474372864 2022-07-20 01:01:54.966710
Epoch:[ 87 6 ] loss: 0.3716494143009186 2022-07-20 01:01:55.379971
Epoch:[ 87 7 ] loss: 0.3720300495624542 2022-07-20 01:01:55.791494
Epoch:[ 87 8 ] loss: 0.3720390796661377 2022-07-20 01:01:56.208109
Epoch:[ 87 9 ] loss: 0.3725888431072235 2022-07-20 01:01:56.621917
Epoch:[ 87 10 ] loss: 0.3720964193344116 2022-07-20 01:01:57.035768
Epoch:[ 87 11 ] loss: 0.37118643522262573 2022-07-20 01:01:57.451310
Epoch:[ 87 12 ] loss: 0.37190523743629456 2022-07-20 01:01:57.862809
Epoch:[ 87 13 ] loss: 0.3728173077106476 2022-07-20 01:01:58.277132
Epoch:[ 87 14 ] loss: 0.37012365460395813 2022-07-20 01:01:58.692243
Epoch:[ 87 15 ] loss: 0.3721923828125 2022-07-20 01:01:59.108536
Epoch:[ 87 16 ] loss: 0.3721091151237488 2022-07-20 01:02:03.984604
Epoch:[ 87 17 ] loss: 0.3718433380126953 2022-07-20 01:02:04.395279
Epoch:[ 87 18 ] loss: 0.3718332350254059 2022-07-20 01:02:04.810573
Epoch:[ 87 19 ] loss: 0.37208566069602966 2022-07-20 01:02:05.219916
Training_Epoch:[ 87 ] Training_loss: 0.3719833463430405 2022-07-20 01:02:05.220620
learning rate:  0.0002724905250390624
val: 1 0.40092846751213074
val: 2 0.4040912389755249
val: 3 0.4008897840976715
val: 4 0.40526801347732544
val: 5 0.4020412862300873
val: 6 0.39439526200294495
val: 7 0.40740805864334106
val: 8 0.40813812613487244
val: 9 0.4056271016597748
val: 10 0.40277716517448425
val: 11 0.4087147116661072
val: 12 0.4170679450035095
val: 13 0.40631359815597534
val: 14 0.41378799080848694
val: 15 0.39437881112098694
val: 16 0.40563884377479553
val: 17 0.4079101085662842
val: 18 0.41063329577445984
val: 19 0.40345290303230286
val: 20 0.4120991826057434
val_Epoch:[ 87 ] val_loss: 0.40557809472084044 2022-07-20 01:02:08.389053
start training 2022-07-20 01:02:08.487635
Epoch:[ 88 0 ] loss: 0.3713812530040741 2022-07-20 01:02:22.862415
Epoch:[ 88 1 ] loss: 0.3725217580795288 2022-07-20 01:02:23.277323
Epoch:[ 88 2 ] loss: 0.37189480662345886 2022-07-20 01:02:23.693345
Epoch:[ 88 3 ] loss: 0.3719215393066406 2022-07-20 01:02:24.108056
Epoch:[ 88 4 ] loss: 0.3699652850627899 2022-07-20 01:02:24.522492
Epoch:[ 88 5 ] loss: 0.37262627482414246 2022-07-20 01:02:24.937713
Epoch:[ 88 6 ] loss: 0.3742627799510956 2022-07-20 01:02:25.350947
Epoch:[ 88 7 ] loss: 0.37277913093566895 2022-07-20 01:02:25.764118
Epoch:[ 88 8 ] loss: 0.3719942271709442 2022-07-20 01:02:26.178436
Epoch:[ 88 9 ] loss: 0.3724830150604248 2022-07-20 01:02:26.588706
Epoch:[ 88 10 ] loss: 0.3713306784629822 2022-07-20 01:02:27.001783
Epoch:[ 88 11 ] loss: 0.3722195029258728 2022-07-20 01:02:27.413596
Epoch:[ 88 12 ] loss: 0.37366926670074463 2022-07-20 01:02:27.827487
Epoch:[ 88 13 ] loss: 0.37317317724227905 2022-07-20 01:02:28.240982
Epoch:[ 88 14 ] loss: 0.3707667291164398 2022-07-20 01:02:28.654610
Epoch:[ 88 15 ] loss: 0.37235018610954285 2022-07-20 01:02:29.068905
Epoch:[ 88 16 ] loss: 0.3720649778842926 2022-07-20 01:02:33.996631
Epoch:[ 88 17 ] loss: 0.3726661503314972 2022-07-20 01:02:34.408152
Epoch:[ 88 18 ] loss: 0.3720336854457855 2022-07-20 01:02:34.817883
Epoch:[ 88 19 ] loss: 0.37420687079429626 2022-07-20 01:02:35.228250
Training_Epoch:[ 88 ] Training_loss: 0.3723155647516251 2022-07-20 01:02:35.228997
learning rate:  0.0002724905250390624
netparams have been saved once 88
val: 1 0.40747350454330444
val: 2 0.418099969625473
val: 3 0.41011086106300354
val: 4 0.40433377027511597
val: 5 0.4001258909702301
val: 6 0.40987107157707214
val: 7 0.4101339280605316
val: 8 0.4071408212184906
val: 9 0.4110918641090393
val: 10 0.4136366546154022
val: 11 0.4079633057117462
val: 12 0.40642401576042175
val: 13 0.401102751493454
val: 14 0.4083058536052704
val: 15 0.41076475381851196
val: 16 0.4067290723323822
val: 17 0.4045345187187195
val: 18 0.4040897786617279
val: 19 0.4103538691997528
val: 20 0.4076595902442932
val_Epoch:[ 88 ] val_loss: 0.40799729228019715 2022-07-20 01:02:38.479503
start training 2022-07-20 01:02:38.576890
Epoch:[ 89 0 ] loss: 0.3700622022151947 2022-07-20 01:02:52.049403
Epoch:[ 89 1 ] loss: 0.37094274163246155 2022-07-20 01:02:52.597029
Epoch:[ 89 2 ] loss: 0.3725760877132416 2022-07-20 01:02:53.009692
Epoch:[ 89 3 ] loss: 0.37099960446357727 2022-07-20 01:02:53.423790
Epoch:[ 89 4 ] loss: 0.3730259835720062 2022-07-20 01:02:53.838043
Epoch:[ 89 5 ] loss: 0.3705500662326813 2022-07-20 01:02:54.254114
Epoch:[ 89 6 ] loss: 0.37288278341293335 2022-07-20 01:02:54.668594
Epoch:[ 89 7 ] loss: 0.37383878231048584 2022-07-20 01:02:55.082020
Epoch:[ 89 8 ] loss: 0.37195494771003723 2022-07-20 01:02:55.495923
Epoch:[ 89 9 ] loss: 0.37365248799324036 2022-07-20 01:02:55.909985
Epoch:[ 89 10 ] loss: 0.3724977672100067 2022-07-20 01:02:56.327049
Epoch:[ 89 11 ] loss: 0.37377771735191345 2022-07-20 01:02:56.744546
Epoch:[ 89 12 ] loss: 0.37284764647483826 2022-07-20 01:02:57.160497
Epoch:[ 89 13 ] loss: 0.3728412687778473 2022-07-20 01:02:57.569379
Epoch:[ 89 14 ] loss: 0.37390491366386414 2022-07-20 01:02:57.982264
Epoch:[ 89 15 ] loss: 0.37278205156326294 2022-07-20 01:02:58.395312
Epoch:[ 89 16 ] loss: 0.3730405569076538 2022-07-20 01:03:03.924262
Epoch:[ 89 17 ] loss: 0.37321990728378296 2022-07-20 01:03:04.334010
Epoch:[ 89 18 ] loss: 0.373346209526062 2022-07-20 01:03:04.748638
Epoch:[ 89 19 ] loss: 0.37407925724983215 2022-07-20 01:03:05.162930
Training_Epoch:[ 89 ] Training_loss: 0.37264114916324614 2022-07-20 01:03:05.163666
learning rate:  0.0002724905250390624
val: 1 0.3961208462715149
val: 2 0.3954557776451111
val: 3 0.40281572937965393
val: 4 0.41065359115600586
val: 5 0.39402952790260315
val: 6 0.3983767330646515
val: 7 0.4010142683982849
val: 8 0.3924301862716675
val: 9 0.4036402106285095
val: 10 0.3937835097312927
val: 11 0.40739768743515015
val: 12 0.39769211411476135
val: 13 0.4082275331020355
val: 14 0.40563759207725525
val: 15 0.40039095282554626
val: 16 0.40401607751846313
val: 17 0.39727655053138733
val: 18 0.40756863355636597
val: 19 0.41149190068244934
val: 20 0.3998386561870575
val_Epoch:[ 89 ] val_loss: 0.40139290392398835 2022-07-20 01:03:08.341925
start training 2022-07-20 01:03:08.440512
Epoch:[ 90 0 ] loss: 0.3708761930465698 2022-07-20 01:03:22.454361
Epoch:[ 90 1 ] loss: 0.37170228362083435 2022-07-20 01:03:22.866797
Epoch:[ 90 2 ] loss: 0.3705574870109558 2022-07-20 01:03:23.278830
Epoch:[ 90 3 ] loss: 0.3717246353626251 2022-07-20 01:03:23.692865
Epoch:[ 90 4 ] loss: 0.3716726303100586 2022-07-20 01:03:24.106788
Epoch:[ 90 5 ] loss: 0.3712422549724579 2022-07-20 01:03:24.519892
Epoch:[ 90 6 ] loss: 0.3754783272743225 2022-07-20 01:03:24.933944
Epoch:[ 90 7 ] loss: 0.3695698380470276 2022-07-20 01:03:25.344318
Epoch:[ 90 8 ] loss: 0.3745690584182739 2022-07-20 01:03:25.754169
Epoch:[ 90 9 ] loss: 0.37143346667289734 2022-07-20 01:03:26.170605
Epoch:[ 90 10 ] loss: 0.3740813136100769 2022-07-20 01:03:26.582232
Epoch:[ 90 11 ] loss: 0.37286925315856934 2022-07-20 01:03:26.997797
Epoch:[ 90 12 ] loss: 0.3717282712459564 2022-07-20 01:03:27.411390
Epoch:[ 90 13 ] loss: 0.3734876215457916 2022-07-20 01:03:27.823334
Epoch:[ 90 14 ] loss: 0.37224963307380676 2022-07-20 01:03:28.237450
Epoch:[ 90 15 ] loss: 0.37433570623397827 2022-07-20 01:03:28.651002
Epoch:[ 90 16 ] loss: 0.3717992305755615 2022-07-20 01:03:33.764846
Epoch:[ 90 17 ] loss: 0.3725695312023163 2022-07-20 01:03:34.179612
Epoch:[ 90 18 ] loss: 0.37047144770622253 2022-07-20 01:03:34.594904
Epoch:[ 90 19 ] loss: 0.37219303846359253 2022-07-20 01:03:35.004073
Training_Epoch:[ 90 ] Training_loss: 0.3722305610775948 2022-07-20 01:03:35.004739
learning rate:  0.0002724905250390624
netparams have been saved once 90
val: 1 0.40701737999916077
val: 2 0.40561237931251526
val: 3 0.40310221910476685
val: 4 0.4148668944835663
val: 5 0.4072679877281189
val: 6 0.41279569268226624
val: 7 0.41539081931114197
val: 8 0.41134828329086304
val: 9 0.4170721471309662
val: 10 0.40872475504875183
val: 11 0.41281524300575256
val: 12 0.39551711082458496
val: 13 0.405190646648407
val: 14 0.40134570002555847
val: 15 0.4075665771961212
val: 16 0.4109506905078888
val: 17 0.4259251058101654
val: 18 0.42152297496795654
val: 19 0.41097894310951233
val: 20 0.4115043580532074
val_Epoch:[ 90 ] val_loss: 0.4103257954120636 2022-07-20 01:03:38.211361
start training 2022-07-20 01:03:38.311000
Epoch:[ 91 0 ] loss: 0.3718782961368561 2022-07-20 01:03:52.277614
Epoch:[ 91 1 ] loss: 0.3710710108280182 2022-07-20 01:03:52.693112
Epoch:[ 91 2 ] loss: 0.37173667550086975 2022-07-20 01:03:53.106981
Epoch:[ 91 3 ] loss: 0.3702312409877777 2022-07-20 01:03:53.521830
Epoch:[ 91 4 ] loss: 0.3699185848236084 2022-07-20 01:03:53.932892
Epoch:[ 91 5 ] loss: 0.372358500957489 2022-07-20 01:03:54.351144
Epoch:[ 91 6 ] loss: 0.3725060224533081 2022-07-20 01:03:54.766784
Epoch:[ 91 7 ] loss: 0.3698635697364807 2022-07-20 01:03:55.181762
Epoch:[ 91 8 ] loss: 0.37244436144828796 2022-07-20 01:03:55.596625
Epoch:[ 91 9 ] loss: 0.3706473112106323 2022-07-20 01:03:56.011925
Epoch:[ 91 10 ] loss: 0.3718928396701813 2022-07-20 01:03:56.425530
Epoch:[ 91 11 ] loss: 0.37064221501350403 2022-07-20 01:03:56.842318
Epoch:[ 91 12 ] loss: 0.3703625798225403 2022-07-20 01:03:57.253690
Epoch:[ 91 13 ] loss: 0.3684736490249634 2022-07-20 01:03:57.669829
Epoch:[ 91 14 ] loss: 0.37179145216941833 2022-07-20 01:03:58.082582
Epoch:[ 91 15 ] loss: 0.3697628080844879 2022-07-20 01:03:58.497658
Epoch:[ 91 16 ] loss: 0.3703382611274719 2022-07-20 01:04:03.331332
Epoch:[ 91 17 ] loss: 0.37025347352027893 2022-07-20 01:04:03.749515
Epoch:[ 91 18 ] loss: 0.370699942111969 2022-07-20 01:04:04.164890
Epoch:[ 91 19 ] loss: 0.37127256393432617 2022-07-20 01:04:04.577624
Training_Epoch:[ 91 ] Training_loss: 0.37090726792812345 2022-07-20 01:04:04.578375
learning rate:  0.00023161694628320305
val: 1 0.4111069142818451
val: 2 0.39442601799964905
val: 3 0.4084712266921997
val: 4 0.4090879559516907
val: 5 0.4008173942565918
val: 6 0.40929001569747925
val: 7 0.40927863121032715
val: 8 0.3986092805862427
val: 9 0.39653947949409485
val: 10 0.39805811643600464
val: 11 0.40120869874954224
val: 12 0.41850408911705017
val: 13 0.4016471803188324
val: 14 0.3993493914604187
val: 15 0.40688836574554443
val: 16 0.40213310718536377
val: 17 0.40029191970825195
val: 18 0.4007927477359772
val: 19 0.409084677696228
val: 20 0.40534475445747375
val_Epoch:[ 91 ] val_loss: 0.4040464982390404 2022-07-20 01:04:07.879752
start training 2022-07-20 01:04:07.978935
Epoch:[ 92 0 ] loss: 0.36842992901802063 2022-07-20 01:04:22.206919
Epoch:[ 92 1 ] loss: 0.3698629140853882 2022-07-20 01:04:22.620360
Epoch:[ 92 2 ] loss: 0.3713751435279846 2022-07-20 01:04:23.034662
Epoch:[ 92 3 ] loss: 0.369209885597229 2022-07-20 01:04:23.449783
Epoch:[ 92 4 ] loss: 0.37063390016555786 2022-07-20 01:04:23.862657
Epoch:[ 92 5 ] loss: 0.3703608810901642 2022-07-20 01:04:24.274268
Epoch:[ 92 6 ] loss: 0.37116584181785583 2022-07-20 01:04:24.688538
Epoch:[ 92 7 ] loss: 0.3686979413032532 2022-07-20 01:04:25.101515
Epoch:[ 92 8 ] loss: 0.3700800836086273 2022-07-20 01:04:25.514794
Epoch:[ 92 9 ] loss: 0.3697170317173004 2022-07-20 01:04:25.928748
Epoch:[ 92 10 ] loss: 0.37207460403442383 2022-07-20 01:04:26.342786
Epoch:[ 92 11 ] loss: 0.36908209323883057 2022-07-20 01:04:26.755769
Epoch:[ 92 12 ] loss: 0.3700820505619049 2022-07-20 01:04:27.170331
Epoch:[ 92 13 ] loss: 0.36978450417518616 2022-07-20 01:04:27.587544
Epoch:[ 92 14 ] loss: 0.37052595615386963 2022-07-20 01:04:27.999342
Epoch:[ 92 15 ] loss: 0.370576947927475 2022-07-20 01:04:28.412047
Epoch:[ 92 16 ] loss: 0.37058544158935547 2022-07-20 01:04:33.425155
Epoch:[ 92 17 ] loss: 0.3702167570590973 2022-07-20 01:04:33.833669
Epoch:[ 92 18 ] loss: 0.36977970600128174 2022-07-20 01:04:34.254028
Epoch:[ 92 19 ] loss: 0.3700839877128601 2022-07-20 01:04:34.669826
Training_Epoch:[ 92 ] Training_loss: 0.3701162800192833 2022-07-20 01:04:34.670514
learning rate:  0.00023161694628320305
netparams have been saved once 92
val: 1 0.39988717436790466
val: 2 0.39793333411216736
val: 3 0.3992476165294647
val: 4 0.4060068726539612
val: 5 0.4025963544845581
val: 6 0.39839425683021545
val: 7 0.39562973380088806
val: 8 0.3982360064983368
val: 9 0.39993277192115784
val: 10 0.4089105725288391
val: 11 0.4023812413215637
val: 12 0.4037371873855591
val: 13 0.404086709022522
val: 14 0.3992924690246582
val: 15 0.3946884572505951
val: 16 0.40451422333717346
val: 17 0.3997408449649811
val: 18 0.40439194440841675
val: 19 0.4008721709251404
val: 20 0.4017913341522217
val_Epoch:[ 92 ] val_loss: 0.40111356377601626 2022-07-20 01:04:37.905056
start training 2022-07-20 01:04:38.002926
Epoch:[ 93 0 ] loss: 0.369133859872818 2022-07-20 01:04:51.796851
Epoch:[ 93 1 ] loss: 0.36991003155708313 2022-07-20 01:04:52.216033
Epoch:[ 93 2 ] loss: 0.3696984052658081 2022-07-20 01:04:52.633154
Epoch:[ 93 3 ] loss: 0.37070921063423157 2022-07-20 01:04:53.047656
Epoch:[ 93 4 ] loss: 0.3692398965358734 2022-07-20 01:04:53.461552
Epoch:[ 93 5 ] loss: 0.36765703558921814 2022-07-20 01:04:53.877510
Epoch:[ 93 6 ] loss: 0.3686208128929138 2022-07-20 01:04:54.292709
Epoch:[ 93 7 ] loss: 0.3687354326248169 2022-07-20 01:04:54.708478
Epoch:[ 93 8 ] loss: 0.3688693940639496 2022-07-20 01:04:55.122514
Epoch:[ 93 9 ] loss: 0.36898693442344666 2022-07-20 01:04:55.535869
Epoch:[ 93 10 ] loss: 0.36911270022392273 2022-07-20 01:04:55.950132
Epoch:[ 93 11 ] loss: 0.3705257475376129 2022-07-20 01:04:56.360242
Epoch:[ 93 12 ] loss: 0.369125634431839 2022-07-20 01:04:56.774441
Epoch:[ 93 13 ] loss: 0.368797242641449 2022-07-20 01:04:57.189643
Epoch:[ 93 14 ] loss: 0.3700130879878998 2022-07-20 01:04:57.605539
Epoch:[ 93 15 ] loss: 0.37099170684814453 2022-07-20 01:04:58.019439
Epoch:[ 93 16 ] loss: 0.3713058829307556 2022-07-20 01:05:03.452336
Epoch:[ 93 17 ] loss: 0.36985543370246887 2022-07-20 01:05:03.861528
Epoch:[ 93 18 ] loss: 0.36954978108406067 2022-07-20 01:05:04.272282
Epoch:[ 93 19 ] loss: 0.37064847350120544 2022-07-20 01:05:04.688105
Training_Epoch:[ 93 ] Training_loss: 0.3695743352174759 2022-07-20 01:05:04.688860
learning rate:  0.00023161694628320305
val: 1 0.40355169773101807
val: 2 0.4116986095905304
val: 3 0.4043881297111511
val: 4 0.40638357400894165
val: 5 0.40773534774780273
val: 6 0.4068627655506134
val: 7 0.4115280210971832
val: 8 0.40852227807044983
val: 9 0.3988547921180725
val: 10 0.40012824535369873
val: 11 0.4024444818496704
val: 12 0.4089384377002716
val: 13 0.40236082673072815
val: 14 0.40991824865341187
val: 15 0.4122348427772522
val: 16 0.40262269973754883
val: 17 0.40975406765937805
val: 18 0.39382269978523254
val: 19 0.4034323990345001
val: 20 0.4022536277770996
val_Epoch:[ 93 ] val_loss: 0.40537178963422776 2022-07-20 01:05:07.849415
start training 2022-07-20 01:05:07.948918
Epoch:[ 94 0 ] loss: 0.36880162358283997 2022-07-20 01:05:21.923764
Epoch:[ 94 1 ] loss: 0.36833277344703674 2022-07-20 01:05:22.338283
Epoch:[ 94 2 ] loss: 0.3711302876472473 2022-07-20 01:05:22.747598
Epoch:[ 94 3 ] loss: 0.3709738254547119 2022-07-20 01:05:23.160091
Epoch:[ 94 4 ] loss: 0.37019604444503784 2022-07-20 01:05:23.574081
Epoch:[ 94 5 ] loss: 0.37022092938423157 2022-07-20 01:05:23.988799
Epoch:[ 94 6 ] loss: 0.3698037564754486 2022-07-20 01:05:24.405337
Epoch:[ 94 7 ] loss: 0.3704979717731476 2022-07-20 01:05:24.820588
Epoch:[ 94 8 ] loss: 0.3690325915813446 2022-07-20 01:05:25.235024
Epoch:[ 94 9 ] loss: 0.36990365386009216 2022-07-20 01:05:25.650419
Epoch:[ 94 10 ] loss: 0.3692929446697235 2022-07-20 01:05:26.060030
Epoch:[ 94 11 ] loss: 0.3693294823169708 2022-07-20 01:05:26.474228
Epoch:[ 94 12 ] loss: 0.37145140767097473 2022-07-20 01:05:26.888992
Epoch:[ 94 13 ] loss: 0.37099164724349976 2022-07-20 01:05:27.302632
Epoch:[ 94 14 ] loss: 0.369571328163147 2022-07-20 01:05:27.714505
Epoch:[ 94 15 ] loss: 0.3713185489177704 2022-07-20 01:05:28.129773
Epoch:[ 94 16 ] loss: 0.37036776542663574 2022-07-20 01:05:33.349639
Epoch:[ 94 17 ] loss: 0.3702712059020996 2022-07-20 01:05:33.760788
Epoch:[ 94 18 ] loss: 0.3708512783050537 2022-07-20 01:05:34.175103
Epoch:[ 94 19 ] loss: 0.36968550086021423 2022-07-20 01:05:34.583356
Training_Epoch:[ 94 ] Training_loss: 0.3701012283563614 2022-07-20 01:05:34.584092
learning rate:  0.00023161694628320305
netparams have been saved once 94
val: 1 0.39976343512535095
val: 2 0.40472209453582764
val: 3 0.3980327546596527
val: 4 0.4086850881576538
val: 5 0.3985593318939209
val: 6 0.40028417110443115
val: 7 0.4111674726009369
val: 8 0.4134311079978943
val: 9 0.4071495831012726
val: 10 0.4030625820159912
val: 11 0.4105032980442047
val: 12 0.40720775723457336
val: 13 0.40941959619522095
val: 14 0.40511688590049744
val: 15 0.4101133942604065
val: 16 0.4040692448616028
val: 17 0.4013844132423401
val: 18 0.4037955701351166
val: 19 0.39923784136772156
val: 20 0.4012885093688965
val_Epoch:[ 94 ] val_loss: 0.4048497065901756 2022-07-20 01:05:37.830129
start training 2022-07-20 01:05:37.927851
Epoch:[ 95 0 ] loss: 0.36831220984458923 2022-07-20 01:05:51.504570
Epoch:[ 95 1 ] loss: 0.37100523710250854 2022-07-20 01:05:51.937041
Epoch:[ 95 2 ] loss: 0.3699318766593933 2022-07-20 01:05:52.350664
Epoch:[ 95 3 ] loss: 0.36911797523498535 2022-07-20 01:05:52.762808
Epoch:[ 95 4 ] loss: 0.3684489130973816 2022-07-20 01:05:53.176167
Epoch:[ 95 5 ] loss: 0.36993005871772766 2022-07-20 01:05:53.587209
Epoch:[ 95 6 ] loss: 0.37052586674690247 2022-07-20 01:05:53.999603
Epoch:[ 95 7 ] loss: 0.3697580099105835 2022-07-20 01:05:54.414078
Epoch:[ 95 8 ] loss: 0.3700381815433502 2022-07-20 01:05:54.827501
Epoch:[ 95 9 ] loss: 0.3694581985473633 2022-07-20 01:05:55.241139
Epoch:[ 95 10 ] loss: 0.36940327286720276 2022-07-20 01:05:55.658766
Epoch:[ 95 11 ] loss: 0.36805111169815063 2022-07-20 01:05:56.072649
Epoch:[ 95 12 ] loss: 0.36975687742233276 2022-07-20 01:05:56.490198
Epoch:[ 95 13 ] loss: 0.36852866411209106 2022-07-20 01:05:56.903291
Epoch:[ 95 14 ] loss: 0.37037035822868347 2022-07-20 01:05:57.315936
Epoch:[ 95 15 ] loss: 0.36862024664878845 2022-07-20 01:05:57.730843
Epoch:[ 95 16 ] loss: 0.37050649523735046 2022-07-20 01:06:03.242359
Epoch:[ 95 17 ] loss: 0.368425577878952 2022-07-20 01:06:03.655670
Epoch:[ 95 18 ] loss: 0.37049540877342224 2022-07-20 01:06:04.075355
Epoch:[ 95 19 ] loss: 0.3680030405521393 2022-07-20 01:06:04.489664
Training_Epoch:[ 95 ] Training_loss: 0.3694343790411949 2022-07-20 01:06:04.490502
learning rate:  0.00023161694628320305
val: 1 0.398561030626297
val: 2 0.4029112756252289
val: 3 0.4046550691127777
val: 4 0.39588621258735657
val: 5 0.39649340510368347
val: 6 0.396541565656662
val: 7 0.4065234661102295
val: 8 0.40280774235725403
val: 9 0.40560173988342285
val: 10 0.4042171835899353
val: 11 0.39655935764312744
val: 12 0.4110874533653259
val: 13 0.40968620777130127
val: 14 0.4080573320388794
val: 15 0.4048795700073242
val: 16 0.4045596718788147
val: 17 0.40498843789100647
val: 18 0.4014439582824707
val: 19 0.42323175072669983
val: 20 0.40507563948631287
val_Epoch:[ 95 ] val_loss: 0.4041884034872055 2022-07-20 01:06:07.685695
start training 2022-07-20 01:06:07.782619
Epoch:[ 96 0 ] loss: 0.3684607148170471 2022-07-20 01:06:21.147750
Epoch:[ 96 1 ] loss: 0.36797034740448 2022-07-20 01:06:21.868944
Epoch:[ 96 2 ] loss: 0.36805808544158936 2022-07-20 01:06:22.283289
Epoch:[ 96 3 ] loss: 0.3682858645915985 2022-07-20 01:06:22.696439
Epoch:[ 96 4 ] loss: 0.3677654564380646 2022-07-20 01:06:23.108111
Epoch:[ 96 5 ] loss: 0.36965420842170715 2022-07-20 01:06:23.522067
Epoch:[ 96 6 ] loss: 0.3675473630428314 2022-07-20 01:06:23.935506
Epoch:[ 96 7 ] loss: 0.36772504448890686 2022-07-20 01:06:24.352630
Epoch:[ 96 8 ] loss: 0.3679479658603668 2022-07-20 01:06:24.765303
Epoch:[ 96 9 ] loss: 0.3673665225505829 2022-07-20 01:06:25.179070
Epoch:[ 96 10 ] loss: 0.3684386909008026 2022-07-20 01:06:25.591925
Epoch:[ 96 11 ] loss: 0.3689342737197876 2022-07-20 01:06:26.008549
Epoch:[ 96 12 ] loss: 0.3690834641456604 2022-07-20 01:06:26.419686
Epoch:[ 96 13 ] loss: 0.3679729402065277 2022-07-20 01:06:26.831005
Epoch:[ 96 14 ] loss: 0.3681703507900238 2022-07-20 01:06:27.242815
Epoch:[ 96 15 ] loss: 0.3676076829433441 2022-07-20 01:06:27.657175
Epoch:[ 96 16 ] loss: 0.36947178840637207 2022-07-20 01:06:32.447840
Epoch:[ 96 17 ] loss: 0.369279682636261 2022-07-20 01:06:33.429182
Epoch:[ 96 18 ] loss: 0.3699165880680084 2022-07-20 01:06:33.839450
Epoch:[ 96 19 ] loss: 0.3682164251804352 2022-07-20 01:06:34.248753
Training_Epoch:[ 96 ] Training_loss: 0.36839367300271986 2022-07-20 01:06:34.249539
learning rate:  0.00023161694628320305
netparams have been saved once 96
val: 1 0.3978646695613861
val: 2 0.4052058160305023
val: 3 0.41198664903640747
val: 4 0.4007749557495117
val: 5 0.39613741636276245
val: 6 0.3984936773777008
val: 7 0.4086076021194458
val: 8 0.40785035490989685
val: 9 0.39977872371673584
val: 10 0.396795392036438
val: 11 0.4086318016052246
val: 12 0.40646788477897644
val: 13 0.396806925535202
val: 14 0.3982315957546234
val: 15 0.40067803859710693
val: 16 0.4085463583469391
val: 17 0.3958866596221924
val: 18 0.4121921956539154
val: 19 0.4033530354499817
val: 20 0.3961823284626007
val_Epoch:[ 96 ] val_loss: 0.4025236040353775 2022-07-20 01:06:37.559061
start training 2022-07-20 01:06:37.659026
Epoch:[ 97 0 ] loss: 0.3679881989955902 2022-07-20 01:06:51.911147
Epoch:[ 97 1 ] loss: 0.36751729249954224 2022-07-20 01:06:52.323939
Epoch:[ 97 2 ] loss: 0.36831405758857727 2022-07-20 01:06:52.741652
Epoch:[ 97 3 ] loss: 0.36964860558509827 2022-07-20 01:06:53.157149
Epoch:[ 97 4 ] loss: 0.36919301748275757 2022-07-20 01:06:53.571151
Epoch:[ 97 5 ] loss: 0.36894670128822327 2022-07-20 01:06:53.992482
Epoch:[ 97 6 ] loss: 0.36951014399528503 2022-07-20 01:06:54.407342
Epoch:[ 97 7 ] loss: 0.36977407336235046 2022-07-20 01:06:54.820823
Epoch:[ 97 8 ] loss: 0.3674173951148987 2022-07-20 01:06:55.234617
Epoch:[ 97 9 ] loss: 0.3683207631111145 2022-07-20 01:06:55.647174
Epoch:[ 97 10 ] loss: 0.3684885501861572 2022-07-20 01:06:56.063739
Epoch:[ 97 11 ] loss: 0.3680088520050049 2022-07-20 01:06:56.481421
Epoch:[ 97 12 ] loss: 0.3721759617328644 2022-07-20 01:06:56.895063
Epoch:[ 97 13 ] loss: 0.36812594532966614 2022-07-20 01:06:57.309353
Epoch:[ 97 14 ] loss: 0.36856740713119507 2022-07-20 01:06:57.724299
Epoch:[ 97 15 ] loss: 0.369144082069397 2022-07-20 01:06:58.138115
Epoch:[ 97 16 ] loss: 0.3683807849884033 2022-07-20 01:07:03.163378
Epoch:[ 97 17 ] loss: 0.3681691586971283 2022-07-20 01:07:03.572235
Epoch:[ 97 18 ] loss: 0.3695698380470276 2022-07-20 01:07:03.988066
Epoch:[ 97 19 ] loss: 0.3675030767917633 2022-07-20 01:07:04.397706
Training_Epoch:[ 97 ] Training_loss: 0.3687381953001022 2022-07-20 01:07:04.398503
learning rate:  0.00023161694628320305
val: 1 0.4052932858467102
val: 2 0.4063527584075928
val: 3 0.4055365025997162
val: 4 0.39534178376197815
val: 5 0.40136441588401794
val: 6 0.39722344279289246
val: 7 0.4023040235042572
val: 8 0.39619001746177673
val: 9 0.4067649245262146
val: 10 0.4017795920372009
val: 11 0.39436620473861694
val: 12 0.39933738112449646
val: 13 0.4021570682525635
val: 14 0.3987845778465271
val: 15 0.40229326486587524
val: 16 0.3990322947502136
val: 17 0.39354071021080017
val: 18 0.4027880132198334
val: 19 0.39994218945503235
val: 20 0.4051987826824188
val_Epoch:[ 97 ] val_loss: 0.40077956169843676 2022-07-20 01:07:07.528638
start training 2022-07-20 01:07:07.626917
Epoch:[ 98 0 ] loss: 0.367226779460907 2022-07-20 01:07:21.229774
Epoch:[ 98 1 ] loss: 0.3685811460018158 2022-07-20 01:07:21.929996
Epoch:[ 98 2 ] loss: 0.36768829822540283 2022-07-20 01:07:22.344144
Epoch:[ 98 3 ] loss: 0.36809125542640686 2022-07-20 01:07:22.757253
Epoch:[ 98 4 ] loss: 0.3684312403202057 2022-07-20 01:07:23.172440
Epoch:[ 98 5 ] loss: 0.36843565106391907 2022-07-20 01:07:23.588055
Epoch:[ 98 6 ] loss: 0.3677729666233063 2022-07-20 01:07:24.001913
Epoch:[ 98 7 ] loss: 0.36939865350723267 2022-07-20 01:07:24.417900
Epoch:[ 98 8 ] loss: 0.3677590787410736 2022-07-20 01:07:24.831084
Epoch:[ 98 9 ] loss: 0.368476003408432 2022-07-20 01:07:25.240238
Epoch:[ 98 10 ] loss: 0.3674537241458893 2022-07-20 01:07:25.655804
Epoch:[ 98 11 ] loss: 0.3684608042240143 2022-07-20 01:07:26.071271
Epoch:[ 98 12 ] loss: 0.36891716718673706 2022-07-20 01:07:26.486028
Epoch:[ 98 13 ] loss: 0.36992210149765015 2022-07-20 01:07:26.899224
Epoch:[ 98 14 ] loss: 0.368543416261673 2022-07-20 01:07:27.311946
Epoch:[ 98 15 ] loss: 0.3686065971851349 2022-07-20 01:07:27.721408
Epoch:[ 98 16 ] loss: 0.3675817847251892 2022-07-20 01:07:32.800210
Epoch:[ 98 17 ] loss: 0.36988815665245056 2022-07-20 01:07:33.362899
Epoch:[ 98 18 ] loss: 0.36858487129211426 2022-07-20 01:07:33.782395
Epoch:[ 98 19 ] loss: 0.3674728572368622 2022-07-20 01:07:34.192110
Training_Epoch:[ 98 ] Training_loss: 0.3683646276593208 2022-07-20 01:07:34.192883
learning rate:  0.00023161694628320305
netparams have been saved once 98
val: 1 0.402703195810318
val: 2 0.4044315814971924
val: 3 0.40581804513931274
val: 4 0.3993779420852661
val: 5 0.41784846782684326
val: 6 0.4130319654941559
val: 7 0.40902936458587646
val: 8 0.4106157124042511
val: 9 0.3988970220088959
val: 10 0.40109288692474365
val: 11 0.3999394476413727
val: 12 0.41019898653030396
val: 13 0.4085111916065216
val: 14 0.40323132276535034
val: 15 0.4082540273666382
val: 16 0.4098181128501892
val: 17 0.3977402150630951
val: 18 0.4105391800403595
val: 19 0.40980204939842224
val: 20 0.40283215045928955
val_Epoch:[ 98 ] val_loss: 0.4061856433749199 2022-07-20 01:07:37.422265
start training 2022-07-20 01:07:37.521336
Epoch:[ 99 0 ] loss: 0.3674069941043854 2022-07-20 01:07:51.767700
Epoch:[ 99 1 ] loss: 0.3703669607639313 2022-07-20 01:07:52.180700
Epoch:[ 99 2 ] loss: 0.36781957745552063 2022-07-20 01:07:52.595855
Epoch:[ 99 3 ] loss: 0.36665695905685425 2022-07-20 01:07:53.009665
Epoch:[ 99 4 ] loss: 0.3683529794216156 2022-07-20 01:07:53.423654
Epoch:[ 99 5 ] loss: 0.3664829432964325 2022-07-20 01:07:53.834725
Epoch:[ 99 6 ] loss: 0.36868372559547424 2022-07-20 01:07:54.250040
Epoch:[ 99 7 ] loss: 0.36871349811553955 2022-07-20 01:07:54.663889
Epoch:[ 99 8 ] loss: 0.36851274967193604 2022-07-20 01:07:55.077334
Epoch:[ 99 9 ] loss: 0.3691624701023102 2022-07-20 01:07:55.491279
Epoch:[ 99 10 ] loss: 0.3690376579761505 2022-07-20 01:07:55.900900
Epoch:[ 99 11 ] loss: 0.36832860112190247 2022-07-20 01:07:56.315585
Epoch:[ 99 12 ] loss: 0.3679373562335968 2022-07-20 01:07:56.726971
Epoch:[ 99 13 ] loss: 0.3692784607410431 2022-07-20 01:07:57.141419
Epoch:[ 99 14 ] loss: 0.36553046107292175 2022-07-20 01:07:57.555385
Epoch:[ 99 15 ] loss: 0.36926326155662537 2022-07-20 01:07:57.968414
Epoch:[ 99 16 ] loss: 0.36695048213005066 2022-07-20 01:08:02.746529
Epoch:[ 99 17 ] loss: 0.368902325630188 2022-07-20 01:08:03.160455
Epoch:[ 99 18 ] loss: 0.3678397238254547 2022-07-20 01:08:03.578510
Epoch:[ 99 19 ] loss: 0.36884501576423645 2022-07-20 01:08:03.990092
Training_Epoch:[ 99 ] Training_loss: 0.36820361018180847 2022-07-20 01:08:03.990831
learning rate:  0.00023161694628320305
val: 1 0.4030356705188751
val: 2 0.3990616202354431
val: 3 0.4167746305465698
val: 4 0.404865562915802
val: 5 0.41025981307029724
val: 6 0.4043480455875397
val: 7 0.4035683572292328
val: 8 0.40882110595703125
val: 9 0.41262754797935486
val: 10 0.3987455368041992
val: 11 0.4038504958152771
val: 12 0.3999805450439453
val: 13 0.40314894914627075
val: 14 0.40386897325515747
val: 15 0.40663135051727295
val: 16 0.4010869264602661
val: 17 0.4056645333766937
val: 18 0.3969138264656067
val: 19 0.40678471326828003
val: 20 0.40056657791137695
val_Epoch:[ 99 ] val_loss: 0.4045302391052246 2022-07-20 01:08:07.150447
start training 2022-07-20 01:08:07.252353
Epoch:[ 100 0 ] loss: 0.36951974034309387 2022-07-20 01:08:21.269561
Epoch:[ 100 1 ] loss: 0.36839625239372253 2022-07-20 01:08:21.683463
Epoch:[ 100 2 ] loss: 0.36711010336875916 2022-07-20 01:08:22.096436
Epoch:[ 100 3 ] loss: 0.3683927357196808 2022-07-20 01:08:22.509947
Epoch:[ 100 4 ] loss: 0.367654412984848 2022-07-20 01:08:22.923496
Epoch:[ 100 5 ] loss: 0.36734291911125183 2022-07-20 01:08:23.334855
Epoch:[ 100 6 ] loss: 0.36687031388282776 2022-07-20 01:08:23.755334
Epoch:[ 100 7 ] loss: 0.3678518533706665 2022-07-20 01:08:24.168967
Epoch:[ 100 8 ] loss: 0.3704504072666168 2022-07-20 01:08:24.581479
Epoch:[ 100 9 ] loss: 0.3683292269706726 2022-07-20 01:08:24.994516
Epoch:[ 100 10 ] loss: 0.3693588376045227 2022-07-20 01:08:25.407027
Epoch:[ 100 11 ] loss: 0.368343710899353 2022-07-20 01:08:25.825116
Epoch:[ 100 12 ] loss: 0.367401659488678 2022-07-20 01:08:26.237173
Epoch:[ 100 13 ] loss: 0.3680820167064667 2022-07-20 01:08:26.657088
Epoch:[ 100 14 ] loss: 0.3695249557495117 2022-07-20 01:08:27.071853
Epoch:[ 100 15 ] loss: 0.36781445145606995 2022-07-20 01:08:27.484038
Epoch:[ 100 16 ] loss: 0.36808380484580994 2022-07-20 01:08:32.988880
Epoch:[ 100 17 ] loss: 0.36811238527297974 2022-07-20 01:08:33.406016
Epoch:[ 100 18 ] loss: 0.3678591251373291 2022-07-20 01:08:33.817023
Epoch:[ 100 19 ] loss: 0.3687591552734375 2022-07-20 01:08:34.228015
Training_Epoch:[ 100 ] Training_loss: 0.36826290339231493 2022-07-20 01:08:34.228757
learning rate:  0.00023161694628320305
netparams have been saved once 100
val: 1 0.39870011806488037
val: 2 0.4056587219238281
val: 3 0.4054047167301178
val: 4 0.396283358335495
val: 5 0.4046352207660675
val: 6 0.403226763010025
val: 7 0.39073020219802856
val: 8 0.4081864356994629
val: 9 0.402423620223999
val: 10 0.3990679383277893
val: 11 0.40547624230384827
val: 12 0.4069298803806305
val: 13 0.40890753269195557
val: 14 0.40834638476371765
val: 15 0.40889766812324524
val: 16 0.38869577646255493
val: 17 0.3994836211204529
val: 18 0.4077993929386139
val: 19 0.40224942564964294
val: 20 0.41634005308151245
val_Epoch:[ 100 ] val_loss: 0.4033721536397934 2022-07-20 01:08:37.482445
start training 2022-07-20 01:08:37.582199
Epoch:[ 101 0 ] loss: 0.3684564530849457 2022-07-20 01:08:51.481345
Epoch:[ 101 1 ] loss: 0.36760082840919495 2022-07-20 01:08:51.895657
Epoch:[ 101 2 ] loss: 0.3663240671157837 2022-07-20 01:08:52.311532
Epoch:[ 101 3 ] loss: 0.3657950758934021 2022-07-20 01:08:52.727225
Epoch:[ 101 4 ] loss: 0.3684040904045105 2022-07-20 01:08:53.142360
Epoch:[ 101 5 ] loss: 0.3655175566673279 2022-07-20 01:08:53.555252
Epoch:[ 101 6 ] loss: 0.36766383051872253 2022-07-20 01:08:53.968581
Epoch:[ 101 7 ] loss: 0.3671739101409912 2022-07-20 01:08:54.378681
Epoch:[ 101 8 ] loss: 0.366843044757843 2022-07-20 01:08:54.793394
Epoch:[ 101 9 ] loss: 0.3685791790485382 2022-07-20 01:08:55.207821
Epoch:[ 101 10 ] loss: 0.36627236008644104 2022-07-20 01:08:55.624258
Epoch:[ 101 11 ] loss: 0.3665998578071594 2022-07-20 01:08:56.038733
Epoch:[ 101 12 ] loss: 0.3680463433265686 2022-07-20 01:08:56.452111
Epoch:[ 101 13 ] loss: 0.36651402711868286 2022-07-20 01:08:56.862411
Epoch:[ 101 14 ] loss: 0.36675381660461426 2022-07-20 01:08:57.273825
Epoch:[ 101 15 ] loss: 0.36644724011421204 2022-07-20 01:08:57.689030
Epoch:[ 101 16 ] loss: 0.36661726236343384 2022-07-20 01:09:02.973513
Epoch:[ 101 17 ] loss: 0.36662304401397705 2022-07-20 01:09:03.384055
Epoch:[ 101 18 ] loss: 0.3662283420562744 2022-07-20 01:09:03.799926
Epoch:[ 101 19 ] loss: 0.36721453070640564 2022-07-20 01:09:04.212837
Training_Epoch:[ 101 ] Training_loss: 0.36698374301195147 2022-07-20 01:09:04.213745
learning rate:  0.0001968744043407226
val: 1 0.40682756900787354
val: 2 0.3993200957775116
val: 3 0.40477097034454346
val: 4 0.41437867283821106
val: 5 0.39968207478523254
val: 6 0.42245784401893616
val: 7 0.40522584319114685
val: 8 0.40496206283569336
val: 9 0.3992762267589569
val: 10 0.40194281935691833
val: 11 0.4013560712337494
val: 12 0.41159215569496155
val: 13 0.39754679799079895
val: 14 0.4049317538738251
val: 15 0.4060620665550232
val: 16 0.40561094880104065
val: 17 0.4052964746952057
val: 18 0.4129123389720917
val: 19 0.40331804752349854
val: 20 0.4054587483406067
val_Epoch:[ 101 ] val_loss: 0.40564647912979124 2022-07-20 01:09:07.409806
start training 2022-07-20 01:09:07.513622
Epoch:[ 102 0 ] loss: 0.3660241663455963 2022-07-20 01:09:21.967598
Epoch:[ 102 1 ] loss: 0.3677811920642853 2022-07-20 01:09:22.381074
Epoch:[ 102 2 ] loss: 0.36691150069236755 2022-07-20 01:09:22.797504
Epoch:[ 102 3 ] loss: 0.366661012172699 2022-07-20 01:09:23.211296
Epoch:[ 102 4 ] loss: 0.36487051844596863 2022-07-20 01:09:23.623298
Epoch:[ 102 5 ] loss: 0.36546751856803894 2022-07-20 01:09:24.036450
Epoch:[ 102 6 ] loss: 0.3662451207637787 2022-07-20 01:09:24.454236
Epoch:[ 102 7 ] loss: 0.3656889796257019 2022-07-20 01:09:24.865943
Epoch:[ 102 8 ] loss: 0.3656342327594757 2022-07-20 01:09:25.279136
Epoch:[ 102 9 ] loss: 0.36609306931495667 2022-07-20 01:09:25.691693
Epoch:[ 102 10 ] loss: 0.3653738796710968 2022-07-20 01:09:26.110095
Epoch:[ 102 11 ] loss: 0.36592188477516174 2022-07-20 01:09:26.524112
Epoch:[ 102 12 ] loss: 0.36614829301834106 2022-07-20 01:09:26.936542
Epoch:[ 102 13 ] loss: 0.36765486001968384 2022-07-20 01:09:27.348979
Epoch:[ 102 14 ] loss: 0.36737489700317383 2022-07-20 01:09:27.761218
Epoch:[ 102 15 ] loss: 0.36593905091285706 2022-07-20 01:09:28.179794
Epoch:[ 102 16 ] loss: 0.36614978313446045 2022-07-20 01:09:33.224056
Epoch:[ 102 17 ] loss: 0.3676229417324066 2022-07-20 01:09:33.640048
Epoch:[ 102 18 ] loss: 0.3659631907939911 2022-07-20 01:09:34.058323
Epoch:[ 102 19 ] loss: 0.3667008876800537 2022-07-20 01:09:34.477449
Training_Epoch:[ 102 ] Training_loss: 0.36631134897470474 2022-07-20 01:09:34.478379
learning rate:  0.0001968744043407226
netparams have been saved once 102
val: 1 0.39564216136932373
val: 2 0.4086611270904541
val: 3 0.4022062420845032
val: 4 0.4016750454902649
val: 5 0.3985956609249115
val: 6 0.40237849950790405
val: 7 0.40367722511291504
val: 8 0.39531874656677246
val: 9 0.40684518218040466
val: 10 0.40625789761543274
val: 11 0.40381819009780884
val: 12 0.40402525663375854
val: 13 0.4066421687602997
val: 14 0.4052409529685974
val: 15 0.41203123331069946
val: 16 0.40230029821395874
val: 17 0.40446215867996216
val: 18 0.39746662974357605
val: 19 0.4028770625591278
val: 20 0.4017801880836487
val_Epoch:[ 102 ] val_loss: 0.4030950963497162 2022-07-20 01:09:37.634770
start training 2022-07-20 01:09:37.736729
Epoch:[ 103 0 ] loss: 0.36629170179367065 2022-07-20 01:09:51.732210
Epoch:[ 103 1 ] loss: 0.365957111120224 2022-07-20 01:09:52.154015
Epoch:[ 103 2 ] loss: 0.3646673560142517 2022-07-20 01:09:52.565667
Epoch:[ 103 3 ] loss: 0.36715760827064514 2022-07-20 01:09:52.981906
Epoch:[ 103 4 ] loss: 0.3653751313686371 2022-07-20 01:09:53.395198
Epoch:[ 103 5 ] loss: 0.36649152636528015 2022-07-20 01:09:53.811876
Epoch:[ 103 6 ] loss: 0.36597877740859985 2022-07-20 01:09:54.226081
Epoch:[ 103 7 ] loss: 0.36571672558784485 2022-07-20 01:09:54.640201
Epoch:[ 103 8 ] loss: 0.3662497401237488 2022-07-20 01:09:55.053855
Epoch:[ 103 9 ] loss: 0.36729946732521057 2022-07-20 01:09:55.463959
Epoch:[ 103 10 ] loss: 0.3662816286087036 2022-07-20 01:09:55.874915
Epoch:[ 103 11 ] loss: 0.36761561036109924 2022-07-20 01:09:56.289758
Epoch:[ 103 12 ] loss: 0.36553025245666504 2022-07-20 01:09:56.704512
Epoch:[ 103 13 ] loss: 0.3674311637878418 2022-07-20 01:09:57.118939
Epoch:[ 103 14 ] loss: 0.36595168709754944 2022-07-20 01:09:57.532703
Epoch:[ 103 15 ] loss: 0.3679122030735016 2022-07-20 01:09:57.945386
Epoch:[ 103 16 ] loss: 0.3674098253250122 2022-07-20 01:10:03.134411
Epoch:[ 103 17 ] loss: 0.36722004413604736 2022-07-20 01:10:03.563186
Epoch:[ 103 18 ] loss: 0.3654005527496338 2022-07-20 01:10:03.984037
Epoch:[ 103 19 ] loss: 0.36400657892227173 2022-07-20 01:10:04.395479
Training_Epoch:[ 103 ] Training_loss: 0.36629723459482194 2022-07-20 01:10:04.396244
learning rate:  0.0001968744043407226
val: 1 0.40815290808677673
val: 2 0.41031190752983093
val: 3 0.4083452820777893
val: 4 0.407243013381958
val: 5 0.4014725685119629
val: 6 0.4092341363430023
val: 7 0.40829771757125854
val: 8 0.39296451210975647
val: 9 0.41214850544929504
val: 10 0.4047214984893799
val: 11 0.40921154618263245
val: 12 0.4028029441833496
val: 13 0.40496623516082764
val: 14 0.4093322455883026
val: 15 0.4090059995651245
val: 16 0.4024164378643036
val: 17 0.40568527579307556
val: 18 0.4038833677768707
val: 19 0.41281095147132874
val: 20 0.40446096658706665
val_Epoch:[ 103 ] val_loss: 0.4063734009861946 2022-07-20 01:10:07.556345
start training 2022-07-20 01:10:07.659350
Epoch:[ 104 0 ] loss: 0.3654646873474121 2022-07-20 01:10:21.465852
Epoch:[ 104 1 ] loss: 0.3651197850704193 2022-07-20 01:10:21.932821
Epoch:[ 104 2 ] loss: 0.36576414108276367 2022-07-20 01:10:22.343912
Epoch:[ 104 3 ] loss: 0.3653930425643921 2022-07-20 01:10:22.759638
Epoch:[ 104 4 ] loss: 0.3663714826107025 2022-07-20 01:10:23.170002
Epoch:[ 104 5 ] loss: 0.36484453082084656 2022-07-20 01:10:23.582897
Epoch:[ 104 6 ] loss: 0.3639775514602661 2022-07-20 01:10:23.995854
Epoch:[ 104 7 ] loss: 0.36567404866218567 2022-07-20 01:10:24.410830
Epoch:[ 104 8 ] loss: 0.36557427048683167 2022-07-20 01:10:24.824363
Epoch:[ 104 9 ] loss: 0.3653686046600342 2022-07-20 01:10:25.237809
Epoch:[ 104 10 ] loss: 0.3659745454788208 2022-07-20 01:10:25.653182
Epoch:[ 104 11 ] loss: 0.3646180033683777 2022-07-20 01:10:26.068400
Epoch:[ 104 12 ] loss: 0.36668622493743896 2022-07-20 01:10:26.482675
Epoch:[ 104 13 ] loss: 0.3652997314929962 2022-07-20 01:10:26.894418
Epoch:[ 104 14 ] loss: 0.3657396733760834 2022-07-20 01:10:27.309131
Epoch:[ 104 15 ] loss: 0.364464670419693 2022-07-20 01:10:27.722641
Epoch:[ 104 16 ] loss: 0.3667382597923279 2022-07-20 01:10:32.936842
Epoch:[ 104 17 ] loss: 0.36703673005104065 2022-07-20 01:10:33.351649
Epoch:[ 104 18 ] loss: 0.36694133281707764 2022-07-20 01:10:33.763481
Epoch:[ 104 19 ] loss: 0.36692580580711365 2022-07-20 01:10:34.176320
Training_Epoch:[ 104 ] Training_loss: 0.3656988561153412 2022-07-20 01:10:34.177013
learning rate:  0.0001968744043407226
netparams have been saved once 104
val: 1 0.40317168831825256
val: 2 0.40409255027770996
val: 3 0.39716553688049316
val: 4 0.414493590593338
val: 5 0.3996756672859192
val: 6 0.4024142920970917
val: 7 0.40633124113082886
val: 8 0.4169389009475708
val: 9 0.40445780754089355
val: 10 0.41941550374031067
val: 11 0.41136765480041504
val: 12 0.40709319710731506
val: 13 0.41139447689056396
val: 14 0.40721336007118225
val: 15 0.4060191512107849
val: 16 0.4183295965194702
val: 17 0.41301411390304565
val: 18 0.4135507643222809
val: 19 0.4047420620918274
val: 20 0.4070624113082886
val_Epoch:[ 104 ] val_loss: 0.4083971783518791 2022-07-20 01:10:37.419542
start training 2022-07-20 01:10:37.521548
Epoch:[ 105 0 ] loss: 0.365781307220459 2022-07-20 01:10:50.918993
Epoch:[ 105 1 ] loss: 0.3666831851005554 2022-07-20 01:10:51.366633
Epoch:[ 105 2 ] loss: 0.36574050784111023 2022-07-20 01:10:51.775646
Epoch:[ 105 3 ] loss: 0.3646436333656311 2022-07-20 01:10:52.188679
Epoch:[ 105 4 ] loss: 0.36511045694351196 2022-07-20 01:10:52.608306
Epoch:[ 105 5 ] loss: 0.36593952775001526 2022-07-20 01:10:53.024978
Epoch:[ 105 6 ] loss: 0.3659918010234833 2022-07-20 01:10:53.439564
Epoch:[ 105 7 ] loss: 0.3653051257133484 2022-07-20 01:10:53.853225
Epoch:[ 105 8 ] loss: 0.36635300517082214 2022-07-20 01:10:54.265434
Epoch:[ 105 9 ] loss: 0.3662985563278198 2022-07-20 01:10:54.678426
Epoch:[ 105 10 ] loss: 0.3664647340774536 2022-07-20 01:10:55.095790
Epoch:[ 105 11 ] loss: 0.36593154072761536 2022-07-20 01:10:55.509948
Epoch:[ 105 12 ] loss: 0.36532163619995117 2022-07-20 01:10:55.923954
Epoch:[ 105 13 ] loss: 0.36645984649658203 2022-07-20 01:10:56.335673
Epoch:[ 105 14 ] loss: 0.3657089173793793 2022-07-20 01:10:56.752008
Epoch:[ 105 15 ] loss: 0.3655910789966583 2022-07-20 01:10:57.165756
Epoch:[ 105 16 ] loss: 0.36742764711380005 2022-07-20 01:11:02.716925
Epoch:[ 105 17 ] loss: 0.3669293224811554 2022-07-20 01:11:03.134079
Epoch:[ 105 18 ] loss: 0.36589887738227844 2022-07-20 01:11:03.553939
Epoch:[ 105 19 ] loss: 0.3664552569389343 2022-07-20 01:11:03.969601
Training_Epoch:[ 105 ] Training_loss: 0.3660017982125282 2022-07-20 01:11:03.970479
learning rate:  0.0001968744043407226
val: 1 0.4085961878299713
val: 2 0.40262213349342346
val: 3 0.40069779753685
val: 4 0.39633992314338684
val: 5 0.39758235216140747
val: 6 0.3997039496898651
val: 7 0.4062427580356598
val: 8 0.3969847559928894
val: 9 0.40993526577949524
val: 10 0.3947432339191437
val: 11 0.4156791567802429
val: 12 0.3966493010520935
val: 13 0.39900705218315125
val: 14 0.4049062728881836
val: 15 0.4005676507949829
val: 16 0.41094332933425903
val: 17 0.3936671316623688
val: 18 0.40184056758880615
val: 19 0.4084625542163849
val: 20 0.41255515813827515
val_Epoch:[ 105 ] val_loss: 0.402886326611042 2022-07-20 01:11:07.225292
start training 2022-07-20 01:11:07.324964
Epoch:[ 106 0 ] loss: 0.36449334025382996 2022-07-20 01:11:21.415603
Epoch:[ 106 1 ] loss: 0.36499151587486267 2022-07-20 01:11:21.829378
Epoch:[ 106 2 ] loss: 0.3643493354320526 2022-07-20 01:11:22.242119
Epoch:[ 106 3 ] loss: 0.36434364318847656 2022-07-20 01:11:22.655682
Epoch:[ 106 4 ] loss: 0.366176575422287 2022-07-20 01:11:23.067682
Epoch:[ 106 5 ] loss: 0.3651837110519409 2022-07-20 01:11:23.483055
Epoch:[ 106 6 ] loss: 0.36456331610679626 2022-07-20 01:11:23.904812
Epoch:[ 106 7 ] loss: 0.3655259311199188 2022-07-20 01:11:24.321843
Epoch:[ 106 8 ] loss: 0.3646175265312195 2022-07-20 01:11:24.733706
Epoch:[ 106 9 ] loss: 0.3657534718513489 2022-07-20 01:11:25.147086
Epoch:[ 106 10 ] loss: 0.36582252383232117 2022-07-20 01:11:25.564460
Epoch:[ 106 11 ] loss: 0.3649713397026062 2022-07-20 01:11:25.976882
Epoch:[ 106 12 ] loss: 0.36465299129486084 2022-07-20 01:11:26.391150
Epoch:[ 106 13 ] loss: 0.366039514541626 2022-07-20 01:11:26.807014
Epoch:[ 106 14 ] loss: 0.3674914538860321 2022-07-20 01:11:27.222910
Epoch:[ 106 15 ] loss: 0.3651260435581207 2022-07-20 01:11:27.636913
Epoch:[ 106 16 ] loss: 0.36495038866996765 2022-07-20 01:11:32.780887
Epoch:[ 106 17 ] loss: 0.36730489134788513 2022-07-20 01:11:33.192069
Epoch:[ 106 18 ] loss: 0.36631685495376587 2022-07-20 01:11:33.609938
Epoch:[ 106 19 ] loss: 0.3667110204696655 2022-07-20 01:11:34.030458
Training_Epoch:[ 106 ] Training_loss: 0.3654692694544792 2022-07-20 01:11:34.031147
learning rate:  0.0001968744043407226
netparams have been saved once 106
val: 1 0.40201854705810547
val: 2 0.3985244035720825
val: 3 0.3965202271938324
val: 4 0.4021085202693939
val: 5 0.40389585494995117
val: 6 0.4055340886116028
val: 7 0.41434550285339355
val: 8 0.3985133469104767
val: 9 0.4111230969429016
val: 10 0.4059557616710663
val: 11 0.4213339388370514
val: 12 0.39761924743652344
val: 13 0.40933355689048767
val: 14 0.39946046471595764
val: 15 0.4098476767539978
val: 16 0.40372800827026367
val: 17 0.4109843075275421
val: 18 0.40752583742141724
val: 19 0.401458203792572
val: 20 0.4069381058216095
val_Epoch:[ 106 ] val_loss: 0.4053384348750114 2022-07-20 01:11:37.242820
start training 2022-07-20 01:11:37.343084
Epoch:[ 107 0 ] loss: 0.36358973383903503 2022-07-20 01:11:50.971067
Epoch:[ 107 1 ] loss: 0.36535555124282837 2022-07-20 01:11:51.403307
Epoch:[ 107 2 ] loss: 0.36472997069358826 2022-07-20 01:11:51.818617
Epoch:[ 107 3 ] loss: 0.36473149061203003 2022-07-20 01:11:52.232736
Epoch:[ 107 4 ] loss: 0.3663211166858673 2022-07-20 01:11:52.650291
Epoch:[ 107 5 ] loss: 0.36433497071266174 2022-07-20 01:11:53.064045
Epoch:[ 107 6 ] loss: 0.36316537857055664 2022-07-20 01:11:53.477877
Epoch:[ 107 7 ] loss: 0.36374562978744507 2022-07-20 01:11:53.892141
Epoch:[ 107 8 ] loss: 0.36555546522140503 2022-07-20 01:11:54.304984
Epoch:[ 107 9 ] loss: 0.364816814661026 2022-07-20 01:11:54.718261
Epoch:[ 107 10 ] loss: 0.3650530278682709 2022-07-20 01:11:55.132324
Epoch:[ 107 11 ] loss: 0.3652849495410919 2022-07-20 01:11:55.545433
Epoch:[ 107 12 ] loss: 0.36460429430007935 2022-07-20 01:11:55.957628
Epoch:[ 107 13 ] loss: 0.3659341633319855 2022-07-20 01:11:56.371159
Epoch:[ 107 14 ] loss: 0.3646101653575897 2022-07-20 01:11:56.785455
Epoch:[ 107 15 ] loss: 0.365195631980896 2022-07-20 01:11:57.198508
Epoch:[ 107 16 ] loss: 0.36535194516181946 2022-07-20 01:12:02.895640
Epoch:[ 107 17 ] loss: 0.36518439650535583 2022-07-20 01:12:03.313266
Epoch:[ 107 18 ] loss: 0.36568230390548706 2022-07-20 01:12:03.729192
Epoch:[ 107 19 ] loss: 0.3655315637588501 2022-07-20 01:12:04.138516
Training_Epoch:[ 107 ] Training_loss: 0.36493892818689344 2022-07-20 01:12:04.140284
learning rate:  0.0001968744043407226
val: 1 0.40633243322372437
val: 2 0.39745256304740906
val: 3 0.40289169549942017
val: 4 0.4065978229045868
val: 5 0.4002596437931061
val: 6 0.4051877558231354
val: 7 0.3981805443763733
val: 8 0.4074978530406952
val: 9 0.40210220217704773
val: 10 0.4092070758342743
val: 11 0.39898255467414856
val: 12 0.40585100650787354
val: 13 0.39887526631355286
val: 14 0.3970188498497009
val: 15 0.40276435017585754
val: 16 0.4031811058521271
val: 17 0.3960130512714386
val: 18 0.4089530110359192
val: 19 0.3993209898471832
val: 20 0.41072556376457214
val_Epoch:[ 107 ] val_loss: 0.4028697669506073 2022-07-20 01:12:07.384194
start training 2022-07-20 01:12:07.485100
Epoch:[ 108 0 ] loss: 0.36506953835487366 2022-07-20 01:12:21.138016
Epoch:[ 108 1 ] loss: 0.3655133545398712 2022-07-20 01:12:21.570176
Epoch:[ 108 2 ] loss: 0.36595699191093445 2022-07-20 01:12:21.981786
Epoch:[ 108 3 ] loss: 0.36433836817741394 2022-07-20 01:12:22.393648
Epoch:[ 108 4 ] loss: 0.36401671171188354 2022-07-20 01:12:22.806650
Epoch:[ 108 5 ] loss: 0.36657360196113586 2022-07-20 01:12:23.224528
Epoch:[ 108 6 ] loss: 0.3646543323993683 2022-07-20 01:12:23.636388
Epoch:[ 108 7 ] loss: 0.3645828068256378 2022-07-20 01:12:24.051083
Epoch:[ 108 8 ] loss: 0.3660902678966522 2022-07-20 01:12:24.464449
Epoch:[ 108 9 ] loss: 0.36362412571907043 2022-07-20 01:12:24.876925
Epoch:[ 108 10 ] loss: 0.36637383699417114 2022-07-20 01:12:25.290571
Epoch:[ 108 11 ] loss: 0.3638775944709778 2022-07-20 01:12:25.703555
Epoch:[ 108 12 ] loss: 0.36602985858917236 2022-07-20 01:12:26.115451
Epoch:[ 108 13 ] loss: 0.36365807056427 2022-07-20 01:12:26.533392
Epoch:[ 108 14 ] loss: 0.36757081747055054 2022-07-20 01:12:26.947845
Epoch:[ 108 15 ] loss: 0.36426597833633423 2022-07-20 01:12:27.361439
Epoch:[ 108 16 ] loss: 0.3665349781513214 2022-07-20 01:12:32.814551
Epoch:[ 108 17 ] loss: 0.36869803071022034 2022-07-20 01:12:33.233481
Epoch:[ 108 18 ] loss: 0.3661297857761383 2022-07-20 01:12:33.648140
Epoch:[ 108 19 ] loss: 0.36767372488975525 2022-07-20 01:12:34.060288
Training_Epoch:[ 108 ] Training_loss: 0.36556163877248765 2022-07-20 01:12:34.061234
learning rate:  0.0001968744043407226
netparams have been saved once 108
val: 1 0.40176287293434143
val: 2 0.4129318594932556
val: 3 0.4069044589996338
val: 4 0.4042972922325134
val: 5 0.4010761082172394
val: 6 0.40767890214920044
val: 7 0.4046225845813751
val: 8 0.4043871760368347
val: 9 0.41090717911720276
val: 10 0.4077548384666443
val: 11 0.4076375961303711
val: 12 0.3989407420158386
val: 13 0.40424710512161255
val: 14 0.40783563256263733
val: 15 0.4084671437740326
val: 16 0.41295841336250305
val: 17 0.39018702507019043
val: 18 0.40227314829826355
val: 19 0.4061221480369568
val: 20 0.4091762602329254
val_Epoch:[ 108 ] val_loss: 0.4055084243416786 2022-07-20 01:12:37.300857
start training 2022-07-20 01:12:37.402227
Epoch:[ 109 0 ] loss: 0.3648378252983093 2022-07-20 01:12:51.651860
Epoch:[ 109 1 ] loss: 0.3648965656757355 2022-07-20 01:12:52.066692
Epoch:[ 109 2 ] loss: 0.364718496799469 2022-07-20 01:12:52.481664
Epoch:[ 109 3 ] loss: 0.3651309907436371 2022-07-20 01:12:52.893742
Epoch:[ 109 4 ] loss: 0.36617511510849 2022-07-20 01:12:53.304044
Epoch:[ 109 5 ] loss: 0.36528781056404114 2022-07-20 01:12:53.717598
Epoch:[ 109 6 ] loss: 0.3662513494491577 2022-07-20 01:12:54.130478
Epoch:[ 109 7 ] loss: 0.36493542790412903 2022-07-20 01:12:54.544962
Epoch:[ 109 8 ] loss: 0.36534473299980164 2022-07-20 01:12:54.959180
Epoch:[ 109 9 ] loss: 0.3668385446071625 2022-07-20 01:12:55.373781
Epoch:[ 109 10 ] loss: 0.3647211790084839 2022-07-20 01:12:55.786500
Epoch:[ 109 11 ] loss: 0.366847962141037 2022-07-20 01:12:56.198307
Epoch:[ 109 12 ] loss: 0.3679558336734772 2022-07-20 01:12:56.610018
Epoch:[ 109 13 ] loss: 0.3660227954387665 2022-07-20 01:12:57.022595
Epoch:[ 109 14 ] loss: 0.3689265847206116 2022-07-20 01:12:57.431071
Epoch:[ 109 15 ] loss: 0.3653694689273834 2022-07-20 01:12:57.845433
Epoch:[ 109 16 ] loss: 0.36802002787590027 2022-07-20 01:13:03.069213
Epoch:[ 109 17 ] loss: 0.36697444319725037 2022-07-20 01:13:03.478974
Epoch:[ 109 18 ] loss: 0.3665608763694763 2022-07-20 01:13:03.903649
Epoch:[ 109 19 ] loss: 0.36738547682762146 2022-07-20 01:13:04.313737
Training_Epoch:[ 109 ] Training_loss: 0.36616007536649703 2022-07-20 01:13:04.314644
learning rate:  0.0001968744043407226
val: 1 0.4086601734161377
val: 2 0.4079473912715912
val: 3 0.4202439486980438
val: 4 0.41726770997047424
val: 5 0.41833576560020447
val: 6 0.4146968126296997
val: 7 0.4139597415924072
val: 8 0.401045024394989
val: 9 0.4024204611778259
val: 10 0.4119332730770111
val: 11 0.41571468114852905
val: 12 0.4077702462673187
val: 13 0.4052477180957794
val: 14 0.402671217918396
val: 15 0.4124579131603241
val: 16 0.4161818027496338
val: 17 0.415361613035202
val: 18 0.4183240234851837
val: 19 0.39992755651474
val: 20 0.4264349341392517
val_Epoch:[ 109 ] val_loss: 0.41183010041713713 2022-07-20 01:13:07.502324
start training 2022-07-20 01:13:07.601798
Epoch:[ 110 0 ] loss: 0.3657653331756592 2022-07-20 01:13:21.702895
Epoch:[ 110 1 ] loss: 0.36678218841552734 2022-07-20 01:13:22.123096
Epoch:[ 110 2 ] loss: 0.3660027086734772 2022-07-20 01:13:22.536817
Epoch:[ 110 3 ] loss: 0.365646094083786 2022-07-20 01:13:22.952138
Epoch:[ 110 4 ] loss: 0.3633098006248474 2022-07-20 01:13:23.363954
Epoch:[ 110 5 ] loss: 0.36509501934051514 2022-07-20 01:13:23.776943
Epoch:[ 110 6 ] loss: 0.36518654227256775 2022-07-20 01:13:24.191988
Epoch:[ 110 7 ] loss: 0.36589473485946655 2022-07-20 01:13:24.606091
Epoch:[ 110 8 ] loss: 0.36401882767677307 2022-07-20 01:13:25.025387
Epoch:[ 110 9 ] loss: 0.3648323714733124 2022-07-20 01:13:25.439703
Epoch:[ 110 10 ] loss: 0.36578214168548584 2022-07-20 01:13:25.853830
Epoch:[ 110 11 ] loss: 0.3636854588985443 2022-07-20 01:13:26.267076
Epoch:[ 110 12 ] loss: 0.36660367250442505 2022-07-20 01:13:26.684775
Epoch:[ 110 13 ] loss: 0.36328577995300293 2022-07-20 01:13:27.098468
Epoch:[ 110 14 ] loss: 0.36499837040901184 2022-07-20 01:13:27.511520
Epoch:[ 110 15 ] loss: 0.3662019968032837 2022-07-20 01:13:27.924862
Epoch:[ 110 16 ] loss: 0.3667953610420227 2022-07-20 01:13:33.194635
Epoch:[ 110 17 ] loss: 0.3662791848182678 2022-07-20 01:13:33.611346
Epoch:[ 110 18 ] loss: 0.364202082157135 2022-07-20 01:13:34.021950
Epoch:[ 110 19 ] loss: 0.36667370796203613 2022-07-20 01:13:34.441099
Training_Epoch:[ 110 ] Training_loss: 0.3653520688414574 2022-07-20 01:13:34.441924
learning rate:  0.0001968744043407226
netparams have been saved once 110
val: 1 0.4017818570137024
val: 2 0.40707284212112427
val: 3 0.4137747883796692
val: 4 0.40511655807495117
val: 5 0.4040379524230957
val: 6 0.4080534279346466
val: 7 0.4083115756511688
val: 8 0.40217772126197815
val: 9 0.404327392578125
val: 10 0.40922674536705017
val: 11 0.4119066298007965
val: 12 0.39850807189941406
val: 13 0.4043431282043457
val: 14 0.3988370895385742
val: 15 0.39895033836364746
val: 16 0.4023496210575104
val: 17 0.4060976505279541
val: 18 0.4012407958507538
val: 19 0.40001198649406433
val: 20 0.4078995883464813
val_Epoch:[ 110 ] val_loss: 0.40470128804445266 2022-07-20 01:13:37.617005
start training 2022-07-20 01:13:37.721081
Epoch:[ 111 0 ] loss: 0.3655451536178589 2022-07-20 01:13:51.035165
Epoch:[ 111 1 ] loss: 0.3651246130466461 2022-07-20 01:13:51.828224
Epoch:[ 111 2 ] loss: 0.3651650547981262 2022-07-20 01:13:52.241490
Epoch:[ 111 3 ] loss: 0.36461591720581055 2022-07-20 01:13:52.656010
Epoch:[ 111 4 ] loss: 0.364216148853302 2022-07-20 01:13:53.070330
Epoch:[ 111 5 ] loss: 0.36476588249206543 2022-07-20 01:13:53.485277
Epoch:[ 111 6 ] loss: 0.3644818067550659 2022-07-20 01:13:53.906467
Epoch:[ 111 7 ] loss: 0.3650073707103729 2022-07-20 01:13:54.320756
Epoch:[ 111 8 ] loss: 0.36536598205566406 2022-07-20 01:13:54.735283
Epoch:[ 111 9 ] loss: 0.3644046187400818 2022-07-20 01:13:55.148635
Epoch:[ 111 10 ] loss: 0.3637368679046631 2022-07-20 01:13:55.564223
Epoch:[ 111 11 ] loss: 0.3644104599952698 2022-07-20 01:13:55.985357
Epoch:[ 111 12 ] loss: 0.363299697637558 2022-07-20 01:13:56.398275
Epoch:[ 111 13 ] loss: 0.36637187004089355 2022-07-20 01:13:56.810786
Epoch:[ 111 14 ] loss: 0.36476224660873413 2022-07-20 01:13:57.225686
Epoch:[ 111 15 ] loss: 0.3641026020050049 2022-07-20 01:13:57.640043
Epoch:[ 111 16 ] loss: 0.36310866475105286 2022-07-20 01:14:02.743124
Epoch:[ 111 17 ] loss: 0.3646421432495117 2022-07-20 01:14:03.158291
Epoch:[ 111 18 ] loss: 0.364156574010849 2022-07-20 01:14:03.573882
Epoch:[ 111 19 ] loss: 0.3655252456665039 2022-07-20 01:14:03.992008
Training_Epoch:[ 111 ] Training_loss: 0.36464044600725176 2022-07-20 01:14:03.992702
learning rate:  0.0001673432436896142
val: 1 0.40329962968826294
val: 2 0.4052375853061676
val: 3 0.40350815653800964
val: 4 0.4061678647994995
val: 5 0.4005817770957947
val: 6 0.406547486782074
val: 7 0.4060729444026947
val: 8 0.40131622552871704
val: 9 0.4018806219100952
val: 10 0.40853413939476013
val: 11 0.4074564278125763
val: 12 0.4070252776145935
val: 13 0.4032946527004242
val: 14 0.41270893812179565
val: 15 0.4125478267669678
val: 16 0.40185442566871643
val: 17 0.4017404317855835
val: 18 0.4053802490234375
val: 19 0.41460028290748596
val: 20 0.405628502368927
val_Epoch:[ 111 ] val_loss: 0.40576917231082915 2022-07-20 01:14:07.141291
start training 2022-07-20 01:14:07.242841
Epoch:[ 112 0 ] loss: 0.36290526390075684 2022-07-20 01:14:20.803958
Epoch:[ 112 1 ] loss: 0.3637171983718872 2022-07-20 01:14:21.362632
Epoch:[ 112 2 ] loss: 0.3633362054824829 2022-07-20 01:14:21.777176
Epoch:[ 112 3 ] loss: 0.3645366132259369 2022-07-20 01:14:22.192192
Epoch:[ 112 4 ] loss: 0.3622076213359833 2022-07-20 01:14:22.609978
Epoch:[ 112 5 ] loss: 0.3662670850753784 2022-07-20 01:14:23.023744
Epoch:[ 112 6 ] loss: 0.36452847719192505 2022-07-20 01:14:23.436429
Epoch:[ 112 7 ] loss: 0.3651829957962036 2022-07-20 01:14:23.848433
Epoch:[ 112 8 ] loss: 0.3633189797401428 2022-07-20 01:14:24.261795
Epoch:[ 112 9 ] loss: 0.36378607153892517 2022-07-20 01:14:24.676224
Epoch:[ 112 10 ] loss: 0.3641602694988251 2022-07-20 01:14:25.092019
Epoch:[ 112 11 ] loss: 0.36452606320381165 2022-07-20 01:14:25.506870
Epoch:[ 112 12 ] loss: 0.3626123368740082 2022-07-20 01:14:25.921764
Epoch:[ 112 13 ] loss: 0.36440354585647583 2022-07-20 01:14:26.335093
Epoch:[ 112 14 ] loss: 0.363839715719223 2022-07-20 01:14:26.748692
Epoch:[ 112 15 ] loss: 0.362509548664093 2022-07-20 01:14:27.167913
Epoch:[ 112 16 ] loss: 0.3640791177749634 2022-07-20 01:14:32.570651
Epoch:[ 112 17 ] loss: 0.3646659851074219 2022-07-20 01:14:32.982613
Epoch:[ 112 18 ] loss: 0.3638208508491516 2022-07-20 01:14:33.403833
Epoch:[ 112 19 ] loss: 0.36394211649894714 2022-07-20 01:14:33.824078
Training_Epoch:[ 112 ] Training_loss: 0.36391730308532716 2022-07-20 01:14:33.824735
learning rate:  0.0001673432436896142
netparams have been saved once 112
val: 1 0.41924959421157837
val: 2 0.40322938561439514
val: 3 0.40493065118789673
val: 4 0.41740044951438904
val: 5 0.40939825773239136
val: 6 0.4022243916988373
val: 7 0.40747976303100586
val: 8 0.40215474367141724
val: 9 0.4012245833873749
val: 10 0.4086166024208069
val: 11 0.4120029807090759
val: 12 0.41200563311576843
val: 13 0.40002790093421936
val: 14 0.4030921757221222
val: 15 0.41073840856552124
val: 16 0.40187209844589233
val: 17 0.41235849261283875
val: 18 0.40190884470939636
val: 19 0.4119662940502167
val: 20 0.4018094837665558
val_Epoch:[ 112 ] val_loss: 0.407184536755085 2022-07-20 01:14:37.059747
start training 2022-07-20 01:14:37.159786
Epoch:[ 113 0 ] loss: 0.36341726779937744 2022-07-20 01:14:50.664557
Epoch:[ 113 1 ] loss: 0.3619958460330963 2022-07-20 01:14:51.102183
Epoch:[ 113 2 ] loss: 0.36395084857940674 2022-07-20 01:14:51.515763
Epoch:[ 113 3 ] loss: 0.3616645932197571 2022-07-20 01:14:51.927533
Epoch:[ 113 4 ] loss: 0.3630083203315735 2022-07-20 01:14:52.340405
Epoch:[ 113 5 ] loss: 0.36311060190200806 2022-07-20 01:14:52.755171
Epoch:[ 113 6 ] loss: 0.36351478099823 2022-07-20 01:14:53.168886
Epoch:[ 113 7 ] loss: 0.36254578828811646 2022-07-20 01:14:53.580924
Epoch:[ 113 8 ] loss: 0.36170369386672974 2022-07-20 01:14:53.998526
Epoch:[ 113 9 ] loss: 0.36256277561187744 2022-07-20 01:14:54.411717
Epoch:[ 113 10 ] loss: 0.3631584942340851 2022-07-20 01:14:54.825089
Epoch:[ 113 11 ] loss: 0.3639184832572937 2022-07-20 01:14:55.240292
Epoch:[ 113 12 ] loss: 0.36300620436668396 2022-07-20 01:14:55.654345
Epoch:[ 113 13 ] loss: 0.36230218410491943 2022-07-20 01:14:56.068526
Epoch:[ 113 14 ] loss: 0.36239391565322876 2022-07-20 01:14:56.487576
Epoch:[ 113 15 ] loss: 0.36298003792762756 2022-07-20 01:14:56.899600
Epoch:[ 113 16 ] loss: 0.36365965008735657 2022-07-20 01:15:02.665867
Epoch:[ 113 17 ] loss: 0.36364686489105225 2022-07-20 01:15:03.083851
Epoch:[ 113 18 ] loss: 0.3632291257381439 2022-07-20 01:15:03.505042
Epoch:[ 113 19 ] loss: 0.36315926909446716 2022-07-20 01:15:03.919163
Training_Epoch:[ 113 ] Training_loss: 0.3629464372992516 2022-07-20 01:15:03.919840
learning rate:  0.0001673432436896142
val: 1 0.40461695194244385
val: 2 0.404403954744339
val: 3 0.40704023838043213
val: 4 0.3935706913471222
val: 5 0.4012983441352844
val: 6 0.40520939230918884
val: 7 0.4021351933479309
val: 8 0.4095427393913269
val: 9 0.4034044146537781
val: 10 0.39961522817611694
val: 11 0.4060654044151306
val: 12 0.40038642287254333
val: 13 0.4048991799354553
val: 14 0.40146392583847046
val: 15 0.40628743171691895
val: 16 0.41163015365600586
val: 17 0.4126323163509369
val: 18 0.39637142419815063
val: 19 0.41031625866889954
val: 20 0.40525972843170166
val_Epoch:[ 113 ] val_loss: 0.4043074697256088 2022-07-20 01:15:07.033246
start training 2022-07-20 01:15:07.133640
Epoch:[ 114 0 ] loss: 0.3627777397632599 2022-07-20 01:15:21.265533
Epoch:[ 114 1 ] loss: 0.36334505677223206 2022-07-20 01:15:21.678554
Epoch:[ 114 2 ] loss: 0.3639567792415619 2022-07-20 01:15:22.091755
Epoch:[ 114 3 ] loss: 0.36256977915763855 2022-07-20 01:15:22.504889
Epoch:[ 114 4 ] loss: 0.3622654378414154 2022-07-20 01:15:22.925004
Epoch:[ 114 5 ] loss: 0.3627501130104065 2022-07-20 01:15:23.338557
Epoch:[ 114 6 ] loss: 0.3639397919178009 2022-07-20 01:15:23.754401
Epoch:[ 114 7 ] loss: 0.36292898654937744 2022-07-20 01:15:24.174629
Epoch:[ 114 8 ] loss: 0.36058610677719116 2022-07-20 01:15:24.588137
Epoch:[ 114 9 ] loss: 0.3629215657711029 2022-07-20 01:15:25.003643
Epoch:[ 114 10 ] loss: 0.36288702487945557 2022-07-20 01:15:25.418844
Epoch:[ 114 11 ] loss: 0.3636043965816498 2022-07-20 01:15:25.832049
Epoch:[ 114 12 ] loss: 0.3619108498096466 2022-07-20 01:15:26.245842
Epoch:[ 114 13 ] loss: 0.36196064949035645 2022-07-20 01:15:26.661575
Epoch:[ 114 14 ] loss: 0.3627738356590271 2022-07-20 01:15:27.085231
Epoch:[ 114 15 ] loss: 0.36282840371131897 2022-07-20 01:15:27.500723
Epoch:[ 114 16 ] loss: 0.36337050795555115 2022-07-20 01:15:32.658715
Epoch:[ 114 17 ] loss: 0.3627515435218811 2022-07-20 01:15:33.077043
Epoch:[ 114 18 ] loss: 0.3634565472602844 2022-07-20 01:15:33.493323
Epoch:[ 114 19 ] loss: 0.36361250281333923 2022-07-20 01:15:33.911245
Training_Epoch:[ 114 ] Training_loss: 0.36285988092422483 2022-07-20 01:15:33.911947
learning rate:  0.0001673432436896142
netparams have been saved once 114
val: 1 0.40151312947273254
val: 2 0.4012618362903595
val: 3 0.41528525948524475
val: 4 0.399506151676178
val: 5 0.40638604760169983
val: 6 0.4212706685066223
val: 7 0.41179487109184265
val: 8 0.4067886769771576
val: 9 0.40219947695732117
val: 10 0.4204973876476288
val: 11 0.4107569754123688
val: 12 0.40566006302833557
val: 13 0.41297224164009094
val: 14 0.40552806854248047
val: 15 0.4071098268032074
val: 16 0.4017685353755951
val: 17 0.4086393117904663
val: 18 0.4045287072658539
val: 19 0.42248162627220154
val: 20 0.4052475690841675
val_Epoch:[ 114 ] val_loss: 0.40855982154607773 2022-07-20 01:15:37.075389
start training 2022-07-20 01:15:37.177326
Epoch:[ 115 0 ] loss: 0.3633463978767395 2022-07-20 01:15:50.782317
Epoch:[ 115 1 ] loss: 0.3641260862350464 2022-07-20 01:15:51.196273
Epoch:[ 115 2 ] loss: 0.36428752541542053 2022-07-20 01:15:51.608644
Epoch:[ 115 3 ] loss: 0.3647768795490265 2022-07-20 01:15:52.022473
Epoch:[ 115 4 ] loss: 0.36327317357063293 2022-07-20 01:15:52.434595
Epoch:[ 115 5 ] loss: 0.36318445205688477 2022-07-20 01:15:52.851499
Epoch:[ 115 6 ] loss: 0.3641599416732788 2022-07-20 01:15:53.263684
Epoch:[ 115 7 ] loss: 0.3640400767326355 2022-07-20 01:15:53.677843
Epoch:[ 115 8 ] loss: 0.3642061948776245 2022-07-20 01:15:54.091452
Epoch:[ 115 9 ] loss: 0.36450502276420593 2022-07-20 01:15:54.503883
Epoch:[ 115 10 ] loss: 0.3643561005592346 2022-07-20 01:15:54.918484
Epoch:[ 115 11 ] loss: 0.36321502923965454 2022-07-20 01:15:55.331299
Epoch:[ 115 12 ] loss: 0.3645186722278595 2022-07-20 01:15:55.744766
Epoch:[ 115 13 ] loss: 0.36323487758636475 2022-07-20 01:15:56.160249
Epoch:[ 115 14 ] loss: 0.36299580335617065 2022-07-20 01:15:56.580807
Epoch:[ 115 15 ] loss: 0.3633008897304535 2022-07-20 01:15:56.993847
Epoch:[ 115 16 ] loss: 0.36345791816711426 2022-07-20 01:16:02.483574
Epoch:[ 115 17 ] loss: 0.36370423436164856 2022-07-20 01:16:02.898359
Epoch:[ 115 18 ] loss: 0.364046573638916 2022-07-20 01:16:03.312857
Epoch:[ 115 19 ] loss: 0.3640541732311249 2022-07-20 01:16:03.730322
Training_Epoch:[ 115 ] Training_loss: 0.36383950114250185 2022-07-20 01:16:03.731001
learning rate:  0.0001673432436896142
val: 1 0.4132551848888397
val: 2 0.4058202803134918
val: 3 0.39959806203842163
val: 4 0.40554893016815186
val: 5 0.4077499508857727
val: 6 0.40978965163230896
val: 7 0.404514878988266
val: 8 0.4073292911052704
val: 9 0.4111451506614685
val: 10 0.4034079313278198
val: 11 0.4135143458843231
val: 12 0.4093559980392456
val: 13 0.3946496844291687
val: 14 0.4056956470012665
val: 15 0.4146798849105835
val: 16 0.4064493775367737
val: 17 0.4102787971496582
val: 18 0.39483124017715454
val: 19 0.4063616394996643
val: 20 0.40165480971336365
val_Epoch:[ 115 ] val_loss: 0.40628153681755064 2022-07-20 01:16:06.861893
start training 2022-07-20 01:16:06.965246
Epoch:[ 116 0 ] loss: 0.36432573199272156 2022-07-20 01:16:20.175566
Epoch:[ 116 1 ] loss: 0.36282020807266235 2022-07-20 01:16:20.969948
Epoch:[ 116 2 ] loss: 0.3637301027774811 2022-07-20 01:16:21.384760
Epoch:[ 116 3 ] loss: 0.3625377416610718 2022-07-20 01:16:21.801009
Epoch:[ 116 4 ] loss: 0.36283183097839355 2022-07-20 01:16:22.214287
Epoch:[ 116 5 ] loss: 0.36294427514076233 2022-07-20 01:16:22.626880
Epoch:[ 116 6 ] loss: 0.36312758922576904 2022-07-20 01:16:23.044681
Epoch:[ 116 7 ] loss: 0.3625183701515198 2022-07-20 01:16:23.458083
Epoch:[ 116 8 ] loss: 0.3609224557876587 2022-07-20 01:16:23.871290
Epoch:[ 116 9 ] loss: 0.3632441759109497 2022-07-20 01:16:24.285295
Epoch:[ 116 10 ] loss: 0.36113420128822327 2022-07-20 01:16:24.698233
Epoch:[ 116 11 ] loss: 0.3622916638851166 2022-07-20 01:16:25.112382
Epoch:[ 116 12 ] loss: 0.36271509528160095 2022-07-20 01:16:25.525546
Epoch:[ 116 13 ] loss: 0.36275994777679443 2022-07-20 01:16:25.939658
Epoch:[ 116 14 ] loss: 0.36308005452156067 2022-07-20 01:16:26.354954
Epoch:[ 116 15 ] loss: 0.36266401410102844 2022-07-20 01:16:26.775317
Epoch:[ 116 16 ] loss: 0.3620208203792572 2022-07-20 01:16:32.227754
Epoch:[ 116 17 ] loss: 0.3637048602104187 2022-07-20 01:16:32.644609
Epoch:[ 116 18 ] loss: 0.36281195282936096 2022-07-20 01:16:33.059982
Epoch:[ 116 19 ] loss: 0.3635621666908264 2022-07-20 01:16:33.469442
Training_Epoch:[ 116 ] Training_loss: 0.3627873629331589 2022-07-20 01:16:33.470296
learning rate:  0.0001673432436896142
netparams have been saved once 116
val: 1 0.4066909849643707
val: 2 0.40052005648612976
val: 3 0.4004378616809845
val: 4 0.3999541401863098
val: 5 0.39971408247947693
val: 6 0.4021986126899719
val: 7 0.40681931376457214
val: 8 0.4116390645503998
val: 9 0.4027368426322937
val: 10 0.40577781200408936
val: 11 0.4100022315979004
val: 12 0.4085409641265869
val: 13 0.4086550176143646
val: 14 0.40733879804611206
val: 15 0.41160067915916443
val: 16 0.40572869777679443
val: 17 0.40713953971862793
val: 18 0.40399783849716187
val: 19 0.41149061918258667
val: 20 0.40540817379951477
val_Epoch:[ 116 ] val_loss: 0.40581956654787066 2022-07-20 01:16:36.679222
start training 2022-07-20 01:16:36.784237
Epoch:[ 117 0 ] loss: 0.3623904585838318 2022-07-20 01:16:50.820828
Epoch:[ 117 1 ] loss: 0.36282384395599365 2022-07-20 01:16:51.234799
Epoch:[ 117 2 ] loss: 0.3644522726535797 2022-07-20 01:16:51.654614
Epoch:[ 117 3 ] loss: 0.3628731667995453 2022-07-20 01:16:52.069604
Epoch:[ 117 4 ] loss: 0.36292901635169983 2022-07-20 01:16:52.482081
Epoch:[ 117 5 ] loss: 0.36189135909080505 2022-07-20 01:16:52.895588
Epoch:[ 117 6 ] loss: 0.36199864745140076 2022-07-20 01:16:53.310720
Epoch:[ 117 7 ] loss: 0.3617751896381378 2022-07-20 01:16:53.729427
Epoch:[ 117 8 ] loss: 0.3609130084514618 2022-07-20 01:16:54.142001
Epoch:[ 117 9 ] loss: 0.3621464669704437 2022-07-20 01:16:54.554146
Epoch:[ 117 10 ] loss: 0.36111360788345337 2022-07-20 01:16:54.969069
Epoch:[ 117 11 ] loss: 0.36156752705574036 2022-07-20 01:16:55.383978
Epoch:[ 117 12 ] loss: 0.36295512318611145 2022-07-20 01:16:55.798445
Epoch:[ 117 13 ] loss: 0.3626129627227783 2022-07-20 01:16:56.212594
Epoch:[ 117 14 ] loss: 0.3620125353336334 2022-07-20 01:16:56.625958
Epoch:[ 117 15 ] loss: 0.3628365099430084 2022-07-20 01:16:57.043238
Epoch:[ 117 16 ] loss: 0.3625181317329407 2022-07-20 01:17:02.520690
Epoch:[ 117 17 ] loss: 0.3610236942768097 2022-07-20 01:17:02.934278
Epoch:[ 117 18 ] loss: 0.3619008958339691 2022-07-20 01:17:03.348897
Epoch:[ 117 19 ] loss: 0.363190233707428 2022-07-20 01:17:03.757250
Training_Epoch:[ 117 ] Training_loss: 0.36229623258113863 2022-07-20 01:17:03.758037
learning rate:  0.0001673432436896142
val: 1 0.4194885790348053
val: 2 0.41603606939315796
val: 3 0.4095988869667053
val: 4 0.4052276909351349
val: 5 0.41268181800842285
val: 6 0.4074913561344147
val: 7 0.3975657522678375
val: 8 0.4068590998649597
val: 9 0.40851131081581116
val: 10 0.40656086802482605
val: 11 0.4125797748565674
val: 12 0.4053989052772522
val: 13 0.4023028314113617
val: 14 0.3978039026260376
val: 15 0.41117987036705017
val: 16 0.4106220602989197
val: 17 0.4006066918373108
val: 18 0.4097367823123932
val: 19 0.40628644824028015
val: 20 0.40645214915275574
val_Epoch:[ 117 ] val_loss: 0.4076495423913002 2022-07-20 01:17:06.925020
start training 2022-07-20 01:17:07.028648
Epoch:[ 118 0 ] loss: 0.3602859377861023 2022-07-20 01:17:20.596880
Epoch:[ 118 1 ] loss: 0.36200612783432007 2022-07-20 01:17:21.025283
Epoch:[ 118 2 ] loss: 0.36165687441825867 2022-07-20 01:17:21.447309
Epoch:[ 118 3 ] loss: 0.36238953471183777 2022-07-20 01:17:21.862620
Epoch:[ 118 4 ] loss: 0.36064228415489197 2022-07-20 01:17:22.277174
Epoch:[ 118 5 ] loss: 0.36216938495635986 2022-07-20 01:17:22.690180
Epoch:[ 118 6 ] loss: 0.36198073625564575 2022-07-20 01:17:23.102548
Epoch:[ 118 7 ] loss: 0.36168816685676575 2022-07-20 01:17:23.516373
Epoch:[ 118 8 ] loss: 0.3631172478199005 2022-07-20 01:17:23.938629
Epoch:[ 118 9 ] loss: 0.36154070496559143 2022-07-20 01:17:24.350619
Epoch:[ 118 10 ] loss: 0.36236119270324707 2022-07-20 01:17:24.766518
Epoch:[ 118 11 ] loss: 0.3628406226634979 2022-07-20 01:17:25.181213
Epoch:[ 118 12 ] loss: 0.3641889691352844 2022-07-20 01:17:25.594328
Epoch:[ 118 13 ] loss: 0.3611091673374176 2022-07-20 01:17:26.008493
Epoch:[ 118 14 ] loss: 0.3625713586807251 2022-07-20 01:17:26.423263
Epoch:[ 118 15 ] loss: 0.36361944675445557 2022-07-20 01:17:26.835985
Epoch:[ 118 16 ] loss: 0.3632872998714447 2022-07-20 01:17:32.303495
Epoch:[ 118 17 ] loss: 0.3635174036026001 2022-07-20 01:17:32.717690
Epoch:[ 118 18 ] loss: 0.3624460697174072 2022-07-20 01:17:33.135495
Epoch:[ 118 19 ] loss: 0.3614949882030487 2022-07-20 01:17:33.553853
Training_Epoch:[ 118 ] Training_loss: 0.36224567592144014 2022-07-20 01:17:33.554715
learning rate:  0.0001673432436896142
netparams have been saved once 118
val: 1 0.4040720760822296
val: 2 0.4169788062572479
val: 3 0.38842907547950745
val: 4 0.40607839822769165
val: 5 0.41218703985214233
val: 6 0.40867069363594055
val: 7 0.4128555655479431
val: 8 0.40232327580451965
val: 9 0.40992724895477295
val: 10 0.4043164849281311
val: 11 0.4037344753742218
val: 12 0.4154674708843231
val: 13 0.39520901441574097
val: 14 0.40945613384246826
val: 15 0.4074311852455139
val: 16 0.400787353515625
val: 17 0.4099505543708801
val: 18 0.40040072798728943
val: 19 0.4065759778022766
val: 20 0.4128057360649109
val_Epoch:[ 118 ] val_loss: 0.4063828647136688 2022-07-20 01:17:36.762666
start training 2022-07-20 01:17:36.867187
Epoch:[ 119 0 ] loss: 0.3613503873348236 2022-07-20 01:17:50.257291
Epoch:[ 119 1 ] loss: 0.3615562915802002 2022-07-20 01:17:50.688338
Epoch:[ 119 2 ] loss: 0.36225569248199463 2022-07-20 01:17:51.126767
Epoch:[ 119 3 ] loss: 0.36324769258499146 2022-07-20 01:17:51.544982
Epoch:[ 119 4 ] loss: 0.36356455087661743 2022-07-20 01:17:51.959481
Epoch:[ 119 5 ] loss: 0.362697958946228 2022-07-20 01:17:52.376719
Epoch:[ 119 6 ] loss: 0.36164864897727966 2022-07-20 01:17:52.792344
Epoch:[ 119 7 ] loss: 0.3608716130256653 2022-07-20 01:17:53.206381
Epoch:[ 119 8 ] loss: 0.3622582256793976 2022-07-20 01:17:53.620067
Epoch:[ 119 9 ] loss: 0.36403024196624756 2022-07-20 01:17:54.034614
Epoch:[ 119 10 ] loss: 0.362151563167572 2022-07-20 01:17:54.447595
Epoch:[ 119 11 ] loss: 0.3636208772659302 2022-07-20 01:17:54.863989
Epoch:[ 119 12 ] loss: 0.3625928461551666 2022-07-20 01:17:55.278281
Epoch:[ 119 13 ] loss: 0.3609801232814789 2022-07-20 01:17:55.697001
Epoch:[ 119 14 ] loss: 0.3631904125213623 2022-07-20 01:17:56.112556
Epoch:[ 119 15 ] loss: 0.36312171816825867 2022-07-20 01:17:56.527646
Epoch:[ 119 16 ] loss: 0.3623310327529907 2022-07-20 01:18:02.167909
Epoch:[ 119 17 ] loss: 0.3621690571308136 2022-07-20 01:18:02.575674
Epoch:[ 119 18 ] loss: 0.3647347688674927 2022-07-20 01:18:02.992076
Epoch:[ 119 19 ] loss: 0.3621703088283539 2022-07-20 01:18:03.410944
Training_Epoch:[ 119 ] Training_loss: 0.36252720057964327 2022-07-20 01:18:03.411655
learning rate:  0.0001673432436896142
val: 1 0.40060654282569885
val: 2 0.4041731655597687
val: 3 0.41964879631996155
val: 4 0.4163610339164734
val: 5 0.40101301670074463
val: 6 0.41637375950813293
val: 7 0.3994262218475342
val: 8 0.40908968448638916
val: 9 0.39795368909835815
val: 10 0.405777245759964
val: 11 0.40896642208099365
val: 12 0.396884948015213
val: 13 0.3998984694480896
val: 14 0.4101172089576721
val: 15 0.4075728952884674
val: 16 0.40816280245780945
val: 17 0.4034193754196167
val: 18 0.3994922339916229
val: 19 0.4030378460884094
val: 20 0.41115307807922363
val_Epoch:[ 119 ] val_loss: 0.4059564217925072 2022-07-20 01:18:06.496293
start training 2022-07-20 01:18:06.602709
Epoch:[ 120 0 ] loss: 0.3625783920288086 2022-07-20 01:18:20.116199
Epoch:[ 120 1 ] loss: 0.3614967465400696 2022-07-20 01:18:20.681750
Epoch:[ 120 2 ] loss: 0.3608052730560303 2022-07-20 01:18:21.094105
Epoch:[ 120 3 ] loss: 0.36292338371276855 2022-07-20 01:18:21.507235
Epoch:[ 120 4 ] loss: 0.36140990257263184 2022-07-20 01:18:21.921701
Epoch:[ 120 5 ] loss: 0.36201366782188416 2022-07-20 01:18:22.337640
Epoch:[ 120 6 ] loss: 0.36310216784477234 2022-07-20 01:18:22.759164
Epoch:[ 120 7 ] loss: 0.3626587390899658 2022-07-20 01:18:23.172167
Epoch:[ 120 8 ] loss: 0.36321842670440674 2022-07-20 01:18:23.585933
Epoch:[ 120 9 ] loss: 0.3628358542919159 2022-07-20 01:18:23.999925
Epoch:[ 120 10 ] loss: 0.36309731006622314 2022-07-20 01:18:24.413528
Epoch:[ 120 11 ] loss: 0.36271512508392334 2022-07-20 01:18:24.831750
Epoch:[ 120 12 ] loss: 0.364508718252182 2022-07-20 01:18:25.245123
Epoch:[ 120 13 ] loss: 0.361092209815979 2022-07-20 01:18:25.660061
Epoch:[ 120 14 ] loss: 0.36251798272132874 2022-07-20 01:18:26.076420
Epoch:[ 120 15 ] loss: 0.36375221610069275 2022-07-20 01:18:26.492009
Epoch:[ 120 16 ] loss: 0.363120973110199 2022-07-20 01:18:31.672009
Epoch:[ 120 17 ] loss: 0.3624899089336395 2022-07-20 01:18:32.084967
Epoch:[ 120 18 ] loss: 0.3633161783218384 2022-07-20 01:18:32.498536
Epoch:[ 120 19 ] loss: 0.3626314699649811 2022-07-20 01:18:32.918463
Training_Epoch:[ 120 ] Training_loss: 0.362614232301712 2022-07-20 01:18:32.919151
learning rate:  0.0001673432436896142
netparams have been saved once 120
val: 1 0.39859330654144287
val: 2 0.4033847749233246
val: 3 0.4091518819332123
val: 4 0.40859895944595337
val: 5 0.4079093635082245
val: 6 0.4081115424633026
val: 7 0.42275580763816833
val: 8 0.41341012716293335
val: 9 0.40754666924476624
val: 10 0.41007888317108154
val: 11 0.40098312497138977
val: 12 0.4059988856315613
val: 13 0.4094041883945465
val: 14 0.4043044447898865
val: 15 0.40707504749298096
val: 16 0.4053918123245239
val: 17 0.4093584716320038
val: 18 0.40316757559776306
val: 19 0.4155966639518738
val: 20 0.4072277843952179
val_Epoch:[ 120 ] val_loss: 0.4079024657607079 2022-07-20 01:18:36.084646
start training 2022-07-20 01:18:36.191963
Epoch:[ 121 0 ] loss: 0.36244508624076843 2022-07-20 01:18:49.987441
Epoch:[ 121 1 ] loss: 0.36078450083732605 2022-07-20 01:18:50.399005
Epoch:[ 121 2 ] loss: 0.3615339696407318 2022-07-20 01:18:50.812563
Epoch:[ 121 3 ] loss: 0.3627806603908539 2022-07-20 01:18:51.225875
Epoch:[ 121 4 ] loss: 0.36061397194862366 2022-07-20 01:18:51.639130
Epoch:[ 121 5 ] loss: 0.3608675003051758 2022-07-20 01:18:52.053216
Epoch:[ 121 6 ] loss: 0.3608865737915039 2022-07-20 01:18:52.473699
Epoch:[ 121 7 ] loss: 0.3604913353919983 2022-07-20 01:18:52.887434
Epoch:[ 121 8 ] loss: 0.36234596371650696 2022-07-20 01:18:53.300948
Epoch:[ 121 9 ] loss: 0.3617360591888428 2022-07-20 01:18:53.715245
Epoch:[ 121 10 ] loss: 0.36085185408592224 2022-07-20 01:18:54.128135
Epoch:[ 121 11 ] loss: 0.36157140135765076 2022-07-20 01:18:54.540691
Epoch:[ 121 12 ] loss: 0.36221057176589966 2022-07-20 01:18:54.959426
Epoch:[ 121 13 ] loss: 0.36318743228912354 2022-07-20 01:18:55.374798
Epoch:[ 121 14 ] loss: 0.3606353998184204 2022-07-20 01:18:55.789530
Epoch:[ 121 15 ] loss: 0.3620162606239319 2022-07-20 01:18:56.208087
Epoch:[ 121 16 ] loss: 0.36011067032814026 2022-07-20 01:19:01.584911
Epoch:[ 121 17 ] loss: 0.3610405921936035 2022-07-20 01:19:01.998199
Epoch:[ 121 18 ] loss: 0.36024412512779236 2022-07-20 01:19:02.423466
Epoch:[ 121 19 ] loss: 0.3605123460292816 2022-07-20 01:19:02.838304
Training_Epoch:[ 121 ] Training_loss: 0.3613433137536049 2022-07-20 01:19:02.838993
learning rate:  0.00014224175713617207
val: 1 0.40323585271835327
val: 2 0.4041527211666107
val: 3 0.40091055631637573
val: 4 0.40073490142822266
val: 5 0.4030473530292511
val: 6 0.39717182517051697
val: 7 0.4078427851200104
val: 8 0.4102378785610199
val: 9 0.4093067944049835
val: 10 0.4109572768211365
val: 11 0.40685489773750305
val: 12 0.4054853916168213
val: 13 0.406146764755249
val: 14 0.40900859236717224
val: 15 0.4151857793331146
val: 16 0.40978842973709106
val: 17 0.4099602997303009
val: 18 0.4103199541568756
val: 19 0.39828962087631226
val: 20 0.4035916328430176
val_Epoch:[ 121 ] val_loss: 0.40611146539449694 2022-07-20 01:19:05.941611
start training 2022-07-20 01:19:06.043305
Epoch:[ 122 0 ] loss: 0.35979005694389343 2022-07-20 01:19:19.388974
Epoch:[ 122 1 ] loss: 0.35905399918556213 2022-07-20 01:19:19.819177
Epoch:[ 122 2 ] loss: 0.36194783449172974 2022-07-20 01:19:20.231265
Epoch:[ 122 3 ] loss: 0.3602546453475952 2022-07-20 01:19:20.643277
Epoch:[ 122 4 ] loss: 0.36032649874687195 2022-07-20 01:19:21.055968
Epoch:[ 122 5 ] loss: 0.3600464165210724 2022-07-20 01:19:21.469692
Epoch:[ 122 6 ] loss: 0.35971078276634216 2022-07-20 01:19:21.882434
Epoch:[ 122 7 ] loss: 0.3607330918312073 2022-07-20 01:19:22.297848
Epoch:[ 122 8 ] loss: 0.36161547899246216 2022-07-20 01:19:22.712304
Epoch:[ 122 9 ] loss: 0.3609241843223572 2022-07-20 01:19:23.131508
Epoch:[ 122 10 ] loss: 0.3600052297115326 2022-07-20 01:19:23.546290
Epoch:[ 122 11 ] loss: 0.3611077666282654 2022-07-20 01:19:23.959030
Epoch:[ 122 12 ] loss: 0.36122411489486694 2022-07-20 01:19:24.372625
Epoch:[ 122 13 ] loss: 0.3611612617969513 2022-07-20 01:19:24.790508
Epoch:[ 122 14 ] loss: 0.3615352213382721 2022-07-20 01:19:25.205785
Epoch:[ 122 15 ] loss: 0.36024004220962524 2022-07-20 01:19:25.620738
Epoch:[ 122 16 ] loss: 0.36279457807540894 2022-07-20 01:19:31.357230
Epoch:[ 122 17 ] loss: 0.3623015582561493 2022-07-20 01:19:31.777077
Epoch:[ 122 18 ] loss: 0.3614705502986908 2022-07-20 01:19:32.196864
Epoch:[ 122 19 ] loss: 0.36093348264694214 2022-07-20 01:19:32.608834
Training_Epoch:[ 122 ] Training_loss: 0.36085883975028993 2022-07-20 01:19:32.609479
learning rate:  0.00014224175713617207
netparams have been saved once 122
val: 1 0.3967778980731964
val: 2 0.41346094012260437
val: 3 0.4111546277999878
val: 4 0.3985759913921356
val: 5 0.40371614694595337
val: 6 0.4164803922176361
val: 7 0.4052983224391937
val: 8 0.40014150738716125
val: 9 0.40396708250045776
val: 10 0.4159090518951416
val: 11 0.40951722860336304
val: 12 0.40836694836616516
val: 13 0.39453059434890747
val: 14 0.4017583429813385
val: 15 0.41476038098335266
val: 16 0.4065975248813629
val: 17 0.4093725383281708
val: 18 0.4056508243083954
val: 19 0.41101375222206116
val: 20 0.39497897028923035
val_Epoch:[ 122 ] val_loss: 0.40610145330429076 2022-07-20 01:19:35.766523
start training 2022-07-20 01:19:35.867890
Epoch:[ 123 0 ] loss: 0.362216979265213 2022-07-20 01:19:49.781907
Epoch:[ 123 1 ] loss: 0.35986700654029846 2022-07-20 01:19:50.195977
Epoch:[ 123 2 ] loss: 0.36162516474723816 2022-07-20 01:19:50.611377
Epoch:[ 123 3 ] loss: 0.35986652970314026 2022-07-20 01:19:51.024008
Epoch:[ 123 4 ] loss: 0.35943108797073364 2022-07-20 01:19:51.443264
Epoch:[ 123 5 ] loss: 0.3607112169265747 2022-07-20 01:19:51.856965
Epoch:[ 123 6 ] loss: 0.3599582016468048 2022-07-20 01:19:52.275418
Epoch:[ 123 7 ] loss: 0.3612515926361084 2022-07-20 01:19:52.688600
Epoch:[ 123 8 ] loss: 0.35902807116508484 2022-07-20 01:19:53.102518
Epoch:[ 123 9 ] loss: 0.3605063855648041 2022-07-20 01:19:53.516818
Epoch:[ 123 10 ] loss: 0.3613739013671875 2022-07-20 01:19:53.929648
Epoch:[ 123 11 ] loss: 0.36029812693595886 2022-07-20 01:19:54.341065
Epoch:[ 123 12 ] loss: 0.36143988370895386 2022-07-20 01:19:54.754613
Epoch:[ 123 13 ] loss: 0.3601607084274292 2022-07-20 01:19:55.168410
Epoch:[ 123 14 ] loss: 0.3605296313762665 2022-07-20 01:19:55.581416
Epoch:[ 123 15 ] loss: 0.36179062724113464 2022-07-20 01:19:56.002211
Epoch:[ 123 16 ] loss: 0.361935019493103 2022-07-20 01:20:01.148894
Epoch:[ 123 17 ] loss: 0.3624529540538788 2022-07-20 01:20:01.561812
Epoch:[ 123 18 ] loss: 0.3615995943546295 2022-07-20 01:20:01.983886
Epoch:[ 123 19 ] loss: 0.35993441939353943 2022-07-20 01:20:02.402654
Training_Epoch:[ 123 ] Training_loss: 0.3607988551259041 2022-07-20 01:20:02.403378
learning rate:  0.00014224175713617207
val: 1 0.4100629687309265
val: 2 0.39693501591682434
val: 3 0.3976062834262848
val: 4 0.41004663705825806
val: 5 0.4048592150211334
val: 6 0.4031534194946289
val: 7 0.40915530920028687
val: 8 0.4046204686164856
val: 9 0.4044349491596222
val: 10 0.4017905592918396
val: 11 0.4062100946903229
val: 12 0.4107709527015686
val: 13 0.409655898809433
val: 14 0.4125593900680542
val: 15 0.41269102692604065
val: 16 0.40022674202919006
val: 17 0.4118340313434601
val: 18 0.3994974195957184
val: 19 0.40522319078445435
val: 20 0.40773120522499084
val_Epoch:[ 123 ] val_loss: 0.40595323890447615 2022-07-20 01:20:05.644857
start training 2022-07-20 01:20:05.748017
Epoch:[ 124 0 ] loss: 0.3602786958217621 2022-07-20 01:20:19.637542
Epoch:[ 124 1 ] loss: 0.35978230834007263 2022-07-20 01:20:20.074027
Epoch:[ 124 2 ] loss: 0.36116698384284973 2022-07-20 01:20:20.488292
Epoch:[ 124 3 ] loss: 0.361797958612442 2022-07-20 01:20:20.902659
Epoch:[ 124 4 ] loss: 0.3603397607803345 2022-07-20 01:20:21.315637
Epoch:[ 124 5 ] loss: 0.3609943687915802 2022-07-20 01:20:21.728408
Epoch:[ 124 6 ] loss: 0.36004671454429626 2022-07-20 01:20:22.141900
Epoch:[ 124 7 ] loss: 0.36122894287109375 2022-07-20 01:20:22.555633
Epoch:[ 124 8 ] loss: 0.3599212169647217 2022-07-20 01:20:22.968250
Epoch:[ 124 9 ] loss: 0.36148855090141296 2022-07-20 01:20:23.383154
Epoch:[ 124 10 ] loss: 0.3600032925605774 2022-07-20 01:20:23.805228
Epoch:[ 124 11 ] loss: 0.36114755272865295 2022-07-20 01:20:24.217888
Epoch:[ 124 12 ] loss: 0.35998809337615967 2022-07-20 01:20:24.635626
Epoch:[ 124 13 ] loss: 0.36038392782211304 2022-07-20 01:20:25.053371
Epoch:[ 124 14 ] loss: 0.36114323139190674 2022-07-20 01:20:25.466402
Epoch:[ 124 15 ] loss: 0.3598567247390747 2022-07-20 01:20:25.879220
Epoch:[ 124 16 ] loss: 0.3611183166503906 2022-07-20 01:20:30.738265
Epoch:[ 124 17 ] loss: 0.36061492562294006 2022-07-20 01:20:31.481291
Epoch:[ 124 18 ] loss: 0.36046457290649414 2022-07-20 01:20:31.900585
Epoch:[ 124 19 ] loss: 0.3601608872413635 2022-07-20 01:20:32.314421
Training_Epoch:[ 124 ] Training_loss: 0.36059635132551193 2022-07-20 01:20:32.315141
learning rate:  0.00014224175713617207
netparams have been saved once 124
val: 1 0.41416722536087036
val: 2 0.4231036603450775
val: 3 0.3984941840171814
val: 4 0.40046966075897217
val: 5 0.40447676181793213
val: 6 0.40794989466667175
val: 7 0.4031355679035187
val: 8 0.40583792328834534
val: 9 0.4119393825531006
val: 10 0.405355304479599
val: 11 0.4067365527153015
val: 12 0.4079221785068512
val: 13 0.3981841802597046
val: 14 0.403780996799469
val: 15 0.3991493284702301
val: 16 0.40875276923179626
val: 17 0.4097220003604889
val: 18 0.4118799567222595
val: 19 0.4040184020996094
val: 20 0.40476083755493164
val_Epoch:[ 124 ] val_loss: 0.40649183839559555 2022-07-20 01:20:35.503664
start training 2022-07-20 01:20:35.605445
Epoch:[ 125 0 ] loss: 0.3606305718421936 2022-07-20 01:20:49.544103
Epoch:[ 125 1 ] loss: 0.36059701442718506 2022-07-20 01:20:49.957824
Epoch:[ 125 2 ] loss: 0.3587888777256012 2022-07-20 01:20:50.370388
Epoch:[ 125 3 ] loss: 0.36193034052848816 2022-07-20 01:20:50.784613
Epoch:[ 125 4 ] loss: 0.36133748292922974 2022-07-20 01:20:51.199595
Epoch:[ 125 5 ] loss: 0.36188265681266785 2022-07-20 01:20:51.613362
Epoch:[ 125 6 ] loss: 0.36168789863586426 2022-07-20 01:20:52.027829
Epoch:[ 125 7 ] loss: 0.3601801097393036 2022-07-20 01:20:52.447169
Epoch:[ 125 8 ] loss: 0.3621152639389038 2022-07-20 01:20:52.860531
Epoch:[ 125 9 ] loss: 0.360422283411026 2022-07-20 01:20:53.273887
Epoch:[ 125 10 ] loss: 0.3625207841396332 2022-07-20 01:20:53.688684
Epoch:[ 125 11 ] loss: 0.36030852794647217 2022-07-20 01:20:54.111320
Epoch:[ 125 12 ] loss: 0.36200594902038574 2022-07-20 01:20:54.530036
Epoch:[ 125 13 ] loss: 0.36231836676597595 2022-07-20 01:20:54.942286
Epoch:[ 125 14 ] loss: 0.3610951900482178 2022-07-20 01:20:55.357376
Epoch:[ 125 15 ] loss: 0.36153164505958557 2022-07-20 01:20:55.771718
Epoch:[ 125 16 ] loss: 0.36171162128448486 2022-07-20 01:21:00.923729
Epoch:[ 125 17 ] loss: 0.3602130711078644 2022-07-20 01:21:01.343171
Epoch:[ 125 18 ] loss: 0.3608410656452179 2022-07-20 01:21:01.758284
Epoch:[ 125 19 ] loss: 0.3613528609275818 2022-07-20 01:21:02.177420
Training_Epoch:[ 125 ] Training_loss: 0.36117357909679415 2022-07-20 01:21:02.178136
learning rate:  0.00014224175713617207
val: 1 0.406123548746109
val: 2 0.41418930888175964
val: 3 0.41846713423728943
val: 4 0.4061415493488312
val: 5 0.4203048348426819
val: 6 0.41307345032691956
val: 7 0.4053848087787628
val: 8 0.40354111790657043
val: 9 0.40814390778541565
val: 10 0.41356635093688965
val: 11 0.411108136177063
val: 12 0.41395890712738037
val: 13 0.41080155968666077
val: 14 0.4146832227706909
val: 15 0.4010011553764343
val: 16 0.41065648198127747
val: 17 0.4044935405254364
val: 18 0.421856164932251
val: 19 0.40544167160987854
val: 20 0.42199042439460754
val_Epoch:[ 125 ] val_loss: 0.4112463638186455 2022-07-20 01:21:05.332643
start training 2022-07-20 01:21:05.437080
Epoch:[ 126 0 ] loss: 0.3594556748867035 2022-07-20 01:21:19.040755
Epoch:[ 126 1 ] loss: 0.35838115215301514 2022-07-20 01:21:19.457831
Epoch:[ 126 2 ] loss: 0.36015018820762634 2022-07-20 01:21:19.874772
Epoch:[ 126 3 ] loss: 0.3592209219932556 2022-07-20 01:21:20.287313
Epoch:[ 126 4 ] loss: 0.3612327575683594 2022-07-20 01:21:20.705243
Epoch:[ 126 5 ] loss: 0.3603079319000244 2022-07-20 01:21:21.118080
Epoch:[ 126 6 ] loss: 0.3609432578086853 2022-07-20 01:21:21.529441
Epoch:[ 126 7 ] loss: 0.3612651228904724 2022-07-20 01:21:21.941640
Epoch:[ 126 8 ] loss: 0.3613024353981018 2022-07-20 01:21:22.353350
Epoch:[ 126 9 ] loss: 0.35950782895088196 2022-07-20 01:21:22.766154
Epoch:[ 126 10 ] loss: 0.3615418076515198 2022-07-20 01:21:23.181907
Epoch:[ 126 11 ] loss: 0.3611389994621277 2022-07-20 01:21:23.595233
Epoch:[ 126 12 ] loss: 0.36209020018577576 2022-07-20 01:21:24.007882
Epoch:[ 126 13 ] loss: 0.36017394065856934 2022-07-20 01:21:24.419120
Epoch:[ 126 14 ] loss: 0.36200231313705444 2022-07-20 01:21:24.830680
Epoch:[ 126 15 ] loss: 0.3602915406227112 2022-07-20 01:21:25.243045
Epoch:[ 126 16 ] loss: 0.3596936762332916 2022-07-20 01:21:30.774479
Epoch:[ 126 17 ] loss: 0.3601306974887848 2022-07-20 01:21:31.183885
Epoch:[ 126 18 ] loss: 0.36005356907844543 2022-07-20 01:21:31.604324
Epoch:[ 126 19 ] loss: 0.35996803641319275 2022-07-20 01:21:32.021970
Training_Epoch:[ 126 ] Training_loss: 0.36044260263442995 2022-07-20 01:21:32.022692
learning rate:  0.00014224175713617207
netparams have been saved once 126
val: 1 0.4149009883403778
val: 2 0.4108615815639496
val: 3 0.408896267414093
val: 4 0.40781456232070923
val: 5 0.4049520194530487
val: 6 0.4133198857307434
val: 7 0.4051080644130707
val: 8 0.4037720859050751
val: 9 0.4156949818134308
val: 10 0.4019645154476166
val: 11 0.402027428150177
val: 12 0.4139035940170288
val: 13 0.4146013557910919
val: 14 0.4109618365764618
val: 15 0.4095062017440796
val: 16 0.42201924324035645
val: 17 0.40171200037002563
val: 18 0.4054652154445648
val: 19 0.4097556173801422
val: 20 0.41156235337257385
val_Epoch:[ 126 ] val_loss: 0.40943998992443087 2022-07-20 01:21:35.246330
start training 2022-07-20 01:21:35.348127
Epoch:[ 127 0 ] loss: 0.36079859733581543 2022-07-20 01:21:49.277268
Epoch:[ 127 1 ] loss: 0.36069029569625854 2022-07-20 01:21:49.691273
Epoch:[ 127 2 ] loss: 0.359429270029068 2022-07-20 01:21:50.104576
Epoch:[ 127 3 ] loss: 0.35894426703453064 2022-07-20 01:21:50.516245
Epoch:[ 127 4 ] loss: 0.36175817251205444 2022-07-20 01:21:50.929661
Epoch:[ 127 5 ] loss: 0.3612305521965027 2022-07-20 01:21:51.349458
Epoch:[ 127 6 ] loss: 0.36021888256073 2022-07-20 01:21:51.762735
Epoch:[ 127 7 ] loss: 0.36038199067115784 2022-07-20 01:21:52.174699
Epoch:[ 127 8 ] loss: 0.35915470123291016 2022-07-20 01:21:52.587200
Epoch:[ 127 9 ] loss: 0.3609473407268524 2022-07-20 01:21:53.001827
Epoch:[ 127 10 ] loss: 0.36084890365600586 2022-07-20 01:21:53.415403
Epoch:[ 127 11 ] loss: 0.3601062595844269 2022-07-20 01:21:53.830013
Epoch:[ 127 12 ] loss: 0.3610832393169403 2022-07-20 01:21:54.243884
Epoch:[ 127 13 ] loss: 0.36020177602767944 2022-07-20 01:21:54.657844
Epoch:[ 127 14 ] loss: 0.36090198159217834 2022-07-20 01:21:55.076729
Epoch:[ 127 15 ] loss: 0.3601835072040558 2022-07-20 01:21:55.495148
Epoch:[ 127 16 ] loss: 0.3599684536457062 2022-07-20 01:22:00.748724
Epoch:[ 127 17 ] loss: 0.36011868715286255 2022-07-20 01:22:01.168581
Epoch:[ 127 18 ] loss: 0.35932597517967224 2022-07-20 01:22:01.590971
Epoch:[ 127 19 ] loss: 0.36032092571258545 2022-07-20 01:22:02.005255
Training_Epoch:[ 127 ] Training_loss: 0.36033068895339965 2022-07-20 01:22:02.005943
learning rate:  0.00014224175713617207
val: 1 0.4128808379173279
val: 2 0.4143405556678772
val: 3 0.41557425260543823
val: 4 0.39187195897102356
val: 5 0.4067234694957733
val: 6 0.40418505668640137
val: 7 0.4080858528614044
val: 8 0.4081021547317505
val: 9 0.40744122862815857
val: 10 0.4110009968280792
val: 11 0.40620893239974976
val: 12 0.4089300036430359
val: 13 0.4103553891181946
val: 14 0.4180051386356354
val: 15 0.40895748138427734
val: 16 0.40869951248168945
val: 17 0.41173255443573
val: 18 0.4049798846244812
val: 19 0.41550713777542114
val: 20 0.40004095435142517
val_Epoch:[ 127 ] val_loss: 0.4086811676621437 2022-07-20 01:22:05.140950
start training 2022-07-20 01:22:05.241495
Epoch:[ 128 0 ] loss: 0.3592754006385803 2022-07-20 01:22:19.220320
Epoch:[ 128 1 ] loss: 0.359983891248703 2022-07-20 01:22:19.632512
Epoch:[ 128 2 ] loss: 0.35915762186050415 2022-07-20 01:22:20.051176
Epoch:[ 128 3 ] loss: 0.36001119017601013 2022-07-20 01:22:20.463223
Epoch:[ 128 4 ] loss: 0.36066511273384094 2022-07-20 01:22:20.875186
Epoch:[ 128 5 ] loss: 0.3596808612346649 2022-07-20 01:22:21.287124
Epoch:[ 128 6 ] loss: 0.36048218607902527 2022-07-20 01:22:21.701166
Epoch:[ 128 7 ] loss: 0.36212360858917236 2022-07-20 01:22:22.119594
Epoch:[ 128 8 ] loss: 0.3610164225101471 2022-07-20 01:22:22.533106
Epoch:[ 128 9 ] loss: 0.36215996742248535 2022-07-20 01:22:22.946820
Epoch:[ 128 10 ] loss: 0.3613026440143585 2022-07-20 01:22:23.358547
Epoch:[ 128 11 ] loss: 0.3601107895374298 2022-07-20 01:22:23.775164
Epoch:[ 128 12 ] loss: 0.3607606589794159 2022-07-20 01:22:24.187181
Epoch:[ 128 13 ] loss: 0.36019712686538696 2022-07-20 01:22:24.599265
Epoch:[ 128 14 ] loss: 0.35873329639434814 2022-07-20 01:22:25.015672
Epoch:[ 128 15 ] loss: 0.36196255683898926 2022-07-20 01:22:25.429659
Epoch:[ 128 16 ] loss: 0.36015498638153076 2022-07-20 01:22:30.628800
Epoch:[ 128 17 ] loss: 0.3625718951225281 2022-07-20 01:22:31.040342
Epoch:[ 128 18 ] loss: 0.3601125180721283 2022-07-20 01:22:31.458761
Epoch:[ 128 19 ] loss: 0.36079755425453186 2022-07-20 01:22:31.875562
Training_Epoch:[ 128 ] Training_loss: 0.36056301444768907 2022-07-20 01:22:31.876207
learning rate:  0.00014224175713617207
netparams have been saved once 128
val: 1 0.4147178530693054
val: 2 0.410961389541626
val: 3 0.40695926547050476
val: 4 0.400874525308609
val: 5 0.40989935398101807
val: 6 0.40630099177360535
val: 7 0.41495680809020996
val: 8 0.40449953079223633
val: 9 0.4080393314361572
val: 10 0.4041207432746887
val: 11 0.40671810507774353
val: 12 0.39869415760040283
val: 13 0.4140537679195404
val: 14 0.40355366468429565
val: 15 0.4105859100818634
val: 16 0.3978405296802521
val: 17 0.39843448996543884
val: 18 0.40713468194007874
val: 19 0.4113359749317169
val: 20 0.40523892641067505
val_Epoch:[ 128 ] val_loss: 0.4067460000514984 2022-07-20 01:22:35.087810
start training 2022-07-20 01:22:35.188731
Epoch:[ 129 0 ] loss: 0.3623678386211395 2022-07-20 01:22:49.024869
Epoch:[ 129 1 ] loss: 0.3603699505329132 2022-07-20 01:22:49.440050
Epoch:[ 129 2 ] loss: 0.36110833287239075 2022-07-20 01:22:49.852463
Epoch:[ 129 3 ] loss: 0.36048653721809387 2022-07-20 01:22:50.266466
Epoch:[ 129 4 ] loss: 0.36009353399276733 2022-07-20 01:22:50.679719
Epoch:[ 129 5 ] loss: 0.36045417189598083 2022-07-20 01:22:51.097799
Epoch:[ 129 6 ] loss: 0.3607943654060364 2022-07-20 01:22:51.515253
Epoch:[ 129 7 ] loss: 0.36216551065444946 2022-07-20 01:22:51.929711
Epoch:[ 129 8 ] loss: 0.36033686995506287 2022-07-20 01:22:52.343542
Epoch:[ 129 9 ] loss: 0.36005350947380066 2022-07-20 01:22:52.756229
Epoch:[ 129 10 ] loss: 0.36279723048210144 2022-07-20 01:22:53.175438
Epoch:[ 129 11 ] loss: 0.3597344756126404 2022-07-20 01:22:53.589060
Epoch:[ 129 12 ] loss: 0.3617771863937378 2022-07-20 01:22:54.002643
Epoch:[ 129 13 ] loss: 0.3602285385131836 2022-07-20 01:22:54.418054
Epoch:[ 129 14 ] loss: 0.3604685068130493 2022-07-20 01:22:54.832019
Epoch:[ 129 15 ] loss: 0.3600936532020569 2022-07-20 01:22:55.246568
Epoch:[ 129 16 ] loss: 0.3591128885746002 2022-07-20 01:23:00.351668
Epoch:[ 129 17 ] loss: 0.3613804280757904 2022-07-20 01:23:00.764473
Epoch:[ 129 18 ] loss: 0.360792338848114 2022-07-20 01:23:01.184274
Epoch:[ 129 19 ] loss: 0.36098289489746094 2022-07-20 01:23:01.597888
Training_Epoch:[ 129 ] Training_loss: 0.3607799381017685 2022-07-20 01:23:01.598612
learning rate:  0.00014224175713617207
val: 1 0.4043117165565491
val: 2 0.39850711822509766
val: 3 0.4187665283679962
val: 4 0.4001346230506897
val: 5 0.41145724058151245
val: 6 0.40897807478904724
val: 7 0.41291287541389465
val: 8 0.4065331518650055
val: 9 0.42172446846961975
val: 10 0.41268375515937805
val: 11 0.4136780798435211
val: 12 0.4064343273639679
val: 13 0.4055929183959961
val: 14 0.4181928038597107
val: 15 0.4117296636104584
val: 16 0.41101446747779846
val: 17 0.3984909653663635
val: 18 0.41152384877204895
val: 19 0.4233151376247406
val: 20 0.41469380259513855
val_Epoch:[ 129 ] val_loss: 0.4105337783694267 2022-07-20 01:23:04.699265
start training 2022-07-20 01:23:04.802206
Epoch:[ 130 0 ] loss: 0.3591247498989105 2022-07-20 01:23:18.206022
Epoch:[ 130 1 ] loss: 0.35922595858573914 2022-07-20 01:23:18.843502
Epoch:[ 130 2 ] loss: 0.3600955605506897 2022-07-20 01:23:19.257467
Epoch:[ 130 3 ] loss: 0.36052942276000977 2022-07-20 01:23:19.670861
Epoch:[ 130 4 ] loss: 0.3610588312149048 2022-07-20 01:23:20.084036
Epoch:[ 130 5 ] loss: 0.3594109117984772 2022-07-20 01:23:20.496885
Epoch:[ 130 6 ] loss: 0.3594966232776642 2022-07-20 01:23:20.909826
Epoch:[ 130 7 ] loss: 0.3597484827041626 2022-07-20 01:23:21.327569
Epoch:[ 130 8 ] loss: 0.359674334526062 2022-07-20 01:23:21.742449
Epoch:[ 130 9 ] loss: 0.3605986535549164 2022-07-20 01:23:22.156473
Epoch:[ 130 10 ] loss: 0.36076271533966064 2022-07-20 01:23:22.570046
Epoch:[ 130 11 ] loss: 0.3606433868408203 2022-07-20 01:23:22.988674
Epoch:[ 130 12 ] loss: 0.360442191362381 2022-07-20 01:23:23.401502
Epoch:[ 130 13 ] loss: 0.3595488965511322 2022-07-20 01:23:23.814429
Epoch:[ 130 14 ] loss: 0.35918423533439636 2022-07-20 01:23:24.230102
Epoch:[ 130 15 ] loss: 0.36019590497016907 2022-07-20 01:23:24.644325
Epoch:[ 130 16 ] loss: 0.3618464171886444 2022-07-20 01:23:30.209774
Epoch:[ 130 17 ] loss: 0.36025241017341614 2022-07-20 01:23:30.622191
Epoch:[ 130 18 ] loss: 0.36039191484451294 2022-07-20 01:23:31.041571
Epoch:[ 130 19 ] loss: 0.3597562313079834 2022-07-20 01:23:31.461344
Training_Epoch:[ 130 ] Training_loss: 0.36009939163923266 2022-07-20 01:23:31.462051
learning rate:  0.00014224175713617207
netparams have been saved once 130
val: 1 0.40273159742355347
val: 2 0.4029732048511505
val: 3 0.413798063993454
val: 4 0.40778738260269165
val: 5 0.40629827976226807
val: 6 0.4026695787906647
val: 7 0.4052548110485077
val: 8 0.43051356077194214
val: 9 0.4050319194793701
val: 10 0.4065576195716858
val: 11 0.41608232259750366
val: 12 0.4168442487716675
val: 13 0.40779247879981995
val: 14 0.40466931462287903
val: 15 0.41631844639778137
val: 16 0.40957167744636536
val: 17 0.4091334044933319
val: 18 0.41346877813339233
val: 19 0.4058850407600403
val: 20 0.4050743281841278
val_Epoch:[ 130 ] val_loss: 0.40942280292510985 2022-07-20 01:23:34.654815
start training 2022-07-20 01:23:34.756407
Epoch:[ 131 0 ] loss: 0.35922712087631226 2022-07-20 01:23:48.478596
Epoch:[ 131 1 ] loss: 0.35961923003196716 2022-07-20 01:23:48.902816
Epoch:[ 131 2 ] loss: 0.3603847920894623 2022-07-20 01:23:49.316290
Epoch:[ 131 3 ] loss: 0.3595656752586365 2022-07-20 01:23:49.737133
Epoch:[ 131 4 ] loss: 0.3594464659690857 2022-07-20 01:23:50.149078
Epoch:[ 131 5 ] loss: 0.35892000794410706 2022-07-20 01:23:50.561525
Epoch:[ 131 6 ] loss: 0.35985198616981506 2022-07-20 01:23:50.981046
Epoch:[ 131 7 ] loss: 0.35921621322631836 2022-07-20 01:23:51.393986
Epoch:[ 131 8 ] loss: 0.36029624938964844 2022-07-20 01:23:51.806567
Epoch:[ 131 9 ] loss: 0.3598877787590027 2022-07-20 01:23:52.219921
Epoch:[ 131 10 ] loss: 0.3597884774208069 2022-07-20 01:23:52.633722
Epoch:[ 131 11 ] loss: 0.3598327934741974 2022-07-20 01:23:53.045958
Epoch:[ 131 12 ] loss: 0.3588324189186096 2022-07-20 01:23:53.457081
Epoch:[ 131 13 ] loss: 0.360007107257843 2022-07-20 01:23:53.875583
Epoch:[ 131 14 ] loss: 0.3596187233924866 2022-07-20 01:23:54.288665
Epoch:[ 131 15 ] loss: 0.3589342534542084 2022-07-20 01:23:54.701031
Epoch:[ 131 16 ] loss: 0.360017329454422 2022-07-20 01:24:00.058173
Epoch:[ 131 17 ] loss: 0.3600181043148041 2022-07-20 01:24:00.470498
Epoch:[ 131 18 ] loss: 0.36040198802948 2022-07-20 01:24:00.884832
Epoch:[ 131 19 ] loss: 0.3598937392234802 2022-07-20 01:24:01.303039
Training_Epoch:[ 131 ] Training_loss: 0.3596880227327347 2022-07-20 01:24:01.303679
learning rate:  0.00012090549356574625
val: 1 0.4090917706489563
val: 2 0.42209020256996155
val: 3 0.4103606939315796
val: 4 0.40772029757499695
val: 5 0.41858088970184326
val: 6 0.39379456639289856
val: 7 0.4009700417518616
val: 8 0.41148537397384644
val: 9 0.41626277565956116
val: 10 0.4120694696903229
val: 11 0.4115569591522217
val: 12 0.39947599172592163
val: 13 0.4103960692882538
val: 14 0.41785022616386414
val: 15 0.41853949427604675
val: 16 0.41406190395355225
val: 17 0.41320374608039856
val: 18 0.4022912085056305
val: 19 0.41682562232017517
val: 20 0.4208076596260071
val_Epoch:[ 131 ] val_loss: 0.411371748149395 2022-07-20 01:24:04.377041
start training 2022-07-20 01:24:04.479874
Epoch:[ 132 0 ] loss: 0.35993918776512146 2022-07-20 01:24:18.221540
Epoch:[ 132 1 ] loss: 0.35935333371162415 2022-07-20 01:24:18.635300
Epoch:[ 132 2 ] loss: 0.3597438931465149 2022-07-20 01:24:19.051440
Epoch:[ 132 3 ] loss: 0.3590724468231201 2022-07-20 01:24:19.465919
Epoch:[ 132 4 ] loss: 0.35990458726882935 2022-07-20 01:24:19.881554
Epoch:[ 132 5 ] loss: 0.35890865325927734 2022-07-20 01:24:20.294563
Epoch:[ 132 6 ] loss: 0.3618386387825012 2022-07-20 01:24:20.707633
Epoch:[ 132 7 ] loss: 0.3578847646713257 2022-07-20 01:24:21.120805
Epoch:[ 132 8 ] loss: 0.3595632314682007 2022-07-20 01:24:21.534960
Epoch:[ 132 9 ] loss: 0.3594339191913605 2022-07-20 01:24:21.952207
Epoch:[ 132 10 ] loss: 0.35878705978393555 2022-07-20 01:24:22.366266
Epoch:[ 132 11 ] loss: 0.3597154915332794 2022-07-20 01:24:22.785481
Epoch:[ 132 12 ] loss: 0.3595968782901764 2022-07-20 01:24:23.198886
Epoch:[ 132 13 ] loss: 0.3601054549217224 2022-07-20 01:24:23.617362
Epoch:[ 132 14 ] loss: 0.35875606536865234 2022-07-20 01:24:24.030951
Epoch:[ 132 15 ] loss: 0.359393835067749 2022-07-20 01:24:24.443735
Epoch:[ 132 16 ] loss: 0.36001408100128174 2022-07-20 01:24:29.869761
Epoch:[ 132 17 ] loss: 0.3609701097011566 2022-07-20 01:24:30.284014
Epoch:[ 132 18 ] loss: 0.36052414774894714 2022-07-20 01:24:30.705334
Epoch:[ 132 19 ] loss: 0.3616377115249634 2022-07-20 01:24:31.117488
Training_Epoch:[ 132 ] Training_loss: 0.359757174551487 2022-07-20 01:24:31.118175
learning rate:  0.00012090549356574625
netparams have been saved once 132
val: 1 0.40501827001571655
val: 2 0.4004538655281067
val: 3 0.39861005544662476
val: 4 0.40194323658943176
val: 5 0.4101048409938812
val: 6 0.39859554171562195
val: 7 0.4184500575065613
val: 8 0.39722827076911926
val: 9 0.4149807095527649
val: 10 0.41123244166374207
val: 11 0.40850529074668884
val: 12 0.4012320041656494
val: 13 0.4012737572193146
val: 14 0.40807995200157166
val: 15 0.4003586173057556
val: 16 0.4009978175163269
val: 17 0.4121965169906616
val: 18 0.40599900484085083
val: 19 0.40210455656051636
val: 20 0.4032924473285675
val_Epoch:[ 132 ] val_loss: 0.4050328627228737 2022-07-20 01:24:34.291735
start training 2022-07-20 01:24:34.395747
Epoch:[ 133 0 ] loss: 0.3602345883846283 2022-07-20 01:24:48.343894
Epoch:[ 133 1 ] loss: 0.35751503705978394 2022-07-20 01:24:48.757157
Epoch:[ 133 2 ] loss: 0.3600405156612396 2022-07-20 01:24:49.170654
Epoch:[ 133 3 ] loss: 0.35946422815322876 2022-07-20 01:24:49.583419
Epoch:[ 133 4 ] loss: 0.36008578538894653 2022-07-20 01:24:49.996349
Epoch:[ 133 5 ] loss: 0.3602597713470459 2022-07-20 01:24:50.418306
Epoch:[ 133 6 ] loss: 0.35925912857055664 2022-07-20 01:24:50.835053
Epoch:[ 133 7 ] loss: 0.3595931828022003 2022-07-20 01:24:51.249625
Epoch:[ 133 8 ] loss: 0.358545184135437 2022-07-20 01:24:51.663304
Epoch:[ 133 9 ] loss: 0.3588193953037262 2022-07-20 01:24:52.076880
Epoch:[ 133 10 ] loss: 0.3588396906852722 2022-07-20 01:24:52.489035
Epoch:[ 133 11 ] loss: 0.35988014936447144 2022-07-20 01:24:52.908418
Epoch:[ 133 12 ] loss: 0.3588566482067108 2022-07-20 01:24:53.322225
Epoch:[ 133 13 ] loss: 0.36039507389068604 2022-07-20 01:24:53.733783
Epoch:[ 133 14 ] loss: 0.35999900102615356 2022-07-20 01:24:54.151190
Epoch:[ 133 15 ] loss: 0.3592839241027832 2022-07-20 01:24:54.563823
Epoch:[ 133 16 ] loss: 0.35943853855133057 2022-07-20 01:24:59.663675
Epoch:[ 133 17 ] loss: 0.35895034670829773 2022-07-20 01:25:00.081686
Epoch:[ 133 18 ] loss: 0.3592184782028198 2022-07-20 01:25:00.498599
Epoch:[ 133 19 ] loss: 0.3590676188468933 2022-07-20 01:25:00.913652
Training_Epoch:[ 133 ] Training_loss: 0.3593873143196106 2022-07-20 01:25:00.914322
learning rate:  0.00012090549356574625
val: 1 0.4091530740261078
val: 2 0.41662833094596863
val: 3 0.40991246700286865
val: 4 0.4115484058856964
val: 5 0.4086107015609741
val: 6 0.41686558723449707
val: 7 0.4027116596698761
val: 8 0.40564000606536865
val: 9 0.4174952208995819
val: 10 0.4138457179069519
val: 11 0.3953607976436615
val: 12 0.41106879711151123
val: 13 0.39890483021736145
val: 14 0.41905519366264343
val: 15 0.4119873046875
val: 16 0.4165969789028168
val: 17 0.4134306311607361
val: 18 0.3955089747905731
val: 19 0.40740105509757996
val: 20 0.40522944927215576
val_Epoch:[ 133 ] val_loss: 0.40934775918722155 2022-07-20 01:25:04.045227
start training 2022-07-20 01:25:04.148946
Epoch:[ 134 0 ] loss: 0.3599868416786194 2022-07-20 01:25:18.386010
Epoch:[ 134 1 ] loss: 0.3601379692554474 2022-07-20 01:25:18.800705
Epoch:[ 134 2 ] loss: 0.3588009178638458 2022-07-20 01:25:19.219761
Epoch:[ 134 3 ] loss: 0.3586429953575134 2022-07-20 01:25:19.632856
Epoch:[ 134 4 ] loss: 0.3589050769805908 2022-07-20 01:25:20.045310
Epoch:[ 134 5 ] loss: 0.3583682179450989 2022-07-20 01:25:20.460512
Epoch:[ 134 6 ] loss: 0.3592124283313751 2022-07-20 01:25:20.877436
Epoch:[ 134 7 ] loss: 0.35928910970687866 2022-07-20 01:25:21.296597
Epoch:[ 134 8 ] loss: 0.35744404792785645 2022-07-20 01:25:21.709552
Epoch:[ 134 9 ] loss: 0.3589525818824768 2022-07-20 01:25:22.121714
Epoch:[ 134 10 ] loss: 0.35917928814888 2022-07-20 01:25:22.534945
Epoch:[ 134 11 ] loss: 0.3593165874481201 2022-07-20 01:25:22.947350
Epoch:[ 134 12 ] loss: 0.3596464693546295 2022-07-20 01:25:23.360524
Epoch:[ 134 13 ] loss: 0.35899850726127625 2022-07-20 01:25:23.775174
Epoch:[ 134 14 ] loss: 0.35939833521842957 2022-07-20 01:25:24.187578
Epoch:[ 134 15 ] loss: 0.35922372341156006 2022-07-20 01:25:24.602761
Epoch:[ 134 16 ] loss: 0.35890844464302063 2022-07-20 01:25:29.965143
Epoch:[ 134 17 ] loss: 0.35879626870155334 2022-07-20 01:25:30.376444
Epoch:[ 134 18 ] loss: 0.3586394488811493 2022-07-20 01:25:30.794139
Epoch:[ 134 19 ] loss: 0.3593613803386688 2022-07-20 01:25:31.213060
Training_Epoch:[ 134 ] Training_loss: 0.3590604320168495 2022-07-20 01:25:31.213746
learning rate:  0.00012090549356574625
netparams have been saved once 134
val: 1 0.4079137444496155
val: 2 0.40998199582099915
val: 3 0.40621253848075867
val: 4 0.4008372128009796
val: 5 0.4135291874408722
val: 6 0.40983617305755615
val: 7 0.4046800434589386
val: 8 0.4038306474685669
val: 9 0.4073179364204407
val: 10 0.4084738790988922
val: 11 0.4054095149040222
val: 12 0.4084327220916748
val: 13 0.40663889050483704
val: 14 0.4128837287425995
val: 15 0.42031624913215637
val: 16 0.3905470073223114
val: 17 0.42044708132743835
val: 18 0.40678948163986206
val: 19 0.41840383410453796
val: 20 0.4119499921798706
val_Epoch:[ 134 ] val_loss: 0.4087215930223465 2022-07-20 01:25:34.439760
start training 2022-07-20 01:25:34.542191
Epoch:[ 135 0 ] loss: 0.3583011329174042 2022-07-20 01:25:48.215659
Epoch:[ 135 1 ] loss: 0.3589293658733368 2022-07-20 01:25:48.646013
Epoch:[ 135 2 ] loss: 0.3596346974372864 2022-07-20 01:25:49.058135
Epoch:[ 135 3 ] loss: 0.35956868529319763 2022-07-20 01:25:49.472163
Epoch:[ 135 4 ] loss: 0.358075886964798 2022-07-20 01:25:49.891033
Epoch:[ 135 5 ] loss: 0.3590727746486664 2022-07-20 01:25:50.306254
Epoch:[ 135 6 ] loss: 0.3586048483848572 2022-07-20 01:25:50.721424
Epoch:[ 135 7 ] loss: 0.3589361310005188 2022-07-20 01:25:51.135462
Epoch:[ 135 8 ] loss: 0.3586350977420807 2022-07-20 01:25:51.550387
Epoch:[ 135 9 ] loss: 0.3594385087490082 2022-07-20 01:25:51.961532
Epoch:[ 135 10 ] loss: 0.3583621382713318 2022-07-20 01:25:52.375616
Epoch:[ 135 11 ] loss: 0.3597095012664795 2022-07-20 01:25:52.793826
Epoch:[ 135 12 ] loss: 0.3584783375263214 2022-07-20 01:25:53.207166
Epoch:[ 135 13 ] loss: 0.3582695424556732 2022-07-20 01:25:53.621076
Epoch:[ 135 14 ] loss: 0.3578755259513855 2022-07-20 01:25:54.036606
Epoch:[ 135 15 ] loss: 0.35920360684394836 2022-07-20 01:25:54.452195
Epoch:[ 135 16 ] loss: 0.35834598541259766 2022-07-20 01:25:59.786789
Epoch:[ 135 17 ] loss: 0.3583744466304779 2022-07-20 01:26:00.198329
Epoch:[ 135 18 ] loss: 0.35960206389427185 2022-07-20 01:26:00.618720
Epoch:[ 135 19 ] loss: 0.35862675309181213 2022-07-20 01:26:01.033801
Training_Epoch:[ 135 ] Training_loss: 0.3588022515177727 2022-07-20 01:26:01.034492
learning rate:  0.00012090549356574625
val: 1 0.41794633865356445
val: 2 0.411138653755188
val: 3 0.4025844931602478
val: 4 0.39989492297172546
val: 5 0.40734580159187317
val: 6 0.41394081711769104
val: 7 0.4032462537288666
val: 8 0.40953341126441956
val: 9 0.4088466763496399
val: 10 0.41015222668647766
val: 11 0.41309118270874023
val: 12 0.41025054454803467
val: 13 0.4250525236129761
val: 14 0.4010774791240692
val: 15 0.40946507453918457
val: 16 0.4096091687679291
val: 17 0.40681880712509155
val: 18 0.41814693808555603
val: 19 0.4161643981933594
val: 20 0.40666040778160095
val_Epoch:[ 135 ] val_loss: 0.41004830598831177 2022-07-20 01:26:04.152541
start training 2022-07-20 01:26:04.256175
Epoch:[ 136 0 ] loss: 0.3594163656234741 2022-07-20 01:26:17.612288
Epoch:[ 136 1 ] loss: 0.35848382115364075 2022-07-20 01:26:18.484944
Epoch:[ 136 2 ] loss: 0.35780617594718933 2022-07-20 01:26:18.896851
Epoch:[ 136 3 ] loss: 0.3585937023162842 2022-07-20 01:26:19.308294
Epoch:[ 136 4 ] loss: 0.35933589935302734 2022-07-20 01:26:19.721300
Epoch:[ 136 5 ] loss: 0.3586936295032501 2022-07-20 01:26:20.133890
Epoch:[ 136 6 ] loss: 0.35794803500175476 2022-07-20 01:26:20.546472
Epoch:[ 136 7 ] loss: 0.3584211766719818 2022-07-20 01:26:20.965916
Epoch:[ 136 8 ] loss: 0.3582504987716675 2022-07-20 01:26:21.379058
Epoch:[ 136 9 ] loss: 0.35874098539352417 2022-07-20 01:26:21.793264
Epoch:[ 136 10 ] loss: 0.3577318787574768 2022-07-20 01:26:22.207552
Epoch:[ 136 11 ] loss: 0.3584405481815338 2022-07-20 01:26:22.621489
Epoch:[ 136 12 ] loss: 0.35876354575157166 2022-07-20 01:26:23.034222
Epoch:[ 136 13 ] loss: 0.35859113931655884 2022-07-20 01:26:23.446216
Epoch:[ 136 14 ] loss: 0.3579588532447815 2022-07-20 01:26:23.865477
Epoch:[ 136 15 ] loss: 0.3581150472164154 2022-07-20 01:26:24.280801
Epoch:[ 136 16 ] loss: 0.3588685691356659 2022-07-20 01:26:29.533504
Epoch:[ 136 17 ] loss: 0.357460081577301 2022-07-20 01:26:29.946304
Epoch:[ 136 18 ] loss: 0.3584980070590973 2022-07-20 01:26:30.365391
Epoch:[ 136 19 ] loss: 0.3595162332057953 2022-07-20 01:26:30.777825
Training_Epoch:[ 136 ] Training_loss: 0.3584817096590996 2022-07-20 01:26:30.778456
learning rate:  0.00012090549356574625
netparams have been saved once 136
val: 1 0.4171752333641052
val: 2 0.40465569496154785
val: 3 0.41051971912384033
val: 4 0.4092106819152832
val: 5 0.4040200114250183
val: 6 0.40590351819992065
val: 7 0.41389262676239014
val: 8 0.4113273620605469
val: 9 0.3979070484638214
val: 10 0.41225916147232056
val: 11 0.40502649545669556
val: 12 0.41336384415626526
val: 13 0.4001915752887726
val: 14 0.4026283621788025
val: 15 0.4184708893299103
val: 16 0.3971640467643738
val: 17 0.4089832901954651
val: 18 0.4157581031322479
val: 19 0.4045858681201935
val: 20 0.4099557399749756
val_Epoch:[ 136 ] val_loss: 0.4081499636173248 2022-07-20 01:26:34.014167
start training 2022-07-20 01:26:34.121117
Epoch:[ 137 0 ] loss: 0.3568848669528961 2022-07-20 01:26:48.364368
Epoch:[ 137 1 ] loss: 0.3579675853252411 2022-07-20 01:26:48.780296
Epoch:[ 137 2 ] loss: 0.35775017738342285 2022-07-20 01:26:49.194039
Epoch:[ 137 3 ] loss: 0.35872671008110046 2022-07-20 01:26:49.612062
Epoch:[ 137 4 ] loss: 0.35758131742477417 2022-07-20 01:26:50.023955
Epoch:[ 137 5 ] loss: 0.35935211181640625 2022-07-20 01:26:50.436885
Epoch:[ 137 6 ] loss: 0.35806649923324585 2022-07-20 01:26:50.855414
Epoch:[ 137 7 ] loss: 0.3579169809818268 2022-07-20 01:26:51.270568
Epoch:[ 137 8 ] loss: 0.35856497287750244 2022-07-20 01:26:51.685105
Epoch:[ 137 9 ] loss: 0.3582465648651123 2022-07-20 01:26:52.101098
Epoch:[ 137 10 ] loss: 0.36048510670661926 2022-07-20 01:26:52.517391
Epoch:[ 137 11 ] loss: 0.3590940237045288 2022-07-20 01:26:52.930392
Epoch:[ 137 12 ] loss: 0.3571920692920685 2022-07-20 01:26:53.342694
Epoch:[ 137 13 ] loss: 0.35749194025993347 2022-07-20 01:26:53.757293
Epoch:[ 137 14 ] loss: 0.3588551878929138 2022-07-20 01:26:54.170824
Epoch:[ 137 15 ] loss: 0.3588651120662689 2022-07-20 01:26:54.586265
Epoch:[ 137 16 ] loss: 0.35747355222702026 2022-07-20 01:26:59.686433
Epoch:[ 137 17 ] loss: 0.3571160137653351 2022-07-20 01:27:00.106574
Epoch:[ 137 18 ] loss: 0.3587509095668793 2022-07-20 01:27:00.523276
Epoch:[ 137 19 ] loss: 0.35904067754745483 2022-07-20 01:27:00.942119
Training_Epoch:[ 137 ] Training_loss: 0.35827111899852754 2022-07-20 01:27:00.942724
learning rate:  0.00012090549356574625
val: 1 0.40689215064048767
val: 2 0.4134051203727722
val: 3 0.4036845564842224
val: 4 0.4033893644809723
val: 5 0.42208918929100037
val: 6 0.4213373064994812
val: 7 0.4046214818954468
val: 8 0.41037362813949585
val: 9 0.4082205295562744
val: 10 0.42120659351348877
val: 11 0.40941768884658813
val: 12 0.4042667746543884
val: 13 0.4195101857185364
val: 14 0.4042026698589325
val: 15 0.40803709626197815
val: 16 0.40962785482406616
val: 17 0.42423221468925476
val: 18 0.4066336452960968
val: 19 0.4060083031654358
val: 20 0.4157903492450714
val_Epoch:[ 137 ] val_loss: 0.41114733517169955 2022-07-20 01:27:04.136961
start training 2022-07-20 01:27:04.241908
Epoch:[ 138 0 ] loss: 0.3588789999485016 2022-07-20 01:27:17.660738
Epoch:[ 138 1 ] loss: 0.3593628406524658 2022-07-20 01:27:18.213053
Epoch:[ 138 2 ] loss: 0.3573669195175171 2022-07-20 01:27:18.627715
Epoch:[ 138 3 ] loss: 0.3586535155773163 2022-07-20 01:27:19.042570
Epoch:[ 138 4 ] loss: 0.35768041014671326 2022-07-20 01:27:19.455138
Epoch:[ 138 5 ] loss: 0.3584067225456238 2022-07-20 01:27:19.871601
Epoch:[ 138 6 ] loss: 0.3572871685028076 2022-07-20 01:27:20.284007
Epoch:[ 138 7 ] loss: 0.3576824367046356 2022-07-20 01:27:20.698787
Epoch:[ 138 8 ] loss: 0.3570442795753479 2022-07-20 01:27:21.110825
Epoch:[ 138 9 ] loss: 0.3576693534851074 2022-07-20 01:27:21.525043
Epoch:[ 138 10 ] loss: 0.35732489824295044 2022-07-20 01:27:21.943306
Epoch:[ 138 11 ] loss: 0.35838064551353455 2022-07-20 01:27:22.357051
Epoch:[ 138 12 ] loss: 0.35844695568084717 2022-07-20 01:27:22.768572
Epoch:[ 138 13 ] loss: 0.3581922948360443 2022-07-20 01:27:23.182347
Epoch:[ 138 14 ] loss: 0.3577243983745575 2022-07-20 01:27:23.595701
Epoch:[ 138 15 ] loss: 0.3584008514881134 2022-07-20 01:27:24.008371
Epoch:[ 138 16 ] loss: 0.35903406143188477 2022-07-20 01:27:29.417522
Epoch:[ 138 17 ] loss: 0.3577287197113037 2022-07-20 01:27:29.831974
Epoch:[ 138 18 ] loss: 0.3575599789619446 2022-07-20 01:27:30.253846
Epoch:[ 138 19 ] loss: 0.3578661382198334 2022-07-20 01:27:30.668468
Training_Epoch:[ 138 ] Training_loss: 0.3580345794558525 2022-07-20 01:27:30.669162
learning rate:  0.00012090549356574625
netparams have been saved once 138
val: 1 0.40984153747558594
val: 2 0.4104037582874298
val: 3 0.4123549461364746
val: 4 0.4102153480052948
val: 5 0.40106818079948425
val: 6 0.4136940836906433
val: 7 0.4054275453090668
val: 8 0.40190383791923523
val: 9 0.41517388820648193
val: 10 0.41326746344566345
val: 11 0.41158685088157654
val: 12 0.4174477458000183
val: 13 0.40956270694732666
val: 14 0.40409255027770996
val: 15 0.41019394993782043
val: 16 0.40335407853126526
val: 17 0.40702131390571594
val: 18 0.4178431034088135
val: 19 0.4115559160709381
val: 20 0.4092480540275574
val_Epoch:[ 138 ] val_loss: 0.4097628429532051 2022-07-20 01:27:33.833282
start training 2022-07-20 01:27:33.938560
Epoch:[ 139 0 ] loss: 0.3577021658420563 2022-07-20 01:27:47.771043
Epoch:[ 139 1 ] loss: 0.3576148450374603 2022-07-20 01:27:48.184459
Epoch:[ 139 2 ] loss: 0.35655272006988525 2022-07-20 01:27:48.597355
Epoch:[ 139 3 ] loss: 0.3564230501651764 2022-07-20 01:27:49.012452
Epoch:[ 139 4 ] loss: 0.35735201835632324 2022-07-20 01:27:49.426819
Epoch:[ 139 5 ] loss: 0.35827791690826416 2022-07-20 01:27:49.838096
Epoch:[ 139 6 ] loss: 0.3581594228744507 2022-07-20 01:27:50.254509
Epoch:[ 139 7 ] loss: 0.35715705156326294 2022-07-20 01:27:50.672344
Epoch:[ 139 8 ] loss: 0.3570384681224823 2022-07-20 01:27:51.084815
Epoch:[ 139 9 ] loss: 0.3578673303127289 2022-07-20 01:27:51.499663
Epoch:[ 139 10 ] loss: 0.3573383688926697 2022-07-20 01:27:51.914390
Epoch:[ 139 11 ] loss: 0.3587355315685272 2022-07-20 01:27:52.335712
Epoch:[ 139 12 ] loss: 0.35725337266921997 2022-07-20 01:27:52.748422
Epoch:[ 139 13 ] loss: 0.35809287428855896 2022-07-20 01:27:53.160741
Epoch:[ 139 14 ] loss: 0.35840651392936707 2022-07-20 01:27:53.579629
Epoch:[ 139 15 ] loss: 0.35847383737564087 2022-07-20 01:27:53.993384
Epoch:[ 139 16 ] loss: 0.35972848534584045 2022-07-20 01:27:59.338373
Epoch:[ 139 17 ] loss: 0.35892921686172485 2022-07-20 01:27:59.756900
Epoch:[ 139 18 ] loss: 0.3582446575164795 2022-07-20 01:28:00.177105
Epoch:[ 139 19 ] loss: 0.3588586449623108 2022-07-20 01:28:00.588535
Training_Epoch:[ 139 ] Training_loss: 0.3579103246331215 2022-07-20 01:28:00.589282
learning rate:  0.00012090549356574625
val: 1 0.409717857837677
val: 2 0.406711220741272
val: 3 0.41870924830436707
val: 4 0.40855419635772705
val: 5 0.41175296902656555
val: 6 0.4096764624118805
val: 7 0.3957127034664154
val: 8 0.41254958510398865
val: 9 0.41559767723083496
val: 10 0.4054394066333771
val: 11 0.4215043783187866
val: 12 0.4030267000198364
val: 13 0.4050809144973755
val: 14 0.4066883623600006
val: 15 0.39979881048202515
val: 16 0.404950350522995
val: 17 0.4117969870567322
val: 18 0.4094836115837097
val: 19 0.40267065167427063
val: 20 0.3956671357154846
val_Epoch:[ 139 ] val_loss: 0.40775446146726607 2022-07-20 01:28:03.711565
start training 2022-07-20 01:28:03.816580
Epoch:[ 140 0 ] loss: 0.3572671413421631 2022-07-20 01:28:17.251089
Epoch:[ 140 1 ] loss: 0.3582903742790222 2022-07-20 01:28:17.677222
Epoch:[ 140 2 ] loss: 0.35567888617515564 2022-07-20 01:28:18.090808
Epoch:[ 140 3 ] loss: 0.35828572511672974 2022-07-20 01:28:18.504701
Epoch:[ 140 4 ] loss: 0.35794293880462646 2022-07-20 01:28:18.919028
Epoch:[ 140 5 ] loss: 0.35791951417922974 2022-07-20 01:28:19.333558
Epoch:[ 140 6 ] loss: 0.35757026076316833 2022-07-20 01:28:19.746867
Epoch:[ 140 7 ] loss: 0.3573051989078522 2022-07-20 01:28:20.158537
Epoch:[ 140 8 ] loss: 0.35782143473625183 2022-07-20 01:28:20.572215
Epoch:[ 140 9 ] loss: 0.358032763004303 2022-07-20 01:28:20.985387
Epoch:[ 140 10 ] loss: 0.3561154305934906 2022-07-20 01:28:21.406490
Epoch:[ 140 11 ] loss: 0.357250452041626 2022-07-20 01:28:21.821986
Epoch:[ 140 12 ] loss: 0.3578554391860962 2022-07-20 01:28:22.237323
Epoch:[ 140 13 ] loss: 0.3581675887107849 2022-07-20 01:28:22.651354
Epoch:[ 140 14 ] loss: 0.3572824001312256 2022-07-20 01:28:23.069120
Epoch:[ 140 15 ] loss: 0.35890325903892517 2022-07-20 01:28:23.482013
Epoch:[ 140 16 ] loss: 0.35898110270500183 2022-07-20 01:28:29.094515
Epoch:[ 140 17 ] loss: 0.358216255903244 2022-07-20 01:28:29.511184
Epoch:[ 140 18 ] loss: 0.35807615518569946 2022-07-20 01:28:29.926968
Epoch:[ 140 19 ] loss: 0.3588956594467163 2022-07-20 01:28:30.345390
Training_Epoch:[ 140 ] Training_loss: 0.3577928990125656 2022-07-20 01:28:30.345999
learning rate:  0.00012090549356574625
netparams have been saved once 140
val: 1 0.40801748633384705
val: 2 0.404294490814209
val: 3 0.3991839289665222
val: 4 0.42348700761795044
val: 5 0.41552379727363586
val: 6 0.40969574451446533
val: 7 0.4087059497833252
val: 8 0.41163474321365356
val: 9 0.40041571855545044
val: 10 0.4174363315105438
val: 11 0.4124336242675781
val: 12 0.41519904136657715
val: 13 0.4125320315361023
val: 14 0.4138622581958771
val: 15 0.415242999792099
val: 16 0.410234272480011
val: 17 0.40473106503486633
val: 18 0.4033183455467224
val: 19 0.41190558671951294
val: 20 0.4187135696411133
val_Epoch:[ 140 ] val_loss: 0.4108283996582031 2022-07-20 01:28:33.537584
start training 2022-07-20 01:28:33.641900
Epoch:[ 141 0 ] loss: 0.35732895135879517 2022-07-20 01:28:46.986448
Epoch:[ 141 1 ] loss: 0.3575623631477356 2022-07-20 01:28:47.400640
Epoch:[ 141 2 ] loss: 0.356659471988678 2022-07-20 01:28:47.820474
Epoch:[ 141 3 ] loss: 0.3565920889377594 2022-07-20 01:28:48.233132
Epoch:[ 141 4 ] loss: 0.3582071363925934 2022-07-20 01:28:48.651706
Epoch:[ 141 5 ] loss: 0.35863277316093445 2022-07-20 01:28:49.065244
Epoch:[ 141 6 ] loss: 0.35619911551475525 2022-07-20 01:28:49.480691
Epoch:[ 141 7 ] loss: 0.3572169542312622 2022-07-20 01:28:49.893103
Epoch:[ 141 8 ] loss: 0.3568307161331177 2022-07-20 01:28:50.304554
Epoch:[ 141 9 ] loss: 0.3564310371875763 2022-07-20 01:28:50.716061
Epoch:[ 141 10 ] loss: 0.35724738240242004 2022-07-20 01:28:51.129176
Epoch:[ 141 11 ] loss: 0.3586263954639435 2022-07-20 01:28:51.544342
Epoch:[ 141 12 ] loss: 0.35710573196411133 2022-07-20 01:28:51.958070
Epoch:[ 141 13 ] loss: 0.35795527696609497 2022-07-20 01:28:52.372825
Epoch:[ 141 14 ] loss: 0.35650745034217834 2022-07-20 01:28:52.784959
Epoch:[ 141 15 ] loss: 0.3576086461544037 2022-07-20 01:28:53.199255
Epoch:[ 141 16 ] loss: 0.3577553629875183 2022-07-20 01:28:58.905393
Epoch:[ 141 17 ] loss: 0.35667684674263 2022-07-20 01:28:59.323215
Epoch:[ 141 18 ] loss: 0.35812175273895264 2022-07-20 01:28:59.741533
Epoch:[ 141 19 ] loss: 0.35821229219436646 2022-07-20 01:29:00.156266
Training_Epoch:[ 141 ] Training_loss: 0.35737388730049136 2022-07-20 01:29:00.156932
learning rate:  0.00010276966953088431
val: 1 0.4153183102607727
val: 2 0.4049910008907318
val: 3 0.3940289616584778
val: 4 0.40411052107810974
val: 5 0.4120524227619171
val: 6 0.41724833846092224
val: 7 0.41008272767066956
val: 8 0.40839335322380066
val: 9 0.40739530324935913
val: 10 0.41511502861976624
val: 11 0.4053992033004761
val: 12 0.40908557176589966
val: 13 0.41049298644065857
val: 14 0.41966745257377625
val: 15 0.4102810025215149
val: 16 0.4101814031600952
val: 17 0.40525659918785095
val: 18 0.4124356210231781
val: 19 0.4029959738254547
val: 20 0.405803382396698
val_Epoch:[ 141 ] val_loss: 0.40901675820350647 2022-07-20 01:29:03.213501
start training 2022-07-20 01:29:03.321861
Epoch:[ 142 0 ] loss: 0.35741475224494934 2022-07-20 01:29:16.630627
Epoch:[ 142 1 ] loss: 0.35706666111946106 2022-07-20 01:29:17.059208
Epoch:[ 142 2 ] loss: 0.35693076252937317 2022-07-20 01:29:17.473493
Epoch:[ 142 3 ] loss: 0.35598286986351013 2022-07-20 01:29:17.885652
Epoch:[ 142 4 ] loss: 0.357774555683136 2022-07-20 01:29:18.298640
Epoch:[ 142 5 ] loss: 0.35694819688796997 2022-07-20 01:29:18.711323
Epoch:[ 142 6 ] loss: 0.3573848009109497 2022-07-20 01:29:19.125982
Epoch:[ 142 7 ] loss: 0.35673046112060547 2022-07-20 01:29:19.540189
Epoch:[ 142 8 ] loss: 0.35789617896080017 2022-07-20 01:29:19.953767
Epoch:[ 142 9 ] loss: 0.35888996720314026 2022-07-20 01:29:20.368595
Epoch:[ 142 10 ] loss: 0.35680028796195984 2022-07-20 01:29:20.789419
Epoch:[ 142 11 ] loss: 0.3572757840156555 2022-07-20 01:29:21.202474
Epoch:[ 142 12 ] loss: 0.35804176330566406 2022-07-20 01:29:21.621956
Epoch:[ 142 13 ] loss: 0.3592270612716675 2022-07-20 01:29:22.035502
Epoch:[ 142 14 ] loss: 0.35769158601760864 2022-07-20 01:29:22.450837
Epoch:[ 142 15 ] loss: 0.3575243651866913 2022-07-20 01:29:22.864775
Epoch:[ 142 16 ] loss: 0.3584953844547272 2022-07-20 01:29:28.247326
Epoch:[ 142 17 ] loss: 0.357818603515625 2022-07-20 01:29:28.667055
Epoch:[ 142 18 ] loss: 0.35803359746932983 2022-07-20 01:29:29.081047
Epoch:[ 142 19 ] loss: 0.35685110092163086 2022-07-20 01:29:29.493239
Training_Epoch:[ 142 ] Training_loss: 0.3575389370322227 2022-07-20 01:29:29.493888
learning rate:  0.00010276966953088431
netparams have been saved once 142
val: 1 0.4133676588535309
val: 2 0.40088003873825073
val: 3 0.41708436608314514
val: 4 0.4205426871776581
val: 5 0.4156976044178009
val: 6 0.4112309515476227
val: 7 0.4043850004673004
val: 8 0.414571613073349
val: 9 0.4147995114326477
val: 10 0.41197526454925537
val: 11 0.4096168875694275
val: 12 0.41362711787223816
val: 13 0.40810245275497437
val: 14 0.4165867865085602
val: 15 0.41788557171821594
val: 16 0.41441765427589417
val: 17 0.400935560464859
val: 18 0.4182050824165344
val: 19 0.41755369305610657
val: 20 0.406545490026474
val_Epoch:[ 142 ] val_loss: 0.41240054965019224 2022-07-20 01:29:32.623535
start training 2022-07-20 01:29:32.729341
Epoch:[ 143 0 ] loss: 0.3575054705142975 2022-07-20 01:29:46.467537
Epoch:[ 143 1 ] loss: 0.35713517665863037 2022-07-20 01:29:46.880483
Epoch:[ 143 2 ] loss: 0.3562166392803192 2022-07-20 01:29:47.299063
Epoch:[ 143 3 ] loss: 0.35634270310401917 2022-07-20 01:29:47.718456
Epoch:[ 143 4 ] loss: 0.35672780871391296 2022-07-20 01:29:48.131128
Epoch:[ 143 5 ] loss: 0.3579758405685425 2022-07-20 01:29:48.544078
Epoch:[ 143 6 ] loss: 0.35696905851364136 2022-07-20 01:29:48.958665
Epoch:[ 143 7 ] loss: 0.35712844133377075 2022-07-20 01:29:49.373691
Epoch:[ 143 8 ] loss: 0.35591813921928406 2022-07-20 01:29:49.787250
Epoch:[ 143 9 ] loss: 0.3571343421936035 2022-07-20 01:29:50.200785
Epoch:[ 143 10 ] loss: 0.3569774031639099 2022-07-20 01:29:50.613686
Epoch:[ 143 11 ] loss: 0.35702744126319885 2022-07-20 01:29:51.028163
Epoch:[ 143 12 ] loss: 0.3562406897544861 2022-07-20 01:29:51.441365
Epoch:[ 143 13 ] loss: 0.35723215341567993 2022-07-20 01:29:51.860624
Epoch:[ 143 14 ] loss: 0.3574928641319275 2022-07-20 01:29:52.276609
Epoch:[ 143 15 ] loss: 0.35741478204727173 2022-07-20 01:29:52.690980
Epoch:[ 143 16 ] loss: 0.35781264305114746 2022-07-20 01:29:58.212288
Epoch:[ 143 17 ] loss: 0.3579198718070984 2022-07-20 01:29:58.623207
Epoch:[ 143 18 ] loss: 0.35694143176078796 2022-07-20 01:29:59.042333
Epoch:[ 143 19 ] loss: 0.3568078577518463 2022-07-20 01:29:59.461267
Training_Epoch:[ 143 ] Training_loss: 0.3570460379123688 2022-07-20 01:29:59.461918
learning rate:  0.00010276966953088431
val: 1 0.41180506348609924
val: 2 0.4139792323112488
val: 3 0.40884003043174744
val: 4 0.4107896685600281
val: 5 0.41631731390953064
val: 6 0.41691866517066956
val: 7 0.4141894280910492
val: 8 0.4131709635257721
val: 9 0.40353548526763916
val: 10 0.4100024402141571
val: 11 0.40689897537231445
val: 12 0.40960678458213806
val: 13 0.41519683599472046
val: 14 0.41141122579574585
val: 15 0.403251975774765
val: 16 0.423470675945282
val: 17 0.4103243947029114
val: 18 0.42208462953567505
val: 19 0.40032991766929626
val: 20 0.40728896856307983
val_Epoch:[ 143 ] val_loss: 0.4114706337451935 2022-07-20 01:30:02.566899
start training 2022-07-20 01:30:02.672018
Epoch:[ 144 0 ] loss: 0.3557664453983307 2022-07-20 01:30:16.350021
Epoch:[ 144 1 ] loss: 0.3569442629814148 2022-07-20 01:30:16.822334
Epoch:[ 144 2 ] loss: 0.355637788772583 2022-07-20 01:30:17.237272
Epoch:[ 144 3 ] loss: 0.3568425178527832 2022-07-20 01:30:17.651838
Epoch:[ 144 4 ] loss: 0.3567126989364624 2022-07-20 01:30:18.065016
Epoch:[ 144 5 ] loss: 0.35874059796333313 2022-07-20 01:30:18.476999
Epoch:[ 144 6 ] loss: 0.35714656114578247 2022-07-20 01:30:18.884568
Epoch:[ 144 7 ] loss: 0.3565715253353119 2022-07-20 01:30:19.297228
Epoch:[ 144 8 ] loss: 0.35841941833496094 2022-07-20 01:30:19.710429
Epoch:[ 144 9 ] loss: 0.35680365562438965 2022-07-20 01:30:20.123458
Epoch:[ 144 10 ] loss: 0.35718268156051636 2022-07-20 01:30:20.536534
Epoch:[ 144 11 ] loss: 0.3572808802127838 2022-07-20 01:30:20.948660
Epoch:[ 144 12 ] loss: 0.3567720055580139 2022-07-20 01:30:21.361821
Epoch:[ 144 13 ] loss: 0.3582988381385803 2022-07-20 01:30:21.774148
Epoch:[ 144 14 ] loss: 0.35794126987457275 2022-07-20 01:30:22.188585
Epoch:[ 144 15 ] loss: 0.3576277494430542 2022-07-20 01:30:22.603138
Epoch:[ 144 16 ] loss: 0.35673609375953674 2022-07-20 01:30:28.396014
Epoch:[ 144 17 ] loss: 0.3578793704509735 2022-07-20 01:30:28.808357
Epoch:[ 144 18 ] loss: 0.3578254282474518 2022-07-20 01:30:29.224712
Epoch:[ 144 19 ] loss: 0.357957661151886 2022-07-20 01:30:29.642921
Training_Epoch:[ 144 ] Training_loss: 0.3572543725371361 2022-07-20 01:30:29.643680
learning rate:  0.00010276966953088431
netparams have been saved once 144
val: 1 0.41013965010643005
val: 2 0.4068436324596405
val: 3 0.4120733141899109
val: 4 0.40659382939338684
val: 5 0.4029143452644348
val: 6 0.40963059663772583
val: 7 0.4086383879184723
val: 8 0.40945494174957275
val: 9 0.41261330246925354
val: 10 0.4085894227027893
val: 11 0.4132610261440277
val: 12 0.4074239730834961
val: 13 0.41940903663635254
val: 14 0.4151470959186554
val: 15 0.41081172227859497
val: 16 0.40700554847717285
val: 17 0.4073677957057953
val: 18 0.4122440218925476
val: 19 0.4205821454524994
val: 20 0.40873852372169495
val_Epoch:[ 144 ] val_loss: 0.4104741156101227 2022-07-20 01:30:32.919461
start training 2022-07-20 01:30:33.029813
Epoch:[ 145 0 ] loss: 0.35826602578163147 2022-07-20 01:30:47.457621
Epoch:[ 145 1 ] loss: 0.35742664337158203 2022-07-20 01:30:47.871274
Epoch:[ 145 2 ] loss: 0.35703879594802856 2022-07-20 01:30:48.286539
Epoch:[ 145 3 ] loss: 0.35744133591651917 2022-07-20 01:30:48.703675
Epoch:[ 145 4 ] loss: 0.3569997549057007 2022-07-20 01:30:49.115437
Epoch:[ 145 5 ] loss: 0.3575519323348999 2022-07-20 01:30:49.523266
Epoch:[ 145 6 ] loss: 0.35713478922843933 2022-07-20 01:30:49.933577
Epoch:[ 145 7 ] loss: 0.35674312710762024 2022-07-20 01:30:50.346173
Epoch:[ 145 8 ] loss: 0.3557978570461273 2022-07-20 01:30:50.759347
Epoch:[ 145 9 ] loss: 0.3581310510635376 2022-07-20 01:30:51.173731
Epoch:[ 145 10 ] loss: 0.35592299699783325 2022-07-20 01:30:51.588083
Epoch:[ 145 11 ] loss: 0.3557656407356262 2022-07-20 01:30:52.000245
Epoch:[ 145 12 ] loss: 0.3566148579120636 2022-07-20 01:30:52.411681
Epoch:[ 145 13 ] loss: 0.3579396903514862 2022-07-20 01:30:52.825547
Epoch:[ 145 14 ] loss: 0.35632213950157166 2022-07-20 01:30:53.238669
Epoch:[ 145 15 ] loss: 0.35683056712150574 2022-07-20 01:30:53.654106
Epoch:[ 145 16 ] loss: 0.3568270206451416 2022-07-20 01:30:59.298281
Epoch:[ 145 17 ] loss: 0.35791483521461487 2022-07-20 01:30:59.712950
Epoch:[ 145 18 ] loss: 0.3564893901348114 2022-07-20 01:31:00.123831
Epoch:[ 145 19 ] loss: 0.3566446602344513 2022-07-20 01:31:00.532486
Training_Epoch:[ 145 ] Training_loss: 0.3569901555776596 2022-07-20 01:31:00.533254
learning rate:  0.00010276966953088431
val: 1 0.41147348284721375
val: 2 0.3943563401699066
val: 3 0.40950530767440796
val: 4 0.413856565952301
val: 5 0.4014342725276947
val: 6 0.4063844084739685
val: 7 0.40741845965385437
val: 8 0.40573519468307495
val: 9 0.40781068801879883
val: 10 0.4199414551258087
val: 11 0.40001338720321655
val: 12 0.4097289443016052
val: 13 0.40403589606285095
val: 14 0.4071986675262451
val: 15 0.40355384349823
val: 16 0.41350802779197693
val: 17 0.40006089210510254
val: 18 0.41289228200912476
val: 19 0.40709230303764343
val: 20 0.4065614938735962
val_Epoch:[ 145 ] val_loss: 0.40712809562683105 2022-07-20 01:31:03.750083
start training 2022-07-20 01:31:03.863411
Epoch:[ 146 0 ] loss: 0.3561619222164154 2022-07-20 01:31:17.795006
Epoch:[ 146 1 ] loss: 0.3569638133049011 2022-07-20 01:31:18.219453
Epoch:[ 146 2 ] loss: 0.3566255569458008 2022-07-20 01:31:18.635411
Epoch:[ 146 3 ] loss: 0.3568655550479889 2022-07-20 01:31:19.051672
Epoch:[ 146 4 ] loss: 0.3573341965675354 2022-07-20 01:31:19.462638
Epoch:[ 146 5 ] loss: 0.3573169708251953 2022-07-20 01:31:19.875930
Epoch:[ 146 6 ] loss: 0.35674363374710083 2022-07-20 01:31:20.289488
Epoch:[ 146 7 ] loss: 0.35654887557029724 2022-07-20 01:31:20.703416
Epoch:[ 146 8 ] loss: 0.3570746183395386 2022-07-20 01:31:21.117151
Epoch:[ 146 9 ] loss: 0.35616400837898254 2022-07-20 01:31:21.529431
Epoch:[ 146 10 ] loss: 0.3574114739894867 2022-07-20 01:31:21.945934
Epoch:[ 146 11 ] loss: 0.35684850811958313 2022-07-20 01:31:22.360619
Epoch:[ 146 12 ] loss: 0.3570868968963623 2022-07-20 01:31:22.773806
Epoch:[ 146 13 ] loss: 0.358010858297348 2022-07-20 01:31:23.189855
Epoch:[ 146 14 ] loss: 0.35758236050605774 2022-07-20 01:31:23.604857
Epoch:[ 146 15 ] loss: 0.3580407202243805 2022-07-20 01:31:24.014497
Epoch:[ 146 16 ] loss: 0.3579208552837372 2022-07-20 01:31:29.228651
Epoch:[ 146 17 ] loss: 0.3566727340221405 2022-07-20 01:31:29.646549
Epoch:[ 146 18 ] loss: 0.3576284646987915 2022-07-20 01:31:30.068950
Epoch:[ 146 19 ] loss: 0.3567333221435547 2022-07-20 01:31:30.482285
Training_Epoch:[ 146 ] Training_loss: 0.35708676725625993 2022-07-20 01:31:30.483208
learning rate:  0.00010276966953088431
netparams have been saved once 146
val: 1 0.4248533844947815
val: 2 0.40426701307296753
val: 3 0.40618085861206055
val: 4 0.39962276816368103
val: 5 0.4025903344154358
val: 6 0.41867923736572266
val: 7 0.40936747193336487
val: 8 0.41526538133621216
val: 9 0.4140176475048065
val: 10 0.41588735580444336
val: 11 0.4107041358947754
val: 12 0.4099760055541992
val: 13 0.40987902879714966
val: 14 0.4227505624294281
val: 15 0.4045679271221161
val: 16 0.4087968170642853
val: 17 0.41648826003074646
val: 18 0.4048517346382141
val: 19 0.413206547498703
val: 20 0.40299269556999207
val_Epoch:[ 146 ] val_loss: 0.41074725836515424 2022-07-20 01:31:33.714301
start training 2022-07-20 01:31:33.819206
Epoch:[ 147 0 ] loss: 0.35745999217033386 2022-07-20 01:31:47.932699
Epoch:[ 147 1 ] loss: 0.3564808964729309 2022-07-20 01:31:48.346622
Epoch:[ 147 2 ] loss: 0.3574928343296051 2022-07-20 01:31:48.758947
Epoch:[ 147 3 ] loss: 0.35638320446014404 2022-07-20 01:31:49.170717
Epoch:[ 147 4 ] loss: 0.35597461462020874 2022-07-20 01:31:49.583309
Epoch:[ 147 5 ] loss: 0.3561941385269165 2022-07-20 01:31:49.997597
Epoch:[ 147 6 ] loss: 0.35775554180145264 2022-07-20 01:31:50.411497
Epoch:[ 147 7 ] loss: 0.3559357523918152 2022-07-20 01:31:50.831674
Epoch:[ 147 8 ] loss: 0.3574356734752655 2022-07-20 01:31:51.250019
Epoch:[ 147 9 ] loss: 0.35748258233070374 2022-07-20 01:31:51.663251
Epoch:[ 147 10 ] loss: 0.35641372203826904 2022-07-20 01:31:52.075553
Epoch:[ 147 11 ] loss: 0.3570413589477539 2022-07-20 01:31:52.488144
Epoch:[ 147 12 ] loss: 0.3559812307357788 2022-07-20 01:31:52.901708
Epoch:[ 147 13 ] loss: 0.3569920063018799 2022-07-20 01:31:53.313520
Epoch:[ 147 14 ] loss: 0.3576936721801758 2022-07-20 01:31:53.726050
Epoch:[ 147 15 ] loss: 0.3567018210887909 2022-07-20 01:31:54.144893
Epoch:[ 147 16 ] loss: 0.3574657738208771 2022-07-20 01:31:59.367375
Epoch:[ 147 17 ] loss: 0.3569415807723999 2022-07-20 01:31:59.785633
Epoch:[ 147 18 ] loss: 0.3564780056476593 2022-07-20 01:32:00.200987
Epoch:[ 147 19 ] loss: 0.35724398493766785 2022-07-20 01:32:00.621154
Training_Epoch:[ 147 ] Training_loss: 0.3568774193525314 2022-07-20 01:32:00.621859
learning rate:  0.00010276966953088431
val: 1 0.40746018290519714
val: 2 0.40274953842163086
val: 3 0.4114547669887543
val: 4 0.4124067425727844
val: 5 0.41456085443496704
val: 6 0.40520262718200684
val: 7 0.39612987637519836
val: 8 0.4043312966823578
val: 9 0.42119574546813965
val: 10 0.40894678235054016
val: 11 0.4127025902271271
val: 12 0.40697118639945984
val: 13 0.4115581512451172
val: 14 0.4098045527935028
val: 15 0.4111408293247223
val: 16 0.41001373529434204
val: 17 0.4010877013206482
val: 18 0.4210238754749298
val: 19 0.4053381383419037
val: 20 0.4101092219352722
val_Epoch:[ 147 ] val_loss: 0.4092094197869301 2022-07-20 01:32:03.729546
start training 2022-07-20 01:32:03.833761
Epoch:[ 148 0 ] loss: 0.35658448934555054 2022-07-20 01:32:17.311898
Epoch:[ 148 1 ] loss: 0.3564607501029968 2022-07-20 01:32:17.968900
Epoch:[ 148 2 ] loss: 0.3564237356185913 2022-07-20 01:32:18.383842
Epoch:[ 148 3 ] loss: 0.3562023639678955 2022-07-20 01:32:18.796966
Epoch:[ 148 4 ] loss: 0.3568022549152374 2022-07-20 01:32:19.210910
Epoch:[ 148 5 ] loss: 0.3565963804721832 2022-07-20 01:32:19.626035
Epoch:[ 148 6 ] loss: 0.355654776096344 2022-07-20 01:32:20.044055
Epoch:[ 148 7 ] loss: 0.3568761944770813 2022-07-20 01:32:20.459238
Epoch:[ 148 8 ] loss: 0.35694098472595215 2022-07-20 01:32:20.874773
Epoch:[ 148 9 ] loss: 0.35725051164627075 2022-07-20 01:32:21.288916
Epoch:[ 148 10 ] loss: 0.3571262061595917 2022-07-20 01:32:21.702529
Epoch:[ 148 11 ] loss: 0.35743460059165955 2022-07-20 01:32:22.116221
Epoch:[ 148 12 ] loss: 0.3562617301940918 2022-07-20 01:32:22.530864
Epoch:[ 148 13 ] loss: 0.3564625382423401 2022-07-20 01:32:22.946261
Epoch:[ 148 14 ] loss: 0.3570846915245056 2022-07-20 01:32:23.363746
Epoch:[ 148 15 ] loss: 0.35687536001205444 2022-07-20 01:32:23.784311
Epoch:[ 148 16 ] loss: 0.35730913281440735 2022-07-20 01:32:28.703408
Epoch:[ 148 17 ] loss: 0.3562363386154175 2022-07-20 01:32:29.121278
Epoch:[ 148 18 ] loss: 0.35689491033554077 2022-07-20 01:32:29.535153
Epoch:[ 148 19 ] loss: 0.3552877604961395 2022-07-20 01:32:29.954867
Training_Epoch:[ 148 ] Training_loss: 0.35663828551769255 2022-07-20 01:32:29.955723
learning rate:  0.00010276966953088431
netparams have been saved once 148
val: 1 0.4065741002559662
val: 2 0.4187820553779602
val: 3 0.4151574671268463
val: 4 0.41236352920532227
val: 5 0.41523218154907227
val: 6 0.41665118932724
val: 7 0.4177577495574951
val: 8 0.4119871258735657
val: 9 0.41340214014053345
val: 10 0.40928924083709717
val: 11 0.41307029128074646
val: 12 0.42290350794792175
val: 13 0.4119046926498413
val: 14 0.4165688157081604
val: 15 0.4224788248538971
val: 16 0.41606178879737854
val: 17 0.4108450412750244
val: 18 0.40740537643432617
val: 19 0.4085994064807892
val: 20 0.39887571334838867
val_Epoch:[ 148 ] val_loss: 0.41329551190137864 2022-07-20 01:32:33.169422
start training 2022-07-20 01:32:33.273559
Epoch:[ 149 0 ] loss: 0.3569999635219574 2022-07-20 01:32:47.354927
Epoch:[ 149 1 ] loss: 0.3564688563346863 2022-07-20 01:32:47.773312
Epoch:[ 149 2 ] loss: 0.35721418261528015 2022-07-20 01:32:48.186762
Epoch:[ 149 3 ] loss: 0.35583338141441345 2022-07-20 01:32:48.600537
Epoch:[ 149 4 ] loss: 0.35615065693855286 2022-07-20 01:32:49.013266
Epoch:[ 149 5 ] loss: 0.3567678928375244 2022-07-20 01:32:49.428179
Epoch:[ 149 6 ] loss: 0.3569350838661194 2022-07-20 01:32:49.844482
Epoch:[ 149 7 ] loss: 0.35608118772506714 2022-07-20 01:32:50.258972
Epoch:[ 149 8 ] loss: 0.35643690824508667 2022-07-20 01:32:50.677588
Epoch:[ 149 9 ] loss: 0.35596293210983276 2022-07-20 01:32:51.089804
Epoch:[ 149 10 ] loss: 0.35774824023246765 2022-07-20 01:32:51.503913
Epoch:[ 149 11 ] loss: 0.35645464062690735 2022-07-20 01:32:51.922570
Epoch:[ 149 12 ] loss: 0.3571002185344696 2022-07-20 01:32:52.336191
Epoch:[ 149 13 ] loss: 0.3572832942008972 2022-07-20 01:32:52.751335
Epoch:[ 149 14 ] loss: 0.35693806409835815 2022-07-20 01:32:53.165972
Epoch:[ 149 15 ] loss: 0.35682639479637146 2022-07-20 01:32:53.579420
Epoch:[ 149 16 ] loss: 0.35620954632759094 2022-07-20 01:32:58.806757
Epoch:[ 149 17 ] loss: 0.3573192358016968 2022-07-20 01:32:59.225251
Epoch:[ 149 18 ] loss: 0.3557189702987671 2022-07-20 01:32:59.639573
Epoch:[ 149 19 ] loss: 0.35731038451194763 2022-07-20 01:33:00.058115
Training_Epoch:[ 149 ] Training_loss: 0.35668800175189974 2022-07-20 01:33:00.058803
learning rate:  0.00010276966953088431
val: 1 0.4164137542247772
val: 2 0.4108601212501526
val: 3 0.4001660645008087
val: 4 0.4184608459472656
val: 5 0.4120475649833679
val: 6 0.41259318590164185
val: 7 0.4085191786289215
val: 8 0.4185657799243927
val: 9 0.4092876613140106
val: 10 0.4079981744289398
val: 11 0.4120217263698578
val: 12 0.4101646840572357
val: 13 0.4139469563961029
val: 14 0.4093208312988281
val: 15 0.40918803215026855
val: 16 0.40300920605659485
val: 17 0.42107945680618286
val: 18 0.4094953238964081
val: 19 0.40871676802635193
val: 20 0.3984346389770508
val_Epoch:[ 149 ] val_loss: 0.41051449775695803 2022-07-20 01:33:03.246606
start training 2022-07-20 01:33:03.351534
Epoch:[ 150 0 ] loss: 0.355755090713501 2022-07-20 01:33:16.916744
Epoch:[ 150 1 ] loss: 0.3558718264102936 2022-07-20 01:33:17.351442
Epoch:[ 150 2 ] loss: 0.35712072253227234 2022-07-20 01:33:17.763380
Epoch:[ 150 3 ] loss: 0.35554227232933044 2022-07-20 01:33:18.177019
Epoch:[ 150 4 ] loss: 0.3576773405075073 2022-07-20 01:33:18.588649
Epoch:[ 150 5 ] loss: 0.35648536682128906 2022-07-20 01:33:19.001030
Epoch:[ 150 6 ] loss: 0.3557201027870178 2022-07-20 01:33:19.413689
Epoch:[ 150 7 ] loss: 0.3584986925125122 2022-07-20 01:33:19.830247
Epoch:[ 150 8 ] loss: 0.35713455080986023 2022-07-20 01:33:20.246370
Epoch:[ 150 9 ] loss: 0.35647690296173096 2022-07-20 01:33:20.660368
Epoch:[ 150 10 ] loss: 0.356695294380188 2022-07-20 01:33:21.075969
Epoch:[ 150 11 ] loss: 0.35585537552833557 2022-07-20 01:33:21.485961
Epoch:[ 150 12 ] loss: 0.35742905735969543 2022-07-20 01:33:21.899497
Epoch:[ 150 13 ] loss: 0.3577118217945099 2022-07-20 01:33:22.312567
Epoch:[ 150 14 ] loss: 0.35916265845298767 2022-07-20 01:33:22.728190
Epoch:[ 150 15 ] loss: 0.35727766156196594 2022-07-20 01:33:23.141181
Epoch:[ 150 16 ] loss: 0.35735973715782166 2022-07-20 01:33:29.158163
Epoch:[ 150 17 ] loss: 0.3560737371444702 2022-07-20 01:33:29.570600
Epoch:[ 150 18 ] loss: 0.3563075363636017 2022-07-20 01:33:29.981100
Epoch:[ 150 19 ] loss: 0.3563138246536255 2022-07-20 01:33:30.394219
Training_Epoch:[ 150 ] Training_loss: 0.35682347863912584 2022-07-20 01:33:30.395076
learning rate:  0.00010276966953088431
netparams have been saved once 150
val: 1 0.40810948610305786
val: 2 0.41472047567367554
val: 3 0.4079645276069641
val: 4 0.4114556312561035
val: 5 0.4134922921657562
val: 6 0.4217740297317505
val: 7 0.4090503752231598
val: 8 0.40765616297721863
val: 9 0.4154578745365143
val: 10 0.4125082790851593
val: 11 0.40773889422416687
val: 12 0.4111206829547882
val: 13 0.4115566313266754
val: 14 0.41087138652801514
val: 15 0.41492435336112976
val: 16 0.4068266451358795
val: 17 0.40973982214927673
val: 18 0.4034416675567627
val: 19 0.41253501176834106
val: 20 0.4059889614582062
val_Epoch:[ 150 ] val_loss: 0.4108466595411301 2022-07-20 01:33:33.751285
start training 2022-07-20 01:33:33.860646
Epoch:[ 151 0 ] loss: 0.3568919599056244 2022-07-20 01:33:48.289816
Epoch:[ 151 1 ] loss: 0.35611310601234436 2022-07-20 01:33:48.704595
Epoch:[ 151 2 ] loss: 0.35651710629463196 2022-07-20 01:33:49.119719
Epoch:[ 151 3 ] loss: 0.3569469451904297 2022-07-20 01:33:49.532505
Epoch:[ 151 4 ] loss: 0.35632404685020447 2022-07-20 01:33:49.941022
Epoch:[ 151 5 ] loss: 0.35477304458618164 2022-07-20 01:33:50.354773
Epoch:[ 151 6 ] loss: 0.3567923307418823 2022-07-20 01:33:50.768900
Epoch:[ 151 7 ] loss: 0.3553653359413147 2022-07-20 01:33:51.177846
Epoch:[ 151 8 ] loss: 0.35623666644096375 2022-07-20 01:33:51.592040
Epoch:[ 151 9 ] loss: 0.3562967777252197 2022-07-20 01:33:52.008955
Epoch:[ 151 10 ] loss: 0.3555632531642914 2022-07-20 01:33:52.420706
Epoch:[ 151 11 ] loss: 0.35611578822135925 2022-07-20 01:33:52.835148
Epoch:[ 151 12 ] loss: 0.3557346761226654 2022-07-20 01:33:53.248322
Epoch:[ 151 13 ] loss: 0.3567093312740326 2022-07-20 01:33:53.663583
Epoch:[ 151 14 ] loss: 0.35567501187324524 2022-07-20 01:33:54.076530
Epoch:[ 151 15 ] loss: 0.3554639518260956 2022-07-20 01:33:54.492371
Epoch:[ 151 16 ] loss: 0.3556421101093292 2022-07-20 01:33:59.933596
Epoch:[ 151 17 ] loss: 0.35658058524131775 2022-07-20 01:34:00.341324
Epoch:[ 151 18 ] loss: 0.35551461577415466 2022-07-20 01:34:00.753335
Epoch:[ 151 19 ] loss: 0.3564697206020355 2022-07-20 01:34:01.168416
Training_Epoch:[ 151 ] Training_loss: 0.3560863181948662 2022-07-20 01:34:01.169168
learning rate:  8.735421910125166e-05
val: 1 0.4113830626010895
val: 2 0.41102904081344604
val: 3 0.4190516471862793
val: 4 0.42025190591812134
val: 5 0.414657324552536
val: 6 0.4139145016670227
val: 7 0.41909685730934143
val: 8 0.4205288887023926
val: 9 0.4060661196708679
val: 10 0.41487759351730347
val: 11 0.40696457028388977
val: 12 0.415399968624115
val: 13 0.41704419255256653
val: 14 0.4114363193511963
val: 15 0.39734265208244324
val: 16 0.40915560722351074
val: 17 0.4071103632450104
val: 18 0.4200422167778015
val: 19 0.40480536222457886
val: 20 0.4063924252986908
val_Epoch:[ 151 ] val_loss: 0.41232753098011016 2022-07-20 01:34:04.422938
start training 2022-07-20 01:34:04.531796
Epoch:[ 152 0 ] loss: 0.3560188114643097 2022-07-20 01:34:18.621806
Epoch:[ 152 1 ] loss: 0.35475674271583557 2022-07-20 01:34:19.034540
Epoch:[ 152 2 ] loss: 0.355013906955719 2022-07-20 01:34:19.453702
Epoch:[ 152 3 ] loss: 0.3546466827392578 2022-07-20 01:34:19.867339
Epoch:[ 152 4 ] loss: 0.35743942856788635 2022-07-20 01:34:20.280168
Epoch:[ 152 5 ] loss: 0.3565582036972046 2022-07-20 01:34:20.694340
Epoch:[ 152 6 ] loss: 0.3556555509567261 2022-07-20 01:34:21.107302
Epoch:[ 152 7 ] loss: 0.3549027740955353 2022-07-20 01:34:21.520734
Epoch:[ 152 8 ] loss: 0.35616371035575867 2022-07-20 01:34:21.938845
Epoch:[ 152 9 ] loss: 0.3557203412055969 2022-07-20 01:34:22.352995
Epoch:[ 152 10 ] loss: 0.3550593852996826 2022-07-20 01:34:22.768124
Epoch:[ 152 11 ] loss: 0.3558776378631592 2022-07-20 01:34:23.180713
Epoch:[ 152 12 ] loss: 0.35535600781440735 2022-07-20 01:34:23.595191
Epoch:[ 152 13 ] loss: 0.3553764224052429 2022-07-20 01:34:24.015357
Epoch:[ 152 14 ] loss: 0.3560759127140045 2022-07-20 01:34:24.427622
Epoch:[ 152 15 ] loss: 0.35559818148612976 2022-07-20 01:34:24.839914
Epoch:[ 152 16 ] loss: 0.3562247157096863 2022-07-20 01:34:29.988696
Epoch:[ 152 17 ] loss: 0.35677406191825867 2022-07-20 01:34:30.404472
Epoch:[ 152 18 ] loss: 0.3551345765590668 2022-07-20 01:34:30.826936
Epoch:[ 152 19 ] loss: 0.3548421561717987 2022-07-20 01:34:31.240878
Training_Epoch:[ 152 ] Training_loss: 0.35565976053476334 2022-07-20 01:34:31.241729
learning rate:  8.735421910125166e-05
netparams have been saved once 152
val: 1 0.40213361382484436
val: 2 0.4026641547679901
val: 3 0.41393232345581055
val: 4 0.4112323224544525
val: 5 0.41354671120643616
val: 6 0.40820467472076416
val: 7 0.40715765953063965
val: 8 0.4170321822166443
val: 9 0.4157876670360565
val: 10 0.3972524404525757
val: 11 0.4207894206047058
val: 12 0.4079798460006714
val: 13 0.4121893346309662
val: 14 0.4223800003528595
val: 15 0.4122849702835083
val: 16 0.420139342546463
val: 17 0.40985482931137085
val: 18 0.40154778957366943
val: 19 0.4161873757839203
val: 20 0.4161553680896759
val_Epoch:[ 152 ] val_loss: 0.4114226013422012 2022-07-20 01:34:34.489437
start training 2022-07-20 01:34:34.591970
Epoch:[ 153 0 ] loss: 0.3562820851802826 2022-07-20 01:34:48.655880
Epoch:[ 153 1 ] loss: 0.35490870475769043 2022-07-20 01:34:49.069978
Epoch:[ 153 2 ] loss: 0.35396522283554077 2022-07-20 01:34:49.478444
Epoch:[ 153 3 ] loss: 0.356975257396698 2022-07-20 01:34:49.893230
Epoch:[ 153 4 ] loss: 0.35546308755874634 2022-07-20 01:34:50.307955
Epoch:[ 153 5 ] loss: 0.3549799621105194 2022-07-20 01:34:50.716292
Epoch:[ 153 6 ] loss: 0.3558305501937866 2022-07-20 01:34:51.131246
Epoch:[ 153 7 ] loss: 0.35519614815711975 2022-07-20 01:34:51.541164
Epoch:[ 153 8 ] loss: 0.3557300567626953 2022-07-20 01:34:51.954834
Epoch:[ 153 9 ] loss: 0.35565459728240967 2022-07-20 01:34:52.368328
Epoch:[ 153 10 ] loss: 0.35533657670021057 2022-07-20 01:34:52.784236
Epoch:[ 153 11 ] loss: 0.35409027338027954 2022-07-20 01:34:53.198545
Epoch:[ 153 12 ] loss: 0.35644882917404175 2022-07-20 01:34:53.611762
Epoch:[ 153 13 ] loss: 0.35644596815109253 2022-07-20 01:34:54.025383
Epoch:[ 153 14 ] loss: 0.3558316230773926 2022-07-20 01:34:54.440701
Epoch:[ 153 15 ] loss: 0.3563879430294037 2022-07-20 01:34:54.855251
Epoch:[ 153 16 ] loss: 0.3565616309642792 2022-07-20 01:35:00.147829
Epoch:[ 153 17 ] loss: 0.35615500807762146 2022-07-20 01:35:00.558220
Epoch:[ 153 18 ] loss: 0.35501885414123535 2022-07-20 01:35:00.973428
Epoch:[ 153 19 ] loss: 0.3555620610713959 2022-07-20 01:35:01.382186
Training_Epoch:[ 153 ] Training_loss: 0.35564122200012205 2022-07-20 01:35:01.383054
learning rate:  8.735421910125166e-05
val: 1 0.41692718863487244
val: 2 0.4165341556072235
val: 3 0.41496679186820984
val: 4 0.40895792841911316
val: 5 0.4193958640098572
val: 6 0.4024777114391327
val: 7 0.41163337230682373
val: 8 0.4130396246910095
val: 9 0.4110676050186157
val: 10 0.414203017950058
val: 11 0.4176985025405884
val: 12 0.4055764377117157
val: 13 0.40908002853393555
val: 14 0.41642633080482483
val: 15 0.4024244248867035
val: 16 0.41041135787963867
val: 17 0.40805336833000183
val: 18 0.412977010011673
val: 19 0.4065280258655548
val: 20 0.40734773874282837
val_Epoch:[ 153 ] val_loss: 0.411286324262619 2022-07-20 01:35:04.609070
start training 2022-07-20 01:35:04.720606
Epoch:[ 154 0 ] loss: 0.354525625705719 2022-07-20 01:35:18.911621
Epoch:[ 154 1 ] loss: 0.3552204966545105 2022-07-20 01:35:19.325046
Epoch:[ 154 2 ] loss: 0.35574430227279663 2022-07-20 01:35:19.738519
Epoch:[ 154 3 ] loss: 0.35479819774627686 2022-07-20 01:35:20.153103
Epoch:[ 154 4 ] loss: 0.3547899127006531 2022-07-20 01:35:20.563248
Epoch:[ 154 5 ] loss: 0.356253057718277 2022-07-20 01:35:20.972552
Epoch:[ 154 6 ] loss: 0.3559664487838745 2022-07-20 01:35:21.385791
Epoch:[ 154 7 ] loss: 0.35501378774642944 2022-07-20 01:35:21.800875
Epoch:[ 154 8 ] loss: 0.3555680215358734 2022-07-20 01:35:22.216675
Epoch:[ 154 9 ] loss: 0.356039434671402 2022-07-20 01:35:22.631054
Epoch:[ 154 10 ] loss: 0.35489267110824585 2022-07-20 01:35:23.044381
Epoch:[ 154 11 ] loss: 0.35479092597961426 2022-07-20 01:35:23.460538
Epoch:[ 154 12 ] loss: 0.3567742109298706 2022-07-20 01:35:23.876786
Epoch:[ 154 13 ] loss: 0.35566970705986023 2022-07-20 01:35:24.290518
Epoch:[ 154 14 ] loss: 0.35466280579566956 2022-07-20 01:35:24.703973
Epoch:[ 154 15 ] loss: 0.3562200367450714 2022-07-20 01:35:25.113612
Epoch:[ 154 16 ] loss: 0.35577449202537537 2022-07-20 01:35:29.983806
Epoch:[ 154 17 ] loss: 0.3556365966796875 2022-07-20 01:35:30.393037
Epoch:[ 154 18 ] loss: 0.356666624546051 2022-07-20 01:35:30.810090
Epoch:[ 154 19 ] loss: 0.35585859417915344 2022-07-20 01:35:31.220546
Training_Epoch:[ 154 ] Training_loss: 0.3555432975292206 2022-07-20 01:35:31.221283
learning rate:  8.735421910125166e-05
netparams have been saved once 154
val: 1 0.40970754623413086
val: 2 0.4121302664279938
val: 3 0.4163917899131775
val: 4 0.39968210458755493
val: 5 0.40949732065200806
val: 6 0.4206937253475189
val: 7 0.4164353609085083
val: 8 0.4028151035308838
val: 9 0.4046948552131653
val: 10 0.4111720323562622
val: 11 0.40877702832221985
val: 12 0.4108961820602417
val: 13 0.4169013202190399
val: 14 0.4038695991039276
val: 15 0.39803367853164673
val: 16 0.41751471161842346
val: 17 0.4135921895503998
val: 18 0.41249585151672363
val: 19 0.41727980971336365
val: 20 0.4182693362236023
val_Epoch:[ 154 ] val_loss: 0.41104249060153963 2022-07-20 01:35:34.459294
start training 2022-07-20 01:35:34.571044
Epoch:[ 155 0 ] loss: 0.35562238097190857 2022-07-20 01:35:48.305913
Epoch:[ 155 1 ] loss: 0.35554713010787964 2022-07-20 01:35:48.736605
Epoch:[ 155 2 ] loss: 0.3552016019821167 2022-07-20 01:35:49.157170
Epoch:[ 155 3 ] loss: 0.35514435172080994 2022-07-20 01:35:49.568527
Epoch:[ 155 4 ] loss: 0.356012761592865 2022-07-20 01:35:49.980271
Epoch:[ 155 5 ] loss: 0.3537046015262604 2022-07-20 01:35:50.394787
Epoch:[ 155 6 ] loss: 0.35682061314582825 2022-07-20 01:35:50.814468
Epoch:[ 155 7 ] loss: 0.354408323764801 2022-07-20 01:35:51.225611
Epoch:[ 155 8 ] loss: 0.35473960638046265 2022-07-20 01:35:51.638118
Epoch:[ 155 9 ] loss: 0.35521578788757324 2022-07-20 01:35:52.056467
Epoch:[ 155 10 ] loss: 0.35419902205467224 2022-07-20 01:35:52.469505
Epoch:[ 155 11 ] loss: 0.35695716738700867 2022-07-20 01:35:52.887567
Epoch:[ 155 12 ] loss: 0.354755699634552 2022-07-20 01:35:53.301612
Epoch:[ 155 13 ] loss: 0.3552214801311493 2022-07-20 01:35:53.714563
Epoch:[ 155 14 ] loss: 0.35638871788978577 2022-07-20 01:35:54.130065
Epoch:[ 155 15 ] loss: 0.35614946484565735 2022-07-20 01:35:54.541893
Epoch:[ 155 16 ] loss: 0.35548391938209534 2022-07-20 01:36:00.161887
Epoch:[ 155 17 ] loss: 0.35643455386161804 2022-07-20 01:36:00.574029
Epoch:[ 155 18 ] loss: 0.35713380575180054 2022-07-20 01:36:00.986819
Epoch:[ 155 19 ] loss: 0.3559415936470032 2022-07-20 01:36:01.406180
Training_Epoch:[ 155 ] Training_loss: 0.3555541291832924 2022-07-20 01:36:01.407124
learning rate:  8.735421910125166e-05
val: 1 0.4160836935043335
val: 2 0.4133191704750061
val: 3 0.4158923327922821
val: 4 0.4128018021583557
val: 5 0.3931826055049896
val: 6 0.4115837514400482
val: 7 0.40710344910621643
val: 8 0.41728290915489197
val: 9 0.42644384503364563
val: 10 0.4065519869327545
val: 11 0.4157428741455078
val: 12 0.41686978936195374
val: 13 0.41005778312683105
val: 14 0.4143262803554535
val: 15 0.41287726163864136
val: 16 0.40876513719558716
val: 17 0.4102168083190918
val: 18 0.4140322804450989
val: 19 0.4243295192718506
val: 20 0.418148934841156
val_Epoch:[ 155 ] val_loss: 0.4132806107401848 2022-07-20 01:36:04.578800
start training 2022-07-20 01:36:04.682284
Epoch:[ 156 0 ] loss: 0.3565966486930847 2022-07-20 01:36:18.845635
Epoch:[ 156 1 ] loss: 0.3554447293281555 2022-07-20 01:36:19.261220
Epoch:[ 156 2 ] loss: 0.35559844970703125 2022-07-20 01:36:19.676199
Epoch:[ 156 3 ] loss: 0.3555814027786255 2022-07-20 01:36:20.090782
Epoch:[ 156 4 ] loss: 0.35569503903388977 2022-07-20 01:36:20.504801
Epoch:[ 156 5 ] loss: 0.35683295130729675 2022-07-20 01:36:20.918512
Epoch:[ 156 6 ] loss: 0.3550003170967102 2022-07-20 01:36:21.330781
Epoch:[ 156 7 ] loss: 0.354294091463089 2022-07-20 01:36:21.746908
Epoch:[ 156 8 ] loss: 0.35549649596214294 2022-07-20 01:36:22.159830
Epoch:[ 156 9 ] loss: 0.3549788296222687 2022-07-20 01:36:22.573532
Epoch:[ 156 10 ] loss: 0.3547923266887665 2022-07-20 01:36:22.988049
Epoch:[ 156 11 ] loss: 0.35605770349502563 2022-07-20 01:36:23.398321
Epoch:[ 156 12 ] loss: 0.3559032082557678 2022-07-20 01:36:23.810649
Epoch:[ 156 13 ] loss: 0.3550397753715515 2022-07-20 01:36:24.225282
Epoch:[ 156 14 ] loss: 0.3557642698287964 2022-07-20 01:36:24.640790
Epoch:[ 156 15 ] loss: 0.35581105947494507 2022-07-20 01:36:25.056626
Epoch:[ 156 16 ] loss: 0.3565596640110016 2022-07-20 01:36:30.082246
Epoch:[ 156 17 ] loss: 0.35605311393737793 2022-07-20 01:36:30.495684
Epoch:[ 156 18 ] loss: 0.35567569732666016 2022-07-20 01:36:30.908069
Epoch:[ 156 19 ] loss: 0.3557453155517578 2022-07-20 01:36:31.316836
Training_Epoch:[ 156 ] Training_loss: 0.3556460544466972 2022-07-20 01:36:31.317758
learning rate:  8.735421910125166e-05
netparams have been saved once 156
val: 1 0.42120862007141113
val: 2 0.40697726607322693
val: 3 0.4131048321723938
val: 4 0.41183289885520935
val: 5 0.41972818970680237
val: 6 0.41352471709251404
val: 7 0.4103994369506836
val: 8 0.411780446767807
val: 9 0.4160720407962799
val: 10 0.4158491790294647
val: 11 0.41948845982551575
val: 12 0.4186418950557709
val: 13 0.40632638335227966
val: 14 0.4149352014064789
val: 15 0.41062745451927185
val: 16 0.40541625022888184
val: 17 0.4104277491569519
val: 18 0.4023211598396301
val: 19 0.41644302010536194
val: 20 0.4116484522819519
val_Epoch:[ 156 ] val_loss: 0.41283768266439436 2022-07-20 01:36:34.619254
start training 2022-07-20 01:36:34.726152
Epoch:[ 157 0 ] loss: 0.3544130325317383 2022-07-20 01:36:48.457203
Epoch:[ 157 1 ] loss: 0.35567718744277954 2022-07-20 01:36:48.996231
Epoch:[ 157 2 ] loss: 0.35561180114746094 2022-07-20 01:36:49.415813
Epoch:[ 157 3 ] loss: 0.3556123375892639 2022-07-20 01:36:49.827761
Epoch:[ 157 4 ] loss: 0.35634279251098633 2022-07-20 01:36:50.239096
Epoch:[ 157 5 ] loss: 0.3551708459854126 2022-07-20 01:36:50.653310
Epoch:[ 157 6 ] loss: 0.35476696491241455 2022-07-20 01:36:51.068470
Epoch:[ 157 7 ] loss: 0.3560637831687927 2022-07-20 01:36:51.487349
Epoch:[ 157 8 ] loss: 0.3553335964679718 2022-07-20 01:36:51.900248
Epoch:[ 157 9 ] loss: 0.3557117283344269 2022-07-20 01:36:52.311947
Epoch:[ 157 10 ] loss: 0.3551073968410492 2022-07-20 01:36:52.723800
Epoch:[ 157 11 ] loss: 0.3553731441497803 2022-07-20 01:36:53.136760
Epoch:[ 157 12 ] loss: 0.35494348406791687 2022-07-20 01:36:53.550103
Epoch:[ 157 13 ] loss: 0.3559315502643585 2022-07-20 01:36:53.962884
Epoch:[ 157 14 ] loss: 0.3550879955291748 2022-07-20 01:36:54.377628
Epoch:[ 157 15 ] loss: 0.35639989376068115 2022-07-20 01:36:54.790996
Epoch:[ 157 16 ] loss: 0.3555496633052826 2022-07-20 01:36:59.836734
Epoch:[ 157 17 ] loss: 0.357225239276886 2022-07-20 01:37:00.528556
Epoch:[ 157 18 ] loss: 0.354044109582901 2022-07-20 01:37:00.947905
Epoch:[ 157 19 ] loss: 0.3576778769493103 2022-07-20 01:37:01.361838
Training_Epoch:[ 157 ] Training_loss: 0.35560222119092944 2022-07-20 01:37:01.362612
learning rate:  8.735421910125166e-05
val: 1 0.40778711438179016
val: 2 0.41233959794044495
val: 3 0.42181769013404846
val: 4 0.4164116084575653
val: 5 0.4098353385925293
val: 6 0.41480153799057007
val: 7 0.41398853063583374
val: 8 0.4137379825115204
val: 9 0.40206530690193176
val: 10 0.4172745645046234
val: 11 0.4173355996608734
val: 12 0.4091634750366211
val: 13 0.40037229657173157
val: 14 0.4134294390678406
val: 15 0.40347737073898315
val: 16 0.4116014838218689
val: 17 0.3989097774028778
val: 18 0.4108707010746002
val: 19 0.40585675835609436
val: 20 0.4079752266407013
val_Epoch:[ 157 ] val_loss: 0.4104525700211525 2022-07-20 01:37:04.560707
start training 2022-07-20 01:37:04.669259
Epoch:[ 158 0 ] loss: 0.3548467755317688 2022-07-20 01:37:18.631737
Epoch:[ 158 1 ] loss: 0.3550792634487152 2022-07-20 01:37:19.045858
Epoch:[ 158 2 ] loss: 0.3542233407497406 2022-07-20 01:37:19.465907
Epoch:[ 158 3 ] loss: 0.3565908670425415 2022-07-20 01:37:19.883693
Epoch:[ 158 4 ] loss: 0.35637974739074707 2022-07-20 01:37:20.295697
Epoch:[ 158 5 ] loss: 0.35591986775398254 2022-07-20 01:37:20.708383
Epoch:[ 158 6 ] loss: 0.3556574583053589 2022-07-20 01:37:21.121049
Epoch:[ 158 7 ] loss: 0.3553962707519531 2022-07-20 01:37:21.535746
Epoch:[ 158 8 ] loss: 0.35578709840774536 2022-07-20 01:37:21.948579
Epoch:[ 158 9 ] loss: 0.3548695147037506 2022-07-20 01:37:22.360860
Epoch:[ 158 10 ] loss: 0.3549007475376129 2022-07-20 01:37:22.776322
Epoch:[ 158 11 ] loss: 0.35613104701042175 2022-07-20 01:37:23.187966
Epoch:[ 158 12 ] loss: 0.3560892641544342 2022-07-20 01:37:23.601137
Epoch:[ 158 13 ] loss: 0.3566119372844696 2022-07-20 01:37:24.014627
Epoch:[ 158 14 ] loss: 0.3556153178215027 2022-07-20 01:37:24.429207
Epoch:[ 158 15 ] loss: 0.3548550307750702 2022-07-20 01:37:24.848797
Epoch:[ 158 16 ] loss: 0.35501813888549805 2022-07-20 01:37:30.146296
Epoch:[ 158 17 ] loss: 0.35651063919067383 2022-07-20 01:37:30.557412
Epoch:[ 158 18 ] loss: 0.35637280344963074 2022-07-20 01:37:30.975694
Epoch:[ 158 19 ] loss: 0.356424480676651 2022-07-20 01:37:31.393984
Training_Epoch:[ 158 ] Training_loss: 0.3556639805436134 2022-07-20 01:37:31.394631
learning rate:  8.735421910125166e-05
netparams have been saved once 158
val: 1 0.4194282591342926
val: 2 0.41639190912246704
val: 3 0.41038915514945984
val: 4 0.41258224844932556
val: 5 0.4162038564682007
val: 6 0.411731481552124
val: 7 0.412341833114624
val: 8 0.41919225454330444
val: 9 0.40977367758750916
val: 10 0.4101056158542633
val: 11 0.423785537481308
val: 12 0.4163498878479004
val: 13 0.4116057753562927
val: 14 0.4140978157520294
val: 15 0.40740033984184265
val: 16 0.41117948293685913
val: 17 0.4064881205558777
val: 18 0.41104626655578613
val: 19 0.41626104712486267
val: 20 0.4187513291835785
val_Epoch:[ 158 ] val_loss: 0.4137552946805954 2022-07-20 01:37:34.603431
start training 2022-07-20 01:37:34.706448
Epoch:[ 159 0 ] loss: 0.35556888580322266 2022-07-20 01:37:48.852763
Epoch:[ 159 1 ] loss: 0.3541622757911682 2022-07-20 01:37:49.266233
Epoch:[ 159 2 ] loss: 0.3559851348400116 2022-07-20 01:37:49.680723
Epoch:[ 159 3 ] loss: 0.3549807369709015 2022-07-20 01:37:50.097720
Epoch:[ 159 4 ] loss: 0.3546146750450134 2022-07-20 01:37:50.510816
Epoch:[ 159 5 ] loss: 0.3556893765926361 2022-07-20 01:37:50.925000
Epoch:[ 159 6 ] loss: 0.35541442036628723 2022-07-20 01:37:51.336340
Epoch:[ 159 7 ] loss: 0.3566228449344635 2022-07-20 01:37:51.749728
Epoch:[ 159 8 ] loss: 0.35512909293174744 2022-07-20 01:37:52.163001
Epoch:[ 159 9 ] loss: 0.3549782931804657 2022-07-20 01:37:52.577618
Epoch:[ 159 10 ] loss: 0.35558274388313293 2022-07-20 01:37:52.989357
Epoch:[ 159 11 ] loss: 0.3560548424720764 2022-07-20 01:37:53.400434
Epoch:[ 159 12 ] loss: 0.35669198632240295 2022-07-20 01:37:53.812335
Epoch:[ 159 13 ] loss: 0.35726624727249146 2022-07-20 01:37:54.227232
Epoch:[ 159 14 ] loss: 0.3559599220752716 2022-07-20 01:37:54.639630
Epoch:[ 159 15 ] loss: 0.354905366897583 2022-07-20 01:37:55.053667
Epoch:[ 159 16 ] loss: 0.3568927049636841 2022-07-20 01:38:00.485990
Epoch:[ 159 17 ] loss: 0.35543304681777954 2022-07-20 01:38:00.895809
Epoch:[ 159 18 ] loss: 0.3561583459377289 2022-07-20 01:38:01.313492
Epoch:[ 159 19 ] loss: 0.3554293215274811 2022-07-20 01:38:01.727172
Training_Epoch:[ 159 ] Training_loss: 0.35567601323127745 2022-07-20 01:38:01.727945
learning rate:  8.735421910125166e-05
val: 1 0.42077675461769104
val: 2 0.41814911365509033
val: 3 0.4035501778125763
val: 4 0.3997756242752075
val: 5 0.4148450493812561
val: 6 0.4051869511604309
val: 7 0.4094581604003906
val: 8 0.40850988030433655
val: 9 0.41384056210517883
val: 10 0.4079524278640747
val: 11 0.4064204692840576
val: 12 0.40515607595443726
val: 13 0.40711262822151184
val: 14 0.4062015414237976
val: 15 0.4091855585575104
val: 16 0.4123149812221527
val: 17 0.40711086988449097
val: 18 0.4180431663990021
val: 19 0.4074843227863312
val: 20 0.4185793101787567
val_Epoch:[ 159 ] val_loss: 0.40998268127441406 2022-07-20 01:38:04.935173
start training 2022-07-20 01:38:05.040119
Epoch:[ 160 0 ] loss: 0.35482093691825867 2022-07-20 01:38:18.610802
Epoch:[ 160 1 ] loss: 0.35602325201034546 2022-07-20 01:38:19.047819
Epoch:[ 160 2 ] loss: 0.35539889335632324 2022-07-20 01:38:19.463923
Epoch:[ 160 3 ] loss: 0.3558039963245392 2022-07-20 01:38:19.880068
Epoch:[ 160 4 ] loss: 0.3549136519432068 2022-07-20 01:38:20.295859
Epoch:[ 160 5 ] loss: 0.35619229078292847 2022-07-20 01:38:20.709125
Epoch:[ 160 6 ] loss: 0.355243057012558 2022-07-20 01:38:21.124494
Epoch:[ 160 7 ] loss: 0.35571637749671936 2022-07-20 01:38:21.531773
Epoch:[ 160 8 ] loss: 0.3558657169342041 2022-07-20 01:38:21.946157
Epoch:[ 160 9 ] loss: 0.35439616441726685 2022-07-20 01:38:22.354124
Epoch:[ 160 10 ] loss: 0.3559030294418335 2022-07-20 01:38:22.769794
Epoch:[ 160 11 ] loss: 0.354759156703949 2022-07-20 01:38:23.185007
Epoch:[ 160 12 ] loss: 0.3561047613620758 2022-07-20 01:38:23.600013
Epoch:[ 160 13 ] loss: 0.35566091537475586 2022-07-20 01:38:24.014690
Epoch:[ 160 14 ] loss: 0.3563501834869385 2022-07-20 01:38:24.428947
Epoch:[ 160 15 ] loss: 0.3557109534740448 2022-07-20 01:38:24.842364
Epoch:[ 160 16 ] loss: 0.355268657207489 2022-07-20 01:38:30.374296
Epoch:[ 160 17 ] loss: 0.35615071654319763 2022-07-20 01:38:30.784726
Epoch:[ 160 18 ] loss: 0.35403314232826233 2022-07-20 01:38:31.202271
Epoch:[ 160 19 ] loss: 0.3557048439979553 2022-07-20 01:38:31.615072
Training_Epoch:[ 160 ] Training_loss: 0.3555010348558426 2022-07-20 01:38:31.615839
learning rate:  8.735421910125166e-05
netparams have been saved once 160
val: 1 0.40551283955574036
val: 2 0.40658193826675415
val: 3 0.4106738865375519
val: 4 0.41235244274139404
val: 5 0.41761261224746704
val: 6 0.40714073181152344
val: 7 0.40917664766311646
val: 8 0.42338958382606506
val: 9 0.40691810846328735
val: 10 0.42003133893013
val: 11 0.4037601947784424
val: 12 0.41799676418304443
val: 13 0.41813015937805176
val: 14 0.40601101517677307
val: 15 0.3986278176307678
val: 16 0.4014274477958679
val: 17 0.4075074791908264
val: 18 0.4133906364440918
val: 19 0.4052709639072418
val: 20 0.4143562614917755
val_Epoch:[ 160 ] val_loss: 0.4102934435009956 2022-07-20 01:38:34.895706
start training 2022-07-20 01:38:35.005355
Epoch:[ 161 0 ] loss: 0.35446861386299133 2022-07-20 01:38:49.266894
Epoch:[ 161 1 ] loss: 0.35413628816604614 2022-07-20 01:38:49.680616
Epoch:[ 161 2 ] loss: 0.35425716638565063 2022-07-20 01:38:50.092561
Epoch:[ 161 3 ] loss: 0.3551355302333832 2022-07-20 01:38:50.509473
Epoch:[ 161 4 ] loss: 0.35452771186828613 2022-07-20 01:38:50.922992
Epoch:[ 161 5 ] loss: 0.3543105125427246 2022-07-20 01:38:51.341729
Epoch:[ 161 6 ] loss: 0.35640981793403625 2022-07-20 01:38:51.754189
Epoch:[ 161 7 ] loss: 0.3544413149356842 2022-07-20 01:38:52.169440
Epoch:[ 161 8 ] loss: 0.35569116473197937 2022-07-20 01:38:52.582131
Epoch:[ 161 9 ] loss: 0.35419800877571106 2022-07-20 01:38:52.995051
Epoch:[ 161 10 ] loss: 0.3561854660511017 2022-07-20 01:38:53.406632
Epoch:[ 161 11 ] loss: 0.35446181893348694 2022-07-20 01:38:53.820025
Epoch:[ 161 12 ] loss: 0.35405033826828003 2022-07-20 01:38:54.234146
Epoch:[ 161 13 ] loss: 0.3546298146247864 2022-07-20 01:38:54.646087
Epoch:[ 161 14 ] loss: 0.3547224998474121 2022-07-20 01:38:55.059895
Epoch:[ 161 15 ] loss: 0.35487285256385803 2022-07-20 01:38:55.479111
Epoch:[ 161 16 ] loss: 0.3557990491390228 2022-07-20 01:39:00.706421
Epoch:[ 161 17 ] loss: 0.3554671108722687 2022-07-20 01:39:01.120872
Epoch:[ 161 18 ] loss: 0.35474616289138794 2022-07-20 01:39:01.543000
Epoch:[ 161 19 ] loss: 0.35486936569213867 2022-07-20 01:39:01.956991
Training_Epoch:[ 161 ] Training_loss: 0.3548690304160118 2022-07-20 01:39:01.957699
learning rate:  7.425108623606391e-05
val: 1 0.42467403411865234
val: 2 0.4107036292552948
val: 3 0.4103296995162964
val: 4 0.40679043531417847
val: 5 0.4138152003288269
val: 6 0.41212549805641174
val: 7 0.4105023443698883
val: 8 0.4245683252811432
val: 9 0.4135347306728363
val: 10 0.4187825918197632
val: 11 0.4139866828918457
val: 12 0.41742512583732605
val: 13 0.4176251292228699
val: 14 0.41328272223472595
val: 15 0.42115411162376404
val: 16 0.4142460227012634
val: 17 0.4112115800380707
val: 18 0.4227062463760376
val: 19 0.41290977597236633
val: 20 0.411126047372818
val_Epoch:[ 161 ] val_loss: 0.41507499665021896 2022-07-20 01:39:05.100896
start training 2022-07-20 01:39:05.209172
Epoch:[ 162 0 ] loss: 0.3542564809322357 2022-07-20 01:39:18.741213
Epoch:[ 162 1 ] loss: 0.3539886474609375 2022-07-20 01:39:19.176172
Epoch:[ 162 2 ] loss: 0.35432955622673035 2022-07-20 01:39:19.591161
Epoch:[ 162 3 ] loss: 0.3549312353134155 2022-07-20 01:39:20.004772
Epoch:[ 162 4 ] loss: 0.35411056876182556 2022-07-20 01:39:20.414114
Epoch:[ 162 5 ] loss: 0.35511624813079834 2022-07-20 01:39:20.828679
Epoch:[ 162 6 ] loss: 0.3536297082901001 2022-07-20 01:39:21.242998
Epoch:[ 162 7 ] loss: 0.3551555573940277 2022-07-20 01:39:21.660104
Epoch:[ 162 8 ] loss: 0.35393792390823364 2022-07-20 01:39:22.073963
Epoch:[ 162 9 ] loss: 0.35437846183776855 2022-07-20 01:39:22.487097
Epoch:[ 162 10 ] loss: 0.35480377078056335 2022-07-20 01:39:22.900930
Epoch:[ 162 11 ] loss: 0.35494062304496765 2022-07-20 01:39:23.312959
Epoch:[ 162 12 ] loss: 0.35487261414527893 2022-07-20 01:39:23.727360
Epoch:[ 162 13 ] loss: 0.35363271832466125 2022-07-20 01:39:24.137247
Epoch:[ 162 14 ] loss: 0.3538341224193573 2022-07-20 01:39:24.550113
Epoch:[ 162 15 ] loss: 0.35338518023490906 2022-07-20 01:39:24.965360
Epoch:[ 162 16 ] loss: 0.35514307022094727 2022-07-20 01:39:30.907683
Epoch:[ 162 17 ] loss: 0.35440701246261597 2022-07-20 01:39:31.319691
Epoch:[ 162 18 ] loss: 0.3549731373786926 2022-07-20 01:39:31.740739
Epoch:[ 162 19 ] loss: 0.35527583956718445 2022-07-20 01:39:32.159978
Training_Epoch:[ 162 ] Training_loss: 0.35445512384176253 2022-07-20 01:39:32.160738
learning rate:  7.425108623606391e-05
netparams have been saved once 162
val: 1 0.40694373846054077
val: 2 0.42837026715278625
val: 3 0.41933679580688477
val: 4 0.40393146872520447
val: 5 0.4169512987136841
val: 6 0.4043726325035095
val: 7 0.40761512517929077
val: 8 0.4203661382198334
val: 9 0.4175095856189728
val: 10 0.4229791462421417
val: 11 0.39924269914627075
val: 12 0.41477325558662415
val: 13 0.40899378061294556
val: 14 0.425178587436676
val: 15 0.4284431040287018
val: 16 0.4094913601875305
val: 17 0.4077867567539215
val: 18 0.4236108064651489
val: 19 0.4107434153556824
val: 20 0.4206836521625519
val_Epoch:[ 162 ] val_loss: 0.4148661807179451 2022-07-20 01:39:35.415808
start training 2022-07-20 01:39:35.525940
Epoch:[ 163 0 ] loss: 0.35437270998954773 2022-07-20 01:39:49.033339
Epoch:[ 163 1 ] loss: 0.3546845614910126 2022-07-20 01:39:49.740691
Epoch:[ 163 2 ] loss: 0.3540351986885071 2022-07-20 01:39:50.150705
Epoch:[ 163 3 ] loss: 0.3542698621749878 2022-07-20 01:39:50.565348
Epoch:[ 163 4 ] loss: 0.353385865688324 2022-07-20 01:39:50.979726
Epoch:[ 163 5 ] loss: 0.3545856773853302 2022-07-20 01:39:51.395660
Epoch:[ 163 6 ] loss: 0.35437074303627014 2022-07-20 01:39:51.811526
Epoch:[ 163 7 ] loss: 0.3548147678375244 2022-07-20 01:39:52.227719
Epoch:[ 163 8 ] loss: 0.3545961081981659 2022-07-20 01:39:52.640856
Epoch:[ 163 9 ] loss: 0.35415393114089966 2022-07-20 01:39:53.053886
Epoch:[ 163 10 ] loss: 0.3541801869869232 2022-07-20 01:39:53.465641
Epoch:[ 163 11 ] loss: 0.3541579842567444 2022-07-20 01:39:53.883951
Epoch:[ 163 12 ] loss: 0.3538985550403595 2022-07-20 01:39:54.296606
Epoch:[ 163 13 ] loss: 0.3544241487979889 2022-07-20 01:39:54.710263
Epoch:[ 163 14 ] loss: 0.35411936044692993 2022-07-20 01:39:55.123889
Epoch:[ 163 15 ] loss: 0.3555256128311157 2022-07-20 01:39:55.537090
Epoch:[ 163 16 ] loss: 0.35483673214912415 2022-07-20 01:40:00.785556
Epoch:[ 163 17 ] loss: 0.35404103994369507 2022-07-20 01:40:01.280489
Epoch:[ 163 18 ] loss: 0.35509204864501953 2022-07-20 01:40:01.705907
Epoch:[ 163 19 ] loss: 0.35467255115509033 2022-07-20 01:40:02.117599
Training_Epoch:[ 163 ] Training_loss: 0.354410882294178 2022-07-20 01:40:02.118299
learning rate:  7.425108623606391e-05
val: 1 0.41010957956314087
val: 2 0.4164627492427826
val: 3 0.42437756061553955
val: 4 0.4123246669769287
val: 5 0.42640629410743713
val: 6 0.41434112191200256
val: 7 0.4226948618888855
val: 8 0.42112985253334045
val: 9 0.4100782573223114
val: 10 0.4074355959892273
val: 11 0.4068823456764221
val: 12 0.4036981463432312
val: 13 0.41192448139190674
val: 14 0.40544217824935913
val: 15 0.41282644867897034
val: 16 0.41075995564460754
val: 17 0.41868850588798523
val: 18 0.4109720289707184
val: 19 0.4152594804763794
val: 20 0.414008766412735
val_Epoch:[ 163 ] val_loss: 0.4137911438941956 2022-07-20 01:40:05.295921
start training 2022-07-20 01:40:05.402142
Epoch:[ 164 0 ] loss: 0.3548811376094818 2022-07-20 01:40:18.754444
Epoch:[ 164 1 ] loss: 0.35408252477645874 2022-07-20 01:40:19.265341
Epoch:[ 164 2 ] loss: 0.3538435697555542 2022-07-20 01:40:19.705176
Epoch:[ 164 3 ] loss: 0.35446271300315857 2022-07-20 01:40:20.116569
Epoch:[ 164 4 ] loss: 0.3546357750892639 2022-07-20 01:40:20.528520
Epoch:[ 164 5 ] loss: 0.3545207679271698 2022-07-20 01:40:20.940304
Epoch:[ 164 6 ] loss: 0.3543355464935303 2022-07-20 01:40:21.352816
Epoch:[ 164 7 ] loss: 0.3547694683074951 2022-07-20 01:40:21.767800
Epoch:[ 164 8 ] loss: 0.3529200553894043 2022-07-20 01:40:22.181645
Epoch:[ 164 9 ] loss: 0.3539770245552063 2022-07-20 01:40:22.595455
Epoch:[ 164 10 ] loss: 0.35435250401496887 2022-07-20 01:40:23.010049
Epoch:[ 164 11 ] loss: 0.35327938199043274 2022-07-20 01:40:23.427657
Epoch:[ 164 12 ] loss: 0.3543526828289032 2022-07-20 01:40:23.842010
Epoch:[ 164 13 ] loss: 0.3545132875442505 2022-07-20 01:40:24.255021
Epoch:[ 164 14 ] loss: 0.3551758825778961 2022-07-20 01:40:24.669913
Epoch:[ 164 15 ] loss: 0.3554663360118866 2022-07-20 01:40:25.086139
Epoch:[ 164 16 ] loss: 0.3536965548992157 2022-07-20 01:40:30.418151
Epoch:[ 164 17 ] loss: 0.35478729009628296 2022-07-20 01:40:30.877220
Epoch:[ 164 18 ] loss: 0.35553157329559326 2022-07-20 01:40:31.297459
Epoch:[ 164 19 ] loss: 0.3546677231788635 2022-07-20 01:40:31.715272
Training_Epoch:[ 164 ] Training_loss: 0.35441258996725084 2022-07-20 01:40:31.716209
learning rate:  7.425108623606391e-05
netparams have been saved once 164
val: 1 0.41251054406166077
val: 2 0.40727534890174866
val: 3 0.4171923100948334
val: 4 0.41283947229385376
val: 5 0.41445082426071167
val: 6 0.4194169342517853
val: 7 0.4156357944011688
val: 8 0.41847777366638184
val: 9 0.4154299199581146
val: 10 0.41090068221092224
val: 11 0.4149002134799957
val: 12 0.4246802031993866
val: 13 0.4196888506412506
val: 14 0.4239862263202667
val: 15 0.4049327075481415
val: 16 0.40439048409461975
val: 17 0.4079345464706421
val: 18 0.4145759642124176
val: 19 0.4142042398452759
val: 20 0.41458767652511597
val_Epoch:[ 164 ] val_loss: 0.41440053582191466 2022-07-20 01:40:34.887086
start training 2022-07-20 01:40:34.991162
Epoch:[ 165 0 ] loss: 0.35410231351852417 2022-07-20 01:40:48.448427
Epoch:[ 165 1 ] loss: 0.35423463582992554 2022-07-20 01:40:48.879359
Epoch:[ 165 2 ] loss: 0.35438182950019836 2022-07-20 01:40:49.292365
Epoch:[ 165 3 ] loss: 0.35525742173194885 2022-07-20 01:40:49.705963
Epoch:[ 165 4 ] loss: 0.35422810912132263 2022-07-20 01:40:50.113206
Epoch:[ 165 5 ] loss: 0.3546338677406311 2022-07-20 01:40:50.523996
Epoch:[ 165 6 ] loss: 0.3546164631843567 2022-07-20 01:40:50.937369
Epoch:[ 165 7 ] loss: 0.35429784655570984 2022-07-20 01:40:51.350906
Epoch:[ 165 8 ] loss: 0.35484957695007324 2022-07-20 01:40:51.766467
Epoch:[ 165 9 ] loss: 0.35434359312057495 2022-07-20 01:40:52.182730
Epoch:[ 165 10 ] loss: 0.3549841344356537 2022-07-20 01:40:52.598878
Epoch:[ 165 11 ] loss: 0.3540315628051758 2022-07-20 01:40:53.015368
Epoch:[ 165 12 ] loss: 0.35354921221733093 2022-07-20 01:40:53.429221
Epoch:[ 165 13 ] loss: 0.35454145073890686 2022-07-20 01:40:53.843409
Epoch:[ 165 14 ] loss: 0.35408711433410645 2022-07-20 01:40:54.257970
Epoch:[ 165 15 ] loss: 0.3538602590560913 2022-07-20 01:40:54.673489
Epoch:[ 165 16 ] loss: 0.35359057784080505 2022-07-20 01:41:00.425465
Epoch:[ 165 17 ] loss: 0.3539077043533325 2022-07-20 01:41:00.833769
Epoch:[ 165 18 ] loss: 0.3546074628829956 2022-07-20 01:41:01.248107
Epoch:[ 165 19 ] loss: 0.35435372591018677 2022-07-20 01:41:01.657735
Training_Epoch:[ 165 ] Training_loss: 0.3543229430913925 2022-07-20 01:41:01.658737
learning rate:  7.425108623606391e-05
val: 1 0.40869712829589844
val: 2 0.40992358326911926
val: 3 0.41294777393341064
val: 4 0.4094735085964203
val: 5 0.4078315794467926
val: 6 0.40302059054374695
val: 7 0.405303031206131
val: 8 0.4100304841995239
val: 9 0.3989633023738861
val: 10 0.4171956777572632
val: 11 0.4202186167240143
val: 12 0.4126855432987213
val: 13 0.4147050678730011
val: 14 0.40130043029785156
val: 15 0.4195205569267273
val: 16 0.4138990640640259
val: 17 0.41812384128570557
val: 18 0.42510196566581726
val: 19 0.41941437125205994
val: 20 0.4078137278556824
val_Epoch:[ 165 ] val_loss: 0.41180849224328997 2022-07-20 01:41:04.886266
start training 2022-07-20 01:41:04.991479
Epoch:[ 166 0 ] loss: 0.352884978055954 2022-07-20 01:41:18.489775
Epoch:[ 166 1 ] loss: 0.3543449938297272 2022-07-20 01:41:18.916432
Epoch:[ 166 2 ] loss: 0.3545800745487213 2022-07-20 01:41:19.331645
Epoch:[ 166 3 ] loss: 0.3537217974662781 2022-07-20 01:41:19.745229
Epoch:[ 166 4 ] loss: 0.3537614345550537 2022-07-20 01:41:20.159267
Epoch:[ 166 5 ] loss: 0.35369381308555603 2022-07-20 01:41:20.575468
Epoch:[ 166 6 ] loss: 0.3532257080078125 2022-07-20 01:41:20.990394
Epoch:[ 166 7 ] loss: 0.3545457720756531 2022-07-20 01:41:21.404035
Epoch:[ 166 8 ] loss: 0.3542271554470062 2022-07-20 01:41:21.821396
Epoch:[ 166 9 ] loss: 0.35456395149230957 2022-07-20 01:41:22.240735
Epoch:[ 166 10 ] loss: 0.3546481728553772 2022-07-20 01:41:22.655396
Epoch:[ 166 11 ] loss: 0.35470831394195557 2022-07-20 01:41:23.066805
Epoch:[ 166 12 ] loss: 0.35423022508621216 2022-07-20 01:41:23.480155
Epoch:[ 166 13 ] loss: 0.3538229763507843 2022-07-20 01:41:23.893133
Epoch:[ 166 14 ] loss: 0.35445380210876465 2022-07-20 01:41:24.306250
Epoch:[ 166 15 ] loss: 0.35385748744010925 2022-07-20 01:41:24.718575
Epoch:[ 166 16 ] loss: 0.35382384061813354 2022-07-20 01:41:30.159576
Epoch:[ 166 17 ] loss: 0.3534959852695465 2022-07-20 01:41:30.577275
Epoch:[ 166 18 ] loss: 0.35578709840774536 2022-07-20 01:41:30.993677
Epoch:[ 166 19 ] loss: 0.354324609041214 2022-07-20 01:41:31.407806
Training_Epoch:[ 166 ] Training_loss: 0.3541351094841957 2022-07-20 01:41:31.408581
learning rate:  7.425108623606391e-05
netparams have been saved once 166
val: 1 0.4120705723762512
val: 2 0.42144298553466797
val: 3 0.40558186173439026
val: 4 0.4111047685146332
val: 5 0.41604480147361755
val: 6 0.4139576256275177
val: 7 0.411728173494339
val: 8 0.408083438873291
val: 9 0.4195225238800049
val: 10 0.40598875284194946
val: 11 0.406215637922287
val: 12 0.41542667150497437
val: 13 0.4218047857284546
val: 14 0.42077872157096863
val: 15 0.4060731530189514
val: 16 0.42170289158821106
val: 17 0.4087126553058624
val: 18 0.41553398966789246
val: 19 0.415985107421875
val: 20 0.41247114539146423
val_Epoch:[ 166 ] val_loss: 0.41351151317358015 2022-07-20 01:41:34.652524
start training 2022-07-20 01:41:34.756201
Epoch:[ 167 0 ] loss: 0.3537777364253998 2022-07-20 01:41:48.588027
Epoch:[ 167 1 ] loss: 0.3537997007369995 2022-07-20 01:41:49.004424
Epoch:[ 167 2 ] loss: 0.35417410731315613 2022-07-20 01:41:49.417287
Epoch:[ 167 3 ] loss: 0.35415899753570557 2022-07-20 01:41:49.831917
Epoch:[ 167 4 ] loss: 0.35449478030204773 2022-07-20 01:41:50.245760
Epoch:[ 167 5 ] loss: 0.3546082675457001 2022-07-20 01:41:50.660712
Epoch:[ 167 6 ] loss: 0.3545684218406677 2022-07-20 01:41:51.073291
Epoch:[ 167 7 ] loss: 0.354157954454422 2022-07-20 01:41:51.487188
Epoch:[ 167 8 ] loss: 0.35403528809547424 2022-07-20 01:41:51.899998
Epoch:[ 167 9 ] loss: 0.35388699173927307 2022-07-20 01:41:52.315837
Epoch:[ 167 10 ] loss: 0.3543635308742523 2022-07-20 01:41:52.731162
Epoch:[ 167 11 ] loss: 0.35478439927101135 2022-07-20 01:41:53.145345
Epoch:[ 167 12 ] loss: 0.35390225052833557 2022-07-20 01:41:53.555229
Epoch:[ 167 13 ] loss: 0.35355344414711 2022-07-20 01:41:53.963784
Epoch:[ 167 14 ] loss: 0.3547112047672272 2022-07-20 01:41:54.378399
Epoch:[ 167 15 ] loss: 0.35349443554878235 2022-07-20 01:41:54.791463
Epoch:[ 167 16 ] loss: 0.35518550872802734 2022-07-20 01:42:00.291774
Epoch:[ 167 17 ] loss: 0.35461491346359253 2022-07-20 01:42:00.706660
Epoch:[ 167 18 ] loss: 0.353740930557251 2022-07-20 01:42:01.118438
Epoch:[ 167 19 ] loss: 0.35450661182403564 2022-07-20 01:42:01.531931
Training_Epoch:[ 167 ] Training_loss: 0.35422597378492354 2022-07-20 01:42:01.532712
learning rate:  7.425108623606391e-05
val: 1 0.41678521037101746
val: 2 0.41753336787223816
val: 3 0.4183829426765442
val: 4 0.4102063477039337
val: 5 0.4114300608634949
val: 6 0.41399243474006653
val: 7 0.40380504727363586
val: 8 0.4202861487865448
val: 9 0.40954646468162537
val: 10 0.4098069369792938
val: 11 0.41224533319473267
val: 12 0.41458556056022644
val: 13 0.41945376992225647
val: 14 0.4145493507385254
val: 15 0.41413629055023193
val: 16 0.4149285554885864
val: 17 0.42183685302734375
val: 18 0.407670259475708
val: 19 0.42211541533470154
val: 20 0.4212963283061981
val_Epoch:[ 167 ] val_loss: 0.4147296339273453 2022-07-20 01:42:04.720927
start training 2022-07-20 01:42:04.827572
Epoch:[ 168 0 ] loss: 0.3530493676662445 2022-07-20 01:42:18.810972
Epoch:[ 168 1 ] loss: 0.3537880480289459 2022-07-20 01:42:19.224457
Epoch:[ 168 2 ] loss: 0.3533971905708313 2022-07-20 01:42:19.634015
Epoch:[ 168 3 ] loss: 0.35352692008018494 2022-07-20 01:42:20.049507
Epoch:[ 168 4 ] loss: 0.35435569286346436 2022-07-20 01:42:20.463908
Epoch:[ 168 5 ] loss: 0.35439741611480713 2022-07-20 01:42:20.877645
Epoch:[ 168 6 ] loss: 0.3551062047481537 2022-07-20 01:42:21.291553
Epoch:[ 168 7 ] loss: 0.3541915714740753 2022-07-20 01:42:21.701135
Epoch:[ 168 8 ] loss: 0.35357871651649475 2022-07-20 01:42:22.115889
Epoch:[ 168 9 ] loss: 0.35576388239860535 2022-07-20 01:42:22.525218
Epoch:[ 168 10 ] loss: 0.3544449210166931 2022-07-20 01:42:22.938463
Epoch:[ 168 11 ] loss: 0.35590189695358276 2022-07-20 01:42:23.354476
Epoch:[ 168 12 ] loss: 0.35494211316108704 2022-07-20 01:42:23.770056
Epoch:[ 168 13 ] loss: 0.35412999987602234 2022-07-20 01:42:24.185655
Epoch:[ 168 14 ] loss: 0.3534959852695465 2022-07-20 01:42:24.601322
Epoch:[ 168 15 ] loss: 0.35395514965057373 2022-07-20 01:42:25.016328
Epoch:[ 168 16 ] loss: 0.35467565059661865 2022-07-20 01:42:30.365614
Epoch:[ 168 17 ] loss: 0.35440659523010254 2022-07-20 01:42:30.779017
Epoch:[ 168 18 ] loss: 0.35402247309684753 2022-07-20 01:42:31.195544
Epoch:[ 168 19 ] loss: 0.3541374206542969 2022-07-20 01:42:31.608062
Training_Epoch:[ 168 ] Training_loss: 0.3542633607983589 2022-07-20 01:42:31.608741
learning rate:  7.425108623606391e-05
netparams have been saved once 168
val: 1 0.40887293219566345
val: 2 0.43697816133499146
val: 3 0.416304349899292
val: 4 0.4109451174736023
val: 5 0.4153613746166229
val: 6 0.4147275984287262
val: 7 0.414688378572464
val: 8 0.4231961965560913
val: 9 0.41015878319740295
val: 10 0.41092532873153687
val: 11 0.4181809425354004
val: 12 0.4141920506954193
val: 13 0.4189404249191284
val: 14 0.4128895699977875
val: 15 0.412157267332077
val: 16 0.4080621898174286
val: 17 0.40738391876220703
val: 18 0.4145640432834625
val: 19 0.41741642355918884
val: 20 0.41466227173805237
val_Epoch:[ 168 ] val_loss: 0.41503036618232725 2022-07-20 01:42:34.898941
start training 2022-07-20 01:42:35.005282
Epoch:[ 169 0 ] loss: 0.3542219400405884 2022-07-20 01:42:49.055233
Epoch:[ 169 1 ] loss: 0.3550065755844116 2022-07-20 01:42:49.470290
Epoch:[ 169 2 ] loss: 0.3547584116458893 2022-07-20 01:42:49.886144
Epoch:[ 169 3 ] loss: 0.3541206419467926 2022-07-20 01:42:50.295544
Epoch:[ 169 4 ] loss: 0.35319241881370544 2022-07-20 01:42:50.710192
Epoch:[ 169 5 ] loss: 0.3531452715396881 2022-07-20 01:42:51.126837
Epoch:[ 169 6 ] loss: 0.3549255430698395 2022-07-20 01:42:51.542639
Epoch:[ 169 7 ] loss: 0.35420411825180054 2022-07-20 01:42:51.952071
Epoch:[ 169 8 ] loss: 0.3540521264076233 2022-07-20 01:42:52.365413
Epoch:[ 169 9 ] loss: 0.3534446060657501 2022-07-20 01:42:52.780216
Epoch:[ 169 10 ] loss: 0.3551863729953766 2022-07-20 01:42:53.193646
Epoch:[ 169 11 ] loss: 0.35414713621139526 2022-07-20 01:42:53.607816
Epoch:[ 169 12 ] loss: 0.35396674275398254 2022-07-20 01:42:54.022440
Epoch:[ 169 13 ] loss: 0.354562908411026 2022-07-20 01:42:54.433046
Epoch:[ 169 14 ] loss: 0.3537248969078064 2022-07-20 01:42:54.846833
Epoch:[ 169 15 ] loss: 0.3551066815853119 2022-07-20 01:42:55.260414
Epoch:[ 169 16 ] loss: 0.3540288805961609 2022-07-20 01:43:00.282896
Epoch:[ 169 17 ] loss: 0.35450729727745056 2022-07-20 01:43:00.691244
Epoch:[ 169 18 ] loss: 0.3534625172615051 2022-07-20 01:43:01.113135
Epoch:[ 169 19 ] loss: 0.35389775037765503 2022-07-20 01:43:01.525498
Training_Epoch:[ 169 ] Training_loss: 0.35418314188718797 2022-07-20 01:43:01.526242
learning rate:  7.425108623606391e-05
val: 1 0.40476566553115845
val: 2 0.4185328483581543
val: 3 0.40714070200920105
val: 4 0.4179724454879761
val: 5 0.4117002785205841
val: 6 0.4256523549556732
val: 7 0.41242167353630066
val: 8 0.41995471715927124
val: 9 0.4074477255344391
val: 10 0.41233956813812256
val: 11 0.412898987531662
val: 12 0.41921982169151306
val: 13 0.4091181457042694
val: 14 0.4024003744125366
val: 15 0.40272846817970276
val: 16 0.41498005390167236
val: 17 0.4027121067047119
val: 18 0.4202010929584503
val: 19 0.4192052185535431
val: 20 0.4090891182422638
val_Epoch:[ 169 ] val_loss: 0.4125240683555603 2022-07-20 01:43:04.735933
start training 2022-07-20 01:43:04.843313
Epoch:[ 170 0 ] loss: 0.35318267345428467 2022-07-20 01:43:18.414585
Epoch:[ 170 1 ] loss: 0.35481247305870056 2022-07-20 01:43:19.140859
Epoch:[ 170 2 ] loss: 0.3546159267425537 2022-07-20 01:43:19.557728
Epoch:[ 170 3 ] loss: 0.35397642850875854 2022-07-20 01:43:19.972452
Epoch:[ 170 4 ] loss: 0.35378679633140564 2022-07-20 01:43:20.381906
Epoch:[ 170 5 ] loss: 0.35367387533187866 2022-07-20 01:43:20.794836
Epoch:[ 170 6 ] loss: 0.35380804538726807 2022-07-20 01:43:21.209484
Epoch:[ 170 7 ] loss: 0.35504353046417236 2022-07-20 01:43:21.627142
Epoch:[ 170 8 ] loss: 0.35329991579055786 2022-07-20 01:43:22.040787
Epoch:[ 170 9 ] loss: 0.3542299270629883 2022-07-20 01:43:22.455668
Epoch:[ 170 10 ] loss: 0.35419100522994995 2022-07-20 01:43:22.871652
Epoch:[ 170 11 ] loss: 0.35355088114738464 2022-07-20 01:43:23.285823
Epoch:[ 170 12 ] loss: 0.3548346757888794 2022-07-20 01:43:23.698606
Epoch:[ 170 13 ] loss: 0.3525761663913727 2022-07-20 01:43:24.109140
Epoch:[ 170 14 ] loss: 0.3539246618747711 2022-07-20 01:43:24.524250
Epoch:[ 170 15 ] loss: 0.35549595952033997 2022-07-20 01:43:24.937668
Epoch:[ 170 16 ] loss: 0.35361790657043457 2022-07-20 01:43:30.365297
Epoch:[ 170 17 ] loss: 0.35606124997138977 2022-07-20 01:43:30.780664
Epoch:[ 170 18 ] loss: 0.3538411855697632 2022-07-20 01:43:31.191015
Epoch:[ 170 19 ] loss: 0.3557959198951721 2022-07-20 01:43:31.604601
Training_Epoch:[ 170 ] Training_loss: 0.3542159602046013 2022-07-20 01:43:31.605329
learning rate:  7.425108623606391e-05
netparams have been saved once 170
val: 1 0.41526180505752563
val: 2 0.41448965668678284
val: 3 0.4181502163410187
val: 4 0.4203833341598511
val: 5 0.41282111406326294
val: 6 0.40472814440727234
val: 7 0.42346128821372986
val: 8 0.41071459650993347
val: 9 0.4133223593235016
val: 10 0.41267135739326477
val: 11 0.41093412041664124
val: 12 0.4131089448928833
val: 13 0.41385841369628906
val: 14 0.4161268174648285
val: 15 0.40829503536224365
val: 16 0.42043089866638184
val: 17 0.41612347960472107
val: 18 0.41374003887176514
val: 19 0.4090447425842285
val: 20 0.4097633361816406
val_Epoch:[ 170 ] val_loss: 0.4138714849948883 2022-07-20 01:43:34.813011
start training 2022-07-20 01:43:34.921124
Epoch:[ 171 0 ] loss: 0.3538723587989807 2022-07-20 01:43:48.908310
Epoch:[ 171 1 ] loss: 0.35230815410614014 2022-07-20 01:43:49.346323
Epoch:[ 171 2 ] loss: 0.3537112772464752 2022-07-20 01:43:49.760178
Epoch:[ 171 3 ] loss: 0.35370150208473206 2022-07-20 01:43:50.173930
Epoch:[ 171 4 ] loss: 0.35468828678131104 2022-07-20 01:43:50.586310
Epoch:[ 171 5 ] loss: 0.3535176217556 2022-07-20 01:43:51.001836
Epoch:[ 171 6 ] loss: 0.35368889570236206 2022-07-20 01:43:51.415838
Epoch:[ 171 7 ] loss: 0.3542066216468811 2022-07-20 01:43:51.829629
Epoch:[ 171 8 ] loss: 0.354136198759079 2022-07-20 01:43:52.249126
Epoch:[ 171 9 ] loss: 0.3530350923538208 2022-07-20 01:43:52.666371
Epoch:[ 171 10 ] loss: 0.3526918888092041 2022-07-20 01:43:53.083860
Epoch:[ 171 11 ] loss: 0.35424885153770447 2022-07-20 01:43:53.496659
Epoch:[ 171 12 ] loss: 0.3541163206100464 2022-07-20 01:43:53.908597
Epoch:[ 171 13 ] loss: 0.3548067510128021 2022-07-20 01:43:54.320390
Epoch:[ 171 14 ] loss: 0.35418716073036194 2022-07-20 01:43:54.734148
Epoch:[ 171 15 ] loss: 0.3531399071216583 2022-07-20 01:43:55.147635
Epoch:[ 171 16 ] loss: 0.35425400733947754 2022-07-20 01:44:00.850350
Epoch:[ 171 17 ] loss: 0.3549409806728363 2022-07-20 01:44:01.266540
Epoch:[ 171 18 ] loss: 0.3541933596134186 2022-07-20 01:44:01.679883
Epoch:[ 171 19 ] loss: 0.3537577986717224 2022-07-20 01:44:02.097824
Training_Epoch:[ 171 ] Training_loss: 0.3538601517677307 2022-07-20 01:44:02.098711
learning rate:  6.311342330065433e-05
val: 1 0.4235450327396393
val: 2 0.41089314222335815
val: 3 0.41265377402305603
val: 4 0.4149981141090393
val: 5 0.41063353419303894
val: 6 0.4231365919113159
val: 7 0.4048411250114441
val: 8 0.41276660561561584
val: 9 0.3984292149543762
val: 10 0.4043180048465729
val: 11 0.403793603181839
val: 12 0.4104677438735962
val: 13 0.4102308452129364
val: 14 0.42021942138671875
val: 15 0.41647636890411377
val: 16 0.42047959566116333
val: 17 0.40910589694976807
val: 18 0.4080279767513275
val: 19 0.4289439618587494
val: 20 0.4139527678489685
val_Epoch:[ 171 ] val_loss: 0.4128956660628319 2022-07-20 01:44:05.331320
start training 2022-07-20 01:44:05.437660
Epoch:[ 172 0 ] loss: 0.35446029901504517 2022-07-20 01:44:19.858736
Epoch:[ 172 1 ] loss: 0.35364964604377747 2022-07-20 01:44:20.273823
Epoch:[ 172 2 ] loss: 0.3531903922557831 2022-07-20 01:44:20.689572
Epoch:[ 172 3 ] loss: 0.35295143723487854 2022-07-20 01:44:21.103987
Epoch:[ 172 4 ] loss: 0.35406044125556946 2022-07-20 01:44:21.517438
Epoch:[ 172 5 ] loss: 0.3530704379081726 2022-07-20 01:44:21.933175
Epoch:[ 172 6 ] loss: 0.3540641665458679 2022-07-20 01:44:22.346845
Epoch:[ 172 7 ] loss: 0.35546690225601196 2022-07-20 01:44:22.762582
Epoch:[ 172 8 ] loss: 0.3547040820121765 2022-07-20 01:44:23.174463
Epoch:[ 172 9 ] loss: 0.3531849980354309 2022-07-20 01:44:23.588883
Epoch:[ 172 10 ] loss: 0.3539462983608246 2022-07-20 01:44:23.998724
Epoch:[ 172 11 ] loss: 0.3539429306983948 2022-07-20 01:44:24.412947
Epoch:[ 172 12 ] loss: 0.355175644159317 2022-07-20 01:44:24.826878
Epoch:[ 172 13 ] loss: 0.3534288704395294 2022-07-20 01:44:25.241313
Epoch:[ 172 14 ] loss: 0.35335850715637207 2022-07-20 01:44:25.658669
Epoch:[ 172 15 ] loss: 0.35399627685546875 2022-07-20 01:44:26.074854
Epoch:[ 172 16 ] loss: 0.35433170199394226 2022-07-20 01:44:31.474920
Epoch:[ 172 17 ] loss: 0.35466352105140686 2022-07-20 01:44:31.883490
Epoch:[ 172 18 ] loss: 0.35460904240608215 2022-07-20 01:44:32.307222
Epoch:[ 172 19 ] loss: 0.3535343408584595 2022-07-20 01:44:32.724042
Training_Epoch:[ 172 ] Training_loss: 0.35398949682712555 2022-07-20 01:44:32.724816
learning rate:  6.311342330065433e-05
netparams have been saved once 172
val: 1 0.4158240258693695
val: 2 0.4090336859226227
val: 3 0.4161231517791748
val: 4 0.4244479238986969
val: 5 0.41148439049720764
val: 6 0.4237858057022095
val: 7 0.40829259157180786
val: 8 0.42302724719047546
val: 9 0.4119587540626526
val: 10 0.42152339220046997
val: 11 0.4041961133480072
val: 12 0.4141860604286194
val: 13 0.4112859070301056
val: 14 0.41029685735702515
val: 15 0.411318838596344
val: 16 0.398998498916626
val: 17 0.42170119285583496
val: 18 0.41971075534820557
val: 19 0.41029489040374756
val: 20 0.4107596278190613
val_Epoch:[ 172 ] val_loss: 0.41391248553991317 2022-07-20 01:44:35.986983
start training 2022-07-20 01:44:36.097747
Epoch:[ 173 0 ] loss: 0.3531181514263153 2022-07-20 01:44:50.346267
Epoch:[ 173 1 ] loss: 0.35360515117645264 2022-07-20 01:44:50.761883
Epoch:[ 173 2 ] loss: 0.3534855544567108 2022-07-20 01:44:51.177352
Epoch:[ 173 3 ] loss: 0.35447609424591064 2022-07-20 01:44:51.592224
Epoch:[ 173 4 ] loss: 0.3541393578052521 2022-07-20 01:44:52.005543
Epoch:[ 173 5 ] loss: 0.3528705835342407 2022-07-20 01:44:52.419947
Epoch:[ 173 6 ] loss: 0.35267606377601624 2022-07-20 01:44:52.835985
Epoch:[ 173 7 ] loss: 0.35301172733306885 2022-07-20 01:44:53.250085
Epoch:[ 173 8 ] loss: 0.35461968183517456 2022-07-20 01:44:53.660550
Epoch:[ 173 9 ] loss: 0.3546470105648041 2022-07-20 01:44:54.076698
Epoch:[ 173 10 ] loss: 0.35377949476242065 2022-07-20 01:44:54.491046
Epoch:[ 173 11 ] loss: 0.35459524393081665 2022-07-20 01:44:54.910425
Epoch:[ 173 12 ] loss: 0.35349246859550476 2022-07-20 01:44:55.327089
Epoch:[ 173 13 ] loss: 0.3542925715446472 2022-07-20 01:44:55.740646
Epoch:[ 173 14 ] loss: 0.3539058268070221 2022-07-20 01:44:56.154018
Epoch:[ 173 15 ] loss: 0.3531476855278015 2022-07-20 01:44:56.568622
Epoch:[ 173 16 ] loss: 0.35353508591651917 2022-07-20 01:45:01.963845
Epoch:[ 173 17 ] loss: 0.3544776737689972 2022-07-20 01:45:02.375526
Epoch:[ 173 18 ] loss: 0.3538191020488739 2022-07-20 01:45:02.793491
Epoch:[ 173 19 ] loss: 0.3542860150337219 2022-07-20 01:45:03.211730
Training_Epoch:[ 173 ] Training_loss: 0.35379902720451356 2022-07-20 01:45:03.212543
learning rate:  6.311342330065433e-05
val: 1 0.41530123353004456
val: 2 0.41384026408195496
val: 3 0.4187901020050049
val: 4 0.4178258776664734
val: 5 0.4091090261936188
val: 6 0.4233461022377014
val: 7 0.4136987030506134
val: 8 0.41622504591941833
val: 9 0.4185500144958496
val: 10 0.42026564478874207
val: 11 0.40602633357048035
val: 12 0.404047429561615
val: 13 0.4139976501464844
val: 14 0.4196864664554596
val: 15 0.41642364859580994
val: 16 0.40616464614868164
val: 17 0.41459935903549194
val: 18 0.41065794229507446
val: 19 0.4106528162956238
val: 20 0.4093016982078552
val_Epoch:[ 173 ] val_loss: 0.4139255002140999 2022-07-20 01:45:06.376109
start training 2022-07-20 01:45:06.482582
Epoch:[ 174 0 ] loss: 0.35310301184654236 2022-07-20 01:45:20.078433
Epoch:[ 174 1 ] loss: 0.35218560695648193 2022-07-20 01:45:20.512301
Epoch:[ 174 2 ] loss: 0.3540394604206085 2022-07-20 01:45:20.923159
Epoch:[ 174 3 ] loss: 0.3544345498085022 2022-07-20 01:45:21.336395
Epoch:[ 174 4 ] loss: 0.3550446331501007 2022-07-20 01:45:21.749763
Epoch:[ 174 5 ] loss: 0.3537701666355133 2022-07-20 01:45:22.163427
Epoch:[ 174 6 ] loss: 0.3531653583049774 2022-07-20 01:45:22.576110
Epoch:[ 174 7 ] loss: 0.35387080907821655 2022-07-20 01:45:22.988998
Epoch:[ 174 8 ] loss: 0.353340744972229 2022-07-20 01:45:23.400977
Epoch:[ 174 9 ] loss: 0.3544580340385437 2022-07-20 01:45:23.818418
Epoch:[ 174 10 ] loss: 0.3530152440071106 2022-07-20 01:45:24.232087
Epoch:[ 174 11 ] loss: 0.3556230068206787 2022-07-20 01:45:24.644402
Epoch:[ 174 12 ] loss: 0.35323140025138855 2022-07-20 01:45:25.057323
Epoch:[ 174 13 ] loss: 0.35291266441345215 2022-07-20 01:45:25.471436
Epoch:[ 174 14 ] loss: 0.35549119114875793 2022-07-20 01:45:25.885455
Epoch:[ 174 15 ] loss: 0.35305994749069214 2022-07-20 01:45:26.303592
Epoch:[ 174 16 ] loss: 0.354810893535614 2022-07-20 01:45:31.824009
Epoch:[ 174 17 ] loss: 0.35591432452201843 2022-07-20 01:45:32.241582
Epoch:[ 174 18 ] loss: 0.3552035093307495 2022-07-20 01:45:32.664168
Epoch:[ 174 19 ] loss: 0.3549554646015167 2022-07-20 01:45:33.079448
Training_Epoch:[ 174 ] Training_loss: 0.35408150106668473 2022-07-20 01:45:33.080288
learning rate:  6.311342330065433e-05
netparams have been saved once 174
val: 1 0.419422447681427
val: 2 0.4209439158439636
val: 3 0.420401006937027
val: 4 0.4132053852081299
val: 5 0.4093046188354492
val: 6 0.42743033170700073
val: 7 0.4101966321468353
val: 8 0.4044112265110016
val: 9 0.41586554050445557
val: 10 0.4115022122859955
val: 11 0.4072303771972656
val: 12 0.4203081727027893
val: 13 0.42653319239616394
val: 14 0.40749409794807434
val: 15 0.4050452411174774
val: 16 0.4159095883369446
val: 17 0.40042632818222046
val: 18 0.40616974234580994
val: 19 0.4173213243484497
val: 20 0.4122082591056824
val_Epoch:[ 174 ] val_loss: 0.41356648206710817 2022-07-20 01:45:36.290807
start training 2022-07-20 01:45:36.394806
Epoch:[ 175 0 ] loss: 0.3538091778755188 2022-07-20 01:45:50.542636
Epoch:[ 175 1 ] loss: 0.355752557516098 2022-07-20 01:45:50.957750
Epoch:[ 175 2 ] loss: 0.3537103235721588 2022-07-20 01:45:51.371920
Epoch:[ 175 3 ] loss: 0.3560732901096344 2022-07-20 01:45:51.786340
Epoch:[ 175 4 ] loss: 0.35455453395843506 2022-07-20 01:45:52.204414
Epoch:[ 175 5 ] loss: 0.3532794415950775 2022-07-20 01:45:52.617466
Epoch:[ 175 6 ] loss: 0.3538551330566406 2022-07-20 01:45:53.029830
Epoch:[ 175 7 ] loss: 0.35374125838279724 2022-07-20 01:45:53.443349
Epoch:[ 175 8 ] loss: 0.3539927303791046 2022-07-20 01:45:53.856013
Epoch:[ 175 9 ] loss: 0.3535674512386322 2022-07-20 01:45:54.272934
Epoch:[ 175 10 ] loss: 0.3542748987674713 2022-07-20 01:45:54.690018
Epoch:[ 175 11 ] loss: 0.35417506098747253 2022-07-20 01:45:55.102571
Epoch:[ 175 12 ] loss: 0.3538835942745209 2022-07-20 01:45:55.516448
Epoch:[ 175 13 ] loss: 0.3545548915863037 2022-07-20 01:45:55.930263
Epoch:[ 175 14 ] loss: 0.35355719923973083 2022-07-20 01:45:56.342561
Epoch:[ 175 15 ] loss: 0.35450658202171326 2022-07-20 01:45:56.755733
Epoch:[ 175 16 ] loss: 0.3540985882282257 2022-07-20 01:46:02.090438
Epoch:[ 175 17 ] loss: 0.3537735641002655 2022-07-20 01:46:02.509743
Epoch:[ 175 18 ] loss: 0.353516161441803 2022-07-20 01:46:02.925747
Epoch:[ 175 19 ] loss: 0.3534581661224365 2022-07-20 01:46:03.344206
Training_Epoch:[ 175 ] Training_loss: 0.354106730222702 2022-07-20 01:46:03.345035
learning rate:  6.311342330065433e-05
val: 1 0.41876399517059326
val: 2 0.4318385720252991
val: 3 0.4016146659851074
val: 4 0.4066295325756073
val: 5 0.41577577590942383
val: 6 0.4112717807292938
val: 7 0.43097081780433655
val: 8 0.41240599751472473
val: 9 0.4064536392688751
val: 10 0.4080689251422882
val: 11 0.41771459579467773
val: 12 0.41047582030296326
val: 13 0.40180543065071106
val: 14 0.4152339994907379
val: 15 0.40278398990631104
val: 16 0.4159245789051056
val: 17 0.4198776185512543
val: 18 0.41632524132728577
val: 19 0.41177213191986084
val: 20 0.41641175746917725
val_Epoch:[ 175 ] val_loss: 0.4136059433221817 2022-07-20 01:46:06.658291
start training 2022-07-20 01:46:06.763947
Epoch:[ 176 0 ] loss: 0.35380324721336365 2022-07-20 01:46:20.634649
Epoch:[ 176 1 ] loss: 0.35281533002853394 2022-07-20 01:46:21.050491
Epoch:[ 176 2 ] loss: 0.35405173897743225 2022-07-20 01:46:21.465534
Epoch:[ 176 3 ] loss: 0.3520469069480896 2022-07-20 01:46:21.874822
Epoch:[ 176 4 ] loss: 0.3538222908973694 2022-07-20 01:46:22.289028
Epoch:[ 176 5 ] loss: 0.353268027305603 2022-07-20 01:46:22.702636
Epoch:[ 176 6 ] loss: 0.3536624610424042 2022-07-20 01:46:23.118137
Epoch:[ 176 7 ] loss: 0.35363051295280457 2022-07-20 01:46:23.534693
Epoch:[ 176 8 ] loss: 0.35383984446525574 2022-07-20 01:46:23.947073
Epoch:[ 176 9 ] loss: 0.3537011444568634 2022-07-20 01:46:24.361857
Epoch:[ 176 10 ] loss: 0.3534752428531647 2022-07-20 01:46:24.774918
Epoch:[ 176 11 ] loss: 0.35271015763282776 2022-07-20 01:46:25.186960
Epoch:[ 176 12 ] loss: 0.35362863540649414 2022-07-20 01:46:25.601328
Epoch:[ 176 13 ] loss: 0.353224515914917 2022-07-20 01:46:26.011862
Epoch:[ 176 14 ] loss: 0.35192957520484924 2022-07-20 01:46:26.426178
Epoch:[ 176 15 ] loss: 0.3535672128200531 2022-07-20 01:46:26.839586
Epoch:[ 176 16 ] loss: 0.3536316156387329 2022-07-20 01:46:32.299310
Epoch:[ 176 17 ] loss: 0.3526589274406433 2022-07-20 01:46:32.711598
Epoch:[ 176 18 ] loss: 0.35304322838783264 2022-07-20 01:46:33.125570
Epoch:[ 176 19 ] loss: 0.3529718518257141 2022-07-20 01:46:33.544879
Training_Epoch:[ 176 ] Training_loss: 0.35327412337064745 2022-07-20 01:46:33.545645
learning rate:  6.311342330065433e-05
netparams have been saved once 176
val: 1 0.41162562370300293
val: 2 0.41486480832099915
val: 3 0.40788453817367554
val: 4 0.4082317352294922
val: 5 0.4175640940666199
val: 6 0.4069218635559082
val: 7 0.4252273440361023
val: 8 0.40526944398880005
val: 9 0.40932849049568176
val: 10 0.41275614500045776
val: 11 0.41206300258636475
val: 12 0.4075479507446289
val: 13 0.40056878328323364
val: 14 0.42480024695396423
val: 15 0.4135223925113678
val: 16 0.4176948666572571
val: 17 0.4191230237483978
val: 18 0.4108832776546478
val: 19 0.4264369010925293
val: 20 0.40377238392829895
val_Epoch:[ 176 ] val_loss: 0.4128043457865715 2022-07-20 01:46:36.773165
start training 2022-07-20 01:46:36.878623
Epoch:[ 177 0 ] loss: 0.35326117277145386 2022-07-20 01:46:51.032682
Epoch:[ 177 1 ] loss: 0.35300374031066895 2022-07-20 01:46:51.444099
Epoch:[ 177 2 ] loss: 0.35188478231430054 2022-07-20 01:46:51.853103
Epoch:[ 177 3 ] loss: 0.35258054733276367 2022-07-20 01:46:52.269003
Epoch:[ 177 4 ] loss: 0.3530031442642212 2022-07-20 01:46:52.683438
Epoch:[ 177 5 ] loss: 0.35323911905288696 2022-07-20 01:46:53.097526
Epoch:[ 177 6 ] loss: 0.3526836931705475 2022-07-20 01:46:53.512657
Epoch:[ 177 7 ] loss: 0.35332411527633667 2022-07-20 01:46:53.928055
Epoch:[ 177 8 ] loss: 0.3535512685775757 2022-07-20 01:46:54.341830
Epoch:[ 177 9 ] loss: 0.35279151797294617 2022-07-20 01:46:54.755220
Epoch:[ 177 10 ] loss: 0.3530133366584778 2022-07-20 01:46:55.170578
Epoch:[ 177 11 ] loss: 0.35422462224960327 2022-07-20 01:46:55.584661
Epoch:[ 177 12 ] loss: 0.35355719923973083 2022-07-20 01:46:55.998726
Epoch:[ 177 13 ] loss: 0.35368040204048157 2022-07-20 01:46:56.413232
Epoch:[ 177 14 ] loss: 0.3521505296230316 2022-07-20 01:46:56.823972
Epoch:[ 177 15 ] loss: 0.3528161346912384 2022-07-20 01:46:57.236929
Epoch:[ 177 16 ] loss: 0.3537856340408325 2022-07-20 01:47:02.720585
Epoch:[ 177 17 ] loss: 0.3536480963230133 2022-07-20 01:47:03.133654
Epoch:[ 177 18 ] loss: 0.3528774380683899 2022-07-20 01:47:03.552571
Epoch:[ 177 19 ] loss: 0.35401859879493713 2022-07-20 01:47:03.969213
Training_Epoch:[ 177 ] Training_loss: 0.35315475463867185 2022-07-20 01:47:03.969975
learning rate:  6.311342330065433e-05
val: 1 0.4105801582336426
val: 2 0.4178473651409149
val: 3 0.41181862354278564
val: 4 0.4042451083660126
val: 5 0.41235607862472534
val: 6 0.41500338912010193
val: 7 0.41259124875068665
val: 8 0.4156763255596161
val: 9 0.4023655951023102
val: 10 0.4080817699432373
val: 11 0.42512649297714233
val: 12 0.4059968888759613
val: 13 0.41537195444107056
val: 14 0.42013469338417053
val: 15 0.41051238775253296
val: 16 0.4075595736503601
val: 17 0.4044664800167084
val: 18 0.4171692430973053
val: 19 0.4104824662208557
val: 20 0.41830766201019287
val_Epoch:[ 177 ] val_loss: 0.41228467524051665 2022-07-20 01:47:07.117952
start training 2022-07-20 01:47:07.223432
Epoch:[ 178 0 ] loss: 0.3521921634674072 2022-07-20 01:47:21.340769
Epoch:[ 178 1 ] loss: 0.353311687707901 2022-07-20 01:47:21.758767
Epoch:[ 178 2 ] loss: 0.35126692056655884 2022-07-20 01:47:22.173351
Epoch:[ 178 3 ] loss: 0.35296016931533813 2022-07-20 01:47:22.588330
Epoch:[ 178 4 ] loss: 0.3524167239665985 2022-07-20 01:47:23.001758
Epoch:[ 178 5 ] loss: 0.35365504026412964 2022-07-20 01:47:23.415530
Epoch:[ 178 6 ] loss: 0.3533077836036682 2022-07-20 01:47:23.828748
Epoch:[ 178 7 ] loss: 0.35336318612098694 2022-07-20 01:47:24.241064
Epoch:[ 178 8 ] loss: 0.3527151048183441 2022-07-20 01:47:24.656255
Epoch:[ 178 9 ] loss: 0.35310062766075134 2022-07-20 01:47:25.065597
Epoch:[ 178 10 ] loss: 0.3535040020942688 2022-07-20 01:47:25.481782
Epoch:[ 178 11 ] loss: 0.35446906089782715 2022-07-20 01:47:25.897097
Epoch:[ 178 12 ] loss: 0.35287177562713623 2022-07-20 01:47:26.311734
Epoch:[ 178 13 ] loss: 0.3550962507724762 2022-07-20 01:47:26.723269
Epoch:[ 178 14 ] loss: 0.35331496596336365 2022-07-20 01:47:27.138852
Epoch:[ 178 15 ] loss: 0.3527723252773285 2022-07-20 01:47:27.556537
Epoch:[ 178 16 ] loss: 0.3541516959667206 2022-07-20 01:47:32.737137
Epoch:[ 178 17 ] loss: 0.3541727066040039 2022-07-20 01:47:33.145721
Epoch:[ 178 18 ] loss: 0.352945476770401 2022-07-20 01:47:33.565785
Epoch:[ 178 19 ] loss: 0.3537940979003906 2022-07-20 01:47:33.977968
Training_Epoch:[ 178 ] Training_loss: 0.35326908826828 2022-07-20 01:47:33.978664
learning rate:  6.311342330065433e-05
netparams have been saved once 178
val: 1 0.40064817667007446
val: 2 0.4159158170223236
val: 3 0.4240904450416565
val: 4 0.41253504157066345
val: 5 0.413644939661026
val: 6 0.40205106139183044
val: 7 0.4226452708244324
val: 8 0.4162636697292328
val: 9 0.41778793931007385
val: 10 0.404745489358902
val: 11 0.4150088429450989
val: 12 0.4250776469707489
val: 13 0.40363699197769165
val: 14 0.41784384846687317
val: 15 0.4240702986717224
val: 16 0.418953537940979
val: 17 0.41222676634788513
val: 18 0.4152352809906006
val: 19 0.41138139367103577
val: 20 0.4113335609436035
val_Epoch:[ 178 ] val_loss: 0.41425480097532275 2022-07-20 01:47:37.183356
start training 2022-07-20 01:47:37.289736
Epoch:[ 179 0 ] loss: 0.35197439789772034 2022-07-20 01:47:50.947206
Epoch:[ 179 1 ] loss: 0.3531641662120819 2022-07-20 01:47:51.777698
Epoch:[ 179 2 ] loss: 0.3530158996582031 2022-07-20 01:47:52.194220
Epoch:[ 179 3 ] loss: 0.3526996970176697 2022-07-20 01:47:52.607689
Epoch:[ 179 4 ] loss: 0.35352152585983276 2022-07-20 01:47:53.016199
Epoch:[ 179 5 ] loss: 0.3527713418006897 2022-07-20 01:47:53.430010
Epoch:[ 179 6 ] loss: 0.35312992334365845 2022-07-20 01:47:53.844436
Epoch:[ 179 7 ] loss: 0.3531712293624878 2022-07-20 01:47:54.258359
Epoch:[ 179 8 ] loss: 0.35184505581855774 2022-07-20 01:47:54.672863
Epoch:[ 179 9 ] loss: 0.35368812084198 2022-07-20 01:47:55.090679
Epoch:[ 179 10 ] loss: 0.3527302145957947 2022-07-20 01:47:55.509158
Epoch:[ 179 11 ] loss: 0.3521166443824768 2022-07-20 01:47:55.924549
Epoch:[ 179 12 ] loss: 0.35230395197868347 2022-07-20 01:47:56.333808
Epoch:[ 179 13 ] loss: 0.354480504989624 2022-07-20 01:47:56.749223
Epoch:[ 179 14 ] loss: 0.3529821038246155 2022-07-20 01:47:57.163233
Epoch:[ 179 15 ] loss: 0.3536798357963562 2022-07-20 01:47:57.578831
Epoch:[ 179 16 ] loss: 0.3522980809211731 2022-07-20 01:48:02.446078
Epoch:[ 179 17 ] loss: 0.3538976311683655 2022-07-20 01:48:03.155163
Epoch:[ 179 18 ] loss: 0.354341059923172 2022-07-20 01:48:03.574192
Epoch:[ 179 19 ] loss: 0.3542328178882599 2022-07-20 01:48:03.991628
Training_Epoch:[ 179 ] Training_loss: 0.3531022101640701 2022-07-20 01:48:03.992434
learning rate:  6.311342330065433e-05
val: 1 0.4163073003292084
val: 2 0.40894395112991333
val: 3 0.40631747245788574
val: 4 0.41905996203422546
val: 5 0.4119645953178406
val: 6 0.4082808196544647
val: 7 0.4184843599796295
val: 8 0.40758052468299866
val: 9 0.4164193272590637
val: 10 0.4076547622680664
val: 11 0.41397789120674133
val: 12 0.4245533347129822
val: 13 0.4008033275604248
val: 14 0.41745468974113464
val: 15 0.4114408791065216
val: 16 0.4130480885505676
val: 17 0.41078805923461914
val: 18 0.4127591550350189
val: 19 0.4133005440235138
val: 20 0.4044605493545532
val_Epoch:[ 179 ] val_loss: 0.4121799796819687 2022-07-20 01:48:07.177058
start training 2022-07-20 01:48:07.282745
Epoch:[ 180 0 ] loss: 0.3541596233844757 2022-07-20 01:48:20.777100
Epoch:[ 180 1 ] loss: 0.35167255997657776 2022-07-20 01:48:21.196921
Epoch:[ 180 2 ] loss: 0.3527216613292694 2022-07-20 01:48:21.660068
Epoch:[ 180 3 ] loss: 0.3545767068862915 2022-07-20 01:48:22.074221
Epoch:[ 180 4 ] loss: 0.35283374786376953 2022-07-20 01:48:22.490473
Epoch:[ 180 5 ] loss: 0.3527910113334656 2022-07-20 01:48:22.904401
Epoch:[ 180 6 ] loss: 0.35327571630477905 2022-07-20 01:48:23.315822
Epoch:[ 180 7 ] loss: 0.35323917865753174 2022-07-20 01:48:23.731878
Epoch:[ 180 8 ] loss: 0.35303938388824463 2022-07-20 01:48:24.142697
Epoch:[ 180 9 ] loss: 0.35351377725601196 2022-07-20 01:48:24.555284
Epoch:[ 180 10 ] loss: 0.35297349095344543 2022-07-20 01:48:24.969138
Epoch:[ 180 11 ] loss: 0.3526041805744171 2022-07-20 01:48:25.381112
Epoch:[ 180 12 ] loss: 0.35259634256362915 2022-07-20 01:48:25.793139
Epoch:[ 180 13 ] loss: 0.3537598252296448 2022-07-20 01:48:26.204922
Epoch:[ 180 14 ] loss: 0.35280197858810425 2022-07-20 01:48:26.616092
Epoch:[ 180 15 ] loss: 0.35372766852378845 2022-07-20 01:48:27.026699
Epoch:[ 180 16 ] loss: 0.353325217962265 2022-07-20 01:48:32.608873
Epoch:[ 180 17 ] loss: 0.35393911600112915 2022-07-20 01:48:33.026807
Epoch:[ 180 18 ] loss: 0.353549063205719 2022-07-20 01:48:33.439871
Epoch:[ 180 19 ] loss: 0.35392308235168457 2022-07-20 01:48:33.858491
Training_Epoch:[ 180 ] Training_loss: 0.3532511666417122 2022-07-20 01:48:33.859181
learning rate:  6.311342330065433e-05
netparams have been saved once 180
val: 1 0.4266369044780731
val: 2 0.4166527986526489
val: 3 0.4130703806877136
val: 4 0.42690151929855347
val: 5 0.40417715907096863
val: 6 0.406533807516098
val: 7 0.41709789633750916
val: 8 0.4139971435070038
val: 9 0.42364421486854553
val: 10 0.4094747006893158
val: 11 0.4203956723213196
val: 12 0.428414911031723
val: 13 0.412645161151886
val: 14 0.4119127690792084
val: 15 0.42558181285858154
val: 16 0.4112265110015869
val: 17 0.41302403807640076
val: 18 0.4080958962440491
val: 19 0.4229738712310791
val: 20 0.4051675498485565
val_Epoch:[ 180 ] val_loss: 0.41588123589754106 2022-07-20 01:48:37.217404
start training 2022-07-20 01:48:37.323357
Epoch:[ 181 0 ] loss: 0.35167625546455383 2022-07-20 01:48:50.975462
Epoch:[ 181 1 ] loss: 0.3529829680919647 2022-07-20 01:48:51.408767
Epoch:[ 181 2 ] loss: 0.3532249629497528 2022-07-20 01:48:51.820352
Epoch:[ 181 3 ] loss: 0.35383549332618713 2022-07-20 01:48:52.233744
Epoch:[ 181 4 ] loss: 0.3534318506717682 2022-07-20 01:48:52.646106
Epoch:[ 181 5 ] loss: 0.3540635406970978 2022-07-20 01:48:53.057648
Epoch:[ 181 6 ] loss: 0.3535366654396057 2022-07-20 01:48:53.476652
Epoch:[ 181 7 ] loss: 0.35196858644485474 2022-07-20 01:48:53.889028
Epoch:[ 181 8 ] loss: 0.3529949188232422 2022-07-20 01:48:54.300326
Epoch:[ 181 9 ] loss: 0.3525319993495941 2022-07-20 01:48:54.712963
Epoch:[ 181 10 ] loss: 0.35303041338920593 2022-07-20 01:48:55.126471
Epoch:[ 181 11 ] loss: 0.35204362869262695 2022-07-20 01:48:55.539601
Epoch:[ 181 12 ] loss: 0.3527315855026245 2022-07-20 01:48:55.952447
Epoch:[ 181 13 ] loss: 0.35287031531333923 2022-07-20 01:48:56.363394
Epoch:[ 181 14 ] loss: 0.3533172607421875 2022-07-20 01:48:56.782243
Epoch:[ 181 15 ] loss: 0.3514487147331238 2022-07-20 01:48:57.194269
Epoch:[ 181 16 ] loss: 0.3534405529499054 2022-07-20 01:49:02.697223
Epoch:[ 181 17 ] loss: 0.35289284586906433 2022-07-20 01:49:03.117536
Epoch:[ 181 18 ] loss: 0.3531980812549591 2022-07-20 01:49:03.538465
Epoch:[ 181 19 ] loss: 0.3532683253288269 2022-07-20 01:49:03.949955
Training_Epoch:[ 181 ] Training_loss: 0.35292444825172425 2022-07-20 01:49:03.950626
learning rate:  5.3646409805556176e-05
val: 1 0.42310455441474915
val: 2 0.42522308230400085
val: 3 0.4122719466686249
val: 4 0.42545580863952637
val: 5 0.4082314074039459
val: 6 0.4119502007961273
val: 7 0.4120676815509796
val: 8 0.41449055075645447
val: 9 0.420509934425354
val: 10 0.4189017415046692
val: 11 0.41328054666519165
val: 12 0.4172665476799011
val: 13 0.41413193941116333
val: 14 0.4118889570236206
val: 15 0.40586763620376587
val: 16 0.4191804528236389
val: 17 0.418950617313385
val: 18 0.4214029908180237
val: 19 0.4193940758705139
val: 20 0.4139217138290405
val_Epoch:[ 181 ] val_loss: 0.4163746193051338 2022-07-20 01:49:07.143482
start training 2022-07-20 01:49:07.251050
Epoch:[ 182 0 ] loss: 0.35344764590263367 2022-07-20 01:49:21.594321
Epoch:[ 182 1 ] loss: 0.3529013395309448 2022-07-20 01:49:22.006679
Epoch:[ 182 2 ] loss: 0.35285210609436035 2022-07-20 01:49:22.419403
Epoch:[ 182 3 ] loss: 0.3533088266849518 2022-07-20 01:49:22.834880
Epoch:[ 182 4 ] loss: 0.35202887654304504 2022-07-20 01:49:23.248197
Epoch:[ 182 5 ] loss: 0.352836936712265 2022-07-20 01:49:23.666494
Epoch:[ 182 6 ] loss: 0.3532806932926178 2022-07-20 01:49:24.080001
Epoch:[ 182 7 ] loss: 0.35262638330459595 2022-07-20 01:49:24.493174
Epoch:[ 182 8 ] loss: 0.352294921875 2022-07-20 01:49:24.905617
Epoch:[ 182 9 ] loss: 0.35307955741882324 2022-07-20 01:49:25.318490
Epoch:[ 182 10 ] loss: 0.352209210395813 2022-07-20 01:49:25.730838
Epoch:[ 182 11 ] loss: 0.35250207781791687 2022-07-20 01:49:26.150356
Epoch:[ 182 12 ] loss: 0.353524386882782 2022-07-20 01:49:26.564629
Epoch:[ 182 13 ] loss: 0.3523460924625397 2022-07-20 01:49:26.979726
Epoch:[ 182 14 ] loss: 0.3522994816303253 2022-07-20 01:49:27.400221
Epoch:[ 182 15 ] loss: 0.3520165979862213 2022-07-20 01:49:27.813492
Epoch:[ 182 16 ] loss: 0.35242560505867004 2022-07-20 01:49:32.661061
Epoch:[ 182 17 ] loss: 0.35234978795051575 2022-07-20 01:49:33.171491
Epoch:[ 182 18 ] loss: 0.3529549241065979 2022-07-20 01:49:33.598353
Epoch:[ 182 19 ] loss: 0.35457199811935425 2022-07-20 01:49:34.013679
Training_Epoch:[ 182 ] Training_loss: 0.35279287248849867 2022-07-20 01:49:34.014404
learning rate:  5.3646409805556176e-05
netparams have been saved once 182
val: 1 0.4226588308811188
val: 2 0.4300990402698517
val: 3 0.4148404002189636
val: 4 0.4068317115306854
val: 5 0.4172374904155731
val: 6 0.4177064597606659
val: 7 0.4112139046192169
val: 8 0.40921467542648315
val: 9 0.4098854064941406
val: 10 0.41481292247772217
val: 11 0.41776445508003235
val: 12 0.41443100571632385
val: 13 0.4273187518119812
val: 14 0.4233415424823761
val: 15 0.41459909081459045
val: 16 0.4064357578754425
val: 17 0.4234834909439087
val: 18 0.41255128383636475
val: 19 0.4168539345264435
val: 20 0.423319548368454
val_Epoch:[ 182 ] val_loss: 0.4167299851775169 2022-07-20 01:49:37.224631
start training 2022-07-20 01:49:37.332227
Epoch:[ 183 0 ] loss: 0.35260260105133057 2022-07-20 01:49:50.965422
Epoch:[ 183 1 ] loss: 0.3527432680130005 2022-07-20 01:49:51.524012
Epoch:[ 183 2 ] loss: 0.3513466715812683 2022-07-20 01:49:51.938508
Epoch:[ 183 3 ] loss: 0.3515220284461975 2022-07-20 01:49:52.351406
Epoch:[ 183 4 ] loss: 0.35215404629707336 2022-07-20 01:49:52.770241
Epoch:[ 183 5 ] loss: 0.3529234826564789 2022-07-20 01:49:53.185137
Epoch:[ 183 6 ] loss: 0.3523443341255188 2022-07-20 01:49:53.599056
Epoch:[ 183 7 ] loss: 0.3527182936668396 2022-07-20 01:49:54.011489
Epoch:[ 183 8 ] loss: 0.35219043493270874 2022-07-20 01:49:54.423621
Epoch:[ 183 9 ] loss: 0.3526185154914856 2022-07-20 01:49:54.835696
Epoch:[ 183 10 ] loss: 0.35310131311416626 2022-07-20 01:49:55.248455
Epoch:[ 183 11 ] loss: 0.3521261215209961 2022-07-20 01:49:55.668135
Epoch:[ 183 12 ] loss: 0.3525161147117615 2022-07-20 01:49:56.082419
Epoch:[ 183 13 ] loss: 0.35226303339004517 2022-07-20 01:49:56.498919
Epoch:[ 183 14 ] loss: 0.3536785840988159 2022-07-20 01:49:56.912335
Epoch:[ 183 15 ] loss: 0.35249194502830505 2022-07-20 01:49:57.324135
Epoch:[ 183 16 ] loss: 0.3525576889514923 2022-07-20 01:50:03.021400
Epoch:[ 183 17 ] loss: 0.3535081446170807 2022-07-20 01:50:03.439968
Epoch:[ 183 18 ] loss: 0.35355478525161743 2022-07-20 01:50:03.854277
Epoch:[ 183 19 ] loss: 0.35347649455070496 2022-07-20 01:50:04.267806
Training_Epoch:[ 183 ] Training_loss: 0.35262189507484437 2022-07-20 01:50:04.268642
learning rate:  5.3646409805556176e-05
val: 1 0.41890469193458557
val: 2 0.42651447653770447
val: 3 0.4202308654785156
val: 4 0.41323551535606384
val: 5 0.4128589928150177
val: 6 0.410103440284729
val: 7 0.4176979660987854
val: 8 0.41252508759498596
val: 9 0.41763123869895935
val: 10 0.4142328202724457
val: 11 0.41616255044937134
val: 12 0.42352917790412903
val: 13 0.4192814230918884
val: 14 0.4165581464767456
val: 15 0.4058481454849243
val: 16 0.41546592116355896
val: 17 0.42738214135169983
val: 18 0.42973819375038147
val: 19 0.4081183969974518
val: 20 0.39771345257759094
val_Epoch:[ 183 ] val_loss: 0.41618663221597674 2022-07-20 01:50:07.475201
start training 2022-07-20 01:50:07.581436
Epoch:[ 184 0 ] loss: 0.35198256373405457 2022-07-20 01:50:21.952364
Epoch:[ 184 1 ] loss: 0.35394561290740967 2022-07-20 01:50:22.367278
Epoch:[ 184 2 ] loss: 0.35257488489151 2022-07-20 01:50:22.780210
Epoch:[ 184 3 ] loss: 0.35234007239341736 2022-07-20 01:50:23.195001
Epoch:[ 184 4 ] loss: 0.35215288400650024 2022-07-20 01:50:23.608352
Epoch:[ 184 5 ] loss: 0.35173842310905457 2022-07-20 01:50:24.022263
Epoch:[ 184 6 ] loss: 0.35240498185157776 2022-07-20 01:50:24.437284
Epoch:[ 184 7 ] loss: 0.3511466085910797 2022-07-20 01:50:24.854502
Epoch:[ 184 8 ] loss: 0.35270509123802185 2022-07-20 01:50:25.267155
Epoch:[ 184 9 ] loss: 0.35337528586387634 2022-07-20 01:50:25.680589
Epoch:[ 184 10 ] loss: 0.35277658700942993 2022-07-20 01:50:26.094908
Epoch:[ 184 11 ] loss: 0.35270634293556213 2022-07-20 01:50:26.508402
Epoch:[ 184 12 ] loss: 0.3532925844192505 2022-07-20 01:50:26.925933
Epoch:[ 184 13 ] loss: 0.35186371207237244 2022-07-20 01:50:27.341934
Epoch:[ 184 14 ] loss: 0.35166221857070923 2022-07-20 01:50:27.756368
Epoch:[ 184 15 ] loss: 0.3528815507888794 2022-07-20 01:50:28.168995
Epoch:[ 184 16 ] loss: 0.35380837321281433 2022-07-20 01:50:33.838853
Epoch:[ 184 17 ] loss: 0.35217517614364624 2022-07-20 01:50:34.252677
Epoch:[ 184 18 ] loss: 0.3526867628097534 2022-07-20 01:50:34.672069
Epoch:[ 184 19 ] loss: 0.3517281115055084 2022-07-20 01:50:35.091495
Training_Epoch:[ 184 ] Training_loss: 0.3524973914027214 2022-07-20 01:50:35.092344
learning rate:  5.3646409805556176e-05
netparams have been saved once 184
val: 1 0.4169054925441742
val: 2 0.40712764859199524
val: 3 0.4159630239009857
val: 4 0.426701158285141
val: 5 0.4096488058567047
val: 6 0.4240938127040863
val: 7 0.4154645800590515
val: 8 0.4130970239639282
val: 9 0.41729554533958435
val: 10 0.4092560112476349
val: 11 0.42021918296813965
val: 12 0.4207821488380432
val: 13 0.4262515902519226
val: 14 0.41964098811149597
val: 15 0.41080334782600403
val: 16 0.405413955450058
val: 17 0.42266446352005005
val: 18 0.41196659207344055
val: 19 0.41699299216270447
val: 20 0.4089545011520386
val_Epoch:[ 184 ] val_loss: 0.41596214324235914 2022-07-20 01:50:38.265620
start training 2022-07-20 01:50:38.368580
Epoch:[ 185 0 ] loss: 0.35205647349357605 2022-07-20 01:50:52.014534
Epoch:[ 185 1 ] loss: 0.3524826467037201 2022-07-20 01:50:52.428806
Epoch:[ 185 2 ] loss: 0.3530832529067993 2022-07-20 01:50:52.841101
Epoch:[ 185 3 ] loss: 0.3512583076953888 2022-07-20 01:50:53.253618
Epoch:[ 185 4 ] loss: 0.3530605733394623 2022-07-20 01:50:53.666345
Epoch:[ 185 5 ] loss: 0.35310497879981995 2022-07-20 01:50:54.077043
Epoch:[ 185 6 ] loss: 0.35244470834732056 2022-07-20 01:50:54.492661
Epoch:[ 185 7 ] loss: 0.35290762782096863 2022-07-20 01:50:54.907976
Epoch:[ 185 8 ] loss: 0.3521043062210083 2022-07-20 01:50:55.323181
Epoch:[ 185 9 ] loss: 0.3522151708602905 2022-07-20 01:50:55.735596
Epoch:[ 185 10 ] loss: 0.3532014489173889 2022-07-20 01:50:56.144454
Epoch:[ 185 11 ] loss: 0.35367563366889954 2022-07-20 01:50:56.557010
Epoch:[ 185 12 ] loss: 0.35155460238456726 2022-07-20 01:50:56.968986
Epoch:[ 185 13 ] loss: 0.3528512418270111 2022-07-20 01:50:57.381602
Epoch:[ 185 14 ] loss: 0.3521980941295624 2022-07-20 01:50:57.797191
Epoch:[ 185 15 ] loss: 0.3520645201206207 2022-07-20 01:50:58.211431
Epoch:[ 185 16 ] loss: 0.3523680567741394 2022-07-20 01:51:03.781815
Epoch:[ 185 17 ] loss: 0.353171706199646 2022-07-20 01:51:04.193974
Epoch:[ 185 18 ] loss: 0.35222455859184265 2022-07-20 01:51:04.608562
Epoch:[ 185 19 ] loss: 0.35335126519203186 2022-07-20 01:51:05.026643
Training_Epoch:[ 185 ] Training_loss: 0.3525689586997032 2022-07-20 01:51:05.027334
learning rate:  5.3646409805556176e-05
val: 1 0.40785127878189087
val: 2 0.4064757823944092
val: 3 0.4131617546081543
val: 4 0.42049309611320496
val: 5 0.41385185718536377
val: 6 0.4196735918521881
val: 7 0.4209550619125366
val: 8 0.4057345390319824
val: 9 0.4135402739048004
val: 10 0.4178677499294281
val: 11 0.4117280840873718
val: 12 0.4068068861961365
val: 13 0.41738343238830566
val: 14 0.41835856437683105
val: 15 0.418617844581604
val: 16 0.4131007790565491
val: 17 0.420382022857666
val: 18 0.4122264087200165
val: 19 0.41647079586982727
val: 20 0.41067880392074585
val_Epoch:[ 185 ] val_loss: 0.4142679303884506 2022-07-20 01:51:08.189859
start training 2022-07-20 01:51:08.298011
Epoch:[ 186 0 ] loss: 0.3524535596370697 2022-07-20 01:51:22.369214
Epoch:[ 186 1 ] loss: 0.3522160053253174 2022-07-20 01:51:22.792211
Epoch:[ 186 2 ] loss: 0.3519578278064728 2022-07-20 01:51:23.207062
Epoch:[ 186 3 ] loss: 0.3525024950504303 2022-07-20 01:51:23.620273
Epoch:[ 186 4 ] loss: 0.3526214361190796 2022-07-20 01:51:24.033426
Epoch:[ 186 5 ] loss: 0.3514367938041687 2022-07-20 01:51:24.446507
Epoch:[ 186 6 ] loss: 0.35320010781288147 2022-07-20 01:51:24.864942
Epoch:[ 186 7 ] loss: 0.3527638018131256 2022-07-20 01:51:25.279018
Epoch:[ 186 8 ] loss: 0.3509129583835602 2022-07-20 01:51:25.693204
Epoch:[ 186 9 ] loss: 0.35336652398109436 2022-07-20 01:51:26.106602
Epoch:[ 186 10 ] loss: 0.35175955295562744 2022-07-20 01:51:26.519052
Epoch:[ 186 11 ] loss: 0.35313084721565247 2022-07-20 01:51:26.930549
Epoch:[ 186 12 ] loss: 0.35281282663345337 2022-07-20 01:51:27.349115
Epoch:[ 186 13 ] loss: 0.35188162326812744 2022-07-20 01:51:27.761671
Epoch:[ 186 14 ] loss: 0.35295018553733826 2022-07-20 01:51:28.176031
Epoch:[ 186 15 ] loss: 0.35126766562461853 2022-07-20 01:51:28.589984
Epoch:[ 186 16 ] loss: 0.3523463010787964 2022-07-20 01:51:33.561498
Epoch:[ 186 17 ] loss: 0.3528800308704376 2022-07-20 01:51:34.263986
Epoch:[ 186 18 ] loss: 0.35220056772232056 2022-07-20 01:51:34.814342
Epoch:[ 186 19 ] loss: 0.35243508219718933 2022-07-20 01:51:35.232137
Training_Epoch:[ 186 ] Training_loss: 0.3523548096418381 2022-07-20 01:51:35.232805
learning rate:  5.3646409805556176e-05
netparams have been saved once 186
val: 1 0.4228789210319519
val: 2 0.412928968667984
val: 3 0.4176357388496399
val: 4 0.4212159514427185
val: 5 0.41455018520355225
val: 6 0.4146508276462555
val: 7 0.4189853072166443
val: 8 0.41477423906326294
val: 9 0.405516117811203
val: 10 0.4180145561695099
val: 11 0.41809582710266113
val: 12 0.4064747393131256
val: 13 0.406598299741745
val: 14 0.42839381098747253
val: 15 0.4165306091308594
val: 16 0.4240666925907135
val: 17 0.4172344207763672
val: 18 0.4115518033504486
val: 19 0.42243143916130066
val: 20 0.41574645042419434
val_Epoch:[ 186 ] val_loss: 0.4164137452840805 2022-07-20 01:51:38.430495
start training 2022-07-20 01:51:38.536828
Epoch:[ 187 0 ] loss: 0.35343924164772034 2022-07-20 01:51:52.451690
Epoch:[ 187 1 ] loss: 0.35159191489219666 2022-07-20 01:51:52.865464
Epoch:[ 187 2 ] loss: 0.352514386177063 2022-07-20 01:51:53.286292
Epoch:[ 187 3 ] loss: 0.35178446769714355 2022-07-20 01:51:53.700890
Epoch:[ 187 4 ] loss: 0.3523719310760498 2022-07-20 01:51:54.113965
Epoch:[ 187 5 ] loss: 0.35170599818229675 2022-07-20 01:51:54.528314
Epoch:[ 187 6 ] loss: 0.3529357314109802 2022-07-20 01:51:54.943371
Epoch:[ 187 7 ] loss: 0.3509480953216553 2022-07-20 01:51:55.356916
Epoch:[ 187 8 ] loss: 0.3523903787136078 2022-07-20 01:51:55.777266
Epoch:[ 187 9 ] loss: 0.3532960116863251 2022-07-20 01:51:56.192929
Epoch:[ 187 10 ] loss: 0.3522251844406128 2022-07-20 01:51:56.608145
Epoch:[ 187 11 ] loss: 0.35166239738464355 2022-07-20 01:51:57.021819
Epoch:[ 187 12 ] loss: 0.3517645299434662 2022-07-20 01:51:57.439012
Epoch:[ 187 13 ] loss: 0.35294416546821594 2022-07-20 01:51:57.852672
Epoch:[ 187 14 ] loss: 0.35221752524375916 2022-07-20 01:51:58.265712
Epoch:[ 187 15 ] loss: 0.35293182730674744 2022-07-20 01:51:58.680590
Epoch:[ 187 16 ] loss: 0.35215649008750916 2022-07-20 01:52:03.964595
Epoch:[ 187 17 ] loss: 0.3509885370731354 2022-07-20 01:52:04.378556
Epoch:[ 187 18 ] loss: 0.35425183176994324 2022-07-20 01:52:04.797867
Epoch:[ 187 19 ] loss: 0.352069228887558 2022-07-20 01:52:05.218257
Training_Epoch:[ 187 ] Training_loss: 0.35230949372053144 2022-07-20 01:52:05.218953
learning rate:  5.3646409805556176e-05
val: 1 0.41979533433914185
val: 2 0.42715248465538025
val: 3 0.41186538338661194
val: 4 0.4118894636631012
val: 5 0.4172922670841217
val: 6 0.41290244460105896
val: 7 0.4064772427082062
val: 8 0.4151013195514679
val: 9 0.42635074257850647
val: 10 0.4240359663963318
val: 11 0.4170282185077667
val: 12 0.414851576089859
val: 13 0.4178314805030823
val: 14 0.41409116983413696
val: 15 0.4114680886268616
val: 16 0.40500155091285706
val: 17 0.4298457205295563
val: 18 0.4169809818267822
val: 19 0.4161830246448517
val: 20 0.43247300386428833
val_Epoch:[ 187 ] val_loss: 0.4174308732151985 2022-07-20 01:52:08.397324
start training 2022-07-20 01:52:08.502304
Epoch:[ 188 0 ] loss: 0.352644681930542 2022-07-20 01:52:22.377706
Epoch:[ 188 1 ] loss: 0.3530871570110321 2022-07-20 01:52:22.789966
Epoch:[ 188 2 ] loss: 0.3517480790615082 2022-07-20 01:52:23.202598
Epoch:[ 188 3 ] loss: 0.3517252802848816 2022-07-20 01:52:23.617302
Epoch:[ 188 4 ] loss: 0.35189199447631836 2022-07-20 01:52:24.032163
Epoch:[ 188 5 ] loss: 0.35354653000831604 2022-07-20 01:52:24.444410
Epoch:[ 188 6 ] loss: 0.3510085344314575 2022-07-20 01:52:24.861288
Epoch:[ 188 7 ] loss: 0.3522588312625885 2022-07-20 01:52:25.274531
Epoch:[ 188 8 ] loss: 0.3528318703174591 2022-07-20 01:52:25.692787
Epoch:[ 188 9 ] loss: 0.35209062695503235 2022-07-20 01:52:26.105285
Epoch:[ 188 10 ] loss: 0.3525739908218384 2022-07-20 01:52:26.524988
Epoch:[ 188 11 ] loss: 0.35113540291786194 2022-07-20 01:52:26.937964
Epoch:[ 188 12 ] loss: 0.3532053232192993 2022-07-20 01:52:27.349881
Epoch:[ 188 13 ] loss: 0.353121280670166 2022-07-20 01:52:27.763916
Epoch:[ 188 14 ] loss: 0.35135430097579956 2022-07-20 01:52:28.177297
Epoch:[ 188 15 ] loss: 0.3519298732280731 2022-07-20 01:52:28.589201
Epoch:[ 188 16 ] loss: 0.3530382215976715 2022-07-20 01:52:34.021321
Epoch:[ 188 17 ] loss: 0.35222092270851135 2022-07-20 01:52:34.435154
Epoch:[ 188 18 ] loss: 0.35211461782455444 2022-07-20 01:52:34.863485
Epoch:[ 188 19 ] loss: 0.352634459733963 2022-07-20 01:52:35.276283
Training_Epoch:[ 188 ] Training_loss: 0.35230809897184373 2022-07-20 01:52:35.276972
learning rate:  5.3646409805556176e-05
netparams have been saved once 188
val: 1 0.42077550292015076
val: 2 0.41993585228919983
val: 3 0.4204849302768707
val: 4 0.41359251737594604
val: 5 0.4235588312149048
val: 6 0.4098922908306122
val: 7 0.41526347398757935
val: 8 0.43269142508506775
val: 9 0.4241393804550171
val: 10 0.4153187572956085
val: 11 0.40528857707977295
val: 12 0.41380175948143005
val: 13 0.4151410460472107
val: 14 0.41921326518058777
val: 15 0.4155544638633728
val: 16 0.41981157660484314
val: 17 0.413644015789032
val: 18 0.4205930531024933
val: 19 0.42458051443099976
val: 20 0.41470882296562195
val_Epoch:[ 188 ] val_loss: 0.41789950281381605 2022-07-20 01:52:38.488835
start training 2022-07-20 01:52:38.590680
Epoch:[ 189 0 ] loss: 0.3521069288253784 2022-07-20 01:52:51.913070
Epoch:[ 189 1 ] loss: 0.3524782657623291 2022-07-20 01:52:52.351818
Epoch:[ 189 2 ] loss: 0.3522152006626129 2022-07-20 01:52:52.785781
Epoch:[ 189 3 ] loss: 0.3519616425037384 2022-07-20 01:52:53.198111
Epoch:[ 189 4 ] loss: 0.3519507646560669 2022-07-20 01:52:53.612356
Epoch:[ 189 5 ] loss: 0.3533039093017578 2022-07-20 01:52:54.026650
Epoch:[ 189 6 ] loss: 0.35167425870895386 2022-07-20 01:52:54.438358
Epoch:[ 189 7 ] loss: 0.35224613547325134 2022-07-20 01:52:54.852583
Epoch:[ 189 8 ] loss: 0.35250309109687805 2022-07-20 01:52:55.264190
Epoch:[ 189 9 ] loss: 0.3520161211490631 2022-07-20 01:52:55.676969
Epoch:[ 189 10 ] loss: 0.3533519208431244 2022-07-20 01:52:56.096858
Epoch:[ 189 11 ] loss: 0.35301724076271057 2022-07-20 01:52:56.511173
Epoch:[ 189 12 ] loss: 0.3522981107234955 2022-07-20 01:52:56.925656
Epoch:[ 189 13 ] loss: 0.35242846608161926 2022-07-20 01:52:57.338327
Epoch:[ 189 14 ] loss: 0.35239842534065247 2022-07-20 01:52:57.752703
Epoch:[ 189 15 ] loss: 0.35274097323417664 2022-07-20 01:52:58.166446
Epoch:[ 189 16 ] loss: 0.35315918922424316 2022-07-20 01:53:03.299038
Epoch:[ 189 17 ] loss: 0.3526385426521301 2022-07-20 01:53:04.149800
Epoch:[ 189 18 ] loss: 0.353235125541687 2022-07-20 01:53:04.565976
Epoch:[ 189 19 ] loss: 0.3529583811759949 2022-07-20 01:53:04.985361
Training_Epoch:[ 189 ] Training_loss: 0.3525341346859932 2022-07-20 01:53:04.986008
learning rate:  5.3646409805556176e-05
val: 1 0.41645509004592896
val: 2 0.424727201461792
val: 3 0.4150221347808838
val: 4 0.42331334948539734
val: 5 0.40377381443977356
val: 6 0.41611525416374207
val: 7 0.4179002046585083
val: 8 0.4075111150741577
val: 9 0.4158320724964142
val: 10 0.41646093130111694
val: 11 0.4171638786792755
val: 12 0.4115122854709625
val: 13 0.42401453852653503
val: 14 0.40725335478782654
val: 15 0.42396894097328186
val: 16 0.4268864393234253
val: 17 0.4126225709915161
val: 18 0.41978973150253296
val: 19 0.4215081036090851
val: 20 0.4188809394836426
val_Epoch:[ 189 ] val_loss: 0.4170355975627899 2022-07-20 01:53:08.099982
start training 2022-07-20 01:53:08.203906
Epoch:[ 190 0 ] loss: 0.35282155871391296 2022-07-20 01:53:22.252050
Epoch:[ 190 1 ] loss: 0.35166221857070923 2022-07-20 01:53:22.666286
Epoch:[ 190 2 ] loss: 0.35144153237342834 2022-07-20 01:53:23.079986
Epoch:[ 190 3 ] loss: 0.3513621389865875 2022-07-20 01:53:23.492974
Epoch:[ 190 4 ] loss: 0.3532670736312866 2022-07-20 01:53:23.911105
Epoch:[ 190 5 ] loss: 0.3520958125591278 2022-07-20 01:53:24.324290
Epoch:[ 190 6 ] loss: 0.35217830538749695 2022-07-20 01:53:24.745119
Epoch:[ 190 7 ] loss: 0.3513987064361572 2022-07-20 01:53:25.165857
Epoch:[ 190 8 ] loss: 0.35211533308029175 2022-07-20 01:53:25.577908
Epoch:[ 190 9 ] loss: 0.3517220616340637 2022-07-20 01:53:25.990398
Epoch:[ 190 10 ] loss: 0.3526916801929474 2022-07-20 01:53:26.403294
Epoch:[ 190 11 ] loss: 0.35230693221092224 2022-07-20 01:53:26.816456
Epoch:[ 190 12 ] loss: 0.35352417826652527 2022-07-20 01:53:27.230394
Epoch:[ 190 13 ] loss: 0.35329508781433105 2022-07-20 01:53:27.644330
Epoch:[ 190 14 ] loss: 0.35249659419059753 2022-07-20 01:53:28.056257
Epoch:[ 190 15 ] loss: 0.3520369529724121 2022-07-20 01:53:28.468383
Epoch:[ 190 16 ] loss: 0.3521834909915924 2022-07-20 01:53:33.982220
Epoch:[ 190 17 ] loss: 0.35231512784957886 2022-07-20 01:53:34.400694
Epoch:[ 190 18 ] loss: 0.35350653529167175 2022-07-20 01:53:34.816533
Epoch:[ 190 19 ] loss: 0.3533191680908203 2022-07-20 01:53:35.237078
Training_Epoch:[ 190 ] Training_loss: 0.35238702446222303 2022-07-20 01:53:35.237767
learning rate:  5.3646409805556176e-05
netparams have been saved once 190
val: 1 0.4249930679798126
val: 2 0.4092974364757538
val: 3 0.42611953616142273
val: 4 0.42102888226509094
val: 5 0.40560382604599
val: 6 0.4140789210796356
val: 7 0.4135223925113678
val: 8 0.40860775113105774
val: 9 0.41185304522514343
val: 10 0.4110197126865387
val: 11 0.4208877682685852
val: 12 0.42682987451553345
val: 13 0.41425907611846924
val: 14 0.4058411121368408
val: 15 0.41467007994651794
val: 16 0.40918833017349243
val: 17 0.40948522090911865
val: 18 0.4216405153274536
val: 19 0.4223404824733734
val: 20 0.40977922081947327
val_Epoch:[ 190 ] val_loss: 0.41505231261253356 2022-07-20 01:53:38.409193
start training 2022-07-20 01:53:38.511743
Epoch:[ 191 0 ] loss: 0.35285046696662903 2022-07-20 01:53:52.778039
Epoch:[ 191 1 ] loss: 0.3514304757118225 2022-07-20 01:53:53.191856
Epoch:[ 191 2 ] loss: 0.35220950841903687 2022-07-20 01:53:53.609919
Epoch:[ 191 3 ] loss: 0.3524971008300781 2022-07-20 01:53:54.022805
Epoch:[ 191 4 ] loss: 0.3520580530166626 2022-07-20 01:53:54.436772
Epoch:[ 191 5 ] loss: 0.350816935300827 2022-07-20 01:53:54.849397
Epoch:[ 191 6 ] loss: 0.35197514295578003 2022-07-20 01:53:55.264660
Epoch:[ 191 7 ] loss: 0.35238268971443176 2022-07-20 01:53:55.678882
Epoch:[ 191 8 ] loss: 0.3513568937778473 2022-07-20 01:53:56.092091
Epoch:[ 191 9 ] loss: 0.3519805669784546 2022-07-20 01:53:56.503984
Epoch:[ 191 10 ] loss: 0.35262659192085266 2022-07-20 01:53:56.917452
Epoch:[ 191 11 ] loss: 0.3527803421020508 2022-07-20 01:53:57.334397
Epoch:[ 191 12 ] loss: 0.35134804248809814 2022-07-20 01:53:57.747076
Epoch:[ 191 13 ] loss: 0.3526945114135742 2022-07-20 01:53:58.162140
Epoch:[ 191 14 ] loss: 0.35198715329170227 2022-07-20 01:53:58.578431
Epoch:[ 191 15 ] loss: 0.3522372841835022 2022-07-20 01:53:58.990974
Epoch:[ 191 16 ] loss: 0.3523792326450348 2022-07-20 01:54:04.608578
Epoch:[ 191 17 ] loss: 0.35224461555480957 2022-07-20 01:54:05.025935
Epoch:[ 191 18 ] loss: 0.3521905243396759 2022-07-20 01:54:05.440044
Epoch:[ 191 19 ] loss: 0.3509584963321686 2022-07-20 01:54:05.859042
Training_Epoch:[ 191 ] Training_loss: 0.35205023139715197 2022-07-20 01:54:05.859751
learning rate:  4.559944833472275e-05
val: 1 0.41837406158447266
val: 2 0.4129355847835541
val: 3 0.4175325036048889
val: 4 0.41437381505966187
val: 5 0.4180338978767395
val: 6 0.41618621349334717
val: 7 0.4244921803474426
val: 8 0.4152780771255493
val: 9 0.40086621046066284
val: 10 0.42112621665000916
val: 11 0.42151081562042236
val: 12 0.42289456725120544
val: 13 0.42166468501091003
val: 14 0.399502694606781
val: 15 0.41940563917160034
val: 16 0.42574962973594666
val: 17 0.4331112504005432
val: 18 0.43108394742012024
val: 19 0.41579964756965637
val: 20 0.41867008805274963
val_Epoch:[ 191 ] val_loss: 0.41842958629131316 2022-07-20 01:54:09.041972
start training 2022-07-20 01:54:09.146021
Epoch:[ 192 0 ] loss: 0.3514382541179657 2022-07-20 01:54:23.329103
Epoch:[ 192 1 ] loss: 0.3525627851486206 2022-07-20 01:54:23.745502
Epoch:[ 192 2 ] loss: 0.3521074056625366 2022-07-20 01:54:24.166284
Epoch:[ 192 3 ] loss: 0.3506818413734436 2022-07-20 01:54:24.580341
Epoch:[ 192 4 ] loss: 0.35275861620903015 2022-07-20 01:54:24.992694
Epoch:[ 192 5 ] loss: 0.3519743084907532 2022-07-20 01:54:25.405746
Epoch:[ 192 6 ] loss: 0.3524516224861145 2022-07-20 01:54:25.818330
Epoch:[ 192 7 ] loss: 0.3526204824447632 2022-07-20 01:54:26.237470
Epoch:[ 192 8 ] loss: 0.35135266184806824 2022-07-20 01:54:26.651411
Epoch:[ 192 9 ] loss: 0.35257688164711 2022-07-20 01:54:27.062946
Epoch:[ 192 10 ] loss: 0.3527754843235016 2022-07-20 01:54:27.478954
Epoch:[ 192 11 ] loss: 0.35176047682762146 2022-07-20 01:54:27.892457
Epoch:[ 192 12 ] loss: 0.3518495261669159 2022-07-20 01:54:28.311421
Epoch:[ 192 13 ] loss: 0.3523143529891968 2022-07-20 01:54:28.725175
Epoch:[ 192 14 ] loss: 0.35089972615242004 2022-07-20 01:54:29.140743
Epoch:[ 192 15 ] loss: 0.3511126935482025 2022-07-20 01:54:29.554252
Epoch:[ 192 16 ] loss: 0.35271960496902466 2022-07-20 01:54:34.994277
Epoch:[ 192 17 ] loss: 0.3519993722438812 2022-07-20 01:54:35.412272
Epoch:[ 192 18 ] loss: 0.3516543507575989 2022-07-20 01:54:35.833814
Epoch:[ 192 19 ] loss: 0.3517487943172455 2022-07-20 01:54:36.250800
Training_Epoch:[ 192 ] Training_loss: 0.35196796208620074 2022-07-20 01:54:36.251482
learning rate:  4.559944833472275e-05
netparams have been saved once 192
val: 1 0.41203024983406067
val: 2 0.41898760199546814
val: 3 0.40907588601112366
val: 4 0.41794073581695557
val: 5 0.4290870130062103
val: 6 0.42387640476226807
val: 7 0.420318067073822
val: 8 0.42333996295928955
val: 9 0.4055474102497101
val: 10 0.41961050033569336
val: 11 0.42322614789009094
val: 12 0.4115544855594635
val: 13 0.42242830991744995
val: 14 0.41769838333129883
val: 15 0.42203623056411743
val: 16 0.4067365825176239
val: 17 0.41162365674972534
val: 18 0.40279483795166016
val: 19 0.41031184792518616
val: 20 0.41657331585884094
val_Epoch:[ 192 ] val_loss: 0.41623988151550295 2022-07-20 01:54:39.411107
start training 2022-07-20 01:54:39.516595
Epoch:[ 193 0 ] loss: 0.35075512528419495 2022-07-20 01:54:53.254110
Epoch:[ 193 1 ] loss: 0.35176777839660645 2022-07-20 01:54:53.690360
Epoch:[ 193 2 ] loss: 0.3520861864089966 2022-07-20 01:54:54.105959
Epoch:[ 193 3 ] loss: 0.3514658808708191 2022-07-20 01:54:54.519012
Epoch:[ 193 4 ] loss: 0.3510058522224426 2022-07-20 01:54:54.930421
Epoch:[ 193 5 ] loss: 0.3516112267971039 2022-07-20 01:54:55.345438
Epoch:[ 193 6 ] loss: 0.35108575224876404 2022-07-20 01:54:55.759227
Epoch:[ 193 7 ] loss: 0.3511829674243927 2022-07-20 01:54:56.171757
Epoch:[ 193 8 ] loss: 0.35230252146720886 2022-07-20 01:54:56.585479
Epoch:[ 193 9 ] loss: 0.3523481488227844 2022-07-20 01:54:56.999936
Epoch:[ 193 10 ] loss: 0.35337507724761963 2022-07-20 01:54:57.413859
Epoch:[ 193 11 ] loss: 0.3510940670967102 2022-07-20 01:54:57.829338
Epoch:[ 193 12 ] loss: 0.3513220250606537 2022-07-20 01:54:58.242604
Epoch:[ 193 13 ] loss: 0.35155677795410156 2022-07-20 01:54:58.656513
Epoch:[ 193 14 ] loss: 0.3524174392223358 2022-07-20 01:54:59.074662
Epoch:[ 193 15 ] loss: 0.35265791416168213 2022-07-20 01:54:59.489542
Epoch:[ 193 16 ] loss: 0.3519599437713623 2022-07-20 01:55:04.968882
Epoch:[ 193 17 ] loss: 0.3535228371620178 2022-07-20 01:55:05.380646
Epoch:[ 193 18 ] loss: 0.3521806299686432 2022-07-20 01:55:05.801499
Epoch:[ 193 19 ] loss: 0.3511425256729126 2022-07-20 01:55:06.215385
Training_Epoch:[ 193 ] Training_loss: 0.3518420338630676 2022-07-20 01:55:06.216086
learning rate:  4.559944833472275e-05
val: 1 0.4200279414653778
val: 2 0.402862012386322
val: 3 0.4248886704444885
val: 4 0.4053235650062561
val: 5 0.41413092613220215
val: 6 0.4229361116886139
val: 7 0.4183567762374878
val: 8 0.4130015969276428
val: 9 0.41972672939300537
val: 10 0.40601491928100586
val: 11 0.4175550639629364
val: 12 0.40754660964012146
val: 13 0.41506555676460266
val: 14 0.4255288243293762
val: 15 0.43781083822250366
val: 16 0.41505080461502075
val: 17 0.41769081354141235
val: 18 0.4274386763572693
val: 19 0.422956258058548
val: 20 0.41368240118026733
val_Epoch:[ 193 ] val_loss: 0.417379754781723 2022-07-20 01:55:09.347402
start training 2022-07-20 01:55:09.454917
Epoch:[ 194 0 ] loss: 0.3512197732925415 2022-07-20 01:55:23.200122
Epoch:[ 194 1 ] loss: 0.3509656488895416 2022-07-20 01:55:23.630471
Epoch:[ 194 2 ] loss: 0.35247308015823364 2022-07-20 01:55:24.046402
Epoch:[ 194 3 ] loss: 0.35178637504577637 2022-07-20 01:55:24.460543
Epoch:[ 194 4 ] loss: 0.3517570495605469 2022-07-20 01:55:24.874072
Epoch:[ 194 5 ] loss: 0.3519849181175232 2022-07-20 01:55:25.288325
Epoch:[ 194 6 ] loss: 0.35244378447532654 2022-07-20 01:55:25.702350
Epoch:[ 194 7 ] loss: 0.3517393171787262 2022-07-20 01:55:26.114606
Epoch:[ 194 8 ] loss: 0.35166460275650024 2022-07-20 01:55:26.527721
Epoch:[ 194 9 ] loss: 0.35219213366508484 2022-07-20 01:55:26.940882
Epoch:[ 194 10 ] loss: 0.3516908586025238 2022-07-20 01:55:27.362444
Epoch:[ 194 11 ] loss: 0.3517776131629944 2022-07-20 01:55:27.777213
Epoch:[ 194 12 ] loss: 0.35220903158187866 2022-07-20 01:55:28.191470
Epoch:[ 194 13 ] loss: 0.352019727230072 2022-07-20 01:55:28.605718
Epoch:[ 194 14 ] loss: 0.35177552700042725 2022-07-20 01:55:29.018805
Epoch:[ 194 15 ] loss: 0.3506647050380707 2022-07-20 01:55:29.437538
Epoch:[ 194 16 ] loss: 0.3522692620754242 2022-07-20 01:55:35.035477
Epoch:[ 194 17 ] loss: 0.3527071177959442 2022-07-20 01:55:35.448110
Epoch:[ 194 18 ] loss: 0.35142526030540466 2022-07-20 01:55:35.866554
Epoch:[ 194 19 ] loss: 0.3509681522846222 2022-07-20 01:55:36.285809
Training_Epoch:[ 194 ] Training_loss: 0.3517866969108582 2022-07-20 01:55:36.286485
learning rate:  4.559944833472275e-05
netparams have been saved once 194
val: 1 0.4145713150501251
val: 2 0.40532055497169495
val: 3 0.4213160574436188
val: 4 0.4141800105571747
val: 5 0.4225909113883972
val: 6 0.4171585142612457
val: 7 0.40934282541275024
val: 8 0.42702311277389526
val: 9 0.41377148032188416
val: 10 0.4212135374546051
val: 11 0.42189517617225647
val: 12 0.4189905524253845
val: 13 0.4106050431728363
val: 14 0.4184856414794922
val: 15 0.40973809361457825
val: 16 0.41928455233573914
val: 17 0.40741848945617676
val: 18 0.40975186228752136
val: 19 0.41490715742111206
val: 20 0.4114299714565277
val_Epoch:[ 194 ] val_loss: 0.4154497429728508 2022-07-20 01:55:39.507598
start training 2022-07-20 01:55:39.615694
Epoch:[ 195 0 ] loss: 0.352413535118103 2022-07-20 01:55:53.192684
Epoch:[ 195 1 ] loss: 0.3523285984992981 2022-07-20 01:55:53.623810
Epoch:[ 195 2 ] loss: 0.35196825861930847 2022-07-20 01:55:54.037403
Epoch:[ 195 3 ] loss: 0.3526740074157715 2022-07-20 01:55:54.450226
Epoch:[ 195 4 ] loss: 0.35206639766693115 2022-07-20 01:55:54.864318
Epoch:[ 195 5 ] loss: 0.35137665271759033 2022-07-20 01:55:55.276266
Epoch:[ 195 6 ] loss: 0.35077568888664246 2022-07-20 01:55:55.689671
Epoch:[ 195 7 ] loss: 0.352033406496048 2022-07-20 01:55:56.108659
Epoch:[ 195 8 ] loss: 0.3511643409729004 2022-07-20 01:55:56.526546
Epoch:[ 195 9 ] loss: 0.35242438316345215 2022-07-20 01:55:56.942494
Epoch:[ 195 10 ] loss: 0.3520022928714752 2022-07-20 01:55:57.356556
Epoch:[ 195 11 ] loss: 0.350757896900177 2022-07-20 01:55:57.771001
Epoch:[ 195 12 ] loss: 0.35296523571014404 2022-07-20 01:55:58.183053
Epoch:[ 195 13 ] loss: 0.35103222727775574 2022-07-20 01:55:58.594812
Epoch:[ 195 14 ] loss: 0.3522833585739136 2022-07-20 01:55:59.009022
Epoch:[ 195 15 ] loss: 0.3523014485836029 2022-07-20 01:55:59.421883
Epoch:[ 195 16 ] loss: 0.3517153263092041 2022-07-20 01:56:04.734759
Epoch:[ 195 17 ] loss: 0.35238900780677795 2022-07-20 01:56:05.166449
Epoch:[ 195 18 ] loss: 0.3511248826980591 2022-07-20 01:56:05.580907
Epoch:[ 195 19 ] loss: 0.35129162669181824 2022-07-20 01:56:05.999150
Training_Epoch:[ 195 ] Training_loss: 0.35185442864894867 2022-07-20 01:56:05.999891
learning rate:  4.559944833472275e-05
val: 1 0.4109174311161041
val: 2 0.41964614391326904
val: 3 0.4159926176071167
val: 4 0.4163306653499603
val: 5 0.4245297908782959
val: 6 0.4073690176010132
val: 7 0.40745434165000916
val: 8 0.41685751080513
val: 9 0.4083179235458374
val: 10 0.41071730852127075
val: 11 0.415779173374176
val: 12 0.39988255500793457
val: 13 0.41966676712036133
val: 14 0.4096470773220062
val: 15 0.4120514392852783
val: 16 0.4170592427253723
val: 17 0.41805583238601685
val: 18 0.4113742411136627
val: 19 0.4301435649394989
val: 20 0.4176676571369171
val_Epoch:[ 195 ] val_loss: 0.41447301506996154 2022-07-20 01:56:09.130176
start training 2022-07-20 01:56:09.235214
Epoch:[ 196 0 ] loss: 0.35166481137275696 2022-07-20 01:56:23.601162
Epoch:[ 196 1 ] loss: 0.3520093858242035 2022-07-20 01:56:24.013603
Epoch:[ 196 2 ] loss: 0.3515844941139221 2022-07-20 01:56:24.431513
Epoch:[ 196 3 ] loss: 0.35268446803092957 2022-07-20 01:56:24.844631
Epoch:[ 196 4 ] loss: 0.3519797623157501 2022-07-20 01:56:25.258654
Epoch:[ 196 5 ] loss: 0.3528909683227539 2022-07-20 01:56:25.674618
Epoch:[ 196 6 ] loss: 0.3521830439567566 2022-07-20 01:56:26.092348
Epoch:[ 196 7 ] loss: 0.35144856572151184 2022-07-20 01:56:26.504686
Epoch:[ 196 8 ] loss: 0.3510122001171112 2022-07-20 01:56:26.917492
Epoch:[ 196 9 ] loss: 0.35195106267929077 2022-07-20 01:56:27.328531
Epoch:[ 196 10 ] loss: 0.35141721367836 2022-07-20 01:56:27.740401
Epoch:[ 196 11 ] loss: 0.35176897048950195 2022-07-20 01:56:28.154072
Epoch:[ 196 12 ] loss: 0.35111144185066223 2022-07-20 01:56:28.567763
Epoch:[ 196 13 ] loss: 0.3509761095046997 2022-07-20 01:56:28.982009
Epoch:[ 196 14 ] loss: 0.35274752974510193 2022-07-20 01:56:29.396009
Epoch:[ 196 15 ] loss: 0.3511945605278015 2022-07-20 01:56:29.810087
Epoch:[ 196 16 ] loss: 0.3532194495201111 2022-07-20 01:56:35.224886
Epoch:[ 196 17 ] loss: 0.35166242718696594 2022-07-20 01:56:35.636508
Epoch:[ 196 18 ] loss: 0.3517741560935974 2022-07-20 01:56:36.062531
Epoch:[ 196 19 ] loss: 0.35195714235305786 2022-07-20 01:56:36.484438
Training_Epoch:[ 196 ] Training_loss: 0.35186188817024233 2022-07-20 01:56:36.485115
learning rate:  4.559944833472275e-05
netparams have been saved once 196
val: 1 0.41918739676475525
val: 2 0.4159241318702698
val: 3 0.4206961989402771
val: 4 0.41578224301338196
val: 5 0.4162215292453766
val: 6 0.41530269384384155
val: 7 0.4150252342224121
val: 8 0.4192754626274109
val: 9 0.414014995098114
val: 10 0.4083145260810852
val: 11 0.4228096008300781
val: 12 0.4068680703639984
val: 13 0.4112088978290558
val: 14 0.4195694327354431
val: 15 0.41558030247688293
val: 16 0.4180409908294678
val: 17 0.41314542293548584
val: 18 0.4056650698184967
val: 19 0.4153718948364258
val: 20 0.41355282068252563
val_Epoch:[ 196 ] val_loss: 0.4150778457522392 2022-07-20 01:56:39.685357
start training 2022-07-20 01:56:39.791352
Epoch:[ 197 0 ] loss: 0.35152286291122437 2022-07-20 01:56:53.089068
Epoch:[ 197 1 ] loss: 0.35268720984458923 2022-07-20 01:56:53.526605
Epoch:[ 197 2 ] loss: 0.3516516387462616 2022-07-20 01:56:54.002870
Epoch:[ 197 3 ] loss: 0.35172775387763977 2022-07-20 01:56:54.417287
Epoch:[ 197 4 ] loss: 0.35243213176727295 2022-07-20 01:56:54.829159
Epoch:[ 197 5 ] loss: 0.35169774293899536 2022-07-20 01:56:55.242833
Epoch:[ 197 6 ] loss: 0.3522860109806061 2022-07-20 01:56:55.658123
Epoch:[ 197 7 ] loss: 0.35121363401412964 2022-07-20 01:56:56.070179
Epoch:[ 197 8 ] loss: 0.3513144254684448 2022-07-20 01:56:56.483374
Epoch:[ 197 9 ] loss: 0.3523898720741272 2022-07-20 01:56:56.896959
Epoch:[ 197 10 ] loss: 0.35217198729515076 2022-07-20 01:56:57.306208
Epoch:[ 197 11 ] loss: 0.3514229953289032 2022-07-20 01:56:57.718898
Epoch:[ 197 12 ] loss: 0.3510289788246155 2022-07-20 01:56:58.133268
Epoch:[ 197 13 ] loss: 0.35236290097236633 2022-07-20 01:56:58.552628
Epoch:[ 197 14 ] loss: 0.35300299525260925 2022-07-20 01:56:58.968080
Epoch:[ 197 15 ] loss: 0.35291624069213867 2022-07-20 01:56:59.377250
Epoch:[ 197 16 ] loss: 0.35210588574409485 2022-07-20 01:57:05.169940
Epoch:[ 197 17 ] loss: 0.35226085782051086 2022-07-20 01:57:05.583467
Epoch:[ 197 18 ] loss: 0.35244685411453247 2022-07-20 01:57:06.001899
Epoch:[ 197 19 ] loss: 0.3514556288719177 2022-07-20 01:57:06.421221
Training_Epoch:[ 197 ] Training_loss: 0.35200493037700653 2022-07-20 01:57:06.422128
learning rate:  4.559944833472275e-05
val: 1 0.4162515103816986
val: 2 0.41232386231422424
val: 3 0.4165104925632477
val: 4 0.410396546125412
val: 5 0.41736578941345215
val: 6 0.4098130762577057
val: 7 0.4196743667125702
val: 8 0.4108002185821533
val: 9 0.3987787961959839
val: 10 0.41802018880844116
val: 11 0.4202755391597748
val: 12 0.419515997171402
val: 13 0.4092947244644165
val: 14 0.4274604022502899
val: 15 0.41843974590301514
val: 16 0.41529402136802673
val: 17 0.41490885615348816
val: 18 0.41630327701568604
val: 19 0.4186653196811676
val: 20 0.4236729145050049
val_Epoch:[ 197 ] val_loss: 0.415688282251358 2022-07-20 01:57:09.542396
start training 2022-07-20 01:57:09.647701
Epoch:[ 198 0 ] loss: 0.3522365093231201 2022-07-20 01:57:23.876154
Epoch:[ 198 1 ] loss: 0.3505024313926697 2022-07-20 01:57:24.287130
Epoch:[ 198 2 ] loss: 0.35119813680648804 2022-07-20 01:57:24.707629
Epoch:[ 198 3 ] loss: 0.35233619809150696 2022-07-20 01:57:25.121345
Epoch:[ 198 4 ] loss: 0.3520011007785797 2022-07-20 01:57:25.533456
Epoch:[ 198 5 ] loss: 0.3522646129131317 2022-07-20 01:57:25.945962
Epoch:[ 198 6 ] loss: 0.3520999252796173 2022-07-20 01:57:26.358933
Epoch:[ 198 7 ] loss: 0.3510245978832245 2022-07-20 01:57:26.774969
Epoch:[ 198 8 ] loss: 0.35258230566978455 2022-07-20 01:57:27.186856
Epoch:[ 198 9 ] loss: 0.35154449939727783 2022-07-20 01:57:27.598309
Epoch:[ 198 10 ] loss: 0.3516465723514557 2022-07-20 01:57:28.016475
Epoch:[ 198 11 ] loss: 0.35034823417663574 2022-07-20 01:57:28.429642
Epoch:[ 198 12 ] loss: 0.35166996717453003 2022-07-20 01:57:28.841630
Epoch:[ 198 13 ] loss: 0.3531796336174011 2022-07-20 01:57:29.255306
Epoch:[ 198 14 ] loss: 0.3530678451061249 2022-07-20 01:57:29.669203
Epoch:[ 198 15 ] loss: 0.3520004451274872 2022-07-20 01:57:30.081626
Epoch:[ 198 16 ] loss: 0.3513670265674591 2022-07-20 01:57:35.594977
Epoch:[ 198 17 ] loss: 0.3523813784122467 2022-07-20 01:57:36.011712
Epoch:[ 198 18 ] loss: 0.35107091069221497 2022-07-20 01:57:36.425307
Epoch:[ 198 19 ] loss: 0.3514243960380554 2022-07-20 01:57:36.842879
Training_Epoch:[ 198 ] Training_loss: 0.3517973363399506 2022-07-20 01:57:36.843563
learning rate:  4.559944833472275e-05
netparams have been saved once 198
val: 1 0.4192271828651428
val: 2 0.4126867353916168
val: 3 0.4114750921726227
val: 4 0.4151645004749298
val: 5 0.42258724570274353
val: 6 0.4193497896194458
val: 7 0.42305195331573486
val: 8 0.4106176495552063
val: 9 0.4100804924964905
val: 10 0.4316175580024719
val: 11 0.42420873045921326
val: 12 0.42424601316452026
val: 13 0.4159605801105499
val: 14 0.4298571050167084
val: 15 0.42128658294677734
val: 16 0.413329154253006
val: 17 0.4142303168773651
val: 18 0.4133211374282837
val: 19 0.41311579942703247
val: 20 0.4136565327644348
val_Epoch:[ 198 ] val_loss: 0.41795350760221484 2022-07-20 01:57:40.030176
start training 2022-07-20 01:57:40.136494
Epoch:[ 199 0 ] loss: 0.3508055806159973 2022-07-20 01:57:53.749910
Epoch:[ 199 1 ] loss: 0.35136234760284424 2022-07-20 01:57:54.163534
Epoch:[ 199 2 ] loss: 0.35088130831718445 2022-07-20 01:57:54.575855
Epoch:[ 199 3 ] loss: 0.352024108171463 2022-07-20 01:57:54.993219
Epoch:[ 199 4 ] loss: 0.35135912895202637 2022-07-20 01:57:55.405362
Epoch:[ 199 5 ] loss: 0.35189586877822876 2022-07-20 01:57:55.819030
Epoch:[ 199 6 ] loss: 0.3511774241924286 2022-07-20 01:57:56.233977
Epoch:[ 199 7 ] loss: 0.3525508940219879 2022-07-20 01:57:56.649315
Epoch:[ 199 8 ] loss: 0.35135409235954285 2022-07-20 01:57:57.063364
Epoch:[ 199 9 ] loss: 0.35150212049484253 2022-07-20 01:57:57.474312
Epoch:[ 199 10 ] loss: 0.3511744439601898 2022-07-20 01:57:57.886271
Epoch:[ 199 11 ] loss: 0.3526970148086548 2022-07-20 01:57:58.298202
Epoch:[ 199 12 ] loss: 0.35149526596069336 2022-07-20 01:57:58.715435
Epoch:[ 199 13 ] loss: 0.351443350315094 2022-07-20 01:57:59.127690
Epoch:[ 199 14 ] loss: 0.35224246978759766 2022-07-20 01:57:59.543303
Epoch:[ 199 15 ] loss: 0.35234346985816956 2022-07-20 01:57:59.957944
Epoch:[ 199 16 ] loss: 0.3517313003540039 2022-07-20 01:58:05.495750
Epoch:[ 199 17 ] loss: 0.3517552316188812 2022-07-20 01:58:05.915496
Epoch:[ 199 18 ] loss: 0.35257723927497864 2022-07-20 01:58:06.329879
Epoch:[ 199 19 ] loss: 0.35279175639152527 2022-07-20 01:58:06.742831
Training_Epoch:[ 199 ] Training_loss: 0.35175822079181673 2022-07-20 01:58:06.743470
learning rate:  4.559944833472275e-05
val: 1 0.42152637243270874
val: 2 0.41941970586776733
val: 3 0.4138520658016205
val: 4 0.411455899477005
val: 5 0.4188937246799469
val: 6 0.41225776076316833
val: 7 0.4254629909992218
val: 8 0.4279041290283203
val: 9 0.4113106429576874
val: 10 0.4090171754360199
val: 11 0.4148394763469696
val: 12 0.4094308018684387
val: 13 0.41219019889831543
val: 14 0.41097503900527954
val: 15 0.4194304347038269
val: 16 0.40351709723472595
val: 17 0.4152431786060333
val: 18 0.42094045877456665
val: 19 0.42572614550590515
val: 20 0.42267346382141113
val_Epoch:[ 199 ] val_loss: 0.41630333811044695 2022-07-20 01:58:09.865226
start training 2022-07-20 01:58:09.973967
Epoch:[ 200 0 ] loss: 0.3514845669269562 2022-07-20 01:58:23.714379
Epoch:[ 200 1 ] loss: 0.3513208329677582 2022-07-20 01:58:24.148458
Epoch:[ 200 2 ] loss: 0.35037940740585327 2022-07-20 01:58:24.562844
Epoch:[ 200 3 ] loss: 0.35090574622154236 2022-07-20 01:58:24.975137
Epoch:[ 200 4 ] loss: 0.35194072127342224 2022-07-20 01:58:25.394495
Epoch:[ 200 5 ] loss: 0.35185757279396057 2022-07-20 01:58:25.806923
Epoch:[ 200 6 ] loss: 0.35182008147239685 2022-07-20 01:58:26.220912
Epoch:[ 200 7 ] loss: 0.35119298100471497 2022-07-20 01:58:26.636071
Epoch:[ 200 8 ] loss: 0.3519461452960968 2022-07-20 01:58:27.049409
Epoch:[ 200 9 ] loss: 0.35321736335754395 2022-07-20 01:58:27.469487
Epoch:[ 200 10 ] loss: 0.35284623503685 2022-07-20 01:58:27.883194
Epoch:[ 200 11 ] loss: 0.3511244058609009 2022-07-20 01:58:28.296256
Epoch:[ 200 12 ] loss: 0.35002943873405457 2022-07-20 01:58:28.710594
Epoch:[ 200 13 ] loss: 0.3517218828201294 2022-07-20 01:58:29.124314
Epoch:[ 200 14 ] loss: 0.35264039039611816 2022-07-20 01:58:29.537424
Epoch:[ 200 15 ] loss: 0.35297372937202454 2022-07-20 01:58:29.952113
Epoch:[ 200 16 ] loss: 0.35221192240715027 2022-07-20 01:58:35.705415
Epoch:[ 200 17 ] loss: 0.35192427039146423 2022-07-20 01:58:36.114724
Epoch:[ 200 18 ] loss: 0.35066327452659607 2022-07-20 01:58:36.542418
Epoch:[ 200 19 ] loss: 0.3516908586025238 2022-07-20 01:58:36.955484
Training_Epoch:[ 200 ] Training_loss: 0.35169459134340286 2022-07-20 01:58:36.956203
learning rate:  4.559944833472275e-05
netparams have been saved once 200
val: 1 0.42018452286720276
val: 2 0.4179467558860779
val: 3 0.4194616377353668
val: 4 0.42111438512802124
val: 5 0.4083448052406311
val: 6 0.4091093838214874
val: 7 0.4278411865234375
val: 8 0.42214542627334595
val: 9 0.41520577669143677
val: 10 0.4169820547103882
val: 11 0.41700437664985657
val: 12 0.43311402201652527
val: 13 0.41074588894844055
val: 14 0.41859275102615356
val: 15 0.41185152530670166
val: 16 0.4167947471141815
val: 17 0.4160845875740051
val: 18 0.4170234799385071
val: 19 0.42765963077545166
val: 20 0.4037517309188843
val_Epoch:[ 200 ] val_loss: 0.41754793375730515 2022-07-20 01:58:40.155890
start training 2022-07-20 01:58:40.260264
Epoch:[ 201 0 ] loss: 0.3503390848636627 2022-07-20 01:58:54.775320
Epoch:[ 201 1 ] loss: 0.3508778214454651 2022-07-20 01:58:55.189805
Epoch:[ 201 2 ] loss: 0.3509889543056488 2022-07-20 01:58:55.610235
Epoch:[ 201 3 ] loss: 0.35237860679626465 2022-07-20 01:58:56.024671
Epoch:[ 201 4 ] loss: 0.3517484664916992 2022-07-20 01:58:56.437699
Epoch:[ 201 5 ] loss: 0.351798415184021 2022-07-20 01:58:56.848281
Epoch:[ 201 6 ] loss: 0.35029667615890503 2022-07-20 01:58:57.262923
Epoch:[ 201 7 ] loss: 0.3509918451309204 2022-07-20 01:58:57.676216
Epoch:[ 201 8 ] loss: 0.3511723279953003 2022-07-20 01:58:58.090054
Epoch:[ 201 9 ] loss: 0.3511274755001068 2022-07-20 01:58:58.504199
Epoch:[ 201 10 ] loss: 0.35108181834220886 2022-07-20 01:58:58.915486
Epoch:[ 201 11 ] loss: 0.35184934735298157 2022-07-20 01:58:59.328369
Epoch:[ 201 12 ] loss: 0.3521121144294739 2022-07-20 01:58:59.740280
Epoch:[ 201 13 ] loss: 0.35167884826660156 2022-07-20 01:59:00.152461
Epoch:[ 201 14 ] loss: 0.3517196774482727 2022-07-20 01:59:00.565644
Epoch:[ 201 15 ] loss: 0.35171136260032654 2022-07-20 01:59:00.980522
Epoch:[ 201 16 ] loss: 0.35101690888404846 2022-07-20 01:59:06.376561
Epoch:[ 201 17 ] loss: 0.35123780369758606 2022-07-20 01:59:06.790221
Epoch:[ 201 18 ] loss: 0.3523547947406769 2022-07-20 01:59:07.201441
Epoch:[ 201 19 ] loss: 0.3519536256790161 2022-07-20 01:59:07.609925
Training_Epoch:[ 201 ] Training_loss: 0.3514217987656593 2022-07-20 01:59:07.610983
learning rate:  3.875953108451434e-05
val: 1 0.42138466238975525
val: 2 0.4241894483566284
val: 3 0.4133821427822113
val: 4 0.40924501419067383
val: 5 0.4134257733821869
val: 6 0.41288813948631287
val: 7 0.41358277201652527
val: 8 0.4229690134525299
val: 9 0.41428762674331665
val: 10 0.41837307810783386
val: 11 0.42953377962112427
val: 12 0.40867680311203003
val: 13 0.4105399549007416
val: 14 0.40780794620513916
val: 15 0.40645185112953186
val: 16 0.4183928072452545
val: 17 0.4141629636287689
val: 18 0.41141965985298157
val: 19 0.4187309741973877
val: 20 0.41409531235694885
val_Epoch:[ 201 ] val_loss: 0.4151769861578941 2022-07-20 01:59:10.910811
start training 2022-07-20 01:59:11.019648
Epoch:[ 202 0 ] loss: 0.3511536717414856 2022-07-20 01:59:25.236275
Epoch:[ 202 1 ] loss: 0.3508916199207306 2022-07-20 01:59:25.645758
Epoch:[ 202 2 ] loss: 0.35006189346313477 2022-07-20 01:59:26.054181
Epoch:[ 202 3 ] loss: 0.3508637547492981 2022-07-20 01:59:26.465268
Epoch:[ 202 4 ] loss: 0.35210737586021423 2022-07-20 01:59:26.880645
Epoch:[ 202 5 ] loss: 0.35121771693229675 2022-07-20 01:59:27.295798
Epoch:[ 202 6 ] loss: 0.35230979323387146 2022-07-20 01:59:27.710527
Epoch:[ 202 7 ] loss: 0.35173898935317993 2022-07-20 01:59:28.124009
Epoch:[ 202 8 ] loss: 0.3506435751914978 2022-07-20 01:59:28.537014
Epoch:[ 202 9 ] loss: 0.35135769844055176 2022-07-20 01:59:28.950456
Epoch:[ 202 10 ] loss: 0.351791650056839 2022-07-20 01:59:29.366301
Epoch:[ 202 11 ] loss: 0.35188382863998413 2022-07-20 01:59:29.781943
Epoch:[ 202 12 ] loss: 0.35152381658554077 2022-07-20 01:59:30.194137
Epoch:[ 202 13 ] loss: 0.3510042428970337 2022-07-20 01:59:30.608738
Epoch:[ 202 14 ] loss: 0.352997750043869 2022-07-20 01:59:31.022700
Epoch:[ 202 15 ] loss: 0.3516875207424164 2022-07-20 01:59:31.436484
Epoch:[ 202 16 ] loss: 0.35191479325294495 2022-07-20 01:59:36.573140
Epoch:[ 202 17 ] loss: 0.35175806283950806 2022-07-20 01:59:36.983293
Epoch:[ 202 18 ] loss: 0.3503839671611786 2022-07-20 01:59:37.399052
Epoch:[ 202 19 ] loss: 0.3507731854915619 2022-07-20 01:59:37.813105
Training_Epoch:[ 202 ] Training_loss: 0.3514032453298569 2022-07-20 01:59:37.813881
learning rate:  3.875953108451434e-05
netparams have been saved once 202
val: 1 0.4129457473754883
val: 2 0.4173576533794403
val: 3 0.4093836545944214
val: 4 0.41086339950561523
val: 5 0.40892234444618225
val: 6 0.41735339164733887
val: 7 0.4210476279258728
val: 8 0.40749379992485046
val: 9 0.39980801939964294
val: 10 0.40828606486320496
val: 11 0.411577433347702
val: 12 0.42994898557662964
val: 13 0.42288845777511597
val: 14 0.4081800878047943
val: 15 0.4228834807872772
val: 16 0.4258649945259094
val: 17 0.42169782519340515
val: 18 0.4282304048538208
val: 19 0.4169853627681732
val: 20 0.4064750075340271
val_Epoch:[ 202 ] val_loss: 0.4154096871614456 2022-07-20 01:59:41.091940
start training 2022-07-20 01:59:41.201696
Epoch:[ 203 0 ] loss: 0.35124471783638 2022-07-20 01:59:55.092540
Epoch:[ 203 1 ] loss: 0.35197967290878296 2022-07-20 01:59:55.511274
Epoch:[ 203 2 ] loss: 0.3504794239997864 2022-07-20 01:59:55.924875
Epoch:[ 203 3 ] loss: 0.3516055643558502 2022-07-20 01:59:56.336439
Epoch:[ 203 4 ] loss: 0.3510288596153259 2022-07-20 01:59:56.753858
Epoch:[ 203 5 ] loss: 0.3511512875556946 2022-07-20 01:59:57.173033
Epoch:[ 203 6 ] loss: 0.35038310289382935 2022-07-20 01:59:57.588535
Epoch:[ 203 7 ] loss: 0.35066115856170654 2022-07-20 01:59:58.000892
Epoch:[ 203 8 ] loss: 0.35212042927742004 2022-07-20 01:59:58.412127
Epoch:[ 203 9 ] loss: 0.3516269624233246 2022-07-20 01:59:58.823325
Epoch:[ 203 10 ] loss: 0.3521758019924164 2022-07-20 01:59:59.238230
Epoch:[ 203 11 ] loss: 0.35130754113197327 2022-07-20 01:59:59.651487
Epoch:[ 203 12 ] loss: 0.351193904876709 2022-07-20 02:00:00.064973
Epoch:[ 203 13 ] loss: 0.3515907824039459 2022-07-20 02:00:00.476602
Epoch:[ 203 14 ] loss: 0.35106393694877625 2022-07-20 02:00:00.888686
Epoch:[ 203 15 ] loss: 0.351596474647522 2022-07-20 02:00:01.301537
Epoch:[ 203 16 ] loss: 0.35184207558631897 2022-07-20 02:00:06.786110
Epoch:[ 203 17 ] loss: 0.35097020864486694 2022-07-20 02:00:07.203602
Epoch:[ 203 18 ] loss: 0.35086071491241455 2022-07-20 02:00:07.626861
Epoch:[ 203 19 ] loss: 0.3508811593055725 2022-07-20 02:00:08.040197
Training_Epoch:[ 203 ] Training_loss: 0.3512881889939308 2022-07-20 02:00:08.041098
learning rate:  3.875953108451434e-05
val: 1 0.41401588916778564
val: 2 0.41771501302719116
val: 3 0.4176202416419983
val: 4 0.42024195194244385
val: 5 0.40712499618530273
val: 6 0.41195350885391235
val: 7 0.4129232168197632
val: 8 0.43069595098495483
val: 9 0.4214492738246918
val: 10 0.41483157873153687
val: 11 0.40890392661094666
val: 12 0.4142836034297943
val: 13 0.4157864451408386
val: 14 0.4258855879306793
val: 15 0.4238414764404297
val: 16 0.4215777814388275
val: 17 0.4266217350959778
val: 18 0.4178743064403534
val: 19 0.42431309819221497
val: 20 0.43489935994148254
val_Epoch:[ 203 ] val_loss: 0.41912794709205625 2022-07-20 02:00:11.260238
start training 2022-07-20 02:00:11.364343
Epoch:[ 204 0 ] loss: 0.35189327597618103 2022-07-20 02:00:24.731500
Epoch:[ 204 1 ] loss: 0.3508997857570648 2022-07-20 02:00:25.429205
Epoch:[ 204 2 ] loss: 0.3514828085899353 2022-07-20 02:00:25.843620
Epoch:[ 204 3 ] loss: 0.3508545458316803 2022-07-20 02:00:26.255427
Epoch:[ 204 4 ] loss: 0.3514728546142578 2022-07-20 02:00:26.670348
Epoch:[ 204 5 ] loss: 0.3510420322418213 2022-07-20 02:00:27.085662
Epoch:[ 204 6 ] loss: 0.3500123918056488 2022-07-20 02:00:27.500595
Epoch:[ 204 7 ] loss: 0.3511267900466919 2022-07-20 02:00:27.913860
Epoch:[ 204 8 ] loss: 0.3521730899810791 2022-07-20 02:00:28.328926
Epoch:[ 204 9 ] loss: 0.350806325674057 2022-07-20 02:00:28.743209
Epoch:[ 204 10 ] loss: 0.3508175015449524 2022-07-20 02:00:29.156395
Epoch:[ 204 11 ] loss: 0.3509434759616852 2022-07-20 02:00:29.570710
Epoch:[ 204 12 ] loss: 0.3510753810405731 2022-07-20 02:00:29.981418
Epoch:[ 204 13 ] loss: 0.3507859408855438 2022-07-20 02:00:30.395931
Epoch:[ 204 14 ] loss: 0.3498355746269226 2022-07-20 02:00:30.812634
Epoch:[ 204 15 ] loss: 0.35135728120803833 2022-07-20 02:00:31.224577
Epoch:[ 204 16 ] loss: 0.35121747851371765 2022-07-20 02:00:36.666913
Epoch:[ 204 17 ] loss: 0.3520137369632721 2022-07-20 02:00:37.081651
Epoch:[ 204 18 ] loss: 0.3521605134010315 2022-07-20 02:00:37.499273
Epoch:[ 204 19 ] loss: 0.3511262536048889 2022-07-20 02:00:37.918340
Training_Epoch:[ 204 ] Training_loss: 0.35115485191345214 2022-07-20 02:00:37.919102
learning rate:  3.875953108451434e-05
netparams have been saved once 204
val: 1 0.4067269563674927
val: 2 0.4169296324253082
val: 3 0.409201443195343
val: 4 0.41329291462898254
val: 5 0.4148161709308624
val: 6 0.41328996419906616
val: 7 0.41391146183013916
val: 8 0.40987473726272583
val: 9 0.4132593870162964
val: 10 0.41087016463279724
val: 11 0.4097604751586914
val: 12 0.42025959491729736
val: 13 0.4179854094982147
val: 14 0.41513296961784363
val: 15 0.40802034735679626
val: 16 0.41412991285324097
val: 17 0.4236084818840027
val: 18 0.4348081946372986
val: 19 0.4177020490169525
val: 20 0.4252105951309204
val_Epoch:[ 204 ] val_loss: 0.4154395431280136 2022-07-20 02:00:41.112840
start training 2022-07-20 02:00:41.221125
Epoch:[ 205 0 ] loss: 0.3516842722892761 2022-07-20 02:00:55.013595
Epoch:[ 205 1 ] loss: 0.35056599974632263 2022-07-20 02:00:55.427030
Epoch:[ 205 2 ] loss: 0.3512558043003082 2022-07-20 02:00:55.840370
Epoch:[ 205 3 ] loss: 0.350796639919281 2022-07-20 02:00:56.254922
Epoch:[ 205 4 ] loss: 0.3506389558315277 2022-07-20 02:00:56.669676
Epoch:[ 205 5 ] loss: 0.3504282832145691 2022-07-20 02:00:57.082144
Epoch:[ 205 6 ] loss: 0.3519325256347656 2022-07-20 02:00:57.498521
Epoch:[ 205 7 ] loss: 0.3515101969242096 2022-07-20 02:00:57.913328
Epoch:[ 205 8 ] loss: 0.35091713070869446 2022-07-20 02:00:58.323464
Epoch:[ 205 9 ] loss: 0.35111692547798157 2022-07-20 02:00:58.737285
Epoch:[ 205 10 ] loss: 0.3511353135108948 2022-07-20 02:00:59.151155
Epoch:[ 205 11 ] loss: 0.3517570495605469 2022-07-20 02:00:59.563805
Epoch:[ 205 12 ] loss: 0.35165631771087646 2022-07-20 02:00:59.983562
Epoch:[ 205 13 ] loss: 0.350714772939682 2022-07-20 02:01:00.400192
Epoch:[ 205 14 ] loss: 0.350207656621933 2022-07-20 02:01:00.813531
Epoch:[ 205 15 ] loss: 0.3517015278339386 2022-07-20 02:01:01.227232
Epoch:[ 205 16 ] loss: 0.35051229596138 2022-07-20 02:01:06.418655
Epoch:[ 205 17 ] loss: 0.35078537464141846 2022-07-20 02:01:06.837279
Epoch:[ 205 18 ] loss: 0.35164809226989746 2022-07-20 02:01:07.259918
Epoch:[ 205 19 ] loss: 0.3519297242164612 2022-07-20 02:01:07.670743
Training_Epoch:[ 205 ] Training_loss: 0.35114474296569825 2022-07-20 02:01:07.671470
learning rate:  3.875953108451434e-05
val: 1 0.4107929766178131
val: 2 0.4067675471305847
val: 3 0.41959378123283386
val: 4 0.42420822381973267
val: 5 0.422096848487854
val: 6 0.4166935384273529
val: 7 0.425626665353775
val: 8 0.4212454557418823
val: 9 0.4129273295402527
val: 10 0.41914042830467224
val: 11 0.4111098051071167
val: 12 0.4093504846096039
val: 13 0.42221057415008545
val: 14 0.4226014316082001
val: 15 0.4086754024028778
val: 16 0.42606374621391296
val: 17 0.42565804719924927
val: 18 0.423003226518631
val: 19 0.4198944866657257
val: 20 0.42183631658554077
val_Epoch:[ 205 ] val_loss: 0.41847481578588486 2022-07-20 02:01:10.852704
start training 2022-07-20 02:01:10.958327
Epoch:[ 206 0 ] loss: 0.35044002532958984 2022-07-20 02:01:24.944037
Epoch:[ 206 1 ] loss: 0.3513393700122833 2022-07-20 02:01:25.363047
Epoch:[ 206 2 ] loss: 0.35055795311927795 2022-07-20 02:01:25.781111
Epoch:[ 206 3 ] loss: 0.35059285163879395 2022-07-20 02:01:26.196772
Epoch:[ 206 4 ] loss: 0.3508436679840088 2022-07-20 02:01:26.611646
Epoch:[ 206 5 ] loss: 0.35118550062179565 2022-07-20 02:01:27.025342
Epoch:[ 206 6 ] loss: 0.35208094120025635 2022-07-20 02:01:27.439228
Epoch:[ 206 7 ] loss: 0.35063838958740234 2022-07-20 02:01:27.854939
Epoch:[ 206 8 ] loss: 0.35067909955978394 2022-07-20 02:01:28.265980
Epoch:[ 206 9 ] loss: 0.351691871881485 2022-07-20 02:01:28.674307
Epoch:[ 206 10 ] loss: 0.35066086053848267 2022-07-20 02:01:29.087411
Epoch:[ 206 11 ] loss: 0.35190048813819885 2022-07-20 02:01:29.501968
Epoch:[ 206 12 ] loss: 0.35084062814712524 2022-07-20 02:01:29.916448
Epoch:[ 206 13 ] loss: 0.3511795401573181 2022-07-20 02:01:30.327501
Epoch:[ 206 14 ] loss: 0.35143178701400757 2022-07-20 02:01:30.742835
Epoch:[ 206 15 ] loss: 0.35124507546424866 2022-07-20 02:01:31.157816
Epoch:[ 206 16 ] loss: 0.3513517677783966 2022-07-20 02:01:36.492464
Epoch:[ 206 17 ] loss: 0.35063350200653076 2022-07-20 02:01:36.906282
Epoch:[ 206 18 ] loss: 0.35205337405204773 2022-07-20 02:01:37.320868
Epoch:[ 206 19 ] loss: 0.3509819805622101 2022-07-20 02:01:37.728877
Training_Epoch:[ 206 ] Training_loss: 0.35111643373966217 2022-07-20 02:01:37.729811
learning rate:  3.875953108451434e-05
netparams have been saved once 206
val: 1 0.41540294885635376
val: 2 0.4060617983341217
val: 3 0.4181482791900635
val: 4 0.41917338967323303
val: 5 0.4265708029270172
val: 6 0.41108056902885437
val: 7 0.412018358707428
val: 8 0.4169940650463104
val: 9 0.4096066653728485
val: 10 0.41869792342185974
val: 11 0.41172778606414795
val: 12 0.4087715148925781
val: 13 0.4191640019416809
val: 14 0.41993701457977295
val: 15 0.4202350378036499
val: 16 0.4267866611480713
val: 17 0.41981241106987
val: 18 0.4077048897743225
val: 19 0.42025232315063477
val: 20 0.41475313901901245
val_Epoch:[ 206 ] val_loss: 0.41614497900009156 2022-07-20 02:01:41.096671
start training 2022-07-20 02:01:41.197086
Epoch:[ 207 0 ] loss: 0.3511969745159149 2022-07-20 02:01:55.341751
Epoch:[ 207 1 ] loss: 0.3513388931751251 2022-07-20 02:01:55.756240
Epoch:[ 207 2 ] loss: 0.35066062211990356 2022-07-20 02:01:56.177347
Epoch:[ 207 3 ] loss: 0.3513457179069519 2022-07-20 02:01:56.591009
Epoch:[ 207 4 ] loss: 0.35143205523490906 2022-07-20 02:01:57.010071
Epoch:[ 207 5 ] loss: 0.35128429532051086 2022-07-20 02:01:57.421912
Epoch:[ 207 6 ] loss: 0.3515019118785858 2022-07-20 02:01:57.833988
Epoch:[ 207 7 ] loss: 0.35075435042381287 2022-07-20 02:01:58.250575
Epoch:[ 207 8 ] loss: 0.3512570559978485 2022-07-20 02:01:58.663153
Epoch:[ 207 9 ] loss: 0.35036179423332214 2022-07-20 02:01:59.074773
Epoch:[ 207 10 ] loss: 0.3503667712211609 2022-07-20 02:01:59.485921
Epoch:[ 207 11 ] loss: 0.3504020869731903 2022-07-20 02:01:59.900866
Epoch:[ 207 12 ] loss: 0.3515843451023102 2022-07-20 02:02:00.314594
Epoch:[ 207 13 ] loss: 0.35140854120254517 2022-07-20 02:02:00.726890
Epoch:[ 207 14 ] loss: 0.35186880826950073 2022-07-20 02:02:01.139861
Epoch:[ 207 15 ] loss: 0.35204750299453735 2022-07-20 02:02:01.552947
Epoch:[ 207 16 ] loss: 0.35054856538772583 2022-07-20 02:02:06.354956
Epoch:[ 207 17 ] loss: 0.3508361577987671 2022-07-20 02:02:07.075931
Epoch:[ 207 18 ] loss: 0.35101112723350525 2022-07-20 02:02:07.495667
Epoch:[ 207 19 ] loss: 0.35137757658958435 2022-07-20 02:02:07.914223
Training_Epoch:[ 207 ] Training_loss: 0.3511292576789856 2022-07-20 02:02:07.915347
learning rate:  3.875953108451434e-05
val: 1 0.4260554313659668
val: 2 0.41287946701049805
val: 3 0.42134663462638855
val: 4 0.41228508949279785
val: 5 0.4283621907234192
val: 6 0.41246336698532104
val: 7 0.4169972240924835
val: 8 0.4295694828033447
val: 9 0.41925081610679626
val: 10 0.4171501398086548
val: 11 0.4057612717151642
val: 12 0.40961697697639465
val: 13 0.41906341910362244
val: 14 0.4234881103038788
val: 15 0.4041152000427246
val: 16 0.417709618806839
val: 17 0.418779581785202
val: 18 0.4192825257778168
val: 19 0.41524556279182434
val: 20 0.4210781157016754
val_Epoch:[ 207 ] val_loss: 0.41752501130104064 2022-07-20 02:02:11.127757
start training 2022-07-20 02:02:11.228375
Epoch:[ 208 0 ] loss: 0.3505686819553375 2022-07-20 02:02:25.338351
Epoch:[ 208 1 ] loss: 0.3509061634540558 2022-07-20 02:02:25.751731
Epoch:[ 208 2 ] loss: 0.3508513569831848 2022-07-20 02:02:26.166041
Epoch:[ 208 3 ] loss: 0.3512284755706787 2022-07-20 02:02:26.579920
Epoch:[ 208 4 ] loss: 0.3515901565551758 2022-07-20 02:02:26.994186
Epoch:[ 208 5 ] loss: 0.3508821427822113 2022-07-20 02:02:27.409344
Epoch:[ 208 6 ] loss: 0.3510203957557678 2022-07-20 02:02:27.823643
Epoch:[ 208 7 ] loss: 0.3510706126689911 2022-07-20 02:02:28.235835
Epoch:[ 208 8 ] loss: 0.35109901428222656 2022-07-20 02:02:28.648471
Epoch:[ 208 9 ] loss: 0.35064783692359924 2022-07-20 02:02:29.062717
Epoch:[ 208 10 ] loss: 0.3510296940803528 2022-07-20 02:02:29.482010
Epoch:[ 208 11 ] loss: 0.35085955262184143 2022-07-20 02:02:29.903418
Epoch:[ 208 12 ] loss: 0.3515523374080658 2022-07-20 02:02:30.317897
Epoch:[ 208 13 ] loss: 0.350492388010025 2022-07-20 02:02:30.732050
Epoch:[ 208 14 ] loss: 0.35182297229766846 2022-07-20 02:02:31.150194
Epoch:[ 208 15 ] loss: 0.3513282537460327 2022-07-20 02:02:31.562535
Epoch:[ 208 16 ] loss: 0.35025718808174133 2022-07-20 02:02:37.158923
Epoch:[ 208 17 ] loss: 0.3504088222980499 2022-07-20 02:02:37.576947
Epoch:[ 208 18 ] loss: 0.3510607182979584 2022-07-20 02:02:38.007262
Epoch:[ 208 19 ] loss: 0.35226568579673767 2022-07-20 02:02:38.420371
Training_Epoch:[ 208 ] Training_loss: 0.35104712247848513 2022-07-20 02:02:38.421083
learning rate:  3.875953108451434e-05
netparams have been saved once 208
val: 1 0.41565409302711487
val: 2 0.4199172556400299
val: 3 0.42745092511177063
val: 4 0.4057994782924652
val: 5 0.4138851761817932
val: 6 0.4190128743648529
val: 7 0.4143237769603729
val: 8 0.431842565536499
val: 9 0.42573368549346924
val: 10 0.4035947322845459
val: 11 0.42751067876815796
val: 12 0.42221739888191223
val: 13 0.4144522249698639
val: 14 0.416878879070282
val: 15 0.42198824882507324
val: 16 0.4131312072277069
val: 17 0.41773876547813416
val: 18 0.4204418957233429
val: 19 0.4146932363510132
val: 20 0.42106863856315613
val_Epoch:[ 208 ] val_loss: 0.41836678683757783 2022-07-20 02:02:41.702906
start training 2022-07-20 02:02:41.805080
Epoch:[ 209 0 ] loss: 0.35079944133758545 2022-07-20 02:02:55.553889
Epoch:[ 209 1 ] loss: 0.35161876678466797 2022-07-20 02:02:55.986529
Epoch:[ 209 2 ] loss: 0.35134363174438477 2022-07-20 02:02:56.402267
Epoch:[ 209 3 ] loss: 0.350717693567276 2022-07-20 02:02:56.818208
Epoch:[ 209 4 ] loss: 0.3504798710346222 2022-07-20 02:02:57.230212
Epoch:[ 209 5 ] loss: 0.35178491473197937 2022-07-20 02:02:57.645926
Epoch:[ 209 6 ] loss: 0.35172605514526367 2022-07-20 02:02:58.059969
Epoch:[ 209 7 ] loss: 0.3523368239402771 2022-07-20 02:02:58.470457
Epoch:[ 209 8 ] loss: 0.3507354259490967 2022-07-20 02:02:58.884007
Epoch:[ 209 9 ] loss: 0.3515951633453369 2022-07-20 02:02:59.298750
Epoch:[ 209 10 ] loss: 0.35068967938423157 2022-07-20 02:02:59.715029
Epoch:[ 209 11 ] loss: 0.35074183344841003 2022-07-20 02:03:00.129354
Epoch:[ 209 12 ] loss: 0.3517053723335266 2022-07-20 02:03:00.542892
Epoch:[ 209 13 ] loss: 0.35126590728759766 2022-07-20 02:03:00.955623
Epoch:[ 209 14 ] loss: 0.3508427143096924 2022-07-20 02:03:01.369514
Epoch:[ 209 15 ] loss: 0.35049062967300415 2022-07-20 02:03:01.783371
Epoch:[ 209 16 ] loss: 0.3502362072467804 2022-07-20 02:03:07.269073
Epoch:[ 209 17 ] loss: 0.35084959864616394 2022-07-20 02:03:07.698245
Epoch:[ 209 18 ] loss: 0.3510022461414337 2022-07-20 02:03:08.118143
Epoch:[ 209 19 ] loss: 0.35128504037857056 2022-07-20 02:03:08.536360
Training_Epoch:[ 209 ] Training_loss: 0.35111235082149506 2022-07-20 02:03:08.537126
learning rate:  3.875953108451434e-05
val: 1 0.4236638844013214
val: 2 0.42386552691459656
val: 3 0.4159366190433502
val: 4 0.41747725009918213
val: 5 0.4205701947212219
val: 6 0.41434046626091003
val: 7 0.4138524830341339
val: 8 0.4201465845108032
val: 9 0.42742857336997986
val: 10 0.41282418370246887
val: 11 0.4111798107624054
val: 12 0.41390424966812134
val: 13 0.41833406686782837
val: 14 0.42100611329078674
val: 15 0.427280992269516
val: 16 0.41741472482681274
val: 17 0.4198329746723175
val: 18 0.4239456057548523
val: 19 0.4092596769332886
val: 20 0.42649978399276733
val_Epoch:[ 209 ] val_loss: 0.4189381882548332 2022-07-20 02:03:11.686986
start training 2022-07-20 02:03:11.788061
Epoch:[ 210 0 ] loss: 0.3507591485977173 2022-07-20 02:03:26.129302
Epoch:[ 210 1 ] loss: 0.35082757472991943 2022-07-20 02:03:26.542715
Epoch:[ 210 2 ] loss: 0.352110892534256 2022-07-20 02:03:26.955938
Epoch:[ 210 3 ] loss: 0.3513587415218353 2022-07-20 02:03:27.369547
Epoch:[ 210 4 ] loss: 0.35036522150039673 2022-07-20 02:03:27.782920
Epoch:[ 210 5 ] loss: 0.35081249475479126 2022-07-20 02:03:28.204669
Epoch:[ 210 6 ] loss: 0.3504283130168915 2022-07-20 02:03:28.618231
Epoch:[ 210 7 ] loss: 0.3515560030937195 2022-07-20 02:03:29.030675
Epoch:[ 210 8 ] loss: 0.3508213758468628 2022-07-20 02:03:29.443260
Epoch:[ 210 9 ] loss: 0.3517072796821594 2022-07-20 02:03:29.856305
Epoch:[ 210 10 ] loss: 0.3511503338813782 2022-07-20 02:03:30.268623
Epoch:[ 210 11 ] loss: 0.35042431950569153 2022-07-20 02:03:30.682332
Epoch:[ 210 12 ] loss: 0.3506627678871155 2022-07-20 02:03:31.095368
Epoch:[ 210 13 ] loss: 0.35128486156463623 2022-07-20 02:03:31.509492
Epoch:[ 210 14 ] loss: 0.351379930973053 2022-07-20 02:03:31.928848
Epoch:[ 210 15 ] loss: 0.35185346007347107 2022-07-20 02:03:32.346901
Epoch:[ 210 16 ] loss: 0.34978795051574707 2022-07-20 02:03:37.509749
Epoch:[ 210 17 ] loss: 0.3518953025341034 2022-07-20 02:03:37.922461
Epoch:[ 210 18 ] loss: 0.3508712649345398 2022-07-20 02:03:38.342765
Epoch:[ 210 19 ] loss: 0.35124069452285767 2022-07-20 02:03:38.763823
Training_Epoch:[ 210 ] Training_loss: 0.3510648965835571 2022-07-20 02:03:38.764528
learning rate:  3.875953108451434e-05
netparams have been saved once 210
val: 1 0.4125124514102936
val: 2 0.4223810136318207
val: 3 0.42502227425575256
val: 4 0.42848625779151917
val: 5 0.4154016971588135
val: 6 0.4278867244720459
val: 7 0.41777026653289795
val: 8 0.4100722074508667
val: 9 0.4123685657978058
val: 10 0.4235915243625641
val: 11 0.41657114028930664
val: 12 0.4139257073402405
val: 13 0.4133739471435547
val: 14 0.4173213839530945
val: 15 0.4189971387386322
val: 16 0.41549938917160034
val: 17 0.4232896864414215
val: 18 0.4208432734012604
val: 19 0.40472379326820374
val: 20 0.4086766541004181
val_Epoch:[ 210 ] val_loss: 0.41743575483560563 2022-07-20 02:03:41.928439
start training 2022-07-20 02:03:42.028165
Epoch:[ 211 0 ] loss: 0.35100415349006653 2022-07-20 02:03:55.975962
Epoch:[ 211 1 ] loss: 0.35051438212394714 2022-07-20 02:03:56.383699
Epoch:[ 211 2 ] loss: 0.3511843681335449 2022-07-20 02:03:56.797903
Epoch:[ 211 3 ] loss: 0.3508983254432678 2022-07-20 02:03:57.211951
Epoch:[ 211 4 ] loss: 0.350114643573761 2022-07-20 02:03:57.625690
Epoch:[ 211 5 ] loss: 0.35077160596847534 2022-07-20 02:03:58.041182
Epoch:[ 211 6 ] loss: 0.3499153256416321 2022-07-20 02:03:58.457023
Epoch:[ 211 7 ] loss: 0.3514443635940552 2022-07-20 02:03:58.870075
Epoch:[ 211 8 ] loss: 0.3513451814651489 2022-07-20 02:03:59.282918
Epoch:[ 211 9 ] loss: 0.35083112120628357 2022-07-20 02:03:59.696898
Epoch:[ 211 10 ] loss: 0.350182443857193 2022-07-20 02:04:00.106704
Epoch:[ 211 11 ] loss: 0.35097989439964294 2022-07-20 02:04:00.520100
Epoch:[ 211 12 ] loss: 0.3513390123844147 2022-07-20 02:04:00.929699
Epoch:[ 211 13 ] loss: 0.3508123755455017 2022-07-20 02:04:01.347058
Epoch:[ 211 14 ] loss: 0.3524453341960907 2022-07-20 02:04:01.762987
Epoch:[ 211 15 ] loss: 0.35084277391433716 2022-07-20 02:04:02.177726
Epoch:[ 211 16 ] loss: 0.35071536898612976 2022-07-20 02:04:07.377930
Epoch:[ 211 17 ] loss: 0.3508630096912384 2022-07-20 02:04:07.790723
Epoch:[ 211 18 ] loss: 0.35183990001678467 2022-07-20 02:04:08.204128
Epoch:[ 211 19 ] loss: 0.351051390171051 2022-07-20 02:04:08.615293
Training_Epoch:[ 211 ] Training_loss: 0.3509547486901283 2022-07-20 02:04:08.616255
learning rate:  3.294560142183719e-05
val: 1 0.4161159098148346
val: 2 0.41417184472084045
val: 3 0.41334229707717896
val: 4 0.4163152873516083
val: 5 0.4153977930545807
val: 6 0.4140370488166809
val: 7 0.42300179600715637
val: 8 0.4209781885147095
val: 9 0.41522014141082764
val: 10 0.42039528489112854
val: 11 0.4169294536113739
val: 12 0.4228876829147339
val: 13 0.41815680265426636
val: 14 0.4137517213821411
val: 15 0.4213423430919647
val: 16 0.4140813648700714
val: 17 0.43149200081825256
val: 18 0.42650434374809265
val: 19 0.4129363000392914
val: 20 0.42220818996429443
val_Epoch:[ 211 ] val_loss: 0.4184632897377014 2022-07-20 02:04:11.885931
start training 2022-07-20 02:04:11.993249
Epoch:[ 212 0 ] loss: 0.3502888083457947 2022-07-20 02:04:26.048529
Epoch:[ 212 1 ] loss: 0.350078821182251 2022-07-20 02:04:26.460897
Epoch:[ 212 2 ] loss: 0.3510567843914032 2022-07-20 02:04:26.877756
Epoch:[ 212 3 ] loss: 0.3512471318244934 2022-07-20 02:04:27.291841
Epoch:[ 212 4 ] loss: 0.34944766759872437 2022-07-20 02:04:27.704665
Epoch:[ 212 5 ] loss: 0.3507642447948456 2022-07-20 02:04:28.118389
Epoch:[ 212 6 ] loss: 0.3509596884250641 2022-07-20 02:04:28.533585
Epoch:[ 212 7 ] loss: 0.35120680928230286 2022-07-20 02:04:28.943809
Epoch:[ 212 8 ] loss: 0.34998929500579834 2022-07-20 02:04:29.352960
Epoch:[ 212 9 ] loss: 0.35053813457489014 2022-07-20 02:04:29.764936
Epoch:[ 212 10 ] loss: 0.35080498456954956 2022-07-20 02:04:30.178975
Epoch:[ 212 11 ] loss: 0.3513491749763489 2022-07-20 02:04:30.592661
Epoch:[ 212 12 ] loss: 0.35048016905784607 2022-07-20 02:04:31.005053
Epoch:[ 212 13 ] loss: 0.35145536065101624 2022-07-20 02:04:31.419955
Epoch:[ 212 14 ] loss: 0.35005268454551697 2022-07-20 02:04:31.835438
Epoch:[ 212 15 ] loss: 0.3516388237476349 2022-07-20 02:04:32.248860
Epoch:[ 212 16 ] loss: 0.3511158525943756 2022-07-20 02:04:37.763432
Epoch:[ 212 17 ] loss: 0.35060688853263855 2022-07-20 02:04:38.176815
Epoch:[ 212 18 ] loss: 0.3512570261955261 2022-07-20 02:04:38.591657
Epoch:[ 212 19 ] loss: 0.3505099415779114 2022-07-20 02:04:39.001815
Training_Epoch:[ 212 ] Training_loss: 0.3507424145936966 2022-07-20 02:04:39.002616
learning rate:  3.294560142183719e-05
netparams have been saved once 212
val: 1 0.41269493103027344
val: 2 0.4070899188518524
val: 3 0.40897536277770996
val: 4 0.4076334536075592
val: 5 0.42728614807128906
val: 6 0.42309120297431946
val: 7 0.4128686189651489
val: 8 0.4167611002922058
val: 9 0.4232245981693268
val: 10 0.4203495383262634
val: 11 0.42051637172698975
val: 12 0.416107714176178
val: 13 0.41450387239456177
val: 14 0.42265966534614563
val: 15 0.4178663194179535
val: 16 0.4247284233570099
val: 17 0.4231001138687134
val: 18 0.42279887199401855
val: 19 0.41800397634506226
val: 20 0.4112313687801361
val_Epoch:[ 212 ] val_loss: 0.4175745785236359 2022-07-20 02:04:42.307643
start training 2022-07-20 02:04:42.416584
Epoch:[ 213 0 ] loss: 0.35054633021354675 2022-07-20 02:04:56.213528
Epoch:[ 213 1 ] loss: 0.3510371148586273 2022-07-20 02:04:56.629059
Epoch:[ 213 2 ] loss: 0.3509281575679779 2022-07-20 02:04:57.040934
Epoch:[ 213 3 ] loss: 0.35030949115753174 2022-07-20 02:04:57.452321
Epoch:[ 213 4 ] loss: 0.35177454352378845 2022-07-20 02:04:57.864562
Epoch:[ 213 5 ] loss: 0.35081005096435547 2022-07-20 02:04:58.278009
Epoch:[ 213 6 ] loss: 0.34996405243873596 2022-07-20 02:04:58.695150
Epoch:[ 213 7 ] loss: 0.35172542929649353 2022-07-20 02:04:59.111001
Epoch:[ 213 8 ] loss: 0.3514153063297272 2022-07-20 02:04:59.524987
Epoch:[ 213 9 ] loss: 0.3501463234424591 2022-07-20 02:04:59.938436
Epoch:[ 213 10 ] loss: 0.35049140453338623 2022-07-20 02:05:00.357940
Epoch:[ 213 11 ] loss: 0.35072824358940125 2022-07-20 02:05:00.770550
Epoch:[ 213 12 ] loss: 0.3495434820652008 2022-07-20 02:05:01.182378
Epoch:[ 213 13 ] loss: 0.3502607047557831 2022-07-20 02:05:01.594979
Epoch:[ 213 14 ] loss: 0.3499198853969574 2022-07-20 02:05:02.009815
Epoch:[ 213 15 ] loss: 0.3502527177333832 2022-07-20 02:05:02.423319
Epoch:[ 213 16 ] loss: 0.35119518637657166 2022-07-20 02:05:07.947065
Epoch:[ 213 17 ] loss: 0.3508383631706238 2022-07-20 02:05:08.362913
Epoch:[ 213 18 ] loss: 0.3507653772830963 2022-07-20 02:05:08.783216
Epoch:[ 213 19 ] loss: 0.3506707549095154 2022-07-20 02:05:09.200482
Training_Epoch:[ 213 ] Training_loss: 0.3506661459803581 2022-07-20 02:05:09.201182
learning rate:  3.294560142183719e-05
val: 1 0.4250272512435913
val: 2 0.4224773645401001
val: 3 0.42130032181739807
val: 4 0.41327154636383057
val: 5 0.41024941205978394
val: 6 0.420824259519577
val: 7 0.41701337695121765
val: 8 0.4265879690647125
val: 9 0.41648608446121216
val: 10 0.42606568336486816
val: 11 0.41432154178619385
val: 12 0.407458633184433
val: 13 0.4245627522468567
val: 14 0.4136757552623749
val: 15 0.4263589382171631
val: 16 0.41977131366729736
val: 17 0.42657673358917236
val: 18 0.4242511987686157
val: 19 0.41200610995292664
val: 20 0.42338231205940247
val_Epoch:[ 213 ] val_loss: 0.41958342790603637 2022-07-20 02:05:12.372608
start training 2022-07-20 02:05:12.471065
Epoch:[ 214 0 ] loss: 0.3514988422393799 2022-07-20 02:05:26.269025
Epoch:[ 214 1 ] loss: 0.3506975769996643 2022-07-20 02:05:26.701896
Epoch:[ 214 2 ] loss: 0.35148894786834717 2022-07-20 02:05:27.116496
Epoch:[ 214 3 ] loss: 0.34969258308410645 2022-07-20 02:05:27.529223
Epoch:[ 214 4 ] loss: 0.3500424027442932 2022-07-20 02:05:27.942132
Epoch:[ 214 5 ] loss: 0.3507475256919861 2022-07-20 02:05:28.354836
Epoch:[ 214 6 ] loss: 0.3504228889942169 2022-07-20 02:05:28.767069
Epoch:[ 214 7 ] loss: 0.3512980043888092 2022-07-20 02:05:29.181148
Epoch:[ 214 8 ] loss: 0.35132864117622375 2022-07-20 02:05:29.593808
Epoch:[ 214 9 ] loss: 0.34966522455215454 2022-07-20 02:05:30.011598
Epoch:[ 214 10 ] loss: 0.35077446699142456 2022-07-20 02:05:30.423696
Epoch:[ 214 11 ] loss: 0.3502407670021057 2022-07-20 02:05:30.836996
Epoch:[ 214 12 ] loss: 0.3501337766647339 2022-07-20 02:05:31.255051
Epoch:[ 214 13 ] loss: 0.3508571982383728 2022-07-20 02:05:31.666715
Epoch:[ 214 14 ] loss: 0.3515132963657379 2022-07-20 02:05:32.079258
Epoch:[ 214 15 ] loss: 0.35020387172698975 2022-07-20 02:05:32.493603
Epoch:[ 214 16 ] loss: 0.3502964377403259 2022-07-20 02:05:38.069317
Epoch:[ 214 17 ] loss: 0.351119726896286 2022-07-20 02:05:38.482079
Epoch:[ 214 18 ] loss: 0.35031092166900635 2022-07-20 02:05:38.897660
Epoch:[ 214 19 ] loss: 0.35075843334198 2022-07-20 02:05:39.315485
Training_Epoch:[ 214 ] Training_loss: 0.35065457671880723 2022-07-20 02:05:39.316164
learning rate:  3.294560142183719e-05
netparams have been saved once 214
val: 1 0.42147931456565857
val: 2 0.41744354367256165
val: 3 0.41285133361816406
val: 4 0.4147945046424866
val: 5 0.42517468333244324
val: 6 0.411744087934494
val: 7 0.4175533056259155
val: 8 0.41872456669807434
val: 9 0.41946306824684143
val: 10 0.4097948372364044
val: 11 0.4103698432445526
val: 12 0.4106736481189728
val: 13 0.42067235708236694
val: 14 0.41771313548088074
val: 15 0.4158737361431122
val: 16 0.42737942934036255
val: 17 0.4109862446784973
val: 18 0.4133179783821106
val: 19 0.4163968861103058
val: 20 0.41803455352783203
val_Epoch:[ 214 ] val_loss: 0.4165220528841019 2022-07-20 02:05:42.520996
start training 2022-07-20 02:05:42.626917
Epoch:[ 215 0 ] loss: 0.35052812099456787 2022-07-20 02:05:56.312808
Epoch:[ 215 1 ] loss: 0.3514370620250702 2022-07-20 02:05:56.943656
Epoch:[ 215 2 ] loss: 0.35107293725013733 2022-07-20 02:05:57.364965
Epoch:[ 215 3 ] loss: 0.3513088524341583 2022-07-20 02:05:57.779120
Epoch:[ 215 4 ] loss: 0.3505403697490692 2022-07-20 02:05:58.190728
Epoch:[ 215 5 ] loss: 0.35062694549560547 2022-07-20 02:05:58.609991
Epoch:[ 215 6 ] loss: 0.3496779799461365 2022-07-20 02:05:59.023355
Epoch:[ 215 7 ] loss: 0.35013389587402344 2022-07-20 02:05:59.435650
Epoch:[ 215 8 ] loss: 0.35061559081077576 2022-07-20 02:05:59.848710
Epoch:[ 215 9 ] loss: 0.35098227858543396 2022-07-20 02:06:00.262878
Epoch:[ 215 10 ] loss: 0.3505462110042572 2022-07-20 02:06:00.677347
Epoch:[ 215 11 ] loss: 0.3508016765117645 2022-07-20 02:06:01.090648
Epoch:[ 215 12 ] loss: 0.35044312477111816 2022-07-20 02:06:01.502730
Epoch:[ 215 13 ] loss: 0.3521985709667206 2022-07-20 02:06:01.920485
Epoch:[ 215 14 ] loss: 0.351301372051239 2022-07-20 02:06:02.335284
Epoch:[ 215 15 ] loss: 0.3499302268028259 2022-07-20 02:06:02.748175
Epoch:[ 215 16 ] loss: 0.3505059480667114 2022-07-20 02:06:08.183994
Epoch:[ 215 17 ] loss: 0.35074248909950256 2022-07-20 02:06:08.598209
Epoch:[ 215 18 ] loss: 0.35121387243270874 2022-07-20 02:06:09.019795
Epoch:[ 215 19 ] loss: 0.34978771209716797 2022-07-20 02:06:09.438072
Training_Epoch:[ 215 ] Training_loss: 0.3507197618484497 2022-07-20 02:06:09.438813
learning rate:  3.294560142183719e-05
val: 1 0.4160305857658386
val: 2 0.4129304587841034
val: 3 0.42446455359458923
val: 4 0.4201716482639313
val: 5 0.4294378459453583
val: 6 0.4188564717769623
val: 7 0.42998018860816956
val: 8 0.420594722032547
val: 9 0.42337101697921753
val: 10 0.42006638646125793
val: 11 0.4060824513435364
val: 12 0.41423672437667847
val: 13 0.418148934841156
val: 14 0.4302682876586914
val: 15 0.4160332977771759
val: 16 0.4252036511898041
val: 17 0.4162456691265106
val: 18 0.4221112132072449
val: 19 0.41834118962287903
val: 20 0.41774290800094604
val_Epoch:[ 215 ] val_loss: 0.4200159102678299 2022-07-20 02:06:12.586536
start training 2022-07-20 02:06:12.684675
Epoch:[ 216 0 ] loss: 0.3507762551307678 2022-07-20 02:06:26.437084
Epoch:[ 216 1 ] loss: 0.34951817989349365 2022-07-20 02:06:26.861267
Epoch:[ 216 2 ] loss: 0.3508788049221039 2022-07-20 02:06:27.273508
Epoch:[ 216 3 ] loss: 0.3506137728691101 2022-07-20 02:06:27.686768
Epoch:[ 216 4 ] loss: 0.34959501028060913 2022-07-20 02:06:28.101477
Epoch:[ 216 5 ] loss: 0.3512760400772095 2022-07-20 02:06:28.515177
Epoch:[ 216 6 ] loss: 0.35104134678840637 2022-07-20 02:06:28.930145
Epoch:[ 216 7 ] loss: 0.3506202697753906 2022-07-20 02:06:29.343985
Epoch:[ 216 8 ] loss: 0.35215291380882263 2022-07-20 02:06:29.756185
Epoch:[ 216 9 ] loss: 0.3505040109157562 2022-07-20 02:06:30.168511
Epoch:[ 216 10 ] loss: 0.35077765583992004 2022-07-20 02:06:30.588659
Epoch:[ 216 11 ] loss: 0.35002627968788147 2022-07-20 02:06:31.003235
Epoch:[ 216 12 ] loss: 0.3509212136268616 2022-07-20 02:06:31.416094
Epoch:[ 216 13 ] loss: 0.35144656896591187 2022-07-20 02:06:31.828510
Epoch:[ 216 14 ] loss: 0.35083386301994324 2022-07-20 02:06:32.242755
Epoch:[ 216 15 ] loss: 0.3511296510696411 2022-07-20 02:06:32.656206
Epoch:[ 216 16 ] loss: 0.35176968574523926 2022-07-20 02:06:37.793399
Epoch:[ 216 17 ] loss: 0.350820928812027 2022-07-20 02:06:38.298266
Epoch:[ 216 18 ] loss: 0.3507901430130005 2022-07-20 02:06:38.718197
Epoch:[ 216 19 ] loss: 0.35076743364334106 2022-07-20 02:06:39.137787
Training_Epoch:[ 216 ] Training_loss: 0.35081300139427185 2022-07-20 02:06:39.138521
learning rate:  3.294560142183719e-05
netparams have been saved once 216
val: 1 0.41601628065109253
val: 2 0.4129854142665863
val: 3 0.42075249552726746
val: 4 0.40960264205932617
val: 5 0.4217437207698822
val: 6 0.4178546965122223
val: 7 0.4156026244163513
val: 8 0.42159003019332886
val: 9 0.421304315328598
val: 10 0.42008012533187866
val: 11 0.4311878979206085
val: 12 0.4267733693122864
val: 13 0.4238814115524292
val: 14 0.4205721914768219
val: 15 0.4191267192363739
val: 16 0.40825435519218445
val: 17 0.41258704662323
val: 18 0.4179903268814087
val: 19 0.43170037865638733
val: 20 0.413543701171875
val_Epoch:[ 216 ] val_loss: 0.41915748715400697 2022-07-20 02:06:42.344506
start training 2022-07-20 02:06:42.446272
Epoch:[ 217 0 ] loss: 0.3517284095287323 2022-07-20 02:06:56.617856
Epoch:[ 217 1 ] loss: 0.34980544447898865 2022-07-20 02:06:57.029878
Epoch:[ 217 2 ] loss: 0.35107213258743286 2022-07-20 02:06:57.440355
Epoch:[ 217 3 ] loss: 0.35013696551322937 2022-07-20 02:06:57.852360
Epoch:[ 217 4 ] loss: 0.35013124346733093 2022-07-20 02:06:58.264641
Epoch:[ 217 5 ] loss: 0.349234014749527 2022-07-20 02:06:58.677996
Epoch:[ 217 6 ] loss: 0.3501395583152771 2022-07-20 02:06:59.094522
Epoch:[ 217 7 ] loss: 0.3507242798805237 2022-07-20 02:06:59.506377
Epoch:[ 217 8 ] loss: 0.3499221205711365 2022-07-20 02:06:59.918234
Epoch:[ 217 9 ] loss: 0.35176441073417664 2022-07-20 02:07:00.329807
Epoch:[ 217 10 ] loss: 0.35003194212913513 2022-07-20 02:07:00.748827
Epoch:[ 217 11 ] loss: 0.35148417949676514 2022-07-20 02:07:01.162654
Epoch:[ 217 12 ] loss: 0.35075390338897705 2022-07-20 02:07:01.575919
Epoch:[ 217 13 ] loss: 0.3500383496284485 2022-07-20 02:07:01.988031
Epoch:[ 217 14 ] loss: 0.35093119740486145 2022-07-20 02:07:02.399496
Epoch:[ 217 15 ] loss: 0.35130342841148376 2022-07-20 02:07:02.812059
Epoch:[ 217 16 ] loss: 0.3502744138240814 2022-07-20 02:07:08.612717
Epoch:[ 217 17 ] loss: 0.3522864878177643 2022-07-20 02:07:09.029580
Epoch:[ 217 18 ] loss: 0.34997299313545227 2022-07-20 02:07:09.450984
Epoch:[ 217 19 ] loss: 0.3513849079608917 2022-07-20 02:07:09.863329
Training_Epoch:[ 217 ] Training_loss: 0.3506560191512108 2022-07-20 02:07:09.864064
learning rate:  3.294560142183719e-05
val: 1 0.4129386842250824
val: 2 0.4127499759197235
val: 3 0.4210513234138489
val: 4 0.41565343737602234
val: 5 0.4335567057132721
val: 6 0.4176042675971985
val: 7 0.4134598970413208
val: 8 0.4232152998447418
val: 9 0.4043622314929962
val: 10 0.4151565432548523
val: 11 0.41738268733024597
val: 12 0.41853299736976624
val: 13 0.41669508814811707
val: 14 0.40818920731544495
val: 15 0.4134059548377991
val: 16 0.42692121863365173
val: 17 0.4238045811653137
val: 18 0.4133048355579376
val: 19 0.4177896976470947
val: 20 0.4249098300933838
val_Epoch:[ 217 ] val_loss: 0.41753422319889066 2022-07-20 02:07:13.006220
start training 2022-07-20 02:07:13.105433
Epoch:[ 218 0 ] loss: 0.34992483258247375 2022-07-20 02:07:27.520674
Epoch:[ 218 1 ] loss: 0.35106760263442993 2022-07-20 02:07:27.931641
Epoch:[ 218 2 ] loss: 0.35025063157081604 2022-07-20 02:07:28.349911
Epoch:[ 218 3 ] loss: 0.3499237596988678 2022-07-20 02:07:28.762561
Epoch:[ 218 4 ] loss: 0.3498961925506592 2022-07-20 02:07:29.175048
Epoch:[ 218 5 ] loss: 0.3505907952785492 2022-07-20 02:07:29.589334
Epoch:[ 218 6 ] loss: 0.3503546118736267 2022-07-20 02:07:30.003227
Epoch:[ 218 7 ] loss: 0.35045087337493896 2022-07-20 02:07:30.414705
Epoch:[ 218 8 ] loss: 0.35085099935531616 2022-07-20 02:07:30.826586
Epoch:[ 218 9 ] loss: 0.3519100248813629 2022-07-20 02:07:31.239504
Epoch:[ 218 10 ] loss: 0.3520379364490509 2022-07-20 02:07:31.652623
Epoch:[ 218 11 ] loss: 0.34974876046180725 2022-07-20 02:07:32.066734
Epoch:[ 218 12 ] loss: 0.3500085771083832 2022-07-20 02:07:32.480641
Epoch:[ 218 13 ] loss: 0.3520384430885315 2022-07-20 02:07:32.893149
Epoch:[ 218 14 ] loss: 0.34995853900909424 2022-07-20 02:07:33.311409
Epoch:[ 218 15 ] loss: 0.3491227924823761 2022-07-20 02:07:33.729111
Epoch:[ 218 16 ] loss: 0.3504578769207001 2022-07-20 02:07:39.299668
Epoch:[ 218 17 ] loss: 0.35035160183906555 2022-07-20 02:07:39.717865
Epoch:[ 218 18 ] loss: 0.3509799540042877 2022-07-20 02:07:40.140262
Epoch:[ 218 19 ] loss: 0.35055288672447205 2022-07-20 02:07:40.554202
Training_Epoch:[ 218 ] Training_loss: 0.35052388459444045 2022-07-20 02:07:40.554895
learning rate:  3.294560142183719e-05
netparams have been saved once 218
val: 1 0.4256974756717682
val: 2 0.43146783113479614
val: 3 0.4128923714160919
val: 4 0.42514094710350037
val: 5 0.4177289605140686
val: 6 0.4080016016960144
val: 7 0.4149208664894104
val: 8 0.41341620683670044
val: 9 0.41278213262557983
val: 10 0.4272713363170624
val: 11 0.4098414182662964
val: 12 0.4198327660560608
val: 13 0.42300865054130554
val: 14 0.4218365252017975
val: 15 0.4129672944545746
val: 16 0.4185200333595276
val: 17 0.41004928946495056
val: 18 0.44076088070869446
val: 19 0.4157976806163788
val: 20 0.42073580622673035
val_Epoch:[ 218 ] val_loss: 0.41913350373506547 2022-07-20 02:07:43.738456
start training 2022-07-20 02:07:43.839652
Epoch:[ 219 0 ] loss: 0.35050836205482483 2022-07-20 02:07:57.765040
Epoch:[ 219 1 ] loss: 0.3503161668777466 2022-07-20 02:07:58.191250
Epoch:[ 219 2 ] loss: 0.3500204086303711 2022-07-20 02:07:58.604429
Epoch:[ 219 3 ] loss: 0.3500213921070099 2022-07-20 02:07:59.016956
Epoch:[ 219 4 ] loss: 0.3506905138492584 2022-07-20 02:07:59.436262
Epoch:[ 219 5 ] loss: 0.3501308858394623 2022-07-20 02:07:59.848782
Epoch:[ 219 6 ] loss: 0.3505443036556244 2022-07-20 02:08:00.264124
Epoch:[ 219 7 ] loss: 0.35010436177253723 2022-07-20 02:08:00.678617
Epoch:[ 219 8 ] loss: 0.351188063621521 2022-07-20 02:08:01.097405
Epoch:[ 219 9 ] loss: 0.35123470425605774 2022-07-20 02:08:01.511288
Epoch:[ 219 10 ] loss: 0.35019785165786743 2022-07-20 02:08:01.925753
Epoch:[ 219 11 ] loss: 0.35066327452659607 2022-07-20 02:08:02.338228
Epoch:[ 219 12 ] loss: 0.35049110651016235 2022-07-20 02:08:02.751543
Epoch:[ 219 13 ] loss: 0.3511486351490021 2022-07-20 02:08:03.167273
Epoch:[ 219 14 ] loss: 0.35025569796562195 2022-07-20 02:08:03.583337
Epoch:[ 219 15 ] loss: 0.35055822134017944 2022-07-20 02:08:03.996090
Epoch:[ 219 16 ] loss: 0.35114744305610657 2022-07-20 02:08:09.256844
Epoch:[ 219 17 ] loss: 0.35115107893943787 2022-07-20 02:08:09.669724
Epoch:[ 219 18 ] loss: 0.35078057646751404 2022-07-20 02:08:10.094943
Epoch:[ 219 19 ] loss: 0.350860595703125 2022-07-20 02:08:10.511418
Training_Epoch:[ 219 ] Training_loss: 0.3506006821990013 2022-07-20 02:08:10.512074
learning rate:  3.294560142183719e-05
val: 1 0.4112692177295685
val: 2 0.42395949363708496
val: 3 0.4114043712615967
val: 4 0.4179897904396057
val: 5 0.41938522458076477
val: 6 0.4077564775943756
val: 7 0.4229419231414795
val: 8 0.42504745721817017
val: 9 0.4238116145133972
val: 10 0.4206749498844147
val: 11 0.4188989996910095
val: 12 0.41623565554618835
val: 13 0.41721218824386597
val: 14 0.4208955466747284
val: 15 0.41141757369041443
val: 16 0.419544517993927
val: 17 0.4131655991077423
val: 18 0.4140717089176178
val: 19 0.4194659888744354
val: 20 0.4147266447544098
val_Epoch:[ 219 ] val_loss: 0.41749374717473986 2022-07-20 02:08:13.655378
start training 2022-07-20 02:08:13.761144
Epoch:[ 220 0 ] loss: 0.3506872355937958 2022-07-20 02:08:27.566214
Epoch:[ 220 1 ] loss: 0.3510091304779053 2022-07-20 02:08:28.000345
Epoch:[ 220 2 ] loss: 0.35179421305656433 2022-07-20 02:08:28.412572
Epoch:[ 220 3 ] loss: 0.3511238992214203 2022-07-20 02:08:28.827050
Epoch:[ 220 4 ] loss: 0.350522518157959 2022-07-20 02:08:29.241306
Epoch:[ 220 5 ] loss: 0.35005268454551697 2022-07-20 02:08:29.653967
Epoch:[ 220 6 ] loss: 0.350400447845459 2022-07-20 02:08:30.072273
Epoch:[ 220 7 ] loss: 0.35080239176750183 2022-07-20 02:08:30.486268
Epoch:[ 220 8 ] loss: 0.35039782524108887 2022-07-20 02:08:30.900725
Epoch:[ 220 9 ] loss: 0.35047072172164917 2022-07-20 02:08:31.313722
Epoch:[ 220 10 ] loss: 0.3502391278743744 2022-07-20 02:08:31.723105
Epoch:[ 220 11 ] loss: 0.35008805990219116 2022-07-20 02:08:32.137997
Epoch:[ 220 12 ] loss: 0.3502689301967621 2022-07-20 02:08:32.551047
Epoch:[ 220 13 ] loss: 0.3507940471172333 2022-07-20 02:08:32.965697
Epoch:[ 220 14 ] loss: 0.34994781017303467 2022-07-20 02:08:33.380951
Epoch:[ 220 15 ] loss: 0.3505822420120239 2022-07-20 02:08:33.795853
Epoch:[ 220 16 ] loss: 0.35148200392723083 2022-07-20 02:08:39.371515
Epoch:[ 220 17 ] loss: 0.35053005814552307 2022-07-20 02:08:39.785471
Epoch:[ 220 18 ] loss: 0.3505513668060303 2022-07-20 02:08:40.204849
Epoch:[ 220 19 ] loss: 0.3511645495891571 2022-07-20 02:08:40.616077
Training_Epoch:[ 220 ] Training_loss: 0.35064546316862105 2022-07-20 02:08:40.616903
learning rate:  3.294560142183719e-05
netparams have been saved once 220
val: 1 0.40784627199172974
val: 2 0.41721194982528687
val: 3 0.4125502407550812
val: 4 0.4217586815357208
val: 5 0.41810470819473267
val: 6 0.41430899500846863
val: 7 0.4297292232513428
val: 8 0.41586771607398987
val: 9 0.4265582263469696
val: 10 0.42573413252830505
val: 11 0.41283518075942993
val: 12 0.41960424184799194
val: 13 0.418678343296051
val: 14 0.42115920782089233
val: 15 0.4215330183506012
val: 16 0.4162202477455139
val: 17 0.4098644554615021
val: 18 0.42056500911712646
val: 19 0.42302176356315613
val: 20 0.4205065965652466
val_Epoch:[ 220 ] val_loss: 0.41868291050195694 2022-07-20 02:08:43.828923
start training 2022-07-20 02:08:43.931619
Epoch:[ 221 0 ] loss: 0.3522442877292633 2022-07-20 02:08:57.751231
Epoch:[ 221 1 ] loss: 0.35038360953330994 2022-07-20 02:08:58.183104
Epoch:[ 221 2 ] loss: 0.35033106803894043 2022-07-20 02:08:58.599488
Epoch:[ 221 3 ] loss: 0.3511310815811157 2022-07-20 02:08:59.014299
Epoch:[ 221 4 ] loss: 0.3501235246658325 2022-07-20 02:08:59.425429
Epoch:[ 221 5 ] loss: 0.3496122360229492 2022-07-20 02:08:59.837729
Epoch:[ 221 6 ] loss: 0.35077497363090515 2022-07-20 02:09:00.250063
Epoch:[ 221 7 ] loss: 0.35053589940071106 2022-07-20 02:09:00.662077
Epoch:[ 221 8 ] loss: 0.3503783047199249 2022-07-20 02:09:01.081904
Epoch:[ 221 9 ] loss: 0.3508394658565521 2022-07-20 02:09:01.501476
Epoch:[ 221 10 ] loss: 0.35078972578048706 2022-07-20 02:09:01.914051
Epoch:[ 221 11 ] loss: 0.3498222529888153 2022-07-20 02:09:02.326873
Epoch:[ 221 12 ] loss: 0.35075321793556213 2022-07-20 02:09:02.738692
Epoch:[ 221 13 ] loss: 0.3509407937526703 2022-07-20 02:09:03.151260
Epoch:[ 221 14 ] loss: 0.3504824936389923 2022-07-20 02:09:03.562884
Epoch:[ 221 15 ] loss: 0.3510456085205078 2022-07-20 02:09:03.976905
Epoch:[ 221 16 ] loss: 0.34939002990722656 2022-07-20 02:09:09.464967
Epoch:[ 221 17 ] loss: 0.3503905236721039 2022-07-20 02:09:09.881600
Epoch:[ 221 18 ] loss: 0.35036203265190125 2022-07-20 02:09:10.302321
Epoch:[ 221 19 ] loss: 0.34905117750167847 2022-07-20 02:09:10.720268
Training_Epoch:[ 221 ] Training_loss: 0.35046911537647246 2022-07-20 02:09:10.720966
learning rate:  2.800376120856161e-05
val: 1 0.4317905902862549
val: 2 0.4090037941932678
val: 3 0.4081241190433502
val: 4 0.418707013130188
val: 5 0.4209725260734558
val: 6 0.4244075119495392
val: 7 0.42569130659103394
val: 8 0.4271504878997803
val: 9 0.42338889837265015
val: 10 0.4241478145122528
val: 11 0.42733728885650635
val: 12 0.4183185398578644
val: 13 0.4232321083545685
val: 14 0.42154988646507263
val: 15 0.4065451920032501
val: 16 0.4178541302680969
val: 17 0.4249703288078308
val: 18 0.4101032316684723
val: 19 0.4228161871433258
val: 20 0.4169199764728546
val_Epoch:[ 221 ] val_loss: 0.4201515465974808 2022-07-20 02:09:13.884153
start training 2022-07-20 02:09:13.982458
Epoch:[ 222 0 ] loss: 0.35038644075393677 2022-07-20 02:09:27.861434
Epoch:[ 222 1 ] loss: 0.35058173537254333 2022-07-20 02:09:28.274250
Epoch:[ 222 2 ] loss: 0.3508566915988922 2022-07-20 02:09:28.688573
Epoch:[ 222 3 ] loss: 0.34982049465179443 2022-07-20 02:09:29.102807
Epoch:[ 222 4 ] loss: 0.34956449270248413 2022-07-20 02:09:29.514752
Epoch:[ 222 5 ] loss: 0.35023972392082214 2022-07-20 02:09:29.927159
Epoch:[ 222 6 ] loss: 0.35117870569229126 2022-07-20 02:09:30.340334
Epoch:[ 222 7 ] loss: 0.35026633739471436 2022-07-20 02:09:30.751765
Epoch:[ 222 8 ] loss: 0.34986016154289246 2022-07-20 02:09:31.164074
Epoch:[ 222 9 ] loss: 0.35120734572410583 2022-07-20 02:09:31.576821
Epoch:[ 222 10 ] loss: 0.35046279430389404 2022-07-20 02:09:31.995554
Epoch:[ 222 11 ] loss: 0.3502284586429596 2022-07-20 02:09:32.413439
Epoch:[ 222 12 ] loss: 0.34965652227401733 2022-07-20 02:09:32.824053
Epoch:[ 222 13 ] loss: 0.3507591187953949 2022-07-20 02:09:33.236480
Epoch:[ 222 14 ] loss: 0.35021844506263733 2022-07-20 02:09:33.648521
Epoch:[ 222 15 ] loss: 0.3504120409488678 2022-07-20 02:09:34.064073
Epoch:[ 222 16 ] loss: 0.35144534707069397 2022-07-20 02:09:39.645512
Epoch:[ 222 17 ] loss: 0.35147684812545776 2022-07-20 02:09:40.058258
Epoch:[ 222 18 ] loss: 0.3503516912460327 2022-07-20 02:09:40.472204
Epoch:[ 222 19 ] loss: 0.3505975306034088 2022-07-20 02:09:40.889080
Training_Epoch:[ 222 ] Training_loss: 0.3504785463213921 2022-07-20 02:09:40.889775
learning rate:  2.800376120856161e-05
netparams have been saved once 222
val: 1 0.4097030758857727
val: 2 0.41727760434150696
val: 3 0.42318931221961975
val: 4 0.41636765003204346
val: 5 0.4323497414588928
val: 6 0.42519262433052063
val: 7 0.4154287278652191
val: 8 0.41910111904144287
val: 9 0.4177010655403137
val: 10 0.4188147783279419
val: 11 0.4274819791316986
val: 12 0.4191231429576874
val: 13 0.4139140248298645
val: 14 0.41681772470474243
val: 15 0.4102272093296051
val: 16 0.4228665232658386
val: 17 0.41685110330581665
val: 18 0.4154590666294098
val: 19 0.4219065308570862
val: 20 0.4182596802711487
val_Epoch:[ 222 ] val_loss: 0.4189016342163086 2022-07-20 02:09:44.049788
start training 2022-07-20 02:09:44.151936
Epoch:[ 223 0 ] loss: 0.3500450849533081 2022-07-20 02:09:57.810499
Epoch:[ 223 1 ] loss: 0.3506377935409546 2022-07-20 02:09:58.240874
Epoch:[ 223 2 ] loss: 0.34999099373817444 2022-07-20 02:09:58.654923
Epoch:[ 223 3 ] loss: 0.35089343786239624 2022-07-20 02:09:59.068657
Epoch:[ 223 4 ] loss: 0.35036206245422363 2022-07-20 02:09:59.483566
Epoch:[ 223 5 ] loss: 0.3501199781894684 2022-07-20 02:09:59.901704
Epoch:[ 223 6 ] loss: 0.34908220171928406 2022-07-20 02:10:00.315645
Epoch:[ 223 7 ] loss: 0.3504899740219116 2022-07-20 02:10:00.729408
Epoch:[ 223 8 ] loss: 0.35244277119636536 2022-07-20 02:10:01.143280
Epoch:[ 223 9 ] loss: 0.3502984642982483 2022-07-20 02:10:01.555946
Epoch:[ 223 10 ] loss: 0.35091209411621094 2022-07-20 02:10:01.970766
Epoch:[ 223 11 ] loss: 0.3503570854663849 2022-07-20 02:10:02.384215
Epoch:[ 223 12 ] loss: 0.350714772939682 2022-07-20 02:10:02.797308
Epoch:[ 223 13 ] loss: 0.3514757752418518 2022-07-20 02:10:03.214650
Epoch:[ 223 14 ] loss: 0.35090377926826477 2022-07-20 02:10:03.627050
Epoch:[ 223 15 ] loss: 0.3500520586967468 2022-07-20 02:10:04.041392
Epoch:[ 223 16 ] loss: 0.34974968433380127 2022-07-20 02:10:09.339481
Epoch:[ 223 17 ] loss: 0.3506263792514801 2022-07-20 02:10:09.753347
Epoch:[ 223 18 ] loss: 0.35106271505355835 2022-07-20 02:10:10.173681
Epoch:[ 223 19 ] loss: 0.35154619812965393 2022-07-20 02:10:10.591943
Training_Epoch:[ 223 ] Training_loss: 0.3505881652235985 2022-07-20 02:10:10.592651
learning rate:  2.800376120856161e-05
val: 1 0.4211907982826233
val: 2 0.41376882791519165
val: 3 0.4130275547504425
val: 4 0.423885315656662
val: 5 0.4108530879020691
val: 6 0.41402310132980347
val: 7 0.4272565543651581
val: 8 0.41503363847732544
val: 9 0.4253905117511749
val: 10 0.42118728160858154
val: 11 0.40704384446144104
val: 12 0.41887566447257996
val: 13 0.4168599247932434
val: 14 0.4135010838508606
val: 15 0.4052925407886505
val: 16 0.42845049500465393
val: 17 0.4061776399612427
val: 18 0.4244924485683441
val: 19 0.41855841875076294
val: 20 0.40932610630989075
val_Epoch:[ 223 ] val_loss: 0.4167097419500351 2022-07-20 02:10:13.726185
start training 2022-07-20 02:10:13.824478
Epoch:[ 224 0 ] loss: 0.35123270750045776 2022-07-20 02:10:27.260228
Epoch:[ 224 1 ] loss: 0.35053500533103943 2022-07-20 02:10:27.681043
Epoch:[ 224 2 ] loss: 0.3505290746688843 2022-07-20 02:10:28.094380
Epoch:[ 224 3 ] loss: 0.350985586643219 2022-07-20 02:10:28.511476
Epoch:[ 224 4 ] loss: 0.3500652611255646 2022-07-20 02:10:28.924836
Epoch:[ 224 5 ] loss: 0.3506019711494446 2022-07-20 02:10:29.340440
Epoch:[ 224 6 ] loss: 0.35008400678634644 2022-07-20 02:10:29.754843
Epoch:[ 224 7 ] loss: 0.35091036558151245 2022-07-20 02:10:30.170257
Epoch:[ 224 8 ] loss: 0.3494305908679962 2022-07-20 02:10:30.582912
Epoch:[ 224 9 ] loss: 0.3510880470275879 2022-07-20 02:10:30.996254
Epoch:[ 224 10 ] loss: 0.35022813081741333 2022-07-20 02:10:31.413830
Epoch:[ 224 11 ] loss: 0.350847989320755 2022-07-20 02:10:31.828790
Epoch:[ 224 12 ] loss: 0.35114866495132446 2022-07-20 02:10:32.245232
Epoch:[ 224 13 ] loss: 0.3506874442100525 2022-07-20 02:10:32.657899
Epoch:[ 224 14 ] loss: 0.3499448597431183 2022-07-20 02:10:33.072814
Epoch:[ 224 15 ] loss: 0.3502863049507141 2022-07-20 02:10:33.484990
Epoch:[ 224 16 ] loss: 0.3506181240081787 2022-07-20 02:10:39.311321
Epoch:[ 224 17 ] loss: 0.3496604859828949 2022-07-20 02:10:39.729952
Epoch:[ 224 18 ] loss: 0.35036909580230713 2022-07-20 02:10:40.156704
Epoch:[ 224 19 ] loss: 0.3500517010688782 2022-07-20 02:10:40.571580
Training_Epoch:[ 224 ] Training_loss: 0.35046527087688445 2022-07-20 02:10:40.572231
learning rate:  2.800376120856161e-05
netparams have been saved once 224
val: 1 0.41358742117881775
val: 2 0.42310163378715515
val: 3 0.41015487909317017
val: 4 0.41402965784072876
val: 5 0.4212793707847595
val: 6 0.41669341921806335
val: 7 0.4131607413291931
val: 8 0.42442378401756287
val: 9 0.42509925365448
val: 10 0.4166138172149658
val: 11 0.42252182960510254
val: 12 0.4143054187297821
val: 13 0.4251723885536194
val: 14 0.40849295258522034
val: 15 0.414196640253067
val: 16 0.42313191294670105
val: 17 0.4186125099658966
val: 18 0.434031218290329
val: 19 0.42112475633621216
val: 20 0.4253934323787689
val_Epoch:[ 224 ] val_loss: 0.4192563518881798 2022-07-20 02:10:43.820958
start training 2022-07-20 02:10:43.920797
Epoch:[ 225 0 ] loss: 0.3500365614891052 2022-07-20 02:10:57.544432
Epoch:[ 225 1 ] loss: 0.3501899838447571 2022-07-20 02:10:58.248696
Epoch:[ 225 2 ] loss: 0.35147741436958313 2022-07-20 02:10:58.662222
Epoch:[ 225 3 ] loss: 0.350856214761734 2022-07-20 02:10:59.075914
Epoch:[ 225 4 ] loss: 0.34994298219680786 2022-07-20 02:10:59.489156
Epoch:[ 225 5 ] loss: 0.350273996591568 2022-07-20 02:10:59.899703
Epoch:[ 225 6 ] loss: 0.3502742648124695 2022-07-20 02:11:00.316294
Epoch:[ 225 7 ] loss: 0.3492285907268524 2022-07-20 02:11:00.725123
Epoch:[ 225 8 ] loss: 0.3507596552371979 2022-07-20 02:11:01.137715
Epoch:[ 225 9 ] loss: 0.3519722819328308 2022-07-20 02:11:01.551165
Epoch:[ 225 10 ] loss: 0.3503335118293762 2022-07-20 02:11:01.963945
Epoch:[ 225 11 ] loss: 0.3515724539756775 2022-07-20 02:11:02.376774
Epoch:[ 225 12 ] loss: 0.3503077030181885 2022-07-20 02:11:02.789868
Epoch:[ 225 13 ] loss: 0.3497193455696106 2022-07-20 02:11:03.207102
Epoch:[ 225 14 ] loss: 0.3505610525608063 2022-07-20 02:11:03.623381
Epoch:[ 225 15 ] loss: 0.3500007688999176 2022-07-20 02:11:04.038546
Epoch:[ 225 16 ] loss: 0.35031870007514954 2022-07-20 02:11:09.531413
Epoch:[ 225 17 ] loss: 0.35025376081466675 2022-07-20 02:11:09.945222
Epoch:[ 225 18 ] loss: 0.35020580887794495 2022-07-20 02:11:10.366846
Epoch:[ 225 19 ] loss: 0.34993740916252136 2022-07-20 02:11:10.777004
Training_Epoch:[ 225 ] Training_loss: 0.35041112303733823 2022-07-20 02:11:10.777922
learning rate:  2.800376120856161e-05
val: 1 0.42096877098083496
val: 2 0.41653692722320557
val: 3 0.4277370274066925
val: 4 0.4196014702320099
val: 5 0.4243990480899811
val: 6 0.4226011037826538
val: 7 0.41378191113471985
val: 8 0.4181450307369232
val: 9 0.42463552951812744
val: 10 0.4272863566875458
val: 11 0.4178391396999359
val: 12 0.41149330139160156
val: 13 0.4230911433696747
val: 14 0.4166382849216461
val: 15 0.4163196086883545
val: 16 0.4221668839454651
val: 17 0.4222254455089569
val: 18 0.428288072347641
val: 19 0.41822656989097595
val: 20 0.41880956292152405
val_Epoch:[ 225 ] val_loss: 0.4205395594239235 2022-07-20 02:11:13.870950
start training 2022-07-20 02:11:13.971808
Epoch:[ 226 0 ] loss: 0.3499385118484497 2022-07-20 02:11:27.643532
Epoch:[ 226 1 ] loss: 0.349931925535202 2022-07-20 02:11:28.068895
Epoch:[ 226 2 ] loss: 0.3501274585723877 2022-07-20 02:11:28.481551
Epoch:[ 226 3 ] loss: 0.35004064440727234 2022-07-20 02:11:28.895965
Epoch:[ 226 4 ] loss: 0.3511781394481659 2022-07-20 02:11:29.309547
Epoch:[ 226 5 ] loss: 0.34977906942367554 2022-07-20 02:11:29.723844
Epoch:[ 226 6 ] loss: 0.34984928369522095 2022-07-20 02:11:30.138990
Epoch:[ 226 7 ] loss: 0.35015320777893066 2022-07-20 02:11:30.553256
Epoch:[ 226 8 ] loss: 0.35076138377189636 2022-07-20 02:11:30.966414
Epoch:[ 226 9 ] loss: 0.3494534492492676 2022-07-20 02:11:31.382924
Epoch:[ 226 10 ] loss: 0.35069313645362854 2022-07-20 02:11:31.797733
Epoch:[ 226 11 ] loss: 0.35077938437461853 2022-07-20 02:11:32.208386
Epoch:[ 226 12 ] loss: 0.350038081407547 2022-07-20 02:11:32.618636
Epoch:[ 226 13 ] loss: 0.3509233593940735 2022-07-20 02:11:33.034034
Epoch:[ 226 14 ] loss: 0.3500550389289856 2022-07-20 02:11:33.449065
Epoch:[ 226 15 ] loss: 0.3507087528705597 2022-07-20 02:11:33.862312
Epoch:[ 226 16 ] loss: 0.3499467372894287 2022-07-20 02:11:39.175628
Epoch:[ 226 17 ] loss: 0.35017356276512146 2022-07-20 02:11:39.605482
Epoch:[ 226 18 ] loss: 0.35019275546073914 2022-07-20 02:11:40.026116
Epoch:[ 226 19 ] loss: 0.35132238268852234 2022-07-20 02:11:40.439834
Training_Epoch:[ 226 ] Training_loss: 0.3503023132681847 2022-07-20 02:11:40.440710
learning rate:  2.800376120856161e-05
netparams have been saved once 226
val: 1 0.42046424746513367
val: 2 0.42416179180145264
val: 3 0.41433632373809814
val: 4 0.4237174391746521
val: 5 0.411487340927124
val: 6 0.4225890636444092
val: 7 0.4216514229774475
val: 8 0.4332960546016693
val: 9 0.4179856777191162
val: 10 0.4222849905490875
val: 11 0.42675596475601196
val: 12 0.4216046929359436
val: 13 0.4059259295463562
val: 14 0.40955880284309387
val: 15 0.4094751477241516
val: 16 0.4203602969646454
val: 17 0.43261483311653137
val: 18 0.4314148426055908
val: 19 0.4098396897315979
val: 20 0.4234209656715393
val_Epoch:[ 226 ] val_loss: 0.4201472759246826 2022-07-20 02:11:43.662974
start training 2022-07-20 02:11:43.765880
Epoch:[ 227 0 ] loss: 0.34995824098587036 2022-07-20 02:11:57.597406
Epoch:[ 227 1 ] loss: 0.349602073431015 2022-07-20 02:11:58.012526
Epoch:[ 227 2 ] loss: 0.350503534078598 2022-07-20 02:11:58.426444
Epoch:[ 227 3 ] loss: 0.3500753343105316 2022-07-20 02:11:58.840808
Epoch:[ 227 4 ] loss: 0.35046452283859253 2022-07-20 02:11:59.253914
Epoch:[ 227 5 ] loss: 0.35028335452079773 2022-07-20 02:11:59.668715
Epoch:[ 227 6 ] loss: 0.35009023547172546 2022-07-20 02:12:00.077192
Epoch:[ 227 7 ] loss: 0.34974434971809387 2022-07-20 02:12:00.492858
Epoch:[ 227 8 ] loss: 0.3502684235572815 2022-07-20 02:12:00.908738
Epoch:[ 227 9 ] loss: 0.34954503178596497 2022-07-20 02:12:01.324213
Epoch:[ 227 10 ] loss: 0.35037827491760254 2022-07-20 02:12:01.737765
Epoch:[ 227 11 ] loss: 0.3502689599990845 2022-07-20 02:12:02.147869
Epoch:[ 227 12 ] loss: 0.3504992127418518 2022-07-20 02:12:02.562069
Epoch:[ 227 13 ] loss: 0.34963545203208923 2022-07-20 02:12:02.975204
Epoch:[ 227 14 ] loss: 0.3501223623752594 2022-07-20 02:12:03.390316
Epoch:[ 227 15 ] loss: 0.35142281651496887 2022-07-20 02:12:03.805234
Epoch:[ 227 16 ] loss: 0.3510153591632843 2022-07-20 02:12:09.178062
Epoch:[ 227 17 ] loss: 0.3503471612930298 2022-07-20 02:12:10.029271
Epoch:[ 227 18 ] loss: 0.3520800769329071 2022-07-20 02:12:10.449825
Epoch:[ 227 19 ] loss: 0.35067322850227356 2022-07-20 02:12:10.858167
Training_Epoch:[ 227 ] Training_loss: 0.3503489002585411 2022-07-20 02:12:10.859105
learning rate:  2.800376120856161e-05
val: 1 0.4104212522506714
val: 2 0.4142046868801117
val: 3 0.4061337113380432
val: 4 0.41877004504203796
val: 5 0.4284746050834656
val: 6 0.4183237552642822
val: 7 0.4278940260410309
val: 8 0.4171202778816223
val: 9 0.41788697242736816
val: 10 0.41934409737586975
val: 11 0.4167358875274658
val: 12 0.41755104064941406
val: 13 0.42575979232788086
val: 14 0.4165845215320587
val: 15 0.41825783252716064
val: 16 0.43373945355415344
val: 17 0.4194760322570801
val: 18 0.41563382744789124
val: 19 0.423540860414505
val: 20 0.42480146884918213
val_Epoch:[ 227 ] val_loss: 0.41953270733356474 2022-07-20 02:12:14.139624
start training 2022-07-20 02:12:14.246008
Epoch:[ 228 0 ] loss: 0.351218044757843 2022-07-20 02:12:28.347130
Epoch:[ 228 1 ] loss: 0.3510187864303589 2022-07-20 02:12:28.760790
Epoch:[ 228 2 ] loss: 0.35043200850486755 2022-07-20 02:12:29.174864
Epoch:[ 228 3 ] loss: 0.35070690512657166 2022-07-20 02:12:29.586409
Epoch:[ 228 4 ] loss: 0.35019543766975403 2022-07-20 02:12:30.000460
Epoch:[ 228 5 ] loss: 0.35032498836517334 2022-07-20 02:12:30.412451
Epoch:[ 228 6 ] loss: 0.34972065687179565 2022-07-20 02:12:30.830311
Epoch:[ 228 7 ] loss: 0.3507698178291321 2022-07-20 02:12:31.244489
Epoch:[ 228 8 ] loss: 0.3505953550338745 2022-07-20 02:12:31.658571
Epoch:[ 228 9 ] loss: 0.34944677352905273 2022-07-20 02:12:32.076451
Epoch:[ 228 10 ] loss: 0.34991803765296936 2022-07-20 02:12:32.489712
Epoch:[ 228 11 ] loss: 0.35157904028892517 2022-07-20 02:12:32.902225
Epoch:[ 228 12 ] loss: 0.35119888186454773 2022-07-20 02:12:33.317330
Epoch:[ 228 13 ] loss: 0.3503834307193756 2022-07-20 02:12:33.731085
Epoch:[ 228 14 ] loss: 0.34958383440971375 2022-07-20 02:12:34.145527
Epoch:[ 228 15 ] loss: 0.3502238690853119 2022-07-20 02:12:34.565432
Epoch:[ 228 16 ] loss: 0.35009562969207764 2022-07-20 02:12:39.948165
Epoch:[ 228 17 ] loss: 0.3498546779155731 2022-07-20 02:12:40.362016
Epoch:[ 228 18 ] loss: 0.35027432441711426 2022-07-20 02:12:40.782301
Epoch:[ 228 19 ] loss: 0.3507792055606842 2022-07-20 02:12:41.200129
Training_Epoch:[ 228 ] Training_loss: 0.3504159852862358 2022-07-20 02:12:41.200910
learning rate:  2.800376120856161e-05
netparams have been saved once 228
val: 1 0.41948482394218445
val: 2 0.41794106364250183
val: 3 0.41607531905174255
val: 4 0.42471325397491455
val: 5 0.4191001355648041
val: 6 0.419628381729126
val: 7 0.412929892539978
val: 8 0.410706102848053
val: 9 0.4163389801979065
val: 10 0.41621673107147217
val: 11 0.4261753559112549
val: 12 0.41963160037994385
val: 13 0.42966166138648987
val: 14 0.4209517538547516
val: 15 0.42223528027534485
val: 16 0.41747406125068665
val: 17 0.4158601462841034
val: 18 0.42399728298187256
val: 19 0.42570698261260986
val: 20 0.414821982383728
val_Epoch:[ 228 ] val_loss: 0.4194825395941734 2022-07-20 02:12:44.430567
start training 2022-07-20 02:12:44.534175
Epoch:[ 229 0 ] loss: 0.35015273094177246 2022-07-20 02:12:58.539975
Epoch:[ 229 1 ] loss: 0.34990498423576355 2022-07-20 02:12:58.960743
Epoch:[ 229 2 ] loss: 0.3499985933303833 2022-07-20 02:12:59.375877
Epoch:[ 229 3 ] loss: 0.35036811232566833 2022-07-20 02:12:59.789766
Epoch:[ 229 4 ] loss: 0.3505871891975403 2022-07-20 02:13:00.203388
Epoch:[ 229 5 ] loss: 0.34986114501953125 2022-07-20 02:13:00.616433
Epoch:[ 229 6 ] loss: 0.3505912721157074 2022-07-20 02:13:01.026369
Epoch:[ 229 7 ] loss: 0.3498969078063965 2022-07-20 02:13:01.439657
Epoch:[ 229 8 ] loss: 0.3503117859363556 2022-07-20 02:13:01.848514
Epoch:[ 229 9 ] loss: 0.3499872088432312 2022-07-20 02:13:02.263161
Epoch:[ 229 10 ] loss: 0.3505859076976776 2022-07-20 02:13:02.677554
Epoch:[ 229 11 ] loss: 0.35048994421958923 2022-07-20 02:13:03.090354
Epoch:[ 229 12 ] loss: 0.3512616753578186 2022-07-20 02:13:03.501902
Epoch:[ 229 13 ] loss: 0.3500131666660309 2022-07-20 02:13:03.915602
Epoch:[ 229 14 ] loss: 0.34988102316856384 2022-07-20 02:13:04.328498
Epoch:[ 229 15 ] loss: 0.3512282073497772 2022-07-20 02:13:04.741162
Epoch:[ 229 16 ] loss: 0.350605845451355 2022-07-20 02:13:10.177583
Epoch:[ 229 17 ] loss: 0.34958896040916443 2022-07-20 02:13:10.661554
Epoch:[ 229 18 ] loss: 0.35007229447364807 2022-07-20 02:13:11.076872
Epoch:[ 229 19 ] loss: 0.3507351577281952 2022-07-20 02:13:11.495018
Training_Epoch:[ 229 ] Training_loss: 0.3503061056137085 2022-07-20 02:13:11.495796
learning rate:  2.800376120856161e-05
val: 1 0.40546512603759766
val: 2 0.4104801416397095
val: 3 0.4260014295578003
val: 4 0.41211697459220886
val: 5 0.42135655879974365
val: 6 0.4186389446258545
val: 7 0.40222156047821045
val: 8 0.4227355420589447
val: 9 0.4084322452545166
val: 10 0.4112634062767029
val: 11 0.4147975742816925
val: 12 0.41937053203582764
val: 13 0.43297460675239563
val: 14 0.4090522527694702
val: 15 0.4201050400733948
val: 16 0.4152063727378845
val: 17 0.41660308837890625
val: 18 0.43028920888900757
val: 19 0.4218234717845917
val: 20 0.4278526306152344
val_Epoch:[ 229 ] val_loss: 0.4173393353819847 2022-07-20 02:13:14.667074
start training 2022-07-20 02:13:14.769406
Epoch:[ 230 0 ] loss: 0.34984076023101807 2022-07-20 02:13:28.853279
Epoch:[ 230 1 ] loss: 0.3503378927707672 2022-07-20 02:13:29.272157
Epoch:[ 230 2 ] loss: 0.35019829869270325 2022-07-20 02:13:29.683925
Epoch:[ 230 3 ] loss: 0.35011520981788635 2022-07-20 02:13:30.103352
Epoch:[ 230 4 ] loss: 0.34979870915412903 2022-07-20 02:13:30.517119
Epoch:[ 230 5 ] loss: 0.3511226177215576 2022-07-20 02:13:30.930690
Epoch:[ 230 6 ] loss: 0.3505863547325134 2022-07-20 02:13:31.346131
Epoch:[ 230 7 ] loss: 0.35026872158050537 2022-07-20 02:13:31.758688
Epoch:[ 230 8 ] loss: 0.35029447078704834 2022-07-20 02:13:32.171027
Epoch:[ 230 9 ] loss: 0.3499859869480133 2022-07-20 02:13:32.583370
Epoch:[ 230 10 ] loss: 0.34943199157714844 2022-07-20 02:13:32.997851
Epoch:[ 230 11 ] loss: 0.3502144515514374 2022-07-20 02:13:33.413528
Epoch:[ 230 12 ] loss: 0.3495936989784241 2022-07-20 02:13:33.826161
Epoch:[ 230 13 ] loss: 0.3512206971645355 2022-07-20 02:13:34.242502
Epoch:[ 230 14 ] loss: 0.35044610500335693 2022-07-20 02:13:34.656684
Epoch:[ 230 15 ] loss: 0.3502967655658722 2022-07-20 02:13:35.069680
Epoch:[ 230 16 ] loss: 0.3503267765045166 2022-07-20 02:13:40.253752
Epoch:[ 230 17 ] loss: 0.35035789012908936 2022-07-20 02:13:40.668352
Epoch:[ 230 18 ] loss: 0.34988245368003845 2022-07-20 02:13:41.082603
Epoch:[ 230 19 ] loss: 0.3505692481994629 2022-07-20 02:13:41.500471
Training_Epoch:[ 230 ] Training_loss: 0.3502444550395012 2022-07-20 02:13:41.501367
learning rate:  2.800376120856161e-05
netparams have been saved once 230
val: 1 0.42694613337516785
val: 2 0.42602020502090454
val: 3 0.40527403354644775
val: 4 0.4170474410057068
val: 5 0.420796275138855
val: 6 0.41895216703414917
val: 7 0.41461503505706787
val: 8 0.420766144990921
val: 9 0.4242178201675415
val: 10 0.4260198473930359
val: 11 0.4112217426300049
val: 12 0.41208934783935547
val: 13 0.4169427454471588
val: 14 0.4169875979423523
val: 15 0.4208853840827942
val: 16 0.41287121176719666
val: 17 0.418518602848053
val: 18 0.42139023542404175
val: 19 0.4173448383808136
val: 20 0.4263136088848114
val_Epoch:[ 230 ] val_loss: 0.41876102089881895 2022-07-20 02:13:44.654622
start training 2022-07-20 02:13:44.753111
Epoch:[ 231 0 ] loss: 0.3502751290798187 2022-07-20 02:13:58.456492
Epoch:[ 231 1 ] loss: 0.3503163158893585 2022-07-20 02:13:59.082697
Epoch:[ 231 2 ] loss: 0.34969112277030945 2022-07-20 02:13:59.493899
Epoch:[ 231 3 ] loss: 0.3495471775531769 2022-07-20 02:13:59.908623
Epoch:[ 231 4 ] loss: 0.3516426980495453 2022-07-20 02:14:00.322001
Epoch:[ 231 5 ] loss: 0.350373774766922 2022-07-20 02:14:00.736919
Epoch:[ 231 6 ] loss: 0.3503917455673218 2022-07-20 02:14:01.148139
Epoch:[ 231 7 ] loss: 0.3507038950920105 2022-07-20 02:14:01.560854
Epoch:[ 231 8 ] loss: 0.3488570749759674 2022-07-20 02:14:01.974538
Epoch:[ 231 9 ] loss: 0.34998974204063416 2022-07-20 02:14:02.385370
Epoch:[ 231 10 ] loss: 0.35088637471199036 2022-07-20 02:14:02.802973
Epoch:[ 231 11 ] loss: 0.3495054543018341 2022-07-20 02:14:03.219242
Epoch:[ 231 12 ] loss: 0.3517089784145355 2022-07-20 02:14:03.632755
Epoch:[ 231 13 ] loss: 0.34962624311447144 2022-07-20 02:14:04.045569
Epoch:[ 231 14 ] loss: 0.3506147563457489 2022-07-20 02:14:04.458293
Epoch:[ 231 15 ] loss: 0.3500633239746094 2022-07-20 02:14:04.871761
Epoch:[ 231 16 ] loss: 0.3495553433895111 2022-07-20 02:14:10.209228
Epoch:[ 231 17 ] loss: 0.3501381278038025 2022-07-20 02:14:10.858938
Epoch:[ 231 18 ] loss: 0.35114994645118713 2022-07-20 02:14:11.276913
Epoch:[ 231 19 ] loss: 0.3497389256954193 2022-07-20 02:14:11.687666
Training_Epoch:[ 231 ] Training_loss: 0.3502388074994087 2022-07-20 02:14:11.688501
learning rate:  2.380319702727737e-05
val: 1 0.41518738865852356
val: 2 0.4275985658168793
val: 3 0.41952088475227356
val: 4 0.42348816990852356
val: 5 0.4188125729560852
val: 6 0.42371708154678345
val: 7 0.41980430483818054
val: 8 0.4065694510936737
val: 9 0.4232974946498871
val: 10 0.41395407915115356
val: 11 0.4309012293815613
val: 12 0.42087316513061523
val: 13 0.4312056601047516
val: 14 0.41410505771636963
val: 15 0.41661936044692993
val: 16 0.4268955886363983
val: 17 0.42687588930130005
val: 18 0.42520010471343994
val: 19 0.4280765950679779
val: 20 0.4200620651245117
val_Epoch:[ 231 ] val_loss: 0.42163823544979095 2022-07-20 02:14:14.978818
start training 2022-07-20 02:14:15.083577
Epoch:[ 232 0 ] loss: 0.35041898488998413 2022-07-20 02:14:28.355948
Epoch:[ 232 1 ] loss: 0.3501681089401245 2022-07-20 02:14:29.570964
Epoch:[ 232 2 ] loss: 0.34945863485336304 2022-07-20 02:14:29.983609
Epoch:[ 232 3 ] loss: 0.3492388129234314 2022-07-20 02:14:30.397151
Epoch:[ 232 4 ] loss: 0.3495563864707947 2022-07-20 02:14:30.810713
Epoch:[ 232 5 ] loss: 0.3504902124404907 2022-07-20 02:14:31.225876
Epoch:[ 232 6 ] loss: 0.3508835732936859 2022-07-20 02:14:31.636428
Epoch:[ 232 7 ] loss: 0.3494407534599304 2022-07-20 02:14:32.049526
Epoch:[ 232 8 ] loss: 0.349796861410141 2022-07-20 02:14:32.462474
Epoch:[ 232 9 ] loss: 0.3504990041255951 2022-07-20 02:14:32.876218
Epoch:[ 232 10 ] loss: 0.34921708703041077 2022-07-20 02:14:33.289848
Epoch:[ 232 11 ] loss: 0.3504507541656494 2022-07-20 02:14:33.705562
Epoch:[ 232 12 ] loss: 0.3505510985851288 2022-07-20 02:14:34.119691
Epoch:[ 232 13 ] loss: 0.3498442769050598 2022-07-20 02:14:34.534501
Epoch:[ 232 14 ] loss: 0.35084405541419983 2022-07-20 02:14:34.947175
Epoch:[ 232 15 ] loss: 0.3502538502216339 2022-07-20 02:14:35.360385
Epoch:[ 232 16 ] loss: 0.3487749993801117 2022-07-20 02:14:40.045106
Epoch:[ 232 17 ] loss: 0.35113510489463806 2022-07-20 02:14:41.035438
Epoch:[ 232 18 ] loss: 0.3512425720691681 2022-07-20 02:14:41.449449
Epoch:[ 232 19 ] loss: 0.3501434326171875 2022-07-20 02:14:41.868605
Training_Epoch:[ 232 ] Training_loss: 0.3501204282045364 2022-07-20 02:14:41.869464
learning rate:  2.380319702727737e-05
netparams have been saved once 232
val: 1 0.4097937047481537
val: 2 0.41749194264411926
val: 3 0.4137439727783203
val: 4 0.41743290424346924
val: 5 0.4306766092777252
val: 6 0.4199056923389435
val: 7 0.4159695506095886
val: 8 0.4136817157268524
val: 9 0.4199783205986023
val: 10 0.4260813891887665
val: 11 0.4228825867176056
val: 12 0.4190536439418793
val: 13 0.4249635338783264
val: 14 0.4309852421283722
val: 15 0.4254540801048279
val: 16 0.41826656460762024
val: 17 0.4146835207939148
val: 18 0.4174979329109192
val: 19 0.4184850752353668
val: 20 0.4112762212753296
val_Epoch:[ 232 ] val_loss: 0.41941521018743516 2022-07-20 02:14:45.148522
start training 2022-07-20 02:14:45.248693
Epoch:[ 233 0 ] loss: 0.3490186631679535 2022-07-20 02:14:58.831116
Epoch:[ 233 1 ] loss: 0.3493237793445587 2022-07-20 02:14:59.265099
Epoch:[ 233 2 ] loss: 0.3484991192817688 2022-07-20 02:14:59.678199
Epoch:[ 233 3 ] loss: 0.35101667046546936 2022-07-20 02:15:00.092034
Epoch:[ 233 4 ] loss: 0.3496890068054199 2022-07-20 02:15:00.506347
Epoch:[ 233 5 ] loss: 0.3493916690349579 2022-07-20 02:15:00.919248
Epoch:[ 233 6 ] loss: 0.3503396511077881 2022-07-20 02:15:01.336078
Epoch:[ 233 7 ] loss: 0.3502708971500397 2022-07-20 02:15:01.746703
Epoch:[ 233 8 ] loss: 0.3490467071533203 2022-07-20 02:15:02.156384
Epoch:[ 233 9 ] loss: 0.3510253131389618 2022-07-20 02:15:02.571490
Epoch:[ 233 10 ] loss: 0.35052910447120667 2022-07-20 02:15:02.987462
Epoch:[ 233 11 ] loss: 0.34982535243034363 2022-07-20 02:15:03.400357
Epoch:[ 233 12 ] loss: 0.3500554859638214 2022-07-20 02:15:03.813251
Epoch:[ 233 13 ] loss: 0.35053351521492004 2022-07-20 02:15:04.228162
Epoch:[ 233 14 ] loss: 0.3501201868057251 2022-07-20 02:15:04.644848
Epoch:[ 233 15 ] loss: 0.34886014461517334 2022-07-20 02:15:05.059693
Epoch:[ 233 16 ] loss: 0.3498251438140869 2022-07-20 02:15:10.488558
Epoch:[ 233 17 ] loss: 0.3497396409511566 2022-07-20 02:15:10.902085
Epoch:[ 233 18 ] loss: 0.34990283846855164 2022-07-20 02:15:11.319080
Epoch:[ 233 19 ] loss: 0.3503537178039551 2022-07-20 02:15:11.738347
Training_Epoch:[ 233 ] Training_loss: 0.3498683303594589 2022-07-20 02:15:11.739101
learning rate:  2.380319702727737e-05
val: 1 0.42070087790489197
val: 2 0.4194810688495636
val: 3 0.4192865490913391
val: 4 0.4225158095359802
val: 5 0.4167505204677582
val: 6 0.42159831523895264
val: 7 0.4187551438808441
val: 8 0.4073063135147095
val: 9 0.4144812822341919
val: 10 0.41883671283721924
val: 11 0.434255987405777
val: 12 0.4133448004722595
val: 13 0.42766934633255005
val: 14 0.4214002788066864
val: 15 0.4109269678592682
val: 16 0.42574626207351685
val: 17 0.4200054109096527
val: 18 0.4257134199142456
val: 19 0.4217008352279663
val: 20 0.41160014271736145
val_Epoch:[ 233 ] val_loss: 0.4196038022637367 2022-07-20 02:15:14.858879
start training 2022-07-20 02:15:14.958615
Epoch:[ 234 0 ] loss: 0.3495972752571106 2022-07-20 02:15:29.281496
Epoch:[ 234 1 ] loss: 0.3506734073162079 2022-07-20 02:15:29.695003
Epoch:[ 234 2 ] loss: 0.35060837864875793 2022-07-20 02:15:30.112944
Epoch:[ 234 3 ] loss: 0.34911876916885376 2022-07-20 02:15:30.527220
Epoch:[ 234 4 ] loss: 0.349702924489975 2022-07-20 02:15:30.940012
Epoch:[ 234 5 ] loss: 0.34908443689346313 2022-07-20 02:15:31.352265
Epoch:[ 234 6 ] loss: 0.34949740767478943 2022-07-20 02:15:31.769543
Epoch:[ 234 7 ] loss: 0.35056957602500916 2022-07-20 02:15:32.182436
Epoch:[ 234 8 ] loss: 0.349946528673172 2022-07-20 02:15:32.595429
Epoch:[ 234 9 ] loss: 0.349558562040329 2022-07-20 02:15:33.007010
Epoch:[ 234 10 ] loss: 0.3505244851112366 2022-07-20 02:15:33.420026
Epoch:[ 234 11 ] loss: 0.34853416681289673 2022-07-20 02:15:33.834241
Epoch:[ 234 12 ] loss: 0.3499141037464142 2022-07-20 02:15:34.246853
Epoch:[ 234 13 ] loss: 0.3499692976474762 2022-07-20 02:15:34.661235
Epoch:[ 234 14 ] loss: 0.3498561978340149 2022-07-20 02:15:35.076326
Epoch:[ 234 15 ] loss: 0.3498026728630066 2022-07-20 02:15:35.490497
Epoch:[ 234 16 ] loss: 0.34931811690330505 2022-07-20 02:15:40.881070
Epoch:[ 234 17 ] loss: 0.35074251890182495 2022-07-20 02:15:41.294189
Epoch:[ 234 18 ] loss: 0.34967857599258423 2022-07-20 02:15:41.714678
Epoch:[ 234 19 ] loss: 0.3497959077358246 2022-07-20 02:15:42.131508
Training_Epoch:[ 234 ] Training_loss: 0.34982466548681257 2022-07-20 02:15:42.132267
learning rate:  2.380319702727737e-05
netparams have been saved once 234
val: 1 0.41142284870147705
val: 2 0.4171254634857178
val: 3 0.42473214864730835
val: 4 0.42489996552467346
val: 5 0.42084842920303345
val: 6 0.4197970926761627
val: 7 0.41953855752944946
val: 8 0.41225042939186096
val: 9 0.41706743836402893
val: 10 0.41102123260498047
val: 11 0.42365771532058716
val: 12 0.4130391776561737
val: 13 0.4172990918159485
val: 14 0.42848968505859375
val: 15 0.4168519079685211
val: 16 0.426604300737381
val: 17 0.42461755871772766
val: 18 0.41808149218559265
val: 19 0.4380449950695038
val: 20 0.41278761625289917
val_Epoch:[ 234 ] val_loss: 0.41990885734558103 2022-07-20 02:15:45.363822
start training 2022-07-20 02:15:45.462648
Epoch:[ 235 0 ] loss: 0.35071057081222534 2022-07-20 02:15:59.759108
Epoch:[ 235 1 ] loss: 0.3493647277355194 2022-07-20 02:16:00.172225
Epoch:[ 235 2 ] loss: 0.34889405965805054 2022-07-20 02:16:00.587366
Epoch:[ 235 3 ] loss: 0.34951040148735046 2022-07-20 02:16:01.004496
Epoch:[ 235 4 ] loss: 0.3494032025337219 2022-07-20 02:16:01.418433
Epoch:[ 235 5 ] loss: 0.35046663880348206 2022-07-20 02:16:01.836565
Epoch:[ 235 6 ] loss: 0.3490859568119049 2022-07-20 02:16:02.249037
Epoch:[ 235 7 ] loss: 0.3497755825519562 2022-07-20 02:16:02.661766
Epoch:[ 235 8 ] loss: 0.35050123929977417 2022-07-20 02:16:03.075755
Epoch:[ 235 9 ] loss: 0.34942278265953064 2022-07-20 02:16:03.490829
Epoch:[ 235 10 ] loss: 0.3491276502609253 2022-07-20 02:16:03.904214
Epoch:[ 235 11 ] loss: 0.3503652513027191 2022-07-20 02:16:04.318075
Epoch:[ 235 12 ] loss: 0.3502642810344696 2022-07-20 02:16:04.731656
Epoch:[ 235 13 ] loss: 0.3495368957519531 2022-07-20 02:16:05.144675
Epoch:[ 235 14 ] loss: 0.3498021960258484 2022-07-20 02:16:05.561645
Epoch:[ 235 15 ] loss: 0.34970957040786743 2022-07-20 02:16:05.972543
Epoch:[ 235 16 ] loss: 0.35021016001701355 2022-07-20 02:16:10.937875
Epoch:[ 235 17 ] loss: 0.3494892716407776 2022-07-20 02:16:11.346713
Epoch:[ 235 18 ] loss: 0.3502422571182251 2022-07-20 02:16:11.760369
Epoch:[ 235 19 ] loss: 0.35021302103996277 2022-07-20 02:16:12.173181
Training_Epoch:[ 235 ] Training_loss: 0.3498047858476639 2022-07-20 02:16:12.173939
learning rate:  2.380319702727737e-05
val: 1 0.4143359065055847
val: 2 0.4094390869140625
val: 3 0.4193781018257141
val: 4 0.4209904968738556
val: 5 0.4142126739025116
val: 6 0.42457225918769836
val: 7 0.4237912595272064
val: 8 0.41480427980422974
val: 9 0.40879279375076294
val: 10 0.4180082082748413
val: 11 0.4162106513977051
val: 12 0.4340347945690155
val: 13 0.41913148760795593
val: 14 0.43080398440361023
val: 15 0.42330124974250793
val: 16 0.420148640871048
val: 17 0.41793617606163025
val: 18 0.4157974421977997
val: 19 0.41695672273635864
val: 20 0.4117449223995209
val_Epoch:[ 235 ] val_loss: 0.418719556927681 2022-07-20 02:16:15.331504
start training 2022-07-20 02:16:15.429870
Epoch:[ 236 0 ] loss: 0.34979307651519775 2022-07-20 02:16:29.577365
Epoch:[ 236 1 ] loss: 0.35053813457489014 2022-07-20 02:16:29.990343
Epoch:[ 236 2 ] loss: 0.34994709491729736 2022-07-20 02:16:30.403986
Epoch:[ 236 3 ] loss: 0.3505447506904602 2022-07-20 02:16:30.824898
Epoch:[ 236 4 ] loss: 0.3499357998371124 2022-07-20 02:16:31.237823
Epoch:[ 236 5 ] loss: 0.34914112091064453 2022-07-20 02:16:31.651222
Epoch:[ 236 6 ] loss: 0.34919866919517517 2022-07-20 02:16:32.070834
Epoch:[ 236 7 ] loss: 0.35015782713890076 2022-07-20 02:16:32.482816
Epoch:[ 236 8 ] loss: 0.3515005111694336 2022-07-20 02:16:32.895194
Epoch:[ 236 9 ] loss: 0.3489319384098053 2022-07-20 02:16:33.308907
Epoch:[ 236 10 ] loss: 0.34899604320526123 2022-07-20 02:16:33.723257
Epoch:[ 236 11 ] loss: 0.35000211000442505 2022-07-20 02:16:34.135878
Epoch:[ 236 12 ] loss: 0.3503476083278656 2022-07-20 02:16:34.553430
Epoch:[ 236 13 ] loss: 0.3496079444885254 2022-07-20 02:16:34.967089
Epoch:[ 236 14 ] loss: 0.3492385745048523 2022-07-20 02:16:35.379193
Epoch:[ 236 15 ] loss: 0.3500405550003052 2022-07-20 02:16:35.790925
Epoch:[ 236 16 ] loss: 0.35041001439094543 2022-07-20 02:16:41.163168
Epoch:[ 236 17 ] loss: 0.3496936857700348 2022-07-20 02:16:41.582384
Epoch:[ 236 18 ] loss: 0.35065343976020813 2022-07-20 02:16:41.997334
Epoch:[ 236 19 ] loss: 0.349952757358551 2022-07-20 02:16:42.413106
Training_Epoch:[ 236 ] Training_loss: 0.34993158280849457 2022-07-20 02:16:42.413853
learning rate:  2.380319702727737e-05
netparams have been saved once 236
val: 1 0.4203948378562927
val: 2 0.4094714820384979
val: 3 0.4277690351009369
val: 4 0.4189518094062805
val: 5 0.41319194436073303
val: 6 0.41622352600097656
val: 7 0.4242776036262512
val: 8 0.40980827808380127
val: 9 0.42051950097084045
val: 10 0.4224351644515991
val: 11 0.4063225984573364
val: 12 0.40582212805747986
val: 13 0.4278016686439514
val: 14 0.4111692011356354
val: 15 0.4211922883987427
val: 16 0.4232388734817505
val: 17 0.4167896807193756
val: 18 0.43511176109313965
val: 19 0.42545226216316223
val: 20 0.42930805683135986
val_Epoch:[ 236 ] val_loss: 0.4192625850439072 2022-07-20 02:16:45.603687
start training 2022-07-20 02:16:45.703560
Epoch:[ 237 0 ] loss: 0.35001277923583984 2022-07-20 02:16:59.802237
Epoch:[ 237 1 ] loss: 0.3496703803539276 2022-07-20 02:17:00.214175
Epoch:[ 237 2 ] loss: 0.35061436891555786 2022-07-20 02:17:00.628948
Epoch:[ 237 3 ] loss: 0.3501301109790802 2022-07-20 02:17:01.043688
Epoch:[ 237 4 ] loss: 0.34956178069114685 2022-07-20 02:17:01.457267
Epoch:[ 237 5 ] loss: 0.34962478280067444 2022-07-20 02:17:01.873826
Epoch:[ 237 6 ] loss: 0.35046330094337463 2022-07-20 02:17:02.285679
Epoch:[ 237 7 ] loss: 0.34933918714523315 2022-07-20 02:17:02.698523
Epoch:[ 237 8 ] loss: 0.34977591037750244 2022-07-20 02:17:03.117559
Epoch:[ 237 9 ] loss: 0.3500881791114807 2022-07-20 02:17:03.528650
Epoch:[ 237 10 ] loss: 0.3506484627723694 2022-07-20 02:17:03.949003
Epoch:[ 237 11 ] loss: 0.3503287434577942 2022-07-20 02:17:04.362857
Epoch:[ 237 12 ] loss: 0.34877362847328186 2022-07-20 02:17:04.774655
Epoch:[ 237 13 ] loss: 0.34972816705703735 2022-07-20 02:17:05.187238
Epoch:[ 237 14 ] loss: 0.3499284088611603 2022-07-20 02:17:05.600536
Epoch:[ 237 15 ] loss: 0.349566787481308 2022-07-20 02:17:06.012736
Epoch:[ 237 16 ] loss: 0.34959837794303894 2022-07-20 02:17:11.355060
Epoch:[ 237 17 ] loss: 0.34942787885665894 2022-07-20 02:17:11.774964
Epoch:[ 237 18 ] loss: 0.3500705063343048 2022-07-20 02:17:12.192186
Epoch:[ 237 19 ] loss: 0.3490770757198334 2022-07-20 02:17:12.609798
Training_Epoch:[ 237 ] Training_loss: 0.34982144087553024 2022-07-20 02:17:12.610479
learning rate:  2.380319702727737e-05
val: 1 0.416669100522995
val: 2 0.41217055916786194
val: 3 0.4088887870311737
val: 4 0.4178663492202759
val: 5 0.4205113351345062
val: 6 0.4245679974555969
val: 7 0.4320424199104309
val: 8 0.4168061316013336
val: 9 0.4284795820713043
val: 10 0.4212718605995178
val: 11 0.4189029633998871
val: 12 0.42870089411735535
val: 13 0.4221206307411194
val: 14 0.41621333360671997
val: 15 0.4264182448387146
val: 16 0.42832472920417786
val: 17 0.406093031167984
val: 18 0.42366448044776917
val: 19 0.40410876274108887
val: 20 0.42318934202194214
val_Epoch:[ 237 ] val_loss: 0.4198505267500877 2022-07-20 02:17:15.770674
start training 2022-07-20 02:17:15.869685
Epoch:[ 238 0 ] loss: 0.35196036100387573 2022-07-20 02:17:30.355813
Epoch:[ 238 1 ] loss: 0.3492651879787445 2022-07-20 02:17:30.770304
Epoch:[ 238 2 ] loss: 0.3492092192173004 2022-07-20 02:17:31.183823
Epoch:[ 238 3 ] loss: 0.3503818213939667 2022-07-20 02:17:31.596979
Epoch:[ 238 4 ] loss: 0.3498374819755554 2022-07-20 02:17:32.011190
Epoch:[ 238 5 ] loss: 0.3506311774253845 2022-07-20 02:17:32.427131
Epoch:[ 238 6 ] loss: 0.34962815046310425 2022-07-20 02:17:32.843433
Epoch:[ 238 7 ] loss: 0.3507404625415802 2022-07-20 02:17:33.258548
Epoch:[ 238 8 ] loss: 0.34996458888053894 2022-07-20 02:17:33.667464
Epoch:[ 238 9 ] loss: 0.35025978088378906 2022-07-20 02:17:34.080861
Epoch:[ 238 10 ] loss: 0.3496139645576477 2022-07-20 02:17:34.492997
Epoch:[ 238 11 ] loss: 0.34929171204566956 2022-07-20 02:17:34.907354
Epoch:[ 238 12 ] loss: 0.350136399269104 2022-07-20 02:17:35.317471
Epoch:[ 238 13 ] loss: 0.34884214401245117 2022-07-20 02:17:35.730421
Epoch:[ 238 14 ] loss: 0.34882134199142456 2022-07-20 02:17:36.145342
Epoch:[ 238 15 ] loss: 0.349456787109375 2022-07-20 02:17:36.559165
Epoch:[ 238 16 ] loss: 0.348827064037323 2022-07-20 02:17:41.693896
Epoch:[ 238 17 ] loss: 0.34961336851119995 2022-07-20 02:17:42.102906
Epoch:[ 238 18 ] loss: 0.34865373373031616 2022-07-20 02:17:42.519313
Epoch:[ 238 19 ] loss: 0.34972262382507324 2022-07-20 02:17:42.938089
Training_Epoch:[ 238 ] Training_loss: 0.3497428685426712 2022-07-20 02:17:42.938865
learning rate:  2.380319702727737e-05
netparams have been saved once 238
val: 1 0.4133746922016144
val: 2 0.42051178216934204
val: 3 0.4128795862197876
val: 4 0.42628368735313416
val: 5 0.4205434024333954
val: 6 0.417353093624115
val: 7 0.4177016615867615
val: 8 0.42994850873947144
val: 9 0.42135775089263916
val: 10 0.41954535245895386
val: 11 0.41607698798179626
val: 12 0.41197049617767334
val: 13 0.420695424079895
val: 14 0.4241362512111664
val: 15 0.4208134710788727
val: 16 0.41986215114593506
val: 17 0.41554543375968933
val: 18 0.420523464679718
val: 19 0.4227399230003357
val: 20 0.41110771894454956
val_Epoch:[ 238 ] val_loss: 0.4191485419869423 2022-07-20 02:17:46.180671
start training 2022-07-20 02:17:46.281544
Epoch:[ 239 0 ] loss: 0.34973567724227905 2022-07-20 02:18:00.120427
Epoch:[ 239 1 ] loss: 0.34916236996650696 2022-07-20 02:18:00.536580
Epoch:[ 239 2 ] loss: 0.3497055768966675 2022-07-20 02:18:00.949821
Epoch:[ 239 3 ] loss: 0.3493413031101227 2022-07-20 02:18:01.362515
Epoch:[ 239 4 ] loss: 0.3511888086795807 2022-07-20 02:18:01.774988
Epoch:[ 239 5 ] loss: 0.3502725064754486 2022-07-20 02:18:02.186846
Epoch:[ 239 6 ] loss: 0.34954342246055603 2022-07-20 02:18:02.603408
Epoch:[ 239 7 ] loss: 0.3494631052017212 2022-07-20 02:18:03.026898
Epoch:[ 239 8 ] loss: 0.3505551517009735 2022-07-20 02:18:03.441397
Epoch:[ 239 9 ] loss: 0.3502255082130432 2022-07-20 02:18:03.855659
Epoch:[ 239 10 ] loss: 0.35080501437187195 2022-07-20 02:18:04.273903
Epoch:[ 239 11 ] loss: 0.3492622971534729 2022-07-20 02:18:04.686716
Epoch:[ 239 12 ] loss: 0.34933939576148987 2022-07-20 02:18:05.100710
Epoch:[ 239 13 ] loss: 0.34918487071990967 2022-07-20 02:18:05.514334
Epoch:[ 239 14 ] loss: 0.3488430082798004 2022-07-20 02:18:05.927987
Epoch:[ 239 15 ] loss: 0.3486509621143341 2022-07-20 02:18:06.342824
Epoch:[ 239 16 ] loss: 0.3504205048084259 2022-07-20 02:18:11.496104
Epoch:[ 239 17 ] loss: 0.34997716546058655 2022-07-20 02:18:12.294258
Epoch:[ 239 18 ] loss: 0.3497888147830963 2022-07-20 02:18:12.716499
Epoch:[ 239 19 ] loss: 0.3495383560657501 2022-07-20 02:18:13.135063
Training_Epoch:[ 239 ] Training_loss: 0.34975019097328186 2022-07-20 02:18:13.135733
learning rate:  2.380319702727737e-05
val: 1 0.41332757472991943
val: 2 0.420833021402359
val: 3 0.41683483123779297
val: 4 0.42089608311653137
val: 5 0.41402295231819153
val: 6 0.4261355698108673
val: 7 0.42811131477355957
val: 8 0.42810505628585815
val: 9 0.4153091311454773
val: 10 0.42641428112983704
val: 11 0.42159974575042725
val: 12 0.41845420002937317
val: 13 0.429211288690567
val: 14 0.4051649570465088
val: 15 0.4109744727611542
val: 16 0.41856303811073303
val: 17 0.42147961258888245
val: 18 0.4107804000377655
val: 19 0.4149298071861267
val: 20 0.4232041537761688
val_Epoch:[ 239 ] val_loss: 0.419217574596405 2022-07-20 02:18:16.288747
start training 2022-07-20 02:18:16.390085
Epoch:[ 240 0 ] loss: 0.34925395250320435 2022-07-20 02:18:29.900089
Epoch:[ 240 1 ] loss: 0.34927189350128174 2022-07-20 02:18:30.321989
Epoch:[ 240 2 ] loss: 0.35015660524368286 2022-07-20 02:18:30.735489
Epoch:[ 240 3 ] loss: 0.3493489623069763 2022-07-20 02:18:31.150090
Epoch:[ 240 4 ] loss: 0.3497074544429779 2022-07-20 02:18:31.563048
Epoch:[ 240 5 ] loss: 0.35047638416290283 2022-07-20 02:18:31.977376
Epoch:[ 240 6 ] loss: 0.34928151965141296 2022-07-20 02:18:32.392920
Epoch:[ 240 7 ] loss: 0.34937864542007446 2022-07-20 02:18:32.806963
Epoch:[ 240 8 ] loss: 0.34957626461982727 2022-07-20 02:18:33.219619
Epoch:[ 240 9 ] loss: 0.35015520453453064 2022-07-20 02:18:33.632974
Epoch:[ 240 10 ] loss: 0.3487769067287445 2022-07-20 02:18:34.046328
Epoch:[ 240 11 ] loss: 0.34978342056274414 2022-07-20 02:18:34.459018
Epoch:[ 240 12 ] loss: 0.349161297082901 2022-07-20 02:18:34.871754
Epoch:[ 240 13 ] loss: 0.3507527709007263 2022-07-20 02:18:35.285939
Epoch:[ 240 14 ] loss: 0.3498954176902771 2022-07-20 02:18:35.706026
Epoch:[ 240 15 ] loss: 0.3500422239303589 2022-07-20 02:18:36.124827
Epoch:[ 240 16 ] loss: 0.3491712212562561 2022-07-20 02:18:41.305971
Epoch:[ 240 17 ] loss: 0.3504018187522888 2022-07-20 02:18:41.805222
Epoch:[ 240 18 ] loss: 0.349595308303833 2022-07-20 02:18:42.224628
Epoch:[ 240 19 ] loss: 0.3503093719482422 2022-07-20 02:18:42.639216
Training_Epoch:[ 240 ] Training_loss: 0.34972483217716216 2022-07-20 02:18:42.639902
learning rate:  2.380319702727737e-05
netparams have been saved once 240
val: 1 0.42514660954475403
val: 2 0.42967304587364197
val: 3 0.415944904088974
val: 4 0.4180328845977783
val: 5 0.425285667181015
val: 6 0.41762393712997437
val: 7 0.418428897857666
val: 8 0.4114150106906891
val: 9 0.42419397830963135
val: 10 0.4206286072731018
val: 11 0.41586849093437195
val: 12 0.4148031771183014
val: 13 0.4166979193687439
val: 14 0.4229656159877777
val: 15 0.4291559159755707
val: 16 0.4274100065231323
val: 17 0.41619566082954407
val: 18 0.41913408041000366
val: 19 0.41672253608703613
val: 20 0.42435145378112793
val_Epoch:[ 240 ] val_loss: 0.4204839199781418 2022-07-20 02:18:45.868137
start training 2022-07-20 02:18:45.968361
Epoch:[ 241 0 ] loss: 0.34917572140693665 2022-07-20 02:19:00.135517
Epoch:[ 241 1 ] loss: 0.34942910075187683 2022-07-20 02:19:00.549344
Epoch:[ 241 2 ] loss: 0.34941866993904114 2022-07-20 02:19:00.961510
Epoch:[ 241 3 ] loss: 0.3491154909133911 2022-07-20 02:19:01.373818
Epoch:[ 241 4 ] loss: 0.35072267055511475 2022-07-20 02:19:01.785989
Epoch:[ 241 5 ] loss: 0.35008567571640015 2022-07-20 02:19:02.196022
Epoch:[ 241 6 ] loss: 0.34966522455215454 2022-07-20 02:19:02.609601
Epoch:[ 241 7 ] loss: 0.34974759817123413 2022-07-20 02:19:03.020410
Epoch:[ 241 8 ] loss: 0.34905678033828735 2022-07-20 02:19:03.431352
Epoch:[ 241 9 ] loss: 0.3496706783771515 2022-07-20 02:19:03.845986
Epoch:[ 241 10 ] loss: 0.34998440742492676 2022-07-20 02:19:04.261785
Epoch:[ 241 11 ] loss: 0.3487585484981537 2022-07-20 02:19:04.675489
Epoch:[ 241 12 ] loss: 0.35104498267173767 2022-07-20 02:19:05.090380
Epoch:[ 241 13 ] loss: 0.349279522895813 2022-07-20 02:19:05.504006
Epoch:[ 241 14 ] loss: 0.3502514660358429 2022-07-20 02:19:05.919446
Epoch:[ 241 15 ] loss: 0.349613755941391 2022-07-20 02:19:06.335549
Epoch:[ 241 16 ] loss: 0.3498396873474121 2022-07-20 02:19:11.612661
Epoch:[ 241 17 ] loss: 0.34969183802604675 2022-07-20 02:19:12.022570
Epoch:[ 241 18 ] loss: 0.35044512152671814 2022-07-20 02:19:12.433410
Epoch:[ 241 19 ] loss: 0.3506256639957428 2022-07-20 02:19:12.846061
Training_Epoch:[ 241 ] Training_loss: 0.34978113025426866 2022-07-20 02:19:12.846946
learning rate:  2.0232717473185764e-05
val: 1 0.4227007031440735
val: 2 0.4235157370567322
val: 3 0.4257870316505432
val: 4 0.42744573950767517
val: 5 0.4195457100868225
val: 6 0.41737100481987
val: 7 0.42204558849334717
val: 8 0.41457870602607727
val: 9 0.4164429008960724
val: 10 0.42065683007240295
val: 11 0.4127521514892578
val: 12 0.41716375946998596
val: 13 0.4219306707382202
val: 14 0.4245067536830902
val: 15 0.41236305236816406
val: 16 0.41404080390930176
val: 17 0.42998024821281433
val: 18 0.4153815507888794
val: 19 0.41384875774383545
val: 20 0.41210970282554626
val_Epoch:[ 241 ] val_loss: 0.4192083701491356 2022-07-20 02:19:16.128508
start training 2022-07-20 02:19:16.234344
Epoch:[ 242 0 ] loss: 0.3484722077846527 2022-07-20 02:19:30.128582
Epoch:[ 242 1 ] loss: 0.3507086932659149 2022-07-20 02:19:30.557708
Epoch:[ 242 2 ] loss: 0.34947502613067627 2022-07-20 02:19:30.972636
Epoch:[ 242 3 ] loss: 0.3495475649833679 2022-07-20 02:19:31.386379
Epoch:[ 242 4 ] loss: 0.3490253686904907 2022-07-20 02:19:31.799870
Epoch:[ 242 5 ] loss: 0.3497541844844818 2022-07-20 02:19:32.208085
Epoch:[ 242 6 ] loss: 0.3488314151763916 2022-07-20 02:19:32.621601
Epoch:[ 242 7 ] loss: 0.3488219678401947 2022-07-20 02:19:33.035738
Epoch:[ 242 8 ] loss: 0.3503904640674591 2022-07-20 02:19:33.450078
Epoch:[ 242 9 ] loss: 0.3508382737636566 2022-07-20 02:19:33.867784
Epoch:[ 242 10 ] loss: 0.3499841094017029 2022-07-20 02:19:34.281391
Epoch:[ 242 11 ] loss: 0.35030049085617065 2022-07-20 02:19:34.693474
Epoch:[ 242 12 ] loss: 0.34931620955467224 2022-07-20 02:19:35.107358
Epoch:[ 242 13 ] loss: 0.3488107919692993 2022-07-20 02:19:35.524586
Epoch:[ 242 14 ] loss: 0.3495742678642273 2022-07-20 02:19:35.937800
Epoch:[ 242 15 ] loss: 0.350186288356781 2022-07-20 02:19:36.353494
Epoch:[ 242 16 ] loss: 0.3491184711456299 2022-07-20 02:19:41.638992
Epoch:[ 242 17 ] loss: 0.3488169312477112 2022-07-20 02:19:42.077922
Epoch:[ 242 18 ] loss: 0.35141342878341675 2022-07-20 02:19:42.499028
Epoch:[ 242 19 ] loss: 0.3500656187534332 2022-07-20 02:19:42.912745
Training_Epoch:[ 242 ] Training_loss: 0.34967258870601653 2022-07-20 02:19:42.913688
learning rate:  2.0232717473185764e-05
netparams have been saved once 242
val: 1 0.42293986678123474
val: 2 0.4207966923713684
val: 3 0.4104003310203552
val: 4 0.4136151373386383
val: 5 0.4138612747192383
val: 6 0.4271790683269501
val: 7 0.4156472682952881
val: 8 0.4169187843799591
val: 9 0.440235435962677
val: 10 0.41528382897377014
val: 11 0.41656360030174255
val: 12 0.41148343682289124
val: 13 0.4259297847747803
val: 14 0.42330434918403625
val: 15 0.41488581895828247
val: 16 0.43336907029151917
val: 17 0.41806405782699585
val: 18 0.40926119685173035
val: 19 0.43473494052886963
val: 20 0.4276476502418518
val_Epoch:[ 242 ] val_loss: 0.42060607969760894 2022-07-20 02:19:46.158347
start training 2022-07-20 02:19:46.261909
Epoch:[ 243 0 ] loss: 0.3492940068244934 2022-07-20 02:20:00.307965
Epoch:[ 243 1 ] loss: 0.34970176219940186 2022-07-20 02:20:00.727439
Epoch:[ 243 2 ] loss: 0.34999585151672363 2022-07-20 02:20:01.143201
Epoch:[ 243 3 ] loss: 0.34905847907066345 2022-07-20 02:20:01.556791
Epoch:[ 243 4 ] loss: 0.3501664698123932 2022-07-20 02:20:01.969872
Epoch:[ 243 5 ] loss: 0.3487853407859802 2022-07-20 02:20:02.382422
Epoch:[ 243 6 ] loss: 0.3497866094112396 2022-07-20 02:20:02.796103
Epoch:[ 243 7 ] loss: 0.34992462396621704 2022-07-20 02:20:03.210249
Epoch:[ 243 8 ] loss: 0.35026684403419495 2022-07-20 02:20:03.623375
Epoch:[ 243 9 ] loss: 0.34956392645835876 2022-07-20 02:20:04.038729
Epoch:[ 243 10 ] loss: 0.3497503697872162 2022-07-20 02:20:04.459694
Epoch:[ 243 11 ] loss: 0.3506079614162445 2022-07-20 02:20:04.872567
Epoch:[ 243 12 ] loss: 0.34911978244781494 2022-07-20 02:20:05.284873
Epoch:[ 243 13 ] loss: 0.35048577189445496 2022-07-20 02:20:05.704952
Epoch:[ 243 14 ] loss: 0.34883275628089905 2022-07-20 02:20:06.118328
Epoch:[ 243 15 ] loss: 0.34914034605026245 2022-07-20 02:20:06.530817
Epoch:[ 243 16 ] loss: 0.3494836986064911 2022-07-20 02:20:12.426546
Epoch:[ 243 17 ] loss: 0.3498455584049225 2022-07-20 02:20:12.841449
Epoch:[ 243 18 ] loss: 0.35029569268226624 2022-07-20 02:20:13.262068
Epoch:[ 243 19 ] loss: 0.3493213653564453 2022-07-20 02:20:13.681872
Training_Epoch:[ 243 ] Training_loss: 0.3496713608503342 2022-07-20 02:20:13.682551
learning rate:  2.0232717473185764e-05
val: 1 0.40889719128608704
val: 2 0.413987398147583
val: 3 0.4199232757091522
val: 4 0.41609326004981995
val: 5 0.4172285795211792
val: 6 0.4302477538585663
val: 7 0.4267396926879883
val: 8 0.4243778884410858
val: 9 0.42657607793807983
val: 10 0.41501542925834656
val: 11 0.4164867401123047
val: 12 0.4254409074783325
val: 13 0.42095810174942017
val: 14 0.4284629225730896
val: 15 0.42211082577705383
val: 16 0.42043501138687134
val: 17 0.4132204055786133
val: 18 0.4216502606868744
val: 19 0.4248954653739929
val: 20 0.41164448857307434
val_Epoch:[ 243 ] val_loss: 0.42021958380937574 2022-07-20 02:20:16.829306
start training 2022-07-20 02:20:16.930230
Epoch:[ 244 0 ] loss: 0.34938472509384155 2022-07-20 02:20:30.721766
Epoch:[ 244 1 ] loss: 0.3501790165901184 2022-07-20 02:20:31.180190
Epoch:[ 244 2 ] loss: 0.35048162937164307 2022-07-20 02:20:31.592372
Epoch:[ 244 3 ] loss: 0.3494454026222229 2022-07-20 02:20:32.007687
Epoch:[ 244 4 ] loss: 0.3504929542541504 2022-07-20 02:20:32.419386
Epoch:[ 244 5 ] loss: 0.35018590092658997 2022-07-20 02:20:32.832517
Epoch:[ 244 6 ] loss: 0.35021501779556274 2022-07-20 02:20:33.246986
Epoch:[ 244 7 ] loss: 0.3493555784225464 2022-07-20 02:20:33.660973
Epoch:[ 244 8 ] loss: 0.3496193587779999 2022-07-20 02:20:34.073896
Epoch:[ 244 9 ] loss: 0.3497855067253113 2022-07-20 02:20:34.486768
Epoch:[ 244 10 ] loss: 0.34956759214401245 2022-07-20 02:20:34.901410
Epoch:[ 244 11 ] loss: 0.34980303049087524 2022-07-20 02:20:35.318116
Epoch:[ 244 12 ] loss: 0.3492435812950134 2022-07-20 02:20:35.731471
Epoch:[ 244 13 ] loss: 0.349473237991333 2022-07-20 02:20:36.140028
Epoch:[ 244 14 ] loss: 0.3501068651676178 2022-07-20 02:20:36.554015
Epoch:[ 244 15 ] loss: 0.34923261404037476 2022-07-20 02:20:36.967821
Epoch:[ 244 16 ] loss: 0.3493276536464691 2022-07-20 02:20:42.365364
Epoch:[ 244 17 ] loss: 0.34928199648857117 2022-07-20 02:20:42.850770
Epoch:[ 244 18 ] loss: 0.34923306107521057 2022-07-20 02:20:43.272258
Epoch:[ 244 19 ] loss: 0.3490464687347412 2022-07-20 02:20:43.684672
Training_Epoch:[ 244 ] Training_loss: 0.3496730595827103 2022-07-20 02:20:43.685366
learning rate:  2.0232717473185764e-05
netparams have been saved once 244
val: 1 0.42302748560905457
val: 2 0.4149022102355957
val: 3 0.4289131760597229
val: 4 0.4217042326927185
val: 5 0.4262799024581909
val: 6 0.4270925521850586
val: 7 0.41865718364715576
val: 8 0.4243737757205963
val: 9 0.4166153073310852
val: 10 0.42678406834602356
val: 11 0.4167976677417755
val: 12 0.42545634508132935
val: 13 0.41522693634033203
val: 14 0.4138003885746002
val: 15 0.4183264970779419
val: 16 0.4176787734031677
val: 17 0.4284173846244812
val: 18 0.4186135530471802
val: 19 0.4212901294231415
val: 20 0.4174000322818756
val_Epoch:[ 244 ] val_loss: 0.4210678800940514 2022-07-20 02:20:46.868019
start training 2022-07-20 02:20:46.969258
Epoch:[ 245 0 ] loss: 0.3499737083911896 2022-07-20 02:21:00.488058
Epoch:[ 245 1 ] loss: 0.34979045391082764 2022-07-20 02:21:00.920680
Epoch:[ 245 2 ] loss: 0.3497656285762787 2022-07-20 02:21:01.334060
Epoch:[ 245 3 ] loss: 0.3488926291465759 2022-07-20 02:21:01.747690
Epoch:[ 245 4 ] loss: 0.34979701042175293 2022-07-20 02:21:02.160961
Epoch:[ 245 5 ] loss: 0.34930452704429626 2022-07-20 02:21:02.574676
Epoch:[ 245 6 ] loss: 0.35090044140815735 2022-07-20 02:21:02.986843
Epoch:[ 245 7 ] loss: 0.35003700852394104 2022-07-20 02:21:03.399732
Epoch:[ 245 8 ] loss: 0.3481120467185974 2022-07-20 02:21:03.814295
Epoch:[ 245 9 ] loss: 0.3493836522102356 2022-07-20 02:21:04.226706
Epoch:[ 245 10 ] loss: 0.35008931159973145 2022-07-20 02:21:04.642422
Epoch:[ 245 11 ] loss: 0.34935957193374634 2022-07-20 02:21:05.057662
Epoch:[ 245 12 ] loss: 0.34984898567199707 2022-07-20 02:21:05.467552
Epoch:[ 245 13 ] loss: 0.34956517815589905 2022-07-20 02:21:05.880905
Epoch:[ 245 14 ] loss: 0.3481453061103821 2022-07-20 02:21:06.290432
Epoch:[ 245 15 ] loss: 0.35059261322021484 2022-07-20 02:21:06.702648
Epoch:[ 245 16 ] loss: 0.35104459524154663 2022-07-20 02:21:12.391085
Epoch:[ 245 17 ] loss: 0.34910640120506287 2022-07-20 02:21:12.803030
Epoch:[ 245 18 ] loss: 0.3498159945011139 2022-07-20 02:21:13.224430
Epoch:[ 245 19 ] loss: 0.3505442142486572 2022-07-20 02:21:13.644461
Training_Epoch:[ 245 ] Training_loss: 0.3497034639120102 2022-07-20 02:21:13.645177
learning rate:  2.0232717473185764e-05
val: 1 0.4317184090614319
val: 2 0.4125092029571533
val: 3 0.4159502685070038
val: 4 0.4222593605518341
val: 5 0.4121779799461365
val: 6 0.42625319957733154
val: 7 0.4193037450313568
val: 8 0.40999701619148254
val: 9 0.4129016101360321
val: 10 0.42957785725593567
val: 11 0.41321948170661926
val: 12 0.42869246006011963
val: 13 0.42049235105514526
val: 14 0.4292302429676056
val: 15 0.41600024700164795
val: 16 0.4192683696746826
val: 17 0.4267460107803345
val: 18 0.4251861572265625
val: 19 0.4136672616004944
val: 20 0.4147723317146301
val_Epoch:[ 245 ] val_loss: 0.419996178150177 2022-07-20 02:21:16.829040
start training 2022-07-20 02:21:16.928784
Epoch:[ 246 0 ] loss: 0.349983811378479 2022-07-20 02:21:31.353420
Epoch:[ 246 1 ] loss: 0.3488253057003021 2022-07-20 02:21:31.765942
Epoch:[ 246 2 ] loss: 0.34918493032455444 2022-07-20 02:21:32.181012
Epoch:[ 246 3 ] loss: 0.3505818247795105 2022-07-20 02:21:32.593895
Epoch:[ 246 4 ] loss: 0.3495379090309143 2022-07-20 02:21:33.003477
Epoch:[ 246 5 ] loss: 0.3496922552585602 2022-07-20 02:21:33.418944
Epoch:[ 246 6 ] loss: 0.3498544991016388 2022-07-20 02:21:33.834964
Epoch:[ 246 7 ] loss: 0.35024935007095337 2022-07-20 02:21:34.247837
Epoch:[ 246 8 ] loss: 0.35027235746383667 2022-07-20 02:21:34.659684
Epoch:[ 246 9 ] loss: 0.3491702079772949 2022-07-20 02:21:35.068004
Epoch:[ 246 10 ] loss: 0.34887295961380005 2022-07-20 02:21:35.482300
Epoch:[ 246 11 ] loss: 0.34941884875297546 2022-07-20 02:21:35.897014
Epoch:[ 246 12 ] loss: 0.34904348850250244 2022-07-20 02:21:36.310768
Epoch:[ 246 13 ] loss: 0.3497544527053833 2022-07-20 02:21:36.725043
Epoch:[ 246 14 ] loss: 0.3496760129928589 2022-07-20 02:21:37.138682
Epoch:[ 246 15 ] loss: 0.34948790073394775 2022-07-20 02:21:37.551323
Epoch:[ 246 16 ] loss: 0.34841251373291016 2022-07-20 02:21:43.066866
Epoch:[ 246 17 ] loss: 0.3489281237125397 2022-07-20 02:21:43.484979
Epoch:[ 246 18 ] loss: 0.34965068101882935 2022-07-20 02:21:43.898276
Epoch:[ 246 19 ] loss: 0.3506816625595093 2022-07-20 02:21:44.318852
Training_Epoch:[ 246 ] Training_loss: 0.349563954770565 2022-07-20 02:21:44.319619
learning rate:  2.0232717473185764e-05
netparams have been saved once 246
val: 1 0.42088425159454346
val: 2 0.4275643527507782
val: 3 0.42534303665161133
val: 4 0.4226698875427246
val: 5 0.41623249650001526
val: 6 0.40880322456359863
val: 7 0.4295066297054291
val: 8 0.41196709871292114
val: 9 0.4188108742237091
val: 10 0.4173740744590759
val: 11 0.42104536294937134
val: 12 0.4281339645385742
val: 13 0.4088798761367798
val: 14 0.42624276876449585
val: 15 0.4354763329029083
val: 16 0.414877325296402
val: 17 0.4282047152519226
val: 18 0.4280663728713989
val: 19 0.4158191382884979
val: 20 0.4201500713825226
val_Epoch:[ 246 ] val_loss: 0.421302592754364 2022-07-20 02:21:47.563727
start training 2022-07-20 02:21:47.665580
Epoch:[ 247 0 ] loss: 0.3497397303581238 2022-07-20 02:22:01.615126
Epoch:[ 247 1 ] loss: 0.3492606282234192 2022-07-20 02:22:02.028924
Epoch:[ 247 2 ] loss: 0.35017457604408264 2022-07-20 02:22:02.439714
Epoch:[ 247 3 ] loss: 0.34956449270248413 2022-07-20 02:22:02.853328
Epoch:[ 247 4 ] loss: 0.3489220440387726 2022-07-20 02:22:03.264981
Epoch:[ 247 5 ] loss: 0.35016128420829773 2022-07-20 02:22:03.676130
Epoch:[ 247 6 ] loss: 0.34951362013816833 2022-07-20 02:22:04.091485
Epoch:[ 247 7 ] loss: 0.34997138381004333 2022-07-20 02:22:04.504014
Epoch:[ 247 8 ] loss: 0.34911400079727173 2022-07-20 02:22:04.916426
Epoch:[ 247 9 ] loss: 0.34955504536628723 2022-07-20 02:22:05.336949
Epoch:[ 247 10 ] loss: 0.34872424602508545 2022-07-20 02:22:05.753964
Epoch:[ 247 11 ] loss: 0.3503074645996094 2022-07-20 02:22:06.172249
Epoch:[ 247 12 ] loss: 0.3492225706577301 2022-07-20 02:22:06.585591
Epoch:[ 247 13 ] loss: 0.3499388098716736 2022-07-20 02:22:06.999292
Epoch:[ 247 14 ] loss: 0.3489720821380615 2022-07-20 02:22:07.414482
Epoch:[ 247 15 ] loss: 0.3494213819503784 2022-07-20 02:22:07.827848
Epoch:[ 247 16 ] loss: 0.34901556372642517 2022-07-20 02:22:13.051463
Epoch:[ 247 17 ] loss: 0.3504875600337982 2022-07-20 02:22:13.638944
Epoch:[ 247 18 ] loss: 0.34977132081985474 2022-07-20 02:22:14.053376
Epoch:[ 247 19 ] loss: 0.34918487071990967 2022-07-20 02:22:14.471529
Training_Epoch:[ 247 ] Training_loss: 0.34955113381147385 2022-07-20 02:22:14.472335
learning rate:  2.0232717473185764e-05
val: 1 0.4120277762413025
val: 2 0.43677398562431335
val: 3 0.41599568724632263
val: 4 0.42930474877357483
val: 5 0.42151445150375366
val: 6 0.4110821485519409
val: 7 0.42296579480171204
val: 8 0.4292752146720886
val: 9 0.42223381996154785
val: 10 0.4163457155227661
val: 11 0.4128952920436859
val: 12 0.40800634026527405
val: 13 0.41289621591567993
val: 14 0.41068366169929504
val: 15 0.411629855632782
val: 16 0.41540077328681946
val: 17 0.4240448772907257
val: 18 0.4072647988796234
val: 19 0.4337098002433777
val: 20 0.4274667799472809
val_Epoch:[ 247 ] val_loss: 0.4190758869051933 2022-07-20 02:22:17.628904
start training 2022-07-20 02:22:17.731898
Epoch:[ 248 0 ] loss: 0.34914571046829224 2022-07-20 02:22:31.586832
Epoch:[ 248 1 ] loss: 0.34954163432121277 2022-07-20 02:22:32.002221
Epoch:[ 248 2 ] loss: 0.3504037857055664 2022-07-20 02:22:32.421317
Epoch:[ 248 3 ] loss: 0.349840372800827 2022-07-20 02:22:32.835960
Epoch:[ 248 4 ] loss: 0.3496314585208893 2022-07-20 02:22:33.248291
Epoch:[ 248 5 ] loss: 0.3487311005592346 2022-07-20 02:22:33.661001
Epoch:[ 248 6 ] loss: 0.34989431500434875 2022-07-20 02:22:34.074200
Epoch:[ 248 7 ] loss: 0.3503219783306122 2022-07-20 02:22:34.494535
Epoch:[ 248 8 ] loss: 0.348930299282074 2022-07-20 02:22:34.909814
Epoch:[ 248 9 ] loss: 0.34903499484062195 2022-07-20 02:22:35.322863
Epoch:[ 248 10 ] loss: 0.3500559329986572 2022-07-20 02:22:35.742991
Epoch:[ 248 11 ] loss: 0.34869176149368286 2022-07-20 02:22:36.157291
Epoch:[ 248 12 ] loss: 0.349504292011261 2022-07-20 02:22:36.570867
Epoch:[ 248 13 ] loss: 0.3495940864086151 2022-07-20 02:22:36.986442
Epoch:[ 248 14 ] loss: 0.3496856689453125 2022-07-20 02:22:37.402272
Epoch:[ 248 15 ] loss: 0.3504367768764496 2022-07-20 02:22:37.817295
Epoch:[ 248 16 ] loss: 0.34850120544433594 2022-07-20 02:22:43.313211
Epoch:[ 248 17 ] loss: 0.3494940400123596 2022-07-20 02:22:43.730927
Epoch:[ 248 18 ] loss: 0.3496704697608948 2022-07-20 02:22:44.145925
Epoch:[ 248 19 ] loss: 0.3495446443557739 2022-07-20 02:22:44.559412
Training_Epoch:[ 248 ] Training_loss: 0.3495327264070511 2022-07-20 02:22:44.560129
learning rate:  2.0232717473185764e-05
netparams have been saved once 248
val: 1 0.4218587577342987
val: 2 0.4117652177810669
val: 3 0.4161660969257355
val: 4 0.4346681535243988
val: 5 0.43096739053726196
val: 6 0.4238337576389313
val: 7 0.4082869291305542
val: 8 0.4131641983985901
val: 9 0.43263742327690125
val: 10 0.4166296422481537
val: 11 0.42366987466812134
val: 12 0.4320688843727112
val: 13 0.409697949886322
val: 14 0.4254601001739502
val: 15 0.4226572811603546
val: 16 0.41946861147880554
val: 17 0.41986361145973206
val: 18 0.40310004353523254
val: 19 0.4153306782245636
val: 20 0.43136799335479736
val_Epoch:[ 248 ] val_loss: 0.42063312977552414 2022-07-20 02:22:47.783587
start training 2022-07-20 02:22:47.883748
Epoch:[ 249 0 ] loss: 0.3498057723045349 2022-07-20 02:23:01.222512
Epoch:[ 249 1 ] loss: 0.35037678480148315 2022-07-20 02:23:01.663147
Epoch:[ 249 2 ] loss: 0.35029298067092896 2022-07-20 02:23:02.095322
Epoch:[ 249 3 ] loss: 0.34969913959503174 2022-07-20 02:23:02.509825
Epoch:[ 249 4 ] loss: 0.3489934504032135 2022-07-20 02:23:02.921915
Epoch:[ 249 5 ] loss: 0.3488585352897644 2022-07-20 02:23:03.335572
Epoch:[ 249 6 ] loss: 0.3501876890659332 2022-07-20 02:23:03.748662
Epoch:[ 249 7 ] loss: 0.34874969720840454 2022-07-20 02:23:04.160968
Epoch:[ 249 8 ] loss: 0.34993764758110046 2022-07-20 02:23:04.576453
Epoch:[ 249 9 ] loss: 0.34897834062576294 2022-07-20 02:23:04.990618
Epoch:[ 249 10 ] loss: 0.3492121696472168 2022-07-20 02:23:05.402632
Epoch:[ 249 11 ] loss: 0.34994110465049744 2022-07-20 02:23:05.813183
Epoch:[ 249 12 ] loss: 0.3499963879585266 2022-07-20 02:23:06.227317
Epoch:[ 249 13 ] loss: 0.34894660115242004 2022-07-20 02:23:06.639961
Epoch:[ 249 14 ] loss: 0.3505604863166809 2022-07-20 02:23:07.051734
Epoch:[ 249 15 ] loss: 0.3490540683269501 2022-07-20 02:23:07.466245
Epoch:[ 249 16 ] loss: 0.3491641581058502 2022-07-20 02:23:13.315366
Epoch:[ 249 17 ] loss: 0.34921205043792725 2022-07-20 02:23:13.724125
Epoch:[ 249 18 ] loss: 0.3492182791233063 2022-07-20 02:23:14.138345
Epoch:[ 249 19 ] loss: 0.3493562638759613 2022-07-20 02:23:14.556803
Training_Epoch:[ 249 ] Training_loss: 0.34952708035707475 2022-07-20 02:23:14.557526
learning rate:  2.0232717473185764e-05
val: 1 0.42212504148483276
val: 2 0.4080469608306885
val: 3 0.42401421070098877
val: 4 0.4194422662258148
val: 5 0.41454175114631653
val: 6 0.4245053231716156
val: 7 0.4266769587993622
val: 8 0.42891159653663635
val: 9 0.42042842507362366
val: 10 0.425565242767334
val: 11 0.42744559049606323
val: 12 0.42320218682289124
val: 13 0.42414435744285583
val: 14 0.41387227177619934
val: 15 0.4219374358654022
val: 16 0.42362064123153687
val: 17 0.4132254421710968
val: 18 0.4143652319908142
val: 19 0.42374464869499207
val: 20 0.4306739568710327
val_Epoch:[ 249 ] val_loss: 0.4215244770050049 2022-07-20 02:23:17.694904
start training 2022-07-20 02:23:17.795285
Epoch:[ 250 0 ] loss: 0.3492540121078491 2022-07-20 02:23:31.068050
Epoch:[ 250 1 ] loss: 0.34921324253082275 2022-07-20 02:23:31.499306
Epoch:[ 250 2 ] loss: 0.35088980197906494 2022-07-20 02:23:31.927791
Epoch:[ 250 3 ] loss: 0.3491520881652832 2022-07-20 02:23:32.344434
Epoch:[ 250 4 ] loss: 0.3495429754257202 2022-07-20 02:23:32.758245
Epoch:[ 250 5 ] loss: 0.3492872714996338 2022-07-20 02:23:33.166505
Epoch:[ 250 6 ] loss: 0.3491172790527344 2022-07-20 02:23:33.580321
Epoch:[ 250 7 ] loss: 0.3492160439491272 2022-07-20 02:23:33.992986
Epoch:[ 250 8 ] loss: 0.34886229038238525 2022-07-20 02:23:34.406170
Epoch:[ 250 9 ] loss: 0.3501400649547577 2022-07-20 02:23:34.816890
Epoch:[ 250 10 ] loss: 0.34920233488082886 2022-07-20 02:23:35.231275
Epoch:[ 250 11 ] loss: 0.35113924741744995 2022-07-20 02:23:35.645297
Epoch:[ 250 12 ] loss: 0.34887009859085083 2022-07-20 02:23:36.057876
Epoch:[ 250 13 ] loss: 0.3493485450744629 2022-07-20 02:23:36.471745
Epoch:[ 250 14 ] loss: 0.3515264391899109 2022-07-20 02:23:36.884302
Epoch:[ 250 15 ] loss: 0.34892886877059937 2022-07-20 02:23:37.299335
Epoch:[ 250 16 ] loss: 0.34971556067466736 2022-07-20 02:23:43.299733
Epoch:[ 250 17 ] loss: 0.3500624895095825 2022-07-20 02:23:43.709726
Epoch:[ 250 18 ] loss: 0.35018157958984375 2022-07-20 02:23:44.133086
Epoch:[ 250 19 ] loss: 0.3498207926750183 2022-07-20 02:23:44.541179
Training_Epoch:[ 250 ] Training_loss: 0.3496735513210297 2022-07-20 02:23:44.542151
learning rate:  2.0232717473185764e-05
netparams have been saved once 250
val: 1 0.4162605404853821
val: 2 0.4126293957233429
val: 3 0.4092238247394562
val: 4 0.42399704456329346
val: 5 0.4299475848674774
val: 6 0.4104229807853699
val: 7 0.4225524961948395
val: 8 0.41308337450027466
val: 9 0.4017655551433563
val: 10 0.4219357967376709
val: 11 0.4325282573699951
val: 12 0.4145379960536957
val: 13 0.4197513461112976
val: 14 0.4158657491207123
val: 15 0.4096818268299103
val: 16 0.42051514983177185
val: 17 0.41451844573020935
val: 18 0.4270748794078827
val: 19 0.41516491770744324
val: 20 0.42572927474975586
val_Epoch:[ 250 ] val_loss: 0.41785932183265684 2022-07-20 02:23:47.904511
