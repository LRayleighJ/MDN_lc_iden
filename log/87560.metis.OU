GPU: True
80
start training 2022-07-01 08:31:39.415062
Epoch:[ 1 0 ] loss: 0.6954191327095032 2022-07-01 08:32:03.414966
Epoch:[ 1 1 ] loss: 0.6970957517623901 2022-07-01 08:32:03.921677
Epoch:[ 1 2 ] loss: 0.6941760182380676 2022-07-01 08:32:04.370770
Epoch:[ 1 3 ] loss: 0.6910203099250793 2022-07-01 08:32:04.821278
Epoch:[ 1 4 ] loss: 0.6843818426132202 2022-07-01 08:32:05.273756
Epoch:[ 1 5 ] loss: 0.6766344308853149 2022-07-01 08:32:05.721911
Epoch:[ 1 6 ] loss: 0.6654581427574158 2022-07-01 08:32:06.168358
Epoch:[ 1 7 ] loss: 0.6571548581123352 2022-07-01 08:32:06.608545
Epoch:[ 1 8 ] loss: 0.6495224833488464 2022-07-01 08:32:07.051904
Epoch:[ 1 9 ] loss: 0.6389068365097046 2022-07-01 08:32:07.493123
Epoch:[ 1 10 ] loss: 0.628861129283905 2022-07-01 08:32:07.933343
Epoch:[ 1 11 ] loss: 0.6276280879974365 2022-07-01 08:32:08.382852
Epoch:[ 1 12 ] loss: 0.6169400811195374 2022-07-01 08:32:08.822579
Epoch:[ 1 13 ] loss: 0.6097100973129272 2022-07-01 08:32:09.267346
Epoch:[ 1 14 ] loss: 0.606671929359436 2022-07-01 08:32:09.715382
Epoch:[ 1 15 ] loss: 0.6088763475418091 2022-07-01 08:32:10.151930
Epoch:[ 1 16 ] loss: 0.5979418158531189 2022-07-01 08:32:10.599670
Epoch:[ 1 17 ] loss: 0.587225615978241 2022-07-01 08:32:11.038527
Epoch:[ 1 18 ] loss: 0.5856869220733643 2022-07-01 08:32:11.481344
Epoch:[ 1 19 ] loss: 0.5829461812973022 2022-07-01 08:32:11.910675
Training_Epoch:[ 1 ] Training_loss: 0.6401129007339478 2022-07-01 08:32:11.911255
learning rate:  0.01
val: 1 0.7026395201683044
val: 2 0.7214596271514893
val: 3 0.7192827463150024
val: 4 0.7112383246421814
val: 5 0.7055520415306091
val: 6 0.7157677412033081
val: 7 0.7176113724708557
val: 8 0.7196593880653381
val: 9 0.7010886073112488
val: 10 0.7183210849761963
val: 11 0.7234935760498047
val: 12 0.7011540532112122
val: 13 0.711746335029602
val: 14 0.7103039026260376
val: 15 0.7210922837257385
val: 16 0.7233440279960632
val: 17 0.7389706969261169
val: 18 0.7269304990768433
val: 19 0.7181699872016907
val: 20 0.7204094529151917
val_Epoch:[ 1 ] val_loss: 0.7164117634296417 2022-07-01 08:32:15.590257
start training 2022-07-01 08:32:15.692921
Epoch:[ 2 0 ] loss: 0.579401969909668 2022-07-01 08:32:30.351135
Epoch:[ 2 1 ] loss: 0.5710844397544861 2022-07-01 08:32:30.855165
Epoch:[ 2 2 ] loss: 0.5697778463363647 2022-07-01 08:32:31.296804
Epoch:[ 2 3 ] loss: 0.5634517073631287 2022-07-01 08:32:31.743851
Epoch:[ 2 4 ] loss: 0.5621580481529236 2022-07-01 08:32:32.194303
Epoch:[ 2 5 ] loss: 0.5614393949508667 2022-07-01 08:32:32.636128
Epoch:[ 2 6 ] loss: 0.5609542727470398 2022-07-01 08:32:33.079105
Epoch:[ 2 7 ] loss: 0.5573945045471191 2022-07-01 08:32:33.523158
Epoch:[ 2 8 ] loss: 0.5529837012290955 2022-07-01 08:32:33.972073
Epoch:[ 2 9 ] loss: 0.5537241697311401 2022-07-01 08:32:34.418275
Epoch:[ 2 10 ] loss: 0.5515264272689819 2022-07-01 08:32:34.868354
Epoch:[ 2 11 ] loss: 0.552944540977478 2022-07-01 08:32:35.311857
Epoch:[ 2 12 ] loss: 0.5530135035514832 2022-07-01 08:32:35.753992
Epoch:[ 2 13 ] loss: 0.5498079061508179 2022-07-01 08:32:36.201319
Epoch:[ 2 14 ] loss: 0.551230788230896 2022-07-01 08:32:36.649339
Epoch:[ 2 15 ] loss: 0.5492879152297974 2022-07-01 08:32:37.092009
Epoch:[ 2 16 ] loss: 0.5460182428359985 2022-07-01 08:32:41.781281
Epoch:[ 2 17 ] loss: 0.5427874326705933 2022-07-01 08:32:42.301535
Epoch:[ 2 18 ] loss: 0.5468178391456604 2022-07-01 08:32:42.736808
Epoch:[ 2 19 ] loss: 0.5463020205497742 2022-07-01 08:32:43.171094
Training_Epoch:[ 2 ] Training_loss: 0.5561053335666657 2022-07-01 08:32:43.171732
learning rate:  0.01
netparams have been saved once 2
val: 1 0.6466125845909119
val: 2 0.6745312213897705
val: 3 0.6706436276435852
val: 4 0.6575519442558289
val: 5 0.6698472499847412
val: 6 0.6721911430358887
val: 7 0.6672484874725342
val: 8 0.6644992232322693
val: 9 0.6806313991546631
val: 10 0.6850757598876953
val: 11 0.6693958640098572
val: 12 0.6569710969924927
val: 13 0.6660892963409424
val: 14 0.6640589237213135
val: 15 0.6608569025993347
val: 16 0.672205924987793
val: 17 0.6776008009910583
val: 18 0.6512990593910217
val: 19 0.6715995073318481
val: 20 0.676147997379303
val_Epoch:[ 2 ] val_loss: 0.6677529007196427 2022-07-01 08:32:46.939891
start training 2022-07-01 08:32:47.039844
Epoch:[ 3 0 ] loss: 0.5432499647140503 2022-07-01 08:33:01.845225
Epoch:[ 3 1 ] loss: 0.5414230227470398 2022-07-01 08:33:02.269960
Epoch:[ 3 2 ] loss: 0.5435336828231812 2022-07-01 08:33:02.700344
Epoch:[ 3 3 ] loss: 0.5467661619186401 2022-07-01 08:33:03.124912
Epoch:[ 3 4 ] loss: 0.5412747859954834 2022-07-01 08:33:03.535212
Epoch:[ 3 5 ] loss: 0.5426403880119324 2022-07-01 08:33:03.948931
Epoch:[ 3 6 ] loss: 0.5405929088592529 2022-07-01 08:33:04.383274
Epoch:[ 3 7 ] loss: 0.5397467613220215 2022-07-01 08:33:04.809503
Epoch:[ 3 8 ] loss: 0.545654833316803 2022-07-01 08:33:05.238384
Epoch:[ 3 9 ] loss: 0.5392932295799255 2022-07-01 08:33:05.661616
Epoch:[ 3 10 ] loss: 0.5390608906745911 2022-07-01 08:33:06.085146
Epoch:[ 3 11 ] loss: 0.5433655381202698 2022-07-01 08:33:06.514421
Epoch:[ 3 12 ] loss: 0.5366729497909546 2022-07-01 08:33:06.944043
Epoch:[ 3 13 ] loss: 0.5356302857398987 2022-07-01 08:33:07.367256
Epoch:[ 3 14 ] loss: 0.5381230711936951 2022-07-01 08:33:07.792706
Epoch:[ 3 15 ] loss: 0.5364834666252136 2022-07-01 08:33:08.218035
Epoch:[ 3 16 ] loss: 0.5365603566169739 2022-07-01 08:33:12.996339
Epoch:[ 3 17 ] loss: 0.5411482453346252 2022-07-01 08:33:13.427265
Epoch:[ 3 18 ] loss: 0.5351018309593201 2022-07-01 08:33:13.858399
Epoch:[ 3 19 ] loss: 0.5373324155807495 2022-07-01 08:33:14.281171
Training_Epoch:[ 3 ] Training_loss: 0.5401827394962311 2022-07-01 08:33:14.281875
learning rate:  0.01
val: 1 0.548184871673584
val: 2 0.557397723197937
val: 3 0.5569324493408203
val: 4 0.5385514497756958
val: 5 0.5496352910995483
val: 6 0.5644142627716064
val: 7 0.5673332214355469
val: 8 0.5517820715904236
val: 9 0.5481817722320557
val: 10 0.5429384708404541
val: 11 0.5511054992675781
val: 12 0.5568124055862427
val: 13 0.5408021211624146
val: 14 0.5516562461853027
val: 15 0.5445839762687683
val: 16 0.5516400337219238
val: 17 0.5400550961494446
val: 18 0.5330163836479187
val: 19 0.5503484606742859
val: 20 0.5400396585464478
val_Epoch:[ 3 ] val_loss: 0.5492705732584 2022-07-01 08:33:17.918488
start training 2022-07-01 08:33:18.024311
Epoch:[ 4 0 ] loss: 0.5347419381141663 2022-07-01 08:33:32.221230
Epoch:[ 4 1 ] loss: 0.5362908244132996 2022-07-01 08:33:32.666530
Epoch:[ 4 2 ] loss: 0.5378392338752747 2022-07-01 08:33:33.086105
Epoch:[ 4 3 ] loss: 0.5326184034347534 2022-07-01 08:33:33.505602
Epoch:[ 4 4 ] loss: 0.5376560091972351 2022-07-01 08:33:33.916626
Epoch:[ 4 5 ] loss: 0.539348304271698 2022-07-01 08:33:34.344867
Epoch:[ 4 6 ] loss: 0.5294480919837952 2022-07-01 08:33:34.767758
Epoch:[ 4 7 ] loss: 0.5343543887138367 2022-07-01 08:33:35.190065
Epoch:[ 4 8 ] loss: 0.5332467555999756 2022-07-01 08:33:35.619339
Epoch:[ 4 9 ] loss: 0.5276736617088318 2022-07-01 08:33:36.038360
Epoch:[ 4 10 ] loss: 0.5368585586547852 2022-07-01 08:33:36.458211
Epoch:[ 4 11 ] loss: 0.530032753944397 2022-07-01 08:33:36.875563
Epoch:[ 4 12 ] loss: 0.5288302898406982 2022-07-01 08:33:37.293577
Epoch:[ 4 13 ] loss: 0.530305802822113 2022-07-01 08:33:37.711906
Epoch:[ 4 14 ] loss: 0.5337609052658081 2022-07-01 08:33:38.135504
Epoch:[ 4 15 ] loss: 0.5303252935409546 2022-07-01 08:33:38.562280
Epoch:[ 4 16 ] loss: 0.5286573171615601 2022-07-01 08:33:43.872124
Epoch:[ 4 17 ] loss: 0.5319162011146545 2022-07-01 08:33:44.290838
Epoch:[ 4 18 ] loss: 0.5329955220222473 2022-07-01 08:33:44.723502
Epoch:[ 4 19 ] loss: 0.5317100286483765 2022-07-01 08:33:45.148724
Training_Epoch:[ 4 ] Training_loss: 0.532930514216423 2022-07-01 08:33:45.149389
learning rate:  0.01
netparams have been saved once 4
val: 1 0.5360797047615051
val: 2 0.5449901223182678
val: 3 0.5406278967857361
val: 4 0.5552797317504883
val: 5 0.5476188063621521
val: 6 0.5438558459281921
val: 7 0.5526226758956909
val: 8 0.5429355502128601
val: 9 0.5361233949661255
val: 10 0.5568506717681885
val: 11 0.5452989935874939
val: 12 0.557826042175293
val: 13 0.5576355457305908
val: 14 0.5400811433792114
val: 15 0.547712504863739
val: 16 0.5460123419761658
val: 17 0.5612891316413879
val: 18 0.5536959767341614
val: 19 0.5558926463127136
val: 20 0.5488314032554626
val_Epoch:[ 4 ] val_loss: 0.5485630065202713 2022-07-01 08:33:48.901914
start training 2022-07-01 08:33:49.007692
Epoch:[ 5 0 ] loss: 0.528921365737915 2022-07-01 08:34:03.361966
Epoch:[ 5 1 ] loss: 0.5310364961624146 2022-07-01 08:34:03.907836
Epoch:[ 5 2 ] loss: 0.5292428731918335 2022-07-01 08:34:04.326421
Epoch:[ 5 3 ] loss: 0.5297548174858093 2022-07-01 08:34:04.750241
Epoch:[ 5 4 ] loss: 0.525899350643158 2022-07-01 08:34:05.170908
Epoch:[ 5 5 ] loss: 0.5273711085319519 2022-07-01 08:34:05.594926
Epoch:[ 5 6 ] loss: 0.5288766622543335 2022-07-01 08:34:06.013499
Epoch:[ 5 7 ] loss: 0.5286254286766052 2022-07-01 08:34:06.432598
Epoch:[ 5 8 ] loss: 0.5276795625686646 2022-07-01 08:34:06.856401
Epoch:[ 5 9 ] loss: 0.5230330228805542 2022-07-01 08:34:07.280741
Epoch:[ 5 10 ] loss: 0.5342065691947937 2022-07-01 08:34:07.699752
Epoch:[ 5 11 ] loss: 0.5293160676956177 2022-07-01 08:34:08.124389
Epoch:[ 5 12 ] loss: 0.528159499168396 2022-07-01 08:34:08.542301
Epoch:[ 5 13 ] loss: 0.5305869579315186 2022-07-01 08:34:08.960460
Epoch:[ 5 14 ] loss: 0.5297438502311707 2022-07-01 08:34:09.378006
Epoch:[ 5 15 ] loss: 0.5282344818115234 2022-07-01 08:34:09.794949
Epoch:[ 5 16 ] loss: 0.5274821519851685 2022-07-01 08:34:15.054992
Epoch:[ 5 17 ] loss: 0.5248453617095947 2022-07-01 08:34:15.509815
Epoch:[ 5 18 ] loss: 0.5257896780967712 2022-07-01 08:34:15.930687
Epoch:[ 5 19 ] loss: 0.5282497406005859 2022-07-01 08:34:16.354256
Training_Epoch:[ 5 ] Training_loss: 0.528352752327919 2022-07-01 08:34:16.354936
learning rate:  0.01
val: 1 0.6082732081413269
val: 2 0.5990222096443176
val: 3 0.5942960977554321
val: 4 0.5991060137748718
val: 5 0.6109941005706787
val: 6 0.6089574694633484
val: 7 0.6013805866241455
val: 8 0.6026889085769653
val: 9 0.6070764064788818
val: 10 0.615227997303009
val: 11 0.6012548208236694
val: 12 0.6187658905982971
val: 13 0.6031695008277893
val: 14 0.6224058270454407
val: 15 0.6076415181159973
val: 16 0.6090736389160156
val: 17 0.6111578941345215
val: 18 0.5961064100265503
val: 19 0.5983645915985107
val: 20 0.6091263294219971
val_Epoch:[ 5 ] val_loss: 0.6062044709920883 2022-07-01 08:34:19.975155
start training 2022-07-01 08:34:20.081814
Epoch:[ 6 0 ] loss: 0.5228091478347778 2022-07-01 08:34:34.728249
Epoch:[ 6 1 ] loss: 0.5235315561294556 2022-07-01 08:34:35.145852
Epoch:[ 6 2 ] loss: 0.5206549763679504 2022-07-01 08:34:35.569570
Epoch:[ 6 3 ] loss: 0.5257313251495361 2022-07-01 08:34:35.994611
Epoch:[ 6 4 ] loss: 0.5274011492729187 2022-07-01 08:34:36.414026
Epoch:[ 6 5 ] loss: 0.5271108746528625 2022-07-01 08:34:36.833408
Epoch:[ 6 6 ] loss: 0.5267630815505981 2022-07-01 08:34:37.255481
Epoch:[ 6 7 ] loss: 0.5234005451202393 2022-07-01 08:34:37.674944
Epoch:[ 6 8 ] loss: 0.523729145526886 2022-07-01 08:34:38.094437
Epoch:[ 6 9 ] loss: 0.5249547958374023 2022-07-01 08:34:38.512217
Epoch:[ 6 10 ] loss: 0.523792028427124 2022-07-01 08:34:38.936984
Epoch:[ 6 11 ] loss: 0.5236524343490601 2022-07-01 08:34:39.356438
Epoch:[ 6 12 ] loss: 0.5252878069877625 2022-07-01 08:34:39.780293
Epoch:[ 6 13 ] loss: 0.5217733979225159 2022-07-01 08:34:40.198048
Epoch:[ 6 14 ] loss: 0.5206461548805237 2022-07-01 08:34:40.623548
Epoch:[ 6 15 ] loss: 0.5209660530090332 2022-07-01 08:34:41.040799
Epoch:[ 6 16 ] loss: 0.5267915725708008 2022-07-01 08:34:46.642227
Epoch:[ 6 17 ] loss: 0.5238965153694153 2022-07-01 08:34:47.065841
Epoch:[ 6 18 ] loss: 0.5260875225067139 2022-07-01 08:34:47.485491
Epoch:[ 6 19 ] loss: 0.5248157382011414 2022-07-01 08:34:47.903907
Training_Epoch:[ 6 ] Training_loss: 0.5241897910833359 2022-07-01 08:34:47.904559
learning rate:  0.01
netparams have been saved once 6
val: 1 0.5375602841377258
val: 2 0.5345339179039001
val: 3 0.5349764227867126
val: 4 0.5384380221366882
val: 5 0.5359562635421753
val: 6 0.5290488004684448
val: 7 0.5353960990905762
val: 8 0.5239444375038147
val: 9 0.5422191619873047
val: 10 0.5510461330413818
val: 11 0.5240833163261414
val: 12 0.5364881157875061
val: 13 0.5190656185150146
val: 14 0.5267351269721985
val: 15 0.5256457328796387
val: 16 0.5424673557281494
val: 17 0.5292580723762512
val: 18 0.5370283722877502
val: 19 0.5206356048583984
val: 20 0.5382962822914124
val_Epoch:[ 6 ] val_loss: 0.5331411570310592 2022-07-01 08:34:51.692238
start training 2022-07-01 08:34:51.792623
Epoch:[ 7 0 ] loss: 0.5226852893829346 2022-07-01 08:35:06.551592
Epoch:[ 7 1 ] loss: 0.5214486122131348 2022-07-01 08:35:06.971814
Epoch:[ 7 2 ] loss: 0.5236585140228271 2022-07-01 08:35:07.389684
Epoch:[ 7 3 ] loss: 0.5218584537506104 2022-07-01 08:35:07.805501
Epoch:[ 7 4 ] loss: 0.522652268409729 2022-07-01 08:35:08.224596
Epoch:[ 7 5 ] loss: 0.5240695476531982 2022-07-01 08:35:08.649252
Epoch:[ 7 6 ] loss: 0.5173748731613159 2022-07-01 08:35:09.066291
Epoch:[ 7 7 ] loss: 0.5207672715187073 2022-07-01 08:35:09.483666
Epoch:[ 7 8 ] loss: 0.5210672616958618 2022-07-01 08:35:09.900921
Epoch:[ 7 9 ] loss: 0.5226873159408569 2022-07-01 08:35:10.324761
Epoch:[ 7 10 ] loss: 0.516541063785553 2022-07-01 08:35:10.748344
Epoch:[ 7 11 ] loss: 0.5196520686149597 2022-07-01 08:35:11.172935
Epoch:[ 7 12 ] loss: 0.518648624420166 2022-07-01 08:35:11.592816
Epoch:[ 7 13 ] loss: 0.5184050798416138 2022-07-01 08:35:12.013887
Epoch:[ 7 14 ] loss: 0.5223008990287781 2022-07-01 08:35:12.436106
Epoch:[ 7 15 ] loss: 0.5179423689842224 2022-07-01 08:35:12.852356
Epoch:[ 7 16 ] loss: 0.5186219215393066 2022-07-01 08:35:18.183579
Epoch:[ 7 17 ] loss: 0.5216861963272095 2022-07-01 08:35:18.599358
Epoch:[ 7 18 ] loss: 0.5202738642692566 2022-07-01 08:35:19.026121
Epoch:[ 7 19 ] loss: 0.5212111473083496 2022-07-01 08:35:19.445152
Training_Epoch:[ 7 ] Training_loss: 0.5206776320934295 2022-07-01 08:35:19.445800
learning rate:  0.01
val: 1 0.6226913928985596
val: 2 0.6251092553138733
val: 3 0.6278687119483948
val: 4 0.6196434497833252
val: 5 0.6143290400505066
val: 6 0.6296392679214478
val: 7 0.6194298267364502
val: 8 0.6148671507835388
val: 9 0.6222370862960815
val: 10 0.6253076195716858
val: 11 0.6028498411178589
val: 12 0.6224159598350525
val: 13 0.6204022169113159
val: 14 0.6202991008758545
val: 15 0.6303939819335938
val: 16 0.6156460046768188
val: 17 0.6110162734985352
val: 18 0.6271962523460388
val: 19 0.6282156109809875
val: 20 0.6140580177307129
val_Epoch:[ 7 ] val_loss: 0.6206808030605316 2022-07-01 08:35:23.116175
start training 2022-07-01 08:35:23.220240
Epoch:[ 8 0 ] loss: 0.5220251679420471 2022-07-01 08:35:38.477404
Epoch:[ 8 1 ] loss: 0.5202710628509521 2022-07-01 08:35:38.896953
Epoch:[ 8 2 ] loss: 0.5200557112693787 2022-07-01 08:35:39.319869
Epoch:[ 8 3 ] loss: 0.5154125094413757 2022-07-01 08:35:39.744520
Epoch:[ 8 4 ] loss: 0.5225399732589722 2022-07-01 08:35:40.160039
Epoch:[ 8 5 ] loss: 0.5170111060142517 2022-07-01 08:35:40.584817
Epoch:[ 8 6 ] loss: 0.5211277604103088 2022-07-01 08:35:41.003631
Epoch:[ 8 7 ] loss: 0.514933705329895 2022-07-01 08:35:41.420767
Epoch:[ 8 8 ] loss: 0.5166034698486328 2022-07-01 08:35:41.838078
Epoch:[ 8 9 ] loss: 0.5144241452217102 2022-07-01 08:35:42.262371
Epoch:[ 8 10 ] loss: 0.5204101204872131 2022-07-01 08:35:42.679458
Epoch:[ 8 11 ] loss: 0.5184844136238098 2022-07-01 08:35:43.102354
Epoch:[ 8 12 ] loss: 0.5190297961235046 2022-07-01 08:35:43.527284
Epoch:[ 8 13 ] loss: 0.517267107963562 2022-07-01 08:35:43.947370
Epoch:[ 8 14 ] loss: 0.520479142665863 2022-07-01 08:35:44.365636
Epoch:[ 8 15 ] loss: 0.5190210938453674 2022-07-01 08:35:44.781455
Epoch:[ 8 16 ] loss: 0.5174278020858765 2022-07-01 08:35:49.797908
Epoch:[ 8 17 ] loss: 0.5147392749786377 2022-07-01 08:35:50.214785
Epoch:[ 8 18 ] loss: 0.5161470174789429 2022-07-01 08:35:50.633082
Epoch:[ 8 19 ] loss: 0.5162205100059509 2022-07-01 08:35:51.057269
Training_Epoch:[ 8 ] Training_loss: 0.5181815445423126 2022-07-01 08:35:51.057886
learning rate:  0.01
netparams have been saved once 8
val: 1 0.6320454478263855
val: 2 0.6485392451286316
val: 3 0.626771867275238
val: 4 0.6243072152137756
val: 5 0.628339946269989
val: 6 0.6325196027755737
val: 7 0.6453506946563721
val: 8 0.6281738877296448
val: 9 0.6440849900245667
val: 10 0.6369362473487854
val: 11 0.6338325142860413
val: 12 0.638276219367981
val: 13 0.6574148535728455
val: 14 0.6278279423713684
val: 15 0.6366655230522156
val: 16 0.6304051280021667
val: 17 0.6358098983764648
val: 18 0.6243427991867065
val: 19 0.6372472047805786
val: 20 0.6213471293449402
val_Epoch:[ 8 ] val_loss: 0.6345119178295135 2022-07-01 08:35:54.767235
start training 2022-07-01 08:35:54.873159
Epoch:[ 9 0 ] loss: 0.5147675275802612 2022-07-01 08:36:09.510897
Epoch:[ 9 1 ] loss: 0.516968309879303 2022-07-01 08:36:09.929913
Epoch:[ 9 2 ] loss: 0.5117769241333008 2022-07-01 08:36:10.348355
Epoch:[ 9 3 ] loss: 0.5175009369850159 2022-07-01 08:36:10.772299
Epoch:[ 9 4 ] loss: 0.5195222496986389 2022-07-01 08:36:11.191311
Epoch:[ 9 5 ] loss: 0.5178413391113281 2022-07-01 08:36:11.608213
Epoch:[ 9 6 ] loss: 0.5168777108192444 2022-07-01 08:36:12.033690
Epoch:[ 9 7 ] loss: 0.5164293050765991 2022-07-01 08:36:12.453464
Epoch:[ 9 8 ] loss: 0.5135292410850525 2022-07-01 08:36:12.876662
Epoch:[ 9 9 ] loss: 0.5157635807991028 2022-07-01 08:36:13.294409
Epoch:[ 9 10 ] loss: 0.5121003985404968 2022-07-01 08:36:13.710944
Epoch:[ 9 11 ] loss: 0.515687882900238 2022-07-01 08:36:14.133767
Epoch:[ 9 12 ] loss: 0.5139788389205933 2022-07-01 08:36:14.556247
Epoch:[ 9 13 ] loss: 0.5162872076034546 2022-07-01 08:36:14.976223
Epoch:[ 9 14 ] loss: 0.5164855718612671 2022-07-01 08:36:15.394849
Epoch:[ 9 15 ] loss: 0.5149050354957581 2022-07-01 08:36:15.819359
Epoch:[ 9 16 ] loss: 0.5149303674697876 2022-07-01 08:36:20.726371
Epoch:[ 9 17 ] loss: 0.5116803646087646 2022-07-01 08:36:21.462949
Epoch:[ 9 18 ] loss: 0.5154445767402649 2022-07-01 08:36:21.883769
Epoch:[ 9 19 ] loss: 0.5138171911239624 2022-07-01 08:36:22.306113
Training_Epoch:[ 9 ] Training_loss: 0.5153147280216217 2022-07-01 08:36:22.306815
learning rate:  0.01
val: 1 0.5299664735794067
val: 2 0.535422682762146
val: 3 0.536190927028656
val: 4 0.5345398187637329
val: 5 0.5227735042572021
val: 6 0.5220392942428589
val: 7 0.5212006568908691
val: 8 0.5298658013343811
val: 9 0.5164417624473572
val: 10 0.5309455394744873
val: 11 0.5278291702270508
val: 12 0.5193021297454834
val: 13 0.5270130634307861
val: 14 0.5220736861228943
val: 15 0.5377771854400635
val: 16 0.541597843170166
val: 17 0.5263120532035828
val: 18 0.5305747389793396
val: 19 0.5282382965087891
val: 20 0.5322861671447754
val_Epoch:[ 9 ] val_loss: 0.5286195397377014 2022-07-01 08:36:25.941807
start training 2022-07-01 08:36:26.050649
Epoch:[ 10 0 ] loss: 0.5142596364021301 2022-07-01 08:36:40.700002
Epoch:[ 10 1 ] loss: 0.5165510177612305 2022-07-01 08:36:41.124878
Epoch:[ 10 2 ] loss: 0.5153428912162781 2022-07-01 08:36:41.542474
Epoch:[ 10 3 ] loss: 0.5136421918869019 2022-07-01 08:36:41.960963
Epoch:[ 10 4 ] loss: 0.5144824981689453 2022-07-01 08:36:42.384010
Epoch:[ 10 5 ] loss: 0.5134994387626648 2022-07-01 08:36:42.807623
Epoch:[ 10 6 ] loss: 0.5160152912139893 2022-07-01 08:36:43.225316
Epoch:[ 10 7 ] loss: 0.5109350085258484 2022-07-01 08:36:43.643804
Epoch:[ 10 8 ] loss: 0.5120260715484619 2022-07-01 08:36:44.067671
Epoch:[ 10 9 ] loss: 0.5109454393386841 2022-07-01 08:36:44.487566
Epoch:[ 10 10 ] loss: 0.5117274522781372 2022-07-01 08:36:44.910287
Epoch:[ 10 11 ] loss: 0.5086541771888733 2022-07-01 08:36:45.327223
Epoch:[ 10 12 ] loss: 0.5097160339355469 2022-07-01 08:36:45.744364
Epoch:[ 10 13 ] loss: 0.5126715898513794 2022-07-01 08:36:46.166727
Epoch:[ 10 14 ] loss: 0.5129721164703369 2022-07-01 08:36:46.585242
Epoch:[ 10 15 ] loss: 0.5091693997383118 2022-07-01 08:36:47.007018
Epoch:[ 10 16 ] loss: 0.5175898671150208 2022-07-01 08:36:52.117634
Epoch:[ 10 17 ] loss: 0.5115158557891846 2022-07-01 08:36:52.540992
Epoch:[ 10 18 ] loss: 0.508973240852356 2022-07-01 08:36:52.960026
Epoch:[ 10 19 ] loss: 0.5124457478523254 2022-07-01 08:36:53.376424
Training_Epoch:[ 10 ] Training_loss: 0.5126567482948303 2022-07-01 08:36:53.377080
learning rate:  0.01
netparams have been saved once 10
val: 1 0.6422104239463806
val: 2 0.636898398399353
val: 3 0.6450444459915161
val: 4 0.6347251534461975
val: 5 0.6453543901443481
val: 6 0.6410689353942871
val: 7 0.641457200050354
val: 8 0.6414257884025574
val: 9 0.6287158727645874
val: 10 0.6348901987075806
val: 11 0.6566622853279114
val: 12 0.6490057706832886
val: 13 0.6511919498443604
val: 14 0.6350154280662537
val: 15 0.6622180938720703
val: 16 0.6411022543907166
val: 17 0.6459963321685791
val: 18 0.6378805637359619
val: 19 0.6418159604072571
val: 20 0.6420517563819885
val_Epoch:[ 10 ] val_loss: 0.6427365601062774 2022-07-01 08:36:57.091953
start training 2022-07-01 08:36:57.193514
Epoch:[ 11 0 ] loss: 0.5112678408622742 2022-07-01 08:37:12.230590
Epoch:[ 11 1 ] loss: 0.5096495747566223 2022-07-01 08:37:12.654471
Epoch:[ 11 2 ] loss: 0.509248673915863 2022-07-01 08:37:13.085478
Epoch:[ 11 3 ] loss: 0.5055141448974609 2022-07-01 08:37:13.510758
Epoch:[ 11 4 ] loss: 0.5096314549446106 2022-07-01 08:37:13.930798
Epoch:[ 11 5 ] loss: 0.5083330273628235 2022-07-01 08:37:14.350370
Epoch:[ 11 6 ] loss: 0.5076804161071777 2022-07-01 08:37:14.773001
Epoch:[ 11 7 ] loss: 0.5063294172286987 2022-07-01 08:37:15.209392
Epoch:[ 11 8 ] loss: 0.5080689191818237 2022-07-01 08:37:15.630551
Epoch:[ 11 9 ] loss: 0.5090131163597107 2022-07-01 08:37:16.062733
Epoch:[ 11 10 ] loss: 0.5069441795349121 2022-07-01 08:37:16.483358
Epoch:[ 11 11 ] loss: 0.5079025030136108 2022-07-01 08:37:16.915705
Epoch:[ 11 12 ] loss: 0.5079470276832581 2022-07-01 08:37:17.340337
Epoch:[ 11 13 ] loss: 0.507041335105896 2022-07-01 08:37:17.773869
Epoch:[ 11 14 ] loss: 0.50715571641922 2022-07-01 08:37:18.198510
Epoch:[ 11 15 ] loss: 0.5035383701324463 2022-07-01 08:37:18.651417
Epoch:[ 11 16 ] loss: 0.5108658671379089 2022-07-01 08:37:23.654263
Epoch:[ 11 17 ] loss: 0.506416380405426 2022-07-01 08:37:24.080002
Epoch:[ 11 18 ] loss: 0.5068275332450867 2022-07-01 08:37:24.510844
Epoch:[ 11 19 ] loss: 0.5029838681221008 2022-07-01 08:37:24.931497
Training_Epoch:[ 11 ] Training_loss: 0.5076179683208466 2022-07-01 08:37:24.932356
learning rate:  0.008
val: 1 0.5109336972236633
val: 2 0.5221404433250427
val: 3 0.5166510343551636
val: 4 0.5098556280136108
val: 5 0.5111980438232422
val: 6 0.5064889788627625
val: 7 0.5198081731796265
val: 8 0.5087664127349854
val: 9 0.5134541392326355
val: 10 0.5139274001121521
val: 11 0.5115098357200623
val: 12 0.5121427178382874
val: 13 0.5145001411437988
val: 14 0.5100988745689392
val: 15 0.5123322010040283
val: 16 0.5065082311630249
val: 17 0.5114151239395142
val: 18 0.5176464319229126
val: 19 0.5075103044509888
val: 20 0.5150936841964722
val_Epoch:[ 11 ] val_loss: 0.5125990748405457 2022-07-01 08:37:28.677501
start training 2022-07-01 08:37:28.774790
Epoch:[ 12 0 ] loss: 0.5036134719848633 2022-07-01 08:37:44.004698
Epoch:[ 12 1 ] loss: 0.5032456517219543 2022-07-01 08:37:44.431445
Epoch:[ 12 2 ] loss: 0.49898475408554077 2022-07-01 08:37:44.852262
Epoch:[ 12 3 ] loss: 0.5036338567733765 2022-07-01 08:37:45.279033
Epoch:[ 12 4 ] loss: 0.5053361654281616 2022-07-01 08:37:45.698236
Epoch:[ 12 5 ] loss: 0.5043789148330688 2022-07-01 08:37:46.127144
Epoch:[ 12 6 ] loss: 0.50652015209198 2022-07-01 08:37:46.548939
Epoch:[ 12 7 ] loss: 0.507469117641449 2022-07-01 08:37:46.974541
Epoch:[ 12 8 ] loss: 0.4976758360862732 2022-07-01 08:37:47.419163
Epoch:[ 12 9 ] loss: 0.5049186944961548 2022-07-01 08:37:47.839951
Epoch:[ 12 10 ] loss: 0.5121393203735352 2022-07-01 08:37:48.265505
Epoch:[ 12 11 ] loss: 0.504009485244751 2022-07-01 08:37:48.711758
Epoch:[ 12 12 ] loss: 0.5051263570785522 2022-07-01 08:37:49.133618
Epoch:[ 12 13 ] loss: 0.5060204267501831 2022-07-01 08:37:49.572072
Epoch:[ 12 14 ] loss: 0.5035721063613892 2022-07-01 08:37:50.011678
Epoch:[ 12 15 ] loss: 0.5034158825874329 2022-07-01 08:37:50.439520
Epoch:[ 12 16 ] loss: 0.5046911239624023 2022-07-01 08:37:55.404560
Epoch:[ 12 17 ] loss: 0.5070772171020508 2022-07-01 08:37:55.824997
Epoch:[ 12 18 ] loss: 0.5015297532081604 2022-07-01 08:37:56.265546
Epoch:[ 12 19 ] loss: 0.4970960021018982 2022-07-01 08:37:56.688967
Training_Epoch:[ 12 ] Training_loss: 0.5040227144956588 2022-07-01 08:37:56.689821
learning rate:  0.008
netparams have been saved once 12
val: 1 0.5359943509101868
val: 2 0.5270106792449951
val: 3 0.5364837646484375
val: 4 0.5193945169448853
val: 5 0.5198060870170593
val: 6 0.5163708925247192
val: 7 0.5362818837165833
val: 8 0.5195056200027466
val: 9 0.5193285942077637
val: 10 0.5201541185379028
val: 11 0.5217103958129883
val: 12 0.5215904116630554
val: 13 0.5331198573112488
val: 14 0.5226759910583496
val: 15 0.5296517610549927
val: 16 0.5253240466117859
val: 17 0.5221908092498779
val: 18 0.5067506432533264
val: 19 0.520349383354187
val: 20 0.5134537220001221
val_Epoch:[ 12 ] val_loss: 0.5233573764562607 2022-07-01 08:38:00.456779
start training 2022-07-01 08:38:00.555945
Epoch:[ 13 0 ] loss: 0.5028709173202515 2022-07-01 08:38:15.611099
Epoch:[ 13 1 ] loss: 0.502982497215271 2022-07-01 08:38:16.037670
Epoch:[ 13 2 ] loss: 0.4998437166213989 2022-07-01 08:38:16.457172
Epoch:[ 13 3 ] loss: 0.5014180541038513 2022-07-01 08:38:16.890566
Epoch:[ 13 4 ] loss: 0.49383246898651123 2022-07-01 08:38:17.315131
Epoch:[ 13 5 ] loss: 0.4929910898208618 2022-07-01 08:38:17.749533
Epoch:[ 13 6 ] loss: 0.5039621591567993 2022-07-01 08:38:18.174403
Epoch:[ 13 7 ] loss: 0.4994528889656067 2022-07-01 08:38:18.598742
Epoch:[ 13 8 ] loss: 0.499407023191452 2022-07-01 08:38:19.016141
Epoch:[ 13 9 ] loss: 0.5050158500671387 2022-07-01 08:38:19.443214
Epoch:[ 13 10 ] loss: 0.4966115653514862 2022-07-01 08:38:19.866516
Epoch:[ 13 11 ] loss: 0.5011430978775024 2022-07-01 08:38:20.293176
Epoch:[ 13 12 ] loss: 0.5033026933670044 2022-07-01 08:38:20.724644
Epoch:[ 13 13 ] loss: 0.4972690939903259 2022-07-01 08:38:21.158919
Epoch:[ 13 14 ] loss: 0.49698057770729065 2022-07-01 08:38:21.598256
Epoch:[ 13 15 ] loss: 0.49539440870285034 2022-07-01 08:38:22.031842
Epoch:[ 13 16 ] loss: 0.4923020005226135 2022-07-01 08:38:27.333729
Epoch:[ 13 17 ] loss: 0.4979294538497925 2022-07-01 08:38:27.755530
Epoch:[ 13 18 ] loss: 0.49228280782699585 2022-07-01 08:38:28.191854
Epoch:[ 13 19 ] loss: 0.49427109956741333 2022-07-01 08:38:28.616026
Training_Epoch:[ 13 ] Training_loss: 0.4984631732106209 2022-07-01 08:38:28.616818
learning rate:  0.008
val: 1 0.5316436886787415
val: 2 0.5274523496627808
val: 3 0.5275720357894897
val: 4 0.5243868231773376
val: 5 0.5320791006088257
val: 6 0.5224140882492065
val: 7 0.5252726078033447
val: 8 0.5145351886749268
val: 9 0.5206031203269958
val: 10 0.5105232000350952
val: 11 0.5209408402442932
val: 12 0.5301074981689453
val: 13 0.5255250930786133
val: 14 0.5346187949180603
val: 15 0.529510498046875
val: 16 0.5283336639404297
val: 17 0.5086779594421387
val: 18 0.5302368998527527
val: 19 0.5185620784759521
val: 20 0.5243178009986877
val_Epoch:[ 13 ] val_loss: 0.5243656665086747 2022-07-01 08:38:32.283932
start training 2022-07-01 08:38:32.383849
Epoch:[ 14 0 ] loss: 0.4987931251525879 2022-07-01 08:38:47.286334
Epoch:[ 14 1 ] loss: 0.4949359893798828 2022-07-01 08:38:47.706339
Epoch:[ 14 2 ] loss: 0.49317747354507446 2022-07-01 08:38:48.125838
Epoch:[ 14 3 ] loss: 0.5014851689338684 2022-07-01 08:38:48.546140
Epoch:[ 14 4 ] loss: 0.4985993504524231 2022-07-01 08:38:48.969806
Epoch:[ 14 5 ] loss: 0.49822038412094116 2022-07-01 08:38:49.392961
Epoch:[ 14 6 ] loss: 0.5025529265403748 2022-07-01 08:38:49.811739
Epoch:[ 14 7 ] loss: 0.4973441958427429 2022-07-01 08:38:50.233505
Epoch:[ 14 8 ] loss: 0.49262502789497375 2022-07-01 08:38:50.655457
Epoch:[ 14 9 ] loss: 0.4942910075187683 2022-07-01 08:38:51.075388
Epoch:[ 14 10 ] loss: 0.493842750787735 2022-07-01 08:38:51.498268
Epoch:[ 14 11 ] loss: 0.49835655093193054 2022-07-01 08:38:51.926605
Epoch:[ 14 12 ] loss: 0.48740801215171814 2022-07-01 08:38:52.353667
Epoch:[ 14 13 ] loss: 0.49666479229927063 2022-07-01 08:38:52.778840
Epoch:[ 14 14 ] loss: 0.494310587644577 2022-07-01 08:38:53.203091
Epoch:[ 14 15 ] loss: 0.49791520833969116 2022-07-01 08:38:53.628969
Epoch:[ 14 16 ] loss: 0.49707984924316406 2022-07-01 08:38:59.069316
Epoch:[ 14 17 ] loss: 0.5018683075904846 2022-07-01 08:38:59.484314
Epoch:[ 14 18 ] loss: 0.49873220920562744 2022-07-01 08:38:59.910612
Epoch:[ 14 19 ] loss: 0.4983247220516205 2022-07-01 08:39:00.329187
Training_Epoch:[ 14 ] Training_loss: 0.49682638198137286 2022-07-01 08:39:00.329919
learning rate:  0.008
netparams have been saved once 14
val: 1 0.5952366590499878
val: 2 0.6022789478302002
val: 3 0.5934471487998962
val: 4 0.607087254524231
val: 5 0.6069722771644592
val: 6 0.5984876751899719
val: 7 0.618598222732544
val: 8 0.5965287089347839
val: 9 0.6129191517829895
val: 10 0.611026406288147
val: 11 0.6164877414703369
val: 12 0.6145929098129272
val: 13 0.5967469215393066
val: 14 0.5997811555862427
val: 15 0.6055795550346375
val: 16 0.6078047752380371
val: 17 0.5986081957817078
val: 18 0.6124445796012878
val: 19 0.6128371357917786
val: 20 0.5959651470184326
val_Epoch:[ 14 ] val_loss: 0.6051715284585952 2022-07-01 08:39:04.095291
start training 2022-07-01 08:39:04.194238
Epoch:[ 15 0 ] loss: 0.5015060305595398 2022-07-01 08:39:18.794548
Epoch:[ 15 1 ] loss: 0.49495893716812134 2022-07-01 08:39:19.213089
Epoch:[ 15 2 ] loss: 0.496942937374115 2022-07-01 08:39:19.630440
Epoch:[ 15 3 ] loss: 0.49728769063949585 2022-07-01 08:39:20.047232
Epoch:[ 15 4 ] loss: 0.4955528676509857 2022-07-01 08:39:20.464015
Epoch:[ 15 5 ] loss: 0.4930223226547241 2022-07-01 08:39:20.888739
Epoch:[ 15 6 ] loss: 0.4971446096897125 2022-07-01 08:39:21.308485
Epoch:[ 15 7 ] loss: 0.49471282958984375 2022-07-01 08:39:21.731707
Epoch:[ 15 8 ] loss: 0.49197444319725037 2022-07-01 08:39:22.154619
Epoch:[ 15 9 ] loss: 0.49366265535354614 2022-07-01 08:39:22.578338
Epoch:[ 15 10 ] loss: 0.4931117296218872 2022-07-01 08:39:22.995465
Epoch:[ 15 11 ] loss: 0.4915132224559784 2022-07-01 08:39:23.413185
Epoch:[ 15 12 ] loss: 0.49196022748947144 2022-07-01 08:39:23.834343
Epoch:[ 15 13 ] loss: 0.49157312512397766 2022-07-01 08:39:24.258929
Epoch:[ 15 14 ] loss: 0.48903888463974 2022-07-01 08:39:24.676754
Epoch:[ 15 15 ] loss: 0.48730921745300293 2022-07-01 08:39:25.099373
Epoch:[ 15 16 ] loss: 0.49267691373825073 2022-07-01 08:39:30.067561
Epoch:[ 15 17 ] loss: 0.4943881034851074 2022-07-01 08:39:30.804778
Epoch:[ 15 18 ] loss: 0.4896059036254883 2022-07-01 08:39:31.221841
Epoch:[ 15 19 ] loss: 0.4893956184387207 2022-07-01 08:39:31.645777
Training_Epoch:[ 15 ] Training_loss: 0.493366913497448 2022-07-01 08:39:31.646430
learning rate:  0.008
val: 1 0.5093068480491638
val: 2 0.4984963834285736
val: 3 0.5033490061759949
val: 4 0.502543032169342
val: 5 0.5025306940078735
val: 6 0.49479833245277405
val: 7 0.49428367614746094
val: 8 0.5002313256263733
val: 9 0.49330657720565796
val: 10 0.5017649531364441
val: 11 0.4967097043991089
val: 12 0.49649733304977417
val: 13 0.503860592842102
val: 14 0.5044564604759216
val: 15 0.48861777782440186
val: 16 0.5043298006057739
val: 17 0.49848875403404236
val: 18 0.5136024355888367
val: 19 0.4950686991214752
val: 20 0.4948408603668213
val_Epoch:[ 15 ] val_loss: 0.4998541623353958 2022-07-01 08:39:35.306863
start training 2022-07-01 08:39:35.403507
Epoch:[ 16 0 ] loss: 0.49007272720336914 2022-07-01 08:39:50.158809
Epoch:[ 16 1 ] loss: 0.4892354905605316 2022-07-01 08:39:50.578427
Epoch:[ 16 2 ] loss: 0.48546233773231506 2022-07-01 08:39:50.995664
Epoch:[ 16 3 ] loss: 0.48674502968788147 2022-07-01 08:39:51.423149
Epoch:[ 16 4 ] loss: 0.49318718910217285 2022-07-01 08:39:51.841422
Epoch:[ 16 5 ] loss: 0.48513132333755493 2022-07-01 08:39:52.259692
Epoch:[ 16 6 ] loss: 0.4855646789073944 2022-07-01 08:39:52.685220
Epoch:[ 16 7 ] loss: 0.4878888726234436 2022-07-01 08:39:53.105219
Epoch:[ 16 8 ] loss: 0.4913189709186554 2022-07-01 08:39:53.524351
Epoch:[ 16 9 ] loss: 0.4869554042816162 2022-07-01 08:39:53.944145
Epoch:[ 16 10 ] loss: 0.4848185181617737 2022-07-01 08:39:54.363872
Epoch:[ 16 11 ] loss: 0.48475193977355957 2022-07-01 08:39:54.787510
Epoch:[ 16 12 ] loss: 0.48579922318458557 2022-07-01 08:39:55.205796
Epoch:[ 16 13 ] loss: 0.48679277300834656 2022-07-01 08:39:55.632462
Epoch:[ 16 14 ] loss: 0.48694902658462524 2022-07-01 08:39:56.057940
Epoch:[ 16 15 ] loss: 0.4879787862300873 2022-07-01 08:39:56.477470
Epoch:[ 16 16 ] loss: 0.4867599308490753 2022-07-01 08:40:02.220003
Epoch:[ 16 17 ] loss: 0.48932313919067383 2022-07-01 08:40:02.644630
Epoch:[ 16 18 ] loss: 0.48877739906311035 2022-07-01 08:40:03.074070
Epoch:[ 16 19 ] loss: 0.48713770508766174 2022-07-01 08:40:03.494344
Training_Epoch:[ 16 ] Training_loss: 0.4875325232744217 2022-07-01 08:40:03.495005
learning rate:  0.008
netparams have been saved once 16
val: 1 0.5196566581726074
val: 2 0.530381977558136
val: 3 0.5299431085586548
val: 4 0.5259880423545837
val: 5 0.5239148139953613
val: 6 0.5330498814582825
val: 7 0.522740364074707
val: 8 0.5339974761009216
val: 9 0.5357619524002075
val: 10 0.531213641166687
val: 11 0.5358164310455322
val: 12 0.5292884707450867
val: 13 0.5339245200157166
val: 14 0.527154803276062
val: 15 0.5288431644439697
val: 16 0.5266057848930359
val: 17 0.5287970304489136
val: 18 0.5223641991615295
val: 19 0.5415588617324829
val: 20 0.5248920917510986
val_Epoch:[ 16 ] val_loss: 0.5292946636676789 2022-07-01 08:40:07.165671
start training 2022-07-01 08:40:07.263894
Epoch:[ 17 0 ] loss: 0.48846128582954407 2022-07-01 08:40:21.218108
Epoch:[ 17 1 ] loss: 0.48449960350990295 2022-07-01 08:40:21.673893
Epoch:[ 17 2 ] loss: 0.4924829304218292 2022-07-01 08:40:22.120508
Epoch:[ 17 3 ] loss: 0.4869079887866974 2022-07-01 08:40:22.542015
Epoch:[ 17 4 ] loss: 0.48250168561935425 2022-07-01 08:40:22.963541
Epoch:[ 17 5 ] loss: 0.48767364025115967 2022-07-01 08:40:23.384335
Epoch:[ 17 6 ] loss: 0.4881746470928192 2022-07-01 08:40:23.805859
Epoch:[ 17 7 ] loss: 0.4871775507926941 2022-07-01 08:40:24.233461
Epoch:[ 17 8 ] loss: 0.4836694002151489 2022-07-01 08:40:24.654742
Epoch:[ 17 9 ] loss: 0.48296648263931274 2022-07-01 08:40:25.078716
Epoch:[ 17 10 ] loss: 0.48735347390174866 2022-07-01 08:40:25.504166
Epoch:[ 17 11 ] loss: 0.4853455722332001 2022-07-01 08:40:25.925699
Epoch:[ 17 12 ] loss: 0.47850465774536133 2022-07-01 08:40:26.353718
Epoch:[ 17 13 ] loss: 0.48620685935020447 2022-07-01 08:40:26.774576
Epoch:[ 17 14 ] loss: 0.4854629933834076 2022-07-01 08:40:27.201999
Epoch:[ 17 15 ] loss: 0.4805106818675995 2022-07-01 08:40:27.623842
Epoch:[ 17 16 ] loss: 0.4781779646873474 2022-07-01 08:40:33.263095
Epoch:[ 17 17 ] loss: 0.4852549731731415 2022-07-01 08:40:33.688742
Epoch:[ 17 18 ] loss: 0.4837959408760071 2022-07-01 08:40:34.115355
Epoch:[ 17 19 ] loss: 0.4801941514015198 2022-07-01 08:40:34.537096
Training_Epoch:[ 17 ] Training_loss: 0.48476612418889997 2022-07-01 08:40:34.537746
learning rate:  0.008
val: 1 0.49118903279304504
val: 2 0.48611098527908325
val: 3 0.4715123176574707
val: 4 0.48240983486175537
val: 5 0.49480709433555603
val: 6 0.4833148717880249
val: 7 0.497334361076355
val: 8 0.48426511883735657
val: 9 0.48882627487182617
val: 10 0.47643887996673584
val: 11 0.4848984181880951
val: 12 0.48566821217536926
val: 13 0.48694518208503723
val: 14 0.48116961121559143
val: 15 0.4844769537448883
val: 16 0.48714321851730347
val: 17 0.48905885219573975
val: 18 0.4852180480957031
val: 19 0.4825274646282196
val: 20 0.49582839012145996
val_Epoch:[ 17 ] val_loss: 0.4859571561217308 2022-07-01 08:40:38.174095
start training 2022-07-01 08:40:38.272305
Epoch:[ 18 0 ] loss: 0.47713932394981384 2022-07-01 08:40:52.204440
Epoch:[ 18 1 ] loss: 0.4765351712703705 2022-07-01 08:40:53.143606
Epoch:[ 18 2 ] loss: 0.48266080021858215 2022-07-01 08:40:53.571536
Epoch:[ 18 3 ] loss: 0.47932255268096924 2022-07-01 08:40:54.000244
Epoch:[ 18 4 ] loss: 0.48224273324012756 2022-07-01 08:40:54.431973
Epoch:[ 18 5 ] loss: 0.48263511061668396 2022-07-01 08:40:54.858803
Epoch:[ 18 6 ] loss: 0.4732353687286377 2022-07-01 08:40:55.285644
Epoch:[ 18 7 ] loss: 0.47313156723976135 2022-07-01 08:40:55.712485
Epoch:[ 18 8 ] loss: 0.4779362380504608 2022-07-01 08:40:56.147972
Epoch:[ 18 9 ] loss: 0.47909343242645264 2022-07-01 08:40:56.578325
Epoch:[ 18 10 ] loss: 0.47674140334129333 2022-07-01 08:40:57.011839
Epoch:[ 18 11 ] loss: 0.4857191741466522 2022-07-01 08:40:57.437747
Epoch:[ 18 12 ] loss: 0.48018550872802734 2022-07-01 08:40:57.873368
Epoch:[ 18 13 ] loss: 0.47843411564826965 2022-07-01 08:40:58.302084
Epoch:[ 18 14 ] loss: 0.4813937246799469 2022-07-01 08:40:58.728755
Epoch:[ 18 15 ] loss: 0.47570812702178955 2022-07-01 08:40:59.165305
Epoch:[ 18 16 ] loss: 0.4825926125049591 2022-07-01 08:41:03.997645
Epoch:[ 18 17 ] loss: 0.4807862341403961 2022-07-01 08:41:04.446231
Epoch:[ 18 18 ] loss: 0.4808498024940491 2022-07-01 08:41:04.877802
Epoch:[ 18 19 ] loss: 0.47727763652801514 2022-07-01 08:41:05.305681
Training_Epoch:[ 18 ] Training_loss: 0.4791810318827629 2022-07-01 08:41:05.306322
learning rate:  0.008
netparams have been saved once 18
val: 1 0.4932008981704712
val: 2 0.4850603938102722
val: 3 0.48676568269729614
val: 4 0.47732213139533997
val: 5 0.48773306608200073
val: 6 0.48458433151245117
val: 7 0.501187801361084
val: 8 0.4857986867427826
val: 9 0.48322078585624695
val: 10 0.4900534749031067
val: 11 0.48683464527130127
val: 12 0.4838895797729492
val: 13 0.4743337333202362
val: 14 0.48626047372817993
val: 15 0.4812759757041931
val: 16 0.47790610790252686
val: 17 0.4800395369529724
val: 18 0.4868280589580536
val: 19 0.4835126996040344
val: 20 0.48204436898231506
val_Epoch:[ 18 ] val_loss: 0.4848926216363907 2022-07-01 08:41:09.031358
start training 2022-07-01 08:41:09.133446
Epoch:[ 19 0 ] loss: 0.4773294925689697 2022-07-01 08:41:23.059962
Epoch:[ 19 1 ] loss: 0.4769362807273865 2022-07-01 08:41:23.820491
Epoch:[ 19 2 ] loss: 0.4796811044216156 2022-07-01 08:41:24.254819
Epoch:[ 19 3 ] loss: 0.47649070620536804 2022-07-01 08:41:24.683755
Epoch:[ 19 4 ] loss: 0.4824361801147461 2022-07-01 08:41:25.112688
Epoch:[ 19 5 ] loss: 0.4823336601257324 2022-07-01 08:41:25.541304
Epoch:[ 19 6 ] loss: 0.4797970652580261 2022-07-01 08:41:25.969318
Epoch:[ 19 7 ] loss: 0.47919559478759766 2022-07-01 08:41:26.396423
Epoch:[ 19 8 ] loss: 0.47806304693222046 2022-07-01 08:41:26.824065
Epoch:[ 19 9 ] loss: 0.4764421284198761 2022-07-01 08:41:27.259615
Epoch:[ 19 10 ] loss: 0.4779050350189209 2022-07-01 08:41:27.694857
Epoch:[ 19 11 ] loss: 0.4782741963863373 2022-07-01 08:41:28.125030
Epoch:[ 19 12 ] loss: 0.47832995653152466 2022-07-01 08:41:28.558673
Epoch:[ 19 13 ] loss: 0.4736996293067932 2022-07-01 08:41:28.992397
Epoch:[ 19 14 ] loss: 0.4745807349681854 2022-07-01 08:41:29.424959
Epoch:[ 19 15 ] loss: 0.4764777719974518 2022-07-01 08:41:29.851635
Epoch:[ 19 16 ] loss: 0.47499120235443115 2022-07-01 08:41:34.953271
Epoch:[ 19 17 ] loss: 0.47230464220046997 2022-07-01 08:41:35.454265
Epoch:[ 19 18 ] loss: 0.4746740758419037 2022-07-01 08:41:35.902952
Epoch:[ 19 19 ] loss: 0.4745822548866272 2022-07-01 08:41:36.331999
Training_Epoch:[ 19 ] Training_loss: 0.4772262379527092 2022-07-01 08:41:36.332689
learning rate:  0.008
val: 1 0.497437983751297
val: 2 0.49757206439971924
val: 3 0.5068174004554749
val: 4 0.5048647522926331
val: 5 0.4983496069908142
val: 6 0.4998151659965515
val: 7 0.49204835295677185
val: 8 0.497234970331192
val: 9 0.513322651386261
val: 10 0.5038709044456482
val: 11 0.5116876363754272
val: 12 0.5097243785858154
val: 13 0.4893469512462616
val: 14 0.4969077408313751
val: 15 0.5058397054672241
val: 16 0.49438193440437317
val: 17 0.5024517178535461
val: 18 0.5008000135421753
val: 19 0.4978759288787842
val: 20 0.5011169910430908
val_Epoch:[ 19 ] val_loss: 0.5010733425617218 2022-07-01 08:41:39.961279
start training 2022-07-01 08:41:40.063358
Epoch:[ 20 0 ] loss: 0.47283828258514404 2022-07-01 08:41:55.004705
Epoch:[ 20 1 ] loss: 0.4759758412837982 2022-07-01 08:41:55.436758
Epoch:[ 20 2 ] loss: 0.47799864411354065 2022-07-01 08:41:55.868811
Epoch:[ 20 3 ] loss: 0.4747260510921478 2022-07-01 08:41:56.298142
Epoch:[ 20 4 ] loss: 0.47767871618270874 2022-07-01 08:41:56.732866
Epoch:[ 20 5 ] loss: 0.4766775071620941 2022-07-01 08:41:57.162482
Epoch:[ 20 6 ] loss: 0.4835951626300812 2022-07-01 08:41:57.588967
Epoch:[ 20 7 ] loss: 0.4754807949066162 2022-07-01 08:41:58.018308
Epoch:[ 20 8 ] loss: 0.4729677140712738 2022-07-01 08:41:58.450728
Epoch:[ 20 9 ] loss: 0.47314831614494324 2022-07-01 08:41:58.879864
Epoch:[ 20 10 ] loss: 0.4728533625602722 2022-07-01 08:41:59.309935
Epoch:[ 20 11 ] loss: 0.47295841574668884 2022-07-01 08:41:59.738678
Epoch:[ 20 12 ] loss: 0.47403696179389954 2022-07-01 08:42:00.173876
Epoch:[ 20 13 ] loss: 0.47651851177215576 2022-07-01 08:42:00.603404
Epoch:[ 20 14 ] loss: 0.47364234924316406 2022-07-01 08:42:01.031385
Epoch:[ 20 15 ] loss: 0.4729466140270233 2022-07-01 08:42:01.464142
Epoch:[ 20 16 ] loss: 0.47231435775756836 2022-07-01 08:42:06.175492
Epoch:[ 20 17 ] loss: 0.47221657633781433 2022-07-01 08:42:06.603156
Epoch:[ 20 18 ] loss: 0.47368237376213074 2022-07-01 08:42:07.040595
Epoch:[ 20 19 ] loss: 0.4706209897994995 2022-07-01 08:42:07.469265
Training_Epoch:[ 20 ] Training_loss: 0.4746438771486282 2022-07-01 08:42:07.469858
learning rate:  0.008
netparams have been saved once 20
val: 1 0.47872042655944824
val: 2 0.47827911376953125
val: 3 0.47564607858657837
val: 4 0.4618150293827057
val: 5 0.4832145571708679
val: 6 0.4840324819087982
val: 7 0.4729224443435669
val: 8 0.47692400217056274
val: 9 0.49095892906188965
val: 10 0.4881170988082886
val: 11 0.4776822328567505
val: 12 0.46397483348846436
val: 13 0.48878955841064453
val: 14 0.4726060926914215
val: 15 0.4714815616607666
val: 16 0.4787379205226898
val: 17 0.4769074022769928
val: 18 0.4802889823913574
val: 19 0.4679121971130371
val: 20 0.4821913540363312
val_Epoch:[ 20 ] val_loss: 0.4775601148605347 2022-07-01 08:42:11.097219
start training 2022-07-01 08:42:11.194939
Epoch:[ 21 0 ] loss: 0.47047552466392517 2022-07-01 08:42:26.213723
Epoch:[ 21 1 ] loss: 0.4692801237106323 2022-07-01 08:42:26.643432
Epoch:[ 21 2 ] loss: 0.4689619243144989 2022-07-01 08:42:27.071351
Epoch:[ 21 3 ] loss: 0.4710388779640198 2022-07-01 08:42:27.506553
Epoch:[ 21 4 ] loss: 0.4720289409160614 2022-07-01 08:42:27.940231
Epoch:[ 21 5 ] loss: 0.464145302772522 2022-07-01 08:42:28.370226
Epoch:[ 21 6 ] loss: 0.46876290440559387 2022-07-01 08:42:28.801399
Epoch:[ 21 7 ] loss: 0.46869856119155884 2022-07-01 08:42:29.234385
Epoch:[ 21 8 ] loss: 0.46900486946105957 2022-07-01 08:42:29.670521
Epoch:[ 21 9 ] loss: 0.4707914888858795 2022-07-01 08:42:30.103304
Epoch:[ 21 10 ] loss: 0.47156473994255066 2022-07-01 08:42:30.530809
Epoch:[ 21 11 ] loss: 0.4695497751235962 2022-07-01 08:42:30.961164
Epoch:[ 21 12 ] loss: 0.4679841697216034 2022-07-01 08:42:31.400860
Epoch:[ 21 13 ] loss: 0.46658238768577576 2022-07-01 08:42:31.831508
Epoch:[ 21 14 ] loss: 0.47555145621299744 2022-07-01 08:42:32.264270
Epoch:[ 21 15 ] loss: 0.4664325714111328 2022-07-01 08:42:32.693337
Epoch:[ 21 16 ] loss: 0.47168368101119995 2022-07-01 08:42:38.171484
Epoch:[ 21 17 ] loss: 0.4661445617675781 2022-07-01 08:42:38.597436
Epoch:[ 21 18 ] loss: 0.4700363278388977 2022-07-01 08:42:39.035693
Epoch:[ 21 19 ] loss: 0.4653571546077728 2022-07-01 08:42:39.464778
Training_Epoch:[ 21 ] Training_loss: 0.4692037671804428 2022-07-01 08:42:39.465467
learning rate:  0.0064
val: 1 0.47081446647644043
val: 2 0.4826059341430664
val: 3 0.47928333282470703
val: 4 0.4689651429653168
val: 5 0.47217413783073425
val: 6 0.461068332195282
val: 7 0.4797655940055847
val: 8 0.47313547134399414
val: 9 0.47182130813598633
val: 10 0.4676414728164673
val: 11 0.4730556607246399
val: 12 0.46941372752189636
val: 13 0.46886128187179565
val: 14 0.4701731204986572
val: 15 0.4659844934940338
val: 16 0.47322309017181396
val: 17 0.4636094272136688
val: 18 0.48015090823173523
val: 19 0.4761793315410614
val: 20 0.4706028699874878
val_Epoch:[ 21 ] val_loss: 0.4719264551997185 2022-07-01 08:42:43.156798
start training 2022-07-01 08:42:43.258295
Epoch:[ 22 0 ] loss: 0.4630681872367859 2022-07-01 08:42:57.776052
Epoch:[ 22 1 ] loss: 0.46248874068260193 2022-07-01 08:42:58.205442
Epoch:[ 22 2 ] loss: 0.463726669549942 2022-07-01 08:42:58.633152
Epoch:[ 22 3 ] loss: 0.46230560541152954 2022-07-01 08:42:59.067620
Epoch:[ 22 4 ] loss: 0.46576741337776184 2022-07-01 08:42:59.496157
Epoch:[ 22 5 ] loss: 0.4677099287509918 2022-07-01 08:42:59.925100
Epoch:[ 22 6 ] loss: 0.4687529504299164 2022-07-01 08:43:00.360677
Epoch:[ 22 7 ] loss: 0.4667779505252838 2022-07-01 08:43:00.788713
Epoch:[ 22 8 ] loss: 0.4663158655166626 2022-07-01 08:43:01.224524
Epoch:[ 22 9 ] loss: 0.4691738784313202 2022-07-01 08:43:01.653000
Epoch:[ 22 10 ] loss: 0.4699177145957947 2022-07-01 08:43:02.085493
Epoch:[ 22 11 ] loss: 0.465277761220932 2022-07-01 08:43:02.512533
Epoch:[ 22 12 ] loss: 0.4644494354724884 2022-07-01 08:43:02.946315
Epoch:[ 22 13 ] loss: 0.4678720235824585 2022-07-01 08:43:03.377119
Epoch:[ 22 14 ] loss: 0.46620744466781616 2022-07-01 08:43:03.811036
Epoch:[ 22 15 ] loss: 0.46657678484916687 2022-07-01 08:43:04.239843
Epoch:[ 22 16 ] loss: 0.46279680728912354 2022-07-01 08:43:09.651996
Epoch:[ 22 17 ] loss: 0.4635757803916931 2022-07-01 08:43:10.083670
Epoch:[ 22 18 ] loss: 0.46493732929229736 2022-07-01 08:43:10.514268
Epoch:[ 22 19 ] loss: 0.46581998467445374 2022-07-01 08:43:10.942726
Training_Epoch:[ 22 ] Training_loss: 0.465675912797451 2022-07-01 08:43:10.943385
learning rate:  0.0064
netparams have been saved once 22
val: 1 0.4860057830810547
val: 2 0.4786134958267212
val: 3 0.49017077684402466
val: 4 0.49185821413993835
val: 5 0.4789260923862457
val: 6 0.48240503668785095
val: 7 0.47631192207336426
val: 8 0.47810623049736023
val: 9 0.47806572914123535
val: 10 0.4775119721889496
val: 11 0.46860235929489136
val: 12 0.4794577658176422
val: 13 0.48357096314430237
val: 14 0.4904818832874298
val: 15 0.4814845025539398
val: 16 0.4789847135543823
val: 17 0.4789859354496002
val: 18 0.47004035115242004
val: 19 0.47243431210517883
val: 20 0.47229084372520447
val_Epoch:[ 22 ] val_loss: 0.4797154441475868 2022-07-01 08:43:14.612959
start training 2022-07-01 08:43:14.709490
Epoch:[ 23 0 ] loss: 0.46144217252731323 2022-07-01 08:43:29.181590
Epoch:[ 23 1 ] loss: 0.46411702036857605 2022-07-01 08:43:29.628578
Epoch:[ 23 2 ] loss: 0.45971307158470154 2022-07-01 08:43:30.058068
Epoch:[ 23 3 ] loss: 0.4583899974822998 2022-07-01 08:43:30.490622
Epoch:[ 23 4 ] loss: 0.4651238024234772 2022-07-01 08:43:30.923574
Epoch:[ 23 5 ] loss: 0.4632793664932251 2022-07-01 08:43:31.351343
Epoch:[ 23 6 ] loss: 0.46427562832832336 2022-07-01 08:43:31.782121
Epoch:[ 23 7 ] loss: 0.4619651436805725 2022-07-01 08:43:32.217912
Epoch:[ 23 8 ] loss: 0.4648422598838806 2022-07-01 08:43:32.648648
Epoch:[ 23 9 ] loss: 0.4654649496078491 2022-07-01 08:43:33.075973
Epoch:[ 23 10 ] loss: 0.4628574252128601 2022-07-01 08:43:33.503780
Epoch:[ 23 11 ] loss: 0.46629488468170166 2022-07-01 08:43:33.936120
Epoch:[ 23 12 ] loss: 0.46127238869667053 2022-07-01 08:43:34.363241
Epoch:[ 23 13 ] loss: 0.4625697433948517 2022-07-01 08:43:34.793445
Epoch:[ 23 14 ] loss: 0.459665447473526 2022-07-01 08:43:35.228830
Epoch:[ 23 15 ] loss: 0.4622513949871063 2022-07-01 08:43:35.663950
Epoch:[ 23 16 ] loss: 0.4671335220336914 2022-07-01 08:43:40.466419
Epoch:[ 23 17 ] loss: 0.4667004644870758 2022-07-01 08:43:41.116837
Epoch:[ 23 18 ] loss: 0.46814867854118347 2022-07-01 08:43:41.558836
Epoch:[ 23 19 ] loss: 0.4605742394924164 2022-07-01 08:43:41.990897
Training_Epoch:[ 23 ] Training_loss: 0.4633040800690651 2022-07-01 08:43:41.991588
learning rate:  0.0064
val: 1 0.46475765109062195
val: 2 0.47248461842536926
val: 3 0.47053301334381104
val: 4 0.479053258895874
val: 5 0.4653521478176117
val: 6 0.47308096289634705
val: 7 0.464622437953949
val: 8 0.4644198715686798
val: 9 0.47381389141082764
val: 10 0.468144953250885
val: 11 0.4754911959171295
val: 12 0.4622765779495239
val: 13 0.47579246759414673
val: 14 0.473733514547348
val: 15 0.46631553769111633
val: 16 0.4727579355239868
val: 17 0.4690083861351013
val: 18 0.4780924320220947
val: 19 0.4659896790981293
val: 20 0.46374914050102234
val_Epoch:[ 23 ] val_loss: 0.4699734836816788 2022-07-01 08:43:45.612815
start training 2022-07-01 08:43:45.707675
Epoch:[ 24 0 ] loss: 0.4636431932449341 2022-07-01 08:43:59.904416
Epoch:[ 24 1 ] loss: 0.4596841037273407 2022-07-01 08:44:00.352424
Epoch:[ 24 2 ] loss: 0.45886528491973877 2022-07-01 08:44:00.783383
Epoch:[ 24 3 ] loss: 0.46441397070884705 2022-07-01 08:44:01.217288
Epoch:[ 24 4 ] loss: 0.4616125226020813 2022-07-01 08:44:01.646174
Epoch:[ 24 5 ] loss: 0.4602305293083191 2022-07-01 08:44:02.080062
Epoch:[ 24 6 ] loss: 0.45624297857284546 2022-07-01 08:44:02.512500
Epoch:[ 24 7 ] loss: 0.4654218852519989 2022-07-01 08:44:02.947508
Epoch:[ 24 8 ] loss: 0.465252548456192 2022-07-01 08:44:03.376633
Epoch:[ 24 9 ] loss: 0.4683685898780823 2022-07-01 08:44:03.807364
Epoch:[ 24 10 ] loss: 0.4627384543418884 2022-07-01 08:44:04.235218
Epoch:[ 24 11 ] loss: 0.4778432846069336 2022-07-01 08:44:04.663877
Epoch:[ 24 12 ] loss: 0.46230965852737427 2022-07-01 08:44:05.093426
Epoch:[ 24 13 ] loss: 0.4663330018520355 2022-07-01 08:44:05.526017
Epoch:[ 24 14 ] loss: 0.47078073024749756 2022-07-01 08:44:05.961016
Epoch:[ 24 15 ] loss: 0.46725940704345703 2022-07-01 08:44:06.391849
Epoch:[ 24 16 ] loss: 0.4678323566913605 2022-07-01 08:44:11.789551
Epoch:[ 24 17 ] loss: 0.4666925370693207 2022-07-01 08:44:12.216451
Epoch:[ 24 18 ] loss: 0.4631412625312805 2022-07-01 08:44:12.648210
Epoch:[ 24 19 ] loss: 0.4614710807800293 2022-07-01 08:44:13.076346
Training_Epoch:[ 24 ] Training_loss: 0.46450686901807786 2022-07-01 08:44:13.076966
learning rate:  0.0064
netparams have been saved once 24
val: 1 0.47464317083358765
val: 2 0.4729348123073578
val: 3 0.4756370484828949
val: 4 0.47121039032936096
val: 5 0.47742557525634766
val: 6 0.4640156626701355
val: 7 0.47036126255989075
val: 8 0.4722999036312103
val: 9 0.47045964002609253
val: 10 0.4744702875614166
val: 11 0.4702383577823639
val: 12 0.47729620337486267
val: 13 0.4758983552455902
val: 14 0.47100815176963806
val: 15 0.47431719303131104
val: 16 0.4734751880168915
val: 17 0.4665720462799072
val: 18 0.481046587228775
val: 19 0.47301772236824036
val: 20 0.4698861241340637
val_Epoch:[ 24 ] val_loss: 0.4728106841444969 2022-07-01 08:44:16.855154
start training 2022-07-01 08:44:16.958531
Epoch:[ 25 0 ] loss: 0.46110865473747253 2022-07-01 08:44:31.680781
Epoch:[ 25 1 ] loss: 0.4623611569404602 2022-07-01 08:44:32.115646
Epoch:[ 25 2 ] loss: 0.45633792877197266 2022-07-01 08:44:32.550317
Epoch:[ 25 3 ] loss: 0.4594271779060364 2022-07-01 08:44:32.965624
Epoch:[ 25 4 ] loss: 0.45816317200660706 2022-07-01 08:44:33.380850
Epoch:[ 25 5 ] loss: 0.458416610956192 2022-07-01 08:44:33.794516
Epoch:[ 25 6 ] loss: 0.460371732711792 2022-07-01 08:44:34.204409
Epoch:[ 25 7 ] loss: 0.45982620120048523 2022-07-01 08:44:34.618565
Epoch:[ 25 8 ] loss: 0.4563175141811371 2022-07-01 08:44:35.035170
Epoch:[ 25 9 ] loss: 0.45860618352890015 2022-07-01 08:44:35.447591
Epoch:[ 25 10 ] loss: 0.46118754148483276 2022-07-01 08:44:35.865656
Epoch:[ 25 11 ] loss: 0.4610474109649658 2022-07-01 08:44:36.279590
Epoch:[ 25 12 ] loss: 0.45934924483299255 2022-07-01 08:44:36.689512
Epoch:[ 25 13 ] loss: 0.4587239921092987 2022-07-01 08:44:37.099482
Epoch:[ 25 14 ] loss: 0.45692524313926697 2022-07-01 08:44:37.511951
Epoch:[ 25 15 ] loss: 0.45232030749320984 2022-07-01 08:44:37.928167
Epoch:[ 25 16 ] loss: 0.4599497318267822 2022-07-01 08:44:43.273912
Epoch:[ 25 17 ] loss: 0.4564233422279358 2022-07-01 08:44:43.689501
Epoch:[ 25 18 ] loss: 0.45884305238723755 2022-07-01 08:44:44.127763
Epoch:[ 25 19 ] loss: 0.4580437242984772 2022-07-01 08:44:44.561144
Training_Epoch:[ 25 ] Training_loss: 0.45868749618530275 2022-07-01 08:44:44.561956
learning rate:  0.0064
val: 1 0.4746614396572113
val: 2 0.4669450521469116
val: 3 0.476053386926651
val: 4 0.47428539395332336
val: 5 0.4814426004886627
val: 6 0.4637809693813324
val: 7 0.4823966324329376
val: 8 0.4776417315006256
val: 9 0.46760520339012146
val: 10 0.4760690927505493
val: 11 0.4766102731227875
val: 12 0.4678001403808594
val: 13 0.4747363328933716
val: 14 0.46694624423980713
val: 15 0.4673786461353302
val: 16 0.47687482833862305
val: 17 0.47613799571990967
val: 18 0.4781618118286133
val: 19 0.4724874198436737
val: 20 0.473267138004303
val_Epoch:[ 25 ] val_loss: 0.4735641166567802 2022-07-01 08:44:48.223499
start training 2022-07-01 08:44:48.321312
Epoch:[ 26 0 ] loss: 0.46293166279792786 2022-07-01 08:45:02.307919
Epoch:[ 26 1 ] loss: 0.4598503112792969 2022-07-01 08:45:03.301059
Epoch:[ 26 2 ] loss: 0.45665740966796875 2022-07-01 08:45:03.729893
Epoch:[ 26 3 ] loss: 0.455049604177475 2022-07-01 08:45:04.164221
Epoch:[ 26 4 ] loss: 0.4574594497680664 2022-07-01 08:45:04.592290
Epoch:[ 26 5 ] loss: 0.45624226331710815 2022-07-01 08:45:05.020706
Epoch:[ 26 6 ] loss: 0.4573221206665039 2022-07-01 08:45:05.446287
Epoch:[ 26 7 ] loss: 0.4553861618041992 2022-07-01 08:45:05.875660
Epoch:[ 26 8 ] loss: 0.45594003796577454 2022-07-01 08:45:06.302879
Epoch:[ 26 9 ] loss: 0.4578121304512024 2022-07-01 08:45:06.731106
Epoch:[ 26 10 ] loss: 0.4564765691757202 2022-07-01 08:45:07.164034
Epoch:[ 26 11 ] loss: 0.4535304605960846 2022-07-01 08:45:07.595832
Epoch:[ 26 12 ] loss: 0.45519986748695374 2022-07-01 08:45:08.027232
Epoch:[ 26 13 ] loss: 0.45383694767951965 2022-07-01 08:45:08.456430
Epoch:[ 26 14 ] loss: 0.45636284351348877 2022-07-01 08:45:08.884545
Epoch:[ 26 15 ] loss: 0.46090465784072876 2022-07-01 08:45:09.316766
Epoch:[ 26 16 ] loss: 0.45979613065719604 2022-07-01 08:45:13.903750
Epoch:[ 26 17 ] loss: 0.4560953378677368 2022-07-01 08:45:14.602054
Epoch:[ 26 18 ] loss: 0.46164149045944214 2022-07-01 08:45:15.043258
Epoch:[ 26 19 ] loss: 0.45960092544555664 2022-07-01 08:45:15.473883
Training_Epoch:[ 26 ] Training_loss: 0.45740481913089753 2022-07-01 08:45:15.474562
learning rate:  0.0064
netparams have been saved once 26
val: 1 0.5140628218650818
val: 2 0.5016940236091614
val: 3 0.4947843849658966
val: 4 0.5231512784957886
val: 5 0.502163290977478
val: 6 0.4918765425682068
val: 7 0.4913698434829712
val: 8 0.5097547173500061
val: 9 0.5064043998718262
val: 10 0.5092890858650208
val: 11 0.5047470927238464
val: 12 0.5050362944602966
val: 13 0.5111938118934631
val: 14 0.522828996181488
val: 15 0.5074262022972107
val: 16 0.5000465512275696
val: 17 0.5013973712921143
val: 18 0.5081455111503601
val: 19 0.5073307156562805
val: 20 0.5202052593231201
val_Epoch:[ 26 ] val_loss: 0.5066454097628593 2022-07-01 08:45:19.062525
start training 2022-07-01 08:45:19.164289
Epoch:[ 27 0 ] loss: 0.45918333530426025 2022-07-01 08:45:33.776846
Epoch:[ 27 1 ] loss: 0.4621785581111908 2022-07-01 08:45:34.208899
Epoch:[ 27 2 ] loss: 0.4538441300392151 2022-07-01 08:45:34.641711
Epoch:[ 27 3 ] loss: 0.460105299949646 2022-07-01 08:45:35.071784
Epoch:[ 27 4 ] loss: 0.45595791935920715 2022-07-01 08:45:35.505928
Epoch:[ 27 5 ] loss: 0.45940884947776794 2022-07-01 08:45:35.932924
Epoch:[ 27 6 ] loss: 0.45847684144973755 2022-07-01 08:45:36.364362
Epoch:[ 27 7 ] loss: 0.45372140407562256 2022-07-01 08:45:36.792541
Epoch:[ 27 8 ] loss: 0.45955950021743774 2022-07-01 08:45:37.219591
Epoch:[ 27 9 ] loss: 0.45610859990119934 2022-07-01 08:45:37.647383
Epoch:[ 27 10 ] loss: 0.45829084515571594 2022-07-01 08:45:38.075847
Epoch:[ 27 11 ] loss: 0.4564478397369385 2022-07-01 08:45:38.510009
Epoch:[ 27 12 ] loss: 0.4540173411369324 2022-07-01 08:45:38.945827
Epoch:[ 27 13 ] loss: 0.45367345213890076 2022-07-01 08:45:39.373440
Epoch:[ 27 14 ] loss: 0.4581637978553772 2022-07-01 08:45:39.800551
Epoch:[ 27 15 ] loss: 0.45652657747268677 2022-07-01 08:45:40.230526
Epoch:[ 27 16 ] loss: 0.45024171471595764 2022-07-01 08:45:45.516722
Epoch:[ 27 17 ] loss: 0.4591774344444275 2022-07-01 08:45:45.956254
Epoch:[ 27 18 ] loss: 0.4588962495326996 2022-07-01 08:45:46.389426
Epoch:[ 27 19 ] loss: 0.4568968117237091 2022-07-01 08:45:46.820091
Training_Epoch:[ 27 ] Training_loss: 0.45704382508993147 2022-07-01 08:45:46.820764
learning rate:  0.0064
val: 1 0.46501287817955017
val: 2 0.4690997302532196
val: 3 0.479961097240448
val: 4 0.47574862837791443
val: 5 0.4698587954044342
val: 6 0.4781339466571808
val: 7 0.4666254222393036
val: 8 0.4657842814922333
val: 9 0.47553324699401855
val: 10 0.46237578988075256
val: 11 0.4727749824523926
val: 12 0.45594140887260437
val: 13 0.4691583216190338
val: 14 0.4662747085094452
val: 15 0.470692902803421
val: 16 0.4750303030014038
val: 17 0.4696407914161682
val: 18 0.47895318269729614
val: 19 0.4833638370037079
val: 20 0.4811558425426483
val_Epoch:[ 27 ] val_loss: 0.47155600488185884 2022-07-01 08:45:50.478957
start training 2022-07-01 08:45:50.575367
Epoch:[ 28 0 ] loss: 0.45528334379196167 2022-07-01 08:46:04.916843
Epoch:[ 28 1 ] loss: 0.45595502853393555 2022-07-01 08:46:05.462910
Epoch:[ 28 2 ] loss: 0.4548155963420868 2022-07-01 08:46:05.895662
Epoch:[ 28 3 ] loss: 0.45382750034332275 2022-07-01 08:46:06.328024
Epoch:[ 28 4 ] loss: 0.45374202728271484 2022-07-01 08:46:06.758383
Epoch:[ 28 5 ] loss: 0.45473331212997437 2022-07-01 08:46:07.189984
Epoch:[ 28 6 ] loss: 0.4546780288219452 2022-07-01 08:46:07.617371
Epoch:[ 28 7 ] loss: 0.45212167501449585 2022-07-01 08:46:08.044147
Epoch:[ 28 8 ] loss: 0.4557594656944275 2022-07-01 08:46:08.473129
Epoch:[ 28 9 ] loss: 0.45574110746383667 2022-07-01 08:46:08.906119
Epoch:[ 28 10 ] loss: 0.44832056760787964 2022-07-01 08:46:09.338804
Epoch:[ 28 11 ] loss: 0.45057594776153564 2022-07-01 08:46:09.769279
Epoch:[ 28 12 ] loss: 0.4472682476043701 2022-07-01 08:46:10.198932
Epoch:[ 28 13 ] loss: 0.4533401131629944 2022-07-01 08:46:10.634848
Epoch:[ 28 14 ] loss: 0.4519246518611908 2022-07-01 08:46:11.068466
Epoch:[ 28 15 ] loss: 0.45382755994796753 2022-07-01 08:46:11.500079
Epoch:[ 28 16 ] loss: 0.45326897501945496 2022-07-01 08:46:16.139078
Epoch:[ 28 17 ] loss: 0.4530918300151825 2022-07-01 08:46:16.683765
Epoch:[ 28 18 ] loss: 0.4526727497577667 2022-07-01 08:46:17.118657
Epoch:[ 28 19 ] loss: 0.4560239017009735 2022-07-01 08:46:17.547213
Training_Epoch:[ 28 ] Training_loss: 0.45334858149290086 2022-07-01 08:46:17.547826
learning rate:  0.0064
netparams have been saved once 28
val: 1 0.4786067008972168
val: 2 0.47591325640678406
val: 3 0.4802444577217102
val: 4 0.48825448751449585
val: 5 0.462111234664917
val: 6 0.4675824046134949
val: 7 0.47535812854766846
val: 8 0.47769367694854736
val: 9 0.47329819202423096
val: 10 0.4781421422958374
val: 11 0.4743545353412628
val: 12 0.4712658226490021
val: 13 0.46577343344688416
val: 14 0.4669033885002136
val: 15 0.4584609866142273
val: 16 0.4692302346229553
val: 17 0.47480082511901855
val: 18 0.46078526973724365
val: 19 0.4722660481929779
val: 20 0.4681329131126404
val_Epoch:[ 28 ] val_loss: 0.47195890694856646 2022-07-01 08:46:21.313159
start training 2022-07-01 08:46:21.410116
Epoch:[ 29 0 ] loss: 0.44942399859428406 2022-07-01 08:46:35.947801
Epoch:[ 29 1 ] loss: 0.4502491056919098 2022-07-01 08:46:36.381962
Epoch:[ 29 2 ] loss: 0.4515044689178467 2022-07-01 08:46:36.809981
Epoch:[ 29 3 ] loss: 0.45213815569877625 2022-07-01 08:46:37.243683
Epoch:[ 29 4 ] loss: 0.4507382810115814 2022-07-01 08:46:37.676270
Epoch:[ 29 5 ] loss: 0.45108452439308167 2022-07-01 08:46:38.112340
Epoch:[ 29 6 ] loss: 0.45043981075286865 2022-07-01 08:46:38.541923
Epoch:[ 29 7 ] loss: 0.4504438638687134 2022-07-01 08:46:38.975895
Epoch:[ 29 8 ] loss: 0.457870215177536 2022-07-01 08:46:39.403344
Epoch:[ 29 9 ] loss: 0.45367759466171265 2022-07-01 08:46:39.833034
Epoch:[ 29 10 ] loss: 0.4529706835746765 2022-07-01 08:46:40.262008
Epoch:[ 29 11 ] loss: 0.4549771249294281 2022-07-01 08:46:40.689228
Epoch:[ 29 12 ] loss: 0.45619407296180725 2022-07-01 08:46:41.124476
Epoch:[ 29 13 ] loss: 0.4545057415962219 2022-07-01 08:46:41.554115
Epoch:[ 29 14 ] loss: 0.4519613981246948 2022-07-01 08:46:41.981854
Epoch:[ 29 15 ] loss: 0.45717012882232666 2022-07-01 08:46:42.409028
Epoch:[ 29 16 ] loss: 0.45453065633773804 2022-07-01 08:46:47.420154
Epoch:[ 29 17 ] loss: 0.4524003565311432 2022-07-01 08:46:47.846681
Epoch:[ 29 18 ] loss: 0.45286962389945984 2022-07-01 08:46:48.276886
Epoch:[ 29 19 ] loss: 0.4518207907676697 2022-07-01 08:46:48.689114
Training_Epoch:[ 29 ] Training_loss: 0.4528485298156738 2022-07-01 08:46:48.689852
learning rate:  0.0064
val: 1 0.47184228897094727
val: 2 0.4670351445674896
val: 3 0.47141504287719727
val: 4 0.464079886674881
val: 5 0.46551597118377686
val: 6 0.4693717062473297
val: 7 0.47095197439193726
val: 8 0.46649664640426636
val: 9 0.4736957252025604
val: 10 0.4587485194206238
val: 11 0.46857765316963196
val: 12 0.47873860597610474
val: 13 0.46366894245147705
val: 14 0.4606996178627014
val: 15 0.4721735119819641
val: 16 0.4685256779193878
val: 17 0.47322753071784973
val: 18 0.4747041165828705
val: 19 0.4564441442489624
val: 20 0.4572773277759552
val_Epoch:[ 29 ] val_loss: 0.4676595017313957 2022-07-01 08:46:52.336410
start training 2022-07-01 08:46:52.434096
Epoch:[ 30 0 ] loss: 0.4525683522224426 2022-07-01 08:47:06.412532
Epoch:[ 30 1 ] loss: 0.45692840218544006 2022-07-01 08:47:07.283599
Epoch:[ 30 2 ] loss: 0.4512691795825958 2022-07-01 08:47:07.715623
Epoch:[ 30 3 ] loss: 0.45095252990722656 2022-07-01 08:47:08.142770
Epoch:[ 30 4 ] loss: 0.45161306858062744 2022-07-01 08:47:08.569663
Epoch:[ 30 5 ] loss: 0.4572484493255615 2022-07-01 08:47:08.996833
Epoch:[ 30 6 ] loss: 0.4527519643306732 2022-07-01 08:47:09.430343
Epoch:[ 30 7 ] loss: 0.4521504044532776 2022-07-01 08:47:09.859237
Epoch:[ 30 8 ] loss: 0.45099955797195435 2022-07-01 08:47:10.288037
Epoch:[ 30 9 ] loss: 0.455276221036911 2022-07-01 08:47:10.716540
Epoch:[ 30 10 ] loss: 0.45972126722335815 2022-07-01 08:47:11.146926
Epoch:[ 30 11 ] loss: 0.4602072238922119 2022-07-01 08:47:11.578435
Epoch:[ 30 12 ] loss: 0.4554302394390106 2022-07-01 08:47:12.009088
Epoch:[ 30 13 ] loss: 0.45702335238456726 2022-07-01 08:47:12.440826
Epoch:[ 30 14 ] loss: 0.46026337146759033 2022-07-01 08:47:12.869421
Epoch:[ 30 15 ] loss: 0.4549177289009094 2022-07-01 08:47:13.302563
Epoch:[ 30 16 ] loss: 0.45440036058425903 2022-07-01 08:47:18.004875
Epoch:[ 30 17 ] loss: 0.4516330063343048 2022-07-01 08:47:18.436103
Epoch:[ 30 18 ] loss: 0.4547390043735504 2022-07-01 08:47:18.867228
Epoch:[ 30 19 ] loss: 0.45367932319641113 2022-07-01 08:47:19.294043
Training_Epoch:[ 30 ] Training_loss: 0.4546886503696442 2022-07-01 08:47:19.294692
learning rate:  0.0064
netparams have been saved once 30
val: 1 0.46690207719802856
val: 2 0.46746334433555603
val: 3 0.47582733631134033
val: 4 0.46385541558265686
val: 5 0.4607864022254944
val: 6 0.4650675356388092
val: 7 0.4479514956474304
val: 8 0.46276214718818665
val: 9 0.46746742725372314
val: 10 0.4548310339450836
val: 11 0.4721890985965729
val: 12 0.4699472188949585
val: 13 0.46130746603012085
val: 14 0.47070902585983276
val: 15 0.45752403140068054
val: 16 0.4551924467086792
val: 17 0.45487451553344727
val: 18 0.46522456407546997
val: 19 0.47498881816864014
val: 20 0.4635124206542969
val_Epoch:[ 30 ] val_loss: 0.4639191910624504 2022-07-01 08:47:22.959714
start training 2022-07-01 08:47:23.059502
Epoch:[ 31 0 ] loss: 0.4515816569328308 2022-07-01 08:47:38.106552
Epoch:[ 31 1 ] loss: 0.4479318857192993 2022-07-01 08:47:38.545715
Epoch:[ 31 2 ] loss: 0.45101821422576904 2022-07-01 08:47:38.979922
Epoch:[ 31 3 ] loss: 0.4498744010925293 2022-07-01 08:47:39.413135
Epoch:[ 31 4 ] loss: 0.44373783469200134 2022-07-01 08:47:39.842000
Epoch:[ 31 5 ] loss: 0.45114365220069885 2022-07-01 08:47:40.272002
Epoch:[ 31 6 ] loss: 0.4461505115032196 2022-07-01 08:47:40.705691
Epoch:[ 31 7 ] loss: 0.44935813546180725 2022-07-01 08:47:41.136326
Epoch:[ 31 8 ] loss: 0.4500296115875244 2022-07-01 08:47:41.569643
Epoch:[ 31 9 ] loss: 0.44626039266586304 2022-07-01 08:47:42.005777
Epoch:[ 31 10 ] loss: 0.4456412196159363 2022-07-01 08:47:42.440047
Epoch:[ 31 11 ] loss: 0.448263555765152 2022-07-01 08:47:42.869497
Epoch:[ 31 12 ] loss: 0.4463917016983032 2022-07-01 08:47:43.303009
Epoch:[ 31 13 ] loss: 0.44778478145599365 2022-07-01 08:47:43.733246
Epoch:[ 31 14 ] loss: 0.44567883014678955 2022-07-01 08:47:44.163825
Epoch:[ 31 15 ] loss: 0.44601622223854065 2022-07-01 08:47:44.594192
Epoch:[ 31 16 ] loss: 0.44753333926200867 2022-07-01 08:47:49.845953
Epoch:[ 31 17 ] loss: 0.446269690990448 2022-07-01 08:47:50.272937
Epoch:[ 31 18 ] loss: 0.4452964663505554 2022-07-01 08:47:50.713100
Epoch:[ 31 19 ] loss: 0.4455873966217041 2022-07-01 08:47:51.140416
Training_Epoch:[ 31 ] Training_loss: 0.4475774750113487 2022-07-01 08:47:51.141062
learning rate:  0.00512
val: 1 0.45495837926864624
val: 2 0.45446404814720154
val: 3 0.4472648501396179
val: 4 0.4707673192024231
val: 5 0.4460870027542114
val: 6 0.4449165165424347
val: 7 0.45428159832954407
val: 8 0.45453429222106934
val: 9 0.4564773440361023
val: 10 0.46406418085098267
val: 11 0.4617702066898346
val: 12 0.4464317262172699
val: 13 0.4497373700141907
val: 14 0.4599149227142334
val: 15 0.4556923806667328
val: 16 0.460968941450119
val: 17 0.4490452706813812
val: 18 0.4565882086753845
val: 19 0.4558921158313751
val: 20 0.456369012594223
val_Epoch:[ 31 ] val_loss: 0.45501128435134885 2022-07-01 08:47:54.781518
start training 2022-07-01 08:47:54.880357
Epoch:[ 32 0 ] loss: 0.44723281264305115 2022-07-01 08:48:08.691812
Epoch:[ 32 1 ] loss: 0.44615840911865234 2022-07-01 08:48:09.255928
Epoch:[ 32 2 ] loss: 0.44760599732398987 2022-07-01 08:48:09.709344
Epoch:[ 32 3 ] loss: 0.4470263719558716 2022-07-01 08:48:10.138575
Epoch:[ 32 4 ] loss: 0.44393306970596313 2022-07-01 08:48:10.566043
Epoch:[ 32 5 ] loss: 0.4458531439304352 2022-07-01 08:48:10.995152
Epoch:[ 32 6 ] loss: 0.44665607810020447 2022-07-01 08:48:11.425102
Epoch:[ 32 7 ] loss: 0.4426642954349518 2022-07-01 08:48:11.858730
Epoch:[ 32 8 ] loss: 0.44784772396087646 2022-07-01 08:48:12.288441
Epoch:[ 32 9 ] loss: 0.4429086148738861 2022-07-01 08:48:12.717689
Epoch:[ 32 10 ] loss: 0.44609078764915466 2022-07-01 08:48:13.147090
Epoch:[ 32 11 ] loss: 0.4408385753631592 2022-07-01 08:48:13.582036
Epoch:[ 32 12 ] loss: 0.4450456202030182 2022-07-01 08:48:14.009198
Epoch:[ 32 13 ] loss: 0.44548237323760986 2022-07-01 08:48:14.440294
Epoch:[ 32 14 ] loss: 0.44361022114753723 2022-07-01 08:48:14.872562
Epoch:[ 32 15 ] loss: 0.44378039240837097 2022-07-01 08:48:15.306883
Epoch:[ 32 16 ] loss: 0.4484110176563263 2022-07-01 08:48:20.831624
Epoch:[ 32 17 ] loss: 0.447927325963974 2022-07-01 08:48:21.258872
Epoch:[ 32 18 ] loss: 0.4427071809768677 2022-07-01 08:48:21.690027
Epoch:[ 32 19 ] loss: 0.4470319449901581 2022-07-01 08:48:22.117840
Training_Epoch:[ 32 ] Training_loss: 0.4454405978322029 2022-07-01 08:48:22.118481
learning rate:  0.00512
netparams have been saved once 32
val: 1 0.4655245542526245
val: 2 0.45759573578834534
val: 3 0.46371230483055115
val: 4 0.46971699595451355
val: 5 0.4507420063018799
val: 6 0.47156742215156555
val: 7 0.46130186319351196
val: 8 0.46700727939605713
val: 9 0.4716317355632782
val: 10 0.46575385332107544
val: 11 0.45969414710998535
val: 12 0.4692448675632477
val: 13 0.4709024429321289
val: 14 0.46756863594055176
val: 15 0.45832857489585876
val: 16 0.463832288980484
val: 17 0.4587129056453705
val: 18 0.4662782549858093
val: 19 0.4656156599521637
val: 20 0.46511879563331604
val_Epoch:[ 32 ] val_loss: 0.46449251621961596 2022-07-01 08:48:25.759624
start training 2022-07-01 08:48:25.859949
Epoch:[ 33 0 ] loss: 0.4436509311199188 2022-07-01 08:48:39.989095
Epoch:[ 33 1 ] loss: 0.4443933367729187 2022-07-01 08:48:40.443094
Epoch:[ 33 2 ] loss: 0.4465959966182709 2022-07-01 08:48:40.878511
Epoch:[ 33 3 ] loss: 0.4412962794303894 2022-07-01 08:48:41.316619
Epoch:[ 33 4 ] loss: 0.4459526836872101 2022-07-01 08:48:41.746910
Epoch:[ 33 5 ] loss: 0.4454127550125122 2022-07-01 08:48:42.178746
Epoch:[ 33 6 ] loss: 0.441646933555603 2022-07-01 08:48:42.614719
Epoch:[ 33 7 ] loss: 0.445978045463562 2022-07-01 08:48:43.050921
Epoch:[ 33 8 ] loss: 0.4484567642211914 2022-07-01 08:48:43.483700
Epoch:[ 33 9 ] loss: 0.44129469990730286 2022-07-01 08:48:43.914467
Epoch:[ 33 10 ] loss: 0.4423486590385437 2022-07-01 08:48:44.353739
Epoch:[ 33 11 ] loss: 0.44841259717941284 2022-07-01 08:48:44.787414
Epoch:[ 33 12 ] loss: 0.4431396722793579 2022-07-01 08:48:45.222410
Epoch:[ 33 13 ] loss: 0.44722744822502136 2022-07-01 08:48:45.653110
Epoch:[ 33 14 ] loss: 0.4427298605442047 2022-07-01 08:48:46.083276
Epoch:[ 33 15 ] loss: 0.4484478533267975 2022-07-01 08:48:46.511208
Epoch:[ 33 16 ] loss: 0.44212496280670166 2022-07-01 08:48:51.682865
Epoch:[ 33 17 ] loss: 0.44853049516677856 2022-07-01 08:48:52.252460
Epoch:[ 33 18 ] loss: 0.44430890679359436 2022-07-01 08:48:52.692098
Epoch:[ 33 19 ] loss: 0.4442337453365326 2022-07-01 08:48:53.123103
Training_Epoch:[ 33 ] Training_loss: 0.44480913132429123 2022-07-01 08:48:53.123811
learning rate:  0.00512
val: 1 0.461789608001709
val: 2 0.4434295892715454
val: 3 0.45330575108528137
val: 4 0.44950228929519653
val: 5 0.4534967243671417
val: 6 0.44777950644493103
val: 7 0.45973432064056396
val: 8 0.4434410631656647
val: 9 0.44913917779922485
val: 10 0.45173048973083496
val: 11 0.4518783688545227
val: 12 0.4544086754322052
val: 13 0.4604969024658203
val: 14 0.44401517510414124
val: 15 0.4409984350204468
val: 16 0.4453524053096771
val: 17 0.4601798355579376
val: 18 0.4486238360404968
val: 19 0.4554322063922882
val: 20 0.44830912351608276
val_Epoch:[ 33 ] val_loss: 0.4511521741747856 2022-07-01 08:48:56.788114
start training 2022-07-01 08:48:56.884196
Epoch:[ 34 0 ] loss: 0.44059720635414124 2022-07-01 08:49:11.440952
Epoch:[ 34 1 ] loss: 0.44173747301101685 2022-07-01 08:49:11.883815
Epoch:[ 34 2 ] loss: 0.4424801170825958 2022-07-01 08:49:12.310504
Epoch:[ 34 3 ] loss: 0.4414621889591217 2022-07-01 08:49:12.740685
Epoch:[ 34 4 ] loss: 0.44186118245124817 2022-07-01 08:49:13.178529
Epoch:[ 34 5 ] loss: 0.44073933362960815 2022-07-01 08:49:13.607206
Epoch:[ 34 6 ] loss: 0.4400891661643982 2022-07-01 08:49:14.037633
Epoch:[ 34 7 ] loss: 0.44233158230781555 2022-07-01 08:49:14.473450
Epoch:[ 34 8 ] loss: 0.44420284032821655 2022-07-01 08:49:14.908028
Epoch:[ 34 9 ] loss: 0.4429813027381897 2022-07-01 08:49:15.339036
Epoch:[ 34 10 ] loss: 0.44159388542175293 2022-07-01 08:49:15.769259
Epoch:[ 34 11 ] loss: 0.4460311830043793 2022-07-01 08:49:16.200639
Epoch:[ 34 12 ] loss: 0.44435402750968933 2022-07-01 08:49:16.634692
Epoch:[ 34 13 ] loss: 0.44448620080947876 2022-07-01 08:49:17.067939
Epoch:[ 34 14 ] loss: 0.4449683129787445 2022-07-01 08:49:17.503612
Epoch:[ 34 15 ] loss: 0.4461122453212738 2022-07-01 08:49:17.930546
Epoch:[ 34 16 ] loss: 0.44949063658714294 2022-07-01 08:49:23.431400
Epoch:[ 34 17 ] loss: 0.44607728719711304 2022-07-01 08:49:23.860915
Epoch:[ 34 18 ] loss: 0.4419679343700409 2022-07-01 08:49:24.294350
Epoch:[ 34 19 ] loss: 0.44435152411460876 2022-07-01 08:49:24.726361
Training_Epoch:[ 34 ] Training_loss: 0.4433957815170288 2022-07-01 08:49:24.727025
learning rate:  0.00512
netparams have been saved once 34
val: 1 0.44571468234062195
val: 2 0.4627971053123474
val: 3 0.46267375349998474
val: 4 0.4573168158531189
val: 5 0.4554280936717987
val: 6 0.457716166973114
val: 7 0.4533308744430542
val: 8 0.453306645154953
val: 9 0.4611394703388214
val: 10 0.45785966515541077
val: 11 0.459866464138031
val: 12 0.4515743851661682
val: 13 0.45675933361053467
val: 14 0.45484215021133423
val: 15 0.4635721743106842
val: 16 0.4690815806388855
val: 17 0.465825617313385
val: 18 0.44989752769470215
val: 19 0.45740023255348206
val: 20 0.4642210602760315
val_Epoch:[ 34 ] val_loss: 0.45801618993282317 2022-07-01 08:49:28.467007
start training 2022-07-01 08:49:28.571266
Epoch:[ 35 0 ] loss: 0.4415956437587738 2022-07-01 08:49:43.252488
Epoch:[ 35 1 ] loss: 0.4448394775390625 2022-07-01 08:49:43.684831
Epoch:[ 35 2 ] loss: 0.44232478737831116 2022-07-01 08:49:44.123890
Epoch:[ 35 3 ] loss: 0.4385330379009247 2022-07-01 08:49:44.556610
Epoch:[ 35 4 ] loss: 0.44003966450691223 2022-07-01 08:49:44.988428
Epoch:[ 35 5 ] loss: 0.4452393054962158 2022-07-01 08:49:45.426325
Epoch:[ 35 6 ] loss: 0.442137748003006 2022-07-01 08:49:45.858974
Epoch:[ 35 7 ] loss: 0.44426125288009644 2022-07-01 08:49:46.288579
Epoch:[ 35 8 ] loss: 0.4417496621608734 2022-07-01 08:49:46.726437
Epoch:[ 35 9 ] loss: 0.4411461651325226 2022-07-01 08:49:47.163835
Epoch:[ 35 10 ] loss: 0.44464901089668274 2022-07-01 08:49:47.600221
Epoch:[ 35 11 ] loss: 0.4468305706977844 2022-07-01 08:49:48.041387
Epoch:[ 35 12 ] loss: 0.43768972158432007 2022-07-01 08:49:48.475860
Epoch:[ 35 13 ] loss: 0.4477076828479767 2022-07-01 08:49:48.920985
Epoch:[ 35 14 ] loss: 0.44477471709251404 2022-07-01 08:49:49.349755
Epoch:[ 35 15 ] loss: 0.44166794419288635 2022-07-01 08:49:49.783249
Epoch:[ 35 16 ] loss: 0.44208911061286926 2022-07-01 08:49:54.608002
Epoch:[ 35 17 ] loss: 0.44287964701652527 2022-07-01 08:49:55.048812
Epoch:[ 35 18 ] loss: 0.44307488203048706 2022-07-01 08:49:55.495987
Epoch:[ 35 19 ] loss: 0.4430808126926422 2022-07-01 08:49:55.930374
Training_Epoch:[ 35 ] Training_loss: 0.44281554222106934 2022-07-01 08:49:55.931008
learning rate:  0.00512
val: 1 0.4641188383102417
val: 2 0.47726747393608093
val: 3 0.46802985668182373
val: 4 0.4601436257362366
val: 5 0.47248923778533936
val: 6 0.4742666482925415
val: 7 0.45813143253326416
val: 8 0.46237912774086
val: 9 0.45506566762924194
val: 10 0.4630592465400696
val: 11 0.464245468378067
val: 12 0.4769577383995056
val: 13 0.4638296067714691
val: 14 0.47339382767677307
val: 15 0.46082571148872375
val: 16 0.4592367112636566
val: 17 0.4580431580543518
val: 18 0.4650408923625946
val: 19 0.4658423364162445
val: 20 0.4728787839412689
val_Epoch:[ 35 ] val_loss: 0.46576226949691774 2022-07-01 08:49:59.687477
start training 2022-07-01 08:49:59.793350
Epoch:[ 36 0 ] loss: 0.4461744427680969 2022-07-01 08:50:13.867791
Epoch:[ 36 1 ] loss: 0.4399155080318451 2022-07-01 08:50:14.329505
Epoch:[ 36 2 ] loss: 0.44260501861572266 2022-07-01 08:50:14.917024
Epoch:[ 36 3 ] loss: 0.44459831714630127 2022-07-01 08:50:15.345453
Epoch:[ 36 4 ] loss: 0.4418570101261139 2022-07-01 08:50:15.775130
Epoch:[ 36 5 ] loss: 0.4409807324409485 2022-07-01 08:50:16.206180
Epoch:[ 36 6 ] loss: 0.4424242675304413 2022-07-01 08:50:16.637518
Epoch:[ 36 7 ] loss: 0.4420190751552582 2022-07-01 08:50:17.071966
Epoch:[ 36 8 ] loss: 0.44345611333847046 2022-07-01 08:50:17.505715
Epoch:[ 36 9 ] loss: 0.4380418360233307 2022-07-01 08:50:17.940939
Epoch:[ 36 10 ] loss: 0.44031333923339844 2022-07-01 08:50:18.373294
Epoch:[ 36 11 ] loss: 0.44146013259887695 2022-07-01 08:50:18.811711
Epoch:[ 36 12 ] loss: 0.4432288110256195 2022-07-01 08:50:19.241942
Epoch:[ 36 13 ] loss: 0.44185853004455566 2022-07-01 08:50:19.672911
Epoch:[ 36 14 ] loss: 0.44189363718032837 2022-07-01 08:50:20.105208
Epoch:[ 36 15 ] loss: 0.44924992322921753 2022-07-01 08:50:20.538457
Epoch:[ 36 16 ] loss: 0.4438156187534332 2022-07-01 08:50:26.335976
Epoch:[ 36 17 ] loss: 0.44284528493881226 2022-07-01 08:50:26.761998
Epoch:[ 36 18 ] loss: 0.4491240084171295 2022-07-01 08:50:27.194116
Epoch:[ 36 19 ] loss: 0.4406963586807251 2022-07-01 08:50:27.621571
Training_Epoch:[ 36 ] Training_loss: 0.44282789826393126 2022-07-01 08:50:27.622328
learning rate:  0.00512
netparams have been saved once 36
val: 1 0.4601784646511078
val: 2 0.45135900378227234
val: 3 0.4564511179924011
val: 4 0.46273332834243774
val: 5 0.45890793204307556
val: 6 0.46988445520401
val: 7 0.45519572496414185
val: 8 0.44350674748420715
val: 9 0.4661102294921875
val: 10 0.45064833760261536
val: 11 0.4524982273578644
val: 12 0.4581068456172943
val: 13 0.4491945207118988
val: 14 0.4487176537513733
val: 15 0.4551509618759155
val: 16 0.4523000717163086
val: 17 0.4554937481880188
val: 18 0.4495769739151001
val: 19 0.46394550800323486
val: 20 0.4558916985988617
val_Epoch:[ 36 ] val_loss: 0.45579257756471636 2022-07-01 08:50:31.452311
start training 2022-07-01 08:50:31.550819
Epoch:[ 37 0 ] loss: 0.4443039894104004 2022-07-01 08:50:45.762386
Epoch:[ 37 1 ] loss: 0.4466172158718109 2022-07-01 08:50:46.318472
Epoch:[ 37 2 ] loss: 0.4422268271446228 2022-07-01 08:50:46.734122
Epoch:[ 37 3 ] loss: 0.44164860248565674 2022-07-01 08:50:47.141716
Epoch:[ 37 4 ] loss: 0.4429943859577179 2022-07-01 08:50:47.556614
Epoch:[ 37 5 ] loss: 0.4441578984260559 2022-07-01 08:50:47.984319
Epoch:[ 37 6 ] loss: 0.43958723545074463 2022-07-01 08:50:48.420121
Epoch:[ 37 7 ] loss: 0.4427989423274994 2022-07-01 08:50:48.851252
Epoch:[ 37 8 ] loss: 0.4425084590911865 2022-07-01 08:50:49.285324
Epoch:[ 37 9 ] loss: 0.44038036465644836 2022-07-01 08:50:49.715500
Epoch:[ 37 10 ] loss: 0.44451525807380676 2022-07-01 08:50:50.143141
Epoch:[ 37 11 ] loss: 0.4435945749282837 2022-07-01 08:50:50.577342
Epoch:[ 37 12 ] loss: 0.4415847659111023 2022-07-01 08:50:51.004698
Epoch:[ 37 13 ] loss: 0.4393823444843292 2022-07-01 08:50:51.436824
Epoch:[ 37 14 ] loss: 0.44236743450164795 2022-07-01 08:50:51.865688
Epoch:[ 37 15 ] loss: 0.44112488627433777 2022-07-01 08:50:52.301558
Epoch:[ 37 16 ] loss: 0.4388730227947235 2022-07-01 08:50:58.039310
Epoch:[ 37 17 ] loss: 0.44174760580062866 2022-07-01 08:50:58.473583
Epoch:[ 37 18 ] loss: 0.4381793141365051 2022-07-01 08:50:58.907978
Epoch:[ 37 19 ] loss: 0.4443165361881256 2022-07-01 08:50:59.335774
Training_Epoch:[ 37 ] Training_loss: 0.44214548319578173 2022-07-01 08:50:59.336421
learning rate:  0.00512
val: 1 0.4550618529319763
val: 2 0.4446629285812378
val: 3 0.4666025936603546
val: 4 0.4568849205970764
val: 5 0.45614540576934814
val: 6 0.4641660749912262
val: 7 0.4474455714225769
val: 8 0.4565620422363281
val: 9 0.45996764302253723
val: 10 0.45372653007507324
val: 11 0.4572591781616211
val: 12 0.4523911476135254
val: 13 0.4680401384830475
val: 14 0.4483776390552521
val: 15 0.45727747678756714
val: 16 0.4545886218547821
val: 17 0.4555976688861847
val: 18 0.45812153816223145
val: 19 0.44475311040878296
val: 20 0.45497578382492065
val_Epoch:[ 37 ] val_loss: 0.4556303933262825 2022-07-01 08:51:02.940569
start training 2022-07-01 08:51:03.045599
Epoch:[ 38 0 ] loss: 0.44505953788757324 2022-07-01 08:51:17.923640
Epoch:[ 38 1 ] loss: 0.4454968571662903 2022-07-01 08:51:18.353320
Epoch:[ 38 2 ] loss: 0.4428357183933258 2022-07-01 08:51:18.789063
Epoch:[ 38 3 ] loss: 0.437995582818985 2022-07-01 08:51:19.223734
Epoch:[ 38 4 ] loss: 0.4368341267108917 2022-07-01 08:51:19.651668
Epoch:[ 38 5 ] loss: 0.4388083219528198 2022-07-01 08:51:20.087481
Epoch:[ 38 6 ] loss: 0.4429839551448822 2022-07-01 08:51:20.522598
Epoch:[ 38 7 ] loss: 0.43501460552215576 2022-07-01 08:51:20.954478
Epoch:[ 38 8 ] loss: 0.44284525513648987 2022-07-01 08:51:21.386841
Epoch:[ 38 9 ] loss: 0.4442875385284424 2022-07-01 08:51:21.815429
Epoch:[ 38 10 ] loss: 0.43902912735939026 2022-07-01 08:51:22.247268
Epoch:[ 38 11 ] loss: 0.4413878321647644 2022-07-01 08:51:22.675235
Epoch:[ 38 12 ] loss: 0.4411950409412384 2022-07-01 08:51:23.105376
Epoch:[ 38 13 ] loss: 0.4361009895801544 2022-07-01 08:51:23.532096
Epoch:[ 38 14 ] loss: 0.4424717128276825 2022-07-01 08:51:23.960975
Epoch:[ 38 15 ] loss: 0.4384332597255707 2022-07-01 08:51:24.394956
Epoch:[ 38 16 ] loss: 0.43922698497772217 2022-07-01 08:51:29.276586
Epoch:[ 38 17 ] loss: 0.4412257969379425 2022-07-01 08:51:29.705137
Epoch:[ 38 18 ] loss: 0.4384395480155945 2022-07-01 08:51:30.136902
Epoch:[ 38 19 ] loss: 0.43920865654945374 2022-07-01 08:51:30.565307
Training_Epoch:[ 38 ] Training_loss: 0.4404440224170685 2022-07-01 08:51:30.565965
learning rate:  0.00512
netparams have been saved once 38
val: 1 0.4621630609035492
val: 2 0.4560192823410034
val: 3 0.45486998558044434
val: 4 0.44874218106269836
val: 5 0.4548571705818176
val: 6 0.4607033431529999
val: 7 0.45008566975593567
val: 8 0.46026191115379333
val: 9 0.4624859690666199
val: 10 0.4629307687282562
val: 11 0.4604852497577667
val: 12 0.461525022983551
val: 13 0.4532691240310669
val: 14 0.4613919258117676
val: 15 0.4574606418609619
val: 16 0.45282214879989624
val: 17 0.46288877725601196
val: 18 0.46418723464012146
val: 19 0.45453399419784546
val: 20 0.4518613815307617
val_Epoch:[ 38 ] val_loss: 0.45767724215984346 2022-07-01 08:51:34.371495
start training 2022-07-01 08:51:34.477580
Epoch:[ 39 0 ] loss: 0.43911662697792053 2022-07-01 08:51:48.986697
Epoch:[ 39 1 ] loss: 0.44011443853378296 2022-07-01 08:51:49.436623
Epoch:[ 39 2 ] loss: 0.43826159834861755 2022-07-01 08:51:49.870975
Epoch:[ 39 3 ] loss: 0.4371165931224823 2022-07-01 08:51:50.306016
Epoch:[ 39 4 ] loss: 0.4416264295578003 2022-07-01 08:51:50.738825
Epoch:[ 39 5 ] loss: 0.4427931308746338 2022-07-01 08:51:51.166769
Epoch:[ 39 6 ] loss: 0.44123509526252747 2022-07-01 08:51:51.594677
Epoch:[ 39 7 ] loss: 0.4406903386116028 2022-07-01 08:51:52.023215
Epoch:[ 39 8 ] loss: 0.4382600486278534 2022-07-01 08:51:52.457330
Epoch:[ 39 9 ] loss: 0.43878501653671265 2022-07-01 08:51:52.894329
Epoch:[ 39 10 ] loss: 0.43964430689811707 2022-07-01 08:51:53.324354
Epoch:[ 39 11 ] loss: 0.4404366612434387 2022-07-01 08:51:53.753303
Epoch:[ 39 12 ] loss: 0.43924012780189514 2022-07-01 08:51:54.180959
Epoch:[ 39 13 ] loss: 0.43653807044029236 2022-07-01 08:51:54.609782
Epoch:[ 39 14 ] loss: 0.4388975203037262 2022-07-01 08:51:55.041325
Epoch:[ 39 15 ] loss: 0.4370676577091217 2022-07-01 08:51:55.471047
Epoch:[ 39 16 ] loss: 0.4354545474052429 2022-07-01 08:52:00.714677
Epoch:[ 39 17 ] loss: 0.435115247964859 2022-07-01 08:52:01.141713
Epoch:[ 39 18 ] loss: 0.4400481581687927 2022-07-01 08:52:01.574287
Epoch:[ 39 19 ] loss: 0.4393048584461212 2022-07-01 08:52:02.003335
Training_Epoch:[ 39 ] Training_loss: 0.43898732364177706 2022-07-01 08:52:02.003919
learning rate:  0.00512
val: 1 0.4560040533542633
val: 2 0.4440397620201111
val: 3 0.45446711778640747
val: 4 0.4518214464187622
val: 5 0.45395755767822266
val: 6 0.43722712993621826
val: 7 0.44883298873901367
val: 8 0.4552639126777649
val: 9 0.4621010422706604
val: 10 0.44865545630455017
val: 11 0.46352851390838623
val: 12 0.44466522336006165
val: 13 0.44692671298980713
val: 14 0.4464375376701355
val: 15 0.4472486078739166
val: 16 0.46261778473854065
val: 17 0.4514211416244507
val: 18 0.4601597487926483
val: 19 0.4442797601222992
val: 20 0.4687924087047577
val_Epoch:[ 39 ] val_loss: 0.4524223953485489 2022-07-01 08:52:05.638991
start training 2022-07-01 08:52:05.738158
Epoch:[ 40 0 ] loss: 0.43775424361228943 2022-07-01 08:52:19.966030
Epoch:[ 40 1 ] loss: 0.4364314079284668 2022-07-01 08:52:20.474120
Epoch:[ 40 2 ] loss: 0.44059163331985474 2022-07-01 08:52:20.909268
Epoch:[ 40 3 ] loss: 0.43618687987327576 2022-07-01 08:52:21.339328
Epoch:[ 40 4 ] loss: 0.43760186433792114 2022-07-01 08:52:21.773185
Epoch:[ 40 5 ] loss: 0.43535131216049194 2022-07-01 08:52:22.207380
Epoch:[ 40 6 ] loss: 0.4361483156681061 2022-07-01 08:52:22.637927
Epoch:[ 40 7 ] loss: 0.4350406527519226 2022-07-01 08:52:23.065915
Epoch:[ 40 8 ] loss: 0.4340064227581024 2022-07-01 08:52:23.494964
Epoch:[ 40 9 ] loss: 0.4348898231983185 2022-07-01 08:52:23.924525
Epoch:[ 40 10 ] loss: 0.43742090463638306 2022-07-01 08:52:24.354649
Epoch:[ 40 11 ] loss: 0.43386173248291016 2022-07-01 08:52:24.784440
Epoch:[ 40 12 ] loss: 0.4354453980922699 2022-07-01 08:52:25.217628
Epoch:[ 40 13 ] loss: 0.43570876121520996 2022-07-01 08:52:25.650672
Epoch:[ 40 14 ] loss: 0.4382077157497406 2022-07-01 08:52:26.080838
Epoch:[ 40 15 ] loss: 0.43709999322891235 2022-07-01 08:52:26.515559
Epoch:[ 40 16 ] loss: 0.44029614329338074 2022-07-01 08:52:31.784862
Epoch:[ 40 17 ] loss: 0.4416866898536682 2022-07-01 08:52:32.217683
Epoch:[ 40 18 ] loss: 0.4417698383331299 2022-07-01 08:52:32.652445
Epoch:[ 40 19 ] loss: 0.44692087173461914 2022-07-01 08:52:33.080160
Training_Epoch:[ 40 ] Training_loss: 0.43762103021144866 2022-07-01 08:52:33.080766
learning rate:  0.00512
netparams have been saved once 40
val: 1 0.4680701196193695
val: 2 0.4594326317310333
val: 3 0.4611235558986664
val: 4 0.448481023311615
val: 5 0.4551394581794739
val: 6 0.45793458819389343
val: 7 0.45433875918388367
val: 8 0.461513489484787
val: 9 0.4550792872905731
val: 10 0.46760094165802
val: 11 0.4549643397331238
val: 12 0.44965890049934387
val: 13 0.4570624828338623
val: 14 0.45271846652030945
val: 15 0.456109881401062
val: 16 0.4722241759300232
val: 17 0.4553084075450897
val: 18 0.4522196352481842
val: 19 0.45073676109313965
val: 20 0.45873960852622986
val_Epoch:[ 40 ] val_loss: 0.45742282569408416 2022-07-01 08:52:36.906299
start training 2022-07-01 08:52:37.026539
Epoch:[ 41 0 ] loss: 0.4381380081176758 2022-07-01 08:52:51.505616
Epoch:[ 41 1 ] loss: 0.436490923166275 2022-07-01 08:52:51.940839
Epoch:[ 41 2 ] loss: 0.43527767062187195 2022-07-01 08:52:52.372976
Epoch:[ 41 3 ] loss: 0.43610915541648865 2022-07-01 08:52:52.807970
Epoch:[ 41 4 ] loss: 0.4348812997341156 2022-07-01 08:52:53.238144
Epoch:[ 41 5 ] loss: 0.43460556864738464 2022-07-01 08:52:53.673679
Epoch:[ 41 6 ] loss: 0.4341440200805664 2022-07-01 08:52:54.106841
Epoch:[ 41 7 ] loss: 0.4326760172843933 2022-07-01 08:52:54.536178
Epoch:[ 41 8 ] loss: 0.4346822500228882 2022-07-01 08:52:54.964348
Epoch:[ 41 9 ] loss: 0.4384641647338867 2022-07-01 08:52:55.393055
Epoch:[ 41 10 ] loss: 0.43294262886047363 2022-07-01 08:52:55.824298
Epoch:[ 41 11 ] loss: 0.43489930033683777 2022-07-01 08:52:56.254548
Epoch:[ 41 12 ] loss: 0.43505963683128357 2022-07-01 08:52:56.684073
Epoch:[ 41 13 ] loss: 0.4326556324958801 2022-07-01 08:52:57.117468
Epoch:[ 41 14 ] loss: 0.43329140543937683 2022-07-01 08:52:57.544445
Epoch:[ 41 15 ] loss: 0.43512409925460815 2022-07-01 08:52:57.973609
Epoch:[ 41 16 ] loss: 0.4350283741950989 2022-07-01 08:53:02.592492
Epoch:[ 41 17 ] loss: 0.43523120880126953 2022-07-01 08:53:03.126717
Epoch:[ 41 18 ] loss: 0.439128041267395 2022-07-01 08:53:03.559636
Epoch:[ 41 19 ] loss: 0.4353020489215851 2022-07-01 08:53:03.968369
Training_Epoch:[ 41 ] Training_loss: 0.43520657271146773 2022-07-01 08:53:03.969345
learning rate:  0.004096000000000001
val: 1 0.456918865442276
val: 2 0.45328012108802795
val: 3 0.4505952298641205
val: 4 0.45527568459510803
val: 5 0.4562789499759674
val: 6 0.44364622235298157
val: 7 0.4394933581352234
val: 8 0.44805461168289185
val: 9 0.4471729099750519
val: 10 0.44213300943374634
val: 11 0.45357319712638855
val: 12 0.44316568970680237
val: 13 0.45637544989585876
val: 14 0.4383314251899719
val: 15 0.4448014795780182
val: 16 0.4597487151622772
val: 17 0.4453534781932831
val: 18 0.4525259733200073
val: 19 0.45824146270751953
val: 20 0.44961681962013245
val_Epoch:[ 41 ] val_loss: 0.4497291326522827 2022-07-01 08:53:07.696014
start training 2022-07-01 08:53:07.796595
Epoch:[ 42 0 ] loss: 0.43059325218200684 2022-07-01 08:53:22.456326
Epoch:[ 42 1 ] loss: 0.43520456552505493 2022-07-01 08:53:22.890043
Epoch:[ 42 2 ] loss: 0.43647170066833496 2022-07-01 08:53:23.318658
Epoch:[ 42 3 ] loss: 0.43647870421409607 2022-07-01 08:53:23.746674
Epoch:[ 42 4 ] loss: 0.4330550730228424 2022-07-01 08:53:24.176031
Epoch:[ 42 5 ] loss: 0.43159741163253784 2022-07-01 08:53:24.606389
Epoch:[ 42 6 ] loss: 0.43683257699012756 2022-07-01 08:53:25.038298
Epoch:[ 42 7 ] loss: 0.43318843841552734 2022-07-01 08:53:25.472480
Epoch:[ 42 8 ] loss: 0.43441903591156006 2022-07-01 08:53:25.901997
Epoch:[ 42 9 ] loss: 0.43414387106895447 2022-07-01 08:53:26.335435
Epoch:[ 42 10 ] loss: 0.434343159198761 2022-07-01 08:53:26.762985
Epoch:[ 42 11 ] loss: 0.4340329170227051 2022-07-01 08:53:27.193595
Epoch:[ 42 12 ] loss: 0.4320920705795288 2022-07-01 08:53:27.623838
Epoch:[ 42 13 ] loss: 0.43347954750061035 2022-07-01 08:53:28.059718
Epoch:[ 42 14 ] loss: 0.43298107385635376 2022-07-01 08:53:28.492359
Epoch:[ 42 15 ] loss: 0.4303746521472931 2022-07-01 08:53:28.920981
Epoch:[ 42 16 ] loss: 0.43783384561538696 2022-07-01 08:53:33.879769
Epoch:[ 42 17 ] loss: 0.43401220440864563 2022-07-01 08:53:34.306830
Epoch:[ 42 18 ] loss: 0.4300716817378998 2022-07-01 08:53:34.751584
Epoch:[ 42 19 ] loss: 0.4317917823791504 2022-07-01 08:53:35.187728
Training_Epoch:[ 42 ] Training_loss: 0.43364987820386885 2022-07-01 08:53:35.188458
learning rate:  0.004096000000000001
netparams have been saved once 42
val: 1 0.45660966634750366
val: 2 0.4467869699001312
val: 3 0.4378553628921509
val: 4 0.4476558268070221
val: 5 0.45612531900405884
val: 6 0.45252665877342224
val: 7 0.44445064663887024
val: 8 0.449275404214859
val: 9 0.45256805419921875
val: 10 0.4404997229576111
val: 11 0.44835036993026733
val: 12 0.4403567314147949
val: 13 0.44740575551986694
val: 14 0.446964293718338
val: 15 0.4501049220561981
val: 16 0.450713574886322
val: 17 0.4508602023124695
val: 18 0.4645920991897583
val: 19 0.43914303183555603
val: 20 0.4580093324184418
val_Epoch:[ 42 ] val_loss: 0.44904269725084306 2022-07-01 08:53:39.005048
start training 2022-07-01 08:53:39.101774
Epoch:[ 43 0 ] loss: 0.4288073480129242 2022-07-01 08:53:53.097546
Epoch:[ 43 1 ] loss: 0.43262892961502075 2022-07-01 08:53:53.550058
Epoch:[ 43 2 ] loss: 0.43210363388061523 2022-07-01 08:53:53.999336
Epoch:[ 43 3 ] loss: 0.4315430521965027 2022-07-01 08:53:54.434378
Epoch:[ 43 4 ] loss: 0.43447017669677734 2022-07-01 08:53:54.861341
Epoch:[ 43 5 ] loss: 0.43417850136756897 2022-07-01 08:53:55.294505
Epoch:[ 43 6 ] loss: 0.4315555691719055 2022-07-01 08:53:55.730133
Epoch:[ 43 7 ] loss: 0.43467167019844055 2022-07-01 08:53:56.162702
Epoch:[ 43 8 ] loss: 0.4296295642852783 2022-07-01 08:53:56.591366
Epoch:[ 43 9 ] loss: 0.43352261185646057 2022-07-01 08:53:57.018807
Epoch:[ 43 10 ] loss: 0.4323456585407257 2022-07-01 08:53:57.449160
Epoch:[ 43 11 ] loss: 0.4368416965007782 2022-07-01 08:53:57.878263
Epoch:[ 43 12 ] loss: 0.43372249603271484 2022-07-01 08:53:58.308290
Epoch:[ 43 13 ] loss: 0.43190842866897583 2022-07-01 08:53:58.739615
Epoch:[ 43 14 ] loss: 0.43390950560569763 2022-07-01 08:53:59.172898
Epoch:[ 43 15 ] loss: 0.4288664162158966 2022-07-01 08:53:59.605632
Epoch:[ 43 16 ] loss: 0.43142563104629517 2022-07-01 08:54:04.978131
Epoch:[ 43 17 ] loss: 0.43329548835754395 2022-07-01 08:54:05.434399
Epoch:[ 43 18 ] loss: 0.43453818559646606 2022-07-01 08:54:05.866595
Epoch:[ 43 19 ] loss: 0.4329255521297455 2022-07-01 08:54:06.296823
Training_Epoch:[ 43 ] Training_loss: 0.4326445057988167 2022-07-01 08:54:06.297435
learning rate:  0.004096000000000001
val: 1 0.45854806900024414
val: 2 0.4521586298942566
val: 3 0.4620702266693115
val: 4 0.4450150430202484
val: 5 0.44331684708595276
val: 6 0.466467022895813
val: 7 0.4394850432872772
val: 8 0.44634267687797546
val: 9 0.4483916163444519
val: 10 0.45320919156074524
val: 11 0.4455718696117401
val: 12 0.4478491246700287
val: 13 0.4436015486717224
val: 14 0.44290611147880554
val: 15 0.44807329773902893
val: 16 0.46440085768699646
val: 17 0.4608387053012848
val: 18 0.44708409905433655
val: 19 0.43941059708595276
val: 20 0.45357316732406616
val_Epoch:[ 43 ] val_loss: 0.45041568726301195 2022-07-01 08:54:09.978586
start training 2022-07-01 08:54:10.072017
Epoch:[ 44 0 ] loss: 0.4292077124118805 2022-07-01 08:54:23.995419
Epoch:[ 44 1 ] loss: 0.4324374794960022 2022-07-01 08:54:24.480765
Epoch:[ 44 2 ] loss: 0.4317278265953064 2022-07-01 08:54:24.998324
Epoch:[ 44 3 ] loss: 0.4282284080982208 2022-07-01 08:54:25.426484
Epoch:[ 44 4 ] loss: 0.43026551604270935 2022-07-01 08:54:25.855107
Epoch:[ 44 5 ] loss: 0.43066805601119995 2022-07-01 08:54:26.287873
Epoch:[ 44 6 ] loss: 0.43107518553733826 2022-07-01 08:54:26.717567
Epoch:[ 44 7 ] loss: 0.4321221709251404 2022-07-01 08:54:27.147971
Epoch:[ 44 8 ] loss: 0.43087902665138245 2022-07-01 08:54:27.586006
Epoch:[ 44 9 ] loss: 0.42982038855552673 2022-07-01 08:54:28.014338
Epoch:[ 44 10 ] loss: 0.4298996925354004 2022-07-01 08:54:28.442762
Epoch:[ 44 11 ] loss: 0.43369391560554504 2022-07-01 08:54:28.874598
Epoch:[ 44 12 ] loss: 0.43008267879486084 2022-07-01 08:54:29.304087
Epoch:[ 44 13 ] loss: 0.4287188947200775 2022-07-01 08:54:29.736669
Epoch:[ 44 14 ] loss: 0.43127891421318054 2022-07-01 08:54:30.171287
Epoch:[ 44 15 ] loss: 0.4316348135471344 2022-07-01 08:54:30.606209
Epoch:[ 44 16 ] loss: 0.4307247996330261 2022-07-01 08:54:36.046745
Epoch:[ 44 17 ] loss: 0.4311642050743103 2022-07-01 08:54:36.474784
Epoch:[ 44 18 ] loss: 0.4328655004501343 2022-07-01 08:54:36.907007
Epoch:[ 44 19 ] loss: 0.4331275522708893 2022-07-01 08:54:37.334863
Training_Epoch:[ 44 ] Training_loss: 0.4309811368584633 2022-07-01 08:54:37.335635
learning rate:  0.004096000000000001
netparams have been saved once 44
val: 1 0.4447442591190338
val: 2 0.4547687768936157
val: 3 0.44190534949302673
val: 4 0.44016435742378235
val: 5 0.4395115077495575
val: 6 0.4532671868801117
val: 7 0.44266268610954285
val: 8 0.4485933482646942
val: 9 0.4404376447200775
val: 10 0.4380517303943634
val: 11 0.44572779536247253
val: 12 0.4427869915962219
val: 13 0.4475776255130768
val: 14 0.4484906494617462
val: 15 0.4511617124080658
val: 16 0.44077634811401367
val: 17 0.44449159502983093
val: 18 0.4440784156322479
val: 19 0.4554888904094696
val: 20 0.4417458474636078
val_Epoch:[ 44 ] val_loss: 0.44532163590192797 2022-07-01 08:54:41.161174
start training 2022-07-01 08:54:41.255548
Epoch:[ 45 0 ] loss: 0.4330056309700012 2022-07-01 08:54:56.146620
Epoch:[ 45 1 ] loss: 0.4338754415512085 2022-07-01 08:54:56.581308
Epoch:[ 45 2 ] loss: 0.4317944049835205 2022-07-01 08:54:57.015364
Epoch:[ 45 3 ] loss: 0.4342235326766968 2022-07-01 08:54:57.443681
Epoch:[ 45 4 ] loss: 0.4325173795223236 2022-07-01 08:54:57.877515
Epoch:[ 45 5 ] loss: 0.43040940165519714 2022-07-01 08:54:58.304491
Epoch:[ 45 6 ] loss: 0.4313928782939911 2022-07-01 08:54:58.736207
Epoch:[ 45 7 ] loss: 0.4307267963886261 2022-07-01 08:54:59.165066
Epoch:[ 45 8 ] loss: 0.43262824416160583 2022-07-01 08:54:59.599604
Epoch:[ 45 9 ] loss: 0.43231216073036194 2022-07-01 08:55:00.027594
Epoch:[ 45 10 ] loss: 0.43205350637435913 2022-07-01 08:55:00.455514
Epoch:[ 45 11 ] loss: 0.4284137189388275 2022-07-01 08:55:00.884432
Epoch:[ 45 12 ] loss: 0.4311027526855469 2022-07-01 08:55:01.317483
Epoch:[ 45 13 ] loss: 0.4324311316013336 2022-07-01 08:55:01.744665
Epoch:[ 45 14 ] loss: 0.43215540051460266 2022-07-01 08:55:02.173531
Epoch:[ 45 15 ] loss: 0.4327560067176819 2022-07-01 08:55:02.603177
Epoch:[ 45 16 ] loss: 0.4369264841079712 2022-07-01 08:55:07.694859
Epoch:[ 45 17 ] loss: 0.43183380365371704 2022-07-01 08:55:08.121297
Epoch:[ 45 18 ] loss: 0.432365745306015 2022-07-01 08:55:08.562161
Epoch:[ 45 19 ] loss: 0.4291206896305084 2022-07-01 08:55:08.989354
Training_Epoch:[ 45 ] Training_loss: 0.4321022555232048 2022-07-01 08:55:08.989983
learning rate:  0.004096000000000001
val: 1 0.45348355174064636
val: 2 0.445253849029541
val: 3 0.4684607982635498
val: 4 0.45828962326049805
val: 5 0.45257192850112915
val: 6 0.45685845613479614
val: 7 0.4611142873764038
val: 8 0.4552483558654785
val: 9 0.4624461233615875
val: 10 0.47146880626678467
val: 11 0.45592623949050903
val: 12 0.4635360836982727
val: 13 0.45737478137016296
val: 14 0.44507452845573425
val: 15 0.4437226355075836
val: 16 0.46329015493392944
val: 17 0.45658352971076965
val: 18 0.4452715218067169
val: 19 0.46154549717903137
val: 20 0.44635462760925293
val_Epoch:[ 45 ] val_loss: 0.4561937689781189 2022-07-01 08:55:12.608864
start training 2022-07-01 08:55:12.703029
Epoch:[ 46 0 ] loss: 0.4339407682418823 2022-07-01 08:55:27.158423
Epoch:[ 46 1 ] loss: 0.43158093094825745 2022-07-01 08:55:27.614751
Epoch:[ 46 2 ] loss: 0.4308449923992157 2022-07-01 08:55:28.043690
Epoch:[ 46 3 ] loss: 0.42790481448173523 2022-07-01 08:55:28.471037
Epoch:[ 46 4 ] loss: 0.4306274354457855 2022-07-01 08:55:28.902165
Epoch:[ 46 5 ] loss: 0.4273790121078491 2022-07-01 08:55:29.334694
Epoch:[ 46 6 ] loss: 0.4296743869781494 2022-07-01 08:55:29.770979
Epoch:[ 46 7 ] loss: 0.4295403063297272 2022-07-01 08:55:30.198162
Epoch:[ 46 8 ] loss: 0.430806428194046 2022-07-01 08:55:30.632854
Epoch:[ 46 9 ] loss: 0.43105971813201904 2022-07-01 08:55:31.062237
Epoch:[ 46 10 ] loss: 0.43243545293807983 2022-07-01 08:55:31.489990
Epoch:[ 46 11 ] loss: 0.4331129491329193 2022-07-01 08:55:31.922025
Epoch:[ 46 12 ] loss: 0.43296578526496887 2022-07-01 08:55:32.349519
Epoch:[ 46 13 ] loss: 0.42957833409309387 2022-07-01 08:55:32.776945
Epoch:[ 46 14 ] loss: 0.4331681430339813 2022-07-01 08:55:33.206917
Epoch:[ 46 15 ] loss: 0.4292054772377014 2022-07-01 08:55:33.640610
Epoch:[ 46 16 ] loss: 0.4308680593967438 2022-07-01 08:55:38.671650
Epoch:[ 46 17 ] loss: 0.4287831485271454 2022-07-01 08:55:39.105212
Epoch:[ 46 18 ] loss: 0.42954614758491516 2022-07-01 08:55:39.546571
Epoch:[ 46 19 ] loss: 0.43598148226737976 2022-07-01 08:55:39.975712
Training_Epoch:[ 46 ] Training_loss: 0.4309501886367798 2022-07-01 08:55:39.976380
learning rate:  0.004096000000000001
netparams have been saved once 46
val: 1 0.444136381149292
val: 2 0.4515654146671295
val: 3 0.44878649711608887
val: 4 0.44684717059135437
val: 5 0.4378419816493988
val: 6 0.45225629210472107
val: 7 0.4568910002708435
val: 8 0.4570896029472351
val: 9 0.4555323123931885
val: 10 0.4557284712791443
val: 11 0.45486000180244446
val: 12 0.4344494640827179
val: 13 0.45911309123039246
val: 14 0.4547754228115082
val: 15 0.45042839646339417
val: 16 0.4412563443183899
val: 17 0.44798582792282104
val: 18 0.4498482048511505
val: 19 0.4458923637866974
val: 20 0.4364059269428253
val_Epoch:[ 46 ] val_loss: 0.44908450841903685 2022-07-01 08:55:43.754599
start training 2022-07-01 08:55:43.850746
Epoch:[ 47 0 ] loss: 0.4309510588645935 2022-07-01 08:55:58.050055
Epoch:[ 47 1 ] loss: 0.42510396242141724 2022-07-01 08:55:58.804302
Epoch:[ 47 2 ] loss: 0.43189287185668945 2022-07-01 08:55:59.238076
Epoch:[ 47 3 ] loss: 0.4302024245262146 2022-07-01 08:55:59.667064
Epoch:[ 47 4 ] loss: 0.42830193042755127 2022-07-01 08:56:00.101895
Epoch:[ 47 5 ] loss: 0.43275225162506104 2022-07-01 08:56:00.534636
Epoch:[ 47 6 ] loss: 0.43173646926879883 2022-07-01 08:56:00.972004
Epoch:[ 47 7 ] loss: 0.4266163408756256 2022-07-01 08:56:01.398751
Epoch:[ 47 8 ] loss: 0.431974321603775 2022-07-01 08:56:01.825799
Epoch:[ 47 9 ] loss: 0.42984724044799805 2022-07-01 08:56:02.260003
Epoch:[ 47 10 ] loss: 0.4304364025592804 2022-07-01 08:56:02.689422
Epoch:[ 47 11 ] loss: 0.4313470125198364 2022-07-01 08:56:03.124075
Epoch:[ 47 12 ] loss: 0.4304557144641876 2022-07-01 08:56:03.551925
Epoch:[ 47 13 ] loss: 0.43098506331443787 2022-07-01 08:56:03.980504
Epoch:[ 47 14 ] loss: 0.4278501272201538 2022-07-01 08:56:04.407421
Epoch:[ 47 15 ] loss: 0.4311267137527466 2022-07-01 08:56:04.837744
Epoch:[ 47 16 ] loss: 0.4314568042755127 2022-07-01 08:56:10.052750
Epoch:[ 47 17 ] loss: 0.42831602692604065 2022-07-01 08:56:10.481224
Epoch:[ 47 18 ] loss: 0.4331764876842499 2022-07-01 08:56:10.913247
Epoch:[ 47 19 ] loss: 0.43470242619514465 2022-07-01 08:56:11.339790
Training_Epoch:[ 47 ] Training_loss: 0.43046158254146577 2022-07-01 08:56:11.340398
learning rate:  0.004096000000000001
val: 1 0.44498205184936523
val: 2 0.4483615458011627
val: 3 0.4454742670059204
val: 4 0.4559800922870636
val: 5 0.44984671473503113
val: 6 0.45531025528907776
val: 7 0.4427967965602875
val: 8 0.46079394221305847
val: 9 0.44995635747909546
val: 10 0.45664894580841064
val: 11 0.4526256024837494
val: 12 0.44940224289894104
val: 13 0.4599589705467224
val: 14 0.45499470829963684
val: 15 0.44727665185928345
val: 16 0.4535727798938751
val: 17 0.4503099322319031
val: 18 0.47921788692474365
val: 19 0.4537433683872223
val: 20 0.45264798402786255
val_Epoch:[ 47 ] val_loss: 0.45319505482912065 2022-07-01 08:56:14.942391
start training 2022-07-01 08:56:15.039565
Epoch:[ 48 0 ] loss: 0.42999011278152466 2022-07-01 08:56:29.021366
Epoch:[ 48 1 ] loss: 0.42745164036750793 2022-07-01 08:56:29.465254
Epoch:[ 48 2 ] loss: 0.4320310056209564 2022-07-01 08:56:29.905945
Epoch:[ 48 3 ] loss: 0.43116018176078796 2022-07-01 08:56:30.334448
Epoch:[ 48 4 ] loss: 0.42540985345840454 2022-07-01 08:56:30.763653
Epoch:[ 48 5 ] loss: 0.42912212014198303 2022-07-01 08:56:31.192290
Epoch:[ 48 6 ] loss: 0.4261363744735718 2022-07-01 08:56:31.624241
Epoch:[ 48 7 ] loss: 0.4308028817176819 2022-07-01 08:56:32.057774
Epoch:[ 48 8 ] loss: 0.4254817068576813 2022-07-01 08:56:32.486125
Epoch:[ 48 9 ] loss: 0.42781075835227966 2022-07-01 08:56:32.918463
Epoch:[ 48 10 ] loss: 0.42793509364128113 2022-07-01 08:56:33.348014
Epoch:[ 48 11 ] loss: 0.42768052220344543 2022-07-01 08:56:33.782362
Epoch:[ 48 12 ] loss: 0.4280144274234772 2022-07-01 08:56:34.214701
Epoch:[ 48 13 ] loss: 0.4283936023712158 2022-07-01 08:56:34.648978
Epoch:[ 48 14 ] loss: 0.4254954755306244 2022-07-01 08:56:35.075793
Epoch:[ 48 15 ] loss: 0.4306330680847168 2022-07-01 08:56:35.502993
Epoch:[ 48 16 ] loss: 0.42658838629722595 2022-07-01 08:56:40.702815
Epoch:[ 48 17 ] loss: 0.4305698275566101 2022-07-01 08:56:41.517980
Epoch:[ 48 18 ] loss: 0.4256742000579834 2022-07-01 08:56:41.965657
Epoch:[ 48 19 ] loss: 0.43090635538101196 2022-07-01 08:56:42.398237
Training_Epoch:[ 48 ] Training_loss: 0.42836437970399854 2022-07-01 08:56:42.398953
learning rate:  0.004096000000000001
netparams have been saved once 48
val: 1 0.44380083680152893
val: 2 0.44725871086120605
val: 3 0.45427602529525757
val: 4 0.4429037868976593
val: 5 0.45131251215934753
val: 6 0.45115652680397034
val: 7 0.4615132510662079
val: 8 0.4596936106681824
val: 9 0.4413284957408905
val: 10 0.4431053400039673
val: 11 0.4517366290092468
val: 12 0.4650484025478363
val: 13 0.4487997591495514
val: 14 0.4528380334377289
val: 15 0.4537602663040161
val: 16 0.4500320255756378
val: 17 0.4471416771411896
val: 18 0.43165314197540283
val: 19 0.44837555289268494
val: 20 0.44916945695877075
val_Epoch:[ 48 ] val_loss: 0.4497452020645142 2022-07-01 08:56:46.082031
start training 2022-07-01 08:56:46.176314
Epoch:[ 49 0 ] loss: 0.429240882396698 2022-07-01 08:57:00.372056
Epoch:[ 49 1 ] loss: 0.4282838702201843 2022-07-01 08:57:00.851424
Epoch:[ 49 2 ] loss: 0.4259259104728699 2022-07-01 08:57:01.282829
Epoch:[ 49 3 ] loss: 0.42666953802108765 2022-07-01 08:57:01.714661
Epoch:[ 49 4 ] loss: 0.42863160371780396 2022-07-01 08:57:02.143200
Epoch:[ 49 5 ] loss: 0.42972463369369507 2022-07-01 08:57:02.571483
Epoch:[ 49 6 ] loss: 0.42657870054244995 2022-07-01 08:57:02.999760
Epoch:[ 49 7 ] loss: 0.42697983980178833 2022-07-01 08:57:03.430607
Epoch:[ 49 8 ] loss: 0.4277389347553253 2022-07-01 08:57:03.865839
Epoch:[ 49 9 ] loss: 0.4273727834224701 2022-07-01 08:57:04.293804
Epoch:[ 49 10 ] loss: 0.42784711718559265 2022-07-01 08:57:04.720474
Epoch:[ 49 11 ] loss: 0.42602694034576416 2022-07-01 08:57:05.153898
Epoch:[ 49 12 ] loss: 0.4285038411617279 2022-07-01 08:57:05.582465
Epoch:[ 49 13 ] loss: 0.42842140793800354 2022-07-01 08:57:06.010306
Epoch:[ 49 14 ] loss: 0.42858418822288513 2022-07-01 08:57:06.437460
Epoch:[ 49 15 ] loss: 0.43048131465911865 2022-07-01 08:57:06.864440
Epoch:[ 49 16 ] loss: 0.4309643507003784 2022-07-01 08:57:11.682990
Epoch:[ 49 17 ] loss: 0.4287704527378082 2022-07-01 08:57:12.195546
Epoch:[ 49 18 ] loss: 0.42986756563186646 2022-07-01 08:57:12.628222
Epoch:[ 49 19 ] loss: 0.432450532913208 2022-07-01 08:57:13.055832
Training_Epoch:[ 49 ] Training_loss: 0.42845322042703626 2022-07-01 08:57:13.056419
learning rate:  0.004096000000000001
val: 1 0.47074660658836365
val: 2 0.46551355719566345
val: 3 0.46347731351852417
val: 4 0.4537622630596161
val: 5 0.46765655279159546
val: 6 0.46308061480522156
val: 7 0.45822495222091675
val: 8 0.46582546830177307
val: 9 0.4560297429561615
val: 10 0.46818000078201294
val: 11 0.4493877589702606
val: 12 0.46130818128585815
val: 13 0.46357446908950806
val: 14 0.4641130864620209
val: 15 0.4762287437915802
val: 16 0.4631953537464142
val: 17 0.46740493178367615
val: 18 0.4608565866947174
val: 19 0.472743958234787
val: 20 0.4493582546710968
val_Epoch:[ 49 ] val_loss: 0.4630334198474884 2022-07-01 08:57:16.718770
start training 2022-07-01 08:57:16.817568
Epoch:[ 50 0 ] loss: 0.4270593523979187 2022-07-01 08:57:31.400030
Epoch:[ 50 1 ] loss: 0.428096204996109 2022-07-01 08:57:31.828162
Epoch:[ 50 2 ] loss: 0.4284825623035431 2022-07-01 08:57:32.257019
Epoch:[ 50 3 ] loss: 0.4262753129005432 2022-07-01 08:57:32.683540
Epoch:[ 50 4 ] loss: 0.4264180064201355 2022-07-01 08:57:33.116092
Epoch:[ 50 5 ] loss: 0.42703622579574585 2022-07-01 08:57:33.554052
Epoch:[ 50 6 ] loss: 0.42976099252700806 2022-07-01 08:57:33.988099
Epoch:[ 50 7 ] loss: 0.42800483107566833 2022-07-01 08:57:34.422319
Epoch:[ 50 8 ] loss: 0.4319314658641815 2022-07-01 08:57:34.850177
Epoch:[ 50 9 ] loss: 0.4276459515094757 2022-07-01 08:57:35.283826
Epoch:[ 50 10 ] loss: 0.4307308793067932 2022-07-01 08:57:35.711303
Epoch:[ 50 11 ] loss: 0.4279222786426544 2022-07-01 08:57:36.137320
Epoch:[ 50 12 ] loss: 0.4302982985973358 2022-07-01 08:57:36.565635
Epoch:[ 50 13 ] loss: 0.42888957262039185 2022-07-01 08:57:36.995457
Epoch:[ 50 14 ] loss: 0.43039947748184204 2022-07-01 08:57:37.428178
Epoch:[ 50 15 ] loss: 0.4272265136241913 2022-07-01 08:57:37.860612
Epoch:[ 50 16 ] loss: 0.4250892400741577 2022-07-01 08:57:42.921518
Epoch:[ 50 17 ] loss: 0.425885945558548 2022-07-01 08:57:43.349568
Epoch:[ 50 18 ] loss: 0.4277135729789734 2022-07-01 08:57:43.782205
Epoch:[ 50 19 ] loss: 0.4279293417930603 2022-07-01 08:57:44.211324
Training_Epoch:[ 50 ] Training_loss: 0.42813980132341384 2022-07-01 08:57:44.211997
learning rate:  0.004096000000000001
netparams have been saved once 50
val: 1 0.43931150436401367
val: 2 0.45218929648399353
val: 3 0.43788906931877136
val: 4 0.4530740976333618
val: 5 0.4552803933620453
val: 6 0.44035017490386963
val: 7 0.44622647762298584
val: 8 0.4472537338733673
val: 9 0.44244393706321716
val: 10 0.44686028361320496
val: 11 0.4358852803707123
val: 12 0.43769359588623047
val: 13 0.4490635395050049
val: 14 0.4465987980365753
val: 15 0.4468815326690674
val: 16 0.44214317202568054
val: 17 0.4405917525291443
val: 18 0.441062867641449
val: 19 0.43485620617866516
val: 20 0.44743016362190247
val_Epoch:[ 50 ] val_loss: 0.44415429383516314 2022-07-01 08:57:47.951097
start training 2022-07-01 08:57:48.052975
Epoch:[ 51 0 ] loss: 0.4284941554069519 2022-07-01 08:58:01.958549
Epoch:[ 51 1 ] loss: 0.4237368404865265 2022-07-01 08:58:02.406020
Epoch:[ 51 2 ] loss: 0.4274447560310364 2022-07-01 08:58:03.007461
Epoch:[ 51 3 ] loss: 0.4257161021232605 2022-07-01 08:58:03.441520
Epoch:[ 51 4 ] loss: 0.4231936037540436 2022-07-01 08:58:03.868249
Epoch:[ 51 5 ] loss: 0.42371007800102234 2022-07-01 08:58:04.295965
Epoch:[ 51 6 ] loss: 0.4215583801269531 2022-07-01 08:58:04.725002
Epoch:[ 51 7 ] loss: 0.4270613491535187 2022-07-01 08:58:05.152562
Epoch:[ 51 8 ] loss: 0.4283226728439331 2022-07-01 08:58:05.580418
Epoch:[ 51 9 ] loss: 0.42678672075271606 2022-07-01 08:58:06.007996
Epoch:[ 51 10 ] loss: 0.42565232515335083 2022-07-01 08:58:06.437775
Epoch:[ 51 11 ] loss: 0.4243529438972473 2022-07-01 08:58:06.864771
Epoch:[ 51 12 ] loss: 0.4269445240497589 2022-07-01 08:58:07.298991
Epoch:[ 51 13 ] loss: 0.42397427558898926 2022-07-01 08:58:07.728497
Epoch:[ 51 14 ] loss: 0.4283390939235687 2022-07-01 08:58:08.163241
Epoch:[ 51 15 ] loss: 0.42622995376586914 2022-07-01 08:58:08.596545
Epoch:[ 51 16 ] loss: 0.4258343577384949 2022-07-01 08:58:13.980347
Epoch:[ 51 17 ] loss: 0.42383208870887756 2022-07-01 08:58:14.412419
Epoch:[ 51 18 ] loss: 0.424201637506485 2022-07-01 08:58:14.843054
Epoch:[ 51 19 ] loss: 0.4252144992351532 2022-07-01 08:58:15.268991
Training_Epoch:[ 51 ] Training_loss: 0.42553001791238787 2022-07-01 08:58:15.269735
learning rate:  0.0032768000000000007
val: 1 0.4457220733165741
val: 2 0.4481336176395416
val: 3 0.4447513818740845
val: 4 0.4518418312072754
val: 5 0.44347256422042847
val: 6 0.4482503831386566
val: 7 0.4372030794620514
val: 8 0.440204918384552
val: 9 0.4444795846939087
val: 10 0.4390280842781067
val: 11 0.4343988299369812
val: 12 0.4505605101585388
val: 13 0.4415847361087799
val: 14 0.42676711082458496
val: 15 0.43365803360939026
val: 16 0.4420798420906067
val: 17 0.4360472559928894
val: 18 0.44240203499794006
val: 19 0.4303453862667084
val: 20 0.45152872800827026
val_Epoch:[ 51 ] val_loss: 0.4416229993104935 2022-07-01 08:58:18.925013
start training 2022-07-01 08:58:19.022016
Epoch:[ 52 0 ] loss: 0.4206557273864746 2022-07-01 08:58:33.930199
Epoch:[ 52 1 ] loss: 0.42877769470214844 2022-07-01 08:58:34.358363
Epoch:[ 52 2 ] loss: 0.42690518498420715 2022-07-01 08:58:34.785680
Epoch:[ 52 3 ] loss: 0.42445218563079834 2022-07-01 08:58:35.212116
Epoch:[ 52 4 ] loss: 0.4251950979232788 2022-07-01 08:58:35.644487
Epoch:[ 52 5 ] loss: 0.42249515652656555 2022-07-01 08:58:36.076553
Epoch:[ 52 6 ] loss: 0.42476046085357666 2022-07-01 08:58:36.501935
Epoch:[ 52 7 ] loss: 0.42421790957450867 2022-07-01 08:58:36.935983
Epoch:[ 52 8 ] loss: 0.4270614683628082 2022-07-01 08:58:37.364786
Epoch:[ 52 9 ] loss: 0.42329537868499756 2022-07-01 08:58:37.797414
Epoch:[ 52 10 ] loss: 0.42317426204681396 2022-07-01 08:58:38.222864
Epoch:[ 52 11 ] loss: 0.4249620735645294 2022-07-01 08:58:38.650792
Epoch:[ 52 12 ] loss: 0.42524150013923645 2022-07-01 08:58:39.082044
Epoch:[ 52 13 ] loss: 0.42509835958480835 2022-07-01 08:58:39.508433
Epoch:[ 52 14 ] loss: 0.42126941680908203 2022-07-01 08:58:39.935651
Epoch:[ 52 15 ] loss: 0.4276875853538513 2022-07-01 08:58:40.368684
Epoch:[ 52 16 ] loss: 0.4221499264240265 2022-07-01 08:58:45.414707
Epoch:[ 52 17 ] loss: 0.4236171245574951 2022-07-01 08:58:45.842483
Epoch:[ 52 18 ] loss: 0.42458805441856384 2022-07-01 08:58:46.279955
Epoch:[ 52 19 ] loss: 0.42783164978027344 2022-07-01 08:58:46.705897
Training_Epoch:[ 52 ] Training_loss: 0.42467181086540223 2022-07-01 08:58:46.706574
learning rate:  0.0032768000000000007
netparams have been saved once 52
val: 1 0.4468310475349426
val: 2 0.43466439843177795
val: 3 0.44579604268074036
val: 4 0.443965882062912
val: 5 0.4344315826892853
val: 6 0.44911161065101624
val: 7 0.4490845799446106
val: 8 0.43872350454330444
val: 9 0.4326874911785126
val: 10 0.4453246295452118
val: 11 0.4372369647026062
val: 12 0.4403699040412903
val: 13 0.45172277092933655
val: 14 0.43555864691734314
val: 15 0.456678181886673
val: 16 0.4409092366695404
val: 17 0.4399818480014801
val: 18 0.43607857823371887
val: 19 0.44731438159942627
val: 20 0.4388068616390228
val_Epoch:[ 52 ] val_loss: 0.44226390719413755 2022-07-01 08:58:50.369527
start training 2022-07-01 08:58:50.466407
Epoch:[ 53 0 ] loss: 0.42167437076568604 2022-07-01 08:59:05.255048
Epoch:[ 53 1 ] loss: 0.4254826605319977 2022-07-01 08:59:05.683003
Epoch:[ 53 2 ] loss: 0.4240545928478241 2022-07-01 08:59:06.113949
Epoch:[ 53 3 ] loss: 0.4242190420627594 2022-07-01 08:59:06.540281
Epoch:[ 53 4 ] loss: 0.42449551820755005 2022-07-01 08:59:06.968098
Epoch:[ 53 5 ] loss: 0.4228884279727936 2022-07-01 08:59:07.397139
Epoch:[ 53 6 ] loss: 0.42378076910972595 2022-07-01 08:59:07.828926
Epoch:[ 53 7 ] loss: 0.4254415035247803 2022-07-01 08:59:08.254541
Epoch:[ 53 8 ] loss: 0.4226551651954651 2022-07-01 08:59:08.682883
Epoch:[ 53 9 ] loss: 0.42602914571762085 2022-07-01 08:59:09.116141
Epoch:[ 53 10 ] loss: 0.4210554361343384 2022-07-01 08:59:09.547402
Epoch:[ 53 11 ] loss: 0.42383676767349243 2022-07-01 08:59:09.972623
Epoch:[ 53 12 ] loss: 0.42095431685447693 2022-07-01 08:59:10.409073
Epoch:[ 53 13 ] loss: 0.42443448305130005 2022-07-01 08:59:10.838107
Epoch:[ 53 14 ] loss: 0.42630839347839355 2022-07-01 08:59:11.268438
Epoch:[ 53 15 ] loss: 0.4234182834625244 2022-07-01 08:59:11.698277
Epoch:[ 53 16 ] loss: 0.42614489793777466 2022-07-01 08:59:16.463316
Epoch:[ 53 17 ] loss: 0.4240669310092926 2022-07-01 08:59:17.031728
Epoch:[ 53 18 ] loss: 0.4207390546798706 2022-07-01 08:59:17.476496
Epoch:[ 53 19 ] loss: 0.4239199757575989 2022-07-01 08:59:17.907727
Training_Epoch:[ 53 ] Training_loss: 0.4237799867987633 2022-07-01 08:59:17.908341
learning rate:  0.0032768000000000007
val: 1 0.4415346086025238
val: 2 0.43803393840789795
val: 3 0.4497290253639221
val: 4 0.43405723571777344
val: 5 0.4406532049179077
val: 6 0.44673654437065125
val: 7 0.4402564465999603
val: 8 0.45397570729255676
val: 9 0.4487123489379883
val: 10 0.43933072686195374
val: 11 0.44526731967926025
val: 12 0.4553166925907135
val: 13 0.44245219230651855
val: 14 0.45144638419151306
val: 15 0.43623968958854675
val: 16 0.44381776452064514
val: 17 0.45155519247055054
val: 18 0.43868184089660645
val: 19 0.4399318993091583
val: 20 0.4542280435562134
val_Epoch:[ 53 ] val_loss: 0.44459784030914307 2022-07-01 08:59:21.503821
start training 2022-07-01 08:59:21.600506
Epoch:[ 54 0 ] loss: 0.4269801676273346 2022-07-01 08:59:36.238819
Epoch:[ 54 1 ] loss: 0.41965341567993164 2022-07-01 08:59:36.668022
Epoch:[ 54 2 ] loss: 0.4208965301513672 2022-07-01 08:59:37.096999
Epoch:[ 54 3 ] loss: 0.42038729786872864 2022-07-01 08:59:37.526131
Epoch:[ 54 4 ] loss: 0.4222263693809509 2022-07-01 08:59:37.960010
Epoch:[ 54 5 ] loss: 0.4202616810798645 2022-07-01 08:59:38.387702
Epoch:[ 54 6 ] loss: 0.4256575405597687 2022-07-01 08:59:38.820470
Epoch:[ 54 7 ] loss: 0.42197349667549133 2022-07-01 08:59:39.254193
Epoch:[ 54 8 ] loss: 0.42125535011291504 2022-07-01 08:59:39.681055
Epoch:[ 54 9 ] loss: 0.4233660101890564 2022-07-01 08:59:40.109825
Epoch:[ 54 10 ] loss: 0.42673105001449585 2022-07-01 08:59:40.539056
Epoch:[ 54 11 ] loss: 0.42185261845588684 2022-07-01 08:59:40.951174
Epoch:[ 54 12 ] loss: 0.42484548687934875 2022-07-01 08:59:41.366264
Epoch:[ 54 13 ] loss: 0.4221777021884918 2022-07-01 08:59:41.779855
Epoch:[ 54 14 ] loss: 0.4232041537761688 2022-07-01 08:59:42.192755
Epoch:[ 54 15 ] loss: 0.4206792116165161 2022-07-01 08:59:42.599698
Epoch:[ 54 16 ] loss: 0.4221974015235901 2022-07-01 08:59:47.640491
Epoch:[ 54 17 ] loss: 0.4236792027950287 2022-07-01 08:59:48.061684
Epoch:[ 54 18 ] loss: 0.42477747797966003 2022-07-01 08:59:48.497638
Epoch:[ 54 19 ] loss: 0.42406895756721497 2022-07-01 08:59:48.928353
Training_Epoch:[ 54 ] Training_loss: 0.42284355610609053 2022-07-01 08:59:48.929244
learning rate:  0.0032768000000000007
netparams have been saved once 54
val: 1 0.451012521982193
val: 2 0.455358624458313
val: 3 0.44060060381889343
val: 4 0.4473540782928467
val: 5 0.45523884892463684
val: 6 0.43933576345443726
val: 7 0.45362588763237
val: 8 0.44878989458084106
val: 9 0.44378662109375
val: 10 0.44159311056137085
val: 11 0.4358901381492615
val: 12 0.43817877769470215
val: 13 0.44334647059440613
val: 14 0.44017407298088074
val: 15 0.4404021203517914
val: 16 0.4494093656539917
val: 17 0.4414122402667999
val: 18 0.4437818229198456
val: 19 0.4355979859828949
val: 20 0.4405185282230377
val_Epoch:[ 54 ] val_loss: 0.4442703738808632 2022-07-01 08:59:52.714659
start training 2022-07-01 08:59:52.813425
Epoch:[ 55 0 ] loss: 0.42370930314064026 2022-07-01 09:00:07.785250
Epoch:[ 55 1 ] loss: 0.42258206009864807 2022-07-01 09:00:08.218450
Epoch:[ 55 2 ] loss: 0.42608213424682617 2022-07-01 09:00:08.646410
Epoch:[ 55 3 ] loss: 0.42395374178886414 2022-07-01 09:00:09.077545
Epoch:[ 55 4 ] loss: 0.4258376955986023 2022-07-01 09:00:09.514383
Epoch:[ 55 5 ] loss: 0.42676636576652527 2022-07-01 09:00:09.956710
Epoch:[ 55 6 ] loss: 0.4216242730617523 2022-07-01 09:00:10.387408
Epoch:[ 55 7 ] loss: 0.42188483476638794 2022-07-01 09:00:10.823934
Epoch:[ 55 8 ] loss: 0.4238089621067047 2022-07-01 09:00:11.256162
Epoch:[ 55 9 ] loss: 0.42359766364097595 2022-07-01 09:00:11.685773
Epoch:[ 55 10 ] loss: 0.4239068329334259 2022-07-01 09:00:12.119721
Epoch:[ 55 11 ] loss: 0.4245985746383667 2022-07-01 09:00:12.557106
Epoch:[ 55 12 ] loss: 0.42079421877861023 2022-07-01 09:00:12.986034
Epoch:[ 55 13 ] loss: 0.42587336897850037 2022-07-01 09:00:13.416631
Epoch:[ 55 14 ] loss: 0.4217066764831543 2022-07-01 09:00:13.846513
Epoch:[ 55 15 ] loss: 0.42529168725013733 2022-07-01 09:00:14.278609
Epoch:[ 55 16 ] loss: 0.4212000370025635 2022-07-01 09:00:19.248398
Epoch:[ 55 17 ] loss: 0.4212189316749573 2022-07-01 09:00:19.680547
Epoch:[ 55 18 ] loss: 0.42080235481262207 2022-07-01 09:00:20.124122
Epoch:[ 55 19 ] loss: 0.42260241508483887 2022-07-01 09:00:20.556759
Training_Epoch:[ 55 ] Training_loss: 0.4233921065926552 2022-07-01 09:00:20.557470
learning rate:  0.0032768000000000007
val: 1 0.45686274766921997
val: 2 0.4386636018753052
val: 3 0.4472251534461975
val: 4 0.4344976544380188
val: 5 0.4394935667514801
val: 6 0.44562840461730957
val: 7 0.4360155165195465
val: 8 0.43329674005508423
val: 9 0.44847381114959717
val: 10 0.4447229504585266
val: 11 0.4375939667224884
val: 12 0.45064428448677063
val: 13 0.4447247087955475
val: 14 0.4494381248950958
val: 15 0.44488033652305603
val: 16 0.43966615200042725
val: 17 0.44662633538246155
val: 18 0.4377991855144501
val: 19 0.43686026334762573
val: 20 0.43893277645111084
val_Epoch:[ 55 ] val_loss: 0.442602314054966 2022-07-01 09:00:24.214354
start training 2022-07-01 09:00:24.314376
Epoch:[ 56 0 ] loss: 0.42010292410850525 2022-07-01 09:00:38.303469
Epoch:[ 56 1 ] loss: 0.4233270287513733 2022-07-01 09:00:38.932927
Epoch:[ 56 2 ] loss: 0.42057228088378906 2022-07-01 09:00:39.593012
Epoch:[ 56 3 ] loss: 0.42190009355545044 2022-07-01 09:00:40.020723
Epoch:[ 56 4 ] loss: 0.42231324315071106 2022-07-01 09:00:40.458124
Epoch:[ 56 5 ] loss: 0.42196181416511536 2022-07-01 09:00:40.886924
Epoch:[ 56 6 ] loss: 0.42262002825737 2022-07-01 09:00:41.318042
Epoch:[ 56 7 ] loss: 0.42304185032844543 2022-07-01 09:00:41.755255
Epoch:[ 56 8 ] loss: 0.42009711265563965 2022-07-01 09:00:42.182323
Epoch:[ 56 9 ] loss: 0.42292520403862 2022-07-01 09:00:42.615852
Epoch:[ 56 10 ] loss: 0.4211398959159851 2022-07-01 09:00:43.044744
Epoch:[ 56 11 ] loss: 0.4222572147846222 2022-07-01 09:00:43.476310
Epoch:[ 56 12 ] loss: 0.42214909195899963 2022-07-01 09:00:43.916761
Epoch:[ 56 13 ] loss: 0.41886019706726074 2022-07-01 09:00:44.351507
Epoch:[ 56 14 ] loss: 0.42558273673057556 2022-07-01 09:00:44.783167
Epoch:[ 56 15 ] loss: 0.4243626296520233 2022-07-01 09:00:45.212516
Epoch:[ 56 16 ] loss: 0.42354151606559753 2022-07-01 09:00:50.572524
Epoch:[ 56 17 ] loss: 0.4240095615386963 2022-07-01 09:00:51.001555
Epoch:[ 56 18 ] loss: 0.42272278666496277 2022-07-01 09:00:51.439454
Epoch:[ 56 19 ] loss: 0.42236077785491943 2022-07-01 09:00:51.866363
Training_Epoch:[ 56 ] Training_loss: 0.4222923994064331 2022-07-01 09:00:51.867060
learning rate:  0.0032768000000000007
netparams have been saved once 56
val: 1 0.4465862810611725
val: 2 0.44658929109573364
val: 3 0.44646304845809937
val: 4 0.44710418581962585
val: 5 0.44317424297332764
val: 6 0.4436821937561035
val: 7 0.43194013833999634
val: 8 0.44609567523002625
val: 9 0.44794583320617676
val: 10 0.44736698269844055
val: 11 0.4434214234352112
val: 12 0.4473797082901001
val: 13 0.44445905089378357
val: 14 0.44206899404525757
val: 15 0.4531993865966797
val: 16 0.43598583340644836
val: 17 0.4559744596481323
val: 18 0.4394938051700592
val: 19 0.4370245635509491
val: 20 0.4393216073513031
val_Epoch:[ 56 ] val_loss: 0.44426383525133134 2022-07-01 09:00:55.634086
start training 2022-07-01 09:00:55.731005
Epoch:[ 57 0 ] loss: 0.42205610871315 2022-07-01 09:01:09.528817
Epoch:[ 57 1 ] loss: 0.42026570439338684 2022-07-01 09:01:10.004854
Epoch:[ 57 2 ] loss: 0.4215267598628998 2022-07-01 09:01:10.457728
Epoch:[ 57 3 ] loss: 0.4177236258983612 2022-07-01 09:01:10.890718
Epoch:[ 57 4 ] loss: 0.4231610596179962 2022-07-01 09:01:11.324102
Epoch:[ 57 5 ] loss: 0.41995519399642944 2022-07-01 09:01:11.757180
Epoch:[ 57 6 ] loss: 0.426296204328537 2022-07-01 09:01:12.195376
Epoch:[ 57 7 ] loss: 0.42335736751556396 2022-07-01 09:01:12.632435
Epoch:[ 57 8 ] loss: 0.4232344627380371 2022-07-01 09:01:13.061145
Epoch:[ 57 9 ] loss: 0.4227190613746643 2022-07-01 09:01:13.493002
Epoch:[ 57 10 ] loss: 0.4213256537914276 2022-07-01 09:01:13.921517
Epoch:[ 57 11 ] loss: 0.4213062822818756 2022-07-01 09:01:14.352961
Epoch:[ 57 12 ] loss: 0.4235118627548218 2022-07-01 09:01:14.789239
Epoch:[ 57 13 ] loss: 0.42313358187675476 2022-07-01 09:01:15.229452
Epoch:[ 57 14 ] loss: 0.42267823219299316 2022-07-01 09:01:15.664971
Epoch:[ 57 15 ] loss: 0.42013269662857056 2022-07-01 09:01:16.097594
Epoch:[ 57 16 ] loss: 0.419838011264801 2022-07-01 09:01:21.345228
Epoch:[ 57 17 ] loss: 0.42261266708374023 2022-07-01 09:01:21.781592
Epoch:[ 57 18 ] loss: 0.4223416745662689 2022-07-01 09:01:22.215001
Epoch:[ 57 19 ] loss: 0.4195623993873596 2022-07-01 09:01:22.646867
Training_Epoch:[ 57 ] Training_loss: 0.42183693051338195 2022-07-01 09:01:22.647572
learning rate:  0.0032768000000000007
val: 1 0.4430472254753113
val: 2 0.45181378722190857
val: 3 0.4617452323436737
val: 4 0.44215258955955505
val: 5 0.45008957386016846
val: 6 0.4497753977775574
val: 7 0.43383464217185974
val: 8 0.44587406516075134
val: 9 0.44724881649017334
val: 10 0.44083356857299805
val: 11 0.4422614872455597
val: 12 0.44448843598365784
val: 13 0.4556281864643097
val: 14 0.4583803415298462
val: 15 0.44183486700057983
val: 16 0.44572561979293823
val: 17 0.46085166931152344
val: 18 0.4532318413257599
val: 19 0.4488673806190491
val: 20 0.4390173554420471
val_Epoch:[ 57 ] val_loss: 0.4478351041674614 2022-07-01 09:01:26.359135
start training 2022-07-01 09:01:26.455860
Epoch:[ 58 0 ] loss: 0.4232422113418579 2022-07-01 09:01:40.405848
Epoch:[ 58 1 ] loss: 0.4214855432510376 2022-07-01 09:01:41.076143
Epoch:[ 58 2 ] loss: 0.4199604094028473 2022-07-01 09:01:41.510721
Epoch:[ 58 3 ] loss: 0.4177270531654358 2022-07-01 09:01:41.941501
Epoch:[ 58 4 ] loss: 0.41805416345596313 2022-07-01 09:01:42.372693
Epoch:[ 58 5 ] loss: 0.42108815908432007 2022-07-01 09:01:42.805854
Epoch:[ 58 6 ] loss: 0.4201037585735321 2022-07-01 09:01:43.236910
Epoch:[ 58 7 ] loss: 0.42242076992988586 2022-07-01 09:01:43.668150
Epoch:[ 58 8 ] loss: 0.42004865407943726 2022-07-01 09:01:44.101399
Epoch:[ 58 9 ] loss: 0.4206462502479553 2022-07-01 09:01:44.530410
Epoch:[ 58 10 ] loss: 0.4181431829929352 2022-07-01 09:01:44.960720
Epoch:[ 58 11 ] loss: 0.4225641191005707 2022-07-01 09:01:45.394808
Epoch:[ 58 12 ] loss: 0.42772912979125977 2022-07-01 09:01:45.827859
Epoch:[ 58 13 ] loss: 0.41813573241233826 2022-07-01 09:01:46.264539
Epoch:[ 58 14 ] loss: 0.42302224040031433 2022-07-01 09:01:46.699945
Epoch:[ 58 15 ] loss: 0.4230690896511078 2022-07-01 09:01:47.134390
Epoch:[ 58 16 ] loss: 0.4209144413471222 2022-07-01 09:01:52.436998
Epoch:[ 58 17 ] loss: 0.4237368404865265 2022-07-01 09:01:52.864987
Epoch:[ 58 18 ] loss: 0.4224914014339447 2022-07-01 09:01:53.301451
Epoch:[ 58 19 ] loss: 0.42135530710220337 2022-07-01 09:01:53.727213
Training_Epoch:[ 58 ] Training_loss: 0.42129692286252973 2022-07-01 09:01:53.727847
learning rate:  0.0032768000000000007
netparams have been saved once 58
val: 1 0.4540861248970032
val: 2 0.4408157169818878
val: 3 0.44387587904930115
val: 4 0.4444091320037842
val: 5 0.4479656517505646
val: 6 0.44266653060913086
val: 7 0.441828191280365
val: 8 0.4448772370815277
val: 9 0.4391997754573822
val: 10 0.4411218464374542
val: 11 0.4335629343986511
val: 12 0.43365755677223206
val: 13 0.44020718336105347
val: 14 0.44908374547958374
val: 15 0.43660956621170044
val: 16 0.44461652636528015
val: 17 0.4473115801811218
val: 18 0.434837281703949
val: 19 0.4409083127975464
val: 20 0.4445847272872925
val_Epoch:[ 58 ] val_loss: 0.44231127500534057 2022-07-01 09:01:57.454322
start training 2022-07-01 09:01:57.552196
Epoch:[ 59 0 ] loss: 0.42259401082992554 2022-07-01 09:02:12.144138
Epoch:[ 59 1 ] loss: 0.41790467500686646 2022-07-01 09:02:12.573924
Epoch:[ 59 2 ] loss: 0.4195273518562317 2022-07-01 09:02:13.007230
Epoch:[ 59 3 ] loss: 0.4193735122680664 2022-07-01 09:02:13.433682
Epoch:[ 59 4 ] loss: 0.41965875029563904 2022-07-01 09:02:13.865234
Epoch:[ 59 5 ] loss: 0.42394331097602844 2022-07-01 09:02:14.293224
Epoch:[ 59 6 ] loss: 0.41724446415901184 2022-07-01 09:02:14.719642
Epoch:[ 59 7 ] loss: 0.4178975522518158 2022-07-01 09:02:15.153684
Epoch:[ 59 8 ] loss: 0.420744925737381 2022-07-01 09:02:15.581626
Epoch:[ 59 9 ] loss: 0.4207088351249695 2022-07-01 09:02:16.011607
Epoch:[ 59 10 ] loss: 0.4209353029727936 2022-07-01 09:02:16.443761
Epoch:[ 59 11 ] loss: 0.4204617440700531 2022-07-01 09:02:16.872758
Epoch:[ 59 12 ] loss: 0.42193546891212463 2022-07-01 09:02:17.301760
Epoch:[ 59 13 ] loss: 0.4206688404083252 2022-07-01 09:02:17.729154
Epoch:[ 59 14 ] loss: 0.42313072085380554 2022-07-01 09:02:18.159150
Epoch:[ 59 15 ] loss: 0.4190711975097656 2022-07-01 09:02:18.593651
Epoch:[ 59 16 ] loss: 0.42109185457229614 2022-07-01 09:02:23.675914
Epoch:[ 59 17 ] loss: 0.42127764225006104 2022-07-01 09:02:24.102698
Epoch:[ 59 18 ] loss: 0.4230026602745056 2022-07-01 09:02:24.548253
Epoch:[ 59 19 ] loss: 0.42055007815361023 2022-07-01 09:02:24.976993
Training_Epoch:[ 59 ] Training_loss: 0.4205861449241638 2022-07-01 09:02:24.977664
learning rate:  0.0032768000000000007
val: 1 0.4507281482219696
val: 2 0.45067098736763
val: 3 0.44747254252433777
val: 4 0.4552841782569885
val: 5 0.44459056854248047
val: 6 0.45817139744758606
val: 7 0.45553112030029297
val: 8 0.44754841923713684
val: 9 0.45250681042671204
val: 10 0.45578402280807495
val: 11 0.4384235739707947
val: 12 0.45566821098327637
val: 13 0.45411956310272217
val: 14 0.4431757926940918
val: 15 0.44966796040534973
val: 16 0.444972962141037
val: 17 0.45618799328804016
val: 18 0.4443925619125366
val: 19 0.4388977885246277
val: 20 0.4385474622249603
val_Epoch:[ 59 ] val_loss: 0.4491171032190323 2022-07-01 09:02:28.635861
start training 2022-07-01 09:02:28.734688
Epoch:[ 60 0 ] loss: 0.4231405258178711 2022-07-01 09:02:42.644888
Epoch:[ 60 1 ] loss: 0.4204576313495636 2022-07-01 09:02:43.112532
Epoch:[ 60 2 ] loss: 0.4182814359664917 2022-07-01 09:02:43.569597
Epoch:[ 60 3 ] loss: 0.4203927516937256 2022-07-01 09:02:44.003748
Epoch:[ 60 4 ] loss: 0.42166292667388916 2022-07-01 09:02:44.431408
Epoch:[ 60 5 ] loss: 0.41765281558036804 2022-07-01 09:02:44.860827
Epoch:[ 60 6 ] loss: 0.4189225137233734 2022-07-01 09:02:45.294680
Epoch:[ 60 7 ] loss: 0.41728630661964417 2022-07-01 09:02:45.725918
Epoch:[ 60 8 ] loss: 0.4192254841327667 2022-07-01 09:02:46.161909
Epoch:[ 60 9 ] loss: 0.4228339195251465 2022-07-01 09:02:46.596344
Epoch:[ 60 10 ] loss: 0.4217230975627899 2022-07-01 09:02:47.026164
Epoch:[ 60 11 ] loss: 0.419307678937912 2022-07-01 09:02:47.461404
Epoch:[ 60 12 ] loss: 0.41839027404785156 2022-07-01 09:02:47.890061
Epoch:[ 60 13 ] loss: 0.41785678267478943 2022-07-01 09:02:48.319674
Epoch:[ 60 14 ] loss: 0.4191944897174835 2022-07-01 09:02:48.754746
Epoch:[ 60 15 ] loss: 0.41927921772003174 2022-07-01 09:02:49.185376
Epoch:[ 60 16 ] loss: 0.42135143280029297 2022-07-01 09:02:54.707281
Epoch:[ 60 17 ] loss: 0.41979625821113586 2022-07-01 09:02:55.138380
Epoch:[ 60 18 ] loss: 0.42006921768188477 2022-07-01 09:02:55.575107
Epoch:[ 60 19 ] loss: 0.4197520315647125 2022-07-01 09:02:56.004343
Training_Epoch:[ 60 ] Training_loss: 0.4198288396000862 2022-07-01 09:02:56.004922
learning rate:  0.0032768000000000007
netparams have been saved once 60
val: 1 0.44673576951026917
val: 2 0.44440758228302
val: 3 0.44286927580833435
val: 4 0.43880927562713623
val: 5 0.4441371262073517
val: 6 0.43609973788261414
val: 7 0.4410865008831024
val: 8 0.44248664379119873
val: 9 0.4322669804096222
val: 10 0.44421717524528503
val: 11 0.4316340386867523
val: 12 0.4314004182815552
val: 13 0.4464902877807617
val: 14 0.43007901310920715
val: 15 0.4485100209712982
val: 16 0.4405963122844696
val: 17 0.4445040822029114
val: 18 0.4426552951335907
val: 19 0.44490838050842285
val: 20 0.4509514570236206
val_Epoch:[ 60 ] val_loss: 0.44124226868152616 2022-07-01 09:02:59.680551
start training 2022-07-01 09:02:59.778801
Epoch:[ 61 0 ] loss: 0.41629624366760254 2022-07-01 09:03:14.165362
Epoch:[ 61 1 ] loss: 0.4179711937904358 2022-07-01 09:03:14.591235
Epoch:[ 61 2 ] loss: 0.4169417917728424 2022-07-01 09:03:15.019365
Epoch:[ 61 3 ] loss: 0.41773343086242676 2022-07-01 09:03:15.447066
Epoch:[ 61 4 ] loss: 0.4163828492164612 2022-07-01 09:03:15.874646
Epoch:[ 61 5 ] loss: 0.41554608941078186 2022-07-01 09:03:16.307253
Epoch:[ 61 6 ] loss: 0.4192987084388733 2022-07-01 09:03:16.737836
Epoch:[ 61 7 ] loss: 0.417711466550827 2022-07-01 09:03:17.163818
Epoch:[ 61 8 ] loss: 0.41728320717811584 2022-07-01 09:03:17.588675
Epoch:[ 61 9 ] loss: 0.41956546902656555 2022-07-01 09:03:18.023601
Epoch:[ 61 10 ] loss: 0.4202998876571655 2022-07-01 09:03:18.452029
Epoch:[ 61 11 ] loss: 0.4180777668952942 2022-07-01 09:03:18.880148
Epoch:[ 61 12 ] loss: 0.41604292392730713 2022-07-01 09:03:19.312477
Epoch:[ 61 13 ] loss: 0.421148419380188 2022-07-01 09:03:19.745518
Epoch:[ 61 14 ] loss: 0.4162847697734833 2022-07-01 09:03:20.171517
Epoch:[ 61 15 ] loss: 0.4156879782676697 2022-07-01 09:03:20.603138
Epoch:[ 61 16 ] loss: 0.4168850779533386 2022-07-01 09:03:25.763533
Epoch:[ 61 17 ] loss: 0.4145139157772064 2022-07-01 09:03:26.191128
Epoch:[ 61 18 ] loss: 0.41616323590278625 2022-07-01 09:03:26.621509
Epoch:[ 61 19 ] loss: 0.4186675250530243 2022-07-01 09:03:27.052305
Training_Epoch:[ 61 ] Training_loss: 0.4174250975251198 2022-07-01 09:03:27.052927
learning rate:  0.002621440000000001
val: 1 0.4445549547672272
val: 2 0.43572181463241577
val: 3 0.4565775692462921
val: 4 0.4470588266849518
val: 5 0.43845388293266296
val: 6 0.4428762197494507
val: 7 0.4427625238895416
val: 8 0.43382540345191956
val: 9 0.4375596344470978
val: 10 0.4471869468688965
val: 11 0.44734397530555725
val: 12 0.4322512149810791
val: 13 0.4490337669849396
val: 14 0.44103604555130005
val: 15 0.43585434556007385
val: 16 0.44454917311668396
val: 17 0.44059205055236816
val: 18 0.4400003254413605
val: 19 0.4398394525051117
val: 20 0.44512632489204407
val_Epoch:[ 61 ] val_loss: 0.4421102225780487 2022-07-01 09:03:30.632269
start training 2022-07-01 09:03:30.731223
Epoch:[ 62 0 ] loss: 0.4151759445667267 2022-07-01 09:03:44.934599
Epoch:[ 62 1 ] loss: 0.41477566957473755 2022-07-01 09:03:45.380290
Epoch:[ 62 2 ] loss: 0.4148792326450348 2022-07-01 09:03:45.807797
Epoch:[ 62 3 ] loss: 0.4147069454193115 2022-07-01 09:03:46.239753
Epoch:[ 62 4 ] loss: 0.4152834117412567 2022-07-01 09:03:46.675188
Epoch:[ 62 5 ] loss: 0.4177033603191376 2022-07-01 09:03:47.105575
Epoch:[ 62 6 ] loss: 0.4140750467777252 2022-07-01 09:03:47.539151
Epoch:[ 62 7 ] loss: 0.4201901853084564 2022-07-01 09:03:47.972090
Epoch:[ 62 8 ] loss: 0.41750088334083557 2022-07-01 09:03:48.400714
Epoch:[ 62 9 ] loss: 0.417187362909317 2022-07-01 09:03:48.829130
Epoch:[ 62 10 ] loss: 0.4187636971473694 2022-07-01 09:03:49.264396
Epoch:[ 62 11 ] loss: 0.42022132873535156 2022-07-01 09:03:49.694566
Epoch:[ 62 12 ] loss: 0.417126327753067 2022-07-01 09:03:50.124961
Epoch:[ 62 13 ] loss: 0.4184073209762573 2022-07-01 09:03:50.559567
Epoch:[ 62 14 ] loss: 0.4157389998435974 2022-07-01 09:03:50.986300
Epoch:[ 62 15 ] loss: 0.419921338558197 2022-07-01 09:03:51.420087
Epoch:[ 62 16 ] loss: 0.41562971472740173 2022-07-01 09:03:56.512594
Epoch:[ 62 17 ] loss: 0.421107679605484 2022-07-01 09:03:56.944522
Epoch:[ 62 18 ] loss: 0.4165457487106323 2022-07-01 09:03:57.382682
Epoch:[ 62 19 ] loss: 0.41721123456954956 2022-07-01 09:03:57.813197
Training_Epoch:[ 62 ] Training_loss: 0.41710757166147233 2022-07-01 09:03:57.813882
learning rate:  0.002621440000000001
netparams have been saved once 62
val: 1 0.44336754083633423
val: 2 0.45125314593315125
val: 3 0.4426705539226532
val: 4 0.4538741409778595
val: 5 0.43340638279914856
val: 6 0.45077455043792725
val: 7 0.45130667090415955
val: 8 0.44292598962783813
val: 9 0.44615450501441956
val: 10 0.4585953652858734
val: 11 0.4455079138278961
val: 12 0.4460102617740631
val: 13 0.45660778880119324
val: 14 0.4399831295013428
val: 15 0.4454452395439148
val: 16 0.44337716698646545
val: 17 0.43864715099334717
val: 18 0.45666781067848206
val: 19 0.4500100612640381
val: 20 0.4448654055595398
val_Epoch:[ 62 ] val_loss: 0.44707253873348235 2022-07-01 09:04:01.479179
start training 2022-07-01 09:04:01.576375
Epoch:[ 63 0 ] loss: 0.4161278009414673 2022-07-01 09:04:15.573030
Epoch:[ 63 1 ] loss: 0.41371628642082214 2022-07-01 09:04:16.048871
Epoch:[ 63 2 ] loss: 0.4139236509799957 2022-07-01 09:04:16.498723
Epoch:[ 63 3 ] loss: 0.41560983657836914 2022-07-01 09:04:16.933762
Epoch:[ 63 4 ] loss: 0.4176328480243683 2022-07-01 09:04:17.365025
Epoch:[ 63 5 ] loss: 0.41812366247177124 2022-07-01 09:04:17.795789
Epoch:[ 63 6 ] loss: 0.41664960980415344 2022-07-01 09:04:18.225030
Epoch:[ 63 7 ] loss: 0.4160734713077545 2022-07-01 09:04:18.657465
Epoch:[ 63 8 ] loss: 0.4143716096878052 2022-07-01 09:04:19.088094
Epoch:[ 63 9 ] loss: 0.41424083709716797 2022-07-01 09:04:19.517204
Epoch:[ 63 10 ] loss: 0.4165235757827759 2022-07-01 09:04:19.944813
Epoch:[ 63 11 ] loss: 0.41736456751823425 2022-07-01 09:04:20.374992
Epoch:[ 63 12 ] loss: 0.420220285654068 2022-07-01 09:04:20.806064
Epoch:[ 63 13 ] loss: 0.41957059502601624 2022-07-01 09:04:21.241410
Epoch:[ 63 14 ] loss: 0.41782158613204956 2022-07-01 09:04:21.674739
Epoch:[ 63 15 ] loss: 0.4191606938838959 2022-07-01 09:04:22.105889
Epoch:[ 63 16 ] loss: 0.41680908203125 2022-07-01 09:04:27.077131
Epoch:[ 63 17 ] loss: 0.4191502630710602 2022-07-01 09:04:27.653891
Epoch:[ 63 18 ] loss: 0.41701123118400574 2022-07-01 09:04:28.088574
Epoch:[ 63 19 ] loss: 0.4181068241596222 2022-07-01 09:04:28.518804
Training_Epoch:[ 63 ] Training_loss: 0.4169104158878326 2022-07-01 09:04:28.519402
learning rate:  0.002621440000000001
val: 1 0.44955000281333923
val: 2 0.43992850184440613
val: 3 0.43798545002937317
val: 4 0.4392760396003723
val: 5 0.4580673575401306
val: 6 0.44726279377937317
val: 7 0.4388852119445801
val: 8 0.4431391656398773
val: 9 0.4512942433357239
val: 10 0.44201433658599854
val: 11 0.4323873221874237
val: 12 0.4445973038673401
val: 13 0.4516429901123047
val: 14 0.4367060959339142
val: 15 0.45557934045791626
val: 16 0.4440181255340576
val: 17 0.44429266452789307
val: 18 0.44297099113464355
val: 19 0.4369874596595764
val: 20 0.4467470049858093
val_Epoch:[ 63 ] val_loss: 0.4441666200757027 2022-07-01 09:04:32.144954
start training 2022-07-01 09:04:32.242789
Epoch:[ 64 0 ] loss: 0.4157290756702423 2022-07-01 09:04:46.543066
Epoch:[ 64 1 ] loss: 0.41768309473991394 2022-07-01 09:04:47.280175
Epoch:[ 64 2 ] loss: 0.41634881496429443 2022-07-01 09:04:47.707436
Epoch:[ 64 3 ] loss: 0.4171012043952942 2022-07-01 09:04:48.134040
Epoch:[ 64 4 ] loss: 0.41681867837905884 2022-07-01 09:04:48.560493
Epoch:[ 64 5 ] loss: 0.4155592918395996 2022-07-01 09:04:48.995841
Epoch:[ 64 6 ] loss: 0.41828638315200806 2022-07-01 09:04:49.429973
Epoch:[ 64 7 ] loss: 0.41598400473594666 2022-07-01 09:04:49.858527
Epoch:[ 64 8 ] loss: 0.4164619445800781 2022-07-01 09:04:50.285806
Epoch:[ 64 9 ] loss: 0.4207676947116852 2022-07-01 09:04:50.718301
Epoch:[ 64 10 ] loss: 0.41581571102142334 2022-07-01 09:04:51.150547
Epoch:[ 64 11 ] loss: 0.4156476557254791 2022-07-01 09:04:51.576308
Epoch:[ 64 12 ] loss: 0.41953960061073303 2022-07-01 09:04:52.010562
Epoch:[ 64 13 ] loss: 0.4176237881183624 2022-07-01 09:04:52.439684
Epoch:[ 64 14 ] loss: 0.41520750522613525 2022-07-01 09:04:52.869847
Epoch:[ 64 15 ] loss: 0.41936245560646057 2022-07-01 09:04:53.301135
Epoch:[ 64 16 ] loss: 0.41447004675865173 2022-07-01 09:04:58.500528
Epoch:[ 64 17 ] loss: 0.41785380244255066 2022-07-01 09:04:59.577900
Epoch:[ 64 18 ] loss: 0.4172763526439667 2022-07-01 09:05:00.009247
Epoch:[ 64 19 ] loss: 0.4163876175880432 2022-07-01 09:05:00.438487
Training_Epoch:[ 64 ] Training_loss: 0.41699623614549636 2022-07-01 09:05:00.439090
learning rate:  0.002621440000000001
netparams have been saved once 64
val: 1 0.43522194027900696
val: 2 0.44576701521873474
val: 3 0.44646915793418884
val: 4 0.4485454261302948
val: 5 0.43931764364242554
val: 6 0.4338052570819855
val: 7 0.43671587109565735
val: 8 0.4379367232322693
val: 9 0.45026859641075134
val: 10 0.4419272840023041
val: 11 0.43783143162727356
val: 12 0.44439852237701416
val: 13 0.44279685616493225
val: 14 0.44569745659828186
val: 15 0.4372294545173645
val: 16 0.44484251737594604
val: 17 0.44308510422706604
val: 18 0.4431414008140564
val: 19 0.4426301121711731
val: 20 0.4423657953739166
val_Epoch:[ 64 ] val_loss: 0.44199967831373216 2022-07-01 09:05:04.102206
start training 2022-07-01 09:05:04.200107
Epoch:[ 65 0 ] loss: 0.4175666570663452 2022-07-01 09:05:17.999996
Epoch:[ 65 1 ] loss: 0.41462787985801697 2022-07-01 09:05:18.533107
Epoch:[ 65 2 ] loss: 0.4134574234485626 2022-07-01 09:05:19.041441
Epoch:[ 65 3 ] loss: 0.41628918051719666 2022-07-01 09:05:19.467905
Epoch:[ 65 4 ] loss: 0.4141671359539032 2022-07-01 09:05:19.893716
Epoch:[ 65 5 ] loss: 0.4171171486377716 2022-07-01 09:05:20.320654
Epoch:[ 65 6 ] loss: 0.4126420021057129 2022-07-01 09:05:20.751816
Epoch:[ 65 7 ] loss: 0.4161166250705719 2022-07-01 09:05:21.179481
Epoch:[ 65 8 ] loss: 0.41368287801742554 2022-07-01 09:05:21.607052
Epoch:[ 65 9 ] loss: 0.41414356231689453 2022-07-01 09:05:22.039242
Epoch:[ 65 10 ] loss: 0.41552138328552246 2022-07-01 09:05:22.467804
Epoch:[ 65 11 ] loss: 0.41734033823013306 2022-07-01 09:05:22.899177
Epoch:[ 65 12 ] loss: 0.4166438579559326 2022-07-01 09:05:23.326794
Epoch:[ 65 13 ] loss: 0.41584330797195435 2022-07-01 09:05:23.754803
Epoch:[ 65 14 ] loss: 0.41747206449508667 2022-07-01 09:05:24.188250
Epoch:[ 65 15 ] loss: 0.4149933159351349 2022-07-01 09:05:24.625132
Epoch:[ 65 16 ] loss: 0.41923558712005615 2022-07-01 09:05:30.036599
Epoch:[ 65 17 ] loss: 0.4185433089733124 2022-07-01 09:05:30.462198
Epoch:[ 65 18 ] loss: 0.418012410402298 2022-07-01 09:05:30.891818
Epoch:[ 65 19 ] loss: 0.4162561595439911 2022-07-01 09:05:31.321016
Training_Epoch:[ 65 ] Training_loss: 0.41598361134529116 2022-07-01 09:05:31.321677
learning rate:  0.002621440000000001
val: 1 0.43429213762283325
val: 2 0.43857434391975403
val: 3 0.4435122609138489
val: 4 0.448500394821167
val: 5 0.4543760418891907
val: 6 0.4443182945251465
val: 7 0.4462123513221741
val: 8 0.4446386396884918
val: 9 0.45127004384994507
val: 10 0.43400871753692627
val: 11 0.44983506202697754
val: 12 0.4368205666542053
val: 13 0.4408615827560425
val: 14 0.4392703175544739
val: 15 0.442455917596817
val: 16 0.4489111304283142
val: 17 0.43705904483795166
val: 18 0.4550008475780487
val: 19 0.43437275290489197
val: 20 0.4374079704284668
val_Epoch:[ 65 ] val_loss: 0.44308492094278334 2022-07-01 09:05:34.988254
start training 2022-07-01 09:05:35.088693
Epoch:[ 66 0 ] loss: 0.4146641492843628 2022-07-01 09:05:49.101005
Epoch:[ 66 1 ] loss: 0.41323497891426086 2022-07-01 09:05:49.994092
Epoch:[ 66 2 ] loss: 0.41535505652427673 2022-07-01 09:05:50.421223
Epoch:[ 66 3 ] loss: 0.4160017669200897 2022-07-01 09:05:50.846549
Epoch:[ 66 4 ] loss: 0.4130661189556122 2022-07-01 09:05:51.273486
Epoch:[ 66 5 ] loss: 0.41844871640205383 2022-07-01 09:05:51.707313
Epoch:[ 66 6 ] loss: 0.4141533374786377 2022-07-01 09:05:52.137648
Epoch:[ 66 7 ] loss: 0.4178459048271179 2022-07-01 09:05:52.566649
Epoch:[ 66 8 ] loss: 0.4138351380825043 2022-07-01 09:05:52.998863
Epoch:[ 66 9 ] loss: 0.4164354205131531 2022-07-01 09:05:53.418517
Epoch:[ 66 10 ] loss: 0.41649091243743896 2022-07-01 09:05:53.832598
Epoch:[ 66 11 ] loss: 0.4180632531642914 2022-07-01 09:05:54.245913
Epoch:[ 66 12 ] loss: 0.415755957365036 2022-07-01 09:05:54.669244
Epoch:[ 66 13 ] loss: 0.4173566401004791 2022-07-01 09:05:55.084112
Epoch:[ 66 14 ] loss: 0.41624489426612854 2022-07-01 09:05:55.494791
Epoch:[ 66 15 ] loss: 0.4191036522388458 2022-07-01 09:05:55.905263
Epoch:[ 66 16 ] loss: 0.4170759320259094 2022-07-01 09:06:00.845421
Epoch:[ 66 17 ] loss: 0.41408655047416687 2022-07-01 09:06:01.304004
Epoch:[ 66 18 ] loss: 0.4190393090248108 2022-07-01 09:06:01.735068
Epoch:[ 66 19 ] loss: 0.41793301701545715 2022-07-01 09:06:02.165680
Training_Epoch:[ 66 ] Training_loss: 0.4162095353007317 2022-07-01 09:06:02.166425
learning rate:  0.002621440000000001
netparams have been saved once 66
val: 1 0.43796414136886597
val: 2 0.43852949142456055
val: 3 0.4414072632789612
val: 4 0.4353272318840027
val: 5 0.4330943524837494
val: 6 0.43895453214645386
val: 7 0.44300079345703125
val: 8 0.4415748417377472
val: 9 0.44123324751853943
val: 10 0.45018792152404785
val: 11 0.4356560707092285
val: 12 0.43863147497177124
val: 13 0.43951934576034546
val: 14 0.4480242133140564
val: 15 0.448916494846344
val: 16 0.4389459490776062
val: 17 0.44562020897865295
val: 18 0.44202765822410583
val: 19 0.44271981716156006
val: 20 0.4528931677341461
val_Epoch:[ 66 ] val_loss: 0.4417114108800888 2022-07-01 09:06:05.843829
start training 2022-07-01 09:06:05.940518
Epoch:[ 67 0 ] loss: 0.41923514008522034 2022-07-01 09:06:20.170203
Epoch:[ 67 1 ] loss: 0.41150692105293274 2022-07-01 09:06:20.625392
Epoch:[ 67 2 ] loss: 0.4169274568557739 2022-07-01 09:06:21.053817
Epoch:[ 67 3 ] loss: 0.4161836504936218 2022-07-01 09:06:21.488376
Epoch:[ 67 4 ] loss: 0.4147934317588806 2022-07-01 09:06:21.915119
Epoch:[ 67 5 ] loss: 0.4162929058074951 2022-07-01 09:06:22.341260
Epoch:[ 67 6 ] loss: 0.41756781935691833 2022-07-01 09:06:22.773141
Epoch:[ 67 7 ] loss: 0.4147879183292389 2022-07-01 09:06:23.204385
Epoch:[ 67 8 ] loss: 0.4132504463195801 2022-07-01 09:06:23.632591
Epoch:[ 67 9 ] loss: 0.4146116077899933 2022-07-01 09:06:24.065739
Epoch:[ 67 10 ] loss: 0.4147317707538605 2022-07-01 09:06:24.496204
Epoch:[ 67 11 ] loss: 0.41649654507637024 2022-07-01 09:06:24.921275
Epoch:[ 67 12 ] loss: 0.41436710953712463 2022-07-01 09:06:25.348679
Epoch:[ 67 13 ] loss: 0.4150383174419403 2022-07-01 09:06:25.774801
Epoch:[ 67 14 ] loss: 0.4136127829551697 2022-07-01 09:06:26.205996
Epoch:[ 67 15 ] loss: 0.41702109575271606 2022-07-01 09:06:26.640752
Epoch:[ 67 16 ] loss: 0.41153189539909363 2022-07-01 09:06:32.135208
Epoch:[ 67 17 ] loss: 0.41489177942276 2022-07-01 09:06:32.560624
Epoch:[ 67 18 ] loss: 0.4166557192802429 2022-07-01 09:06:32.989378
Epoch:[ 67 19 ] loss: 0.41660383343696594 2022-07-01 09:06:33.418320
Training_Epoch:[ 67 ] Training_loss: 0.415305407345295 2022-07-01 09:06:33.418954
learning rate:  0.002621440000000001
val: 1 0.441440612077713
val: 2 0.44590166211128235
val: 3 0.4390927255153656
val: 4 0.45777204632759094
val: 5 0.44663307070732117
val: 6 0.4505331814289093
val: 7 0.43310442566871643
val: 8 0.44953012466430664
val: 9 0.43621188402175903
val: 10 0.4494973123073578
val: 11 0.44839638471603394
val: 12 0.45838662981987
val: 13 0.4433458149433136
val: 14 0.4356347918510437
val: 15 0.43947213888168335
val: 16 0.45245063304901123
val: 17 0.4461737871170044
val: 18 0.44681671261787415
val: 19 0.45300161838531494
val: 20 0.4613580107688904
val_Epoch:[ 67 ] val_loss: 0.4467376783490181 2022-07-01 09:06:37.140554
start training 2022-07-01 09:06:37.241743
Epoch:[ 68 0 ] loss: 0.4167121648788452 2022-07-01 09:06:51.915881
Epoch:[ 68 1 ] loss: 0.4149222671985626 2022-07-01 09:06:52.348272
Epoch:[ 68 2 ] loss: 0.41501155495643616 2022-07-01 09:06:52.777534
Epoch:[ 68 3 ] loss: 0.4109611511230469 2022-07-01 09:06:53.223967
Epoch:[ 68 4 ] loss: 0.414364218711853 2022-07-01 09:06:53.657118
Epoch:[ 68 5 ] loss: 0.4167851209640503 2022-07-01 09:06:54.089564
Epoch:[ 68 6 ] loss: 0.41115620732307434 2022-07-01 09:06:54.523983
Epoch:[ 68 7 ] loss: 0.4139997065067291 2022-07-01 09:06:54.949160
Epoch:[ 68 8 ] loss: 0.4138518273830414 2022-07-01 09:06:55.374733
Epoch:[ 68 9 ] loss: 0.41348955035209656 2022-07-01 09:06:55.802112
Epoch:[ 68 10 ] loss: 0.41324976086616516 2022-07-01 09:06:56.230919
Epoch:[ 68 11 ] loss: 0.4128400385379791 2022-07-01 09:06:56.658481
Epoch:[ 68 12 ] loss: 0.41411876678466797 2022-07-01 09:06:57.089463
Epoch:[ 68 13 ] loss: 0.41707995533943176 2022-07-01 09:06:57.515375
Epoch:[ 68 14 ] loss: 0.41430217027664185 2022-07-01 09:06:57.947613
Epoch:[ 68 15 ] loss: 0.4152021110057831 2022-07-01 09:06:58.373488
Epoch:[ 68 16 ] loss: 0.41626912355422974 2022-07-01 09:07:03.556265
Epoch:[ 68 17 ] loss: 0.413453608751297 2022-07-01 09:07:03.986445
Epoch:[ 68 18 ] loss: 0.4152195155620575 2022-07-01 09:07:04.417605
Epoch:[ 68 19 ] loss: 0.4125114977359772 2022-07-01 09:07:04.848454
Training_Epoch:[ 68 ] Training_loss: 0.4142750158905983 2022-07-01 09:07:04.849107
learning rate:  0.002621440000000001
netparams have been saved once 68
val: 1 0.4337545335292816
val: 2 0.4431130588054657
val: 3 0.4481301009654999
val: 4 0.4362815320491791
val: 5 0.44715091586112976
val: 6 0.43680065870285034
val: 7 0.4477181136608124
val: 8 0.45451077818870544
val: 9 0.44095104932785034
val: 10 0.4487392008304596
val: 11 0.43733713030815125
val: 12 0.4423855245113373
val: 13 0.44097980856895447
val: 14 0.44472870230674744
val: 15 0.43122604489326477
val: 16 0.43200427293777466
val: 17 0.4425913393497467
val: 18 0.4403940737247467
val: 19 0.44632551074028015
val: 20 0.4352838099002838
val_Epoch:[ 68 ] val_loss: 0.4415203079581261 2022-07-01 09:07:08.640397
start training 2022-07-01 09:07:08.741322
Epoch:[ 69 0 ] loss: 0.4132539629936218 2022-07-01 09:07:23.088388
Epoch:[ 69 1 ] loss: 0.4141784608364105 2022-07-01 09:07:23.538934
Epoch:[ 69 2 ] loss: 0.4125119745731354 2022-07-01 09:07:23.964949
Epoch:[ 69 3 ] loss: 0.41162076592445374 2022-07-01 09:07:24.398154
Epoch:[ 69 4 ] loss: 0.4123189151287079 2022-07-01 09:07:24.831704
Epoch:[ 69 5 ] loss: 0.4123607575893402 2022-07-01 09:07:25.264263
Epoch:[ 69 6 ] loss: 0.4150099456310272 2022-07-01 09:07:25.691475
Epoch:[ 69 7 ] loss: 0.4124968945980072 2022-07-01 09:07:26.123460
Epoch:[ 69 8 ] loss: 0.4118780493736267 2022-07-01 09:07:26.552700
Epoch:[ 69 9 ] loss: 0.41084399819374084 2022-07-01 09:07:26.979238
Epoch:[ 69 10 ] loss: 0.41097044944763184 2022-07-01 09:07:27.406627
Epoch:[ 69 11 ] loss: 0.41419848799705505 2022-07-01 09:07:27.836716
Epoch:[ 69 12 ] loss: 0.41322192549705505 2022-07-01 09:07:28.269715
Epoch:[ 69 13 ] loss: 0.41164740920066833 2022-07-01 09:07:28.704535
Epoch:[ 69 14 ] loss: 0.4129124581813812 2022-07-01 09:07:29.131693
Epoch:[ 69 15 ] loss: 0.41266241669654846 2022-07-01 09:07:29.557688
Epoch:[ 69 16 ] loss: 0.41317811608314514 2022-07-01 09:07:34.472593
Epoch:[ 69 17 ] loss: 0.4161792993545532 2022-07-01 09:07:34.900141
Epoch:[ 69 18 ] loss: 0.41320499777793884 2022-07-01 09:07:35.336810
Epoch:[ 69 19 ] loss: 0.4137941896915436 2022-07-01 09:07:35.764516
Training_Epoch:[ 69 ] Training_loss: 0.4129221737384796 2022-07-01 09:07:35.765185
learning rate:  0.002621440000000001
val: 1 0.4370688796043396
val: 2 0.44554534554481506
val: 3 0.4473448395729065
val: 4 0.4451325535774231
val: 5 0.43873247504234314
val: 6 0.44105613231658936
val: 7 0.43592917919158936
val: 8 0.44760313630104065
val: 9 0.44424185156822205
val: 10 0.43785402178764343
val: 11 0.43488824367523193
val: 12 0.4464394748210907
val: 13 0.44111168384552
val: 14 0.43959182500839233
val: 15 0.4490264356136322
val: 16 0.4390088617801666
val: 17 0.4389016330242157
val: 18 0.4526945948600769
val: 19 0.4403741657733917
val: 20 0.4495090842247009
val_Epoch:[ 69 ] val_loss: 0.4426027208566666 2022-07-01 09:07:39.370304
start training 2022-07-01 09:07:39.471627
Epoch:[ 70 0 ] loss: 0.4124838709831238 2022-07-01 09:07:54.104000
Epoch:[ 70 1 ] loss: 0.4125107526779175 2022-07-01 09:07:54.531379
Epoch:[ 70 2 ] loss: 0.413754940032959 2022-07-01 09:07:54.957512
Epoch:[ 70 3 ] loss: 0.4108305275440216 2022-07-01 09:07:55.389570
Epoch:[ 70 4 ] loss: 0.4137532114982605 2022-07-01 09:07:55.819712
Epoch:[ 70 5 ] loss: 0.4118613600730896 2022-07-01 09:07:56.248814
Epoch:[ 70 6 ] loss: 0.4105273485183716 2022-07-01 09:07:56.680585
Epoch:[ 70 7 ] loss: 0.41296079754829407 2022-07-01 09:07:57.105710
Epoch:[ 70 8 ] loss: 0.41213929653167725 2022-07-01 09:07:57.532538
Epoch:[ 70 9 ] loss: 0.41479888558387756 2022-07-01 09:07:57.958659
Epoch:[ 70 10 ] loss: 0.41039082407951355 2022-07-01 09:07:58.384415
Epoch:[ 70 11 ] loss: 0.41263389587402344 2022-07-01 09:07:58.813285
Epoch:[ 70 12 ] loss: 0.41138091683387756 2022-07-01 09:07:59.245904
Epoch:[ 70 13 ] loss: 0.4112227261066437 2022-07-01 09:07:59.675544
Epoch:[ 70 14 ] loss: 0.4136652648448944 2022-07-01 09:08:00.106722
Epoch:[ 70 15 ] loss: 0.41125553846359253 2022-07-01 09:08:00.538412
Epoch:[ 70 16 ] loss: 0.4140155613422394 2022-07-01 09:08:05.744705
Epoch:[ 70 17 ] loss: 0.41309264302253723 2022-07-01 09:08:06.170287
Epoch:[ 70 18 ] loss: 0.41528910398483276 2022-07-01 09:08:06.601598
Epoch:[ 70 19 ] loss: 0.4135890603065491 2022-07-01 09:08:07.029562
Training_Epoch:[ 70 ] Training_loss: 0.4126078262925148 2022-07-01 09:08:07.030175
learning rate:  0.002621440000000001
netparams have been saved once 70
val: 1 0.45132970809936523
val: 2 0.434602290391922
val: 3 0.44272929430007935
val: 4 0.4354175627231598
val: 5 0.4319940507411957
val: 6 0.4502013027667999
val: 7 0.4503708779811859
val: 8 0.4445015788078308
val: 9 0.4465261399745941
val: 10 0.44727638363838196
val: 11 0.4428563117980957
val: 12 0.43400004506111145
val: 13 0.4272998571395874
val: 14 0.42951700091362
val: 15 0.44903403520584106
val: 16 0.4443094730377197
val: 17 0.4316295087337494
val: 18 0.45607224106788635
val: 19 0.4420372545719147
val: 20 0.4400752782821655
val_Epoch:[ 70 ] val_loss: 0.4415890097618103 2022-07-01 09:08:10.798997
start training 2022-07-01 09:08:10.897900
Epoch:[ 71 0 ] loss: 0.41208454966545105 2022-07-01 09:08:25.646339
Epoch:[ 71 1 ] loss: 0.40908730030059814 2022-07-01 09:08:26.077478
Epoch:[ 71 2 ] loss: 0.414872407913208 2022-07-01 09:08:26.507073
Epoch:[ 71 3 ] loss: 0.41512060165405273 2022-07-01 09:08:26.938258
Epoch:[ 71 4 ] loss: 0.4120747148990631 2022-07-01 09:08:27.369663
Epoch:[ 71 5 ] loss: 0.4105660617351532 2022-07-01 09:08:27.799854
Epoch:[ 71 6 ] loss: 0.4135337173938751 2022-07-01 09:08:28.229219
Epoch:[ 71 7 ] loss: 0.4120664894580841 2022-07-01 09:08:28.655832
Epoch:[ 71 8 ] loss: 0.409627228975296 2022-07-01 09:08:29.082105
Epoch:[ 71 9 ] loss: 0.4088027775287628 2022-07-01 09:08:29.509105
Epoch:[ 71 10 ] loss: 0.40982505679130554 2022-07-01 09:08:29.936268
Epoch:[ 71 11 ] loss: 0.40990665555000305 2022-07-01 09:08:30.361769
Epoch:[ 71 12 ] loss: 0.4083646833896637 2022-07-01 09:08:30.790021
Epoch:[ 71 13 ] loss: 0.4119322597980499 2022-07-01 09:08:31.223690
Epoch:[ 71 14 ] loss: 0.41220685839653015 2022-07-01 09:08:31.650354
Epoch:[ 71 15 ] loss: 0.41326621174812317 2022-07-01 09:08:32.082679
Epoch:[ 71 16 ] loss: 0.4110439419746399 2022-07-01 09:08:37.141675
Epoch:[ 71 17 ] loss: 0.40954750776290894 2022-07-01 09:08:37.570654
Epoch:[ 71 18 ] loss: 0.41192084550857544 2022-07-01 09:08:38.003537
Epoch:[ 71 19 ] loss: 0.41059428453445435 2022-07-01 09:08:38.432406
Training_Epoch:[ 71 ] Training_loss: 0.41132220774888995 2022-07-01 09:08:38.433059
learning rate:  0.002097152000000001
val: 1 0.4422074258327484
val: 2 0.44706857204437256
val: 3 0.4451262652873993
val: 4 0.4453926086425781
val: 5 0.4218483865261078
val: 6 0.4361519515514374
val: 7 0.4407522678375244
val: 8 0.45221441984176636
val: 9 0.447154700756073
val: 10 0.44509291648864746
val: 11 0.4496665298938751
val: 12 0.4505946636199951
val: 13 0.4401630461215973
val: 14 0.4343086779117584
val: 15 0.4438716769218445
val: 16 0.45133453607559204
val: 17 0.4431816339492798
val: 18 0.44184455275535583
val: 19 0.43624183535575867
val: 20 0.4345065951347351
val_Epoch:[ 71 ] val_loss: 0.44243616312742234 2022-07-01 09:08:42.107971
start training 2022-07-01 09:08:42.210639
Epoch:[ 72 0 ] loss: 0.40764379501342773 2022-07-01 09:08:57.163893
Epoch:[ 72 1 ] loss: 0.4098905324935913 2022-07-01 09:08:57.598938
Epoch:[ 72 2 ] loss: 0.40668579936027527 2022-07-01 09:08:58.032559
Epoch:[ 72 3 ] loss: 0.409706711769104 2022-07-01 09:08:58.458561
Epoch:[ 72 4 ] loss: 0.41350290179252625 2022-07-01 09:08:58.889734
Epoch:[ 72 5 ] loss: 0.40656930208206177 2022-07-01 09:08:59.316204
Epoch:[ 72 6 ] loss: 0.41112634539604187 2022-07-01 09:08:59.748790
Epoch:[ 72 7 ] loss: 0.4119552671909332 2022-07-01 09:09:00.182776
Epoch:[ 72 8 ] loss: 0.4130840301513672 2022-07-01 09:09:00.610943
Epoch:[ 72 9 ] loss: 0.40986722707748413 2022-07-01 09:09:01.040955
Epoch:[ 72 10 ] loss: 0.4121555685997009 2022-07-01 09:09:01.466818
Epoch:[ 72 11 ] loss: 0.4089600145816803 2022-07-01 09:09:01.898878
Epoch:[ 72 12 ] loss: 0.409429669380188 2022-07-01 09:09:02.328920
Epoch:[ 72 13 ] loss: 0.4114995300769806 2022-07-01 09:09:02.756614
Epoch:[ 72 14 ] loss: 0.41210442781448364 2022-07-01 09:09:03.183017
Epoch:[ 72 15 ] loss: 0.41134271025657654 2022-07-01 09:09:03.609084
Epoch:[ 72 16 ] loss: 0.41065263748168945 2022-07-01 09:09:08.619338
Epoch:[ 72 17 ] loss: 0.40908387303352356 2022-07-01 09:09:09.045322
Epoch:[ 72 18 ] loss: 0.41121017932891846 2022-07-01 09:09:09.474767
Epoch:[ 72 19 ] loss: 0.4120114743709564 2022-07-01 09:09:09.900278
Training_Epoch:[ 72 ] Training_loss: 0.41042409986257555 2022-07-01 09:09:09.900926
learning rate:  0.002097152000000001
netparams have been saved once 72
val: 1 0.44700565934181213
val: 2 0.43551456928253174
val: 3 0.4521990120410919
val: 4 0.4445626437664032
val: 5 0.4595606029033661
val: 6 0.43491053581237793
val: 7 0.4463931620121002
val: 8 0.43323034048080444
val: 9 0.43714606761932373
val: 10 0.44476068019866943
val: 11 0.45278283953666687
val: 12 0.4517205059528351
val: 13 0.434461772441864
val: 14 0.45060980319976807
val: 15 0.4600287675857544
val: 16 0.4492553174495697
val: 17 0.43489718437194824
val: 18 0.4531714916229248
val: 19 0.44422972202301025
val: 20 0.44586631655693054
val_Epoch:[ 72 ] val_loss: 0.4456153497099876 2022-07-01 09:09:13.616840
start training 2022-07-01 09:09:13.718129
Epoch:[ 73 0 ] loss: 0.4104488492012024 2022-07-01 09:09:28.402091
Epoch:[ 73 1 ] loss: 0.4060163199901581 2022-07-01 09:09:28.835861
Epoch:[ 73 2 ] loss: 0.4114207625389099 2022-07-01 09:09:29.263739
Epoch:[ 73 3 ] loss: 0.4121067523956299 2022-07-01 09:09:29.690018
Epoch:[ 73 4 ] loss: 0.41281622648239136 2022-07-01 09:09:30.123103
Epoch:[ 73 5 ] loss: 0.4086935222148895 2022-07-01 09:09:30.550095
Epoch:[ 73 6 ] loss: 0.4141367971897125 2022-07-01 09:09:30.975407
Epoch:[ 73 7 ] loss: 0.4094696044921875 2022-07-01 09:09:31.405825
Epoch:[ 73 8 ] loss: 0.4122505486011505 2022-07-01 09:09:31.833673
Epoch:[ 73 9 ] loss: 0.4104737341403961 2022-07-01 09:09:32.268030
Epoch:[ 73 10 ] loss: 0.4097997546195984 2022-07-01 09:09:32.694716
Epoch:[ 73 11 ] loss: 0.415116548538208 2022-07-01 09:09:33.127373
Epoch:[ 73 12 ] loss: 0.4101383686065674 2022-07-01 09:09:33.553776
Epoch:[ 73 13 ] loss: 0.4145199656486511 2022-07-01 09:09:33.986011
Epoch:[ 73 14 ] loss: 0.40676504373550415 2022-07-01 09:09:34.414772
Epoch:[ 73 15 ] loss: 0.40706944465637207 2022-07-01 09:09:34.843549
Epoch:[ 73 16 ] loss: 0.4096915125846863 2022-07-01 09:09:39.761699
Epoch:[ 73 17 ] loss: 0.41213053464889526 2022-07-01 09:09:40.188858
Epoch:[ 73 18 ] loss: 0.4114977717399597 2022-07-01 09:09:40.634864
Epoch:[ 73 19 ] loss: 0.41072583198547363 2022-07-01 09:09:41.060292
Training_Epoch:[ 73 ] Training_loss: 0.41076439470052717 2022-07-01 09:09:41.060929
learning rate:  0.002097152000000001
val: 1 0.4360276758670807
val: 2 0.43818768858909607
val: 3 0.44697728753089905
val: 4 0.43759268522262573
val: 5 0.44543522596359253
val: 6 0.43964236974716187
val: 7 0.44604140520095825
val: 8 0.4478670358657837
val: 9 0.4469037652015686
val: 10 0.4314796030521393
val: 11 0.43879374861717224
val: 12 0.4438227117061615
val: 13 0.4373338520526886
val: 14 0.4366346597671509
val: 15 0.440500944852829
val: 16 0.4477473497390747
val: 17 0.4446953535079956
val: 18 0.4484092891216278
val: 19 0.4555685222148895
val: 20 0.4328712224960327
val_Epoch:[ 73 ] val_loss: 0.4421266198158264 2022-07-01 09:09:44.719700
start training 2022-07-01 09:09:44.821487
Epoch:[ 74 0 ] loss: 0.40804389119148254 2022-07-01 09:09:59.064407
Epoch:[ 74 1 ] loss: 0.4062753915786743 2022-07-01 09:09:59.515769
Epoch:[ 74 2 ] loss: 0.4088285267353058 2022-07-01 09:09:59.943126
Epoch:[ 74 3 ] loss: 0.41132256388664246 2022-07-01 09:10:00.378090
Epoch:[ 74 4 ] loss: 0.4111037254333496 2022-07-01 09:10:00.810501
Epoch:[ 74 5 ] loss: 0.4096672832965851 2022-07-01 09:10:01.238571
Epoch:[ 74 6 ] loss: 0.41167935729026794 2022-07-01 09:10:01.667441
Epoch:[ 74 7 ] loss: 0.41006404161453247 2022-07-01 09:10:02.093769
Epoch:[ 74 8 ] loss: 0.4076371490955353 2022-07-01 09:10:02.502895
Epoch:[ 74 9 ] loss: 0.4107762575149536 2022-07-01 09:10:02.912367
Epoch:[ 74 10 ] loss: 0.4069914221763611 2022-07-01 09:10:03.320768
Epoch:[ 74 11 ] loss: 0.41524261236190796 2022-07-01 09:10:03.726804
Epoch:[ 74 12 ] loss: 0.411428302526474 2022-07-01 09:10:04.141119
Epoch:[ 74 13 ] loss: 0.4101303815841675 2022-07-01 09:10:04.556344
Epoch:[ 74 14 ] loss: 0.4099003076553345 2022-07-01 09:10:04.968315
Epoch:[ 74 15 ] loss: 0.41062963008880615 2022-07-01 09:10:05.382669
Epoch:[ 74 16 ] loss: 0.4103145897388458 2022-07-01 09:10:10.626454
Epoch:[ 74 17 ] loss: 0.4123898446559906 2022-07-01 09:10:11.047672
Epoch:[ 74 18 ] loss: 0.4110003709793091 2022-07-01 09:10:11.462356
Epoch:[ 74 19 ] loss: 0.4109897315502167 2022-07-01 09:10:11.869483
Training_Epoch:[ 74 ] Training_loss: 0.41022076904773713 2022-07-01 09:10:11.870260
learning rate:  0.002097152000000001
netparams have been saved once 74
val: 1 0.44513848423957825
val: 2 0.4436229169368744
val: 3 0.4557585120201111
val: 4 0.4455118179321289
val: 5 0.4330897331237793
val: 6 0.4508073329925537
val: 7 0.4483258128166199
val: 8 0.4383919835090637
val: 9 0.4398387670516968
val: 10 0.4471777677536011
val: 11 0.439186692237854
val: 12 0.4487250745296478
val: 13 0.44559404253959656
val: 14 0.448675274848938
val: 15 0.4430295526981354
val: 16 0.4458470344543457
val: 17 0.4373553395271301
val: 18 0.43759885430336
val: 19 0.4325715899467468
val: 20 0.4401722848415375
val_Epoch:[ 74 ] val_loss: 0.4433209434151649 2022-07-01 09:10:15.636871
start training 2022-07-01 09:10:15.740093
Epoch:[ 75 0 ] loss: 0.41057485342025757 2022-07-01 09:10:30.618406
Epoch:[ 75 1 ] loss: 0.40578708052635193 2022-07-01 09:10:31.049603
Epoch:[ 75 2 ] loss: 0.4090079963207245 2022-07-01 09:10:31.483628
Epoch:[ 75 3 ] loss: 0.4090915620326996 2022-07-01 09:10:31.910481
Epoch:[ 75 4 ] loss: 0.40926945209503174 2022-07-01 09:10:32.338114
Epoch:[ 75 5 ] loss: 0.40890493988990784 2022-07-01 09:10:32.766249
Epoch:[ 75 6 ] loss: 0.4081866443157196 2022-07-01 09:10:33.192922
Epoch:[ 75 7 ] loss: 0.4100208878517151 2022-07-01 09:10:33.626062
Epoch:[ 75 8 ] loss: 0.40899786353111267 2022-07-01 09:10:34.053063
Epoch:[ 75 9 ] loss: 0.4074218273162842 2022-07-01 09:10:34.480498
Epoch:[ 75 10 ] loss: 0.40872082114219666 2022-07-01 09:10:34.907148
Epoch:[ 75 11 ] loss: 0.41139718890190125 2022-07-01 09:10:35.334377
Epoch:[ 75 12 ] loss: 0.40854617953300476 2022-07-01 09:10:35.760510
Epoch:[ 75 13 ] loss: 0.4104624092578888 2022-07-01 09:10:36.193195
Epoch:[ 75 14 ] loss: 0.40866225957870483 2022-07-01 09:10:36.618610
Epoch:[ 75 15 ] loss: 0.41030797362327576 2022-07-01 09:10:37.048776
Epoch:[ 75 16 ] loss: 0.40720924735069275 2022-07-01 09:10:42.036448
Epoch:[ 75 17 ] loss: 0.4107477068901062 2022-07-01 09:10:42.469286
Epoch:[ 75 18 ] loss: 0.4124893844127655 2022-07-01 09:10:42.898754
Epoch:[ 75 19 ] loss: 0.4116508662700653 2022-07-01 09:10:43.325129
Training_Epoch:[ 75 ] Training_loss: 0.4093728572130203 2022-07-01 09:10:43.325786
learning rate:  0.002097152000000001
val: 1 0.440099835395813
val: 2 0.45713120698928833
val: 3 0.45043542981147766
val: 4 0.445746511220932
val: 5 0.4532555341720581
val: 6 0.4547097086906433
val: 7 0.44428831338882446
val: 8 0.45089974999427795
val: 9 0.4536307752132416
val: 10 0.4407751262187958
val: 11 0.4459695518016815
val: 12 0.44389334321022034
val: 13 0.44969087839126587
val: 14 0.44943416118621826
val: 15 0.4533396363258362
val: 16 0.4539254903793335
val: 17 0.4466696083545685
val: 18 0.46253693103790283
val: 19 0.4573822617530823
val: 20 0.45258915424346924
val_Epoch:[ 75 ] val_loss: 0.4503201603889465 2022-07-01 09:10:46.906583
start training 2022-07-01 09:10:47.006476
Epoch:[ 76 0 ] loss: 0.40941694378852844 2022-07-01 09:11:01.456522
Epoch:[ 76 1 ] loss: 0.41138020157814026 2022-07-01 09:11:01.973380
Epoch:[ 76 2 ] loss: 0.4116749167442322 2022-07-01 09:11:02.405372
Epoch:[ 76 3 ] loss: 0.41229307651519775 2022-07-01 09:11:02.831425
Epoch:[ 76 4 ] loss: 0.4133780598640442 2022-07-01 09:11:03.258606
Epoch:[ 76 5 ] loss: 0.4087226986885071 2022-07-01 09:11:03.684492
Epoch:[ 76 6 ] loss: 0.411629855632782 2022-07-01 09:11:04.115738
Epoch:[ 76 7 ] loss: 0.4095241129398346 2022-07-01 09:11:04.548595
Epoch:[ 76 8 ] loss: 0.41016536951065063 2022-07-01 09:11:04.974951
Epoch:[ 76 9 ] loss: 0.40997880697250366 2022-07-01 09:11:05.404839
Epoch:[ 76 10 ] loss: 0.4130978286266327 2022-07-01 09:11:05.832938
Epoch:[ 76 11 ] loss: 0.40735647082328796 2022-07-01 09:11:06.262101
Epoch:[ 76 12 ] loss: 0.4135057330131531 2022-07-01 09:11:06.687795
Epoch:[ 76 13 ] loss: 0.4064815938472748 2022-07-01 09:11:07.119191
Epoch:[ 76 14 ] loss: 0.40702322125434875 2022-07-01 09:11:07.545551
Epoch:[ 76 15 ] loss: 0.4097861349582672 2022-07-01 09:11:07.977446
Epoch:[ 76 16 ] loss: 0.4128805994987488 2022-07-01 09:11:13.302565
Epoch:[ 76 17 ] loss: 0.40744107961654663 2022-07-01 09:11:13.732262
Epoch:[ 76 18 ] loss: 0.40975522994995117 2022-07-01 09:11:14.165495
Epoch:[ 76 19 ] loss: 0.40828725695610046 2022-07-01 09:11:14.591698
Training_Epoch:[ 76 ] Training_loss: 0.41018895953893664 2022-07-01 09:11:14.592369
learning rate:  0.002097152000000001
netparams have been saved once 76
val: 1 0.44743600487709045
val: 2 0.45180878043174744
val: 3 0.43100273609161377
val: 4 0.4373217821121216
val: 5 0.44166672229766846
val: 6 0.44553783535957336
val: 7 0.4525316655635834
val: 8 0.4501124918460846
val: 9 0.4463164806365967
val: 10 0.4565984308719635
val: 11 0.43616071343421936
val: 12 0.4480434060096741
val: 13 0.44972747564315796
val: 14 0.4391171932220459
val: 15 0.46224337816238403
val: 16 0.4556725323200226
val: 17 0.44277018308639526
val: 18 0.4459649622440338
val: 19 0.44901061058044434
val: 20 0.43048834800720215
val_Epoch:[ 76 ] val_loss: 0.44597658663988116 2022-07-01 09:11:18.246901
start training 2022-07-01 09:11:18.350298
Epoch:[ 77 0 ] loss: 0.4095795452594757 2022-07-01 09:11:32.697407
Epoch:[ 77 1 ] loss: 0.4055019021034241 2022-07-01 09:11:33.156024
Epoch:[ 77 2 ] loss: 0.4090960919857025 2022-07-01 09:11:33.583039
Epoch:[ 77 3 ] loss: 0.4089672565460205 2022-07-01 09:11:34.011860
Epoch:[ 77 4 ] loss: 0.40850839018821716 2022-07-01 09:11:34.446239
Epoch:[ 77 5 ] loss: 0.40532875061035156 2022-07-01 09:11:34.882084
Epoch:[ 77 6 ] loss: 0.4093640446662903 2022-07-01 09:11:35.317615
Epoch:[ 77 7 ] loss: 0.4089812636375427 2022-07-01 09:11:35.754555
Epoch:[ 77 8 ] loss: 0.40936386585235596 2022-07-01 09:11:36.190019
Epoch:[ 77 9 ] loss: 0.4083871841430664 2022-07-01 09:11:36.617853
Epoch:[ 77 10 ] loss: 0.40801307559013367 2022-07-01 09:11:37.049798
Epoch:[ 77 11 ] loss: 0.4099639356136322 2022-07-01 09:11:37.486903
Epoch:[ 77 12 ] loss: 0.40890565514564514 2022-07-01 09:11:37.915667
Epoch:[ 77 13 ] loss: 0.4097415804862976 2022-07-01 09:11:38.346532
Epoch:[ 77 14 ] loss: 0.40997856855392456 2022-07-01 09:11:38.774377
Epoch:[ 77 15 ] loss: 0.4086975157260895 2022-07-01 09:11:39.203761
Epoch:[ 77 16 ] loss: 0.40735843777656555 2022-07-01 09:11:44.542457
Epoch:[ 77 17 ] loss: 0.4092540740966797 2022-07-01 09:11:44.970994
Epoch:[ 77 18 ] loss: 0.40834254026412964 2022-07-01 09:11:45.409879
Epoch:[ 77 19 ] loss: 0.4086577296257019 2022-07-01 09:11:45.836428
Training_Epoch:[ 77 ] Training_loss: 0.4085995703935623 2022-07-01 09:11:45.837052
learning rate:  0.002097152000000001
val: 1 0.4397139251232147
val: 2 0.4368200898170471
val: 3 0.4336899518966675
val: 4 0.44197845458984375
val: 5 0.4367208182811737
val: 6 0.4374947249889374
val: 7 0.43400338292121887
val: 8 0.4508195221424103
val: 9 0.44630634784698486
val: 10 0.4299315810203552
val: 11 0.4354039430618286
val: 12 0.4438377022743225
val: 13 0.44618281722068787
val: 14 0.452839732170105
val: 15 0.4356096684932709
val: 16 0.4429819583892822
val: 17 0.4473700225353241
val: 18 0.4518508017063141
val: 19 0.43422290682792664
val: 20 0.4420807957649231
val_Epoch:[ 77 ] val_loss: 0.4409929573535919 2022-07-01 09:11:49.499819
start training 2022-07-01 09:11:49.604954
Epoch:[ 78 0 ] loss: 0.4063345193862915 2022-07-01 09:12:04.190976
Epoch:[ 78 1 ] loss: 0.4058952033519745 2022-07-01 09:12:04.654393
Epoch:[ 78 2 ] loss: 0.40746739506721497 2022-07-01 09:12:05.092094
Epoch:[ 78 3 ] loss: 0.4075956642627716 2022-07-01 09:12:05.522571
Epoch:[ 78 4 ] loss: 0.40706098079681396 2022-07-01 09:12:05.958234
Epoch:[ 78 5 ] loss: 0.40481317043304443 2022-07-01 09:12:06.392837
Epoch:[ 78 6 ] loss: 0.405590683221817 2022-07-01 09:12:06.824434
Epoch:[ 78 7 ] loss: 0.4076726734638214 2022-07-01 09:12:07.255121
Epoch:[ 78 8 ] loss: 0.40740618109703064 2022-07-01 09:12:07.687545
Epoch:[ 78 9 ] loss: 0.41040942072868347 2022-07-01 09:12:08.117244
Epoch:[ 78 10 ] loss: 0.40797314047813416 2022-07-01 09:12:08.552210
Epoch:[ 78 11 ] loss: 0.40787962079048157 2022-07-01 09:12:08.982474
Epoch:[ 78 12 ] loss: 0.4090983271598816 2022-07-01 09:12:09.411781
Epoch:[ 78 13 ] loss: 0.40858787298202515 2022-07-01 09:12:09.846029
Epoch:[ 78 14 ] loss: 0.40992704033851624 2022-07-01 09:12:10.280015
Epoch:[ 78 15 ] loss: 0.40665102005004883 2022-07-01 09:12:10.706160
Epoch:[ 78 16 ] loss: 0.40610167384147644 2022-07-01 09:12:15.923222
Epoch:[ 78 17 ] loss: 0.4083004295825958 2022-07-01 09:12:16.349864
Epoch:[ 78 18 ] loss: 0.4074687659740448 2022-07-01 09:12:16.782769
Epoch:[ 78 19 ] loss: 0.40770426392555237 2022-07-01 09:12:17.210327
Training_Epoch:[ 78 ] Training_loss: 0.407496902346611 2022-07-01 09:12:17.211018
learning rate:  0.002097152000000001
netparams have been saved once 78
val: 1 0.4409438371658325
val: 2 0.44708138704299927
val: 3 0.4452816843986511
val: 4 0.43098902702331543
val: 5 0.4453803300857544
val: 6 0.43535861372947693
val: 7 0.430332750082016
val: 8 0.44139623641967773
val: 9 0.44346553087234497
val: 10 0.4355926215648651
val: 11 0.440287709236145
val: 12 0.4346541166305542
val: 13 0.4410702884197235
val: 14 0.4437030851840973
val: 15 0.4417858123779297
val: 16 0.44521889090538025
val: 17 0.44347167015075684
val: 18 0.44262370467185974
val: 19 0.44585391879081726
val: 20 0.438236802816391
val_Epoch:[ 78 ] val_loss: 0.4406364008784294 2022-07-01 09:12:20.913622
start training 2022-07-01 09:12:21.019179
Epoch:[ 79 0 ] loss: 0.40792059898376465 2022-07-01 09:12:35.579841
Epoch:[ 79 1 ] loss: 0.40696099400520325 2022-07-01 09:12:36.034301
Epoch:[ 79 2 ] loss: 0.40353646874427795 2022-07-01 09:12:36.463960
Epoch:[ 79 3 ] loss: 0.4073989987373352 2022-07-01 09:12:36.896696
Epoch:[ 79 4 ] loss: 0.4040895700454712 2022-07-01 09:12:37.327395
Epoch:[ 79 5 ] loss: 0.4064735174179077 2022-07-01 09:12:37.758817
Epoch:[ 79 6 ] loss: 0.40479961037635803 2022-07-01 09:12:38.190480
Epoch:[ 79 7 ] loss: 0.40941122174263 2022-07-01 09:12:38.623577
Epoch:[ 79 8 ] loss: 0.40580442547798157 2022-07-01 09:12:39.051613
Epoch:[ 79 9 ] loss: 0.4083460867404938 2022-07-01 09:12:39.488164
Epoch:[ 79 10 ] loss: 0.4107425808906555 2022-07-01 09:12:39.917255
Epoch:[ 79 11 ] loss: 0.40668895840644836 2022-07-01 09:12:40.350061
Epoch:[ 79 12 ] loss: 0.4112037420272827 2022-07-01 09:12:40.777297
Epoch:[ 79 13 ] loss: 0.4096582531929016 2022-07-01 09:12:41.210187
Epoch:[ 79 14 ] loss: 0.40957921743392944 2022-07-01 09:12:41.641900
Epoch:[ 79 15 ] loss: 0.40877941250801086 2022-07-01 09:12:42.077969
Epoch:[ 79 16 ] loss: 0.40842971205711365 2022-07-01 09:12:47.830284
Epoch:[ 79 17 ] loss: 0.40812772512435913 2022-07-01 09:12:48.259447
Epoch:[ 79 18 ] loss: 0.40845710039138794 2022-07-01 09:12:48.694292
Epoch:[ 79 19 ] loss: 0.41051924228668213 2022-07-01 09:12:49.124723
Training_Epoch:[ 79 ] Training_loss: 0.4078463718295097 2022-07-01 09:12:49.125395
learning rate:  0.002097152000000001
val: 1 0.4375699758529663
val: 2 0.4472140967845917
val: 3 0.4432535469532013
val: 4 0.44476553797721863
val: 5 0.43934503197669983
val: 6 0.44450676441192627
val: 7 0.43478408455848694
val: 8 0.447263240814209
val: 9 0.44455695152282715
val: 10 0.44151976704597473
val: 11 0.43402713537216187
val: 12 0.45176926255226135
val: 13 0.44129058718681335
val: 14 0.43927058577537537
val: 15 0.43696141242980957
val: 16 0.4417135417461395
val: 17 0.4286225140094757
val: 18 0.4415302574634552
val: 19 0.439628541469574
val: 20 0.4436812996864319
val_Epoch:[ 79 ] val_loss: 0.44116370677947997 2022-07-01 09:12:52.799115
start training 2022-07-01 09:12:52.904170
Epoch:[ 80 0 ] loss: 0.4054490327835083 2022-07-01 09:13:07.235499
Epoch:[ 80 1 ] loss: 0.40503519773483276 2022-07-01 09:13:07.764350
Epoch:[ 80 2 ] loss: 0.40701180696487427 2022-07-01 09:13:08.190248
Epoch:[ 80 3 ] loss: 0.40644872188568115 2022-07-01 09:13:08.618742
Epoch:[ 80 4 ] loss: 0.4061233699321747 2022-07-01 09:13:09.050752
Epoch:[ 80 5 ] loss: 0.40400251746177673 2022-07-01 09:13:09.475011
Epoch:[ 80 6 ] loss: 0.40462958812713623 2022-07-01 09:13:09.899982
Epoch:[ 80 7 ] loss: 0.4035646617412567 2022-07-01 09:13:10.333596
Epoch:[ 80 8 ] loss: 0.40375152230262756 2022-07-01 09:13:10.760456
Epoch:[ 80 9 ] loss: 0.406642347574234 2022-07-01 09:13:11.198329
Epoch:[ 80 10 ] loss: 0.4042196571826935 2022-07-01 09:13:11.628956
Epoch:[ 80 11 ] loss: 0.4102509021759033 2022-07-01 09:13:12.058903
Epoch:[ 80 12 ] loss: 0.40694791078567505 2022-07-01 09:13:12.485428
Epoch:[ 80 13 ] loss: 0.41015109419822693 2022-07-01 09:13:12.909587
Epoch:[ 80 14 ] loss: 0.4067683517932892 2022-07-01 09:13:13.343340
Epoch:[ 80 15 ] loss: 0.4086577296257019 2022-07-01 09:13:13.770665
Epoch:[ 80 16 ] loss: 0.40552818775177 2022-07-01 09:13:18.936790
Epoch:[ 80 17 ] loss: 0.40993231534957886 2022-07-01 09:13:19.360927
Epoch:[ 80 18 ] loss: 0.40929052233695984 2022-07-01 09:13:19.792637
Epoch:[ 80 19 ] loss: 0.406654417514801 2022-07-01 09:13:20.215230
Training_Epoch:[ 80 ] Training_loss: 0.4065529927611351 2022-07-01 09:13:20.215902
learning rate:  0.002097152000000001
netparams have been saved once 80
val: 1 0.4463716149330139
val: 2 0.4398060441017151
val: 3 0.44627171754837036
val: 4 0.4451298713684082
val: 5 0.4514351785182953
val: 6 0.4476625621318817
val: 7 0.44383248686790466
val: 8 0.44321954250335693
val: 9 0.4402244985103607
val: 10 0.4470515549182892
val: 11 0.44548213481903076
val: 12 0.43189749121665955
val: 13 0.4438077509403229
val: 14 0.4338986873626709
val: 15 0.4355483949184418
val: 16 0.4667258858680725
val: 17 0.4523279070854187
val: 18 0.44920405745506287
val: 19 0.44992032647132874
val: 20 0.44472622871398926
val_Epoch:[ 80 ] val_loss: 0.4452271968126297 2022-07-01 09:13:23.869721
start training 2022-07-01 09:13:23.971135
Epoch:[ 81 0 ] loss: 0.4043387174606323 2022-07-01 09:13:39.024116
Epoch:[ 81 1 ] loss: 0.4073510468006134 2022-07-01 09:13:39.456250
Epoch:[ 81 2 ] loss: 0.403550922870636 2022-07-01 09:13:39.882759
Epoch:[ 81 3 ] loss: 0.4035191833972931 2022-07-01 09:13:40.313483
Epoch:[ 81 4 ] loss: 0.4049425423145294 2022-07-01 09:13:40.742568
Epoch:[ 81 5 ] loss: 0.4022853374481201 2022-07-01 09:13:41.167627
Epoch:[ 81 6 ] loss: 0.4058683216571808 2022-07-01 09:13:41.596153
Epoch:[ 81 7 ] loss: 0.40610232949256897 2022-07-01 09:13:42.021922
Epoch:[ 81 8 ] loss: 0.4033101499080658 2022-07-01 09:13:42.447168
Epoch:[ 81 9 ] loss: 0.4058828055858612 2022-07-01 09:13:42.873960
Epoch:[ 81 10 ] loss: 0.4069601893424988 2022-07-01 09:13:43.302071
Epoch:[ 81 11 ] loss: 0.4064718186855316 2022-07-01 09:13:43.730892
Epoch:[ 81 12 ] loss: 0.4066810607910156 2022-07-01 09:13:44.161817
Epoch:[ 81 13 ] loss: 0.40963974595069885 2022-07-01 09:13:44.586434
Epoch:[ 81 14 ] loss: 0.40300723910331726 2022-07-01 09:13:45.012707
Epoch:[ 81 15 ] loss: 0.4048762023448944 2022-07-01 09:13:45.444420
Epoch:[ 81 16 ] loss: 0.40508323907852173 2022-07-01 09:13:50.254978
Epoch:[ 81 17 ] loss: 0.4075184464454651 2022-07-01 09:13:50.687450
Epoch:[ 81 18 ] loss: 0.40629780292510986 2022-07-01 09:13:51.115963
Epoch:[ 81 19 ] loss: 0.40691661834716797 2022-07-01 09:13:51.542486
Training_Epoch:[ 81 ] Training_loss: 0.40553018599748614 2022-07-01 09:13:51.543136
learning rate:  0.001677721600000001
val: 1 0.4421563446521759
val: 2 0.44673770666122437
val: 3 0.4402954876422882
val: 4 0.4495183229446411
val: 5 0.4578215777873993
val: 6 0.4482083022594452
val: 7 0.45621970295906067
val: 8 0.44857528805732727
val: 9 0.4540637731552124
val: 10 0.44346103072166443
val: 11 0.4515746235847473
val: 12 0.4489329755306244
val: 13 0.4461926519870758
val: 14 0.44476115703582764
val: 15 0.4468522071838379
val: 16 0.4551559090614319
val: 17 0.45429888367652893
val: 18 0.44362008571624756
val: 19 0.4455166161060333
val: 20 0.45611944794654846
val_Epoch:[ 81 ] val_loss: 0.4490041047334671 2022-07-01 09:13:55.174577
start training 2022-07-01 09:13:55.280380
Epoch:[ 82 0 ] loss: 0.4044399857521057 2022-07-01 09:14:09.712758
Epoch:[ 82 1 ] loss: 0.40509432554244995 2022-07-01 09:14:10.297776
Epoch:[ 82 2 ] loss: 0.4067177176475525 2022-07-01 09:14:10.724890
Epoch:[ 82 3 ] loss: 0.40396547317504883 2022-07-01 09:14:11.158940
Epoch:[ 82 4 ] loss: 0.4043048322200775 2022-07-01 09:14:11.585523
Epoch:[ 82 5 ] loss: 0.4044284522533417 2022-07-01 09:14:12.012590
Epoch:[ 82 6 ] loss: 0.40795841813087463 2022-07-01 09:14:12.439199
Epoch:[ 82 7 ] loss: 0.4063032269477844 2022-07-01 09:14:12.873000
Epoch:[ 82 8 ] loss: 0.4039229154586792 2022-07-01 09:14:13.304617
Epoch:[ 82 9 ] loss: 0.4055154621601105 2022-07-01 09:14:13.732893
Epoch:[ 82 10 ] loss: 0.4072115123271942 2022-07-01 09:14:14.159749
Epoch:[ 82 11 ] loss: 0.40370261669158936 2022-07-01 09:14:14.591609
Epoch:[ 82 12 ] loss: 0.40543320775032043 2022-07-01 09:14:15.022450
Epoch:[ 82 13 ] loss: 0.40546080470085144 2022-07-01 09:14:15.448018
Epoch:[ 82 14 ] loss: 0.40621715784072876 2022-07-01 09:14:15.873868
Epoch:[ 82 15 ] loss: 0.403760701417923 2022-07-01 09:14:16.298658
Epoch:[ 82 16 ] loss: 0.4043406844139099 2022-07-01 09:14:20.870812
Epoch:[ 82 17 ] loss: 0.40492066740989685 2022-07-01 09:14:21.500122
Epoch:[ 82 18 ] loss: 0.4042321443557739 2022-07-01 09:14:21.939688
Epoch:[ 82 19 ] loss: 0.4043271243572235 2022-07-01 09:14:22.369745
Training_Epoch:[ 82 ] Training_loss: 0.40511287152767184 2022-07-01 09:14:22.370452
learning rate:  0.001677721600000001
netparams have been saved once 82
val: 1 0.4531429708003998
val: 2 0.4390752613544464
val: 3 0.44184306263923645
val: 4 0.44426971673965454
val: 5 0.4391362965106964
val: 6 0.4378509521484375
val: 7 0.44942763447761536
val: 8 0.4478398859500885
val: 9 0.4574185013771057
val: 10 0.44151511788368225
val: 11 0.4430939257144928
val: 12 0.4487675726413727
val: 13 0.4306783080101013
val: 14 0.4556451737880707
val: 15 0.45903828740119934
val: 16 0.4389604330062866
val: 17 0.4493151903152466
val: 18 0.4355098605155945
val: 19 0.44521012902259827
val: 20 0.4423179030418396
val_Epoch:[ 82 ] val_loss: 0.44500280916690826 2022-07-01 09:14:26.129496
start training 2022-07-01 09:14:26.230973
Epoch:[ 83 0 ] loss: 0.4027138650417328 2022-07-01 09:14:40.514404
Epoch:[ 83 1 ] loss: 0.40243783593177795 2022-07-01 09:14:40.944227
Epoch:[ 83 2 ] loss: 0.40445995330810547 2022-07-01 09:14:41.368172
Epoch:[ 83 3 ] loss: 0.4063160717487335 2022-07-01 09:14:41.799123
Epoch:[ 83 4 ] loss: 0.4014394283294678 2022-07-01 09:14:42.230814
Epoch:[ 83 5 ] loss: 0.40427500009536743 2022-07-01 09:14:42.656587
Epoch:[ 83 6 ] loss: 0.40163829922676086 2022-07-01 09:14:43.085592
Epoch:[ 83 7 ] loss: 0.4047120213508606 2022-07-01 09:14:43.510556
Epoch:[ 83 8 ] loss: 0.4054186940193176 2022-07-01 09:14:43.937809
Epoch:[ 83 9 ] loss: 0.402630478143692 2022-07-01 09:14:44.367069
Epoch:[ 83 10 ] loss: 0.4056914746761322 2022-07-01 09:14:44.794282
Epoch:[ 83 11 ] loss: 0.40530624985694885 2022-07-01 09:14:45.221263
Epoch:[ 83 12 ] loss: 0.4006008803844452 2022-07-01 09:14:45.652008
Epoch:[ 83 13 ] loss: 0.4041719436645508 2022-07-01 09:14:46.079590
Epoch:[ 83 14 ] loss: 0.40383094549179077 2022-07-01 09:14:46.504275
Epoch:[ 83 15 ] loss: 0.40689384937286377 2022-07-01 09:14:46.929186
Epoch:[ 83 16 ] loss: 0.4080424904823303 2022-07-01 09:14:52.141597
Epoch:[ 83 17 ] loss: 0.4055470824241638 2022-07-01 09:14:52.569143
Epoch:[ 83 18 ] loss: 0.4072391390800476 2022-07-01 09:14:52.999565
Epoch:[ 83 19 ] loss: 0.4056083858013153 2022-07-01 09:14:53.428939
Training_Epoch:[ 83 ] Training_loss: 0.40444870442152026 2022-07-01 09:14:53.429544
learning rate:  0.001677721600000001
val: 1 0.44210952520370483
val: 2 0.44313833117485046
val: 3 0.4464409649372101
val: 4 0.44084879755973816
val: 5 0.4536290466785431
val: 6 0.44284912943840027
val: 7 0.4377947151660919
val: 8 0.4435412287712097
val: 9 0.441091924905777
val: 10 0.44300028681755066
val: 11 0.4506104588508606
val: 12 0.4484960436820984
val: 13 0.43339258432388306
val: 14 0.4504519999027252
val: 15 0.4332863688468933
val: 16 0.43349453806877136
val: 17 0.44195932149887085
val: 18 0.43940627574920654
val: 19 0.4338267147541046
val: 20 0.4416932761669159
val_Epoch:[ 83 ] val_loss: 0.4420530766248703 2022-07-01 09:14:57.116034
start training 2022-07-01 09:14:57.212832
Epoch:[ 84 0 ] loss: 0.4047931730747223 2022-07-01 09:15:12.408072
Epoch:[ 84 1 ] loss: 0.40657228231430054 2022-07-01 09:15:12.833638
Epoch:[ 84 2 ] loss: 0.4042740762233734 2022-07-01 09:15:13.263383
Epoch:[ 84 3 ] loss: 0.4045921862125397 2022-07-01 09:15:13.688150
Epoch:[ 84 4 ] loss: 0.4052308201789856 2022-07-01 09:15:14.121253
Epoch:[ 84 5 ] loss: 0.40512627363204956 2022-07-01 09:15:14.553200
Epoch:[ 84 6 ] loss: 0.4024651050567627 2022-07-01 09:15:14.979284
Epoch:[ 84 7 ] loss: 0.4024178981781006 2022-07-01 09:15:15.408975
Epoch:[ 84 8 ] loss: 0.4048646092414856 2022-07-01 09:15:15.834283
Epoch:[ 84 9 ] loss: 0.403860479593277 2022-07-01 09:15:16.264641
Epoch:[ 84 10 ] loss: 0.4031822085380554 2022-07-01 09:15:16.689549
Epoch:[ 84 11 ] loss: 0.4063756465911865 2022-07-01 09:15:17.117106
Epoch:[ 84 12 ] loss: 0.40328747034072876 2022-07-01 09:15:17.543193
Epoch:[ 84 13 ] loss: 0.40515372157096863 2022-07-01 09:15:17.970338
Epoch:[ 84 14 ] loss: 0.4031801223754883 2022-07-01 09:15:18.396711
Epoch:[ 84 15 ] loss: 0.4034406244754791 2022-07-01 09:15:18.821914
Epoch:[ 84 16 ] loss: 0.4082186818122864 2022-07-01 09:15:23.769960
Epoch:[ 84 17 ] loss: 0.40359196066856384 2022-07-01 09:15:24.199134
Epoch:[ 84 18 ] loss: 0.403415709733963 2022-07-01 09:15:24.629524
Epoch:[ 84 19 ] loss: 0.40600091218948364 2022-07-01 09:15:25.056328
Training_Epoch:[ 84 ] Training_loss: 0.40450219810009 2022-07-01 09:15:25.056946
learning rate:  0.001677721600000001
netparams have been saved once 84
val: 1 0.44408032298088074
val: 2 0.44189193844795227
val: 3 0.43922555446624756
val: 4 0.43260395526885986
val: 5 0.4499899446964264
val: 6 0.4515570104122162
val: 7 0.448986679315567
val: 8 0.4366673231124878
val: 9 0.4556918144226074
val: 10 0.45298486948013306
val: 11 0.4478338956832886
val: 12 0.45585981011390686
val: 13 0.44767484068870544
val: 14 0.4541434943675995
val: 15 0.45217230916023254
val: 16 0.4591245651245117
val: 17 0.43946102261543274
val: 18 0.46150025725364685
val: 19 0.4397144317626953
val: 20 0.45056843757629395
val_Epoch:[ 84 ] val_loss: 0.4480866238474846 2022-07-01 09:15:28.780586
start training 2022-07-01 09:15:28.878852
Epoch:[ 85 0 ] loss: 0.40126726031303406 2022-07-01 09:15:42.986836
Epoch:[ 85 1 ] loss: 0.40289729833602905 2022-07-01 09:15:43.803183
Epoch:[ 85 2 ] loss: 0.4039905369281769 2022-07-01 09:15:44.234737
Epoch:[ 85 3 ] loss: 0.4000505805015564 2022-07-01 09:15:44.659203
Epoch:[ 85 4 ] loss: 0.4006534516811371 2022-07-01 09:15:45.083246
Epoch:[ 85 5 ] loss: 0.4016357660293579 2022-07-01 09:15:45.515419
Epoch:[ 85 6 ] loss: 0.4027051627635956 2022-07-01 09:15:45.947166
Epoch:[ 85 7 ] loss: 0.40312904119491577 2022-07-01 09:15:46.373536
Epoch:[ 85 8 ] loss: 0.4033960998058319 2022-07-01 09:15:46.802401
Epoch:[ 85 9 ] loss: 0.4045122563838959 2022-07-01 09:15:47.226699
Epoch:[ 85 10 ] loss: 0.40604105591773987 2022-07-01 09:15:47.656747
Epoch:[ 85 11 ] loss: 0.4023629426956177 2022-07-01 09:15:48.086185
Epoch:[ 85 12 ] loss: 0.4075792133808136 2022-07-01 09:15:48.512570
Epoch:[ 85 13 ] loss: 0.4041442573070526 2022-07-01 09:15:48.938946
Epoch:[ 85 14 ] loss: 0.40329498052597046 2022-07-01 09:15:49.364057
Epoch:[ 85 15 ] loss: 0.4036790728569031 2022-07-01 09:15:49.790427
Epoch:[ 85 16 ] loss: 0.40348193049430847 2022-07-01 09:15:54.413519
Epoch:[ 85 17 ] loss: 0.40360596776008606 2022-07-01 09:15:55.540605
Epoch:[ 85 18 ] loss: 0.4063262939453125 2022-07-01 09:15:55.977772
Epoch:[ 85 19 ] loss: 0.4022589325904846 2022-07-01 09:15:56.409553
Training_Epoch:[ 85 ] Training_loss: 0.40335060507059095 2022-07-01 09:15:56.410216
learning rate:  0.001677721600000001
val: 1 0.4452957808971405
val: 2 0.44369691610336304
val: 3 0.4579834043979645
val: 4 0.44276732206344604
val: 5 0.4377397298812866
val: 6 0.4437193274497986
val: 7 0.440221905708313
val: 8 0.4395796060562134
val: 9 0.44345447421073914
val: 10 0.44163087010383606
val: 11 0.4401993751525879
val: 12 0.4380510747432709
val: 13 0.4403699040412903
val: 14 0.4582906663417816
val: 15 0.43745696544647217
val: 16 0.43263986706733704
val: 17 0.43751639127731323
val: 18 0.44407910108566284
val: 19 0.4417535066604614
val: 20 0.4464293122291565
val_Epoch:[ 85 ] val_loss: 0.4426437750458717 2022-07-01 09:16:00.046583
start training 2022-07-01 09:16:00.145078
Epoch:[ 86 0 ] loss: 0.404666543006897 2022-07-01 09:16:15.001811
Epoch:[ 86 1 ] loss: 0.4063071310520172 2022-07-01 09:16:15.428858
Epoch:[ 86 2 ] loss: 0.4035826325416565 2022-07-01 09:16:15.859831
Epoch:[ 86 3 ] loss: 0.4049570858478546 2022-07-01 09:16:16.284690
Epoch:[ 86 4 ] loss: 0.4023955762386322 2022-07-01 09:16:16.715326
Epoch:[ 86 5 ] loss: 0.40397465229034424 2022-07-01 09:16:17.145215
Epoch:[ 86 6 ] loss: 0.4022435247898102 2022-07-01 09:16:17.573503
Epoch:[ 86 7 ] loss: 0.40174955129623413 2022-07-01 09:16:18.001079
Epoch:[ 86 8 ] loss: 0.4064916968345642 2022-07-01 09:16:18.427402
Epoch:[ 86 9 ] loss: 0.4040711522102356 2022-07-01 09:16:18.855130
Epoch:[ 86 10 ] loss: 0.405575156211853 2022-07-01 09:16:19.285834
Epoch:[ 86 11 ] loss: 0.4062092900276184 2022-07-01 09:16:19.716401
Epoch:[ 86 12 ] loss: 0.4047071635723114 2022-07-01 09:16:20.145729
Epoch:[ 86 13 ] loss: 0.4043813943862915 2022-07-01 09:16:20.573148
Epoch:[ 86 14 ] loss: 0.40544477105140686 2022-07-01 09:16:21.000335
Epoch:[ 86 15 ] loss: 0.40120676159858704 2022-07-01 09:16:21.427395
Epoch:[ 86 16 ] loss: 0.4062301516532898 2022-07-01 09:16:26.367226
Epoch:[ 86 17 ] loss: 0.4035794138908386 2022-07-01 09:16:26.792970
Epoch:[ 86 18 ] loss: 0.40300658345222473 2022-07-01 09:16:27.229889
Epoch:[ 86 19 ] loss: 0.40766793489456177 2022-07-01 09:16:27.647621
Training_Epoch:[ 86 ] Training_loss: 0.40442240834236143 2022-07-01 09:16:27.648264
learning rate:  0.001677721600000001
netparams have been saved once 86
val: 1 0.4560452103614807
val: 2 0.4442853629589081
val: 3 0.45295819640159607
val: 4 0.45599955320358276
val: 5 0.45567581057548523
val: 6 0.44249916076660156
val: 7 0.44545772671699524
val: 8 0.46431437134742737
val: 9 0.45227211713790894
val: 10 0.4412004053592682
val: 11 0.43309715390205383
val: 12 0.4480828642845154
val: 13 0.4412154257297516
val: 14 0.4498576521873474
val: 15 0.44442546367645264
val: 16 0.4455765187740326
val: 17 0.45134812593460083
val: 18 0.44516825675964355
val: 19 0.43995165824890137
val: 20 0.4446486830711365
val_Epoch:[ 86 ] val_loss: 0.44770398586988447 2022-07-01 09:16:31.361062
start training 2022-07-01 09:16:31.460145
Epoch:[ 87 0 ] loss: 0.4029136300086975 2022-07-01 09:16:45.784999
Epoch:[ 87 1 ] loss: 0.40416884422302246 2022-07-01 09:16:46.218860
Epoch:[ 87 2 ] loss: 0.4014799892902374 2022-07-01 09:16:46.648802
Epoch:[ 87 3 ] loss: 0.4064693748950958 2022-07-01 09:16:47.073484
Epoch:[ 87 4 ] loss: 0.4030589461326599 2022-07-01 09:16:47.498710
Epoch:[ 87 5 ] loss: 0.40218883752822876 2022-07-01 09:16:47.923373
Epoch:[ 87 6 ] loss: 0.4010835886001587 2022-07-01 09:16:48.346375
Epoch:[ 87 7 ] loss: 0.40426701307296753 2022-07-01 09:16:48.773438
Epoch:[ 87 8 ] loss: 0.4038790464401245 2022-07-01 09:16:49.202962
Epoch:[ 87 9 ] loss: 0.40089350938796997 2022-07-01 09:16:49.634196
Epoch:[ 87 10 ] loss: 0.40405917167663574 2022-07-01 09:16:50.064625
Epoch:[ 87 11 ] loss: 0.40386566519737244 2022-07-01 09:16:50.489011
Epoch:[ 87 12 ] loss: 0.40213480591773987 2022-07-01 09:16:50.919394
Epoch:[ 87 13 ] loss: 0.4049360752105713 2022-07-01 09:16:51.346254
Epoch:[ 87 14 ] loss: 0.4016905426979065 2022-07-01 09:16:51.772357
Epoch:[ 87 15 ] loss: 0.4052255153656006 2022-07-01 09:16:52.204458
Epoch:[ 87 16 ] loss: 0.40176787972450256 2022-07-01 09:16:57.227328
Epoch:[ 87 17 ] loss: 0.4033872187137604 2022-07-01 09:16:57.651745
Epoch:[ 87 18 ] loss: 0.4015201926231384 2022-07-01 09:16:58.079982
Epoch:[ 87 19 ] loss: 0.4031134843826294 2022-07-01 09:16:58.509145
Training_Epoch:[ 87 ] Training_loss: 0.403105166554451 2022-07-01 09:16:58.509839
learning rate:  0.001677721600000001
val: 1 0.4323576092720032
val: 2 0.4381292462348938
val: 3 0.4356774091720581
val: 4 0.437726229429245
val: 5 0.4488617479801178
val: 6 0.43193358182907104
val: 7 0.43719545006752014
val: 8 0.435150682926178
val: 9 0.44502776861190796
val: 10 0.448790967464447
val: 11 0.4379904270172119
val: 12 0.4389917254447937
val: 13 0.4390738904476166
val: 14 0.44437509775161743
val: 15 0.44469866156578064
val: 16 0.45722442865371704
val: 17 0.45309972763061523
val: 18 0.4416030943393707
val: 19 0.4442685544490814
val: 20 0.43524229526519775
val_Epoch:[ 87 ] val_loss: 0.4413709297776222 2022-07-01 09:17:02.159389
start training 2022-07-01 09:17:02.254991
Epoch:[ 88 0 ] loss: 0.4004981219768524 2022-07-01 09:17:16.315797
Epoch:[ 88 1 ] loss: 0.40094998478889465 2022-07-01 09:17:16.763211
Epoch:[ 88 2 ] loss: 0.3999709486961365 2022-07-01 09:17:17.334173
Epoch:[ 88 3 ] loss: 0.4018291234970093 2022-07-01 09:17:17.759759
Epoch:[ 88 4 ] loss: 0.40318799018859863 2022-07-01 09:17:18.191312
Epoch:[ 88 5 ] loss: 0.40393123030662537 2022-07-01 09:17:18.617484
Epoch:[ 88 6 ] loss: 0.40307167172431946 2022-07-01 09:17:19.047604
Epoch:[ 88 7 ] loss: 0.40150004625320435 2022-07-01 09:17:19.471593
Epoch:[ 88 8 ] loss: 0.3997531235218048 2022-07-01 09:17:19.897865
Epoch:[ 88 9 ] loss: 0.4034036695957184 2022-07-01 09:17:20.330774
Epoch:[ 88 10 ] loss: 0.40239831805229187 2022-07-01 09:17:20.756188
Epoch:[ 88 11 ] loss: 0.4018048644065857 2022-07-01 09:17:21.181056
Epoch:[ 88 12 ] loss: 0.40375426411628723 2022-07-01 09:17:21.607457
Epoch:[ 88 13 ] loss: 0.40350863337516785 2022-07-01 09:17:22.034373
Epoch:[ 88 14 ] loss: 0.4030973017215729 2022-07-01 09:17:22.463989
Epoch:[ 88 15 ] loss: 0.40415850281715393 2022-07-01 09:17:22.889969
Epoch:[ 88 16 ] loss: 0.4054271876811981 2022-07-01 09:17:28.002814
Epoch:[ 88 17 ] loss: 0.39985471963882446 2022-07-01 09:17:28.427785
Epoch:[ 88 18 ] loss: 0.4030461609363556 2022-07-01 09:17:29.224341
Epoch:[ 88 19 ] loss: 0.40273547172546387 2022-07-01 09:17:29.654537
Training_Epoch:[ 88 ] Training_loss: 0.40239406675100325 2022-07-01 09:17:29.655189
learning rate:  0.001677721600000001
netparams have been saved once 88
val: 1 0.4469212293624878
val: 2 0.43861472606658936
val: 3 0.43929851055145264
val: 4 0.455845445394516
val: 5 0.4474886655807495
val: 6 0.4450156092643738
val: 7 0.4471398591995239
val: 8 0.4379000961780548
val: 9 0.453338086605072
val: 10 0.45121732354164124
val: 11 0.4360373914241791
val: 12 0.44007349014282227
val: 13 0.4502231478691101
val: 14 0.4419093132019043
val: 15 0.4432486891746521
val: 16 0.4320843815803528
val: 17 0.44160768389701843
val: 18 0.4352644681930542
val: 19 0.4409526586532593
val: 20 0.4353376626968384
val_Epoch:[ 88 ] val_loss: 0.4429759219288826 2022-07-01 09:17:33.314642
start training 2022-07-01 09:17:33.410396
Epoch:[ 89 0 ] loss: 0.4025155305862427 2022-07-01 09:17:48.251138
Epoch:[ 89 1 ] loss: 0.4023844301700592 2022-07-01 09:17:48.676398
Epoch:[ 89 2 ] loss: 0.4025312662124634 2022-07-01 09:17:49.107069
Epoch:[ 89 3 ] loss: 0.40150773525238037 2022-07-01 09:17:49.533044
Epoch:[ 89 4 ] loss: 0.40323105454444885 2022-07-01 09:17:49.958840
Epoch:[ 89 5 ] loss: 0.40174147486686707 2022-07-01 09:17:50.384200
Epoch:[ 89 6 ] loss: 0.40070703625679016 2022-07-01 09:17:50.813485
Epoch:[ 89 7 ] loss: 0.4001668691635132 2022-07-01 09:17:51.243205
Epoch:[ 89 8 ] loss: 0.4007475972175598 2022-07-01 09:17:51.668884
Epoch:[ 89 9 ] loss: 0.4015476703643799 2022-07-01 09:17:52.101027
Epoch:[ 89 10 ] loss: 0.4023841321468353 2022-07-01 09:17:52.528434
Epoch:[ 89 11 ] loss: 0.403139591217041 2022-07-01 09:17:52.953058
Epoch:[ 89 12 ] loss: 0.4022097885608673 2022-07-01 09:17:53.377515
Epoch:[ 89 13 ] loss: 0.40517309308052063 2022-07-01 09:17:53.807148
Epoch:[ 89 14 ] loss: 0.40470340847969055 2022-07-01 09:17:54.231272
Epoch:[ 89 15 ] loss: 0.4014679491519928 2022-07-01 09:17:54.659342
Epoch:[ 89 16 ] loss: 0.4037439823150635 2022-07-01 09:17:59.655547
Epoch:[ 89 17 ] loss: 0.40103617310523987 2022-07-01 09:18:00.081529
Epoch:[ 89 18 ] loss: 0.4023621678352356 2022-07-01 09:18:00.512343
Epoch:[ 89 19 ] loss: 0.4016893804073334 2022-07-01 09:18:00.936134
Training_Epoch:[ 89 ] Training_loss: 0.40224951654672625 2022-07-01 09:18:00.936839
learning rate:  0.001677721600000001
val: 1 0.4645134210586548
val: 2 0.44705912470817566
val: 3 0.4419381320476532
val: 4 0.4390983581542969
val: 5 0.44540709257125854
val: 6 0.45190849900245667
val: 7 0.43675243854522705
val: 8 0.461877703666687
val: 9 0.45299041271209717
val: 10 0.4487355053424835
val: 11 0.45042166113853455
val: 12 0.44313737750053406
val: 13 0.43634968996047974
val: 14 0.44651710987091064
val: 15 0.44427356123924255
val: 16 0.4487670958042145
val: 17 0.4518752992153168
val: 18 0.45067596435546875
val: 19 0.4373234510421753
val: 20 0.4486260712146759
val_Epoch:[ 89 ] val_loss: 0.44741239845752717 2022-07-01 09:18:04.630468
start training 2022-07-01 09:18:04.729926
Epoch:[ 90 0 ] loss: 0.40035149455070496 2022-07-01 09:18:19.099202
Epoch:[ 90 1 ] loss: 0.40102288126945496 2022-07-01 09:18:19.556953
Epoch:[ 90 2 ] loss: 0.40092143416404724 2022-07-01 09:18:19.981187
Epoch:[ 90 3 ] loss: 0.40074586868286133 2022-07-01 09:18:20.406900
Epoch:[ 90 4 ] loss: 0.3999515473842621 2022-07-01 09:18:20.833295
Epoch:[ 90 5 ] loss: 0.4027469754219055 2022-07-01 09:18:21.261077
Epoch:[ 90 6 ] loss: 0.4020787179470062 2022-07-01 09:18:21.692714
Epoch:[ 90 7 ] loss: 0.39936476945877075 2022-07-01 09:18:22.123263
Epoch:[ 90 8 ] loss: 0.4027884900569916 2022-07-01 09:18:22.548351
Epoch:[ 90 9 ] loss: 0.4018990099430084 2022-07-01 09:18:22.978857
Epoch:[ 90 10 ] loss: 0.4043228328227997 2022-07-01 09:18:23.404714
Epoch:[ 90 11 ] loss: 0.399302214384079 2022-07-01 09:18:23.837748
Epoch:[ 90 12 ] loss: 0.40286678075790405 2022-07-01 09:18:24.271145
Epoch:[ 90 13 ] loss: 0.400590717792511 2022-07-01 09:18:24.696269
Epoch:[ 90 14 ] loss: 0.39956384897232056 2022-07-01 09:18:25.122646
Epoch:[ 90 15 ] loss: 0.40323400497436523 2022-07-01 09:18:25.549026
Epoch:[ 90 16 ] loss: 0.4006337821483612 2022-07-01 09:18:30.591108
Epoch:[ 90 17 ] loss: 0.4026326537132263 2022-07-01 09:18:31.021901
Epoch:[ 90 18 ] loss: 0.4017745852470398 2022-07-01 09:18:31.452984
Epoch:[ 90 19 ] loss: 0.4026983976364136 2022-07-01 09:18:31.878062
Training_Epoch:[ 90 ] Training_loss: 0.4014745503664017 2022-07-01 09:18:31.878764
learning rate:  0.001677721600000001
netparams have been saved once 90
val: 1 0.44562646746635437
val: 2 0.4380640685558319
val: 3 0.44610387086868286
val: 4 0.44424179196357727
val: 5 0.446957528591156
val: 6 0.43885913491249084
val: 7 0.44228655099868774
val: 8 0.4377664625644684
val: 9 0.4519793391227722
val: 10 0.44780346751213074
val: 11 0.4384937286376953
val: 12 0.4410778284072876
val: 13 0.4374864101409912
val: 14 0.44096097350120544
val: 15 0.45233267545700073
val: 16 0.4538171887397766
val: 17 0.45878860354423523
val: 18 0.44079285860061646
val: 19 0.4460891783237457
val: 20 0.44918373227119446
val_Epoch:[ 90 ] val_loss: 0.44493559300899505 2022-07-01 09:18:35.614493
start training 2022-07-01 09:18:35.712452
Epoch:[ 91 0 ] loss: 0.3989998400211334 2022-07-01 09:18:50.523556
Epoch:[ 91 1 ] loss: 0.40021204948425293 2022-07-01 09:18:50.949184
Epoch:[ 91 2 ] loss: 0.4012003242969513 2022-07-01 09:18:51.373376
Epoch:[ 91 3 ] loss: 0.40141308307647705 2022-07-01 09:18:51.802855
Epoch:[ 91 4 ] loss: 0.40087011456489563 2022-07-01 09:18:52.229121
Epoch:[ 91 5 ] loss: 0.4020993113517761 2022-07-01 09:18:52.654836
Epoch:[ 91 6 ] loss: 0.39815306663513184 2022-07-01 09:18:53.082251
Epoch:[ 91 7 ] loss: 0.40177714824676514 2022-07-01 09:18:53.511152
Epoch:[ 91 8 ] loss: 0.4010730981826782 2022-07-01 09:18:53.941251
Epoch:[ 91 9 ] loss: 0.4015142619609833 2022-07-01 09:18:54.366842
Epoch:[ 91 10 ] loss: 0.40069109201431274 2022-07-01 09:18:54.791256
Epoch:[ 91 11 ] loss: 0.4029988646507263 2022-07-01 09:18:55.218066
Epoch:[ 91 12 ] loss: 0.4009944200515747 2022-07-01 09:18:55.649512
Epoch:[ 91 13 ] loss: 0.40130549669265747 2022-07-01 09:18:56.077891
Epoch:[ 91 14 ] loss: 0.3975013792514801 2022-07-01 09:18:56.504724
Epoch:[ 91 15 ] loss: 0.39937084913253784 2022-07-01 09:18:56.935035
Epoch:[ 91 16 ] loss: 0.40127140283584595 2022-07-01 09:19:02.193050
Epoch:[ 91 17 ] loss: 0.4023032784461975 2022-07-01 09:19:02.615911
Epoch:[ 91 18 ] loss: 0.40093499422073364 2022-07-01 09:19:03.050054
Epoch:[ 91 19 ] loss: 0.4018411338329315 2022-07-01 09:19:03.481867
Training_Epoch:[ 91 ] Training_loss: 0.40082626044750214 2022-07-01 09:19:03.482497
learning rate:  0.0013421772800000008
val: 1 0.43575772643089294
val: 2 0.4445054829120636
val: 3 0.44422584772109985
val: 4 0.4498462677001953
val: 5 0.44487687945365906
val: 6 0.4506220519542694
val: 7 0.44442078471183777
val: 8 0.43632519245147705
val: 9 0.43589434027671814
val: 10 0.44614502787590027
val: 11 0.437238484621048
val: 12 0.4409313201904297
val: 13 0.44720691442489624
val: 14 0.44586458802223206
val: 15 0.4442567527294159
val: 16 0.4450671672821045
val: 17 0.4473895728588104
val: 18 0.43216875195503235
val: 19 0.44584131240844727
val: 20 0.4424932897090912
val_Epoch:[ 91 ] val_loss: 0.44305388778448107 2022-07-01 09:19:07.098764
start training 2022-07-01 09:19:07.212773
Epoch:[ 92 0 ] loss: 0.39724233746528625 2022-07-01 09:19:21.987480
Epoch:[ 92 1 ] loss: 0.39771735668182373 2022-07-01 09:19:22.413007
Epoch:[ 92 2 ] loss: 0.3989737629890442 2022-07-01 09:19:22.842729
Epoch:[ 92 3 ] loss: 0.3981615900993347 2022-07-01 09:19:23.267762
Epoch:[ 92 4 ] loss: 0.39930278062820435 2022-07-01 09:19:23.697869
Epoch:[ 92 5 ] loss: 0.39762985706329346 2022-07-01 09:19:24.124543
Epoch:[ 92 6 ] loss: 0.4000682830810547 2022-07-01 09:19:24.551384
Epoch:[ 92 7 ] loss: 0.4023624360561371 2022-07-01 09:19:24.976600
Epoch:[ 92 8 ] loss: 0.3988393545150757 2022-07-01 09:19:25.401328
Epoch:[ 92 9 ] loss: 0.39776286482810974 2022-07-01 09:19:25.831401
Epoch:[ 92 10 ] loss: 0.4004935622215271 2022-07-01 09:19:26.255692
Epoch:[ 92 11 ] loss: 0.396444708108902 2022-07-01 09:19:26.685259
Epoch:[ 92 12 ] loss: 0.40123435854911804 2022-07-01 09:19:27.117789
Epoch:[ 92 13 ] loss: 0.3982279300689697 2022-07-01 09:19:27.549728
Epoch:[ 92 14 ] loss: 0.399175226688385 2022-07-01 09:19:27.977028
Epoch:[ 92 15 ] loss: 0.39918407797813416 2022-07-01 09:19:28.401407
Epoch:[ 92 16 ] loss: 0.39833390712738037 2022-07-01 09:19:33.302107
Epoch:[ 92 17 ] loss: 0.40179210901260376 2022-07-01 09:19:33.726080
Epoch:[ 92 18 ] loss: 0.398605614900589 2022-07-01 09:19:34.155935
Epoch:[ 92 19 ] loss: 0.39968979358673096 2022-07-01 09:19:34.586398
Training_Epoch:[ 92 ] Training_loss: 0.3990620955824852 2022-07-01 09:19:34.587047
learning rate:  0.0013421772800000008
netparams have been saved once 92
val: 1 0.44858190417289734
val: 2 0.44511303305625916
val: 3 0.44384822249412537
val: 4 0.43411070108413696
val: 5 0.43653908371925354
val: 6 0.4464769959449768
val: 7 0.44474753737449646
val: 8 0.431239515542984
val: 9 0.4411451518535614
val: 10 0.46434450149536133
val: 11 0.4420575797557831
val: 12 0.45702478289604187
val: 13 0.43526148796081543
val: 14 0.449431449174881
val: 15 0.43485361337661743
val: 16 0.45082777738571167
val: 17 0.43071746826171875
val: 18 0.4422689974308014
val: 19 0.4463396370410919
val: 20 0.45553964376449585
val_Epoch:[ 92 ] val_loss: 0.44402345418930056 2022-07-01 09:19:38.310257
start training 2022-07-01 09:19:38.406755
Epoch:[ 93 0 ] loss: 0.39605680108070374 2022-07-01 09:19:52.781604
Epoch:[ 93 1 ] loss: 0.3986224830150604 2022-07-01 09:19:53.233120
Epoch:[ 93 2 ] loss: 0.3996512293815613 2022-07-01 09:19:53.662011
Epoch:[ 93 3 ] loss: 0.4013444781303406 2022-07-01 09:19:54.087285
Epoch:[ 93 4 ] loss: 0.39918798208236694 2022-07-01 09:19:54.511808
Epoch:[ 93 5 ] loss: 0.39695948362350464 2022-07-01 09:19:54.936372
Epoch:[ 93 6 ] loss: 0.3963291347026825 2022-07-01 09:19:55.362747
Epoch:[ 93 7 ] loss: 0.4023147225379944 2022-07-01 09:19:55.795076
Epoch:[ 93 8 ] loss: 0.39734604954719543 2022-07-01 09:19:56.219960
Epoch:[ 93 9 ] loss: 0.399347186088562 2022-07-01 09:19:56.650741
Epoch:[ 93 10 ] loss: 0.39945030212402344 2022-07-01 09:19:57.076046
Epoch:[ 93 11 ] loss: 0.40113013982772827 2022-07-01 09:19:57.507971
Epoch:[ 93 12 ] loss: 0.3975924551486969 2022-07-01 09:19:57.932319
Epoch:[ 93 13 ] loss: 0.3997288644313812 2022-07-01 09:19:58.359991
Epoch:[ 93 14 ] loss: 0.40031829476356506 2022-07-01 09:19:58.792421
Epoch:[ 93 15 ] loss: 0.4003790616989136 2022-07-01 09:19:59.216995
Epoch:[ 93 16 ] loss: 0.40138447284698486 2022-07-01 09:20:03.944058
Epoch:[ 93 17 ] loss: 0.3991362154483795 2022-07-01 09:20:04.369143
Epoch:[ 93 18 ] loss: 0.3999430239200592 2022-07-01 09:20:04.801711
Epoch:[ 93 19 ] loss: 0.4004552364349365 2022-07-01 09:20:05.225484
Training_Epoch:[ 93 ] Training_loss: 0.39933388084173205 2022-07-01 09:20:05.226175
learning rate:  0.0013421772800000008
val: 1 0.4492453336715698
val: 2 0.44064420461654663
val: 3 0.4388941824436188
val: 4 0.4499823749065399
val: 5 0.43918266892433167
val: 6 0.43296030163764954
val: 7 0.4456945061683655
val: 8 0.44493767619132996
val: 9 0.44408154487609863
val: 10 0.4528140127658844
val: 11 0.4608950912952423
val: 12 0.44421088695526123
val: 13 0.4418134093284607
val: 14 0.4459640085697174
val: 15 0.44486260414123535
val: 16 0.4472772777080536
val: 17 0.44092556834220886
val: 18 0.4442160725593567
val: 19 0.44144585728645325
val: 20 0.4509240984916687
val_Epoch:[ 93 ] val_loss: 0.4450485840439796 2022-07-01 09:20:08.984913
start training 2022-07-01 09:20:09.099768
Epoch:[ 94 0 ] loss: 0.39745891094207764 2022-07-01 09:20:23.480403
Epoch:[ 94 1 ] loss: 0.3975876271724701 2022-07-01 09:20:23.909799
Epoch:[ 94 2 ] loss: 0.3995032012462616 2022-07-01 09:20:24.334343
Epoch:[ 94 3 ] loss: 0.39639419317245483 2022-07-01 09:20:24.764661
Epoch:[ 94 4 ] loss: 0.39853864908218384 2022-07-01 09:20:25.187995
Epoch:[ 94 5 ] loss: 0.398646742105484 2022-07-01 09:20:25.610697
Epoch:[ 94 6 ] loss: 0.39756548404693604 2022-07-01 09:20:26.039347
Epoch:[ 94 7 ] loss: 0.39599430561065674 2022-07-01 09:20:26.465364
Epoch:[ 94 8 ] loss: 0.39914560317993164 2022-07-01 09:20:26.896928
Epoch:[ 94 9 ] loss: 0.39684489369392395 2022-07-01 09:20:27.322148
Epoch:[ 94 10 ] loss: 0.40111851692199707 2022-07-01 09:20:27.751470
Epoch:[ 94 11 ] loss: 0.39943912625312805 2022-07-01 09:20:28.177015
Epoch:[ 94 12 ] loss: 0.39951062202453613 2022-07-01 09:20:28.606915
Epoch:[ 94 13 ] loss: 0.39996176958084106 2022-07-01 09:20:29.031782
Epoch:[ 94 14 ] loss: 0.39931097626686096 2022-07-01 09:20:29.464353
Epoch:[ 94 15 ] loss: 0.3993760943412781 2022-07-01 09:20:29.892772
Epoch:[ 94 16 ] loss: 0.3987552225589752 2022-07-01 09:20:35.130749
Epoch:[ 94 17 ] loss: 0.3981848955154419 2022-07-01 09:20:35.562764
Epoch:[ 94 18 ] loss: 0.3986090421676636 2022-07-01 09:20:36.003022
Epoch:[ 94 19 ] loss: 0.40138500928878784 2022-07-01 09:20:36.420750
Training_Epoch:[ 94 ] Training_loss: 0.3986665442585945 2022-07-01 09:20:36.421403
learning rate:  0.0013421772800000008
netparams have been saved once 94
val: 1 0.44990357756614685
val: 2 0.4407033324241638
val: 3 0.4471241235733032
val: 4 0.4419989585876465
val: 5 0.4436433017253876
val: 6 0.44598832726478577
val: 7 0.4464690387248993
val: 8 0.44687530398368835
val: 9 0.4497275650501251
val: 10 0.4353182911872864
val: 11 0.44508323073387146
val: 12 0.43852314352989197
val: 13 0.43705952167510986
val: 14 0.4559490978717804
val: 15 0.4429665207862854
val: 16 0.4432884454727173
val: 17 0.4424450993537903
val: 18 0.4501025378704071
val: 19 0.43989595770835876
val: 20 0.44364702701568604
val_Epoch:[ 94 ] val_loss: 0.44433562010526656 2022-07-01 09:20:40.137232
start training 2022-07-01 09:20:40.232497
Epoch:[ 95 0 ] loss: 0.3971309959888458 2022-07-01 09:20:54.289537
Epoch:[ 95 1 ] loss: 0.39640507102012634 2022-07-01 09:20:54.735735
Epoch:[ 95 2 ] loss: 0.396911084651947 2022-07-01 09:20:55.163267
Epoch:[ 95 3 ] loss: 0.3979535698890686 2022-07-01 09:20:55.589158
Epoch:[ 95 4 ] loss: 0.39886224269866943 2022-07-01 09:20:56.015421
Epoch:[ 95 5 ] loss: 0.39696601033210754 2022-07-01 09:20:56.445633
Epoch:[ 95 6 ] loss: 0.39682263135910034 2022-07-01 09:20:56.860418
Epoch:[ 95 7 ] loss: 0.3974308669567108 2022-07-01 09:20:57.267853
Epoch:[ 95 8 ] loss: 0.39686137437820435 2022-07-01 09:20:57.681759
Epoch:[ 95 9 ] loss: 0.3959321081638336 2022-07-01 09:20:58.094588
Epoch:[ 95 10 ] loss: 0.4009789228439331 2022-07-01 09:20:58.503921
Epoch:[ 95 11 ] loss: 0.39570310711860657 2022-07-01 09:20:58.912210
Epoch:[ 95 12 ] loss: 0.39763155579566956 2022-07-01 09:20:59.330049
Epoch:[ 95 13 ] loss: 0.39661091566085815 2022-07-01 09:20:59.738914
Epoch:[ 95 14 ] loss: 0.39762434363365173 2022-07-01 09:21:00.152456
Epoch:[ 95 15 ] loss: 0.3984604775905609 2022-07-01 09:21:00.567961
Epoch:[ 95 16 ] loss: 0.3984580636024475 2022-07-01 09:21:06.244623
Epoch:[ 95 17 ] loss: 0.3983877897262573 2022-07-01 09:21:06.655023
Epoch:[ 95 18 ] loss: 0.39885443449020386 2022-07-01 09:21:07.083326
Epoch:[ 95 19 ] loss: 0.3953408896923065 2022-07-01 09:21:07.498913
Training_Epoch:[ 95 ] Training_loss: 0.39746632277965543 2022-07-01 09:21:07.499763
learning rate:  0.0013421772800000008
val: 1 0.45131823420524597
val: 2 0.44526854157447815
val: 3 0.4488362967967987
val: 4 0.4451821744441986
val: 5 0.43680712580680847
val: 6 0.4350370764732361
val: 7 0.4462645351886749
val: 8 0.44024211168289185
val: 9 0.44404810667037964
val: 10 0.46468424797058105
val: 11 0.4440913498401642
val: 12 0.4505099058151245
val: 13 0.43633973598480225
val: 14 0.43001964688301086
val: 15 0.4444148540496826
val: 16 0.4476228654384613
val: 17 0.44249480962753296
val: 18 0.449204683303833
val: 19 0.440096378326416
val: 20 0.44015347957611084
val_Epoch:[ 95 ] val_loss: 0.4441318079829216 2022-07-01 09:21:11.170380
start training 2022-07-01 09:21:11.283806
