GPU: True
80
start training 2022-06-30 23:47:45.208287
Epoch:[ 1 0 ] loss: 0.6947557926177979 2022-06-30 23:48:07.602532
Epoch:[ 1 1 ] loss: 0.6980770230293274 2022-06-30 23:48:08.078199
Epoch:[ 1 2 ] loss: 0.691495418548584 2022-06-30 23:48:08.489204
Epoch:[ 1 3 ] loss: 0.6757524013519287 2022-06-30 23:48:08.908159
Epoch:[ 1 4 ] loss: 0.6545972228050232 2022-06-30 23:48:09.328634
Epoch:[ 1 5 ] loss: 0.6322706937789917 2022-06-30 23:48:09.739410
Epoch:[ 1 6 ] loss: 0.6120383143424988 2022-06-30 23:48:10.150738
Epoch:[ 1 7 ] loss: 0.5991942882537842 2022-06-30 23:48:10.559776
Epoch:[ 1 8 ] loss: 0.5849853157997131 2022-06-30 23:48:10.988862
Epoch:[ 1 9 ] loss: 0.582452118396759 2022-06-30 23:48:11.426518
Epoch:[ 1 10 ] loss: 0.5702376365661621 2022-06-30 23:48:11.862261
Epoch:[ 1 11 ] loss: 0.5750871896743774 2022-06-30 23:48:12.292983
Epoch:[ 1 12 ] loss: 0.5707048773765564 2022-06-30 23:48:12.722678
Epoch:[ 1 13 ] loss: 0.5691962242126465 2022-06-30 23:48:13.156247
Epoch:[ 1 14 ] loss: 0.5750043392181396 2022-06-30 23:48:13.587376
Epoch:[ 1 15 ] loss: 0.5718757510185242 2022-06-30 23:48:14.020047
Epoch:[ 1 16 ] loss: 0.5717774629592896 2022-06-30 23:48:14.451343
Epoch:[ 1 17 ] loss: 0.5644472241401672 2022-06-30 23:48:14.883757
Epoch:[ 1 18 ] loss: 0.5712325572967529 2022-06-30 23:48:15.322227
Epoch:[ 1 19 ] loss: 0.5605303645133972 2022-06-30 23:48:15.757175
Training_Epoch:[ 1 ] Training_loss: 0.6062856107950211 2022-06-30 23:48:15.757862
learning rate:  0.05
val: 1 0.7859534025192261
val: 2 0.7805015444755554
val: 3 0.7805013060569763
val: 4 0.7949511408805847
val: 5 0.7619483470916748
val: 6 0.8054286241531372
val: 7 0.7815967202186584
val: 8 0.7816848158836365
val: 9 0.7850186824798584
val: 10 0.7803253531455994
val: 11 0.7821553945541382
val: 12 0.7823319435119629
val: 13 0.7849193811416626
val: 14 0.7678690552711487
val: 15 0.7844835519790649
val: 16 0.7817139029502869
val: 17 0.7788673639297485
val: 18 0.7533342838287354
val: 19 0.7891712188720703
val: 20 0.7732087969779968
val_Epoch:[ 1 ] val_loss: 0.7807982414960861 2022-06-30 23:48:19.553733
start training 2022-06-30 23:48:19.657491
Epoch:[ 2 0 ] loss: 0.56479412317276 2022-06-30 23:48:34.664730
Epoch:[ 2 1 ] loss: 0.5598137974739075 2022-06-30 23:48:35.099052
Epoch:[ 2 2 ] loss: 0.5646846890449524 2022-06-30 23:48:35.529341
Epoch:[ 2 3 ] loss: 0.5581094026565552 2022-06-30 23:48:35.964124
Epoch:[ 2 4 ] loss: 0.5662544369697571 2022-06-30 23:48:36.397935
Epoch:[ 2 5 ] loss: 0.5642781853675842 2022-06-30 23:48:36.830465
Epoch:[ 2 6 ] loss: 0.5639540553092957 2022-06-30 23:48:37.267099
Epoch:[ 2 7 ] loss: 0.5616444945335388 2022-06-30 23:48:37.702778
Epoch:[ 2 8 ] loss: 0.5613421201705933 2022-06-30 23:48:38.132423
Epoch:[ 2 9 ] loss: 0.5592355132102966 2022-06-30 23:48:38.560443
Epoch:[ 2 10 ] loss: 0.5594900846481323 2022-06-30 23:48:38.999052
Epoch:[ 2 11 ] loss: 0.5568786859512329 2022-06-30 23:48:39.433004
Epoch:[ 2 12 ] loss: 0.5581846833229065 2022-06-30 23:48:39.866883
Epoch:[ 2 13 ] loss: 0.558078408241272 2022-06-30 23:48:40.302208
Epoch:[ 2 14 ] loss: 0.5529014468193054 2022-06-30 23:48:40.738167
Epoch:[ 2 15 ] loss: 0.5611578226089478 2022-06-30 23:48:41.172175
Epoch:[ 2 16 ] loss: 0.557975172996521 2022-06-30 23:48:46.003406
Epoch:[ 2 17 ] loss: 0.55599445104599 2022-06-30 23:48:46.435636
Epoch:[ 2 18 ] loss: 0.5574514269828796 2022-06-30 23:48:46.889114
Epoch:[ 2 19 ] loss: 0.5574275255203247 2022-06-30 23:48:47.321807
Training_Epoch:[ 2 ] Training_loss: 0.5599825263023377 2022-06-30 23:48:47.322427
learning rate:  0.05
netparams have been saved once 2
val: 1 0.6893870830535889
val: 2 0.6890268921852112
val: 3 0.6930086612701416
val: 4 0.6901228427886963
val: 5 0.7026874423027039
val: 6 0.6969577670097351
val: 7 0.6810263395309448
val: 8 0.6993414163589478
val: 9 0.6990647315979004
val: 10 0.6958912014961243
val: 11 0.6979756951332092
val: 12 0.6927328109741211
val: 13 0.7030472159385681
val: 14 0.7214699387550354
val: 15 0.6919962167739868
val: 16 0.6924278736114502
val: 17 0.7043322920799255
val: 18 0.7190971970558167
val: 19 0.7001051306724548
val: 20 0.7019301652908325
val_Epoch:[ 2 ] val_loss: 0.6980814456939697 2022-06-30 23:48:51.155630
start training 2022-06-30 23:48:51.250113
Epoch:[ 3 0 ] loss: 0.554202139377594 2022-06-30 23:49:06.326889
Epoch:[ 3 1 ] loss: 0.5543320775032043 2022-06-30 23:49:06.762776
Epoch:[ 3 2 ] loss: 0.556326150894165 2022-06-30 23:49:07.197484
Epoch:[ 3 3 ] loss: 0.5530954599380493 2022-06-30 23:49:07.631015
Epoch:[ 3 4 ] loss: 0.5546627044677734 2022-06-30 23:49:08.064794
Epoch:[ 3 5 ] loss: 0.5552998185157776 2022-06-30 23:49:08.497803
Epoch:[ 3 6 ] loss: 0.5532699823379517 2022-06-30 23:49:08.932034
Epoch:[ 3 7 ] loss: 0.5517888069152832 2022-06-30 23:49:09.366269
Epoch:[ 3 8 ] loss: 0.5513797998428345 2022-06-30 23:49:09.800378
Epoch:[ 3 9 ] loss: 0.5547536015510559 2022-06-30 23:49:10.233760
Epoch:[ 3 10 ] loss: 0.5540233850479126 2022-06-30 23:49:10.664009
Epoch:[ 3 11 ] loss: 0.5504570007324219 2022-06-30 23:49:11.093090
Epoch:[ 3 12 ] loss: 0.5544734597206116 2022-06-30 23:49:11.521830
Epoch:[ 3 13 ] loss: 0.5564567446708679 2022-06-30 23:49:11.956521
Epoch:[ 3 14 ] loss: 0.5533656477928162 2022-06-30 23:49:12.391577
Epoch:[ 3 15 ] loss: 0.5503997802734375 2022-06-30 23:49:12.829919
Epoch:[ 3 16 ] loss: 0.5439457893371582 2022-06-30 23:49:17.798021
Epoch:[ 3 17 ] loss: 0.549390971660614 2022-06-30 23:49:18.228970
Epoch:[ 3 18 ] loss: 0.5490094423294067 2022-06-30 23:49:18.667837
Epoch:[ 3 19 ] loss: 0.5490167140960693 2022-06-30 23:49:19.100935
Training_Epoch:[ 3 ] Training_loss: 0.5524824738502503 2022-06-30 23:49:19.101572
learning rate:  0.05
val: 1 0.5683689117431641
val: 2 0.5617393255233765
val: 3 0.5713397860527039
val: 4 0.5695641040802002
val: 5 0.5497011542320251
val: 6 0.5520988702774048
val: 7 0.5518639087677002
val: 8 0.5622662901878357
val: 9 0.5616674423217773
val: 10 0.5580621957778931
val: 11 0.5688117742538452
val: 12 0.5611677765846252
val: 13 0.5666698813438416
val: 14 0.5515974760055542
val: 15 0.5734562277793884
val: 16 0.5652369856834412
val: 17 0.5534117817878723
val: 18 0.5725042819976807
val: 19 0.5663851499557495
val: 20 0.5508646965026855
val_Epoch:[ 3 ] val_loss: 0.5618389010429382 2022-06-30 23:49:22.969131
start training 2022-06-30 23:49:23.086499
Epoch:[ 4 0 ] loss: 0.5492985248565674 2022-06-30 23:49:37.853309
Epoch:[ 4 1 ] loss: 0.5482503175735474 2022-06-30 23:49:38.290027
Epoch:[ 4 2 ] loss: 0.5479803085327148 2022-06-30 23:49:38.725830
Epoch:[ 4 3 ] loss: 0.5490976572036743 2022-06-30 23:49:39.160852
Epoch:[ 4 4 ] loss: 0.5481441020965576 2022-06-30 23:49:39.595579
Epoch:[ 4 5 ] loss: 0.5475300550460815 2022-06-30 23:49:40.029044
Epoch:[ 4 6 ] loss: 0.5441984534263611 2022-06-30 23:49:40.465201
Epoch:[ 4 7 ] loss: 0.5435810685157776 2022-06-30 23:49:40.899117
Epoch:[ 4 8 ] loss: 0.5434424877166748 2022-06-30 23:49:41.335540
Epoch:[ 4 9 ] loss: 0.5446894764900208 2022-06-30 23:49:41.766648
Epoch:[ 4 10 ] loss: 0.5500956773757935 2022-06-30 23:49:42.201377
Epoch:[ 4 11 ] loss: 0.5466376543045044 2022-06-30 23:49:42.638632
Epoch:[ 4 12 ] loss: 0.5371653437614441 2022-06-30 23:49:43.068153
Epoch:[ 4 13 ] loss: 0.5400368571281433 2022-06-30 23:49:43.505111
Epoch:[ 4 14 ] loss: 0.5416723489761353 2022-06-30 23:49:43.939441
Epoch:[ 4 15 ] loss: 0.536859393119812 2022-06-30 23:49:44.369683
Epoch:[ 4 16 ] loss: 0.5437831878662109 2022-06-30 23:49:49.514429
Epoch:[ 4 17 ] loss: 0.5393884778022766 2022-06-30 23:49:49.946574
Epoch:[ 4 18 ] loss: 0.5399707555770874 2022-06-30 23:49:50.399603
Epoch:[ 4 19 ] loss: 0.5419742465019226 2022-06-30 23:49:50.835593
Training_Epoch:[ 4 ] Training_loss: 0.5441898196935654 2022-06-30 23:49:50.836251
learning rate:  0.05
netparams have been saved once 4
val: 1 0.546836256980896
val: 2 0.5468823909759521
val: 3 0.5567290782928467
val: 4 0.5529201030731201
val: 5 0.5433146357536316
val: 6 0.5364376902580261
val: 7 0.5417982935905457
val: 8 0.54328453540802
val: 9 0.5415663123130798
val: 10 0.5395618081092834
val: 11 0.5395082831382751
val: 12 0.5389997959136963
val: 13 0.5473736524581909
val: 14 0.5476495027542114
val: 15 0.5582124590873718
val: 16 0.5524991750717163
val: 17 0.545708179473877
val: 18 0.5465888381004333
val: 19 0.5390536189079285
val: 20 0.5544818639755249
val_Epoch:[ 4 ] val_loss: 0.5459703236818314 2022-06-30 23:49:54.709614
start training 2022-06-30 23:49:54.810025
Epoch:[ 5 0 ] loss: 0.5347000956535339 2022-06-30 23:50:08.957784
Epoch:[ 5 1 ] loss: 0.5391149520874023 2022-06-30 23:50:09.442143
Epoch:[ 5 2 ] loss: 0.5388277769088745 2022-06-30 23:50:09.877463
Epoch:[ 5 3 ] loss: 0.5381888747215271 2022-06-30 23:50:10.307994
Epoch:[ 5 4 ] loss: 0.5353584289550781 2022-06-30 23:50:10.743192
Epoch:[ 5 5 ] loss: 0.5368433594703674 2022-06-30 23:50:11.178574
Epoch:[ 5 6 ] loss: 0.5385693907737732 2022-06-30 23:50:11.613737
Epoch:[ 5 7 ] loss: 0.5344306826591492 2022-06-30 23:50:12.053921
Epoch:[ 5 8 ] loss: 0.535659909248352 2022-06-30 23:50:12.487673
Epoch:[ 5 9 ] loss: 0.533902108669281 2022-06-30 23:50:12.923233
Epoch:[ 5 10 ] loss: 0.532974898815155 2022-06-30 23:50:13.358979
Epoch:[ 5 11 ] loss: 0.537036657333374 2022-06-30 23:50:13.787525
Epoch:[ 5 12 ] loss: 0.5366782546043396 2022-06-30 23:50:14.221019
Epoch:[ 5 13 ] loss: 0.5322668552398682 2022-06-30 23:50:14.654373
Epoch:[ 5 14 ] loss: 0.5360096096992493 2022-06-30 23:50:15.089729
Epoch:[ 5 15 ] loss: 0.5326858162879944 2022-06-30 23:50:15.522328
Epoch:[ 5 16 ] loss: 0.5362120866775513 2022-06-30 23:50:21.349060
Epoch:[ 5 17 ] loss: 0.5352436900138855 2022-06-30 23:50:21.781569
Epoch:[ 5 18 ] loss: 0.5389939546585083 2022-06-30 23:50:22.225634
Epoch:[ 5 19 ] loss: 0.5293979644775391 2022-06-30 23:50:22.658784
Training_Epoch:[ 5 ] Training_loss: 0.5356547683477402 2022-06-30 23:50:22.659494
learning rate:  0.05
val: 1 0.6439870595932007
val: 2 0.6567310690879822
val: 3 0.640822172164917
val: 4 0.6451852321624756
val: 5 0.6540974974632263
val: 6 0.6558493971824646
val: 7 0.6362496018409729
val: 8 0.6371200084686279
val: 9 0.6546177864074707
val: 10 0.6438405513763428
val: 11 0.6560363173484802
val: 12 0.6487299799919128
val: 13 0.6615052819252014
val: 14 0.6591305732727051
val: 15 0.6485066413879395
val: 16 0.6578601598739624
val: 17 0.6606399416923523
val: 18 0.659088134765625
val: 19 0.6489058136940002
val: 20 0.6550050377845764
val_Epoch:[ 5 ] val_loss: 0.6511954128742218 2022-06-30 23:50:26.490824
start training 2022-06-30 23:50:26.608605
Epoch:[ 6 0 ] loss: 0.5344768166542053 2022-06-30 23:50:41.637119
Epoch:[ 6 1 ] loss: 0.5343827605247498 2022-06-30 23:50:42.071238
Epoch:[ 6 2 ] loss: 0.5232987403869629 2022-06-30 23:50:42.506745
Epoch:[ 6 3 ] loss: 0.5293417572975159 2022-06-30 23:50:42.941973
Epoch:[ 6 4 ] loss: 0.5332794785499573 2022-06-30 23:50:43.377161
Epoch:[ 6 5 ] loss: 0.5339757204055786 2022-06-30 23:50:43.811731
Epoch:[ 6 6 ] loss: 0.5269774794578552 2022-06-30 23:50:44.245594
Epoch:[ 6 7 ] loss: 0.5287449359893799 2022-06-30 23:50:44.677970
Epoch:[ 6 8 ] loss: 0.5309218168258667 2022-06-30 23:50:45.109788
Epoch:[ 6 9 ] loss: 0.5284441709518433 2022-06-30 23:50:45.538134
Epoch:[ 6 10 ] loss: 0.5301889777183533 2022-06-30 23:50:45.974146
Epoch:[ 6 11 ] loss: 0.5292276740074158 2022-06-30 23:50:46.408292
Epoch:[ 6 12 ] loss: 0.5273145437240601 2022-06-30 23:50:46.839801
Epoch:[ 6 13 ] loss: 0.5241057276725769 2022-06-30 23:50:47.273589
Epoch:[ 6 14 ] loss: 0.5233566761016846 2022-06-30 23:50:47.707003
Epoch:[ 6 15 ] loss: 0.518724262714386 2022-06-30 23:50:48.140469
Epoch:[ 6 16 ] loss: 0.5258663296699524 2022-06-30 23:50:53.173487
Epoch:[ 6 17 ] loss: 0.5260761380195618 2022-06-30 23:50:53.605886
Epoch:[ 6 18 ] loss: 0.5224481225013733 2022-06-30 23:50:54.048961
Epoch:[ 6 19 ] loss: 0.5193352699279785 2022-06-30 23:50:54.482632
Training_Epoch:[ 6 ] Training_loss: 0.5275243699550629 2022-06-30 23:50:54.483265
learning rate:  0.05
netparams have been saved once 6
val: 1 0.5832505822181702
val: 2 0.578409731388092
val: 3 0.5769258737564087
val: 4 0.5684180855751038
val: 5 0.5779926180839539
val: 6 0.577350378036499
val: 7 0.5594626069068909
val: 8 0.5726168155670166
val: 9 0.574245035648346
val: 10 0.5741212964057922
val: 11 0.566491961479187
val: 12 0.5621007680892944
val: 13 0.5723981261253357
val: 14 0.5601290464401245
val: 15 0.5633792281150818
val: 16 0.5677448511123657
val: 17 0.5666481256484985
val: 18 0.5926365852355957
val: 19 0.575370192527771
val: 20 0.5634514093399048
val_Epoch:[ 6 ] val_loss: 0.5716571658849716 2022-06-30 23:50:58.331196
start training 2022-06-30 23:50:58.431220
Epoch:[ 7 0 ] loss: 0.5240128040313721 2022-06-30 23:51:13.129236
Epoch:[ 7 1 ] loss: 0.5209246873855591 2022-06-30 23:51:13.562266
Epoch:[ 7 2 ] loss: 0.5234192609786987 2022-06-30 23:51:13.996011
Epoch:[ 7 3 ] loss: 0.5212076306343079 2022-06-30 23:51:14.428615
Epoch:[ 7 4 ] loss: 0.5227391719818115 2022-06-30 23:51:14.863580
Epoch:[ 7 5 ] loss: 0.5215677618980408 2022-06-30 23:51:15.293410
Epoch:[ 7 6 ] loss: 0.5206518173217773 2022-06-30 23:51:15.730843
Epoch:[ 7 7 ] loss: 0.5220597982406616 2022-06-30 23:51:16.166706
Epoch:[ 7 8 ] loss: 0.5167245268821716 2022-06-30 23:51:16.595888
Epoch:[ 7 9 ] loss: 0.5217764973640442 2022-06-30 23:51:17.031957
Epoch:[ 7 10 ] loss: 0.5200574994087219 2022-06-30 23:51:17.468995
Epoch:[ 7 11 ] loss: 0.5133530497550964 2022-06-30 23:51:17.904073
Epoch:[ 7 12 ] loss: 0.5187380313873291 2022-06-30 23:51:18.335597
Epoch:[ 7 13 ] loss: 0.5165314674377441 2022-06-30 23:51:18.770767
Epoch:[ 7 14 ] loss: 0.5182577967643738 2022-06-30 23:51:19.205799
Epoch:[ 7 15 ] loss: 0.5155687928199768 2022-06-30 23:51:19.640820
Epoch:[ 7 16 ] loss: 0.5161094069480896 2022-06-30 23:51:24.887355
Epoch:[ 7 17 ] loss: 0.5174598097801208 2022-06-30 23:51:25.321837
Epoch:[ 7 18 ] loss: 0.5135372281074524 2022-06-30 23:51:25.762888
Epoch:[ 7 19 ] loss: 0.5156477093696594 2022-06-30 23:51:26.200419
Training_Epoch:[ 7 ] Training_loss: 0.5190172374248505 2022-06-30 23:51:26.201147
learning rate:  0.05
val: 1 0.5751721262931824
val: 2 0.5718759298324585
val: 3 0.5880668759346008
val: 4 0.5742855668067932
val: 5 0.579603910446167
val: 6 0.5731843113899231
val: 7 0.5780123472213745
val: 8 0.5857613682746887
val: 9 0.5748088955879211
val: 10 0.5691652297973633
val: 11 0.5746413469314575
val: 12 0.5729422569274902
val: 13 0.5929851531982422
val: 14 0.5713603496551514
val: 15 0.5633538961410522
val: 16 0.5845108032226562
val: 17 0.586841344833374
val: 18 0.5817410945892334
val: 19 0.5748360753059387
val: 20 0.5650374293327332
val_Epoch:[ 7 ] val_loss: 0.57690931558609 2022-06-30 23:51:29.967951
start training 2022-06-30 23:51:30.065235
Epoch:[ 8 0 ] loss: 0.5104703903198242 2022-06-30 23:51:44.229982
Epoch:[ 8 1 ] loss: 0.5186207294464111 2022-06-30 23:51:44.673586
Epoch:[ 8 2 ] loss: 0.514430046081543 2022-06-30 23:51:45.111683
Epoch:[ 8 3 ] loss: 0.5126527547836304 2022-06-30 23:51:45.548168
Epoch:[ 8 4 ] loss: 0.5156564116477966 2022-06-30 23:51:45.979296
Epoch:[ 8 5 ] loss: 0.5153844952583313 2022-06-30 23:51:46.415751
Epoch:[ 8 6 ] loss: 0.5173733830451965 2022-06-30 23:51:46.851729
Epoch:[ 8 7 ] loss: 0.5117363929748535 2022-06-30 23:51:47.286821
Epoch:[ 8 8 ] loss: 0.5072598457336426 2022-06-30 23:51:47.722280
Epoch:[ 8 9 ] loss: 0.5149502158164978 2022-06-30 23:51:48.132020
Epoch:[ 8 10 ] loss: 0.5182972550392151 2022-06-30 23:51:48.540337
Epoch:[ 8 11 ] loss: 0.5098404288291931 2022-06-30 23:51:48.949862
Epoch:[ 8 12 ] loss: 0.511287271976471 2022-06-30 23:51:49.359681
Epoch:[ 8 13 ] loss: 0.51338791847229 2022-06-30 23:51:49.769994
Epoch:[ 8 14 ] loss: 0.5066778063774109 2022-06-30 23:51:50.185623
Epoch:[ 8 15 ] loss: 0.5105561017990112 2022-06-30 23:51:50.594040
Epoch:[ 8 16 ] loss: 0.5122674107551575 2022-06-30 23:51:56.583483
Epoch:[ 8 17 ] loss: 0.5138381719589233 2022-06-30 23:51:56.989120
Epoch:[ 8 18 ] loss: 0.5079496502876282 2022-06-30 23:51:57.429993
Epoch:[ 8 19 ] loss: 0.5097582340240479 2022-06-30 23:51:57.864699
Training_Epoch:[ 8 ] Training_loss: 0.5126197457313537 2022-06-30 23:51:57.865400
learning rate:  0.05
netparams have been saved once 8
val: 1 0.5287625789642334
val: 2 0.5391135811805725
val: 3 0.5157483816146851
val: 4 0.5416300892829895
val: 5 0.5276517271995544
val: 6 0.5267632007598877
val: 7 0.5235114693641663
val: 8 0.5261646509170532
val: 9 0.5242257118225098
val: 10 0.5137501358985901
val: 11 0.5328706502914429
val: 12 0.5340287089347839
val: 13 0.5283684730529785
val: 14 0.5340009331703186
val: 15 0.5411824584007263
val: 16 0.5289004445075989
val: 17 0.5178204774856567
val: 18 0.5164547562599182
val: 19 0.5222469568252563
val: 20 0.5339488983154297
val_Epoch:[ 8 ] val_loss: 0.5278572142124176 2022-06-30 23:52:01.751395
start training 2022-06-30 23:52:01.853379
Epoch:[ 9 0 ] loss: 0.5127730965614319 2022-06-30 23:52:15.927312
Epoch:[ 9 1 ] loss: 0.5163097977638245 2022-06-30 23:52:16.837833
Epoch:[ 9 2 ] loss: 0.5104476809501648 2022-06-30 23:52:17.269016
Epoch:[ 9 3 ] loss: 0.5107793807983398 2022-06-30 23:52:17.706854
Epoch:[ 9 4 ] loss: 0.510662317276001 2022-06-30 23:52:18.140106
Epoch:[ 9 5 ] loss: 0.5071929097175598 2022-06-30 23:52:18.570534
Epoch:[ 9 6 ] loss: 0.5115398168563843 2022-06-30 23:52:19.006587
Epoch:[ 9 7 ] loss: 0.5137683749198914 2022-06-30 23:52:19.442245
Epoch:[ 9 8 ] loss: 0.511771559715271 2022-06-30 23:52:19.878072
Epoch:[ 9 9 ] loss: 0.505569338798523 2022-06-30 23:52:20.312231
Epoch:[ 9 10 ] loss: 0.5171023011207581 2022-06-30 23:52:20.746013
Epoch:[ 9 11 ] loss: 0.5119512677192688 2022-06-30 23:52:21.180241
Epoch:[ 9 12 ] loss: 0.5147386193275452 2022-06-30 23:52:21.613261
Epoch:[ 9 13 ] loss: 0.5157939791679382 2022-06-30 23:52:22.048778
Epoch:[ 9 14 ] loss: 0.5147274732589722 2022-06-30 23:52:22.485859
Epoch:[ 9 15 ] loss: 0.5114156603813171 2022-06-30 23:52:22.919618
Epoch:[ 9 16 ] loss: 0.5049045085906982 2022-06-30 23:52:27.754342
Epoch:[ 9 17 ] loss: 0.5137345194816589 2022-06-30 23:52:28.281984
Epoch:[ 9 18 ] loss: 0.5090512037277222 2022-06-30 23:52:28.722684
Epoch:[ 9 19 ] loss: 0.5139391422271729 2022-06-30 23:52:29.156423
Training_Epoch:[ 9 ] Training_loss: 0.5119086474180221 2022-06-30 23:52:29.157110
learning rate:  0.05
val: 1 0.5208171010017395
val: 2 0.5228121876716614
val: 3 0.512285590171814
val: 4 0.5246748924255371
val: 5 0.5364336967468262
val: 6 0.520309329032898
val: 7 0.520987868309021
val: 8 0.532137393951416
val: 9 0.5285181403160095
val: 10 0.5366086363792419
val: 11 0.5268574953079224
val: 12 0.5224815011024475
val: 13 0.530397355556488
val: 14 0.5231619477272034
val: 15 0.5238447189331055
val: 16 0.5267091393470764
val: 17 0.5230072736740112
val: 18 0.5221258401870728
val: 19 0.5212060809135437
val: 20 0.5180932879447937
val_Epoch:[ 9 ] val_loss: 0.5246734738349914 2022-06-30 23:52:32.986849
start training 2022-06-30 23:52:33.087772
Epoch:[ 10 0 ] loss: 0.5069127678871155 2022-06-30 23:52:47.407431
Epoch:[ 10 1 ] loss: 0.5104868412017822 2022-06-30 23:52:48.004226
Epoch:[ 10 2 ] loss: 0.5103223323822021 2022-06-30 23:52:48.432982
Epoch:[ 10 3 ] loss: 0.506417989730835 2022-06-30 23:52:48.865908
Epoch:[ 10 4 ] loss: 0.5074819922447205 2022-06-30 23:52:49.299508
Epoch:[ 10 5 ] loss: 0.5077545642852783 2022-06-30 23:52:49.730524
Epoch:[ 10 6 ] loss: 0.5045019388198853 2022-06-30 23:52:50.164322
Epoch:[ 10 7 ] loss: 0.5047221183776855 2022-06-30 23:52:50.599783
Epoch:[ 10 8 ] loss: 0.5040708184242249 2022-06-30 23:52:51.034622
Epoch:[ 10 9 ] loss: 0.5048127770423889 2022-06-30 23:52:51.468564
Epoch:[ 10 10 ] loss: 0.5097825527191162 2022-06-30 23:52:51.902561
Epoch:[ 10 11 ] loss: 0.5073662996292114 2022-06-30 23:52:52.335890
Epoch:[ 10 12 ] loss: 0.508122444152832 2022-06-30 23:52:52.768026
Epoch:[ 10 13 ] loss: 0.505970299243927 2022-06-30 23:52:53.200131
Epoch:[ 10 14 ] loss: 0.5035710334777832 2022-06-30 23:52:53.634992
Epoch:[ 10 15 ] loss: 0.5060085654258728 2022-06-30 23:52:54.070144
Epoch:[ 10 16 ] loss: 0.5054804086685181 2022-06-30 23:52:59.703655
Epoch:[ 10 17 ] loss: 0.5061048269271851 2022-06-30 23:53:00.132856
Epoch:[ 10 18 ] loss: 0.5065940022468567 2022-06-30 23:53:00.574254
Epoch:[ 10 19 ] loss: 0.5089040994644165 2022-06-30 23:53:01.007685
Training_Epoch:[ 10 ] Training_loss: 0.5067694336175919 2022-06-30 23:53:01.008296
learning rate:  0.05
netparams have been saved once 10
val: 1 0.4941868484020233
val: 2 0.5067018270492554
val: 3 0.5014728903770447
val: 4 0.5162447094917297
val: 5 0.5024011731147766
val: 6 0.5084404945373535
val: 7 0.5073145031929016
val: 8 0.5101187825202942
val: 9 0.5018802881240845
val: 10 0.5102116465568542
val: 11 0.5016446113586426
val: 12 0.49794045090675354
val: 13 0.5126861333847046
val: 14 0.5043139457702637
val: 15 0.4959913492202759
val: 16 0.5053188800811768
val: 17 0.5173419117927551
val: 18 0.5041791200637817
val: 19 0.50822913646698
val: 20 0.5018438696861267
val_Epoch:[ 10 ] val_loss: 0.5054231286048889 2022-06-30 23:53:04.841319
start training 2022-06-30 23:53:04.936495
Epoch:[ 11 0 ] loss: 0.5050170421600342 2022-06-30 23:53:19.923432
Epoch:[ 11 1 ] loss: 0.5056146383285522 2022-06-30 23:53:20.360451
Epoch:[ 11 2 ] loss: 0.5037690997123718 2022-06-30 23:53:20.797757
Epoch:[ 11 3 ] loss: 0.5054516792297363 2022-06-30 23:53:21.231508
Epoch:[ 11 4 ] loss: 0.5029841065406799 2022-06-30 23:53:21.659990
Epoch:[ 11 5 ] loss: 0.49965912103652954 2022-06-30 23:53:22.094012
Epoch:[ 11 6 ] loss: 0.5037481188774109 2022-06-30 23:53:22.528288
Epoch:[ 11 7 ] loss: 0.5020855665206909 2022-06-30 23:53:22.961914
Epoch:[ 11 8 ] loss: 0.5036038756370544 2022-06-30 23:53:23.397003
Epoch:[ 11 9 ] loss: 0.5073559284210205 2022-06-30 23:53:23.831679
Epoch:[ 11 10 ] loss: 0.5048617720603943 2022-06-30 23:53:24.268560
Epoch:[ 11 11 ] loss: 0.5027148723602295 2022-06-30 23:53:24.697439
Epoch:[ 11 12 ] loss: 0.504001796245575 2022-06-30 23:53:25.131329
Epoch:[ 11 13 ] loss: 0.5028348565101624 2022-06-30 23:53:25.564413
Epoch:[ 11 14 ] loss: 0.49905285239219666 2022-06-30 23:53:25.998212
Epoch:[ 11 15 ] loss: 0.5007020831108093 2022-06-30 23:53:26.432554
Epoch:[ 11 16 ] loss: 0.5056519508361816 2022-06-30 23:53:31.722167
Epoch:[ 11 17 ] loss: 0.5034728646278381 2022-06-30 23:53:32.154425
Epoch:[ 11 18 ] loss: 0.5039172172546387 2022-06-30 23:53:32.595853
Epoch:[ 11 19 ] loss: 0.5030201077461243 2022-06-30 23:53:33.030151
Training_Epoch:[ 11 ] Training_loss: 0.5034759774804115 2022-06-30 23:53:33.030827
learning rate:  0.04000000000000001
val: 1 0.5256174206733704
val: 2 0.5213606357574463
val: 3 0.5338640213012695
val: 4 0.5260278582572937
val: 5 0.5164715647697449
val: 6 0.5358108282089233
val: 7 0.5260061621665955
val: 8 0.518955647945404
val: 9 0.5218254923820496
val: 10 0.5280753970146179
val: 11 0.5140722990036011
val: 12 0.5249520540237427
val: 13 0.515250563621521
val: 14 0.5182607173919678
val: 15 0.5219073295593262
val: 16 0.5138909816741943
val: 17 0.5190918445587158
val: 18 0.5273972153663635
val: 19 0.5117972493171692
val: 20 0.5283654928207397
val_Epoch:[ 11 ] val_loss: 0.5224500387907028 2022-06-30 23:53:36.708615
start training 2022-06-30 23:53:36.808430
Epoch:[ 12 0 ] loss: 0.49872922897338867 2022-06-30 23:53:51.351898
Epoch:[ 12 1 ] loss: 0.5006601810455322 2022-06-30 23:53:51.792841
Epoch:[ 12 2 ] loss: 0.5013516545295715 2022-06-30 23:53:52.228369
Epoch:[ 12 3 ] loss: 0.49997416138648987 2022-06-30 23:53:52.660131
Epoch:[ 12 4 ] loss: 0.5055685043334961 2022-06-30 23:53:53.096819
Epoch:[ 12 5 ] loss: 0.5055142641067505 2022-06-30 23:53:53.524669
Epoch:[ 12 6 ] loss: 0.5006663799285889 2022-06-30 23:53:53.959578
Epoch:[ 12 7 ] loss: 0.4999741315841675 2022-06-30 23:53:54.393650
Epoch:[ 12 8 ] loss: 0.5004002451896667 2022-06-30 23:53:54.826374
Epoch:[ 12 9 ] loss: 0.5019761323928833 2022-06-30 23:53:55.261343
Epoch:[ 12 10 ] loss: 0.49930256605148315 2022-06-30 23:53:55.697562
Epoch:[ 12 11 ] loss: 0.5024993419647217 2022-06-30 23:53:56.127133
Epoch:[ 12 12 ] loss: 0.5007318258285522 2022-06-30 23:53:56.560272
Epoch:[ 12 13 ] loss: 0.5009766221046448 2022-06-30 23:53:56.992765
Epoch:[ 12 14 ] loss: 0.5059231519699097 2022-06-30 23:53:57.429053
Epoch:[ 12 15 ] loss: 0.4984678328037262 2022-06-30 23:53:57.861888
Epoch:[ 12 16 ] loss: 0.5013731718063354 2022-06-30 23:54:03.248539
Epoch:[ 12 17 ] loss: 0.5016785860061646 2022-06-30 23:54:03.685697
Epoch:[ 12 18 ] loss: 0.5053972005844116 2022-06-30 23:54:04.130879
Epoch:[ 12 19 ] loss: 0.5032073259353638 2022-06-30 23:54:04.563766
Training_Epoch:[ 12 ] Training_loss: 0.5017186254262924 2022-06-30 23:54:04.564407
learning rate:  0.04000000000000001
netparams have been saved once 12
val: 1 0.5088475346565247
val: 2 0.5070273876190186
val: 3 0.5205556750297546
val: 4 0.5204526782035828
val: 5 0.5220057964324951
val: 6 0.5293540358543396
val: 7 0.5174780488014221
val: 8 0.5283989906311035
val: 9 0.5073662996292114
val: 10 0.5207363963127136
val: 11 0.5161057114601135
val: 12 0.5290010571479797
val: 13 0.5191256999969482
val: 14 0.5082455277442932
val: 15 0.5170758366584778
val: 16 0.5173417329788208
val: 17 0.5180742144584656
val: 18 0.5292363166809082
val: 19 0.5304805040359497
val: 20 0.5225138068199158
val_Epoch:[ 12 ] val_loss: 0.519471162557602 2022-06-30 23:54:08.415379
start training 2022-06-30 23:54:08.515275
Epoch:[ 13 0 ] loss: 0.49849867820739746 2022-06-30 23:54:22.603808
Epoch:[ 13 1 ] loss: 0.4999997615814209 2022-06-30 23:54:23.048660
Epoch:[ 13 2 ] loss: 0.500088632106781 2022-06-30 23:54:23.483227
Epoch:[ 13 3 ] loss: 0.5018920302391052 2022-06-30 23:54:23.918954
Epoch:[ 13 4 ] loss: 0.49456751346588135 2022-06-30 23:54:24.355926
Epoch:[ 13 5 ] loss: 0.5008474588394165 2022-06-30 23:54:24.793425
Epoch:[ 13 6 ] loss: 0.498879075050354 2022-06-30 23:54:25.223595
Epoch:[ 13 7 ] loss: 0.4992477297782898 2022-06-30 23:54:25.660497
Epoch:[ 13 8 ] loss: 0.49627038836479187 2022-06-30 23:54:26.094342
Epoch:[ 13 9 ] loss: 0.5013395547866821 2022-06-30 23:54:26.530507
Epoch:[ 13 10 ] loss: 0.4972670376300812 2022-06-30 23:54:26.964267
Epoch:[ 13 11 ] loss: 0.4958830773830414 2022-06-30 23:54:27.402362
Epoch:[ 13 12 ] loss: 0.4996539056301117 2022-06-30 23:54:27.838406
Epoch:[ 13 13 ] loss: 0.5060426592826843 2022-06-30 23:54:28.272948
Epoch:[ 13 14 ] loss: 0.5003088116645813 2022-06-30 23:54:28.710224
Epoch:[ 13 15 ] loss: 0.5026134848594666 2022-06-30 23:54:29.145312
Epoch:[ 13 16 ] loss: 0.5042248368263245 2022-06-30 23:54:34.347339
Epoch:[ 13 17 ] loss: 0.5002752542495728 2022-06-30 23:54:34.784308
Epoch:[ 13 18 ] loss: 0.5000880360603333 2022-06-30 23:54:35.228641
Epoch:[ 13 19 ] loss: 0.5050368309020996 2022-06-30 23:54:35.665052
Training_Epoch:[ 13 ] Training_loss: 0.5001512378454208 2022-06-30 23:54:35.665678
learning rate:  0.04000000000000001
val: 1 0.510478675365448
val: 2 0.5203166007995605
val: 3 0.5104455351829529
val: 4 0.5214070081710815
val: 5 0.5145171284675598
val: 6 0.5158470869064331
val: 7 0.5049567222595215
val: 8 0.5178197026252747
val: 9 0.5209739804267883
val: 10 0.5107366442680359
val: 11 0.5071113705635071
val: 12 0.5117951035499573
val: 13 0.5110332369804382
val: 14 0.5196386575698853
val: 15 0.5188398361206055
val: 16 0.5290461778640747
val: 17 0.5225569605827332
val: 18 0.531775951385498
val: 19 0.5161179900169373
val: 20 0.5238136053085327
val_Epoch:[ 13 ] val_loss: 0.5169613987207413 2022-06-30 23:54:39.486206
start training 2022-06-30 23:54:39.582829
Epoch:[ 14 0 ] loss: 0.49699950218200684 2022-06-30 23:54:53.946322
Epoch:[ 14 1 ] loss: 0.5005686283111572 2022-06-30 23:54:54.413601
Epoch:[ 14 2 ] loss: 0.4997202157974243 2022-06-30 23:54:54.849563
Epoch:[ 14 3 ] loss: 0.5002498030662537 2022-06-30 23:54:55.286718
Epoch:[ 14 4 ] loss: 0.4936011731624603 2022-06-30 23:54:55.717583
Epoch:[ 14 5 ] loss: 0.4966863989830017 2022-06-30 23:54:56.152749
Epoch:[ 14 6 ] loss: 0.5016044974327087 2022-06-30 23:54:56.589487
Epoch:[ 14 7 ] loss: 0.4998418688774109 2022-06-30 23:54:57.026754
Epoch:[ 14 8 ] loss: 0.49678835272789 2022-06-30 23:54:57.461454
Epoch:[ 14 9 ] loss: 0.49864089488983154 2022-06-30 23:54:57.896401
Epoch:[ 14 10 ] loss: 0.49755191802978516 2022-06-30 23:54:58.335232
Epoch:[ 14 11 ] loss: 0.4993685781955719 2022-06-30 23:54:58.771227
Epoch:[ 14 12 ] loss: 0.4994223117828369 2022-06-30 23:54:59.213278
Epoch:[ 14 13 ] loss: 0.49864640831947327 2022-06-30 23:54:59.650938
Epoch:[ 14 14 ] loss: 0.4988158643245697 2022-06-30 23:55:00.086846
Epoch:[ 14 15 ] loss: 0.4970181882381439 2022-06-30 23:55:00.519979
Epoch:[ 14 16 ] loss: 0.4937666654586792 2022-06-30 23:55:06.353072
Epoch:[ 14 17 ] loss: 0.49672460556030273 2022-06-30 23:55:06.787441
Epoch:[ 14 18 ] loss: 0.4919542372226715 2022-06-30 23:55:07.230941
Epoch:[ 14 19 ] loss: 0.49701711535453796 2022-06-30 23:55:07.659348
Training_Epoch:[ 14 ] Training_loss: 0.49774936139583587 2022-06-30 23:55:07.660068
learning rate:  0.04000000000000001
netparams have been saved once 14
val: 1 0.5579355359077454
val: 2 0.5683811902999878
val: 3 0.5502821207046509
val: 4 0.5469231605529785
val: 5 0.5487191677093506
val: 6 0.5542771220207214
val: 7 0.5319287180900574
val: 8 0.5414670705795288
val: 9 0.5652686953544617
val: 10 0.5499926805496216
val: 11 0.5626440644264221
val: 12 0.5497703552246094
val: 13 0.5395585298538208
val: 14 0.5533080101013184
val: 15 0.5532950162887573
val: 16 0.5534670352935791
val: 17 0.544674277305603
val: 18 0.5430247783660889
val: 19 0.5647339224815369
val: 20 0.5324164032936096
val_Epoch:[ 14 ] val_loss: 0.5506033927202225 2022-06-30 23:55:11.440084
start training 2022-06-30 23:55:11.539900
Epoch:[ 15 0 ] loss: 0.49687692523002625 2022-06-30 23:55:25.869976
Epoch:[ 15 1 ] loss: 0.4968864321708679 2022-06-30 23:55:26.296923
Epoch:[ 15 2 ] loss: 0.4950106143951416 2022-06-30 23:55:26.726857
Epoch:[ 15 3 ] loss: 0.4930912256240845 2022-06-30 23:55:27.147477
Epoch:[ 15 4 ] loss: 0.5009559988975525 2022-06-30 23:55:27.575718
Epoch:[ 15 5 ] loss: 0.4964637756347656 2022-06-30 23:55:27.997630
Epoch:[ 15 6 ] loss: 0.49407002329826355 2022-06-30 23:55:28.425314
Epoch:[ 15 7 ] loss: 0.4974432587623596 2022-06-30 23:55:28.854616
Epoch:[ 15 8 ] loss: 0.49950480461120605 2022-06-30 23:55:29.281108
Epoch:[ 15 9 ] loss: 0.49229755997657776 2022-06-30 23:55:29.709891
Epoch:[ 15 10 ] loss: 0.4900243282318115 2022-06-30 23:55:30.138794
Epoch:[ 15 11 ] loss: 0.5021710395812988 2022-06-30 23:55:30.569765
Epoch:[ 15 12 ] loss: 0.48819345235824585 2022-06-30 23:55:30.998145
Epoch:[ 15 13 ] loss: 0.49394547939300537 2022-06-30 23:55:31.429078
Epoch:[ 15 14 ] loss: 0.4899371266365051 2022-06-30 23:55:31.855302
Epoch:[ 15 15 ] loss: 0.4914289116859436 2022-06-30 23:55:32.283226
Epoch:[ 15 16 ] loss: 0.49156492948532104 2022-06-30 23:55:37.537410
Epoch:[ 15 17 ] loss: 0.49267011880874634 2022-06-30 23:55:38.367914
Epoch:[ 15 18 ] loss: 0.49392274022102356 2022-06-30 23:55:38.806425
Epoch:[ 15 19 ] loss: 0.4953361451625824 2022-06-30 23:55:39.236991
Training_Epoch:[ 15 ] Training_loss: 0.4945897445082664 2022-06-30 23:55:39.237682
learning rate:  0.04000000000000001
val: 1 0.6358286142349243
val: 2 0.6246984601020813
val: 3 0.6222459673881531
val: 4 0.6398555040359497
val: 5 0.636052131652832
val: 6 0.6446886658668518
val: 7 0.620718777179718
val: 8 0.625396728515625
val: 9 0.6398276090621948
val: 10 0.6308600306510925
val: 11 0.6421500444412231
val: 12 0.6359920501708984
val: 13 0.6417738795280457
val: 14 0.626534104347229
val: 15 0.6323337554931641
val: 16 0.6431106328964233
val: 17 0.6218663454055786
val: 18 0.6376075744628906
val: 19 0.6322007179260254
val: 20 0.6436025500297546
val_Epoch:[ 15 ] val_loss: 0.6338672071695328 2022-06-30 23:55:43.011785
start training 2022-06-30 23:55:43.112932
Epoch:[ 16 0 ] loss: 0.4952389597892761 2022-06-30 23:55:57.258876
Epoch:[ 16 1 ] loss: 0.49537426233291626 2022-06-30 23:55:57.707107
Epoch:[ 16 2 ] loss: 0.4947546422481537 2022-06-30 23:55:58.136668
Epoch:[ 16 3 ] loss: 0.49250054359436035 2022-06-30 23:55:58.560880
Epoch:[ 16 4 ] loss: 0.49323272705078125 2022-06-30 23:55:58.987673
Epoch:[ 16 5 ] loss: 0.4916378855705261 2022-06-30 23:55:59.417221
Epoch:[ 16 6 ] loss: 0.4945147633552551 2022-06-30 23:55:59.844884
Epoch:[ 16 7 ] loss: 0.4955931305885315 2022-06-30 23:56:00.275907
Epoch:[ 16 8 ] loss: 0.49240100383758545 2022-06-30 23:56:00.702386
Epoch:[ 16 9 ] loss: 0.49410632252693176 2022-06-30 23:56:01.130199
Epoch:[ 16 10 ] loss: 0.48899224400520325 2022-06-30 23:56:01.560907
Epoch:[ 16 11 ] loss: 0.4911746680736542 2022-06-30 23:56:01.980924
Epoch:[ 16 12 ] loss: 0.49465227127075195 2022-06-30 23:56:02.409965
Epoch:[ 16 13 ] loss: 0.4903925061225891 2022-06-30 23:56:02.837299
Epoch:[ 16 14 ] loss: 0.49098390340805054 2022-06-30 23:56:03.266986
Epoch:[ 16 15 ] loss: 0.49257388710975647 2022-06-30 23:56:03.694487
Epoch:[ 16 16 ] loss: 0.4939950406551361 2022-06-30 23:56:09.088318
Epoch:[ 16 17 ] loss: 0.494381308555603 2022-06-30 23:56:09.521719
Epoch:[ 16 18 ] loss: 0.4885918200016022 2022-06-30 23:56:09.948828
Epoch:[ 16 19 ] loss: 0.4918801188468933 2022-06-30 23:56:10.378229
Training_Epoch:[ 16 ] Training_loss: 0.4928486004471779 2022-06-30 23:56:10.378904
learning rate:  0.04000000000000001
netparams have been saved once 16
val: 1 0.5060304999351501
val: 2 0.5036956071853638
val: 3 0.5003551244735718
val: 4 0.49609023332595825
val: 5 0.48927563428878784
val: 6 0.503809928894043
val: 7 0.49354466795921326
val: 8 0.49741435050964355
val: 9 0.5022673010826111
val: 10 0.4860718548297882
val: 11 0.5090816617012024
val: 12 0.5043055415153503
val: 13 0.49929574131965637
val: 14 0.49338629841804504
val: 15 0.49984338879585266
val: 16 0.5049717426300049
val: 17 0.5156272053718567
val: 18 0.501377284526825
val: 19 0.5030063390731812
val: 20 0.49941718578338623
val_Epoch:[ 16 ] val_loss: 0.5004433795809746 2022-06-30 23:56:14.276153
start training 2022-06-30 23:56:14.377209
Epoch:[ 17 0 ] loss: 0.48782649636268616 2022-06-30 23:56:28.411430
Epoch:[ 17 1 ] loss: 0.4902670085430145 2022-06-30 23:56:28.860695
Epoch:[ 17 2 ] loss: 0.48897314071655273 2022-06-30 23:56:29.325864
Epoch:[ 17 3 ] loss: 0.48718318343162537 2022-06-30 23:56:29.755679
Epoch:[ 17 4 ] loss: 0.4901171326637268 2022-06-30 23:56:30.183037
Epoch:[ 17 5 ] loss: 0.48883411288261414 2022-06-30 23:56:30.613653
Epoch:[ 17 6 ] loss: 0.48895397782325745 2022-06-30 23:56:31.041771
Epoch:[ 17 7 ] loss: 0.48991858959198 2022-06-30 23:56:31.473492
Epoch:[ 17 8 ] loss: 0.4903623163700104 2022-06-30 23:56:31.903979
Epoch:[ 17 9 ] loss: 0.4978580176830292 2022-06-30 23:56:32.334210
Epoch:[ 17 10 ] loss: 0.4912932515144348 2022-06-30 23:56:32.765312
Epoch:[ 17 11 ] loss: 0.4913509786128998 2022-06-30 23:56:33.194232
Epoch:[ 17 12 ] loss: 0.488689124584198 2022-06-30 23:56:33.619253
Epoch:[ 17 13 ] loss: 0.48904189467430115 2022-06-30 23:56:34.048595
Epoch:[ 17 14 ] loss: 0.4859224259853363 2022-06-30 23:56:34.478935
Epoch:[ 17 15 ] loss: 0.4893588721752167 2022-06-30 23:56:34.909146
Epoch:[ 17 16 ] loss: 0.4861755073070526 2022-06-30 23:56:40.255649
Epoch:[ 17 17 ] loss: 0.48847997188568115 2022-06-30 23:56:40.840153
Epoch:[ 17 18 ] loss: 0.48642268776893616 2022-06-30 23:56:41.280877
Epoch:[ 17 19 ] loss: 0.4856567978858948 2022-06-30 23:56:41.707310
Training_Epoch:[ 17 ] Training_loss: 0.4891342744231224 2022-06-30 23:56:41.707984
learning rate:  0.04000000000000001
val: 1 0.6223572492599487
val: 2 0.6303359270095825
val: 3 0.6245962977409363
val: 4 0.6137216687202454
val: 5 0.6194515228271484
val: 6 0.6301808953285217
val: 7 0.6336280703544617
val: 8 0.6179021000862122
val: 9 0.622184693813324
val: 10 0.6243898272514343
val: 11 0.623038649559021
val: 12 0.6387844085693359
val: 13 0.6430088877677917
val: 14 0.6315383315086365
val: 15 0.6091698408126831
val: 16 0.6397098898887634
val: 17 0.6295909285545349
val: 18 0.6180619597434998
val: 19 0.6319306492805481
val: 20 0.6094458699226379
val_Epoch:[ 17 ] val_loss: 0.6256513833999634 2022-06-30 23:56:45.442903
start training 2022-06-30 23:56:45.543830
Epoch:[ 18 0 ] loss: 0.48906955122947693 2022-06-30 23:56:59.966121
Epoch:[ 18 1 ] loss: 0.4831351041793823 2022-06-30 23:57:00.606152
Epoch:[ 18 2 ] loss: 0.4910127818584442 2022-06-30 23:57:01.034408
Epoch:[ 18 3 ] loss: 0.4876173436641693 2022-06-30 23:57:01.461738
Epoch:[ 18 4 ] loss: 0.48609599471092224 2022-06-30 23:57:01.889431
Epoch:[ 18 5 ] loss: 0.4842360317707062 2022-06-30 23:57:02.316065
Epoch:[ 18 6 ] loss: 0.4863876402378082 2022-06-30 23:57:02.742150
Epoch:[ 18 7 ] loss: 0.48571887612342834 2022-06-30 23:57:03.170121
Epoch:[ 18 8 ] loss: 0.48451346158981323 2022-06-30 23:57:03.597876
Epoch:[ 18 9 ] loss: 0.48338139057159424 2022-06-30 23:57:04.026552
Epoch:[ 18 10 ] loss: 0.4788561463356018 2022-06-30 23:57:04.455897
Epoch:[ 18 11 ] loss: 0.48798081278800964 2022-06-30 23:57:04.885614
Epoch:[ 18 12 ] loss: 0.48419567942619324 2022-06-30 23:57:05.312772
Epoch:[ 18 13 ] loss: 0.4840035140514374 2022-06-30 23:57:05.735191
Epoch:[ 18 14 ] loss: 0.48772603273391724 2022-06-30 23:57:06.161692
Epoch:[ 18 15 ] loss: 0.4877096712589264 2022-06-30 23:57:06.584359
Epoch:[ 18 16 ] loss: 0.4913579225540161 2022-06-30 23:57:11.435667
Epoch:[ 18 17 ] loss: 0.4919854402542114 2022-06-30 23:57:12.013829
Epoch:[ 18 18 ] loss: 0.4958578646183014 2022-06-30 23:57:12.448456
Epoch:[ 18 19 ] loss: 0.4950530529022217 2022-06-30 23:57:12.874813
Training_Epoch:[ 18 ] Training_loss: 0.4872947156429291 2022-06-30 23:57:12.875470
learning rate:  0.04000000000000001
netparams have been saved once 18
val: 1 0.6422528028488159
val: 2 0.6243853569030762
val: 3 0.6286323666572571
val: 4 0.6193488240242004
val: 5 0.620288074016571
val: 6 0.6260114908218384
val: 7 0.6250841021537781
val: 8 0.6305031776428223
val: 9 0.6208878755569458
val: 10 0.6157280802726746
val: 11 0.6338649392127991
val: 12 0.6214184761047363
val: 13 0.6141798496246338
val: 14 0.628957211971283
val: 15 0.6250503063201904
val: 16 0.6286743879318237
val: 17 0.622054398059845
val: 18 0.6171597838401794
val: 19 0.6189915537834167
val: 20 0.6129433512687683
val_Epoch:[ 18 ] val_loss: 0.6238208204507828 2022-06-30 23:57:16.642170
start training 2022-06-30 23:57:16.740378
Epoch:[ 19 0 ] loss: 0.49235475063323975 2022-06-30 23:57:31.698073
Epoch:[ 19 1 ] loss: 0.4879761040210724 2022-06-30 23:57:32.124095
Epoch:[ 19 2 ] loss: 0.4900585114955902 2022-06-30 23:57:32.546851
Epoch:[ 19 3 ] loss: 0.4870460033416748 2022-06-30 23:57:32.974875
Epoch:[ 19 4 ] loss: 0.48847272992134094 2022-06-30 23:57:33.402215
Epoch:[ 19 5 ] loss: 0.4910338222980499 2022-06-30 23:57:33.830436
Epoch:[ 19 6 ] loss: 0.4881554841995239 2022-06-30 23:57:34.258027
Epoch:[ 19 7 ] loss: 0.4865948557853699 2022-06-30 23:57:34.686876
Epoch:[ 19 8 ] loss: 0.48606571555137634 2022-06-30 23:57:35.114086
Epoch:[ 19 9 ] loss: 0.4855625629425049 2022-06-30 23:57:35.541446
Epoch:[ 19 10 ] loss: 0.48831215500831604 2022-06-30 23:57:35.969540
Epoch:[ 19 11 ] loss: 0.4820745885372162 2022-06-30 23:57:36.396939
Epoch:[ 19 12 ] loss: 0.48233628273010254 2022-06-30 23:57:36.823244
Epoch:[ 19 13 ] loss: 0.486852765083313 2022-06-30 23:57:37.244901
Epoch:[ 19 14 ] loss: 0.48341989517211914 2022-06-30 23:57:37.672678
Epoch:[ 19 15 ] loss: 0.4835537374019623 2022-06-30 23:57:38.093776
Epoch:[ 19 16 ] loss: 0.4836960732936859 2022-06-30 23:57:43.077749
Epoch:[ 19 17 ] loss: 0.4785004258155823 2022-06-30 23:57:43.505385
Epoch:[ 19 18 ] loss: 0.48521146178245544 2022-06-30 23:57:43.937046
Epoch:[ 19 19 ] loss: 0.48210933804512024 2022-06-30 23:57:44.363341
Training_Epoch:[ 19 ] Training_loss: 0.4859693631529808 2022-06-30 23:57:44.364028
learning rate:  0.04000000000000001
val: 1 0.5022905468940735
val: 2 0.4846534729003906
val: 3 0.4814772307872772
val: 4 0.4847943186759949
val: 5 0.49105557799339294
val: 6 0.4880530536174774
val: 7 0.4890369474887848
val: 8 0.4863611161708832
val: 9 0.4953155815601349
val: 10 0.48999038338661194
val: 11 0.49011966586112976
val: 12 0.49052467942237854
val: 13 0.49653351306915283
val: 14 0.4910355508327484
val: 15 0.4825446605682373
val: 16 0.48230165243148804
val: 17 0.4953175187110901
val: 18 0.503274142742157
val: 19 0.489469438791275
val: 20 0.4885505139827728
val_Epoch:[ 19 ] val_loss: 0.4901349782943726 2022-06-30 23:57:48.063969
start training 2022-06-30 23:57:48.162605
Epoch:[ 20 0 ] loss: 0.48743531107902527 2022-06-30 23:58:02.410091
Epoch:[ 20 1 ] loss: 0.4837772846221924 2022-06-30 23:58:03.134089
Epoch:[ 20 2 ] loss: 0.4902268052101135 2022-06-30 23:58:03.560499
Epoch:[ 20 3 ] loss: 0.48210352659225464 2022-06-30 23:58:03.988620
Epoch:[ 20 4 ] loss: 0.4895091950893402 2022-06-30 23:58:04.412127
Epoch:[ 20 5 ] loss: 0.4828781485557556 2022-06-30 23:58:04.839246
Epoch:[ 20 6 ] loss: 0.48751139640808105 2022-06-30 23:58:05.267455
Epoch:[ 20 7 ] loss: 0.4909816384315491 2022-06-30 23:58:05.689889
Epoch:[ 20 8 ] loss: 0.4832226037979126 2022-06-30 23:58:06.116675
Epoch:[ 20 9 ] loss: 0.48657381534576416 2022-06-30 23:58:06.542465
Epoch:[ 20 10 ] loss: 0.4833986759185791 2022-06-30 23:58:06.971079
Epoch:[ 20 11 ] loss: 0.4852266311645508 2022-06-30 23:58:07.402033
Epoch:[ 20 12 ] loss: 0.47909215092658997 2022-06-30 23:58:07.830221
Epoch:[ 20 13 ] loss: 0.48345834016799927 2022-06-30 23:58:08.257460
Epoch:[ 20 14 ] loss: 0.47854113578796387 2022-06-30 23:58:08.685134
Epoch:[ 20 15 ] loss: 0.4795639216899872 2022-06-30 23:58:09.112757
Epoch:[ 20 16 ] loss: 0.48197925090789795 2022-06-30 23:58:14.463516
Epoch:[ 20 17 ] loss: 0.48408055305480957 2022-06-30 23:58:14.891602
Epoch:[ 20 18 ] loss: 0.47983524203300476 2022-06-30 23:58:15.325388
Epoch:[ 20 19 ] loss: 0.48141995072364807 2022-06-30 23:58:15.755414
Training_Epoch:[ 20 ] Training_loss: 0.48404077887535096 2022-06-30 23:58:15.756145
learning rate:  0.04000000000000001
netparams have been saved once 20
val: 1 0.5002729892730713
val: 2 0.49350693821907043
val: 3 0.4858257472515106
val: 4 0.4961700737476349
val: 5 0.4962800443172455
val: 6 0.49089252948760986
val: 7 0.49962013959884644
val: 8 0.4884786605834961
val: 9 0.4932793080806732
val: 10 0.4960097372531891
val: 11 0.48813241720199585
val: 12 0.5002627968788147
val: 13 0.48660656809806824
val: 14 0.496911883354187
val: 15 0.5038765668869019
val: 16 0.485138863325119
val: 17 0.4916037321090698
val: 18 0.4904564917087555
val: 19 0.4908298850059509
val: 20 0.49200746417045593
val_Epoch:[ 20 ] val_loss: 0.4933081418275833 2022-06-30 23:58:19.650022
start training 2022-06-30 23:58:19.749381
Epoch:[ 21 0 ] loss: 0.48481613397598267 2022-06-30 23:58:34.294865
Epoch:[ 21 1 ] loss: 0.4813440442085266 2022-06-30 23:58:34.726252
Epoch:[ 21 2 ] loss: 0.4821736514568329 2022-06-30 23:58:35.148481
Epoch:[ 21 3 ] loss: 0.48132023215293884 2022-06-30 23:58:35.575138
Epoch:[ 21 4 ] loss: 0.4798223078250885 2022-06-30 23:58:36.007174
Epoch:[ 21 5 ] loss: 0.47769737243652344 2022-06-30 23:58:36.437673
Epoch:[ 21 6 ] loss: 0.4836769104003906 2022-06-30 23:58:36.868574
Epoch:[ 21 7 ] loss: 0.47834891080856323 2022-06-30 23:58:37.296503
Epoch:[ 21 8 ] loss: 0.4805906116962433 2022-06-30 23:58:37.725847
Epoch:[ 21 9 ] loss: 0.47991716861724854 2022-06-30 23:58:38.155340
Epoch:[ 21 10 ] loss: 0.48032209277153015 2022-06-30 23:58:38.584561
Epoch:[ 21 11 ] loss: 0.48466846346855164 2022-06-30 23:58:39.013532
Epoch:[ 21 12 ] loss: 0.4802457094192505 2022-06-30 23:58:39.442807
Epoch:[ 21 13 ] loss: 0.48535841703414917 2022-06-30 23:58:39.871421
Epoch:[ 21 14 ] loss: 0.48037099838256836 2022-06-30 23:58:40.295743
Epoch:[ 21 15 ] loss: 0.4785888195037842 2022-06-30 23:58:40.717328
Epoch:[ 21 16 ] loss: 0.4791935980319977 2022-06-30 23:58:45.996814
Epoch:[ 21 17 ] loss: 0.48019862174987793 2022-06-30 23:58:46.424241
Epoch:[ 21 18 ] loss: 0.47715333104133606 2022-06-30 23:58:46.859876
Epoch:[ 21 19 ] loss: 0.4748358428478241 2022-06-30 23:58:47.289969
Training_Epoch:[ 21 ] Training_loss: 0.4805321618914604 2022-06-30 23:58:47.290625
learning rate:  0.03200000000000001
val: 1 0.5012945532798767
val: 2 0.49368810653686523
val: 3 0.5089812278747559
val: 4 0.49248960614204407
val: 5 0.503713846206665
val: 6 0.4978506565093994
val: 7 0.5019959807395935
val: 8 0.503006100654602
val: 9 0.5052576661109924
val: 10 0.5112309455871582
val: 11 0.4947228729724884
val: 12 0.5088542699813843
val: 13 0.5148721933364868
val: 14 0.4943377673625946
val: 15 0.5065420866012573
val: 16 0.492666631937027
val: 17 0.4989539384841919
val: 18 0.4919774532318115
val: 19 0.4832005500793457
val: 20 0.5019026398658752
val_Epoch:[ 21 ] val_loss: 0.5003769546747208 2022-06-30 23:58:51.056277
start training 2022-06-30 23:58:51.161955
Epoch:[ 22 0 ] loss: 0.4794652462005615 2022-06-30 23:59:05.248564
Epoch:[ 22 1 ] loss: 0.4764312505722046 2022-06-30 23:59:05.718859
Epoch:[ 22 2 ] loss: 0.47601422667503357 2022-06-30 23:59:06.145281
Epoch:[ 22 3 ] loss: 0.47653162479400635 2022-06-30 23:59:06.571913
Epoch:[ 22 4 ] loss: 0.4783083498477936 2022-06-30 23:59:06.998468
Epoch:[ 22 5 ] loss: 0.4768477976322174 2022-06-30 23:59:07.428423
Epoch:[ 22 6 ] loss: 0.4805317521095276 2022-06-30 23:59:07.845943
Epoch:[ 22 7 ] loss: 0.4786736071109772 2022-06-30 23:59:08.254494
Epoch:[ 22 8 ] loss: 0.4770149886608124 2022-06-30 23:59:08.663330
Epoch:[ 22 9 ] loss: 0.4770202040672302 2022-06-30 23:59:09.072036
Epoch:[ 22 10 ] loss: 0.4812426269054413 2022-06-30 23:59:09.480588
Epoch:[ 22 11 ] loss: 0.47702932357788086 2022-06-30 23:59:09.891051
Epoch:[ 22 12 ] loss: 0.4823334217071533 2022-06-30 23:59:10.310136
Epoch:[ 22 13 ] loss: 0.4734595715999603 2022-06-30 23:59:10.720735
Epoch:[ 22 14 ] loss: 0.474198579788208 2022-06-30 23:59:11.130906
Epoch:[ 22 15 ] loss: 0.47782137989997864 2022-06-30 23:59:11.540233
Epoch:[ 22 16 ] loss: 0.47652122378349304 2022-06-30 23:59:16.997485
Epoch:[ 22 17 ] loss: 0.4790378510951996 2022-06-30 23:59:17.424793
Epoch:[ 22 18 ] loss: 0.47665074467658997 2022-06-30 23:59:17.854812
Epoch:[ 22 19 ] loss: 0.47929927706718445 2022-06-30 23:59:18.283299
Training_Epoch:[ 22 ] Training_loss: 0.47772165238857267 2022-06-30 23:59:18.284047
learning rate:  0.03200000000000001
netparams have been saved once 22
val: 1 0.49624064564704895
val: 2 0.502873957157135
val: 3 0.48784172534942627
val: 4 0.5121463537216187
val: 5 0.4959231913089752
val: 6 0.5000985264778137
val: 7 0.5067744255065918
val: 8 0.5005205273628235
val: 9 0.5101068019866943
val: 10 0.49674177169799805
val: 11 0.4973067343235016
val: 12 0.5045866370201111
val: 13 0.4986172914505005
val: 14 0.501998245716095
val: 15 0.5070178508758545
val: 16 0.49969667196273804
val: 17 0.5032517313957214
val: 18 0.5139405131340027
val: 19 0.5078217387199402
val: 20 0.49672171473503113
val_Epoch:[ 22 ] val_loss: 0.5020113527774811 2022-06-30 23:59:22.101156
start training 2022-06-30 23:59:22.199392
Epoch:[ 23 0 ] loss: 0.48050418496131897 2022-06-30 23:59:36.161122
Epoch:[ 23 1 ] loss: 0.4720507264137268 2022-06-30 23:59:36.595169
Epoch:[ 23 2 ] loss: 0.47630736231803894 2022-06-30 23:59:37.032212
Epoch:[ 23 3 ] loss: 0.47945401072502136 2022-06-30 23:59:37.460336
Epoch:[ 23 4 ] loss: 0.47620534896850586 2022-06-30 23:59:37.886721
Epoch:[ 23 5 ] loss: 0.4781862199306488 2022-06-30 23:59:38.312755
Epoch:[ 23 6 ] loss: 0.47700923681259155 2022-06-30 23:59:38.724748
Epoch:[ 23 7 ] loss: 0.4728260040283203 2022-06-30 23:59:39.143868
Epoch:[ 23 8 ] loss: 0.47780847549438477 2022-06-30 23:59:39.555064
Epoch:[ 23 9 ] loss: 0.47263994812965393 2022-06-30 23:59:39.962718
Epoch:[ 23 10 ] loss: 0.4776982069015503 2022-06-30 23:59:40.371112
Epoch:[ 23 11 ] loss: 0.47434553503990173 2022-06-30 23:59:40.780386
Epoch:[ 23 12 ] loss: 0.47506970167160034 2022-06-30 23:59:41.188995
Epoch:[ 23 13 ] loss: 0.47626158595085144 2022-06-30 23:59:41.599156
Epoch:[ 23 14 ] loss: 0.47737517952919006 2022-06-30 23:59:42.011176
Epoch:[ 23 15 ] loss: 0.4763258695602417 2022-06-30 23:59:42.420458
Epoch:[ 23 16 ] loss: 0.4730750620365143 2022-06-30 23:59:47.969767
Epoch:[ 23 17 ] loss: 0.47883519530296326 2022-06-30 23:59:48.378084
Epoch:[ 23 18 ] loss: 0.4765056073665619 2022-06-30 23:59:48.794950
Epoch:[ 23 19 ] loss: 0.4741923213005066 2022-06-30 23:59:49.202923
Training_Epoch:[ 23 ] Training_loss: 0.47613378912210463 2022-06-30 23:59:49.203726
learning rate:  0.03200000000000001
val: 1 0.49087461829185486
val: 2 0.47525647282600403
val: 3 0.49760279059410095
val: 4 0.48308080434799194
val: 5 0.4967256486415863
val: 6 0.4960878789424896
val: 7 0.5042849779129028
val: 8 0.48385748267173767
val: 9 0.49319446086883545
val: 10 0.480566143989563
val: 11 0.488347589969635
val: 12 0.47868460416793823
val: 13 0.4796486794948578
val: 14 0.4884702265262604
val: 15 0.47372856736183167
val: 16 0.4907669723033905
val: 17 0.4904033839702606
val: 18 0.48222094774246216
val: 19 0.49187129735946655
val: 20 0.4843052625656128
val_Epoch:[ 23 ] val_loss: 0.48749894052743914 2022-06-30 23:59:53.148805
start training 2022-06-30 23:59:53.245027
Epoch:[ 24 0 ] loss: 0.4776058793067932 2022-07-01 00:00:08.169577
Epoch:[ 24 1 ] loss: 0.4778963625431061 2022-07-01 00:00:08.598262
Epoch:[ 24 2 ] loss: 0.4729540944099426 2022-07-01 00:00:09.025689
Epoch:[ 24 3 ] loss: 0.4736265242099762 2022-07-01 00:00:09.453130
Epoch:[ 24 4 ] loss: 0.4753420650959015 2022-07-01 00:00:09.880428
Epoch:[ 24 5 ] loss: 0.47669538855552673 2022-07-01 00:00:10.289179
Epoch:[ 24 6 ] loss: 0.47292301058769226 2022-07-01 00:00:10.704449
Epoch:[ 24 7 ] loss: 0.47469210624694824 2022-07-01 00:00:11.114481
Epoch:[ 24 8 ] loss: 0.47622445225715637 2022-07-01 00:00:11.527196
Epoch:[ 24 9 ] loss: 0.47191670536994934 2022-07-01 00:00:11.935208
Epoch:[ 24 10 ] loss: 0.47245359420776367 2022-07-01 00:00:12.344615
Epoch:[ 24 11 ] loss: 0.4714609682559967 2022-07-01 00:00:12.769441
Epoch:[ 24 12 ] loss: 0.4739896357059479 2022-07-01 00:00:13.179825
Epoch:[ 24 13 ] loss: 0.47404494881629944 2022-07-01 00:00:13.588479
Epoch:[ 24 14 ] loss: 0.4727274477481842 2022-07-01 00:00:13.999226
Epoch:[ 24 15 ] loss: 0.47383442521095276 2022-07-01 00:00:14.414525
Epoch:[ 24 16 ] loss: 0.46837809681892395 2022-07-01 00:00:19.517017
Epoch:[ 24 17 ] loss: 0.4701964259147644 2022-07-01 00:00:19.984617
Epoch:[ 24 18 ] loss: 0.47341489791870117 2022-07-01 00:00:20.421459
Epoch:[ 24 19 ] loss: 0.47476887702941895 2022-07-01 00:00:20.846869
Training_Epoch:[ 24 ] Training_loss: 0.47375729531049726 2022-07-01 00:00:20.847643
learning rate:  0.03200000000000001
netparams have been saved once 24
val: 1 0.47196075320243835
val: 2 0.4874318242073059
val: 3 0.49468815326690674
val: 4 0.48553338646888733
val: 5 0.49209117889404297
val: 6 0.4817587733268738
val: 7 0.4846600890159607
val: 8 0.4843538999557495
val: 9 0.4859934151172638
val: 10 0.4714674651622772
val: 11 0.4826769530773163
val: 12 0.4755396246910095
val: 13 0.4952295422554016
val: 14 0.4922546446323395
val: 15 0.4904897212982178
val: 16 0.48307791352272034
val: 17 0.4815487861633301
val: 18 0.4883030354976654
val: 19 0.48668429255485535
val: 20 0.4768964350223541
val_Epoch:[ 24 ] val_loss: 0.48463199436664584 2022-07-01 00:00:24.764502
start training 2022-07-01 00:00:24.865624
Epoch:[ 25 0 ] loss: 0.47428014874458313 2022-07-01 00:00:39.758209
Epoch:[ 25 1 ] loss: 0.4771180748939514 2022-07-01 00:00:40.187109
Epoch:[ 25 2 ] loss: 0.47152984142303467 2022-07-01 00:00:40.616232
Epoch:[ 25 3 ] loss: 0.4760580360889435 2022-07-01 00:00:41.043600
Epoch:[ 25 4 ] loss: 0.4724624752998352 2022-07-01 00:00:41.470254
Epoch:[ 25 5 ] loss: 0.47078707814216614 2022-07-01 00:00:41.897035
Epoch:[ 25 6 ] loss: 0.4711189866065979 2022-07-01 00:00:42.325082
Epoch:[ 25 7 ] loss: 0.47185018658638 2022-07-01 00:00:42.750021
Epoch:[ 25 8 ] loss: 0.46856555342674255 2022-07-01 00:00:43.178125
Epoch:[ 25 9 ] loss: 0.4718194305896759 2022-07-01 00:00:43.600130
Epoch:[ 25 10 ] loss: 0.46925994753837585 2022-07-01 00:00:44.021994
Epoch:[ 25 11 ] loss: 0.4776812195777893 2022-07-01 00:00:44.448160
Epoch:[ 25 12 ] loss: 0.46787869930267334 2022-07-01 00:00:44.876147
Epoch:[ 25 13 ] loss: 0.46838852763175964 2022-07-01 00:00:45.302794
Epoch:[ 25 14 ] loss: 0.46818435192108154 2022-07-01 00:00:45.730034
Epoch:[ 25 15 ] loss: 0.47669413685798645 2022-07-01 00:00:46.157986
Epoch:[ 25 16 ] loss: 0.4703005850315094 2022-07-01 00:00:51.363823
Epoch:[ 25 17 ] loss: 0.46550077199935913 2022-07-01 00:00:51.789737
Epoch:[ 25 18 ] loss: 0.47334885597229004 2022-07-01 00:00:52.236063
Epoch:[ 25 19 ] loss: 0.4733869731426239 2022-07-01 00:00:52.663947
Training_Epoch:[ 25 ] Training_loss: 0.47181069403886794 2022-07-01 00:00:52.664622
learning rate:  0.03200000000000001
val: 1 0.467883437871933
val: 2 0.47431546449661255
val: 3 0.47784286737442017
val: 4 0.48830845952033997
val: 5 0.48543715476989746
val: 6 0.48715949058532715
val: 7 0.4733341932296753
val: 8 0.47810712456703186
val: 9 0.48194172978401184
val: 10 0.47538721561431885
val: 11 0.48450398445129395
val: 12 0.4807278513908386
val: 13 0.4823218286037445
val: 14 0.471214234828949
val: 15 0.4764024317264557
val: 16 0.48137637972831726
val: 17 0.4909287095069885
val: 18 0.4779857099056244
val: 19 0.4788339138031006
val: 20 0.48267441987991333
val_Epoch:[ 25 ] val_loss: 0.4798343300819397 2022-07-01 00:00:56.456217
start training 2022-07-01 00:00:56.557148
Epoch:[ 26 0 ] loss: 0.47049611806869507 2022-07-01 00:01:11.526617
Epoch:[ 26 1 ] loss: 0.46865954995155334 2022-07-01 00:01:11.953840
Epoch:[ 26 2 ] loss: 0.47216174006462097 2022-07-01 00:01:12.381375
Epoch:[ 26 3 ] loss: 0.4700213074684143 2022-07-01 00:01:12.809957
Epoch:[ 26 4 ] loss: 0.4722762107849121 2022-07-01 00:01:13.239769
Epoch:[ 26 5 ] loss: 0.474010169506073 2022-07-01 00:01:13.665585
Epoch:[ 26 6 ] loss: 0.4745585024356842 2022-07-01 00:01:14.087371
Epoch:[ 26 7 ] loss: 0.4698781371116638 2022-07-01 00:01:14.514326
Epoch:[ 26 8 ] loss: 0.468845933675766 2022-07-01 00:01:14.940809
Epoch:[ 26 9 ] loss: 0.4699208736419678 2022-07-01 00:01:15.369217
Epoch:[ 26 10 ] loss: 0.4738823473453522 2022-07-01 00:01:15.797554
Epoch:[ 26 11 ] loss: 0.47225308418273926 2022-07-01 00:01:16.224176
Epoch:[ 26 12 ] loss: 0.46987220644950867 2022-07-01 00:01:16.645366
Epoch:[ 26 13 ] loss: 0.46712130308151245 2022-07-01 00:01:17.072732
Epoch:[ 26 14 ] loss: 0.4682578146457672 2022-07-01 00:01:17.499232
Epoch:[ 26 15 ] loss: 0.4701148569583893 2022-07-01 00:01:17.926001
Epoch:[ 26 16 ] loss: 0.46777594089508057 2022-07-01 00:01:23.271025
Epoch:[ 26 17 ] loss: 0.47221624851226807 2022-07-01 00:01:23.698476
Epoch:[ 26 18 ] loss: 0.47156643867492676 2022-07-01 00:01:24.131524
Epoch:[ 26 19 ] loss: 0.46749505400657654 2022-07-01 00:01:24.557205
Training_Epoch:[ 26 ] Training_loss: 0.47056919187307356 2022-07-01 00:01:24.557946
learning rate:  0.03200000000000001
netparams have been saved once 26
val: 1 0.4942270517349243
val: 2 0.4977636933326721
val: 3 0.49670112133026123
val: 4 0.49129197001457214
val: 5 0.5015823841094971
val: 6 0.49327540397644043
val: 7 0.4912763833999634
val: 8 0.5005115866661072
val: 9 0.5003058910369873
val: 10 0.5070952773094177
val: 11 0.4982912838459015
val: 12 0.49642473459243774
val: 13 0.4879993498325348
val: 14 0.49959275126457214
val: 15 0.5077516436576843
val: 16 0.48555058240890503
val: 17 0.49571141600608826
val: 18 0.49201661348342896
val: 19 0.48627975583076477
val: 20 0.4970761835575104
val_Epoch:[ 26 ] val_loss: 0.49603625386953354 2022-07-01 00:01:28.408066
start training 2022-07-01 00:01:28.505507
Epoch:[ 27 0 ] loss: 0.46886399388313293 2022-07-01 00:01:43.175525
Epoch:[ 27 1 ] loss: 0.46530187129974365 2022-07-01 00:01:43.596417
Epoch:[ 27 2 ] loss: 0.4655420482158661 2022-07-01 00:01:44.023101
Epoch:[ 27 3 ] loss: 0.46762675046920776 2022-07-01 00:01:44.445232
Epoch:[ 27 4 ] loss: 0.4697626829147339 2022-07-01 00:01:44.874540
Epoch:[ 27 5 ] loss: 0.4693656265735626 2022-07-01 00:01:45.301928
Epoch:[ 27 6 ] loss: 0.47226738929748535 2022-07-01 00:01:45.728597
Epoch:[ 27 7 ] loss: 0.4657629728317261 2022-07-01 00:01:46.158702
Epoch:[ 27 8 ] loss: 0.4675484597682953 2022-07-01 00:01:46.585447
Epoch:[ 27 9 ] loss: 0.46597662568092346 2022-07-01 00:01:47.011565
Epoch:[ 27 10 ] loss: 0.4682772755622864 2022-07-01 00:01:47.440908
Epoch:[ 27 11 ] loss: 0.4671647846698761 2022-07-01 00:01:47.869230
Epoch:[ 27 12 ] loss: 0.47443339228630066 2022-07-01 00:01:48.295823
Epoch:[ 27 13 ] loss: 0.4697301983833313 2022-07-01 00:01:48.717453
Epoch:[ 27 14 ] loss: 0.46558722853660583 2022-07-01 00:01:49.146083
Epoch:[ 27 15 ] loss: 0.4732933044433594 2022-07-01 00:01:49.578702
Epoch:[ 27 16 ] loss: 0.46923527121543884 2022-07-01 00:01:55.223023
Epoch:[ 27 17 ] loss: 0.4701789617538452 2022-07-01 00:01:55.649838
Epoch:[ 27 18 ] loss: 0.464704304933548 2022-07-01 00:01:56.082523
Epoch:[ 27 19 ] loss: 0.4721057415008545 2022-07-01 00:01:56.509577
Training_Epoch:[ 27 ] Training_loss: 0.46863644421100614 2022-07-01 00:01:56.510253
learning rate:  0.03200000000000001
val: 1 0.48137208819389343
val: 2 0.4705379605293274
val: 3 0.47221070528030396
val: 4 0.477459579706192
val: 5 0.48047247529029846
val: 6 0.48160064220428467
val: 7 0.4590775966644287
val: 8 0.46485674381256104
val: 9 0.4726426303386688
val: 10 0.4752517342567444
val: 11 0.4678855836391449
val: 12 0.4690941870212555
val: 13 0.4790855646133423
val: 14 0.4883844256401062
val: 15 0.48332667350769043
val: 16 0.47624629735946655
val: 17 0.4735524356365204
val: 18 0.4803796112537384
val: 19 0.4738103747367859
val: 20 0.469908207654953
val_Epoch:[ 27 ] val_loss: 0.4748577758669853 2022-07-01 00:02:00.232622
start training 2022-07-01 00:02:00.331543
Epoch:[ 28 0 ] loss: 0.4698925316333771 2022-07-01 00:02:14.637981
Epoch:[ 28 1 ] loss: 0.46601608395576477 2022-07-01 00:02:15.067826
Epoch:[ 28 2 ] loss: 0.46944522857666016 2022-07-01 00:02:15.495495
Epoch:[ 28 3 ] loss: 0.4709142744541168 2022-07-01 00:02:15.923142
Epoch:[ 28 4 ] loss: 0.4648086428642273 2022-07-01 00:02:16.352943
Epoch:[ 28 5 ] loss: 0.46900108456611633 2022-07-01 00:02:16.781689
Epoch:[ 28 6 ] loss: 0.46735042333602905 2022-07-01 00:02:17.205151
Epoch:[ 28 7 ] loss: 0.46521103382110596 2022-07-01 00:02:17.632069
Epoch:[ 28 8 ] loss: 0.4657740294933319 2022-07-01 00:02:18.060082
Epoch:[ 28 9 ] loss: 0.4719548225402832 2022-07-01 00:02:18.485383
Epoch:[ 28 10 ] loss: 0.4677181839942932 2022-07-01 00:02:18.911329
Epoch:[ 28 11 ] loss: 0.46781125664711 2022-07-01 00:02:19.342491
Epoch:[ 28 12 ] loss: 0.46996748447418213 2022-07-01 00:02:19.772675
Epoch:[ 28 13 ] loss: 0.4700493812561035 2022-07-01 00:02:20.203427
Epoch:[ 28 14 ] loss: 0.46345850825309753 2022-07-01 00:02:20.625290
Epoch:[ 28 15 ] loss: 0.4702732264995575 2022-07-01 00:02:21.053660
Epoch:[ 28 16 ] loss: 0.4640563428401947 2022-07-01 00:02:26.837372
Epoch:[ 28 17 ] loss: 0.46260660886764526 2022-07-01 00:02:27.263115
Epoch:[ 28 18 ] loss: 0.4620494842529297 2022-07-01 00:02:27.696859
Epoch:[ 28 19 ] loss: 0.4668877124786377 2022-07-01 00:02:28.126214
Training_Epoch:[ 28 ] Training_loss: 0.4672623172402382 2022-07-01 00:02:28.126939
learning rate:  0.03200000000000001
netparams have been saved once 28
val: 1 0.4847847819328308
val: 2 0.486307829618454
val: 3 0.48614031076431274
val: 4 0.48424214124679565
val: 5 0.4836871325969696
val: 6 0.4753124415874481
val: 7 0.47830671072006226
val: 8 0.4702203869819641
val: 9 0.48428523540496826
val: 10 0.4947674870491028
val: 11 0.47422170639038086
val: 12 0.48142093420028687
val: 13 0.48227500915527344
val: 14 0.48147621750831604
val: 15 0.4750411808490753
val: 16 0.48913782835006714
val: 17 0.4815034866333008
val: 18 0.4844275116920471
val: 19 0.475169837474823
val: 20 0.4777751564979553
val_Epoch:[ 28 ] val_loss: 0.4815251663327217 2022-07-01 00:02:31.912280
start training 2022-07-01 00:02:32.010260
Epoch:[ 29 0 ] loss: 0.4605938792228699 2022-07-01 00:02:47.042704
Epoch:[ 29 1 ] loss: 0.46456289291381836 2022-07-01 00:02:47.470301
Epoch:[ 29 2 ] loss: 0.4622403085231781 2022-07-01 00:02:47.898810
Epoch:[ 29 3 ] loss: 0.4664176106452942 2022-07-01 00:02:48.328613
Epoch:[ 29 4 ] loss: 0.4664960205554962 2022-07-01 00:02:48.756156
Epoch:[ 29 5 ] loss: 0.46619313955307007 2022-07-01 00:02:49.185028
Epoch:[ 29 6 ] loss: 0.46201571822166443 2022-07-01 00:02:49.613716
Epoch:[ 29 7 ] loss: 0.4608233869075775 2022-07-01 00:02:50.041136
Epoch:[ 29 8 ] loss: 0.47050192952156067 2022-07-01 00:02:50.461968
Epoch:[ 29 9 ] loss: 0.46555522084236145 2022-07-01 00:02:50.889328
Epoch:[ 29 10 ] loss: 0.46425673365592957 2022-07-01 00:02:51.312536
Epoch:[ 29 11 ] loss: 0.46900179982185364 2022-07-01 00:02:51.742385
Epoch:[ 29 12 ] loss: 0.4732236862182617 2022-07-01 00:02:52.171185
Epoch:[ 29 13 ] loss: 0.4749312698841095 2022-07-01 00:02:52.599611
Epoch:[ 29 14 ] loss: 0.4640766680240631 2022-07-01 00:02:53.024138
Epoch:[ 29 15 ] loss: 0.46972644329071045 2022-07-01 00:02:53.451585
Epoch:[ 29 16 ] loss: 0.4625335931777954 2022-07-01 00:02:59.043358
Epoch:[ 29 17 ] loss: 0.46870970726013184 2022-07-01 00:02:59.470016
Epoch:[ 29 18 ] loss: 0.46798986196517944 2022-07-01 00:02:59.902744
Epoch:[ 29 19 ] loss: 0.4698033928871155 2022-07-01 00:03:00.332103
Training_Epoch:[ 29 ] Training_loss: 0.4664826631546021 2022-07-01 00:03:00.332729
learning rate:  0.03200000000000001
val: 1 0.5131406188011169
val: 2 0.5267963409423828
val: 3 0.5058431029319763
val: 4 0.5099909901618958
val: 5 0.4986673891544342
val: 6 0.509739339351654
val: 7 0.5011347532272339
val: 8 0.5204713344573975
val: 9 0.5122698545455933
val: 10 0.5162014961242676
val: 11 0.5243598222732544
val: 12 0.501823902130127
val: 13 0.5134806632995605
val: 14 0.5144410729408264
val: 15 0.5117147564888
val: 16 0.5074700713157654
val: 17 0.5021243095397949
val: 18 0.5225816965103149
val: 19 0.5034568905830383
val: 20 0.5258888006210327
val_Epoch:[ 29 ] val_loss: 0.5120798602700234 2022-07-01 00:03:04.081735
start training 2022-07-01 00:03:04.186282
Epoch:[ 30 0 ] loss: 0.47525274753570557 2022-07-01 00:03:18.976196
Epoch:[ 30 1 ] loss: 0.46793848276138306 2022-07-01 00:03:19.404782
Epoch:[ 30 2 ] loss: 0.46422117948532104 2022-07-01 00:03:19.834824
Epoch:[ 30 3 ] loss: 0.4681553542613983 2022-07-01 00:03:20.262648
Epoch:[ 30 4 ] loss: 0.4659462869167328 2022-07-01 00:03:20.689945
Epoch:[ 30 5 ] loss: 0.4664778411388397 2022-07-01 00:03:21.115580
Epoch:[ 30 6 ] loss: 0.46506431698799133 2022-07-01 00:03:21.545158
Epoch:[ 30 7 ] loss: 0.4685575067996979 2022-07-01 00:03:21.968232
Epoch:[ 30 8 ] loss: 0.46391725540161133 2022-07-01 00:03:22.396378
Epoch:[ 30 9 ] loss: 0.4674206078052521 2022-07-01 00:03:22.823215
Epoch:[ 30 10 ] loss: 0.4607454836368561 2022-07-01 00:03:23.250507
Epoch:[ 30 11 ] loss: 0.46161898970603943 2022-07-01 00:03:23.678590
Epoch:[ 30 12 ] loss: 0.4643976390361786 2022-07-01 00:03:24.106484
Epoch:[ 30 13 ] loss: 0.4650079309940338 2022-07-01 00:03:24.538562
Epoch:[ 30 14 ] loss: 0.4633827805519104 2022-07-01 00:03:24.968494
Epoch:[ 30 15 ] loss: 0.46900755167007446 2022-07-01 00:03:25.392027
Epoch:[ 30 16 ] loss: 0.4617166519165039 2022-07-01 00:03:30.442260
Epoch:[ 30 17 ] loss: 0.4623246490955353 2022-07-01 00:03:30.868033
Epoch:[ 30 18 ] loss: 0.4657427966594696 2022-07-01 00:03:31.309739
Epoch:[ 30 19 ] loss: 0.4640948176383972 2022-07-01 00:03:31.717779
Training_Epoch:[ 30 ] Training_loss: 0.4655495434999466 2022-07-01 00:03:31.718611
learning rate:  0.03200000000000001
netparams have been saved once 30
val: 1 0.4926755428314209
val: 2 0.4830228388309479
val: 3 0.47190800309181213
val: 4 0.4749738276004791
val: 5 0.4873991906642914
val: 6 0.4752116799354553
val: 7 0.4777964651584625
val: 8 0.4812259078025818
val: 9 0.4893221855163574
val: 10 0.49172496795654297
val: 11 0.48466476798057556
val: 12 0.48538848757743835
val: 13 0.4841148853302002
val: 14 0.47939351201057434
val: 15 0.4807360768318176
val: 16 0.48468902707099915
val: 17 0.487760990858078
val: 18 0.4783637523651123
val: 19 0.4830239415168762
val: 20 0.47768208384513855
val_Epoch:[ 30 ] val_loss: 0.4825539067387581 2022-07-01 00:03:35.593899
start training 2022-07-01 00:03:35.695974
Epoch:[ 31 0 ] loss: 0.4665050506591797 2022-07-01 00:03:50.452064
Epoch:[ 31 1 ] loss: 0.46036604046821594 2022-07-01 00:03:50.882322
Epoch:[ 31 2 ] loss: 0.46190422773361206 2022-07-01 00:03:51.314983
Epoch:[ 31 3 ] loss: 0.4625827670097351 2022-07-01 00:03:51.741699
Epoch:[ 31 4 ] loss: 0.4614068269729614 2022-07-01 00:03:52.169149
Epoch:[ 31 5 ] loss: 0.46374717354774475 2022-07-01 00:03:52.596572
Epoch:[ 31 6 ] loss: 0.4688764214515686 2022-07-01 00:03:53.023317
Epoch:[ 31 7 ] loss: 0.4631289839744568 2022-07-01 00:03:53.453001
Epoch:[ 31 8 ] loss: 0.46079307794570923 2022-07-01 00:03:53.881376
Epoch:[ 31 9 ] loss: 0.4599815905094147 2022-07-01 00:03:54.311739
Epoch:[ 31 10 ] loss: 0.46432214975357056 2022-07-01 00:03:54.733470
Epoch:[ 31 11 ] loss: 0.46280014514923096 2022-07-01 00:03:55.162057
Epoch:[ 31 12 ] loss: 0.45908838510513306 2022-07-01 00:03:55.589319
Epoch:[ 31 13 ] loss: 0.46351101994514465 2022-07-01 00:03:56.016220
Epoch:[ 31 14 ] loss: 0.4670615792274475 2022-07-01 00:03:56.440469
Epoch:[ 31 15 ] loss: 0.46292051672935486 2022-07-01 00:03:56.869056
Epoch:[ 31 16 ] loss: 0.4608006179332733 2022-07-01 00:04:02.695104
Epoch:[ 31 17 ] loss: 0.4628612697124481 2022-07-01 00:04:03.120890
Epoch:[ 31 18 ] loss: 0.4618504047393799 2022-07-01 00:04:03.553679
Epoch:[ 31 19 ] loss: 0.4582609534263611 2022-07-01 00:04:03.980956
Training_Epoch:[ 31 ] Training_loss: 0.4626384600996971 2022-07-01 00:04:03.981683
learning rate:  0.025600000000000008
val: 1 0.48229512572288513
val: 2 0.4683198034763336
val: 3 0.475628137588501
val: 4 0.4787006378173828
val: 5 0.4737793803215027
val: 6 0.4818257689476013
val: 7 0.46800529956817627
val: 8 0.4802183508872986
val: 9 0.4808230996131897
val: 10 0.48731139302253723
val: 11 0.4939388930797577
val: 12 0.4819869101047516
val: 13 0.47183966636657715
val: 14 0.48782816529273987
val: 15 0.49329373240470886
val: 16 0.480045884847641
val: 17 0.4920300841331482
val: 18 0.4777796268463135
val: 19 0.4661436676979065
val: 20 0.48860183358192444
val_Epoch:[ 31 ] val_loss: 0.4805197730660439 2022-07-01 00:04:07.820352
start training 2022-07-01 00:04:07.920808
Epoch:[ 32 0 ] loss: 0.45592164993286133 2022-07-01 00:04:22.465834
Epoch:[ 32 1 ] loss: 0.46531176567077637 2022-07-01 00:04:22.888515
Epoch:[ 32 2 ] loss: 0.46109795570373535 2022-07-01 00:04:23.313508
Epoch:[ 32 3 ] loss: 0.46174225211143494 2022-07-01 00:04:23.741043
Epoch:[ 32 4 ] loss: 0.4609614312648773 2022-07-01 00:04:24.169138
Epoch:[ 32 5 ] loss: 0.4606763422489166 2022-07-01 00:04:24.597014
Epoch:[ 32 6 ] loss: 0.46032819151878357 2022-07-01 00:04:25.023496
Epoch:[ 32 7 ] loss: 0.4609413146972656 2022-07-01 00:04:25.443419
Epoch:[ 32 8 ] loss: 0.4557628035545349 2022-07-01 00:04:25.871887
Epoch:[ 32 9 ] loss: 0.4587208032608032 2022-07-01 00:04:26.299292
Epoch:[ 32 10 ] loss: 0.45659470558166504 2022-07-01 00:04:26.729850
Epoch:[ 32 11 ] loss: 0.4570050537586212 2022-07-01 00:04:27.156469
Epoch:[ 32 12 ] loss: 0.4572431147098541 2022-07-01 00:04:27.586750
Epoch:[ 32 13 ] loss: 0.459270715713501 2022-07-01 00:04:28.015793
Epoch:[ 32 14 ] loss: 0.4595768451690674 2022-07-01 00:04:28.442966
Epoch:[ 32 15 ] loss: 0.4618969261646271 2022-07-01 00:04:28.874026
Epoch:[ 32 16 ] loss: 0.46112215518951416 2022-07-01 00:04:34.422960
Epoch:[ 32 17 ] loss: 0.4580579102039337 2022-07-01 00:04:34.850157
Epoch:[ 32 18 ] loss: 0.4590053856372833 2022-07-01 00:04:35.283141
Epoch:[ 32 19 ] loss: 0.45928019285202026 2022-07-01 00:04:35.710923
Training_Epoch:[ 32 ] Training_loss: 0.4595258757472038 2022-07-01 00:04:35.711605
learning rate:  0.025600000000000008
netparams have been saved once 32
val: 1 0.460322767496109
val: 2 0.4586077630519867
val: 3 0.4571011960506439
val: 4 0.4630905091762543
val: 5 0.4604871869087219
val: 6 0.45969927310943604
val: 7 0.4623880684375763
val: 8 0.45963823795318604
val: 9 0.46753114461898804
val: 10 0.46843862533569336
val: 11 0.46645447611808777
val: 12 0.47017043828964233
val: 13 0.4651535451412201
val: 14 0.46192821860313416
val: 15 0.47689157724380493
val: 16 0.4687105119228363
val: 17 0.4656864106655121
val: 18 0.46503835916519165
val: 19 0.4575027525424957
val: 20 0.4620538353919983
val_Epoch:[ 32 ] val_loss: 0.4638447448611259 2022-07-01 00:04:39.544083
start training 2022-07-01 00:04:39.644350
Epoch:[ 33 0 ] loss: 0.4648157060146332 2022-07-01 00:04:54.370485
Epoch:[ 33 1 ] loss: 0.4588093161582947 2022-07-01 00:04:54.791262
Epoch:[ 33 2 ] loss: 0.46243372559547424 2022-07-01 00:04:55.219389
Epoch:[ 33 3 ] loss: 0.45685267448425293 2022-07-01 00:04:55.647310
Epoch:[ 33 4 ] loss: 0.4585585594177246 2022-07-01 00:04:56.074688
Epoch:[ 33 5 ] loss: 0.462431937456131 2022-07-01 00:04:56.495686
Epoch:[ 33 6 ] loss: 0.4605828523635864 2022-07-01 00:04:56.925778
Epoch:[ 33 7 ] loss: 0.4543747007846832 2022-07-01 00:04:57.353100
Epoch:[ 33 8 ] loss: 0.4595143795013428 2022-07-01 00:04:57.779784
Epoch:[ 33 9 ] loss: 0.45567452907562256 2022-07-01 00:04:58.202515
Epoch:[ 33 10 ] loss: 0.45548388361930847 2022-07-01 00:04:58.631314
Epoch:[ 33 11 ] loss: 0.45696404576301575 2022-07-01 00:04:59.059049
Epoch:[ 33 12 ] loss: 0.4580487012863159 2022-07-01 00:04:59.485725
Epoch:[ 33 13 ] loss: 0.4592452645301819 2022-07-01 00:04:59.913104
Epoch:[ 33 14 ] loss: 0.4606598913669586 2022-07-01 00:05:00.340443
Epoch:[ 33 15 ] loss: 0.4570292532444 2022-07-01 00:05:00.768159
Epoch:[ 33 16 ] loss: 0.45978087186813354 2022-07-01 00:05:06.402462
Epoch:[ 33 17 ] loss: 0.45808959007263184 2022-07-01 00:05:06.830210
Epoch:[ 33 18 ] loss: 0.4563813805580139 2022-07-01 00:05:07.265431
Epoch:[ 33 19 ] loss: 0.45692113041877747 2022-07-01 00:05:07.692127
Training_Epoch:[ 33 ] Training_loss: 0.4586326196789742 2022-07-01 00:05:07.692839
learning rate:  0.025600000000000008
val: 1 0.47322914004325867
val: 2 0.47251829504966736
val: 3 0.4661254584789276
val: 4 0.46802660822868347
val: 5 0.46818971633911133
val: 6 0.4673258066177368
val: 7 0.46320202946662903
val: 8 0.463714063167572
val: 9 0.4695432782173157
val: 10 0.4667688310146332
val: 11 0.4732920229434967
val: 12 0.4714610278606415
val: 13 0.4682104289531708
val: 14 0.46225690841674805
val: 15 0.4623872637748718
val: 16 0.4610874354839325
val: 17 0.4641214609146118
val: 18 0.46345120668411255
val: 19 0.46933063864707947
val: 20 0.4643290340900421
val_Epoch:[ 33 ] val_loss: 0.4669285327196121 2022-07-01 00:05:11.477841
start training 2022-07-01 00:05:11.578854
Epoch:[ 34 0 ] loss: 0.45388907194137573 2022-07-01 00:05:26.635174
Epoch:[ 34 1 ] loss: 0.45837122201919556 2022-07-01 00:05:27.063480
Epoch:[ 34 2 ] loss: 0.45982134342193604 2022-07-01 00:05:27.490268
Epoch:[ 34 3 ] loss: 0.45634040236473083 2022-07-01 00:05:27.920316
Epoch:[ 34 4 ] loss: 0.4572870433330536 2022-07-01 00:05:28.343651
Epoch:[ 34 5 ] loss: 0.4563629627227783 2022-07-01 00:05:28.772214
Epoch:[ 34 6 ] loss: 0.45757174491882324 2022-07-01 00:05:29.201117
Epoch:[ 34 7 ] loss: 0.4615660309791565 2022-07-01 00:05:29.629758
Epoch:[ 34 8 ] loss: 0.4584704041481018 2022-07-01 00:05:30.036832
Epoch:[ 34 9 ] loss: 0.4578796923160553 2022-07-01 00:05:30.444702
Epoch:[ 34 10 ] loss: 0.46625766158103943 2022-07-01 00:05:30.855422
Epoch:[ 34 11 ] loss: 0.45383504033088684 2022-07-01 00:05:31.267388
Epoch:[ 34 12 ] loss: 0.46138498187065125 2022-07-01 00:05:31.683429
Epoch:[ 34 13 ] loss: 0.45700740814208984 2022-07-01 00:05:32.094079
Epoch:[ 34 14 ] loss: 0.4612428843975067 2022-07-01 00:05:32.513750
Epoch:[ 34 15 ] loss: 0.4615324139595032 2022-07-01 00:05:32.925386
Epoch:[ 34 16 ] loss: 0.45717599987983704 2022-07-01 00:05:38.168132
Epoch:[ 34 17 ] loss: 0.46153467893600464 2022-07-01 00:05:38.578064
Epoch:[ 34 18 ] loss: 0.4554470479488373 2022-07-01 00:05:38.996560
Epoch:[ 34 19 ] loss: 0.45931509137153625 2022-07-01 00:05:39.405394
Training_Epoch:[ 34 ] Training_loss: 0.458614656329155 2022-07-01 00:05:39.406345
learning rate:  0.025600000000000008
netparams have been saved once 34
val: 1 0.4695449471473694
val: 2 0.46207955479621887
val: 3 0.455518513917923
val: 4 0.47043052315711975
val: 5 0.465770423412323
val: 6 0.4482174813747406
val: 7 0.46314576268196106
val: 8 0.4749871790409088
val: 9 0.4492843747138977
val: 10 0.4631628692150116
val: 11 0.46509429812431335
val: 12 0.4600915312767029
val: 13 0.4768000543117523
val: 14 0.46689242124557495
val: 15 0.46018439531326294
val: 16 0.46297264099121094
val: 17 0.4621546268463135
val: 18 0.4665089547634125
val: 19 0.46715793013572693
val: 20 0.46407705545425415
val_Epoch:[ 34 ] val_loss: 0.4637037768959999 2022-07-01 00:05:43.541644
start training 2022-07-01 00:05:43.646323
Epoch:[ 35 0 ] loss: 0.4583289623260498 2022-07-01 00:05:58.703992
Epoch:[ 35 1 ] loss: 0.4597243070602417 2022-07-01 00:05:59.119985
Epoch:[ 35 2 ] loss: 0.4608273506164551 2022-07-01 00:05:59.553767
Epoch:[ 35 3 ] loss: 0.45916229486465454 2022-07-01 00:05:59.988846
Epoch:[ 35 4 ] loss: 0.4581699073314667 2022-07-01 00:06:00.424882
Epoch:[ 35 5 ] loss: 0.45396435260772705 2022-07-01 00:06:00.863595
Epoch:[ 35 6 ] loss: 0.4564996659755707 2022-07-01 00:06:01.299756
Epoch:[ 35 7 ] loss: 0.45782896876335144 2022-07-01 00:06:01.735268
Epoch:[ 35 8 ] loss: 0.45807895064353943 2022-07-01 00:06:02.177284
Epoch:[ 35 9 ] loss: 0.4582557678222656 2022-07-01 00:06:02.606165
Epoch:[ 35 10 ] loss: 0.4550282955169678 2022-07-01 00:06:03.040524
Epoch:[ 35 11 ] loss: 0.45634037256240845 2022-07-01 00:06:03.480823
Epoch:[ 35 12 ] loss: 0.45814746618270874 2022-07-01 00:06:03.899763
Epoch:[ 35 13 ] loss: 0.45745012164115906 2022-07-01 00:06:04.330484
Epoch:[ 35 14 ] loss: 0.4539065659046173 2022-07-01 00:06:04.766716
Epoch:[ 35 15 ] loss: 0.45884987711906433 2022-07-01 00:06:05.190259
Epoch:[ 35 16 ] loss: 0.4553997814655304 2022-07-01 00:06:10.609233
Epoch:[ 35 17 ] loss: 0.4563068151473999 2022-07-01 00:06:11.041892
Epoch:[ 35 18 ] loss: 0.4581907093524933 2022-07-01 00:06:11.459401
Epoch:[ 35 19 ] loss: 0.45494505763053894 2022-07-01 00:06:11.872453
Training_Epoch:[ 35 ] Training_loss: 0.4572702795267105 2022-07-01 00:06:11.873440
learning rate:  0.025600000000000008
val: 1 0.4669629633426666
val: 2 0.45874983072280884
val: 3 0.47495657205581665
val: 4 0.45606932044029236
val: 5 0.4604850709438324
val: 6 0.46858707070350647
val: 7 0.4625406265258789
val: 8 0.45376041531562805
val: 9 0.45482873916625977
val: 10 0.4585568606853485
val: 11 0.4650687277317047
val: 12 0.4616459012031555
val: 13 0.46738067269325256
val: 14 0.4643194377422333
val: 15 0.4549102187156677
val: 16 0.4573225677013397
val: 17 0.45454224944114685
val: 18 0.46033915877342224
val: 19 0.4577583372592926
val: 20 0.4659793972969055
val_Epoch:[ 35 ] val_loss: 0.461238206923008 2022-07-01 00:06:16.034621
start training 2022-07-01 00:06:16.145894
Epoch:[ 36 0 ] loss: 0.4559871256351471 2022-07-01 00:06:31.243112
Epoch:[ 36 1 ] loss: 0.45259425044059753 2022-07-01 00:06:31.676655
Epoch:[ 36 2 ] loss: 0.454933226108551 2022-07-01 00:06:32.088478
Epoch:[ 36 3 ] loss: 0.4561253786087036 2022-07-01 00:06:32.502871
Epoch:[ 36 4 ] loss: 0.45742887258529663 2022-07-01 00:06:32.911657
Epoch:[ 36 5 ] loss: 0.4561043381690979 2022-07-01 00:06:33.323895
Epoch:[ 36 6 ] loss: 0.4523486793041229 2022-07-01 00:06:33.735872
Epoch:[ 36 7 ] loss: 0.4531952440738678 2022-07-01 00:06:34.149058
Epoch:[ 36 8 ] loss: 0.4531276226043701 2022-07-01 00:06:34.561569
Epoch:[ 36 9 ] loss: 0.45572590827941895 2022-07-01 00:06:34.971030
Epoch:[ 36 10 ] loss: 0.46173110604286194 2022-07-01 00:06:35.389255
Epoch:[ 36 11 ] loss: 0.45757338404655457 2022-07-01 00:06:35.797985
Epoch:[ 36 12 ] loss: 0.4533989727497101 2022-07-01 00:06:36.209249
Epoch:[ 36 13 ] loss: 0.45817989110946655 2022-07-01 00:06:36.622246
Epoch:[ 36 14 ] loss: 0.4539080858230591 2022-07-01 00:06:37.041122
Epoch:[ 36 15 ] loss: 0.45963868498802185 2022-07-01 00:06:37.452560
Epoch:[ 36 16 ] loss: 0.45888155698776245 2022-07-01 00:06:42.850460
Epoch:[ 36 17 ] loss: 0.4549020230770111 2022-07-01 00:06:43.270284
Epoch:[ 36 18 ] loss: 0.4569760859012604 2022-07-01 00:06:43.690363
Epoch:[ 36 19 ] loss: 0.4533514976501465 2022-07-01 00:06:44.110997
Training_Epoch:[ 36 ] Training_loss: 0.4558055967092514 2022-07-01 00:06:44.112022
learning rate:  0.025600000000000008
netparams have been saved once 36
val: 1 0.4721817970275879
val: 2 0.45907527208328247
val: 3 0.4553043246269226
val: 4 0.4560794532299042
val: 5 0.4700508415699005
val: 6 0.46955835819244385
val: 7 0.4594695568084717
val: 8 0.46044692397117615
val: 9 0.46201837062835693
val: 10 0.47124791145324707
val: 11 0.4615994691848755
val: 12 0.4706471860408783
val: 13 0.4646255075931549
val: 14 0.4745996594429016
val: 15 0.46937599778175354
val: 16 0.4744572341442108
val: 17 0.4604172706604004
val: 18 0.4788442552089691
val: 19 0.4740908145904541
val: 20 0.46801868081092834
val_Epoch:[ 36 ] val_loss: 0.466605444252491 2022-07-01 00:06:48.078247
start training 2022-07-01 00:06:48.182056
Epoch:[ 37 0 ] loss: 0.45646238327026367 2022-07-01 00:07:02.469684
Epoch:[ 37 1 ] loss: 0.453148752450943 2022-07-01 00:07:02.911622
Epoch:[ 37 2 ] loss: 0.451840341091156 2022-07-01 00:07:03.333238
Epoch:[ 37 3 ] loss: 0.45440274477005005 2022-07-01 00:07:03.758499
Epoch:[ 37 4 ] loss: 0.4504421651363373 2022-07-01 00:07:04.177912
Epoch:[ 37 5 ] loss: 0.4572872519493103 2022-07-01 00:07:04.599027
Epoch:[ 37 6 ] loss: 0.456589013338089 2022-07-01 00:07:05.022038
Epoch:[ 37 7 ] loss: 0.45646539330482483 2022-07-01 00:07:05.442016
Epoch:[ 37 8 ] loss: 0.45621156692504883 2022-07-01 00:07:05.864799
Epoch:[ 37 9 ] loss: 0.4516575336456299 2022-07-01 00:07:06.292749
Epoch:[ 37 10 ] loss: 0.4559692442417145 2022-07-01 00:07:06.716945
Epoch:[ 37 11 ] loss: 0.45603734254837036 2022-07-01 00:07:07.138024
Epoch:[ 37 12 ] loss: 0.4508347809314728 2022-07-01 00:07:07.553818
Epoch:[ 37 13 ] loss: 0.45528644323349 2022-07-01 00:07:07.980116
Epoch:[ 37 14 ] loss: 0.4504217803478241 2022-07-01 00:07:08.400942
Epoch:[ 37 15 ] loss: 0.4485742449760437 2022-07-01 00:07:08.827326
Epoch:[ 37 16 ] loss: 0.44875267148017883 2022-07-01 00:07:14.333957
Epoch:[ 37 17 ] loss: 0.45115071535110474 2022-07-01 00:07:14.872562
Epoch:[ 37 18 ] loss: 0.45292940735816956 2022-07-01 00:07:15.295787
Epoch:[ 37 19 ] loss: 0.44878089427948 2022-07-01 00:07:15.715660
Training_Epoch:[ 37 ] Training_loss: 0.45316223353147506 2022-07-01 00:07:15.716464
learning rate:  0.025600000000000008
val: 1 0.46596741676330566
val: 2 0.4665674865245819
val: 3 0.46826890110969543
val: 4 0.46961545944213867
val: 5 0.4763832688331604
val: 6 0.44429948925971985
val: 7 0.468563050031662
val: 8 0.453681081533432
val: 9 0.45968788862228394
val: 10 0.4622749388217926
val: 11 0.45968493819236755
val: 12 0.46064725518226624
val: 13 0.46673503518104553
val: 14 0.45688295364379883
val: 15 0.4787733256816864
val: 16 0.4592434763908386
val: 17 0.4765193462371826
val: 18 0.4670351445674896
val: 19 0.45096278190612793
val: 20 0.47835594415664673
val_Epoch:[ 37 ] val_loss: 0.4645074591040611 2022-07-01 00:07:19.506796
start training 2022-07-01 00:07:19.621142
Epoch:[ 38 0 ] loss: 0.4530080258846283 2022-07-01 00:07:34.800851
Epoch:[ 38 1 ] loss: 0.45351099967956543 2022-07-01 00:07:35.221483
Epoch:[ 38 2 ] loss: 0.45388081669807434 2022-07-01 00:07:35.643198
Epoch:[ 38 3 ] loss: 0.45260995626449585 2022-07-01 00:07:36.054647
Epoch:[ 38 4 ] loss: 0.45505863428115845 2022-07-01 00:07:36.468079
Epoch:[ 38 5 ] loss: 0.450909823179245 2022-07-01 00:07:36.880122
Epoch:[ 38 6 ] loss: 0.45109546184539795 2022-07-01 00:07:37.298261
Epoch:[ 38 7 ] loss: 0.4544975757598877 2022-07-01 00:07:37.712438
Epoch:[ 38 8 ] loss: 0.4545527696609497 2022-07-01 00:07:38.137067
Epoch:[ 38 9 ] loss: 0.45436954498291016 2022-07-01 00:07:38.557544
Epoch:[ 38 10 ] loss: 0.4524379074573517 2022-07-01 00:07:38.980491
Epoch:[ 38 11 ] loss: 0.45314908027648926 2022-07-01 00:07:39.402438
Epoch:[ 38 12 ] loss: 0.44995519518852234 2022-07-01 00:07:39.825020
Epoch:[ 38 13 ] loss: 0.45712974667549133 2022-07-01 00:07:40.246597
Epoch:[ 38 14 ] loss: 0.4534127116203308 2022-07-01 00:07:40.669174
Epoch:[ 38 15 ] loss: 0.4507792592048645 2022-07-01 00:07:41.091164
Epoch:[ 38 16 ] loss: 0.450958251953125 2022-07-01 00:07:46.850227
Epoch:[ 38 17 ] loss: 0.4506368935108185 2022-07-01 00:07:47.270539
Epoch:[ 38 18 ] loss: 0.4502331614494324 2022-07-01 00:07:47.699671
Epoch:[ 38 19 ] loss: 0.4527759850025177 2022-07-01 00:07:48.121553
Training_Epoch:[ 38 ] Training_loss: 0.4527480900287628 2022-07-01 00:07:48.122291
learning rate:  0.025600000000000008
netparams have been saved once 38
val: 1 0.46698716282844543
val: 2 0.4644431471824646
val: 3 0.4645998477935791
val: 4 0.4658026695251465
val: 5 0.46097132563591003
val: 6 0.46078988909721375
val: 7 0.4587308466434479
val: 8 0.45840996503829956
val: 9 0.47089341282844543
val: 10 0.4623832106590271
val: 11 0.46609169244766235
val: 12 0.46699845790863037
val: 13 0.46225133538246155
val: 14 0.46670612692832947
val: 15 0.45674750208854675
val: 16 0.45223432779312134
val: 17 0.4591105580329895
val: 18 0.4573889672756195
val: 19 0.4714382588863373
val: 20 0.4537968039512634
val_Epoch:[ 38 ] val_loss: 0.46233877539634705 2022-07-01 00:07:51.957327
start training 2022-07-01 00:07:52.059789
Epoch:[ 39 0 ] loss: 0.4502447843551636 2022-07-01 00:08:06.984680
Epoch:[ 39 1 ] loss: 0.4482145607471466 2022-07-01 00:08:07.406515
Epoch:[ 39 2 ] loss: 0.4503365457057953 2022-07-01 00:08:07.828464
Epoch:[ 39 3 ] loss: 0.45377352833747864 2022-07-01 00:08:08.248653
Epoch:[ 39 4 ] loss: 0.4554891884326935 2022-07-01 00:08:08.670969
Epoch:[ 39 5 ] loss: 0.45587581396102905 2022-07-01 00:08:09.091268
Epoch:[ 39 6 ] loss: 0.4491893947124481 2022-07-01 00:08:09.511759
Epoch:[ 39 7 ] loss: 0.4519164264202118 2022-07-01 00:08:09.925264
Epoch:[ 39 8 ] loss: 0.4503204822540283 2022-07-01 00:08:10.347849
Epoch:[ 39 9 ] loss: 0.45004701614379883 2022-07-01 00:08:10.769961
Epoch:[ 39 10 ] loss: 0.44335564970970154 2022-07-01 00:08:11.194316
Epoch:[ 39 11 ] loss: 0.4513948857784271 2022-07-01 00:08:11.613993
Epoch:[ 39 12 ] loss: 0.44996151328086853 2022-07-01 00:08:12.035689
Epoch:[ 39 13 ] loss: 0.45205214619636536 2022-07-01 00:08:12.454777
Epoch:[ 39 14 ] loss: 0.45227324962615967 2022-07-01 00:08:12.867846
Epoch:[ 39 15 ] loss: 0.4519155025482178 2022-07-01 00:08:13.288735
Epoch:[ 39 16 ] loss: 0.4510761499404907 2022-07-01 00:08:18.405312
Epoch:[ 39 17 ] loss: 0.4501058757305145 2022-07-01 00:08:18.825952
Epoch:[ 39 18 ] loss: 0.45091381669044495 2022-07-01 00:08:19.247148
Epoch:[ 39 19 ] loss: 0.4523865878582001 2022-07-01 00:08:19.666504
Training_Epoch:[ 39 ] Training_loss: 0.4510421559214592 2022-07-01 00:08:19.667190
learning rate:  0.025600000000000008
val: 1 0.4668346643447876
val: 2 0.4631733298301697
val: 3 0.4581034481525421
val: 4 0.44653385877609253
val: 5 0.4608596861362457
val: 6 0.46394914388656616
val: 7 0.4678710699081421
val: 8 0.4485398232936859
val: 9 0.46432027220726013
val: 10 0.45506685972213745
val: 11 0.45211634039878845
val: 12 0.4786781370639801
val: 13 0.4606369137763977
val: 14 0.4617706537246704
val: 15 0.4676474630832672
val: 16 0.4663938581943512
val: 17 0.45138561725616455
val: 18 0.4643345773220062
val: 19 0.4530053436756134
val: 20 0.47392258048057556
val_Epoch:[ 39 ] val_loss: 0.4612571820616722 2022-07-01 00:08:23.436684
start training 2022-07-01 00:08:23.540228
Epoch:[ 40 0 ] loss: 0.448346346616745 2022-07-01 00:08:37.799526
Epoch:[ 40 1 ] loss: 0.44928449392318726 2022-07-01 00:08:38.233991
Epoch:[ 40 2 ] loss: 0.4469332993030548 2022-07-01 00:08:38.655082
Epoch:[ 40 3 ] loss: 0.45006588101387024 2022-07-01 00:08:39.079186
Epoch:[ 40 4 ] loss: 0.44945982098579407 2022-07-01 00:08:39.499409
Epoch:[ 40 5 ] loss: 0.4532965421676636 2022-07-01 00:08:39.919127
Epoch:[ 40 6 ] loss: 0.45065975189208984 2022-07-01 00:08:40.331746
Epoch:[ 40 7 ] loss: 0.450117290019989 2022-07-01 00:08:40.741436
Epoch:[ 40 8 ] loss: 0.4506608545780182 2022-07-01 00:08:41.149324
Epoch:[ 40 9 ] loss: 0.4518626928329468 2022-07-01 00:08:41.558971
Epoch:[ 40 10 ] loss: 0.45695051550865173 2022-07-01 00:08:41.970714
Epoch:[ 40 11 ] loss: 0.44817230105400085 2022-07-01 00:08:42.385712
Epoch:[ 40 12 ] loss: 0.45074769854545593 2022-07-01 00:08:42.794611
Epoch:[ 40 13 ] loss: 0.45598652958869934 2022-07-01 00:08:43.204616
Epoch:[ 40 14 ] loss: 0.450035959482193 2022-07-01 00:08:43.616302
Epoch:[ 40 15 ] loss: 0.4574643671512604 2022-07-01 00:08:44.025300
Epoch:[ 40 16 ] loss: 0.44668513536453247 2022-07-01 00:08:49.466578
Epoch:[ 40 17 ] loss: 0.45060285925865173 2022-07-01 00:08:49.877380
Epoch:[ 40 18 ] loss: 0.45206770300865173 2022-07-01 00:08:50.300430
Epoch:[ 40 19 ] loss: 0.45204243063926697 2022-07-01 00:08:50.709343
Training_Epoch:[ 40 ] Training_loss: 0.45107212364673616 2022-07-01 00:08:50.710113
learning rate:  0.025600000000000008
netparams have been saved once 40
val: 1 0.4489867687225342
val: 2 0.45580437779426575
val: 3 0.45204171538352966
val: 4 0.45390063524246216
val: 5 0.44961950182914734
val: 6 0.4569667875766754
val: 7 0.45357978343963623
val: 8 0.4682857394218445
val: 9 0.4641910791397095
val: 10 0.46524742245674133
val: 11 0.45989447832107544
val: 12 0.45195332169532776
val: 13 0.45180606842041016
val: 14 0.45906758308410645
val: 15 0.452955424785614
val: 16 0.4684353768825531
val: 17 0.44728854298591614
val: 18 0.4565361738204956
val: 19 0.4527868628501892
val: 20 0.4524767994880676
val_Epoch:[ 40 ] val_loss: 0.4560912221670151 2022-07-01 00:08:54.522524
start training 2022-07-01 00:08:54.625100
Epoch:[ 41 0 ] loss: 0.4504902958869934 2022-07-01 00:09:09.531786
Epoch:[ 41 1 ] loss: 0.45002982020378113 2022-07-01 00:09:09.955476
Epoch:[ 41 2 ] loss: 0.448580801486969 2022-07-01 00:09:10.368864
Epoch:[ 41 3 ] loss: 0.449768602848053 2022-07-01 00:09:10.789852
Epoch:[ 41 4 ] loss: 0.4496108889579773 2022-07-01 00:09:11.210764
Epoch:[ 41 5 ] loss: 0.4483466148376465 2022-07-01 00:09:11.630760
Epoch:[ 41 6 ] loss: 0.4491614103317261 2022-07-01 00:09:12.050711
Epoch:[ 41 7 ] loss: 0.4520127475261688 2022-07-01 00:09:12.469856
Epoch:[ 41 8 ] loss: 0.446435809135437 2022-07-01 00:09:12.889632
Epoch:[ 41 9 ] loss: 0.44638538360595703 2022-07-01 00:09:13.308038
Epoch:[ 41 10 ] loss: 0.4492981433868408 2022-07-01 00:09:13.728616
Epoch:[ 41 11 ] loss: 0.45082342624664307 2022-07-01 00:09:14.149502
Epoch:[ 41 12 ] loss: 0.4456577003002167 2022-07-01 00:09:14.571112
Epoch:[ 41 13 ] loss: 0.44514068961143494 2022-07-01 00:09:14.990991
Epoch:[ 41 14 ] loss: 0.44754546880722046 2022-07-01 00:09:15.411136
Epoch:[ 41 15 ] loss: 0.44828182458877563 2022-07-01 00:09:15.830199
Epoch:[ 41 16 ] loss: 0.44654330611228943 2022-07-01 00:09:20.994159
Epoch:[ 41 17 ] loss: 0.4460858106613159 2022-07-01 00:09:21.416111
Epoch:[ 41 18 ] loss: 0.44705814123153687 2022-07-01 00:09:21.838274
Epoch:[ 41 19 ] loss: 0.44328823685646057 2022-07-01 00:09:22.258578
Training_Epoch:[ 41 ] Training_loss: 0.44802725613117217 2022-07-01 00:09:22.259309
learning rate:  0.02048000000000001
val: 1 0.4572194814682007
val: 2 0.4654800593852997
val: 3 0.4629720151424408
val: 4 0.4627656638622284
val: 5 0.4572247266769409
val: 6 0.4564269781112671
val: 7 0.45768338441848755
val: 8 0.45677629113197327
val: 9 0.45445457100868225
val: 10 0.4554492235183716
val: 11 0.46509429812431335
val: 12 0.47003886103630066
val: 13 0.44732779264450073
val: 14 0.4571538269519806
val: 15 0.45085829496383667
val: 16 0.448765367269516
val: 17 0.4536345601081848
val: 18 0.4587737023830414
val: 19 0.46320146322250366
val: 20 0.46886903047561646
val_Epoch:[ 41 ] val_loss: 0.4585084795951843 2022-07-01 00:09:25.954177
start training 2022-07-01 00:09:26.059217
Epoch:[ 42 0 ] loss: 0.44853663444519043 2022-07-01 00:09:40.928726
Epoch:[ 42 1 ] loss: 0.44411206245422363 2022-07-01 00:09:41.352387
Epoch:[ 42 2 ] loss: 0.44551464915275574 2022-07-01 00:09:41.769018
Epoch:[ 42 3 ] loss: 0.4446757435798645 2022-07-01 00:09:42.177995
Epoch:[ 42 4 ] loss: 0.4496488869190216 2022-07-01 00:09:42.588460
Epoch:[ 42 5 ] loss: 0.44583556056022644 2022-07-01 00:09:42.999551
Epoch:[ 42 6 ] loss: 0.44628119468688965 2022-07-01 00:09:43.414074
Epoch:[ 42 7 ] loss: 0.4470672905445099 2022-07-01 00:09:43.822179
Epoch:[ 42 8 ] loss: 0.44360682368278503 2022-07-01 00:09:44.231569
Epoch:[ 42 9 ] loss: 0.44705721735954285 2022-07-01 00:09:44.641933
Epoch:[ 42 10 ] loss: 0.44333401322364807 2022-07-01 00:09:45.052115
Epoch:[ 42 11 ] loss: 0.4463139474391937 2022-07-01 00:09:45.463372
Epoch:[ 42 12 ] loss: 0.44731223583221436 2022-07-01 00:09:45.874486
Epoch:[ 42 13 ] loss: 0.44658035039901733 2022-07-01 00:09:46.287691
Epoch:[ 42 14 ] loss: 0.44659093022346497 2022-07-01 00:09:46.702531
Epoch:[ 42 15 ] loss: 0.4445623457431793 2022-07-01 00:09:47.112544
Epoch:[ 42 16 ] loss: 0.4463053345680237 2022-07-01 00:09:52.304197
Epoch:[ 42 17 ] loss: 0.44589823484420776 2022-07-01 00:09:52.711739
Epoch:[ 42 18 ] loss: 0.4440702795982361 2022-07-01 00:09:53.134350
Epoch:[ 42 19 ] loss: 0.4484855830669403 2022-07-01 00:09:53.555352
Training_Epoch:[ 42 ] Training_loss: 0.4460894659161568 2022-07-01 00:09:53.556153
learning rate:  0.02048000000000001
netparams have been saved once 42
val: 1 0.45491206645965576
val: 2 0.44372937083244324
val: 3 0.4537019729614258
val: 4 0.45341822504997253
val: 5 0.4513839781284332
val: 6 0.45242637395858765
val: 7 0.4383768141269684
val: 8 0.45551347732543945
val: 9 0.44248929619789124
val: 10 0.4550400972366333
val: 11 0.46083974838256836
val: 12 0.45594802498817444
val: 13 0.45954829454421997
val: 14 0.459110289812088
val: 15 0.45244431495666504
val: 16 0.45771855115890503
val: 17 0.46511754393577576
val: 18 0.44666942954063416
val: 19 0.46192413568496704
val: 20 0.46820616722106934
val_Epoch:[ 42 ] val_loss: 0.4544259086251259 2022-07-01 00:09:57.337670
start training 2022-07-01 00:09:57.438146
Epoch:[ 43 0 ] loss: 0.44365742802619934 2022-07-01 00:10:12.160777
Epoch:[ 43 1 ] loss: 0.44698891043663025 2022-07-01 00:10:12.580837
Epoch:[ 43 2 ] loss: 0.4434852600097656 2022-07-01 00:10:12.997530
Epoch:[ 43 3 ] loss: 0.443711519241333 2022-07-01 00:10:13.417352
Epoch:[ 43 4 ] loss: 0.4410853981971741 2022-07-01 00:10:13.836638
Epoch:[ 43 5 ] loss: 0.4443601071834564 2022-07-01 00:10:14.257955
Epoch:[ 43 6 ] loss: 0.44243836402893066 2022-07-01 00:10:14.680457
Epoch:[ 43 7 ] loss: 0.44741547107696533 2022-07-01 00:10:15.102091
Epoch:[ 43 8 ] loss: 0.4483494162559509 2022-07-01 00:10:15.522516
Epoch:[ 43 9 ] loss: 0.4493354260921478 2022-07-01 00:10:15.930779
Epoch:[ 43 10 ] loss: 0.4515036344528198 2022-07-01 00:10:16.339704
Epoch:[ 43 11 ] loss: 0.4471514821052551 2022-07-01 00:10:16.748327
Epoch:[ 43 12 ] loss: 0.45084601640701294 2022-07-01 00:10:17.157756
Epoch:[ 43 13 ] loss: 0.4536166191101074 2022-07-01 00:10:17.566846
Epoch:[ 43 14 ] loss: 0.44979920983314514 2022-07-01 00:10:17.975996
Epoch:[ 43 15 ] loss: 0.4535095989704132 2022-07-01 00:10:18.384019
Epoch:[ 43 16 ] loss: 0.44721314311027527 2022-07-01 00:10:23.556864
Epoch:[ 43 17 ] loss: 0.45100709795951843 2022-07-01 00:10:23.963922
Epoch:[ 43 18 ] loss: 0.4460213780403137 2022-07-01 00:10:24.382591
Epoch:[ 43 19 ] loss: 0.4481319487094879 2022-07-01 00:10:24.792612
Training_Epoch:[ 43 ] Training_loss: 0.4474813714623451 2022-07-01 00:10:24.793522
learning rate:  0.02048000000000001
val: 1 0.4504898488521576
val: 2 0.45370715856552124
val: 3 0.4694044589996338
val: 4 0.4634040296077728
val: 5 0.456687331199646
val: 6 0.4462737739086151
val: 7 0.4572463035583496
val: 8 0.45126163959503174
val: 9 0.4642321765422821
val: 10 0.4554334580898285
val: 11 0.45768946409225464
val: 12 0.45458805561065674
val: 13 0.4479026794433594
val: 14 0.461154580116272
val: 15 0.4576249122619629
val: 16 0.44309481978416443
val: 17 0.4522783160209656
val: 18 0.465371310710907
val: 19 0.4518260359764099
val: 20 0.4614618122577667
val_Epoch:[ 43 ] val_loss: 0.45605660825967786 2022-07-01 00:10:28.679083
start training 2022-07-01 00:10:28.777489
Epoch:[ 44 0 ] loss: 0.45100465416908264 2022-07-01 00:10:43.006027
Epoch:[ 44 1 ] loss: 0.4438535273075104 2022-07-01 00:10:43.836287
Epoch:[ 44 2 ] loss: 0.4477155804634094 2022-07-01 00:10:44.249672
Epoch:[ 44 3 ] loss: 0.44710013270378113 2022-07-01 00:10:44.669038
Epoch:[ 44 4 ] loss: 0.44992953538894653 2022-07-01 00:10:45.088417
Epoch:[ 44 5 ] loss: 0.4435702860355377 2022-07-01 00:10:45.508313
Epoch:[ 44 6 ] loss: 0.4493282735347748 2022-07-01 00:10:45.930248
Epoch:[ 44 7 ] loss: 0.44664210081100464 2022-07-01 00:10:46.351981
Epoch:[ 44 8 ] loss: 0.4488869607448578 2022-07-01 00:10:46.772687
Epoch:[ 44 9 ] loss: 0.4457724392414093 2022-07-01 00:10:47.191719
Epoch:[ 44 10 ] loss: 0.4461092948913574 2022-07-01 00:10:47.613003
Epoch:[ 44 11 ] loss: 0.4478600025177002 2022-07-01 00:10:48.033163
Epoch:[ 44 12 ] loss: 0.4440380036830902 2022-07-01 00:10:48.452010
Epoch:[ 44 13 ] loss: 0.4454740285873413 2022-07-01 00:10:48.872426
Epoch:[ 44 14 ] loss: 0.44575145840644836 2022-07-01 00:10:49.294444
Epoch:[ 44 15 ] loss: 0.44687891006469727 2022-07-01 00:10:49.714478
Epoch:[ 44 16 ] loss: 0.4506833553314209 2022-07-01 00:10:54.616527
Epoch:[ 44 17 ] loss: 0.44675639271736145 2022-07-01 00:10:55.738044
Epoch:[ 44 18 ] loss: 0.44676417112350464 2022-07-01 00:10:56.169561
Epoch:[ 44 19 ] loss: 0.44461169838905334 2022-07-01 00:10:56.588329
Training_Epoch:[ 44 ] Training_loss: 0.44693654030561447 2022-07-01 00:10:56.589226
learning rate:  0.02048000000000001
netparams have been saved once 44
val: 1 0.456461101770401
val: 2 0.4653697907924652
val: 3 0.46593520045280457
val: 4 0.4517970383167267
val: 5 0.4580861032009125
val: 6 0.456465482711792
val: 7 0.46959492564201355
val: 8 0.45966270565986633
val: 9 0.46767115592956543
val: 10 0.4627326726913452
val: 11 0.4608475863933563
val: 12 0.4493044912815094
val: 13 0.45279714465141296
val: 14 0.4595532715320587
val: 15 0.4547727108001709
val: 16 0.46467337012290955
val: 17 0.4620282053947449
val: 18 0.46504896879196167
val: 19 0.4796372652053833
val: 20 0.46502581238746643
val_Epoch:[ 44 ] val_loss: 0.4613732501864433 2022-07-01 00:11:00.340042
start training 2022-07-01 00:11:00.437328
Epoch:[ 45 0 ] loss: 0.44792914390563965 2022-07-01 00:11:15.184279
Epoch:[ 45 1 ] loss: 0.4449702799320221 2022-07-01 00:11:15.605893
Epoch:[ 45 2 ] loss: 0.4439760446548462 2022-07-01 00:11:16.029199
Epoch:[ 45 3 ] loss: 0.4432317912578583 2022-07-01 00:11:16.449380
Epoch:[ 45 4 ] loss: 0.44703495502471924 2022-07-01 00:11:16.868806
Epoch:[ 45 5 ] loss: 0.44399774074554443 2022-07-01 00:11:17.288249
Epoch:[ 45 6 ] loss: 0.4484109580516815 2022-07-01 00:11:17.708695
Epoch:[ 45 7 ] loss: 0.4438503384590149 2022-07-01 00:11:18.129196
Epoch:[ 45 8 ] loss: 0.44384175539016724 2022-07-01 00:11:18.551227
Epoch:[ 45 9 ] loss: 0.4438169300556183 2022-07-01 00:11:18.967837
Epoch:[ 45 10 ] loss: 0.444592148065567 2022-07-01 00:11:19.388101
Epoch:[ 45 11 ] loss: 0.44503292441368103 2022-07-01 00:11:19.809159
Epoch:[ 45 12 ] loss: 0.4436569809913635 2022-07-01 00:11:20.228404
Epoch:[ 45 13 ] loss: 0.44682246446609497 2022-07-01 00:11:20.640905
Epoch:[ 45 14 ] loss: 0.4451643228530884 2022-07-01 00:11:21.064365
Epoch:[ 45 15 ] loss: 0.44338294863700867 2022-07-01 00:11:21.486566
Epoch:[ 45 16 ] loss: 0.4475807547569275 2022-07-01 00:11:26.681354
Epoch:[ 45 17 ] loss: 0.4497148394584656 2022-07-01 00:11:27.100113
Epoch:[ 45 18 ] loss: 0.4451712369918823 2022-07-01 00:11:27.520614
Epoch:[ 45 19 ] loss: 0.4511183500289917 2022-07-01 00:11:27.939703
Training_Epoch:[ 45 ] Training_loss: 0.4456648454070091 2022-07-01 00:11:27.940389
learning rate:  0.02048000000000001
val: 1 0.4484502375125885
val: 2 0.4579101502895355
val: 3 0.4417804181575775
val: 4 0.457396924495697
val: 5 0.4360254406929016
val: 6 0.45804363489151
val: 7 0.4422626197338104
val: 8 0.4514751732349396
val: 9 0.4379271864891052
val: 10 0.4490829408168793
val: 11 0.4506426453590393
val: 12 0.4391874372959137
val: 13 0.4417223036289215
val: 14 0.4564961791038513
val: 15 0.45013952255249023
val: 16 0.4522879123687744
val: 17 0.4455546438694
val: 18 0.46264582872390747
val: 19 0.4540618360042572
val: 20 0.4580240249633789
val_Epoch:[ 45 ] val_loss: 0.44955585300922396 2022-07-01 00:11:31.615818
start training 2022-07-01 00:11:31.712886
Epoch:[ 46 0 ] loss: 0.44106000661849976 2022-07-01 00:11:46.361280
Epoch:[ 46 1 ] loss: 0.4462173283100128 2022-07-01 00:11:46.782619
Epoch:[ 46 2 ] loss: 0.44645029306411743 2022-07-01 00:11:47.205143
Epoch:[ 46 3 ] loss: 0.44580429792404175 2022-07-01 00:11:47.618854
Epoch:[ 46 4 ] loss: 0.4475076496601105 2022-07-01 00:11:48.030641
Epoch:[ 46 5 ] loss: 0.44622498750686646 2022-07-01 00:11:48.440475
Epoch:[ 46 6 ] loss: 0.4419442415237427 2022-07-01 00:11:48.848476
Epoch:[ 46 7 ] loss: 0.4402746558189392 2022-07-01 00:11:49.257052
Epoch:[ 46 8 ] loss: 0.442208468914032 2022-07-01 00:11:49.667608
Epoch:[ 46 9 ] loss: 0.44262823462486267 2022-07-01 00:11:50.077557
Epoch:[ 46 10 ] loss: 0.44109997153282166 2022-07-01 00:11:50.488542
Epoch:[ 46 11 ] loss: 0.4458354711532593 2022-07-01 00:11:50.896931
Epoch:[ 46 12 ] loss: 0.44147610664367676 2022-07-01 00:11:51.307534
Epoch:[ 46 13 ] loss: 0.4441790282726288 2022-07-01 00:11:51.718144
Epoch:[ 46 14 ] loss: 0.441934734582901 2022-07-01 00:11:52.132586
Epoch:[ 46 15 ] loss: 0.44140294194221497 2022-07-01 00:11:52.541518
Epoch:[ 46 16 ] loss: 0.4417082965373993 2022-07-01 00:11:58.192503
Epoch:[ 46 17 ] loss: 0.44372859597206116 2022-07-01 00:11:58.610529
Epoch:[ 46 18 ] loss: 0.4434359073638916 2022-07-01 00:11:59.031288
Epoch:[ 46 19 ] loss: 0.4441242218017578 2022-07-01 00:11:59.452139
Training_Epoch:[ 46 ] Training_loss: 0.4434622719883919 2022-07-01 00:11:59.452931
learning rate:  0.02048000000000001
netparams have been saved once 46
val: 1 0.45674020051956177
val: 2 0.4482930898666382
val: 3 0.4533487558364868
val: 4 0.44471877813339233
val: 5 0.4472515285015106
val: 6 0.4467550814151764
val: 7 0.4472563862800598
val: 8 0.43310093879699707
val: 9 0.44996628165245056
val: 10 0.44125643372535706
val: 11 0.44710251688957214
val: 12 0.4585089683532715
val: 13 0.4463268518447876
val: 14 0.442088782787323
val: 15 0.45271697640419006
val: 16 0.44632798433303833
val: 17 0.4477725923061371
val: 18 0.45788344740867615
val: 19 0.4531853497028351
val: 20 0.45627135038375854
val_Epoch:[ 46 ] val_loss: 0.448843614757061 2022-07-01 00:12:03.264502
start training 2022-07-01 00:12:03.362121
Epoch:[ 47 0 ] loss: 0.443012535572052 2022-07-01 00:12:17.301912
Epoch:[ 47 1 ] loss: 0.4424181580543518 2022-07-01 00:12:17.721426
Epoch:[ 47 2 ] loss: 0.44018304347991943 2022-07-01 00:12:18.145002
Epoch:[ 47 3 ] loss: 0.4459095299243927 2022-07-01 00:12:18.565683
Epoch:[ 47 4 ] loss: 0.44423824548721313 2022-07-01 00:12:18.985148
Epoch:[ 47 5 ] loss: 0.444222629070282 2022-07-01 00:12:19.404578
Epoch:[ 47 6 ] loss: 0.44304636120796204 2022-07-01 00:12:19.827776
Epoch:[ 47 7 ] loss: 0.44439926743507385 2022-07-01 00:12:20.247941
Epoch:[ 47 8 ] loss: 0.44317904114723206 2022-07-01 00:12:20.667877
Epoch:[ 47 9 ] loss: 0.44177547097206116 2022-07-01 00:12:21.089491
Epoch:[ 47 10 ] loss: 0.44341444969177246 2022-07-01 00:12:21.512445
Epoch:[ 47 11 ] loss: 0.44196000695228577 2022-07-01 00:12:21.926436
Epoch:[ 47 12 ] loss: 0.4373096823692322 2022-07-01 00:12:22.346190
Epoch:[ 47 13 ] loss: 0.4451866149902344 2022-07-01 00:12:22.766180
Epoch:[ 47 14 ] loss: 0.4431970417499542 2022-07-01 00:12:23.183201
Epoch:[ 47 15 ] loss: 0.4422873258590698 2022-07-01 00:12:23.591874
Epoch:[ 47 16 ] loss: 0.44411641359329224 2022-07-01 00:12:29.320179
Epoch:[ 47 17 ] loss: 0.44319871068000793 2022-07-01 00:12:29.737708
Epoch:[ 47 18 ] loss: 0.4433610141277313 2022-07-01 00:12:30.162770
Epoch:[ 47 19 ] loss: 0.44365936517715454 2022-07-01 00:12:30.581667
Training_Epoch:[ 47 ] Training_loss: 0.4430037453770638 2022-07-01 00:12:30.582393
learning rate:  0.02048000000000001
val: 1 0.4557046592235565
val: 2 0.45958632230758667
val: 3 0.44491562247276306
val: 4 0.459644079208374
val: 5 0.43831393122673035
val: 6 0.44774365425109863
val: 7 0.4465520679950714
val: 8 0.4553559422492981
val: 9 0.4435313940048218
val: 10 0.45610126852989197
val: 11 0.4482160210609436
val: 12 0.44966819882392883
val: 13 0.4480701982975006
val: 14 0.455867737531662
val: 15 0.45745497941970825
val: 16 0.44081756472587585
val: 17 0.4429992139339447
val: 18 0.45801156759262085
val: 19 0.4543208181858063
val: 20 0.4479547441005707
val_Epoch:[ 47 ] val_loss: 0.4505414992570877 2022-07-01 00:12:34.331275
start training 2022-07-01 00:12:34.428094
Epoch:[ 48 0 ] loss: 0.4397217631340027 2022-07-01 00:12:48.498004
Epoch:[ 48 1 ] loss: 0.44220390915870667 2022-07-01 00:12:49.274810
Epoch:[ 48 2 ] loss: 0.442484050989151 2022-07-01 00:12:49.694043
Epoch:[ 48 3 ] loss: 0.4424373507499695 2022-07-01 00:12:50.115664
Epoch:[ 48 4 ] loss: 0.43957093358039856 2022-07-01 00:12:50.538250
Epoch:[ 48 5 ] loss: 0.4412098228931427 2022-07-01 00:12:50.957859
Epoch:[ 48 6 ] loss: 0.43935707211494446 2022-07-01 00:12:51.380450
Epoch:[ 48 7 ] loss: 0.4425967037677765 2022-07-01 00:12:51.800692
Epoch:[ 48 8 ] loss: 0.4412594735622406 2022-07-01 00:12:52.214550
Epoch:[ 48 9 ] loss: 0.43899309635162354 2022-07-01 00:12:52.633707
Epoch:[ 48 10 ] loss: 0.43890953063964844 2022-07-01 00:12:53.056456
Epoch:[ 48 11 ] loss: 0.43974706530570984 2022-07-01 00:12:53.479162
Epoch:[ 48 12 ] loss: 0.4406454563140869 2022-07-01 00:12:53.900568
Epoch:[ 48 13 ] loss: 0.44156935811042786 2022-07-01 00:12:54.320431
Epoch:[ 48 14 ] loss: 0.4403478801250458 2022-07-01 00:12:54.741374
Epoch:[ 48 15 ] loss: 0.4404357969760895 2022-07-01 00:12:55.160731
Epoch:[ 48 16 ] loss: 0.44140055775642395 2022-07-01 00:13:00.300060
Epoch:[ 48 17 ] loss: 0.44068169593811035 2022-07-01 00:13:00.720236
Epoch:[ 48 18 ] loss: 0.4379155933856964 2022-07-01 00:13:01.142189
Epoch:[ 48 19 ] loss: 0.44021299481391907 2022-07-01 00:13:01.564158
Training_Epoch:[ 48 ] Training_loss: 0.4405850052833557 2022-07-01 00:13:01.564820
learning rate:  0.02048000000000001
netparams have been saved once 48
val: 1 0.44746842980384827
val: 2 0.457004189491272
val: 3 0.4468737244606018
val: 4 0.4414556920528412
val: 5 0.4441303610801697
val: 6 0.4534982740879059
val: 7 0.4502483904361725
val: 8 0.45554113388061523
val: 9 0.44443124532699585
val: 10 0.4485197365283966
val: 11 0.45200932025909424
val: 12 0.44665050506591797
val: 13 0.46184858679771423
val: 14 0.4417703449726105
val: 15 0.4412273168563843
val: 16 0.4604282081127167
val: 17 0.44830867648124695
val: 18 0.4407415986061096
val: 19 0.4387924373149872
val: 20 0.4472788870334625
val_Epoch:[ 48 ] val_loss: 0.44841135293245316 2022-07-01 00:13:05.341426
start training 2022-07-01 00:13:05.440393
Epoch:[ 49 0 ] loss: 0.4386328458786011 2022-07-01 00:13:20.276274
Epoch:[ 49 1 ] loss: 0.442864328622818 2022-07-01 00:13:20.695916
Epoch:[ 49 2 ] loss: 0.4414398968219757 2022-07-01 00:13:21.114439
Epoch:[ 49 3 ] loss: 0.43726810812950134 2022-07-01 00:13:21.533845
Epoch:[ 49 4 ] loss: 0.43877488374710083 2022-07-01 00:13:21.953558
Epoch:[ 49 5 ] loss: 0.43901628255844116 2022-07-01 00:13:22.365070
Epoch:[ 49 6 ] loss: 0.43629881739616394 2022-07-01 00:13:22.774353
Epoch:[ 49 7 ] loss: 0.44083142280578613 2022-07-01 00:13:23.189901
Epoch:[ 49 8 ] loss: 0.44334983825683594 2022-07-01 00:13:23.598804
Epoch:[ 49 9 ] loss: 0.4412437975406647 2022-07-01 00:13:24.006199
Epoch:[ 49 10 ] loss: 0.4462685286998749 2022-07-01 00:13:24.413126
Epoch:[ 49 11 ] loss: 0.44207531213760376 2022-07-01 00:13:24.822146
Epoch:[ 49 12 ] loss: 0.4413132965564728 2022-07-01 00:13:25.232282
Epoch:[ 49 13 ] loss: 0.4435725808143616 2022-07-01 00:13:25.646448
Epoch:[ 49 14 ] loss: 0.4437618553638458 2022-07-01 00:13:26.056550
Epoch:[ 49 15 ] loss: 0.4406444728374481 2022-07-01 00:13:26.470274
Epoch:[ 49 16 ] loss: 0.44757819175720215 2022-07-01 00:13:31.774832
Epoch:[ 49 17 ] loss: 0.4418899714946747 2022-07-01 00:13:32.181851
Epoch:[ 49 18 ] loss: 0.4438948929309845 2022-07-01 00:13:32.602030
Epoch:[ 49 19 ] loss: 0.4411170184612274 2022-07-01 00:13:33.012162
Training_Epoch:[ 49 ] Training_loss: 0.4415918171405792 2022-07-01 00:13:33.012888
learning rate:  0.02048000000000001
val: 1 0.4500942826271057
val: 2 0.46504127979278564
val: 3 0.44730260968208313
val: 4 0.45390576124191284
val: 5 0.45451611280441284
val: 6 0.4495871961116791
val: 7 0.45722243189811707
val: 8 0.4401078522205353
val: 9 0.446928471326828
val: 10 0.45000389218330383
val: 11 0.45674633979797363
val: 12 0.4486568868160248
val: 13 0.44982045888900757
val: 14 0.44745299220085144
val: 15 0.4490613639354706
val: 16 0.4616960287094116
val: 17 0.4535079002380371
val: 18 0.4468458592891693
val: 19 0.4583790898323059
val: 20 0.4474732279777527
val_Epoch:[ 49 ] val_loss: 0.4517175018787384 2022-07-01 00:13:36.744980
start training 2022-07-01 00:13:36.843169
Epoch:[ 50 0 ] loss: 0.4399144947528839 2022-07-01 00:13:51.005689
Epoch:[ 50 1 ] loss: 0.442438006401062 2022-07-01 00:13:51.701001
Epoch:[ 50 2 ] loss: 0.4411005973815918 2022-07-01 00:13:52.121138
Epoch:[ 50 3 ] loss: 0.44281911849975586 2022-07-01 00:13:52.541018
Epoch:[ 50 4 ] loss: 0.44095051288604736 2022-07-01 00:13:52.960139
Epoch:[ 50 5 ] loss: 0.44236913323402405 2022-07-01 00:13:53.382386
Epoch:[ 50 6 ] loss: 0.4423658847808838 2022-07-01 00:13:53.804778
Epoch:[ 50 7 ] loss: 0.44336143136024475 2022-07-01 00:13:54.225644
Epoch:[ 50 8 ] loss: 0.4412296414375305 2022-07-01 00:13:54.645034
Epoch:[ 50 9 ] loss: 0.44695213437080383 2022-07-01 00:13:55.065241
Epoch:[ 50 10 ] loss: 0.442120224237442 2022-07-01 00:13:55.484550
Epoch:[ 50 11 ] loss: 0.4404093027114868 2022-07-01 00:13:55.905261
Epoch:[ 50 12 ] loss: 0.4424239993095398 2022-07-01 00:13:56.316582
Epoch:[ 50 13 ] loss: 0.4439340829849243 2022-07-01 00:13:56.726234
Epoch:[ 50 14 ] loss: 0.4394448697566986 2022-07-01 00:13:57.137256
Epoch:[ 50 15 ] loss: 0.4406539499759674 2022-07-01 00:13:57.546936
Epoch:[ 50 16 ] loss: 0.44297054409980774 2022-07-01 00:14:02.716916
Epoch:[ 50 17 ] loss: 0.440320760011673 2022-07-01 00:14:03.125916
Epoch:[ 50 18 ] loss: 0.4440477192401886 2022-07-01 00:14:03.544051
Epoch:[ 50 19 ] loss: 0.4394373595714569 2022-07-01 00:14:03.953013
Training_Epoch:[ 50 ] Training_loss: 0.44196318835020065 2022-07-01 00:14:03.953897
learning rate:  0.02048000000000001
netparams have been saved once 50
val: 1 0.44153714179992676
val: 2 0.45559942722320557
val: 3 0.4496747851371765
val: 4 0.45265382528305054
val: 5 0.44987383484840393
val: 6 0.4512151777744293
val: 7 0.44952628016471863
val: 8 0.4537460207939148
val: 9 0.45047450065612793
val: 10 0.44172704219818115
val: 11 0.44774243235588074
val: 12 0.4536263644695282
val: 13 0.45062828063964844
val: 14 0.44765740633010864
val: 15 0.44423508644104004
val: 16 0.4477466344833374
val: 17 0.44902631640434265
val: 18 0.45151856541633606
val: 19 0.44575783610343933
val: 20 0.4509749412536621
val_Epoch:[ 50 ] val_loss: 0.4492470949888229 2022-07-01 00:14:07.836833
start training 2022-07-01 00:14:07.935717
Epoch:[ 51 0 ] loss: 0.43920227885246277 2022-07-01 00:14:22.570191
Epoch:[ 51 1 ] loss: 0.43972715735435486 2022-07-01 00:14:22.991944
Epoch:[ 51 2 ] loss: 0.43940019607543945 2022-07-01 00:14:23.412484
Epoch:[ 51 3 ] loss: 0.4436061978340149 2022-07-01 00:14:23.832702
Epoch:[ 51 4 ] loss: 0.44001713395118713 2022-07-01 00:14:24.252786
Epoch:[ 51 5 ] loss: 0.440060019493103 2022-07-01 00:14:24.672045
Epoch:[ 51 6 ] loss: 0.4401059150695801 2022-07-01 00:14:25.093068
Epoch:[ 51 7 ] loss: 0.4418404996395111 2022-07-01 00:14:25.515059
Epoch:[ 51 8 ] loss: 0.43710580468177795 2022-07-01 00:14:25.929701
Epoch:[ 51 9 ] loss: 0.4397863447666168 2022-07-01 00:14:26.349316
Epoch:[ 51 10 ] loss: 0.43495550751686096 2022-07-01 00:14:26.770598
Epoch:[ 51 11 ] loss: 0.43909135460853577 2022-07-01 00:14:27.190754
Epoch:[ 51 12 ] loss: 0.4381926953792572 2022-07-01 00:14:27.603791
Epoch:[ 51 13 ] loss: 0.4396703243255615 2022-07-01 00:14:28.024868
Epoch:[ 51 14 ] loss: 0.43957775831222534 2022-07-01 00:14:28.445629
Epoch:[ 51 15 ] loss: 0.43567031621932983 2022-07-01 00:14:28.866662
Epoch:[ 51 16 ] loss: 0.4370471239089966 2022-07-01 00:14:33.788268
Epoch:[ 51 17 ] loss: 0.43519291281700134 2022-07-01 00:14:34.208761
Epoch:[ 51 18 ] loss: 0.435302197933197 2022-07-01 00:14:34.634067
Epoch:[ 51 19 ] loss: 0.4360378086566925 2022-07-01 00:14:35.053359
Training_Epoch:[ 51 ] Training_loss: 0.4385794773697853 2022-07-01 00:14:35.054014
learning rate:  0.016384000000000006
val: 1 0.4526662528514862
val: 2 0.4509192705154419
val: 3 0.46321558952331543
val: 4 0.4621160626411438
val: 5 0.45292872190475464
val: 6 0.4579510986804962
val: 7 0.4584081768989563
val: 8 0.44937801361083984
val: 9 0.4684440493583679
val: 10 0.45328497886657715
val: 11 0.4527938663959503
val: 12 0.45530951023101807
val: 13 0.44607728719711304
val: 14 0.45767268538475037
val: 15 0.46555471420288086
val: 16 0.45687881112098694
val: 17 0.46652424335479736
val: 18 0.464927077293396
val: 19 0.4617471694946289
val: 20 0.4518333077430725
val_Epoch:[ 51 ] val_loss: 0.4574315443634987 2022-07-01 00:14:38.804365
start training 2022-07-01 00:14:38.904885
Epoch:[ 52 0 ] loss: 0.43722274899482727 2022-07-01 00:14:53.649734
Epoch:[ 52 1 ] loss: 0.43694597482681274 2022-07-01 00:14:54.065591
Epoch:[ 52 2 ] loss: 0.4389338791370392 2022-07-01 00:14:54.486584
Epoch:[ 52 3 ] loss: 0.4354124367237091 2022-07-01 00:14:54.909391
Epoch:[ 52 4 ] loss: 0.43579989671707153 2022-07-01 00:14:55.329487
Epoch:[ 52 5 ] loss: 0.43694007396698 2022-07-01 00:14:55.749026
Epoch:[ 52 6 ] loss: 0.4344366192817688 2022-07-01 00:14:56.171230
Epoch:[ 52 7 ] loss: 0.4390978217124939 2022-07-01 00:14:56.592144
Epoch:[ 52 8 ] loss: 0.4392585754394531 2022-07-01 00:14:57.012840
Epoch:[ 52 9 ] loss: 0.43647122383117676 2022-07-01 00:14:57.431795
Epoch:[ 52 10 ] loss: 0.4365289509296417 2022-07-01 00:14:57.853108
Epoch:[ 52 11 ] loss: 0.4404311180114746 2022-07-01 00:14:58.271898
Epoch:[ 52 12 ] loss: 0.4419514536857605 2022-07-01 00:14:58.693243
Epoch:[ 52 13 ] loss: 0.43494442105293274 2022-07-01 00:14:59.111104
Epoch:[ 52 14 ] loss: 0.4377276599407196 2022-07-01 00:14:59.532535
Epoch:[ 52 15 ] loss: 0.4349866211414337 2022-07-01 00:14:59.946857
Epoch:[ 52 16 ] loss: 0.43861865997314453 2022-07-01 00:15:05.341845
Epoch:[ 52 17 ] loss: 0.4363662302494049 2022-07-01 00:15:05.758976
Epoch:[ 52 18 ] loss: 0.4350587725639343 2022-07-01 00:15:06.179457
Epoch:[ 52 19 ] loss: 0.4343911409378052 2022-07-01 00:15:06.598658
Training_Epoch:[ 52 ] Training_loss: 0.4370762139558792 2022-07-01 00:15:06.599327
learning rate:  0.016384000000000006
netparams have been saved once 52
val: 1 0.4513148367404938
val: 2 0.45321765542030334
val: 3 0.44929561018943787
val: 4 0.44253847002983093
val: 5 0.44649019837379456
val: 6 0.4373997151851654
val: 7 0.43730318546295166
val: 8 0.4463520050048828
val: 9 0.4494103491306305
val: 10 0.44946497678756714
val: 11 0.4533502161502838
val: 12 0.43985870480537415
val: 13 0.4469594657421112
val: 14 0.45292630791664124
val: 15 0.44547730684280396
val: 16 0.45398420095443726
val: 17 0.4454967975616455
val: 18 0.4437502324581146
val: 19 0.4456104040145874
val: 20 0.445179283618927
val_Epoch:[ 52 ] val_loss: 0.4467689961194992 2022-07-01 00:15:10.454161
start training 2022-07-01 00:15:10.551529
Epoch:[ 53 0 ] loss: 0.4355562627315521 2022-07-01 00:15:24.895433
Epoch:[ 53 1 ] loss: 0.4385516345500946 2022-07-01 00:15:25.323893
Epoch:[ 53 2 ] loss: 0.4327140748500824 2022-07-01 00:15:25.745476
Epoch:[ 53 3 ] loss: 0.437124639749527 2022-07-01 00:15:26.164444
Epoch:[ 53 4 ] loss: 0.43486759066581726 2022-07-01 00:15:26.584303
Epoch:[ 53 5 ] loss: 0.43454036116600037 2022-07-01 00:15:27.003456
Epoch:[ 53 6 ] loss: 0.43331223726272583 2022-07-01 00:15:27.423073
Epoch:[ 53 7 ] loss: 0.43811869621276855 2022-07-01 00:15:27.837179
Epoch:[ 53 8 ] loss: 0.43666258454322815 2022-07-01 00:15:28.257950
Epoch:[ 53 9 ] loss: 0.4355839490890503 2022-07-01 00:15:28.673114
Epoch:[ 53 10 ] loss: 0.4372663199901581 2022-07-01 00:15:29.093168
Epoch:[ 53 11 ] loss: 0.43910276889801025 2022-07-01 00:15:29.511869
Epoch:[ 53 12 ] loss: 0.4403477907180786 2022-07-01 00:15:29.931159
Epoch:[ 53 13 ] loss: 0.4347284436225891 2022-07-01 00:15:30.350103
Epoch:[ 53 14 ] loss: 0.43457821011543274 2022-07-01 00:15:30.769477
Epoch:[ 53 15 ] loss: 0.43512848019599915 2022-07-01 00:15:31.191389
Epoch:[ 53 16 ] loss: 0.4315769672393799 2022-07-01 00:15:36.933902
Epoch:[ 53 17 ] loss: 0.438117116689682 2022-07-01 00:15:37.351504
Epoch:[ 53 18 ] loss: 0.4398258626461029 2022-07-01 00:15:37.773717
Epoch:[ 53 19 ] loss: 0.4379812479019165 2022-07-01 00:15:38.193064
Training_Epoch:[ 53 ] Training_loss: 0.4362842619419098 2022-07-01 00:15:38.193756
learning rate:  0.016384000000000006
val: 1 0.4382181465625763
val: 2 0.4492638111114502
val: 3 0.4479605555534363
val: 4 0.44903096556663513
val: 5 0.43872687220573425
val: 6 0.4387827217578888
val: 7 0.44742992520332336
val: 8 0.43897557258605957
val: 9 0.4382016956806183
val: 10 0.44989073276519775
val: 11 0.44241559505462646
val: 12 0.4546000361442566
val: 13 0.4373423159122467
val: 14 0.45066773891448975
val: 15 0.4468815326690674
val: 16 0.4438531696796417
val: 17 0.45134857296943665
val: 18 0.4432486891746521
val: 19 0.448678195476532
val: 20 0.46212038397789
val_Epoch:[ 53 ] val_loss: 0.44588186144828795 2022-07-01 00:15:41.936204
start training 2022-07-01 00:15:42.033670
Epoch:[ 54 0 ] loss: 0.4345668852329254 2022-07-01 00:15:56.249745
Epoch:[ 54 1 ] loss: 0.4372537434101105 2022-07-01 00:15:56.922604
Epoch:[ 54 2 ] loss: 0.43508195877075195 2022-07-01 00:15:57.345162
Epoch:[ 54 3 ] loss: 0.43320199847221375 2022-07-01 00:15:57.768108
Epoch:[ 54 4 ] loss: 0.43556100130081177 2022-07-01 00:15:58.189736
Epoch:[ 54 5 ] loss: 0.4397023320198059 2022-07-01 00:15:58.609725
Epoch:[ 54 6 ] loss: 0.43882468342781067 2022-07-01 00:15:59.030291
Epoch:[ 54 7 ] loss: 0.4361456632614136 2022-07-01 00:15:59.450731
Epoch:[ 54 8 ] loss: 0.43986666202545166 2022-07-01 00:15:59.869537
Epoch:[ 54 9 ] loss: 0.4378439784049988 2022-07-01 00:16:00.293375
Epoch:[ 54 10 ] loss: 0.4384421110153198 2022-07-01 00:16:00.709731
Epoch:[ 54 11 ] loss: 0.43750154972076416 2022-07-01 00:16:01.130605
Epoch:[ 54 12 ] loss: 0.43443167209625244 2022-07-01 00:16:01.553387
Epoch:[ 54 13 ] loss: 0.43724629282951355 2022-07-01 00:16:01.973634
Epoch:[ 54 14 ] loss: 0.4409339129924774 2022-07-01 00:16:02.394568
Epoch:[ 54 15 ] loss: 0.4369300603866577 2022-07-01 00:16:02.817823
Epoch:[ 54 16 ] loss: 0.4379348158836365 2022-07-01 00:16:07.846166
Epoch:[ 54 17 ] loss: 0.43434780836105347 2022-07-01 00:16:08.488564
Epoch:[ 54 18 ] loss: 0.43683987855911255 2022-07-01 00:16:08.908586
Epoch:[ 54 19 ] loss: 0.43786314129829407 2022-07-01 00:16:09.328677
Training_Epoch:[ 54 ] Training_loss: 0.43702600747346876 2022-07-01 00:16:09.329361
learning rate:  0.016384000000000006
netparams have been saved once 54
val: 1 0.4542262554168701
val: 2 0.4348568022251129
val: 3 0.4374196529388428
val: 4 0.4389791488647461
val: 5 0.4414442181587219
val: 6 0.44282689690589905
val: 7 0.4436433017253876
val: 8 0.45364874601364136
val: 9 0.4492538571357727
val: 10 0.43147554993629456
val: 11 0.4473808705806732
val: 12 0.44332054257392883
val: 13 0.4494818150997162
val: 14 0.4385918378829956
val: 15 0.4376039206981659
val: 16 0.43733498454093933
val: 17 0.4362514913082123
val: 18 0.4360488951206207
val: 19 0.4382580518722534
val: 20 0.4434233605861664
val_Epoch:[ 54 ] val_loss: 0.441773509979248 2022-07-01 00:16:13.230251
start training 2022-07-01 00:16:13.330359
Epoch:[ 55 0 ] loss: 0.43591931462287903 2022-07-01 00:16:27.326588
Epoch:[ 55 1 ] loss: 0.4391024112701416 2022-07-01 00:16:27.776365
Epoch:[ 55 2 ] loss: 0.4350179433822632 2022-07-01 00:16:28.222422
Epoch:[ 55 3 ] loss: 0.4332372546195984 2022-07-01 00:16:28.645191
Epoch:[ 55 4 ] loss: 0.4319668412208557 2022-07-01 00:16:29.067946
Epoch:[ 55 5 ] loss: 0.4363311529159546 2022-07-01 00:16:29.488849
Epoch:[ 55 6 ] loss: 0.43673673272132874 2022-07-01 00:16:29.909958
Epoch:[ 55 7 ] loss: 0.4325186610221863 2022-07-01 00:16:30.330541
Epoch:[ 55 8 ] loss: 0.4317537546157837 2022-07-01 00:16:30.750087
Epoch:[ 55 9 ] loss: 0.43652740120887756 2022-07-01 00:16:31.171871
Epoch:[ 55 10 ] loss: 0.43397271633148193 2022-07-01 00:16:31.594352
Epoch:[ 55 11 ] loss: 0.4352347254753113 2022-07-01 00:16:32.017600
Epoch:[ 55 12 ] loss: 0.43477144837379456 2022-07-01 00:16:32.440824
Epoch:[ 55 13 ] loss: 0.43679070472717285 2022-07-01 00:16:32.861539
Epoch:[ 55 14 ] loss: 0.4347527027130127 2022-07-01 00:16:33.282781
Epoch:[ 55 15 ] loss: 0.4338306188583374 2022-07-01 00:16:33.702303
Epoch:[ 55 16 ] loss: 0.4358839988708496 2022-07-01 00:16:38.973528
Epoch:[ 55 17 ] loss: 0.432913601398468 2022-07-01 00:16:39.634291
Epoch:[ 55 18 ] loss: 0.4340350925922394 2022-07-01 00:16:40.056889
Epoch:[ 55 19 ] loss: 0.4363553822040558 2022-07-01 00:16:40.478033
Training_Epoch:[ 55 ] Training_loss: 0.4348826229572296 2022-07-01 00:16:40.478681
learning rate:  0.016384000000000006
val: 1 0.4408048689365387
val: 2 0.4405519962310791
val: 3 0.4321652948856354
val: 4 0.44460707902908325
val: 5 0.4438842833042145
val: 6 0.4492236375808716
val: 7 0.44134005904197693
val: 8 0.4406408667564392
val: 9 0.45359307527542114
val: 10 0.4413878917694092
val: 11 0.4490966498851776
val: 12 0.44229498505592346
val: 13 0.4385744035243988
val: 14 0.43406805396080017
val: 15 0.4352855980396271
val: 16 0.444927453994751
val: 17 0.4418693780899048
val: 18 0.43273791670799255
val: 19 0.4391278624534607
val: 20 0.4413132965564728
val_Epoch:[ 55 ] val_loss: 0.44137473255395887 2022-07-01 00:16:44.250030
start training 2022-07-01 00:16:44.348728
Epoch:[ 56 0 ] loss: 0.43203747272491455 2022-07-01 00:16:58.444850
Epoch:[ 56 1 ] loss: 0.4332346022129059 2022-07-01 00:16:59.303246
Epoch:[ 56 2 ] loss: 0.4307517111301422 2022-07-01 00:16:59.716913
Epoch:[ 56 3 ] loss: 0.4334925413131714 2022-07-01 00:17:00.135769
Epoch:[ 56 4 ] loss: 0.43530598282814026 2022-07-01 00:17:00.558997
Epoch:[ 56 5 ] loss: 0.43132489919662476 2022-07-01 00:17:00.980210
Epoch:[ 56 6 ] loss: 0.4346282482147217 2022-07-01 00:17:01.401207
Epoch:[ 56 7 ] loss: 0.42991188168525696 2022-07-01 00:17:01.820340
Epoch:[ 56 8 ] loss: 0.4336622953414917 2022-07-01 00:17:02.241017
Epoch:[ 56 9 ] loss: 0.4370309114456177 2022-07-01 00:17:02.659279
Epoch:[ 56 10 ] loss: 0.4388140141963959 2022-07-01 00:17:03.078487
Epoch:[ 56 11 ] loss: 0.4378138780593872 2022-07-01 00:17:03.500017
Epoch:[ 56 12 ] loss: 0.43372049927711487 2022-07-01 00:17:03.922218
Epoch:[ 56 13 ] loss: 0.4376051127910614 2022-07-01 00:17:04.342342
Epoch:[ 56 14 ] loss: 0.43646398186683655 2022-07-01 00:17:04.762279
Epoch:[ 56 15 ] loss: 0.4369468688964844 2022-07-01 00:17:05.183226
Epoch:[ 56 16 ] loss: 0.4376295804977417 2022-07-01 00:17:10.031007
Epoch:[ 56 17 ] loss: 0.43691712617874146 2022-07-01 00:17:10.703829
Epoch:[ 56 18 ] loss: 0.4399450421333313 2022-07-01 00:17:11.126471
Epoch:[ 56 19 ] loss: 0.43104639649391174 2022-07-01 00:17:11.547334
Training_Epoch:[ 56 ] Training_loss: 0.43491415232419967 2022-07-01 00:17:11.547972
learning rate:  0.016384000000000006
netparams have been saved once 56
val: 1 0.4631216824054718
val: 2 0.4473356604576111
val: 3 0.4510703384876251
val: 4 0.4413124918937683
val: 5 0.451926589012146
val: 6 0.4582100808620453
val: 7 0.45293760299682617
val: 8 0.45568180084228516
val: 9 0.44722428917884827
val: 10 0.452802449464798
val: 11 0.45480337738990784
val: 12 0.45941421389579773
val: 13 0.4470943808555603
val: 14 0.45164525508880615
val: 15 0.45737677812576294
val: 16 0.4563748836517334
val: 17 0.441480427980423
val: 18 0.4441641867160797
val: 19 0.4566192328929901
val: 20 0.4525901973247528
val_Epoch:[ 56 ] val_loss: 0.45215929597616195 2022-07-01 00:17:15.423982
start training 2022-07-01 00:17:15.523018
Epoch:[ 57 0 ] loss: 0.4362284243106842 2022-07-01 00:17:29.859010
Epoch:[ 57 1 ] loss: 0.4334116280078888 2022-07-01 00:17:30.287976
Epoch:[ 57 2 ] loss: 0.4334528148174286 2022-07-01 00:17:30.708777
Epoch:[ 57 3 ] loss: 0.4320888817310333 2022-07-01 00:17:31.127765
Epoch:[ 57 4 ] loss: 0.4326231777667999 2022-07-01 00:17:31.543431
Epoch:[ 57 5 ] loss: 0.4357542097568512 2022-07-01 00:17:31.968344
Epoch:[ 57 6 ] loss: 0.4316839873790741 2022-07-01 00:17:32.390475
Epoch:[ 57 7 ] loss: 0.4345396161079407 2022-07-01 00:17:32.816698
Epoch:[ 57 8 ] loss: 0.43418559432029724 2022-07-01 00:17:33.237337
Epoch:[ 57 9 ] loss: 0.43394696712493896 2022-07-01 00:17:33.658700
Epoch:[ 57 10 ] loss: 0.43860527873039246 2022-07-01 00:17:34.082035
Epoch:[ 57 11 ] loss: 0.43500545620918274 2022-07-01 00:17:34.502087
Epoch:[ 57 12 ] loss: 0.4346961975097656 2022-07-01 00:17:34.923455
Epoch:[ 57 13 ] loss: 0.43776804208755493 2022-07-01 00:17:35.347033
Epoch:[ 57 14 ] loss: 0.4344096779823303 2022-07-01 00:17:35.770973
Epoch:[ 57 15 ] loss: 0.437081903219223 2022-07-01 00:17:36.192628
Epoch:[ 57 16 ] loss: 0.4351758360862732 2022-07-01 00:17:41.486496
Epoch:[ 57 17 ] loss: 0.43607327342033386 2022-07-01 00:17:41.906132
Epoch:[ 57 18 ] loss: 0.43107569217681885 2022-07-01 00:17:42.326267
Epoch:[ 57 19 ] loss: 0.43404117226600647 2022-07-01 00:17:42.750542
Training_Epoch:[ 57 ] Training_loss: 0.4345923915505409 2022-07-01 00:17:42.751300
learning rate:  0.016384000000000006
val: 1 0.45604828000068665
val: 2 0.4460500478744507
val: 3 0.4433741271495819
val: 4 0.4639812409877777
val: 5 0.4415823817253113
val: 6 0.45050209760665894
val: 7 0.4516037106513977
val: 8 0.4539463520050049
val: 9 0.4585745334625244
val: 10 0.4373624920845032
val: 11 0.4627217948436737
val: 12 0.4452829360961914
val: 13 0.45378056168556213
val: 14 0.45238062739372253
val: 15 0.45251402258872986
val: 16 0.453041136264801
val: 17 0.44288766384124756
val: 18 0.4369606375694275
val: 19 0.4514143168926239
val: 20 0.446399450302124
val_Epoch:[ 57 ] val_loss: 0.45002042055130004 2022-07-01 00:17:46.509732
start training 2022-07-01 00:17:46.609029
Epoch:[ 58 0 ] loss: 0.434496134519577 2022-07-01 00:18:01.053533
Epoch:[ 58 1 ] loss: 0.43265438079833984 2022-07-01 00:18:01.500620
Epoch:[ 58 2 ] loss: 0.43453091382980347 2022-07-01 00:18:01.913931
Epoch:[ 58 3 ] loss: 0.4367733299732208 2022-07-01 00:18:02.336326
Epoch:[ 58 4 ] loss: 0.4367954134941101 2022-07-01 00:18:02.759213
Epoch:[ 58 5 ] loss: 0.4347398281097412 2022-07-01 00:18:03.177921
Epoch:[ 58 6 ] loss: 0.43362101912498474 2022-07-01 00:18:03.600407
Epoch:[ 58 7 ] loss: 0.4328513741493225 2022-07-01 00:18:04.021885
Epoch:[ 58 8 ] loss: 0.4322097599506378 2022-07-01 00:18:04.443681
Epoch:[ 58 9 ] loss: 0.43271002173423767 2022-07-01 00:18:04.864012
Epoch:[ 58 10 ] loss: 0.4362577795982361 2022-07-01 00:18:05.286269
Epoch:[ 58 11 ] loss: 0.43626168370246887 2022-07-01 00:18:05.709415
Epoch:[ 58 12 ] loss: 0.4338519275188446 2022-07-01 00:18:06.129032
Epoch:[ 58 13 ] loss: 0.433381050825119 2022-07-01 00:18:06.553493
Epoch:[ 58 14 ] loss: 0.4356684982776642 2022-07-01 00:18:06.975275
Epoch:[ 58 15 ] loss: 0.4317825436592102 2022-07-01 00:18:07.400116
Epoch:[ 58 16 ] loss: 0.43528103828430176 2022-07-01 00:18:12.701397
Epoch:[ 58 17 ] loss: 0.4338929355144501 2022-07-01 00:18:13.122851
Epoch:[ 58 18 ] loss: 0.43473362922668457 2022-07-01 00:18:13.997562
Epoch:[ 58 19 ] loss: 0.4305638372898102 2022-07-01 00:18:14.419023
Training_Epoch:[ 58 ] Training_loss: 0.4341528549790382 2022-07-01 00:18:14.419716
learning rate:  0.016384000000000006
netparams have been saved once 58
val: 1 0.43924105167388916
val: 2 0.44049665331840515
val: 3 0.4391421675682068
val: 4 0.44609931111335754
val: 5 0.4413009583950043
val: 6 0.44618019461631775
val: 7 0.4435131549835205
val: 8 0.44708383083343506
val: 9 0.4436459541320801
val: 10 0.42847299575805664
val: 11 0.4391229748725891
val: 12 0.4422517716884613
val: 13 0.42753568291664124
val: 14 0.4493751525878906
val: 15 0.43963009119033813
val: 16 0.4441398084163666
val: 17 0.4278566539287567
val: 18 0.43861427903175354
val: 19 0.4468185007572174
val: 20 0.4541751742362976
val_Epoch:[ 58 ] val_loss: 0.44123481810092924 2022-07-01 00:18:18.234698
start training 2022-07-01 00:18:18.335924
Epoch:[ 59 0 ] loss: 0.435665100812912 2022-07-01 00:18:32.877069
Epoch:[ 59 1 ] loss: 0.43259310722351074 2022-07-01 00:18:33.292471
Epoch:[ 59 2 ] loss: 0.4323759973049164 2022-07-01 00:18:33.712597
Epoch:[ 59 3 ] loss: 0.43496885895729065 2022-07-01 00:18:34.135329
Epoch:[ 59 4 ] loss: 0.4330226182937622 2022-07-01 00:18:34.558650
Epoch:[ 59 5 ] loss: 0.43244504928588867 2022-07-01 00:18:34.978798
Epoch:[ 59 6 ] loss: 0.4349460303783417 2022-07-01 00:18:35.401385
Epoch:[ 59 7 ] loss: 0.4327363073825836 2022-07-01 00:18:35.824724
Epoch:[ 59 8 ] loss: 0.4352109134197235 2022-07-01 00:18:36.250320
Epoch:[ 59 9 ] loss: 0.4327978491783142 2022-07-01 00:18:36.666870
Epoch:[ 59 10 ] loss: 0.4340594708919525 2022-07-01 00:18:37.090030
Epoch:[ 59 11 ] loss: 0.4326203465461731 2022-07-01 00:18:37.505664
Epoch:[ 59 12 ] loss: 0.43297144770622253 2022-07-01 00:18:37.928790
Epoch:[ 59 13 ] loss: 0.4325616657733917 2022-07-01 00:18:38.352571
Epoch:[ 59 14 ] loss: 0.43037641048431396 2022-07-01 00:18:38.776174
Epoch:[ 59 15 ] loss: 0.4324319660663605 2022-07-01 00:18:39.197591
Epoch:[ 59 16 ] loss: 0.43550363183021545 2022-07-01 00:18:44.807888
Epoch:[ 59 17 ] loss: 0.43107253313064575 2022-07-01 00:18:45.229382
Epoch:[ 59 18 ] loss: 0.43220770359039307 2022-07-01 00:18:45.654741
Epoch:[ 59 19 ] loss: 0.43139514327049255 2022-07-01 00:18:46.074359
Training_Epoch:[ 59 ] Training_loss: 0.43309810757637024 2022-07-01 00:18:46.075019
learning rate:  0.016384000000000006
val: 1 0.44651126861572266
val: 2 0.46526744961738586
val: 3 0.45229029655456543
val: 4 0.44942429661750793
val: 5 0.44218021631240845
val: 6 0.4313489496707916
val: 7 0.4399060606956482
val: 8 0.4542360305786133
val: 9 0.429736465215683
val: 10 0.43991732597351074
val: 11 0.4365788996219635
val: 12 0.4430442154407501
val: 13 0.4463982582092285
val: 14 0.4570614695549011
val: 15 0.4530610740184784
val: 16 0.4405295252799988
val: 17 0.4547690153121948
val: 18 0.44917821884155273
val: 19 0.4570137858390808
val: 20 0.4420035779476166
val_Epoch:[ 59 ] val_loss: 0.4465228199958801 2022-07-01 00:18:49.872111
start training 2022-07-01 00:18:49.973231
Epoch:[ 60 0 ] loss: 0.4305861294269562 2022-07-01 00:19:03.885305
Epoch:[ 60 1 ] loss: 0.4308498203754425 2022-07-01 00:19:04.310349
Epoch:[ 60 2 ] loss: 0.4307438135147095 2022-07-01 00:19:04.744969
Epoch:[ 60 3 ] loss: 0.43379321694374084 2022-07-01 00:19:05.167402
Epoch:[ 60 4 ] loss: 0.43103277683258057 2022-07-01 00:19:05.590439
Epoch:[ 60 5 ] loss: 0.42709967494010925 2022-07-01 00:19:06.009932
Epoch:[ 60 6 ] loss: 0.4380134344100952 2022-07-01 00:19:06.430745
Epoch:[ 60 7 ] loss: 0.4329167604446411 2022-07-01 00:19:06.850285
Epoch:[ 60 8 ] loss: 0.43187353014945984 2022-07-01 00:19:07.273290
Epoch:[ 60 9 ] loss: 0.4355211853981018 2022-07-01 00:19:07.695771
Epoch:[ 60 10 ] loss: 0.436846524477005 2022-07-01 00:19:08.116787
Epoch:[ 60 11 ] loss: 0.43728846311569214 2022-07-01 00:19:08.538681
Epoch:[ 60 12 ] loss: 0.42994803190231323 2022-07-01 00:19:08.959224
Epoch:[ 60 13 ] loss: 0.4390197694301605 2022-07-01 00:19:09.381490
Epoch:[ 60 14 ] loss: 0.43391019105911255 2022-07-01 00:19:09.801409
Epoch:[ 60 15 ] loss: 0.4365421533584595 2022-07-01 00:19:10.222666
Epoch:[ 60 16 ] loss: 0.43525195121765137 2022-07-01 00:19:16.077768
Epoch:[ 60 17 ] loss: 0.4368419051170349 2022-07-01 00:19:16.498153
Epoch:[ 60 18 ] loss: 0.4364199638366699 2022-07-01 00:19:16.918641
Epoch:[ 60 19 ] loss: 0.438911497592926 2022-07-01 00:19:17.339601
Training_Epoch:[ 60 ] Training_loss: 0.4341705396771431 2022-07-01 00:19:17.340236
learning rate:  0.016384000000000006
netparams have been saved once 60
val: 1 0.4450613558292389
val: 2 0.4513579308986664
val: 3 0.44427940249443054
val: 4 0.4574125409126282
val: 5 0.4397747814655304
val: 6 0.4496724605560303
val: 7 0.44989582896232605
val: 8 0.4388655126094818
val: 9 0.4512997269630432
val: 10 0.4534488618373871
val: 11 0.46331149339675903
val: 12 0.44576066732406616
val: 13 0.4517085552215576
val: 14 0.449913889169693
val: 15 0.4548012614250183
val: 16 0.4476703107357025
val: 17 0.45019441843032837
val: 18 0.4484209418296814
val: 19 0.4388810992240906
val: 20 0.44480982422828674
val_Epoch:[ 60 ] val_loss: 0.4488270431756973 2022-07-01 00:19:21.203198
start training 2022-07-01 00:19:21.303636
Epoch:[ 61 0 ] loss: 0.43262550234794617 2022-07-01 00:19:35.693461
Epoch:[ 61 1 ] loss: 0.4340941309928894 2022-07-01 00:19:36.113879
Epoch:[ 61 2 ] loss: 0.4291872978210449 2022-07-01 00:19:36.535521
Epoch:[ 61 3 ] loss: 0.43219178915023804 2022-07-01 00:19:36.958829
Epoch:[ 61 4 ] loss: 0.4343545436859131 2022-07-01 00:19:37.379281
Epoch:[ 61 5 ] loss: 0.4306284189224243 2022-07-01 00:19:37.801285
Epoch:[ 61 6 ] loss: 0.4327012300491333 2022-07-01 00:19:38.215547
Epoch:[ 61 7 ] loss: 0.4299573302268982 2022-07-01 00:19:38.636501
Epoch:[ 61 8 ] loss: 0.4358867406845093 2022-07-01 00:19:39.051008
Epoch:[ 61 9 ] loss: 0.43054908514022827 2022-07-01 00:19:39.472377
Epoch:[ 61 10 ] loss: 0.4356987178325653 2022-07-01 00:19:39.895160
Epoch:[ 61 11 ] loss: 0.4308427572250366 2022-07-01 00:19:40.315500
Epoch:[ 61 12 ] loss: 0.43261465430259705 2022-07-01 00:19:40.735639
Epoch:[ 61 13 ] loss: 0.4302467405796051 2022-07-01 00:19:41.156616
Epoch:[ 61 14 ] loss: 0.43363189697265625 2022-07-01 00:19:41.579967
Epoch:[ 61 15 ] loss: 0.43003585934638977 2022-07-01 00:19:41.999104
Epoch:[ 61 16 ] loss: 0.432675838470459 2022-07-01 00:19:47.680053
Epoch:[ 61 17 ] loss: 0.43157169222831726 2022-07-01 00:19:48.100363
Epoch:[ 61 18 ] loss: 0.437832236289978 2022-07-01 00:19:48.521590
Epoch:[ 61 19 ] loss: 0.4292559325695038 2022-07-01 00:19:48.939923
Training_Epoch:[ 61 ] Training_loss: 0.4323291197419167 2022-07-01 00:19:48.940593
learning rate:  0.013107200000000006
val: 1 0.4389231204986572
val: 2 0.4354986548423767
val: 3 0.4465106129646301
val: 4 0.43423619866371155
val: 5 0.44893980026245117
val: 6 0.43769964575767517
val: 7 0.42786601185798645
val: 8 0.4450216293334961
val: 9 0.43936648964881897
val: 10 0.4441321790218353
val: 11 0.4390042722225189
val: 12 0.4422120749950409
val: 13 0.45263639092445374
val: 14 0.4481721520423889
val: 15 0.45024609565734863
val: 16 0.43601804971694946
val: 17 0.44729068875312805
val: 18 0.4429098069667816
val: 19 0.43982985615730286
val: 20 0.43956971168518066
val_Epoch:[ 61 ] val_loss: 0.44180417209863665 2022-07-01 00:19:52.761417
start training 2022-07-01 00:19:52.870408
Epoch:[ 62 0 ] loss: 0.43271633982658386 2022-07-01 00:20:07.713240
Epoch:[ 62 1 ] loss: 0.42951980233192444 2022-07-01 00:20:08.132745
Epoch:[ 62 2 ] loss: 0.43237218260765076 2022-07-01 00:20:08.552356
Epoch:[ 62 3 ] loss: 0.43140751123428345 2022-07-01 00:20:08.974538
Epoch:[ 62 4 ] loss: 0.43157684803009033 2022-07-01 00:20:09.396110
Epoch:[ 62 5 ] loss: 0.4319884479045868 2022-07-01 00:20:09.815772
Epoch:[ 62 6 ] loss: 0.4303285479545593 2022-07-01 00:20:10.234723
Epoch:[ 62 7 ] loss: 0.4303792715072632 2022-07-01 00:20:10.649617
Epoch:[ 62 8 ] loss: 0.42920851707458496 2022-07-01 00:20:11.068964
Epoch:[ 62 9 ] loss: 0.42906567454338074 2022-07-01 00:20:11.490153
Epoch:[ 62 10 ] loss: 0.43175628781318665 2022-07-01 00:20:11.913431
Epoch:[ 62 11 ] loss: 0.4317219853401184 2022-07-01 00:20:12.335253
Epoch:[ 62 12 ] loss: 0.4293404221534729 2022-07-01 00:20:12.749889
Epoch:[ 62 13 ] loss: 0.43206292390823364 2022-07-01 00:20:13.168698
Epoch:[ 62 14 ] loss: 0.43034830689430237 2022-07-01 00:20:13.589132
Epoch:[ 62 15 ] loss: 0.4307762384414673 2022-07-01 00:20:14.009086
Epoch:[ 62 16 ] loss: 0.4302864670753479 2022-07-01 00:20:19.070846
Epoch:[ 62 17 ] loss: 0.4271559715270996 2022-07-01 00:20:19.491900
Epoch:[ 62 18 ] loss: 0.42817044258117676 2022-07-01 00:20:19.915306
Epoch:[ 62 19 ] loss: 0.42916339635849 2022-07-01 00:20:20.335975
Training_Epoch:[ 62 ] Training_loss: 0.4304672792553902 2022-07-01 00:20:20.336579
learning rate:  0.013107200000000006
netparams have been saved once 62
val: 1 0.44793298840522766
val: 2 0.44444459676742554
val: 3 0.45341530442237854
val: 4 0.4498477578163147
val: 5 0.4455689489841461
val: 6 0.45720982551574707
val: 7 0.4465429186820984
val: 8 0.453931599855423
val: 9 0.44811466336250305
val: 10 0.45680609345436096
val: 11 0.4419783055782318
val: 12 0.45023152232170105
val: 13 0.4440672993659973
val: 14 0.4549207389354706
val: 15 0.451878160238266
val: 16 0.44213953614234924
val: 17 0.44272440671920776
val: 18 0.4483831226825714
val: 19 0.4548005759716034
val: 20 0.45027026534080505
val_Epoch:[ 62 ] val_loss: 0.4492604315280914 2022-07-01 00:20:24.091117
start training 2022-07-01 00:20:24.191391
Epoch:[ 63 0 ] loss: 0.4353255033493042 2022-07-01 00:20:38.674518
Epoch:[ 63 1 ] loss: 0.4262906312942505 2022-07-01 00:20:39.094975
Epoch:[ 63 2 ] loss: 0.4303368330001831 2022-07-01 00:20:39.514712
Epoch:[ 63 3 ] loss: 0.43162307143211365 2022-07-01 00:20:39.933798
Epoch:[ 63 4 ] loss: 0.4283714294433594 2022-07-01 00:20:40.355155
Epoch:[ 63 5 ] loss: 0.4328802227973938 2022-07-01 00:20:40.776559
Epoch:[ 63 6 ] loss: 0.43188756704330444 2022-07-01 00:20:41.197086
Epoch:[ 63 7 ] loss: 0.4281638264656067 2022-07-01 00:20:41.616843
Epoch:[ 63 8 ] loss: 0.42997226119041443 2022-07-01 00:20:42.036053
Epoch:[ 63 9 ] loss: 0.42927470803260803 2022-07-01 00:20:42.448877
Epoch:[ 63 10 ] loss: 0.43091902136802673 2022-07-01 00:20:42.868250
Epoch:[ 63 11 ] loss: 0.4332989454269409 2022-07-01 00:20:43.283764
Epoch:[ 63 12 ] loss: 0.4299546182155609 2022-07-01 00:20:43.704922
Epoch:[ 63 13 ] loss: 0.42754170298576355 2022-07-01 00:20:44.127805
Epoch:[ 63 14 ] loss: 0.42971304059028625 2022-07-01 00:20:44.547936
Epoch:[ 63 15 ] loss: 0.4260770380496979 2022-07-01 00:20:44.967929
Epoch:[ 63 16 ] loss: 0.4345948100090027 2022-07-01 00:20:50.425707
Epoch:[ 63 17 ] loss: 0.4285750091075897 2022-07-01 00:20:50.843903
Epoch:[ 63 18 ] loss: 0.42842021584510803 2022-07-01 00:20:51.267087
Epoch:[ 63 19 ] loss: 0.4320882558822632 2022-07-01 00:20:51.689647
Training_Epoch:[ 63 ] Training_loss: 0.4302654355764389 2022-07-01 00:20:51.690406
learning rate:  0.013107200000000006
val: 1 0.4494793713092804
val: 2 0.43526723980903625
val: 3 0.43742823600769043
val: 4 0.43663290143013
val: 5 0.43775445222854614
val: 6 0.44217684864997864
val: 7 0.4434286952018738
val: 8 0.43772366642951965
val: 9 0.4414360225200653
val: 10 0.4385683536529541
val: 11 0.4363432824611664
val: 12 0.4324370324611664
val: 13 0.43573006987571716
val: 14 0.4362921118736267
val: 15 0.44602179527282715
val: 16 0.43999528884887695
val: 17 0.4372100234031677
val: 18 0.4374247193336487
val: 19 0.431163489818573
val: 20 0.4510095715522766
val_Epoch:[ 63 ] val_loss: 0.4391761586070061 2022-07-01 00:20:55.449810
start training 2022-07-01 00:20:55.550471
Epoch:[ 64 0 ] loss: 0.4273732304573059 2022-07-01 00:21:09.706055
Epoch:[ 64 1 ] loss: 0.42637255787849426 2022-07-01 00:21:10.130930
Epoch:[ 64 2 ] loss: 0.4304933249950409 2022-07-01 00:21:10.551334
Epoch:[ 64 3 ] loss: 0.4259811043739319 2022-07-01 00:21:10.970996
Epoch:[ 64 4 ] loss: 0.431854248046875 2022-07-01 00:21:11.391135
Epoch:[ 64 5 ] loss: 0.42768430709838867 2022-07-01 00:21:11.814139
Epoch:[ 64 6 ] loss: 0.43203896284103394 2022-07-01 00:21:12.235255
Epoch:[ 64 7 ] loss: 0.4286080598831177 2022-07-01 00:21:12.656773
Epoch:[ 64 8 ] loss: 0.4285575747489929 2022-07-01 00:21:13.064833
Epoch:[ 64 9 ] loss: 0.4292038083076477 2022-07-01 00:21:13.472436
Epoch:[ 64 10 ] loss: 0.4306332767009735 2022-07-01 00:21:13.879580
Epoch:[ 64 11 ] loss: 0.430904746055603 2022-07-01 00:21:14.286879
Epoch:[ 64 12 ] loss: 0.4272042214870453 2022-07-01 00:21:14.697634
Epoch:[ 64 13 ] loss: 0.4272879660129547 2022-07-01 00:21:15.109647
Epoch:[ 64 14 ] loss: 0.4284251928329468 2022-07-01 00:21:15.519641
Epoch:[ 64 15 ] loss: 0.4305638372898102 2022-07-01 00:21:15.928564
Epoch:[ 64 16 ] loss: 0.4262262284755707 2022-07-01 00:21:21.646719
Epoch:[ 64 17 ] loss: 0.4327485263347626 2022-07-01 00:21:22.057459
Epoch:[ 64 18 ] loss: 0.4322056472301483 2022-07-01 00:21:22.467297
Epoch:[ 64 19 ] loss: 0.43134579062461853 2022-07-01 00:21:22.876859
Training_Epoch:[ 64 ] Training_loss: 0.4292856305837631 2022-07-01 00:21:22.877704
learning rate:  0.013107200000000006
netparams have been saved once 64
val: 1 0.4397966265678406
val: 2 0.44984304904937744
val: 3 0.442497193813324
val: 4 0.44398772716522217
val: 5 0.4357028305530548
val: 6 0.43626299500465393
val: 7 0.44419366121292114
val: 8 0.4293536841869354
val: 9 0.4486137628555298
val: 10 0.4470115303993225
val: 11 0.4457099437713623
val: 12 0.4322254955768585
val: 13 0.4603758156299591
val: 14 0.44832712411880493
val: 15 0.4286293387413025
val: 16 0.43601304292678833
val: 17 0.4463529884815216
val: 18 0.4362684190273285
val: 19 0.43209749460220337
val: 20 0.43356823921203613
val_Epoch:[ 64 ] val_loss: 0.44084154814481735 2022-07-01 00:21:26.767130
start training 2022-07-01 00:21:26.871996
Epoch:[ 65 0 ] loss: 0.4281623065471649 2022-07-01 00:21:40.651661
Epoch:[ 65 1 ] loss: 0.42776477336883545 2022-07-01 00:21:41.095302
Epoch:[ 65 2 ] loss: 0.42903584241867065 2022-07-01 00:21:41.516241
Epoch:[ 65 3 ] loss: 0.42655888199806213 2022-07-01 00:21:41.937600
Epoch:[ 65 4 ] loss: 0.4287952184677124 2022-07-01 00:21:42.358763
Epoch:[ 65 5 ] loss: 0.4278174638748169 2022-07-01 00:21:42.777771
Epoch:[ 65 6 ] loss: 0.4277868866920471 2022-07-01 00:21:43.200183
Epoch:[ 65 7 ] loss: 0.43183061480522156 2022-07-01 00:21:43.624246
Epoch:[ 65 8 ] loss: 0.4311295747756958 2022-07-01 00:21:44.045374
Epoch:[ 65 9 ] loss: 0.42768532037734985 2022-07-01 00:21:44.467810
Epoch:[ 65 10 ] loss: 0.43113842606544495 2022-07-01 00:21:44.889161
Epoch:[ 65 11 ] loss: 0.4291057586669922 2022-07-01 00:21:45.309700
Epoch:[ 65 12 ] loss: 0.43515053391456604 2022-07-01 00:21:45.734366
Epoch:[ 65 13 ] loss: 0.4296967387199402 2022-07-01 00:21:46.155649
Epoch:[ 65 14 ] loss: 0.42711183428764343 2022-07-01 00:21:46.578470
Epoch:[ 65 15 ] loss: 0.42628633975982666 2022-07-01 00:21:47.002474
Epoch:[ 65 16 ] loss: 0.4264538586139679 2022-07-01 00:21:52.568295
Epoch:[ 65 17 ] loss: 0.4268747568130493 2022-07-01 00:21:52.987415
Epoch:[ 65 18 ] loss: 0.4302493929862976 2022-07-01 00:21:53.408248
Epoch:[ 65 19 ] loss: 0.42786329984664917 2022-07-01 00:21:53.828300
Training_Epoch:[ 65 ] Training_loss: 0.4288248911499977 2022-07-01 00:21:53.829026
learning rate:  0.013107200000000006
val: 1 0.43176209926605225
val: 2 0.4385630786418915
val: 3 0.43124908208847046
val: 4 0.4333949089050293
val: 5 0.43878602981567383
val: 6 0.4450817108154297
val: 7 0.42979955673217773
val: 8 0.4400157332420349
val: 9 0.4334318935871124
val: 10 0.43455198407173157
val: 11 0.45292750000953674
val: 12 0.4489315152168274
val: 13 0.4361684322357178
val: 14 0.44488009810447693
val: 15 0.436184287071228
val: 16 0.43840333819389343
val: 17 0.43340393900871277
val: 18 0.4369719326496124
val: 19 0.43136143684387207
val: 20 0.43871167302131653
val_Epoch:[ 65 ] val_loss: 0.4377290114760399 2022-07-01 00:21:57.611239
start training 2022-07-01 00:21:57.710756
Epoch:[ 66 0 ] loss: 0.4256129562854767 2022-07-01 00:22:11.948846
Epoch:[ 66 1 ] loss: 0.42797455191612244 2022-07-01 00:22:12.597944
Epoch:[ 66 2 ] loss: 0.42470934987068176 2022-07-01 00:22:13.019640
Epoch:[ 66 3 ] loss: 0.429019570350647 2022-07-01 00:22:13.428970
Epoch:[ 66 4 ] loss: 0.42803648114204407 2022-07-01 00:22:13.838028
Epoch:[ 66 5 ] loss: 0.42406177520751953 2022-07-01 00:22:14.245185
Epoch:[ 66 6 ] loss: 0.43099701404571533 2022-07-01 00:22:14.653422
Epoch:[ 66 7 ] loss: 0.424568235874176 2022-07-01 00:22:15.069447
Epoch:[ 66 8 ] loss: 0.4260694682598114 2022-07-01 00:22:15.481291
Epoch:[ 66 9 ] loss: 0.42756277322769165 2022-07-01 00:22:15.889905
Epoch:[ 66 10 ] loss: 0.4265429973602295 2022-07-01 00:22:16.300227
Epoch:[ 66 11 ] loss: 0.4271947741508484 2022-07-01 00:22:16.710610
Epoch:[ 66 12 ] loss: 0.42771244049072266 2022-07-01 00:22:17.119022
Epoch:[ 66 13 ] loss: 0.43021419644355774 2022-07-01 00:22:17.526501
Epoch:[ 66 14 ] loss: 0.4289337396621704 2022-07-01 00:22:17.937846
Epoch:[ 66 15 ] loss: 0.42839476466178894 2022-07-01 00:22:18.348477
Epoch:[ 66 16 ] loss: 0.43631893396377563 2022-07-01 00:22:23.841097
Epoch:[ 66 17 ] loss: 0.43088608980178833 2022-07-01 00:22:24.248218
Epoch:[ 66 18 ] loss: 0.4315641224384308 2022-07-01 00:22:24.670909
Epoch:[ 66 19 ] loss: 0.42730480432510376 2022-07-01 00:22:25.091508
Training_Epoch:[ 66 ] Training_loss: 0.4281839519739151 2022-07-01 00:22:25.092256
learning rate:  0.013107200000000006
netparams have been saved once 66
val: 1 0.4489617645740509
val: 2 0.44360965490341187
val: 3 0.44189903140068054
val: 4 0.4496164917945862
val: 5 0.4442059099674225
val: 6 0.45002782344818115
val: 7 0.44534119963645935
val: 8 0.4418911337852478
val: 9 0.4421280026435852
val: 10 0.4486753046512604
val: 11 0.4427677094936371
val: 12 0.44141313433647156
val: 13 0.4487658739089966
val: 14 0.4494253098964691
val: 15 0.45134398341178894
val: 16 0.44222068786621094
val: 17 0.44852736592292786
val: 18 0.4398292899131775
val: 19 0.4454292356967926
val: 20 0.4539223611354828
val_Epoch:[ 66 ] val_loss: 0.44600006341934206 2022-07-01 00:22:28.953366
start training 2022-07-01 00:22:29.057641
Epoch:[ 67 0 ] loss: 0.4310935139656067 2022-07-01 00:22:43.140506
Epoch:[ 67 1 ] loss: 0.42613485455513 2022-07-01 00:22:43.566494
Epoch:[ 67 2 ] loss: 0.42758259177207947 2022-07-01 00:22:43.989125
Epoch:[ 67 3 ] loss: 0.42608001828193665 2022-07-01 00:22:44.411815
Epoch:[ 67 4 ] loss: 0.42487967014312744 2022-07-01 00:22:44.831192
Epoch:[ 67 5 ] loss: 0.42602071166038513 2022-07-01 00:22:45.251736
Epoch:[ 67 6 ] loss: 0.42723348736763 2022-07-01 00:22:45.675940
Epoch:[ 67 7 ] loss: 0.42893144488334656 2022-07-01 00:22:46.095173
Epoch:[ 67 8 ] loss: 0.4277039170265198 2022-07-01 00:22:46.517285
Epoch:[ 67 9 ] loss: 0.42748379707336426 2022-07-01 00:22:46.941636
Epoch:[ 67 10 ] loss: 0.4274410605430603 2022-07-01 00:22:47.362068
Epoch:[ 67 11 ] loss: 0.4229296147823334 2022-07-01 00:22:47.781798
Epoch:[ 67 12 ] loss: 0.42661523818969727 2022-07-01 00:22:48.201600
Epoch:[ 67 13 ] loss: 0.42789655923843384 2022-07-01 00:22:48.614949
Epoch:[ 67 14 ] loss: 0.4265703856945038 2022-07-01 00:22:49.036603
Epoch:[ 67 15 ] loss: 0.4260943830013275 2022-07-01 00:22:49.457863
Epoch:[ 67 16 ] loss: 0.4271053075790405 2022-07-01 00:22:55.096917
Epoch:[ 67 17 ] loss: 0.42630138993263245 2022-07-01 00:22:55.516290
Epoch:[ 67 18 ] loss: 0.42813920974731445 2022-07-01 00:22:55.936244
Epoch:[ 67 19 ] loss: 0.42795664072036743 2022-07-01 00:22:56.355829
Training_Epoch:[ 67 ] Training_loss: 0.42700968980789183 2022-07-01 00:22:56.356468
learning rate:  0.013107200000000006
val: 1 0.4485674500465393
val: 2 0.4432711899280548
val: 3 0.4451840817928314
val: 4 0.4367109537124634
val: 5 0.44167742133140564
val: 6 0.4489491879940033
val: 7 0.43905380368232727
val: 8 0.43906423449516296
val: 9 0.4548165202140808
val: 10 0.4456813931465149
val: 11 0.44647416472435
val: 12 0.4480578303337097
val: 13 0.4397679567337036
val: 14 0.4474921226501465
val: 15 0.4420844316482544
val: 16 0.4473588168621063
val: 17 0.4521266520023346
val: 18 0.45264843106269836
val: 19 0.4416116178035736
val: 20 0.44364720582962036
val_Epoch:[ 67 ] val_loss: 0.44521227329969404 2022-07-01 00:23:00.072847
start training 2022-07-01 00:23:00.176541
Epoch:[ 68 0 ] loss: 0.42623066902160645 2022-07-01 00:23:14.351889
Epoch:[ 68 1 ] loss: 0.42673611640930176 2022-07-01 00:23:14.794185
Epoch:[ 68 2 ] loss: 0.42741337418556213 2022-07-01 00:23:15.231709
Epoch:[ 68 3 ] loss: 0.4273134469985962 2022-07-01 00:23:15.651902
Epoch:[ 68 4 ] loss: 0.4291497766971588 2022-07-01 00:23:16.065456
Epoch:[ 68 5 ] loss: 0.430328905582428 2022-07-01 00:23:16.474323
Epoch:[ 68 6 ] loss: 0.4270264208316803 2022-07-01 00:23:16.882940
Epoch:[ 68 7 ] loss: 0.42934101819992065 2022-07-01 00:23:17.305279
Epoch:[ 68 8 ] loss: 0.42629769444465637 2022-07-01 00:23:17.718792
Epoch:[ 68 9 ] loss: 0.42798203229904175 2022-07-01 00:23:18.140307
Epoch:[ 68 10 ] loss: 0.430315226316452 2022-07-01 00:23:18.562629
Epoch:[ 68 11 ] loss: 0.42458271980285645 2022-07-01 00:23:18.983954
Epoch:[ 68 12 ] loss: 0.4289112687110901 2022-07-01 00:23:19.405464
Epoch:[ 68 13 ] loss: 0.4296526610851288 2022-07-01 00:23:19.829147
Epoch:[ 68 14 ] loss: 0.42965930700302124 2022-07-01 00:23:20.251797
Epoch:[ 68 15 ] loss: 0.4263627827167511 2022-07-01 00:23:20.672407
Epoch:[ 68 16 ] loss: 0.4285067021846771 2022-07-01 00:23:26.073885
Epoch:[ 68 17 ] loss: 0.4272306263446808 2022-07-01 00:23:26.487346
Epoch:[ 68 18 ] loss: 0.4265463948249817 2022-07-01 00:23:26.909943
Epoch:[ 68 19 ] loss: 0.42621469497680664 2022-07-01 00:23:27.330277
Training_Epoch:[ 68 ] Training_loss: 0.42779009193181994 2022-07-01 00:23:27.330981
learning rate:  0.013107200000000006
netparams have been saved once 68
val: 1 0.4574272334575653
val: 2 0.46086835861206055
val: 3 0.4465954899787903
val: 4 0.4392988681793213
val: 5 0.46578356623649597
val: 6 0.44789406657218933
val: 7 0.4375321865081787
val: 8 0.44451895356178284
val: 9 0.44615092873573303
val: 10 0.4493260681629181
val: 11 0.4402408301830292
val: 12 0.4354035556316376
val: 13 0.4458303451538086
val: 14 0.4519045948982239
val: 15 0.446713924407959
val: 16 0.45002317428588867
val: 17 0.4535432457923889
val: 18 0.4474652409553528
val: 19 0.4540518522262573
val: 20 0.4356685280799866
val_Epoch:[ 68 ] val_loss: 0.4478120505809784 2022-07-01 00:23:31.175730
start training 2022-07-01 00:23:31.280810
Epoch:[ 69 0 ] loss: 0.429648220539093 2022-07-01 00:23:45.111430
Epoch:[ 69 1 ] loss: 0.4286346435546875 2022-07-01 00:23:45.552760
Epoch:[ 69 2 ] loss: 0.42930614948272705 2022-07-01 00:23:45.997737
Epoch:[ 69 3 ] loss: 0.4264500141143799 2022-07-01 00:23:46.419147
Epoch:[ 69 4 ] loss: 0.4274677634239197 2022-07-01 00:23:46.839478
Epoch:[ 69 5 ] loss: 0.4298721253871918 2022-07-01 00:23:47.262127
Epoch:[ 69 6 ] loss: 0.4309789538383484 2022-07-01 00:23:47.681812
Epoch:[ 69 7 ] loss: 0.42916449904441833 2022-07-01 00:23:48.101036
Epoch:[ 69 8 ] loss: 0.43068307638168335 2022-07-01 00:23:48.522372
Epoch:[ 69 9 ] loss: 0.43078097701072693 2022-07-01 00:23:48.941465
Epoch:[ 69 10 ] loss: 0.42838895320892334 2022-07-01 00:23:49.353742
Epoch:[ 69 11 ] loss: 0.42934826016426086 2022-07-01 00:23:49.776751
Epoch:[ 69 12 ] loss: 0.42684242129325867 2022-07-01 00:23:50.197029
Epoch:[ 69 13 ] loss: 0.4248099625110626 2022-07-01 00:23:50.616415
Epoch:[ 69 14 ] loss: 0.42943665385246277 2022-07-01 00:23:51.037585
Epoch:[ 69 15 ] loss: 0.4266161322593689 2022-07-01 00:23:51.447101
Epoch:[ 69 16 ] loss: 0.4314969778060913 2022-07-01 00:23:56.947682
Epoch:[ 69 17 ] loss: 0.428905189037323 2022-07-01 00:23:57.380785
Epoch:[ 69 18 ] loss: 0.42923703789711 2022-07-01 00:23:57.809648
Epoch:[ 69 19 ] loss: 0.42886853218078613 2022-07-01 00:23:58.230474
Training_Epoch:[ 69 ] Training_loss: 0.42884682714939115 2022-07-01 00:23:58.231182
learning rate:  0.013107200000000006
val: 1 0.44757288694381714
val: 2 0.44077467918395996
val: 3 0.4349062442779541
val: 4 0.44103574752807617
val: 5 0.4344707429409027
val: 6 0.4361111521720886
val: 7 0.4274003505706787
val: 8 0.4354564845561981
val: 9 0.44227126240730286
val: 10 0.4417096972465515
val: 11 0.43958932161331177
val: 12 0.43522149324417114
val: 13 0.4315241277217865
val: 14 0.43467774987220764
val: 15 0.45263051986694336
val: 16 0.44336917996406555
val: 17 0.4337434768676758
val: 18 0.4431549906730652
val: 19 0.44275712966918945
val: 20 0.44392475485801697
val_Epoch:[ 69 ] val_loss: 0.43911509960889816 2022-07-01 00:24:01.986148
start training 2022-07-01 00:24:02.107264
Epoch:[ 70 0 ] loss: 0.4273039698600769 2022-07-01 00:24:16.112712
Epoch:[ 70 1 ] loss: 0.4253857731819153 2022-07-01 00:24:17.160537
Epoch:[ 70 2 ] loss: 0.42460188269615173 2022-07-01 00:24:17.570439
Epoch:[ 70 3 ] loss: 0.4259333610534668 2022-07-01 00:24:17.977621
Epoch:[ 70 4 ] loss: 0.4265401065349579 2022-07-01 00:24:18.387799
Epoch:[ 70 5 ] loss: 0.4273202121257782 2022-07-01 00:24:18.798914
Epoch:[ 70 6 ] loss: 0.4250260591506958 2022-07-01 00:24:19.210276
Epoch:[ 70 7 ] loss: 0.426279753446579 2022-07-01 00:24:19.623445
Epoch:[ 70 8 ] loss: 0.4259229600429535 2022-07-01 00:24:20.033256
Epoch:[ 70 9 ] loss: 0.4264048635959625 2022-07-01 00:24:20.440191
Epoch:[ 70 10 ] loss: 0.42733532190322876 2022-07-01 00:24:20.849137
Epoch:[ 70 11 ] loss: 0.42793935537338257 2022-07-01 00:24:21.259510
Epoch:[ 70 12 ] loss: 0.423260897397995 2022-07-01 00:24:21.669385
Epoch:[ 70 13 ] loss: 0.4295385777950287 2022-07-01 00:24:22.078448
Epoch:[ 70 14 ] loss: 0.4271634519100189 2022-07-01 00:24:22.489263
Epoch:[ 70 15 ] loss: 0.42818179726600647 2022-07-01 00:24:22.898517
Epoch:[ 70 16 ] loss: 0.42632532119750977 2022-07-01 00:24:28.496441
Epoch:[ 70 17 ] loss: 0.42515844106674194 2022-07-01 00:24:28.905758
Epoch:[ 70 18 ] loss: 0.4275636076927185 2022-07-01 00:24:29.328229
Epoch:[ 70 19 ] loss: 0.42893099784851074 2022-07-01 00:24:29.750134
Training_Epoch:[ 70 ] Training_loss: 0.42660583555698395 2022-07-01 00:24:29.750953
learning rate:  0.013107200000000006
netparams have been saved once 70
val: 1 0.43093183636665344
val: 2 0.45294803380966187
val: 3 0.4360615909099579
val: 4 0.4372366666793823
val: 5 0.44632938504219055
val: 6 0.4354540705680847
val: 7 0.4423615038394928
val: 8 0.4354122281074524
val: 9 0.44832664728164673
val: 10 0.4344962239265442
val: 11 0.4387498199939728
val: 12 0.4433252513408661
val: 13 0.45015549659729004
val: 14 0.4444597363471985
val: 15 0.44167688488960266
val: 16 0.4418025314807892
val: 17 0.42972564697265625
val: 18 0.43401744961738586
val: 19 0.44528162479400635
val: 20 0.4393619894981384
val_Epoch:[ 70 ] val_loss: 0.44040573090314866 2022-07-01 00:24:33.526329
start training 2022-07-01 00:24:33.630717
Epoch:[ 71 0 ] loss: 0.4260178208351135 2022-07-01 00:24:48.293879
Epoch:[ 71 1 ] loss: 0.42496970295906067 2022-07-01 00:24:48.713413
Epoch:[ 71 2 ] loss: 0.42518624663352966 2022-07-01 00:24:49.134616
Epoch:[ 71 3 ] loss: 0.42535585165023804 2022-07-01 00:24:49.554956
Epoch:[ 71 4 ] loss: 0.42326799035072327 2022-07-01 00:24:49.974220
Epoch:[ 71 5 ] loss: 0.42232638597488403 2022-07-01 00:24:50.395471
Epoch:[ 71 6 ] loss: 0.42525047063827515 2022-07-01 00:24:50.818123
Epoch:[ 71 7 ] loss: 0.42292165756225586 2022-07-01 00:24:51.233934
Epoch:[ 71 8 ] loss: 0.4251004457473755 2022-07-01 00:24:51.654397
Epoch:[ 71 9 ] loss: 0.42596617341041565 2022-07-01 00:24:52.074128
Epoch:[ 71 10 ] loss: 0.4252164959907532 2022-07-01 00:24:52.497200
Epoch:[ 71 11 ] loss: 0.4240546226501465 2022-07-01 00:24:52.916088
Epoch:[ 71 12 ] loss: 0.4252864420413971 2022-07-01 00:24:53.338488
Epoch:[ 71 13 ] loss: 0.4242142140865326 2022-07-01 00:24:53.759530
Epoch:[ 71 14 ] loss: 0.42388632893562317 2022-07-01 00:24:54.179878
Epoch:[ 71 15 ] loss: 0.4296654462814331 2022-07-01 00:24:54.596368
Epoch:[ 71 16 ] loss: 0.42328885197639465 2022-07-01 00:24:59.822653
Epoch:[ 71 17 ] loss: 0.42740920186042786 2022-07-01 00:25:00.244742
Epoch:[ 71 18 ] loss: 0.42535191774368286 2022-07-01 00:25:00.665217
Epoch:[ 71 19 ] loss: 0.42520391941070557 2022-07-01 00:25:01.086658
Training_Epoch:[ 71 ] Training_loss: 0.4249970093369484 2022-07-01 00:25:01.087349
learning rate:  0.010485760000000005
val: 1 0.4369819462299347
val: 2 0.4293890595436096
val: 3 0.43498021364212036
val: 4 0.43292495608329773
val: 5 0.43024924397468567
val: 6 0.4390718340873718
val: 7 0.42899802327156067
val: 8 0.4306242763996124
val: 9 0.44080016016960144
val: 10 0.4432118833065033
val: 11 0.438008576631546
val: 12 0.43551772832870483
val: 13 0.44414442777633667
val: 14 0.4327835738658905
val: 15 0.43416205048561096
val: 16 0.44025954604148865
val: 17 0.4435468912124634
val: 18 0.43046674132347107
val: 19 0.44049835205078125
val: 20 0.4397560656070709
val_Epoch:[ 71 ] val_loss: 0.4363187775015831 2022-07-01 00:25:04.854356
start training 2022-07-01 00:25:04.974425
Epoch:[ 72 0 ] loss: 0.4213535785675049 2022-07-01 00:25:19.520252
Epoch:[ 72 1 ] loss: 0.4228002429008484 2022-07-01 00:25:19.960441
Epoch:[ 72 2 ] loss: 0.4221925139427185 2022-07-01 00:25:20.380900
Epoch:[ 72 3 ] loss: 0.42527395486831665 2022-07-01 00:25:20.794607
Epoch:[ 72 4 ] loss: 0.42376548051834106 2022-07-01 00:25:21.214573
Epoch:[ 72 5 ] loss: 0.4220030605792999 2022-07-01 00:25:21.636856
Epoch:[ 72 6 ] loss: 0.4247971475124359 2022-07-01 00:25:22.058201
Epoch:[ 72 7 ] loss: 0.4231836497783661 2022-07-01 00:25:22.481083
Epoch:[ 72 8 ] loss: 0.4252933859825134 2022-07-01 00:25:22.903001
Epoch:[ 72 9 ] loss: 0.42606446146965027 2022-07-01 00:25:23.324281
Epoch:[ 72 10 ] loss: 0.42393311858177185 2022-07-01 00:25:23.745291
Epoch:[ 72 11 ] loss: 0.4236904978752136 2022-07-01 00:25:24.167855
Epoch:[ 72 12 ] loss: 0.4241717755794525 2022-07-01 00:25:24.589272
Epoch:[ 72 13 ] loss: 0.42780011892318726 2022-07-01 00:25:25.010900
Epoch:[ 72 14 ] loss: 0.42930126190185547 2022-07-01 00:25:25.433281
Epoch:[ 72 15 ] loss: 0.4225510060787201 2022-07-01 00:25:25.854108
Epoch:[ 72 16 ] loss: 0.4253850281238556 2022-07-01 00:25:31.082905
Epoch:[ 72 17 ] loss: 0.42583712935447693 2022-07-01 00:25:31.501883
Epoch:[ 72 18 ] loss: 0.4265490174293518 2022-07-01 00:25:31.933109
Epoch:[ 72 19 ] loss: 0.4227062463760376 2022-07-01 00:25:32.351505
Training_Epoch:[ 72 ] Training_loss: 0.42443263381719587 2022-07-01 00:25:32.352217
learning rate:  0.010485760000000005
netparams have been saved once 72
val: 1 0.43855488300323486
val: 2 0.43183228373527527
val: 3 0.4432050585746765
val: 4 0.44026973843574524
val: 5 0.435747355222702
val: 6 0.4463033974170685
val: 7 0.4445282518863678
val: 8 0.4329470992088318
val: 9 0.43838828802108765
val: 10 0.44292891025543213
val: 11 0.4345797598361969
val: 12 0.43616968393325806
val: 13 0.4427081048488617
val: 14 0.44999757409095764
val: 15 0.44810935854911804
val: 16 0.44357919692993164
val: 17 0.43987128138542175
val: 18 0.4367775321006775
val: 19 0.45292308926582336
val: 20 0.4381699562072754
val_Epoch:[ 72 ] val_loss: 0.4408795401453972 2022-07-01 00:25:36.132745
start training 2022-07-01 00:25:36.236457
Epoch:[ 73 0 ] loss: 0.4218900799751282 2022-07-01 00:25:50.764850
Epoch:[ 73 1 ] loss: 0.4208860695362091 2022-07-01 00:25:51.186375
Epoch:[ 73 2 ] loss: 0.4250803291797638 2022-07-01 00:25:51.606866
Epoch:[ 73 3 ] loss: 0.42331966757774353 2022-07-01 00:25:52.027305
Epoch:[ 73 4 ] loss: 0.42668452858924866 2022-07-01 00:25:52.436059
Epoch:[ 73 5 ] loss: 0.42573294043540955 2022-07-01 00:25:52.843888
Epoch:[ 73 6 ] loss: 0.42161303758621216 2022-07-01 00:25:53.257140
Epoch:[ 73 7 ] loss: 0.4251403212547302 2022-07-01 00:25:53.670168
Epoch:[ 73 8 ] loss: 0.4211750030517578 2022-07-01 00:25:54.079543
Epoch:[ 73 9 ] loss: 0.42296385765075684 2022-07-01 00:25:54.489743
Epoch:[ 73 10 ] loss: 0.4228714108467102 2022-07-01 00:25:54.898146
Epoch:[ 73 11 ] loss: 0.42272576689720154 2022-07-01 00:25:55.306929
Epoch:[ 73 12 ] loss: 0.42240622639656067 2022-07-01 00:25:55.713473
Epoch:[ 73 13 ] loss: 0.42432093620300293 2022-07-01 00:25:56.121504
Epoch:[ 73 14 ] loss: 0.42609402537345886 2022-07-01 00:25:56.537760
Epoch:[ 73 15 ] loss: 0.4280359148979187 2022-07-01 00:25:56.949858
Epoch:[ 73 16 ] loss: 0.4255920946598053 2022-07-01 00:26:02.212761
Epoch:[ 73 17 ] loss: 0.42488738894462585 2022-07-01 00:26:02.621532
Epoch:[ 73 18 ] loss: 0.42483627796173096 2022-07-01 00:26:03.041205
Epoch:[ 73 19 ] loss: 0.4233815670013428 2022-07-01 00:26:03.460033
Training_Epoch:[ 73 ] Training_loss: 0.4239818722009659 2022-07-01 00:26:03.460796
learning rate:  0.010485760000000005
val: 1 0.43357670307159424
val: 2 0.43810203671455383
val: 3 0.43871328234672546
val: 4 0.4239647090435028
val: 5 0.4327857494354248
val: 6 0.43700212240219116
val: 7 0.4412102699279785
val: 8 0.4330482482910156
val: 9 0.4362168610095978
val: 10 0.43432119488716125
val: 11 0.43461474776268005
val: 12 0.4349505305290222
val: 13 0.4399789273738861
val: 14 0.43895426392555237
val: 15 0.4430629014968872
val: 16 0.44494184851646423
val: 17 0.4307977855205536
val: 18 0.44112861156463623
val: 19 0.44239166378974915
val: 20 0.44547751545906067
val_Epoch:[ 73 ] val_loss: 0.43726199865341187 2022-07-01 00:26:07.248144
start training 2022-07-01 00:26:07.372421
Epoch:[ 74 0 ] loss: 0.42063742876052856 2022-07-01 00:26:21.528128
Epoch:[ 74 1 ] loss: 0.42536982893943787 2022-07-01 00:26:22.422127
Epoch:[ 74 2 ] loss: 0.42108267545700073 2022-07-01 00:26:22.845510
Epoch:[ 74 3 ] loss: 0.423758864402771 2022-07-01 00:26:23.259993
Epoch:[ 74 4 ] loss: 0.422717422246933 2022-07-01 00:26:23.681446
Epoch:[ 74 5 ] loss: 0.42131152749061584 2022-07-01 00:26:24.104895
Epoch:[ 74 6 ] loss: 0.4234909415245056 2022-07-01 00:26:24.525759
Epoch:[ 74 7 ] loss: 0.4197182357311249 2022-07-01 00:26:24.945591
Epoch:[ 74 8 ] loss: 0.4234156906604767 2022-07-01 00:26:25.367616
Epoch:[ 74 9 ] loss: 0.42276570200920105 2022-07-01 00:26:25.790220
Epoch:[ 74 10 ] loss: 0.4234178066253662 2022-07-01 00:26:26.213914
Epoch:[ 74 11 ] loss: 0.4234423041343689 2022-07-01 00:26:26.632727
Epoch:[ 74 12 ] loss: 0.4226098358631134 2022-07-01 00:26:27.053415
Epoch:[ 74 13 ] loss: 0.42593127489089966 2022-07-01 00:26:27.473506
Epoch:[ 74 14 ] loss: 0.4229128062725067 2022-07-01 00:26:27.893770
Epoch:[ 74 15 ] loss: 0.4232972264289856 2022-07-01 00:26:28.316461
Epoch:[ 74 16 ] loss: 0.42418360710144043 2022-07-01 00:26:33.304974
Epoch:[ 74 17 ] loss: 0.4253115653991699 2022-07-01 00:26:33.966909
Epoch:[ 74 18 ] loss: 0.424159973859787 2022-07-01 00:26:34.390597
Epoch:[ 74 19 ] loss: 0.4262109398841858 2022-07-01 00:26:34.810390
Training_Epoch:[ 74 ] Training_loss: 0.42328728288412093 2022-07-01 00:26:34.811074
learning rate:  0.010485760000000005
netparams have been saved once 74
val: 1 0.44010353088378906
val: 2 0.4343869388103485
val: 3 0.4271731376647949
val: 4 0.44050800800323486
val: 5 0.4388069808483124
val: 6 0.4556167721748352
val: 7 0.4416065514087677
val: 8 0.4366907775402069
val: 9 0.44674134254455566
val: 10 0.4389234483242035
val: 11 0.4360116422176361
val: 12 0.44312945008277893
val: 13 0.4400387108325958
val: 14 0.4382212162017822
val: 15 0.4455834627151489
val: 16 0.4503078758716583
val: 17 0.44541609287261963
val: 18 0.4422931373119354
val: 19 0.45127490162849426
val: 20 0.4412349462509155
val_Epoch:[ 74 ] val_loss: 0.4417034462094307 2022-07-01 00:26:38.568707
start training 2022-07-01 00:26:38.671954
Epoch:[ 75 0 ] loss: 0.4240844249725342 2022-07-01 00:26:52.815110
Epoch:[ 75 1 ] loss: 0.42119523882865906 2022-07-01 00:26:53.380575
Epoch:[ 75 2 ] loss: 0.4253785014152527 2022-07-01 00:26:53.803023
Epoch:[ 75 3 ] loss: 0.42481011152267456 2022-07-01 00:26:54.226463
Epoch:[ 75 4 ] loss: 0.4235275983810425 2022-07-01 00:26:54.637687
Epoch:[ 75 5 ] loss: 0.42437121272087097 2022-07-01 00:26:55.046845
Epoch:[ 75 6 ] loss: 0.42312973737716675 2022-07-01 00:26:55.462038
Epoch:[ 75 7 ] loss: 0.42525920271873474 2022-07-01 00:26:55.869289
Epoch:[ 75 8 ] loss: 0.4235049784183502 2022-07-01 00:26:56.278041
Epoch:[ 75 9 ] loss: 0.4222072660923004 2022-07-01 00:26:56.687967
Epoch:[ 75 10 ] loss: 0.4232146739959717 2022-07-01 00:26:57.100080
Epoch:[ 75 11 ] loss: 0.42469143867492676 2022-07-01 00:26:57.509169
Epoch:[ 75 12 ] loss: 0.4248044490814209 2022-07-01 00:26:57.917420
Epoch:[ 75 13 ] loss: 0.42361387610435486 2022-07-01 00:26:58.327211
Epoch:[ 75 14 ] loss: 0.427170991897583 2022-07-01 00:26:58.736261
Epoch:[ 75 15 ] loss: 0.4229113757610321 2022-07-01 00:26:59.147300
Epoch:[ 75 16 ] loss: 0.4242463707923889 2022-07-01 00:27:04.741771
Epoch:[ 75 17 ] loss: 0.4241564869880676 2022-07-01 00:27:05.152294
Epoch:[ 75 18 ] loss: 0.4227147698402405 2022-07-01 00:27:05.579427
Epoch:[ 75 19 ] loss: 0.4260454475879669 2022-07-01 00:27:05.998641
Training_Epoch:[ 75 ] Training_loss: 0.424051907658577 2022-07-01 00:27:05.999405
learning rate:  0.010485760000000005
val: 1 0.4355810880661011
val: 2 0.43715664744377136
val: 3 0.4387696087360382
val: 4 0.4381484091281891
val: 5 0.4415045976638794
val: 6 0.4365970492362976
val: 7 0.431130051612854
val: 8 0.4253988265991211
val: 9 0.4432366192340851
val: 10 0.4290311932563782
val: 11 0.441245973110199
val: 12 0.4378400146961212
val: 13 0.42810696363449097
val: 14 0.4335934817790985
val: 15 0.4522053599357605
val: 16 0.4518357515335083
val: 17 0.43739053606987
val: 18 0.4335916340351105
val: 19 0.438963919878006
val: 20 0.4480450749397278
val_Epoch:[ 75 ] val_loss: 0.43796864002943037 2022-07-01 00:27:09.801267
start training 2022-07-01 00:27:09.921293
Epoch:[ 76 0 ] loss: 0.42233219742774963 2022-07-01 00:27:24.602862
Epoch:[ 76 1 ] loss: 0.42049553990364075 2022-07-01 00:27:25.026242
Epoch:[ 76 2 ] loss: 0.4205188751220703 2022-07-01 00:27:25.446660
Epoch:[ 76 3 ] loss: 0.423179030418396 2022-07-01 00:27:25.856576
Epoch:[ 76 4 ] loss: 0.42511630058288574 2022-07-01 00:27:26.266035
Epoch:[ 76 5 ] loss: 0.4274558424949646 2022-07-01 00:27:26.678140
Epoch:[ 76 6 ] loss: 0.4209745228290558 2022-07-01 00:27:27.086069
Epoch:[ 76 7 ] loss: 0.4226798713207245 2022-07-01 00:27:27.494708
Epoch:[ 76 8 ] loss: 0.4255141019821167 2022-07-01 00:27:27.908798
Epoch:[ 76 9 ] loss: 0.4218519330024719 2022-07-01 00:27:28.315242
Epoch:[ 76 10 ] loss: 0.4255245327949524 2022-07-01 00:27:28.726312
Epoch:[ 76 11 ] loss: 0.4227043688297272 2022-07-01 00:27:29.136414
Epoch:[ 76 12 ] loss: 0.42409905791282654 2022-07-01 00:27:29.551623
Epoch:[ 76 13 ] loss: 0.42178159952163696 2022-07-01 00:27:29.960316
Epoch:[ 76 14 ] loss: 0.4213758707046509 2022-07-01 00:27:30.368763
Epoch:[ 76 15 ] loss: 0.42348170280456543 2022-07-01 00:27:30.777882
Epoch:[ 76 16 ] loss: 0.4262829124927521 2022-07-01 00:27:36.477406
Epoch:[ 76 17 ] loss: 0.4246346056461334 2022-07-01 00:27:36.887866
Epoch:[ 76 18 ] loss: 0.4213142693042755 2022-07-01 00:27:37.307395
Epoch:[ 76 19 ] loss: 0.4232402443885803 2022-07-01 00:27:37.716937
Training_Epoch:[ 76 ] Training_loss: 0.42322786897420883 2022-07-01 00:27:37.717852
learning rate:  0.010485760000000005
netparams have been saved once 76
val: 1 0.43308427929878235
val: 2 0.438976526260376
val: 3 0.43794769048690796
val: 4 0.4236498177051544
val: 5 0.43615734577178955
val: 6 0.43823838233947754
val: 7 0.4337024986743927
val: 8 0.42591941356658936
val: 9 0.4410700500011444
val: 10 0.4313925802707672
val: 11 0.42006391286849976
val: 12 0.4445360600948334
val: 13 0.4325873851776123
val: 14 0.4303942024707794
val: 15 0.4330531060695648
val: 16 0.44220349192619324
val: 17 0.44202589988708496
val: 18 0.4439115822315216
val: 19 0.43915557861328125
val: 20 0.4435538649559021
val_Epoch:[ 76 ] val_loss: 0.4355811834335327 2022-07-01 00:27:41.810732
start training 2022-07-01 00:27:41.918618
Epoch:[ 77 0 ] loss: 0.42057234048843384 2022-07-01 00:27:55.911936
Epoch:[ 77 1 ] loss: 0.4228976368904114 2022-07-01 00:27:56.332336
Epoch:[ 77 2 ] loss: 0.4216699004173279 2022-07-01 00:27:56.754117
Epoch:[ 77 3 ] loss: 0.4199780821800232 2022-07-01 00:27:57.173378
Epoch:[ 77 4 ] loss: 0.42050185799598694 2022-07-01 00:27:57.595759
Epoch:[ 77 5 ] loss: 0.4209035634994507 2022-07-01 00:27:58.020769
Epoch:[ 77 6 ] loss: 0.42291125655174255 2022-07-01 00:27:58.444899
Epoch:[ 77 7 ] loss: 0.4220709204673767 2022-07-01 00:27:58.865558
Epoch:[ 77 8 ] loss: 0.42168864607810974 2022-07-01 00:27:59.287419
Epoch:[ 77 9 ] loss: 0.4198877215385437 2022-07-01 00:27:59.707363
Epoch:[ 77 10 ] loss: 0.42315447330474854 2022-07-01 00:28:00.122905
Epoch:[ 77 11 ] loss: 0.42591527104377747 2022-07-01 00:28:00.533462
Epoch:[ 77 12 ] loss: 0.42415085434913635 2022-07-01 00:28:00.949050
Epoch:[ 77 13 ] loss: 0.42327195405960083 2022-07-01 00:28:01.363473
Epoch:[ 77 14 ] loss: 0.42517855763435364 2022-07-01 00:28:01.785093
Epoch:[ 77 15 ] loss: 0.42054855823516846 2022-07-01 00:28:02.206133
Epoch:[ 77 16 ] loss: 0.42343124747276306 2022-07-01 00:28:08.083566
Epoch:[ 77 17 ] loss: 0.4237074553966522 2022-07-01 00:28:08.504871
Epoch:[ 77 18 ] loss: 0.42423176765441895 2022-07-01 00:28:08.927705
Epoch:[ 77 19 ] loss: 0.4233645498752594 2022-07-01 00:28:09.349315
Training_Epoch:[ 77 ] Training_loss: 0.42250183075666425 2022-07-01 00:28:09.350195
learning rate:  0.010485760000000005
val: 1 0.43870487809181213
val: 2 0.44789502024650574
val: 3 0.4354233741760254
val: 4 0.42811623215675354
val: 5 0.4428121745586395
val: 6 0.43210428953170776
val: 7 0.4443422257900238
val: 8 0.4422118067741394
val: 9 0.44661104679107666
val: 10 0.43462038040161133
val: 11 0.43206050992012024
val: 12 0.4346637427806854
val: 13 0.44236740469932556
val: 14 0.4455319344997406
val: 15 0.4407244622707367
val: 16 0.4434148669242859
val: 17 0.43605440855026245
val: 18 0.4388470947742462
val: 19 0.4449616074562073
val: 20 0.44214409589767456
val_Epoch:[ 77 ] val_loss: 0.43968057781457903 2022-07-01 00:28:13.233989
start training 2022-07-01 00:28:13.337899
Epoch:[ 78 0 ] loss: 0.42366617918014526 2022-07-01 00:28:28.028393
Epoch:[ 78 1 ] loss: 0.42046496272087097 2022-07-01 00:28:28.447541
Epoch:[ 78 2 ] loss: 0.4218098521232605 2022-07-01 00:28:28.868264
Epoch:[ 78 3 ] loss: 0.4208295941352844 2022-07-01 00:28:29.283768
Epoch:[ 78 4 ] loss: 0.418613076210022 2022-07-01 00:28:29.703690
Epoch:[ 78 5 ] loss: 0.42189162969589233 2022-07-01 00:28:30.124890
Epoch:[ 78 6 ] loss: 0.41807976365089417 2022-07-01 00:28:30.547831
Epoch:[ 78 7 ] loss: 0.4235839545726776 2022-07-01 00:28:30.968421
Epoch:[ 78 8 ] loss: 0.4242335855960846 2022-07-01 00:28:31.390087
Epoch:[ 78 9 ] loss: 0.42331650853157043 2022-07-01 00:28:31.811253
Epoch:[ 78 10 ] loss: 0.42369216680526733 2022-07-01 00:28:32.230955
Epoch:[ 78 11 ] loss: 0.42312487959861755 2022-07-01 00:28:32.644946
Epoch:[ 78 12 ] loss: 0.4239498972892761 2022-07-01 00:28:33.067604
Epoch:[ 78 13 ] loss: 0.4242441654205322 2022-07-01 00:28:33.488276
Epoch:[ 78 14 ] loss: 0.42169758677482605 2022-07-01 00:28:33.911271
Epoch:[ 78 15 ] loss: 0.42347073554992676 2022-07-01 00:28:34.334846
Epoch:[ 78 16 ] loss: 0.4242788255214691 2022-07-01 00:28:39.560385
Epoch:[ 78 17 ] loss: 0.4274640381336212 2022-07-01 00:28:39.980159
Epoch:[ 78 18 ] loss: 0.4266515374183655 2022-07-01 00:28:40.399103
Epoch:[ 78 19 ] loss: 0.422305166721344 2022-07-01 00:28:40.823868
Training_Epoch:[ 78 ] Training_loss: 0.4228684052824974 2022-07-01 00:28:40.824590
learning rate:  0.010485760000000005
netparams have been saved once 78
val: 1 0.4485146403312683
val: 2 0.44780558347702026
val: 3 0.4321520924568176
val: 4 0.4357638359069824
val: 5 0.4384653568267822
val: 6 0.4378647208213806
val: 7 0.44883954524993896
val: 8 0.43743619322776794
val: 9 0.439321905374527
val: 10 0.44256436824798584
val: 11 0.4320288300514221
val: 12 0.45308929681777954
val: 13 0.449550598859787
val: 14 0.44778987765312195
val: 15 0.44726717472076416
val: 16 0.43650656938552856
val: 17 0.4478151798248291
val: 18 0.4395827054977417
val: 19 0.4414689242839813
val: 20 0.44196808338165283
val_Epoch:[ 78 ] val_loss: 0.442289774119854 2022-07-01 00:28:44.683301
start training 2022-07-01 00:28:44.792981
Epoch:[ 79 0 ] loss: 0.42459508776664734 2022-07-01 00:28:59.601134
Epoch:[ 79 1 ] loss: 0.4208624064922333 2022-07-01 00:29:00.024081
Epoch:[ 79 2 ] loss: 0.42792484164237976 2022-07-01 00:29:00.445267
Epoch:[ 79 3 ] loss: 0.4229966402053833 2022-07-01 00:29:00.861812
Epoch:[ 79 4 ] loss: 0.42823895812034607 2022-07-01 00:29:01.280972
Epoch:[ 79 5 ] loss: 0.4196896255016327 2022-07-01 00:29:01.699621
Epoch:[ 79 6 ] loss: 0.42292845249176025 2022-07-01 00:29:02.121874
Epoch:[ 79 7 ] loss: 0.4231542646884918 2022-07-01 00:29:02.543837
Epoch:[ 79 8 ] loss: 0.4253172278404236 2022-07-01 00:29:02.965534
Epoch:[ 79 9 ] loss: 0.422425776720047 2022-07-01 00:29:03.388336
Epoch:[ 79 10 ] loss: 0.42295902967453003 2022-07-01 00:29:03.812975
Epoch:[ 79 11 ] loss: 0.42257845401763916 2022-07-01 00:29:04.235257
Epoch:[ 79 12 ] loss: 0.4238843619823456 2022-07-01 00:29:04.658500
Epoch:[ 79 13 ] loss: 0.422039270401001 2022-07-01 00:29:05.083490
Epoch:[ 79 14 ] loss: 0.42430877685546875 2022-07-01 00:29:05.505997
Epoch:[ 79 15 ] loss: 0.42373356223106384 2022-07-01 00:29:05.931388
Epoch:[ 79 16 ] loss: 0.426017701625824 2022-07-01 00:29:11.333659
Epoch:[ 79 17 ] loss: 0.42443209886550903 2022-07-01 00:29:11.758051
Epoch:[ 79 18 ] loss: 0.4219602644443512 2022-07-01 00:29:12.178618
Epoch:[ 79 19 ] loss: 0.426938533782959 2022-07-01 00:29:12.601669
Training_Epoch:[ 79 ] Training_loss: 0.42384926676750184 2022-07-01 00:29:12.602363
learning rate:  0.010485760000000005
val: 1 0.440546452999115
val: 2 0.43918535113334656
val: 3 0.4458184838294983
val: 4 0.43535035848617554
val: 5 0.4438360631465912
val: 6 0.4384959638118744
val: 7 0.4483872056007385
val: 8 0.437520295381546
val: 9 0.436612606048584
val: 10 0.4293471574783325
val: 11 0.44067952036857605
val: 12 0.445265531539917
val: 13 0.4361477196216583
val: 14 0.4258584678173065
val: 15 0.4483194053173065
val: 16 0.43296557664871216
val: 17 0.4370672404766083
val: 18 0.4261646866798401
val: 19 0.44007691740989685
val: 20 0.4463651478290558
val_Epoch:[ 79 ] val_loss: 0.43870050758123397 2022-07-01 00:29:16.363288
start training 2022-07-01 00:29:16.467537
Epoch:[ 80 0 ] loss: 0.42124322056770325 2022-07-01 00:29:30.999203
Epoch:[ 80 1 ] loss: 0.419615775346756 2022-07-01 00:29:31.491581
Epoch:[ 80 2 ] loss: 0.42205262184143066 2022-07-01 00:29:31.914962
Epoch:[ 80 3 ] loss: 0.42036229372024536 2022-07-01 00:29:32.334599
Epoch:[ 80 4 ] loss: 0.4175967276096344 2022-07-01 00:29:32.753728
Epoch:[ 80 5 ] loss: 0.4229376018047333 2022-07-01 00:29:33.175059
Epoch:[ 80 6 ] loss: 0.4246279299259186 2022-07-01 00:29:33.594236
Epoch:[ 80 7 ] loss: 0.42038509249687195 2022-07-01 00:29:34.018163
Epoch:[ 80 8 ] loss: 0.42263874411582947 2022-07-01 00:29:34.441905
Epoch:[ 80 9 ] loss: 0.42111098766326904 2022-07-01 00:29:34.864431
Epoch:[ 80 10 ] loss: 0.42348653078079224 2022-07-01 00:29:35.285009
Epoch:[ 80 11 ] loss: 0.4219319224357605 2022-07-01 00:29:35.707382
Epoch:[ 80 12 ] loss: 0.42254525423049927 2022-07-01 00:29:36.130452
Epoch:[ 80 13 ] loss: 0.4227046072483063 2022-07-01 00:29:36.551373
Epoch:[ 80 14 ] loss: 0.42307281494140625 2022-07-01 00:29:36.975876
Epoch:[ 80 15 ] loss: 0.4225285053253174 2022-07-01 00:29:37.398857
Epoch:[ 80 16 ] loss: 0.42029035091400146 2022-07-01 00:29:43.231679
Epoch:[ 80 17 ] loss: 0.4252100884914398 2022-07-01 00:29:43.655093
Epoch:[ 80 18 ] loss: 0.4249650537967682 2022-07-01 00:29:44.079078
Epoch:[ 80 19 ] loss: 0.4211236834526062 2022-07-01 00:29:44.501708
Training_Epoch:[ 80 ] Training_loss: 0.4220214903354645 2022-07-01 00:29:44.502469
learning rate:  0.010485760000000005
netparams have been saved once 80
val: 1 0.4335114657878876
val: 2 0.4301728904247284
val: 3 0.4337219297885895
val: 4 0.4268319308757782
val: 5 0.43894949555397034
val: 6 0.4297734797000885
val: 7 0.4358072578907013
val: 8 0.43662723898887634
val: 9 0.447950154542923
val: 10 0.442935049533844
val: 11 0.4378805458545685
val: 12 0.4412635862827301
val: 13 0.44928908348083496
val: 14 0.43905818462371826
val: 15 0.4345709979534149
val: 16 0.4328458905220032
val: 17 0.42544904351234436
val: 18 0.4382975697517395
val: 19 0.4268360733985901
val: 20 0.43426233530044556
val_Epoch:[ 80 ] val_loss: 0.4358017101883888 2022-07-01 00:29:48.284497
start training 2022-07-01 00:29:48.388565
Epoch:[ 81 0 ] loss: 0.421133428812027 2022-07-01 00:30:03.428012
Epoch:[ 81 1 ] loss: 0.4215821623802185 2022-07-01 00:30:03.848872
Epoch:[ 81 2 ] loss: 0.4209789037704468 2022-07-01 00:30:04.263913
Epoch:[ 81 3 ] loss: 0.41526320576667786 2022-07-01 00:30:04.686574
Epoch:[ 81 4 ] loss: 0.4180695712566376 2022-07-01 00:30:05.107812
Epoch:[ 81 5 ] loss: 0.42271023988723755 2022-07-01 00:30:05.527626
Epoch:[ 81 6 ] loss: 0.42484113574028015 2022-07-01 00:30:05.949978
Epoch:[ 81 7 ] loss: 0.4197990298271179 2022-07-01 00:30:06.368947
Epoch:[ 81 8 ] loss: 0.42337125539779663 2022-07-01 00:30:06.791009
Epoch:[ 81 9 ] loss: 0.4198424816131592 2022-07-01 00:30:07.213859
Epoch:[ 81 10 ] loss: 0.42186182737350464 2022-07-01 00:30:07.630278
Epoch:[ 81 11 ] loss: 0.42098602652549744 2022-07-01 00:30:08.051328
Epoch:[ 81 12 ] loss: 0.42148739099502563 2022-07-01 00:30:08.473854
Epoch:[ 81 13 ] loss: 0.4241126775741577 2022-07-01 00:30:08.895262
Epoch:[ 81 14 ] loss: 0.4183841049671173 2022-07-01 00:30:09.319375
Epoch:[ 81 15 ] loss: 0.4206112027168274 2022-07-01 00:30:09.740830
Epoch:[ 81 16 ] loss: 0.42022550106048584 2022-07-01 00:30:15.942530
Epoch:[ 81 17 ] loss: 0.4203847050666809 2022-07-01 00:30:16.368396
Epoch:[ 81 18 ] loss: 0.4204220473766327 2022-07-01 00:30:16.793776
Epoch:[ 81 19 ] loss: 0.41702431440353394 2022-07-01 00:30:17.213708
Training_Epoch:[ 81 ] Training_loss: 0.4206545606255531 2022-07-01 00:30:17.214563
learning rate:  0.008388608000000004
val: 1 0.434927374124527
val: 2 0.4431784152984619
val: 3 0.4473060965538025
val: 4 0.4469902813434601
val: 5 0.4503953158855438
val: 6 0.445069819688797
val: 7 0.4319973289966583
val: 8 0.4305121898651123
val: 9 0.43248191475868225
val: 10 0.43378639221191406
val: 11 0.44762736558914185
val: 12 0.43333080410957336
val: 13 0.4456480145454407
val: 14 0.44128069281578064
val: 15 0.4463529586791992
val: 16 0.4287571907043457
val: 17 0.44507700204849243
val: 18 0.43182387948036194
val: 19 0.4368184506893158
val: 20 0.43274548649787903
val_Epoch:[ 81 ] val_loss: 0.43930534869432447 2022-07-01 00:30:21.057407
start training 2022-07-01 00:30:21.162034
Epoch:[ 82 0 ] loss: 0.41783076524734497 2022-07-01 00:30:36.059900
Epoch:[ 82 1 ] loss: 0.4196169674396515 2022-07-01 00:30:36.479562
Epoch:[ 82 2 ] loss: 0.42056888341903687 2022-07-01 00:30:36.901886
Epoch:[ 82 3 ] loss: 0.4180321991443634 2022-07-01 00:30:37.317030
Epoch:[ 82 4 ] loss: 0.41869255900382996 2022-07-01 00:30:37.741051
Epoch:[ 82 5 ] loss: 0.41872701048851013 2022-07-01 00:30:38.160596
Epoch:[ 82 6 ] loss: 0.41769886016845703 2022-07-01 00:30:38.580903
Epoch:[ 82 7 ] loss: 0.417898029088974 2022-07-01 00:30:38.999954
Epoch:[ 82 8 ] loss: 0.4201592206954956 2022-07-01 00:30:39.419405
Epoch:[ 82 9 ] loss: 0.41907069087028503 2022-07-01 00:30:39.841016
Epoch:[ 82 10 ] loss: 0.41991281509399414 2022-07-01 00:30:40.262919
Epoch:[ 82 11 ] loss: 0.4222075939178467 2022-07-01 00:30:40.683142
Epoch:[ 82 12 ] loss: 0.4216674268245697 2022-07-01 00:30:41.104564
Epoch:[ 82 13 ] loss: 0.4180695116519928 2022-07-01 00:30:41.524454
Epoch:[ 82 14 ] loss: 0.4185592830181122 2022-07-01 00:30:41.944112
Epoch:[ 82 15 ] loss: 0.4205557107925415 2022-07-01 00:30:42.363493
Epoch:[ 82 16 ] loss: 0.4215916395187378 2022-07-01 00:30:47.409408
Epoch:[ 82 17 ] loss: 0.4227573573589325 2022-07-01 00:30:47.831019
Epoch:[ 82 18 ] loss: 0.4191676378250122 2022-07-01 00:30:48.251408
Epoch:[ 82 19 ] loss: 0.4200407564640045 2022-07-01 00:30:48.671533
Training_Epoch:[ 82 ] Training_loss: 0.41964124590158464 2022-07-01 00:30:48.672194
learning rate:  0.008388608000000004
netparams have been saved once 82
val: 1 0.4335843622684479
val: 2 0.4305013120174408
val: 3 0.4262581765651703
val: 4 0.43143758177757263
val: 5 0.4340326189994812
val: 6 0.436854749917984
val: 7 0.430754691362381
val: 8 0.44577693939208984
val: 9 0.43554121255874634
val: 10 0.43930965662002563
val: 11 0.4306342899799347
val: 12 0.42442047595977783
val: 13 0.4306052029132843
val: 14 0.43070071935653687
val: 15 0.4397179186344147
val: 16 0.43644264340400696
val: 17 0.4486358165740967
val: 18 0.4359033703804016
val: 19 0.4307129681110382
val: 20 0.42945802211761475
val_Epoch:[ 82 ] val_loss: 0.43406413644552233 2022-07-01 00:30:52.458306
start training 2022-07-01 00:30:52.562218
Epoch:[ 83 0 ] loss: 0.41735464334487915 2022-07-01 00:31:06.886173
Epoch:[ 83 1 ] loss: 0.4190824031829834 2022-07-01 00:31:07.326546
Epoch:[ 83 2 ] loss: 0.41485685110092163 2022-07-01 00:31:07.746238
Epoch:[ 83 3 ] loss: 0.42148301005363464 2022-07-01 00:31:08.168417
Epoch:[ 83 4 ] loss: 0.4181843101978302 2022-07-01 00:31:08.589492
Epoch:[ 83 5 ] loss: 0.4202878773212433 2022-07-01 00:31:09.009673
Epoch:[ 83 6 ] loss: 0.4188261032104492 2022-07-01 00:31:09.429779
Epoch:[ 83 7 ] loss: 0.4196682274341583 2022-07-01 00:31:09.850575
Epoch:[ 83 8 ] loss: 0.4189935326576233 2022-07-01 00:31:10.271700
Epoch:[ 83 9 ] loss: 0.41696423292160034 2022-07-01 00:31:10.690930
Epoch:[ 83 10 ] loss: 0.4200884699821472 2022-07-01 00:31:11.112128
Epoch:[ 83 11 ] loss: 0.418797105550766 2022-07-01 00:31:11.533461
Epoch:[ 83 12 ] loss: 0.4215817451477051 2022-07-01 00:31:11.947192
Epoch:[ 83 13 ] loss: 0.4210400879383087 2022-07-01 00:31:12.367132
Epoch:[ 83 14 ] loss: 0.4207864999771118 2022-07-01 00:31:12.788276
Epoch:[ 83 15 ] loss: 0.4202080965042114 2022-07-01 00:31:13.208352
Epoch:[ 83 16 ] loss: 0.4233575761318207 2022-07-01 00:31:18.467220
Epoch:[ 83 17 ] loss: 0.4208551347255707 2022-07-01 00:31:18.888621
Epoch:[ 83 18 ] loss: 0.41520339250564575 2022-07-01 00:31:19.310243
Epoch:[ 83 19 ] loss: 0.4202963709831238 2022-07-01 00:31:19.729286
Training_Epoch:[ 83 ] Training_loss: 0.41939578354358675 2022-07-01 00:31:19.729952
learning rate:  0.008388608000000004
val: 1 0.4397573173046112
val: 2 0.4333566427230835
val: 3 0.4331616461277008
val: 4 0.4502769410610199
val: 5 0.4366302490234375
val: 6 0.4340842366218567
val: 7 0.43308714032173157
val: 8 0.42242297530174255
val: 9 0.44877907633781433
val: 10 0.4459139406681061
val: 11 0.4287816882133484
val: 12 0.432437002658844
val: 13 0.43653690814971924
val: 14 0.43008890748023987
val: 15 0.44094640016555786
val: 16 0.43699881434440613
val: 17 0.4408703148365021
val: 18 0.4307520091533661
val: 19 0.4440343379974365
val: 20 0.4488818645477295
val_Epoch:[ 83 ] val_loss: 0.4373899206519127 2022-07-01 00:31:23.448785
start training 2022-07-01 00:31:23.546010
Epoch:[ 84 0 ] loss: 0.4176129996776581 2022-07-01 00:31:38.330086
Epoch:[ 84 1 ] loss: 0.4213082492351532 2022-07-01 00:31:38.748988
Epoch:[ 84 2 ] loss: 0.4195462167263031 2022-07-01 00:31:39.169067
Epoch:[ 84 3 ] loss: 0.4222400486469269 2022-07-01 00:31:39.588871
Epoch:[ 84 4 ] loss: 0.41880279779434204 2022-07-01 00:31:40.010244
Epoch:[ 84 5 ] loss: 0.4199472665786743 2022-07-01 00:31:40.425544
Epoch:[ 84 6 ] loss: 0.41950249671936035 2022-07-01 00:31:40.844722
Epoch:[ 84 7 ] loss: 0.41958290338516235 2022-07-01 00:31:41.264981
Epoch:[ 84 8 ] loss: 0.4201178252696991 2022-07-01 00:31:41.684416
Epoch:[ 84 9 ] loss: 0.4211820363998413 2022-07-01 00:31:42.102674
Epoch:[ 84 10 ] loss: 0.41977986693382263 2022-07-01 00:31:42.521312
Epoch:[ 84 11 ] loss: 0.4194074869155884 2022-07-01 00:31:42.944488
Epoch:[ 84 12 ] loss: 0.4205126464366913 2022-07-01 00:31:43.366859
Epoch:[ 84 13 ] loss: 0.4185228645801544 2022-07-01 00:31:43.786782
Epoch:[ 84 14 ] loss: 0.4168660044670105 2022-07-01 00:31:44.209453
Epoch:[ 84 15 ] loss: 0.4179579019546509 2022-07-01 00:31:44.630156
Epoch:[ 84 16 ] loss: 0.4188665747642517 2022-07-01 00:31:49.890988
Epoch:[ 84 17 ] loss: 0.41936296224594116 2022-07-01 00:31:50.309096
Epoch:[ 84 18 ] loss: 0.41715365648269653 2022-07-01 00:31:50.731698
Epoch:[ 84 19 ] loss: 0.42089253664016724 2022-07-01 00:31:51.152908
Training_Epoch:[ 84 ] Training_loss: 0.4194582670927048 2022-07-01 00:31:51.153596
learning rate:  0.008388608000000004
netparams have been saved once 84
val: 1 0.4350139796733856
val: 2 0.4318883717060089
val: 3 0.43721845746040344
val: 4 0.43602606654167175
val: 5 0.43434199690818787
val: 6 0.4343182444572449
val: 7 0.44193390011787415
val: 8 0.43523839116096497
val: 9 0.43089428544044495
val: 10 0.4325186014175415
val: 11 0.43318116664886475
val: 12 0.4457505941390991
val: 13 0.4296835958957672
val: 14 0.4326837360858917
val: 15 0.4386332035064697
val: 16 0.42344316840171814
val: 17 0.4369262754917145
val: 18 0.43347278237342834
val: 19 0.43833816051483154
val: 20 0.43611451983451843
val_Epoch:[ 84 ] val_loss: 0.43488097488880156 2022-07-01 00:31:55.033161
start training 2022-07-01 00:31:55.130679
Epoch:[ 85 0 ] loss: 0.4169807732105255 2022-07-01 00:32:09.795471
Epoch:[ 85 1 ] loss: 0.4175572991371155 2022-07-01 00:32:10.215028
Epoch:[ 85 2 ] loss: 0.4178960919380188 2022-07-01 00:32:10.634407
Epoch:[ 85 3 ] loss: 0.4210480749607086 2022-07-01 00:32:11.047938
Epoch:[ 85 4 ] loss: 0.41983094811439514 2022-07-01 00:32:11.468080
Epoch:[ 85 5 ] loss: 0.4189808964729309 2022-07-01 00:32:11.889807
Epoch:[ 85 6 ] loss: 0.41687965393066406 2022-07-01 00:32:12.312823
Epoch:[ 85 7 ] loss: 0.41685739159584045 2022-07-01 00:32:12.733578
Epoch:[ 85 8 ] loss: 0.42007747292518616 2022-07-01 00:32:13.153371
Epoch:[ 85 9 ] loss: 0.41902410984039307 2022-07-01 00:32:13.574791
Epoch:[ 85 10 ] loss: 0.41883933544158936 2022-07-01 00:32:13.995074
Epoch:[ 85 11 ] loss: 0.41796115040779114 2022-07-01 00:32:14.415708
Epoch:[ 85 12 ] loss: 0.4213159680366516 2022-07-01 00:32:14.836414
Epoch:[ 85 13 ] loss: 0.4195229709148407 2022-07-01 00:32:15.273172
Epoch:[ 85 14 ] loss: 0.4177759885787964 2022-07-01 00:32:15.694324
Epoch:[ 85 15 ] loss: 0.4207366406917572 2022-07-01 00:32:16.112131
Epoch:[ 85 16 ] loss: 0.4185120463371277 2022-07-01 00:32:21.285451
Epoch:[ 85 17 ] loss: 0.4156506657600403 2022-07-01 00:32:21.704577
Epoch:[ 85 18 ] loss: 0.4189547896385193 2022-07-01 00:32:22.125140
Epoch:[ 85 19 ] loss: 0.41872164607048035 2022-07-01 00:32:22.547275
Training_Epoch:[ 85 ] Training_loss: 0.4186561957001686 2022-07-01 00:32:22.547915
learning rate:  0.008388608000000004
val: 1 0.43534138798713684
val: 2 0.43701836466789246
val: 3 0.4356403648853302
val: 4 0.43437036871910095
val: 5 0.42825913429260254
val: 6 0.4362363815307617
val: 7 0.42942455410957336
val: 8 0.44200393557548523
val: 9 0.4373479187488556
val: 10 0.43552732467651367
val: 11 0.4374992251396179
val: 12 0.43532583117485046
val: 13 0.44083699584007263
val: 14 0.4285077154636383
val: 15 0.4335726201534271
val: 16 0.43346402049064636
val: 17 0.43270957469940186
val: 18 0.4443059265613556
val: 19 0.44194015860557556
val: 20 0.4420170783996582
val_Epoch:[ 85 ] val_loss: 0.43606744408607484 2022-07-01 00:32:26.298000
start training 2022-07-01 00:32:26.398602
Epoch:[ 86 0 ] loss: 0.41731321811676025 2022-07-01 00:32:41.300098
Epoch:[ 86 1 ] loss: 0.4169558584690094 2022-07-01 00:32:41.720590
Epoch:[ 86 2 ] loss: 0.4189543128013611 2022-07-01 00:32:42.140822
Epoch:[ 86 3 ] loss: 0.4178515672683716 2022-07-01 00:32:42.554866
Epoch:[ 86 4 ] loss: 0.42047321796417236 2022-07-01 00:32:42.976962
Epoch:[ 86 5 ] loss: 0.41940921545028687 2022-07-01 00:32:43.395461
Epoch:[ 86 6 ] loss: 0.4174312353134155 2022-07-01 00:32:43.816737
Epoch:[ 86 7 ] loss: 0.4164426922798157 2022-07-01 00:32:44.238835
Epoch:[ 86 8 ] loss: 0.41971394419670105 2022-07-01 00:32:44.659226
Epoch:[ 86 9 ] loss: 0.4175606966018677 2022-07-01 00:32:45.079325
Epoch:[ 86 10 ] loss: 0.4193091094493866 2022-07-01 00:32:45.493361
Epoch:[ 86 11 ] loss: 0.41967862844467163 2022-07-01 00:32:45.913656
Epoch:[ 86 12 ] loss: 0.41672131419181824 2022-07-01 00:32:46.333770
Epoch:[ 86 13 ] loss: 0.4224716126918793 2022-07-01 00:32:46.754215
Epoch:[ 86 14 ] loss: 0.41768813133239746 2022-07-01 00:32:47.176700
Epoch:[ 86 15 ] loss: 0.42016735672950745 2022-07-01 00:32:47.597890
Epoch:[ 86 16 ] loss: 0.41814887523651123 2022-07-01 00:32:52.722691
Epoch:[ 86 17 ] loss: 0.41861507296562195 2022-07-01 00:32:53.142259
Epoch:[ 86 18 ] loss: 0.4175868034362793 2022-07-01 00:32:53.563560
Epoch:[ 86 19 ] loss: 0.4188328683376312 2022-07-01 00:32:53.983802
Training_Epoch:[ 86 ] Training_loss: 0.4185662865638733 2022-07-01 00:32:53.984493
learning rate:  0.008388608000000004
netparams have been saved once 86
val: 1 0.44305816292762756
val: 2 0.4257793724536896
val: 3 0.43824952840805054
val: 4 0.43671685457229614
val: 5 0.4382849633693695
val: 6 0.43310073018074036
val: 7 0.43145737051963806
val: 8 0.4340203106403351
val: 9 0.4385254383087158
val: 10 0.4341844916343689
val: 11 0.4256197214126587
val: 12 0.43598461151123047
val: 13 0.4346224069595337
val: 14 0.4341089427471161
val: 15 0.4331837296485901
val: 16 0.4360286295413971
val: 17 0.4403970539569855
val: 18 0.4392656087875366
val: 19 0.4271046221256256
val: 20 0.43574976921081543
val_Epoch:[ 86 ] val_loss: 0.43477211594581605 2022-07-01 00:32:57.765341
start training 2022-07-01 00:32:57.862207
Epoch:[ 87 0 ] loss: 0.41946670413017273 2022-07-01 00:33:11.693064
Epoch:[ 87 1 ] loss: 0.419032484292984 2022-07-01 00:33:12.135171
Epoch:[ 87 2 ] loss: 0.41767168045043945 2022-07-01 00:33:12.561873
Epoch:[ 87 3 ] loss: 0.41614773869514465 2022-07-01 00:33:12.981766
Epoch:[ 87 4 ] loss: 0.418194055557251 2022-07-01 00:33:13.403252
Epoch:[ 87 5 ] loss: 0.4189174473285675 2022-07-01 00:33:13.823182
Epoch:[ 87 6 ] loss: 0.4141443073749542 2022-07-01 00:33:14.243214
Epoch:[ 87 7 ] loss: 0.41898486018180847 2022-07-01 00:33:14.667772
Epoch:[ 87 8 ] loss: 0.41603395342826843 2022-07-01 00:33:15.089504
Epoch:[ 87 9 ] loss: 0.41520869731903076 2022-07-01 00:33:15.510342
Epoch:[ 87 10 ] loss: 0.4190225601196289 2022-07-01 00:33:15.933493
Epoch:[ 87 11 ] loss: 0.4181346595287323 2022-07-01 00:33:16.355645
Epoch:[ 87 12 ] loss: 0.41784974932670593 2022-07-01 00:33:16.776443
Epoch:[ 87 13 ] loss: 0.4215802550315857 2022-07-01 00:33:17.196436
Epoch:[ 87 14 ] loss: 0.4168741703033447 2022-07-01 00:33:17.618809
Epoch:[ 87 15 ] loss: 0.41562148928642273 2022-07-01 00:33:18.042187
Epoch:[ 87 16 ] loss: 0.42057162523269653 2022-07-01 00:33:23.986780
Epoch:[ 87 17 ] loss: 0.42169514298439026 2022-07-01 00:33:24.406327
Epoch:[ 87 18 ] loss: 0.41870179772377014 2022-07-01 00:33:24.830451
Epoch:[ 87 19 ] loss: 0.42036646604537964 2022-07-01 00:33:25.250785
Training_Epoch:[ 87 ] Training_loss: 0.4182109922170639 2022-07-01 00:33:25.251501
learning rate:  0.008388608000000004
val: 1 0.4374393820762634
val: 2 0.4315212070941925
val: 3 0.432921826839447
val: 4 0.4435027539730072
val: 5 0.43086209893226624
val: 6 0.43698740005493164
val: 7 0.4306442439556122
val: 8 0.4462815225124359
val: 9 0.42631715536117554
val: 10 0.43572497367858887
val: 11 0.43203434348106384
val: 12 0.44204410910606384
val: 13 0.4441585838794708
val: 14 0.441440224647522
val: 15 0.4406175911426544
val: 16 0.437744677066803
val: 17 0.43412357568740845
val: 18 0.43520429730415344
val: 19 0.43221503496170044
val: 20 0.44201719760894775
val_Epoch:[ 87 ] val_loss: 0.4366901099681854 2022-07-01 00:33:29.062742
start training 2022-07-01 00:33:29.161692
Epoch:[ 88 0 ] loss: 0.4209299385547638 2022-07-01 00:33:44.040218
Epoch:[ 88 1 ] loss: 0.4170878231525421 2022-07-01 00:33:44.461226
Epoch:[ 88 2 ] loss: 0.4166480004787445 2022-07-01 00:33:44.882877
Epoch:[ 88 3 ] loss: 0.4187462031841278 2022-07-01 00:33:45.303118
Epoch:[ 88 4 ] loss: 0.4161447286605835 2022-07-01 00:33:45.723625
Epoch:[ 88 5 ] loss: 0.41576024889945984 2022-07-01 00:33:46.138323
Epoch:[ 88 6 ] loss: 0.4163294732570648 2022-07-01 00:33:46.558340
Epoch:[ 88 7 ] loss: 0.41980332136154175 2022-07-01 00:33:46.978916
Epoch:[ 88 8 ] loss: 0.41573646664619446 2022-07-01 00:33:47.400641
Epoch:[ 88 9 ] loss: 0.4168628454208374 2022-07-01 00:33:47.821600
Epoch:[ 88 10 ] loss: 0.4187661111354828 2022-07-01 00:33:48.242225
Epoch:[ 88 11 ] loss: 0.42018598318099976 2022-07-01 00:33:48.662152
Epoch:[ 88 12 ] loss: 0.4179895520210266 2022-07-01 00:33:49.083855
Epoch:[ 88 13 ] loss: 0.4181518256664276 2022-07-01 00:33:49.503945
Epoch:[ 88 14 ] loss: 0.41897305846214294 2022-07-01 00:33:49.923853
Epoch:[ 88 15 ] loss: 0.4181225895881653 2022-07-01 00:33:50.346661
Epoch:[ 88 16 ] loss: 0.4184516668319702 2022-07-01 00:33:55.514009
Epoch:[ 88 17 ] loss: 0.42053699493408203 2022-07-01 00:33:55.933568
Epoch:[ 88 18 ] loss: 0.4187072813510895 2022-07-01 00:33:56.353822
Epoch:[ 88 19 ] loss: 0.4179728329181671 2022-07-01 00:33:56.774921
Training_Epoch:[ 88 ] Training_loss: 0.4180953472852707 2022-07-01 00:33:56.775609
learning rate:  0.008388608000000004
netparams have been saved once 88
val: 1 0.4370834529399872
val: 2 0.426140695810318
val: 3 0.42414015531539917
val: 4 0.44506508111953735
val: 5 0.43083643913269043
val: 6 0.4184669554233551
val: 7 0.4443482458591461
val: 8 0.4344364106655121
val: 9 0.43449458479881287
val: 10 0.4446446895599365
val: 11 0.44285181164741516
val: 12 0.4446287155151367
val: 13 0.4441945552825928
val: 14 0.44899246096611023
val: 15 0.4353542923927307
val: 16 0.4549412429332733
val: 17 0.43418216705322266
val: 18 0.4394140839576721
val: 19 0.4429604113101959
val: 20 0.4347411096096039
val_Epoch:[ 88 ] val_loss: 0.4380958780646324 2022-07-01 00:34:00.609982
start training 2022-07-01 00:34:00.709217
Epoch:[ 89 0 ] loss: 0.41808101534843445 2022-07-01 00:34:15.337087
Epoch:[ 89 1 ] loss: 0.41943269968032837 2022-07-01 00:34:15.757094
Epoch:[ 89 2 ] loss: 0.4150902032852173 2022-07-01 00:34:16.179193
Epoch:[ 89 3 ] loss: 0.41960686445236206 2022-07-01 00:34:16.600728
Epoch:[ 89 4 ] loss: 0.4207107126712799 2022-07-01 00:34:17.022640
Epoch:[ 89 5 ] loss: 0.420131117105484 2022-07-01 00:34:17.442090
Epoch:[ 89 6 ] loss: 0.4161698520183563 2022-07-01 00:34:17.865317
Epoch:[ 89 7 ] loss: 0.4178179204463959 2022-07-01 00:34:18.284660
Epoch:[ 89 8 ] loss: 0.417806476354599 2022-07-01 00:34:18.703923
Epoch:[ 89 9 ] loss: 0.41970720887184143 2022-07-01 00:34:19.119924
Epoch:[ 89 10 ] loss: 0.41851767897605896 2022-07-01 00:34:19.542446
Epoch:[ 89 11 ] loss: 0.4172593355178833 2022-07-01 00:34:19.965205
Epoch:[ 89 12 ] loss: 0.4173011779785156 2022-07-01 00:34:20.388180
Epoch:[ 89 13 ] loss: 0.41623833775520325 2022-07-01 00:34:20.802280
Epoch:[ 89 14 ] loss: 0.42148342728614807 2022-07-01 00:34:21.223529
Epoch:[ 89 15 ] loss: 0.4180851876735687 2022-07-01 00:34:21.643589
Epoch:[ 89 16 ] loss: 0.4200192391872406 2022-07-01 00:34:26.859879
Epoch:[ 89 17 ] loss: 0.41842228174209595 2022-07-01 00:34:27.284235
Epoch:[ 89 18 ] loss: 0.4166926443576813 2022-07-01 00:34:27.712657
Epoch:[ 89 19 ] loss: 0.4178624153137207 2022-07-01 00:34:28.134502
Training_Epoch:[ 89 ] Training_loss: 0.4183217898011208 2022-07-01 00:34:28.135275
learning rate:  0.008388608000000004
val: 1 0.43312275409698486
val: 2 0.4323897361755371
val: 3 0.42829376459121704
val: 4 0.44824331998825073
val: 5 0.43180355429649353
val: 6 0.4444228708744049
val: 7 0.43494319915771484
val: 8 0.4471338987350464
val: 9 0.4463115930557251
val: 10 0.4346649944782257
val: 11 0.44089144468307495
val: 12 0.4422365427017212
val: 13 0.44805896282196045
val: 14 0.43936267495155334
val: 15 0.43029728531837463
val: 16 0.4394095540046692
val: 17 0.4340285360813141
val: 18 0.4324369728565216
val: 19 0.43551185727119446
val: 20 0.4299740195274353
val_Epoch:[ 89 ] val_loss: 0.43767687678337097 2022-07-01 00:34:31.873168
start training 2022-07-01 00:34:31.976703
Epoch:[ 90 0 ] loss: 0.4167460799217224 2022-07-01 00:34:46.197761
Epoch:[ 90 1 ] loss: 0.41854605078697205 2022-07-01 00:34:46.621137
Epoch:[ 90 2 ] loss: 0.4200487732887268 2022-07-01 00:34:47.028657
Epoch:[ 90 3 ] loss: 0.41386061906814575 2022-07-01 00:34:47.437615
Epoch:[ 90 4 ] loss: 0.4167649745941162 2022-07-01 00:34:47.848443
Epoch:[ 90 5 ] loss: 0.4158667027950287 2022-07-01 00:34:48.256192
Epoch:[ 90 6 ] loss: 0.41848719120025635 2022-07-01 00:34:48.666172
Epoch:[ 90 7 ] loss: 0.4201779365539551 2022-07-01 00:34:49.087207
Epoch:[ 90 8 ] loss: 0.41848069429397583 2022-07-01 00:34:49.508227
Epoch:[ 90 9 ] loss: 0.4179385304450989 2022-07-01 00:34:49.927400
Epoch:[ 90 10 ] loss: 0.4185492992401123 2022-07-01 00:34:50.350059
Epoch:[ 90 11 ] loss: 0.41636568307876587 2022-07-01 00:34:50.771393
Epoch:[ 90 12 ] loss: 0.41768425703048706 2022-07-01 00:34:51.191478
Epoch:[ 90 13 ] loss: 0.41578325629234314 2022-07-01 00:34:51.610681
Epoch:[ 90 14 ] loss: 0.4162481427192688 2022-07-01 00:34:52.025899
Epoch:[ 90 15 ] loss: 0.41669657826423645 2022-07-01 00:34:52.446214
Epoch:[ 90 16 ] loss: 0.41848278045654297 2022-07-01 00:34:58.273546
Epoch:[ 90 17 ] loss: 0.42030203342437744 2022-07-01 00:34:58.695277
Epoch:[ 90 18 ] loss: 0.41815564036369324 2022-07-01 00:34:59.124033
Epoch:[ 90 19 ] loss: 0.4178118407726288 2022-07-01 00:34:59.545152
Training_Epoch:[ 90 ] Training_loss: 0.4176498532295227 2022-07-01 00:34:59.545875
learning rate:  0.008388608000000004
netparams have been saved once 90
val: 1 0.43450114130973816
val: 2 0.43564528226852417
val: 3 0.4318188726902008
val: 4 0.43160000443458557
val: 5 0.42914384603500366
val: 6 0.4290657341480255
val: 7 0.42655932903289795
val: 8 0.4319867193698883
val: 9 0.43761396408081055
val: 10 0.42835038900375366
val: 11 0.43663081526756287
val: 12 0.4335334002971649
val: 13 0.4264127016067505
val: 14 0.4311942160129547
val: 15 0.42827752232551575
val: 16 0.4450385570526123
val: 17 0.4395516812801361
val: 18 0.4342593252658844
val: 19 0.43541550636291504
val: 20 0.4402097463607788
val_Epoch:[ 90 ] val_loss: 0.4333404377102852 2022-07-01 00:35:03.373597
start training 2022-07-01 00:35:03.471090
Epoch:[ 91 0 ] loss: 0.415396511554718 2022-07-01 00:35:18.000252
Epoch:[ 91 1 ] loss: 0.41475874185562134 2022-07-01 00:35:18.419931
Epoch:[ 91 2 ] loss: 0.4161118268966675 2022-07-01 00:35:18.840615
Epoch:[ 91 3 ] loss: 0.41325315833091736 2022-07-01 00:35:19.260535
Epoch:[ 91 4 ] loss: 0.413971871137619 2022-07-01 00:35:19.675892
Epoch:[ 91 5 ] loss: 0.4147656261920929 2022-07-01 00:35:20.098838
Epoch:[ 91 6 ] loss: 0.41363444924354553 2022-07-01 00:35:20.519117
Epoch:[ 91 7 ] loss: 0.4149845242500305 2022-07-01 00:35:20.935373
Epoch:[ 91 8 ] loss: 0.4152226746082306 2022-07-01 00:35:21.357124
Epoch:[ 91 9 ] loss: 0.41373276710510254 2022-07-01 00:35:21.777122
Epoch:[ 91 10 ] loss: 0.4154510200023651 2022-07-01 00:35:22.197197
Epoch:[ 91 11 ] loss: 0.4179166555404663 2022-07-01 00:35:22.619039
Epoch:[ 91 12 ] loss: 0.41616106033325195 2022-07-01 00:35:23.040606
Epoch:[ 91 13 ] loss: 0.41168105602264404 2022-07-01 00:35:23.460191
Epoch:[ 91 14 ] loss: 0.4173719882965088 2022-07-01 00:35:23.880202
Epoch:[ 91 15 ] loss: 0.41476359963417053 2022-07-01 00:35:24.301858
Epoch:[ 91 16 ] loss: 0.4156187176704407 2022-07-01 00:35:29.791023
Epoch:[ 91 17 ] loss: 0.416792631149292 2022-07-01 00:35:30.214449
Epoch:[ 91 18 ] loss: 0.41857439279556274 2022-07-01 00:35:30.636539
Epoch:[ 91 19 ] loss: 0.41724058985710144 2022-07-01 00:35:31.058343
Training_Epoch:[ 91 ] Training_loss: 0.41537019312381745 2022-07-01 00:35:31.059028
learning rate:  0.006710886400000004
val: 1 0.4346860647201538
val: 2 0.4328237473964691
val: 3 0.4278494119644165
val: 4 0.43608319759368896
val: 5 0.44198188185691833
val: 6 0.4279101490974426
val: 7 0.43838199973106384
val: 8 0.44052770733833313
val: 9 0.44085338711738586
val: 10 0.43527382612228394
val: 11 0.4343302845954895
val: 12 0.4326815903186798
val: 13 0.43458911776542664
val: 14 0.4413383901119232
val: 15 0.43197575211524963
val: 16 0.433126837015152
val: 17 0.4339233338832855
val: 18 0.42946773767471313
val: 19 0.4319366216659546
val: 20 0.42858177423477173
val_Epoch:[ 91 ] val_loss: 0.4344161406159401 2022-07-01 00:35:34.841902
start training 2022-07-01 00:35:34.940494
Epoch:[ 92 0 ] loss: 0.41404885053634644 2022-07-01 00:35:49.704077
Epoch:[ 92 1 ] loss: 0.4132901132106781 2022-07-01 00:35:50.123489
Epoch:[ 92 2 ] loss: 0.4126293957233429 2022-07-01 00:35:50.544515
Epoch:[ 92 3 ] loss: 0.4143185317516327 2022-07-01 00:35:50.965547
Epoch:[ 92 4 ] loss: 0.414569616317749 2022-07-01 00:35:51.385305
Epoch:[ 92 5 ] loss: 0.4149087965488434 2022-07-01 00:35:51.808962
Epoch:[ 92 6 ] loss: 0.41653507947921753 2022-07-01 00:35:52.231418
Epoch:[ 92 7 ] loss: 0.41762739419937134 2022-07-01 00:35:52.655325
Epoch:[ 92 8 ] loss: 0.4147992730140686 2022-07-01 00:35:53.078094
Epoch:[ 92 9 ] loss: 0.41399985551834106 2022-07-01 00:35:53.498163
Epoch:[ 92 10 ] loss: 0.4123767912387848 2022-07-01 00:35:53.919504
Epoch:[ 92 11 ] loss: 0.4114788770675659 2022-07-01 00:35:54.338822
Epoch:[ 92 12 ] loss: 0.41596293449401855 2022-07-01 00:35:54.760741
Epoch:[ 92 13 ] loss: 0.4163726568222046 2022-07-01 00:35:55.177008
Epoch:[ 92 14 ] loss: 0.41925114393234253 2022-07-01 00:35:55.598008
Epoch:[ 92 15 ] loss: 0.4165998101234436 2022-07-01 00:35:56.018833
Epoch:[ 92 16 ] loss: 0.4151186943054199 2022-07-01 00:36:01.198274
Epoch:[ 92 17 ] loss: 0.4162515699863434 2022-07-01 00:36:01.617081
Epoch:[ 92 18 ] loss: 0.4112657904624939 2022-07-01 00:36:02.037940
Epoch:[ 92 19 ] loss: 0.4199189841747284 2022-07-01 00:36:02.459509
Training_Epoch:[ 92 ] Training_loss: 0.4150662079453468 2022-07-01 00:36:02.460154
learning rate:  0.006710886400000004
netparams have been saved once 92
val: 1 0.4269903004169464
val: 2 0.43860924243927
val: 3 0.43316736817359924
val: 4 0.43910452723503113
val: 5 0.43905091285705566
val: 6 0.4271364212036133
val: 7 0.4463232159614563
val: 8 0.44209474325180054
val: 9 0.42666083574295044
val: 10 0.4372981786727905
val: 11 0.4344780743122101
val: 12 0.43696045875549316
val: 13 0.43155983090400696
val: 14 0.438551127910614
val: 15 0.43529781699180603
val: 16 0.43811702728271484
val: 17 0.41860005259513855
val: 18 0.4302084743976593
val: 19 0.44131553173065186
val: 20 0.43085795640945435
val_Epoch:[ 92 ] val_loss: 0.4346191048622131 2022-07-01 00:36:06.260645
start training 2022-07-01 00:36:06.360503
Epoch:[ 93 0 ] loss: 0.4136311411857605 2022-07-01 00:36:20.370661
Epoch:[ 93 1 ] loss: 0.4142098128795624 2022-07-01 00:36:20.809182
Epoch:[ 93 2 ] loss: 0.4157942235469818 2022-07-01 00:36:21.230474
Epoch:[ 93 3 ] loss: 0.41269752383232117 2022-07-01 00:36:21.640149
Epoch:[ 93 4 ] loss: 0.4140205681324005 2022-07-01 00:36:22.048890
Epoch:[ 93 5 ] loss: 0.41361626982688904 2022-07-01 00:36:22.456852
Epoch:[ 93 6 ] loss: 0.4162188768386841 2022-07-01 00:36:22.868352
Epoch:[ 93 7 ] loss: 0.4140143096446991 2022-07-01 00:36:23.279260
Epoch:[ 93 8 ] loss: 0.41306495666503906 2022-07-01 00:36:23.689053
Epoch:[ 93 9 ] loss: 0.41673868894577026 2022-07-01 00:36:24.097257
Epoch:[ 93 10 ] loss: 0.4133524000644684 2022-07-01 00:36:24.507742
Epoch:[ 93 11 ] loss: 0.41504940390586853 2022-07-01 00:36:24.927032
Epoch:[ 93 12 ] loss: 0.4144098162651062 2022-07-01 00:36:25.334463
Epoch:[ 93 13 ] loss: 0.4135842025279999 2022-07-01 00:36:25.743928
Epoch:[ 93 14 ] loss: 0.41358035802841187 2022-07-01 00:36:26.154996
Epoch:[ 93 15 ] loss: 0.4191793203353882 2022-07-01 00:36:26.567252
Epoch:[ 93 16 ] loss: 0.4152466356754303 2022-07-01 00:36:32.477377
Epoch:[ 93 17 ] loss: 0.41548362374305725 2022-07-01 00:36:32.887969
Epoch:[ 93 18 ] loss: 0.4140775203704834 2022-07-01 00:36:33.309741
Epoch:[ 93 19 ] loss: 0.41627073287963867 2022-07-01 00:36:33.729503
Training_Epoch:[ 93 ] Training_loss: 0.41471201926469803 2022-07-01 00:36:33.730318
learning rate:  0.006710886400000004
val: 1 0.4429013431072235
val: 2 0.43625032901763916
val: 3 0.4435359239578247
val: 4 0.43705835938453674
val: 5 0.420735627412796
val: 6 0.4314288794994354
val: 7 0.4364003837108612
val: 8 0.42725130915641785
val: 9 0.4328707158565521
val: 10 0.4525362253189087
val: 11 0.44598132371902466
val: 12 0.43636807799339294
val: 13 0.43343475461006165
val: 14 0.42770496010780334
val: 15 0.43878060579299927
val: 16 0.42903241515159607
val: 17 0.42822447419166565
val: 18 0.4310528337955475
val: 19 0.43082913756370544
val: 20 0.4417322874069214
val_Epoch:[ 93 ] val_loss: 0.4352054983377457 2022-07-01 00:36:37.510364
start training 2022-07-01 00:36:37.610753
Epoch:[ 94 0 ] loss: 0.415725439786911 2022-07-01 00:36:52.055504
Epoch:[ 94 1 ] loss: 0.4134111702442169 2022-07-01 00:36:52.489788
Epoch:[ 94 2 ] loss: 0.41290295124053955 2022-07-01 00:36:52.913417
Epoch:[ 94 3 ] loss: 0.41197511553764343 2022-07-01 00:36:53.333094
Epoch:[ 94 4 ] loss: 0.4134872257709503 2022-07-01 00:36:53.753040
Epoch:[ 94 5 ] loss: 0.41224825382232666 2022-07-01 00:36:54.172761
Epoch:[ 94 6 ] loss: 0.4154263138771057 2022-07-01 00:36:54.586528
Epoch:[ 94 7 ] loss: 0.4113803505897522 2022-07-01 00:36:54.998879
Epoch:[ 94 8 ] loss: 0.4171309471130371 2022-07-01 00:36:55.407754
Epoch:[ 94 9 ] loss: 0.4129320979118347 2022-07-01 00:36:55.816743
Epoch:[ 94 10 ] loss: 0.4136843681335449 2022-07-01 00:36:56.224320
Epoch:[ 94 11 ] loss: 0.41608238220214844 2022-07-01 00:36:56.640735
Epoch:[ 94 12 ] loss: 0.4142327904701233 2022-07-01 00:36:57.049045
Epoch:[ 94 13 ] loss: 0.4150199592113495 2022-07-01 00:36:57.461173
Epoch:[ 94 14 ] loss: 0.4157712161540985 2022-07-01 00:36:57.873216
Epoch:[ 94 15 ] loss: 0.4120193421840668 2022-07-01 00:36:58.283474
Epoch:[ 94 16 ] loss: 0.4148387312889099 2022-07-01 00:37:03.740730
Epoch:[ 94 17 ] loss: 0.41482168436050415 2022-07-01 00:37:04.147731
Epoch:[ 94 18 ] loss: 0.4161563813686371 2022-07-01 00:37:04.577942
Epoch:[ 94 19 ] loss: 0.41384896636009216 2022-07-01 00:37:05.000518
Training_Epoch:[ 94 ] Training_loss: 0.41415478438138964 2022-07-01 00:37:05.001252
learning rate:  0.006710886400000004
netparams have been saved once 94
val: 1 0.4310914874076843
val: 2 0.4467819035053253
val: 3 0.4423845410346985
val: 4 0.42967846989631653
val: 5 0.43711912631988525
val: 6 0.4305391311645508
val: 7 0.43869319558143616
val: 8 0.4474588930606842
val: 9 0.4343213737010956
val: 10 0.4232303500175476
val: 11 0.42865586280822754
val: 12 0.4314160645008087
val: 13 0.436489462852478
val: 14 0.4384075403213501
val: 15 0.43253034353256226
val: 16 0.4388362467288971
val: 17 0.4328150153160095
val: 18 0.4414459764957428
val: 19 0.4474897086620331
val: 20 0.435783326625824
val_Epoch:[ 94 ] val_loss: 0.43625840097665786 2022-07-01 00:37:08.816278
start training 2022-07-01 00:37:08.915226
Epoch:[ 95 0 ] loss: 0.41111892461776733 2022-07-01 00:37:23.240318
Epoch:[ 95 1 ] loss: 0.41426214575767517 2022-07-01 00:37:23.669436
Epoch:[ 95 2 ] loss: 0.41110309958457947 2022-07-01 00:37:24.092419
Epoch:[ 95 3 ] loss: 0.41768625378608704 2022-07-01 00:37:24.515731
Epoch:[ 95 4 ] loss: 0.41400429606437683 2022-07-01 00:37:24.935946
Epoch:[ 95 5 ] loss: 0.4178987443447113 2022-07-01 00:37:25.355254
Epoch:[ 95 6 ] loss: 0.4127870202064514 2022-07-01 00:37:25.776308
Epoch:[ 95 7 ] loss: 0.4126838147640228 2022-07-01 00:37:26.189606
Epoch:[ 95 8 ] loss: 0.41364580392837524 2022-07-01 00:37:26.611313
Epoch:[ 95 9 ] loss: 0.41413503885269165 2022-07-01 00:37:27.033675
Epoch:[ 95 10 ] loss: 0.4143093526363373 2022-07-01 00:37:27.453845
Epoch:[ 95 11 ] loss: 0.4134012460708618 2022-07-01 00:37:27.876287
Epoch:[ 95 12 ] loss: 0.413101464509964 2022-07-01 00:37:28.295860
Epoch:[ 95 13 ] loss: 0.41305968165397644 2022-07-01 00:37:28.715043
Epoch:[ 95 14 ] loss: 0.4160316288471222 2022-07-01 00:37:29.139801
Epoch:[ 95 15 ] loss: 0.413632333278656 2022-07-01 00:37:29.555447
Epoch:[ 95 16 ] loss: 0.4150277376174927 2022-07-01 00:37:34.824004
Epoch:[ 95 17 ] loss: 0.41468939185142517 2022-07-01 00:37:35.243685
Epoch:[ 95 18 ] loss: 0.41701626777648926 2022-07-01 00:37:35.663836
Epoch:[ 95 19 ] loss: 0.414976567029953 2022-07-01 00:37:36.083741
Training_Epoch:[ 95 ] Training_loss: 0.4142285406589508 2022-07-01 00:37:36.084401
learning rate:  0.006710886400000004
val: 1 0.4312111437320709
val: 2 0.4281938076019287
val: 3 0.4374080002307892
val: 4 0.4471163749694824
val: 5 0.43238335847854614
val: 6 0.43361544609069824
val: 7 0.43099161982536316
val: 8 0.42361268401145935
val: 9 0.43285873532295227
val: 10 0.4385974705219269
val: 11 0.4361540377140045
val: 12 0.4299079179763794
val: 13 0.4347003102302551
val: 14 0.4214385449886322
val: 15 0.42692890763282776
val: 16 0.43966999650001526
val: 17 0.44591352343559265
val: 18 0.43216758966445923
val: 19 0.42944425344467163
val: 20 0.4398066997528076
val_Epoch:[ 95 ] val_loss: 0.43360602110624313 2022-07-01 00:37:39.865059
start training 2022-07-01 00:37:39.962815
Epoch:[ 96 0 ] loss: 0.4130610227584839 2022-07-01 00:37:54.410350
Epoch:[ 96 1 ] loss: 0.4156249165534973 2022-07-01 00:37:54.840659
Epoch:[ 96 2 ] loss: 0.4123249351978302 2022-07-01 00:37:55.249287
Epoch:[ 96 3 ] loss: 0.41475263237953186 2022-07-01 00:37:55.659988
Epoch:[ 96 4 ] loss: 0.41203784942626953 2022-07-01 00:37:56.068979
Epoch:[ 96 5 ] loss: 0.4123947024345398 2022-07-01 00:37:56.476869
Epoch:[ 96 6 ] loss: 0.41267791390419006 2022-07-01 00:37:56.892218
Epoch:[ 96 7 ] loss: 0.4112689793109894 2022-07-01 00:37:57.299334
Epoch:[ 96 8 ] loss: 0.40952757000923157 2022-07-01 00:37:57.708390
Epoch:[ 96 9 ] loss: 0.41394147276878357 2022-07-01 00:37:58.117609
Epoch:[ 96 10 ] loss: 0.41352221369743347 2022-07-01 00:37:58.527254
Epoch:[ 96 11 ] loss: 0.4137762784957886 2022-07-01 00:37:58.945672
Epoch:[ 96 12 ] loss: 0.413831889629364 2022-07-01 00:37:59.354220
Epoch:[ 96 13 ] loss: 0.4132530391216278 2022-07-01 00:37:59.763107
Epoch:[ 96 14 ] loss: 0.4143357276916504 2022-07-01 00:38:00.175645
Epoch:[ 96 15 ] loss: 0.4142951965332031 2022-07-01 00:38:00.584767
Epoch:[ 96 16 ] loss: 0.4126726984977722 2022-07-01 00:38:05.994772
Epoch:[ 96 17 ] loss: 0.41470959782600403 2022-07-01 00:38:06.404842
Epoch:[ 96 18 ] loss: 0.41551274061203003 2022-07-01 00:38:06.835559
Epoch:[ 96 19 ] loss: 0.41312649846076965 2022-07-01 00:38:07.253253
Training_Epoch:[ 96 ] Training_loss: 0.4133323937654495 2022-07-01 00:38:07.253995
learning rate:  0.006710886400000004
netparams have been saved once 96
val: 1 0.43706345558166504
val: 2 0.43746206164360046
val: 3 0.4352501928806305
val: 4 0.4287567436695099
val: 5 0.4308275282382965
val: 6 0.43780744075775146
val: 7 0.43549564480781555
val: 8 0.4372205436229706
val: 9 0.43705034255981445
val: 10 0.4327433705329895
val: 11 0.43655914068222046
val: 12 0.4342329800128937
val: 13 0.4374639689922333
val: 14 0.42372989654541016
val: 15 0.4203401505947113
val: 16 0.43343934416770935
val: 17 0.4349077045917511
val: 18 0.4286905825138092
val: 19 0.4261597692966461
val: 20 0.44492465257644653
val_Epoch:[ 96 ] val_loss: 0.43350627571344375 2022-07-01 00:38:11.131320
start training 2022-07-01 00:38:11.234738
Epoch:[ 97 0 ] loss: 0.4133914113044739 2022-07-01 00:38:25.652844
Epoch:[ 97 1 ] loss: 0.4152367413043976 2022-07-01 00:38:26.093566
Epoch:[ 97 2 ] loss: 0.4110981822013855 2022-07-01 00:38:26.502049
Epoch:[ 97 3 ] loss: 0.41392239928245544 2022-07-01 00:38:26.918374
Epoch:[ 97 4 ] loss: 0.4105301797389984 2022-07-01 00:38:27.328141
Epoch:[ 97 5 ] loss: 0.4134463667869568 2022-07-01 00:38:27.738724
Epoch:[ 97 6 ] loss: 0.4132153391838074 2022-07-01 00:38:28.146456
Epoch:[ 97 7 ] loss: 0.41310685873031616 2022-07-01 00:38:28.555326
Epoch:[ 97 8 ] loss: 0.41124799847602844 2022-07-01 00:38:28.965000
Epoch:[ 97 9 ] loss: 0.4145624041557312 2022-07-01 00:38:29.372834
Epoch:[ 97 10 ] loss: 0.4144989848136902 2022-07-01 00:38:29.782932
Epoch:[ 97 11 ] loss: 0.41609618067741394 2022-07-01 00:38:30.192940
Epoch:[ 97 12 ] loss: 0.41349172592163086 2022-07-01 00:38:30.602044
Epoch:[ 97 13 ] loss: 0.410342276096344 2022-07-01 00:38:31.009479
Epoch:[ 97 14 ] loss: 0.4115212857723236 2022-07-01 00:38:31.417443
Epoch:[ 97 15 ] loss: 0.41574305295944214 2022-07-01 00:38:31.826005
Epoch:[ 97 16 ] loss: 0.41382452845573425 2022-07-01 00:38:37.481489
Epoch:[ 97 17 ] loss: 0.41370269656181335 2022-07-01 00:38:37.890129
Epoch:[ 97 18 ] loss: 0.4140966832637787 2022-07-01 00:38:38.313630
Epoch:[ 97 19 ] loss: 0.41540926694869995 2022-07-01 00:38:38.733608
Training_Epoch:[ 97 ] Training_loss: 0.4134242281317711 2022-07-01 00:38:38.734394
learning rate:  0.006710886400000004
val: 1 0.43219828605651855
val: 2 0.44056445360183716
val: 3 0.4463018476963043
val: 4 0.4363408386707306
val: 5 0.43707966804504395
val: 6 0.43314242362976074
val: 7 0.4432145357131958
val: 8 0.4343869388103485
val: 9 0.43141302466392517
val: 10 0.43721452355384827
val: 11 0.4324605166912079
val: 12 0.41739845275878906
val: 13 0.43509095907211304
val: 14 0.4300779104232788
val: 15 0.44029659032821655
val: 16 0.4356843829154968
val: 17 0.43039533495903015
val: 18 0.442409485578537
val: 19 0.44876527786254883
val: 20 0.4294227361679077
val_Epoch:[ 97 ] val_loss: 0.43569290935993193 2022-07-01 00:38:42.482803
start training 2022-07-01 00:38:42.584115
Epoch:[ 98 0 ] loss: 0.4125622808933258 2022-07-01 00:38:56.705159
Epoch:[ 98 1 ] loss: 0.4118257164955139 2022-07-01 00:38:57.262096
Epoch:[ 98 2 ] loss: 0.40925559401512146 2022-07-01 00:38:57.673143
Epoch:[ 98 3 ] loss: 0.4141238033771515 2022-07-01 00:38:58.080713
Epoch:[ 98 4 ] loss: 0.41256895661354065 2022-07-01 00:38:58.489380
Epoch:[ 98 5 ] loss: 0.4147278666496277 2022-07-01 00:38:58.900461
Epoch:[ 98 6 ] loss: 0.41150417923927307 2022-07-01 00:38:59.311805
Epoch:[ 98 7 ] loss: 0.41119980812072754 2022-07-01 00:38:59.719085
Epoch:[ 98 8 ] loss: 0.4133757948875427 2022-07-01 00:39:00.128955
Epoch:[ 98 9 ] loss: 0.4137585759162903 2022-07-01 00:39:00.535427
Epoch:[ 98 10 ] loss: 0.4161331057548523 2022-07-01 00:39:00.942371
Epoch:[ 98 11 ] loss: 0.4142407178878784 2022-07-01 00:39:01.351583
Epoch:[ 98 12 ] loss: 0.4130234122276306 2022-07-01 00:39:01.763335
Epoch:[ 98 13 ] loss: 0.4120230972766876 2022-07-01 00:39:02.173405
Epoch:[ 98 14 ] loss: 0.4144551753997803 2022-07-01 00:39:02.588168
Epoch:[ 98 15 ] loss: 0.4127538800239563 2022-07-01 00:39:02.998926
Epoch:[ 98 16 ] loss: 0.4132673442363739 2022-07-01 00:39:08.655571
Epoch:[ 98 17 ] loss: 0.41328781843185425 2022-07-01 00:39:09.064064
Epoch:[ 98 18 ] loss: 0.4136529862880707 2022-07-01 00:39:09.486506
Epoch:[ 98 19 ] loss: 0.4124848246574402 2022-07-01 00:39:09.909054
Training_Epoch:[ 98 ] Training_loss: 0.413011246919632 2022-07-01 00:39:09.909890
learning rate:  0.006710886400000004
netparams have been saved once 98
val: 1 0.4275737404823303
val: 2 0.4387017786502838
val: 3 0.4374410808086395
val: 4 0.43039971590042114
val: 5 0.437534898519516
val: 6 0.4347776472568512
val: 7 0.4314897060394287
val: 8 0.4378261864185333
val: 9 0.4328135550022125
val: 10 0.4354994297027588
val: 11 0.41885602474212646
val: 12 0.43833574652671814
val: 13 0.43787020444869995
val: 14 0.4394530653953552
val: 15 0.4403840899467468
val: 16 0.4390029311180115
val: 17 0.44002270698547363
val: 18 0.43214043974876404
val: 19 0.42908453941345215
val: 20 0.4404523968696594
val_Epoch:[ 98 ] val_loss: 0.43498299419879916 2022-07-01 00:39:13.744481
start training 2022-07-01 00:39:13.845472
Epoch:[ 99 0 ] loss: 0.41381752490997314 2022-07-01 00:39:27.891981
Epoch:[ 99 1 ] loss: 0.41256144642829895 2022-07-01 00:39:28.344236
Epoch:[ 99 2 ] loss: 0.411103218793869 2022-07-01 00:39:28.774649
Epoch:[ 99 3 ] loss: 0.41278377175331116 2022-07-01 00:39:29.194700
Epoch:[ 99 4 ] loss: 0.41437193751335144 2022-07-01 00:39:29.609000
Epoch:[ 99 5 ] loss: 0.41372227668762207 2022-07-01 00:39:30.031881
Epoch:[ 99 6 ] loss: 0.41318121552467346 2022-07-01 00:39:30.454561
Epoch:[ 99 7 ] loss: 0.4135420620441437 2022-07-01 00:39:30.875693
Epoch:[ 99 8 ] loss: 0.4145030379295349 2022-07-01 00:39:31.297515
Epoch:[ 99 9 ] loss: 0.41347330808639526 2022-07-01 00:39:31.717918
Epoch:[ 99 10 ] loss: 0.41191625595092773 2022-07-01 00:39:32.138270
Epoch:[ 99 11 ] loss: 0.4148457646369934 2022-07-01 00:39:32.560441
Epoch:[ 99 12 ] loss: 0.4119243025779724 2022-07-01 00:39:32.982580
Epoch:[ 99 13 ] loss: 0.4126936197280884 2022-07-01 00:39:33.402926
Epoch:[ 99 14 ] loss: 0.41211411356925964 2022-07-01 00:39:33.823552
Epoch:[ 99 15 ] loss: 0.41683274507522583 2022-07-01 00:39:34.243457
Epoch:[ 99 16 ] loss: 0.4114135205745697 2022-07-01 00:39:39.427493
Epoch:[ 99 17 ] loss: 0.4152197241783142 2022-07-01 00:39:39.875061
Epoch:[ 99 18 ] loss: 0.41163432598114014 2022-07-01 00:39:40.295091
Epoch:[ 99 19 ] loss: 0.41467154026031494 2022-07-01 00:39:40.716757
Training_Epoch:[ 99 ] Training_loss: 0.41331628561019895 2022-07-01 00:39:40.717455
learning rate:  0.006710886400000004
val: 1 0.4401077926158905
val: 2 0.4363287091255188
val: 3 0.42760956287384033
val: 4 0.44405579566955566
val: 5 0.43203631043434143
val: 6 0.44919735193252563
val: 7 0.44079145789146423
val: 8 0.43366312980651855
val: 9 0.43754246830940247
val: 10 0.44326499104499817
val: 11 0.43185949325561523
val: 12 0.4343692660331726
val: 13 0.4408789873123169
val: 14 0.43325936794281006
val: 15 0.41832491755485535
val: 16 0.43000519275665283
val: 17 0.4389970004558563
val: 18 0.43145105242729187
val: 19 0.43093839287757874
val: 20 0.43240365386009216
val_Epoch:[ 99 ] val_loss: 0.4353542447090149 2022-07-01 00:39:44.664200
start training 2022-07-01 00:39:44.766517
Epoch:[ 100 0 ] loss: 0.41390472650527954 2022-07-01 00:39:59.185448
Epoch:[ 100 1 ] loss: 0.4124564230442047 2022-07-01 00:39:59.615595
Epoch:[ 100 2 ] loss: 0.4125789403915405 2022-07-01 00:40:00.025783
Epoch:[ 100 3 ] loss: 0.4160326421260834 2022-07-01 00:40:00.435104
Epoch:[ 100 4 ] loss: 0.4114028513431549 2022-07-01 00:40:00.846131
Epoch:[ 100 5 ] loss: 0.4100247025489807 2022-07-01 00:40:01.260686
Epoch:[ 100 6 ] loss: 0.41318854689598083 2022-07-01 00:40:01.671305
Epoch:[ 100 7 ] loss: 0.4093899130821228 2022-07-01 00:40:02.083186
Epoch:[ 100 8 ] loss: 0.4085891544818878 2022-07-01 00:40:02.495804
Epoch:[ 100 9 ] loss: 0.4109138548374176 2022-07-01 00:40:02.910064
Epoch:[ 100 10 ] loss: 0.41471371054649353 2022-07-01 00:40:03.327546
Epoch:[ 100 11 ] loss: 0.41174930334091187 2022-07-01 00:40:03.742428
Epoch:[ 100 12 ] loss: 0.4130397439002991 2022-07-01 00:40:04.151833
Epoch:[ 100 13 ] loss: 0.4126899242401123 2022-07-01 00:40:04.562737
Epoch:[ 100 14 ] loss: 0.41473644971847534 2022-07-01 00:40:04.975834
Epoch:[ 100 15 ] loss: 0.41261470317840576 2022-07-01 00:40:05.386251
Epoch:[ 100 16 ] loss: 0.4134009778499603 2022-07-01 00:40:10.842744
Epoch:[ 100 17 ] loss: 0.4128336012363434 2022-07-01 00:40:11.254774
Epoch:[ 100 18 ] loss: 0.41168102622032166 2022-07-01 00:40:11.677825
Epoch:[ 100 19 ] loss: 0.4120822250843048 2022-07-01 00:40:12.091217
Training_Epoch:[ 100 ] Training_loss: 0.41240117102861407 2022-07-01 00:40:12.092315
learning rate:  0.006710886400000004
netparams have been saved once 100
val: 1 0.4224371314048767
val: 2 0.4343658983707428
val: 3 0.4336867034435272
val: 4 0.45191705226898193
val: 5 0.44726142287254333
val: 6 0.43854376673698425
val: 7 0.4352903962135315
val: 8 0.44209182262420654
val: 9 0.43538185954093933
val: 10 0.45260173082351685
val: 11 0.4463065564632416
val: 12 0.44342106580734253
val: 13 0.44085580110549927
val: 14 0.43517667055130005
val: 15 0.43976566195487976
val: 16 0.42301878333091736
val: 17 0.4319774806499481
val: 18 0.4312903583049774
val: 19 0.4269005358219147
val: 20 0.4293099045753479
val_Epoch:[ 100 ] val_loss: 0.43708003014326097 2022-07-01 00:40:16.022693
start training 2022-07-01 00:40:16.132898
Epoch:[ 101 0 ] loss: 0.41342881321907043 2022-07-01 00:40:30.366895
Epoch:[ 101 1 ] loss: 0.4144846796989441 2022-07-01 00:40:31.206787
Epoch:[ 101 2 ] loss: 0.41306203603744507 2022-07-01 00:40:31.630587
Epoch:[ 101 3 ] loss: 0.4120992422103882 2022-07-01 00:40:32.054646
Epoch:[ 101 4 ] loss: 0.4096153974533081 2022-07-01 00:40:32.475106
Epoch:[ 101 5 ] loss: 0.40935781598091125 2022-07-01 00:40:32.897986
Epoch:[ 101 6 ] loss: 0.41294732689857483 2022-07-01 00:40:33.320677
Epoch:[ 101 7 ] loss: 0.4114414155483246 2022-07-01 00:40:33.743396
Epoch:[ 101 8 ] loss: 0.41133543848991394 2022-07-01 00:40:34.162937
Epoch:[ 101 9 ] loss: 0.4105329215526581 2022-07-01 00:40:34.583028
Epoch:[ 101 10 ] loss: 0.41046538949012756 2022-07-01 00:40:35.003149
Epoch:[ 101 11 ] loss: 0.41287872195243835 2022-07-01 00:40:35.427892
Epoch:[ 101 12 ] loss: 0.41080302000045776 2022-07-01 00:40:35.849464
Epoch:[ 101 13 ] loss: 0.40874820947647095 2022-07-01 00:40:36.269937
Epoch:[ 101 14 ] loss: 0.41045472025871277 2022-07-01 00:40:36.692850
Epoch:[ 101 15 ] loss: 0.4087783992290497 2022-07-01 00:40:37.114176
Epoch:[ 101 16 ] loss: 0.4122045338153839 2022-07-01 00:40:42.256487
Epoch:[ 101 17 ] loss: 0.4122083783149719 2022-07-01 00:40:43.476820
Epoch:[ 101 18 ] loss: 0.4134538471698761 2022-07-01 00:40:43.897307
Epoch:[ 101 19 ] loss: 0.4127322733402252 2022-07-01 00:40:44.319903
Training_Epoch:[ 101 ] Training_loss: 0.41155162900686265 2022-07-01 00:40:44.320749
learning rate:  0.005368709120000003
val: 1 0.43231141567230225
val: 2 0.4426707923412323
val: 3 0.4409400224685669
val: 4 0.43377625942230225
val: 5 0.43010348081588745
val: 6 0.4297703206539154
val: 7 0.44002315402030945
val: 8 0.4451794922351837
val: 9 0.4349675476551056
val: 10 0.4316582679748535
val: 11 0.43861207365989685
val: 12 0.4290706217288971
val: 13 0.4283096194267273
val: 14 0.430746465921402
val: 15 0.4298684597015381
val: 16 0.44164085388183594
val: 17 0.4277273118495941
val: 18 0.4293162524700165
val: 19 0.43482130765914917
val: 20 0.4415700137615204
val_Epoch:[ 101 ] val_loss: 0.4346541866660118 2022-07-01 00:40:48.141291
start training 2022-07-01 00:40:48.240859
Epoch:[ 102 0 ] loss: 0.4095257818698883 2022-07-01 00:41:03.157793
Epoch:[ 102 1 ] loss: 0.4096872806549072 2022-07-01 00:41:03.578358
Epoch:[ 102 2 ] loss: 0.4090636670589447 2022-07-01 00:41:04.001126
Epoch:[ 102 3 ] loss: 0.4115252196788788 2022-07-01 00:41:04.423533
Epoch:[ 102 4 ] loss: 0.41037696599960327 2022-07-01 00:41:04.838815
Epoch:[ 102 5 ] loss: 0.41118940711021423 2022-07-01 00:41:05.261215
Epoch:[ 102 6 ] loss: 0.4100499153137207 2022-07-01 00:41:05.683411
Epoch:[ 102 7 ] loss: 0.4093044102191925 2022-07-01 00:41:06.104786
Epoch:[ 102 8 ] loss: 0.409565269947052 2022-07-01 00:41:06.526144
Epoch:[ 102 9 ] loss: 0.4102303385734558 2022-07-01 00:41:06.950431
Epoch:[ 102 10 ] loss: 0.4100643992424011 2022-07-01 00:41:07.373671
Epoch:[ 102 11 ] loss: 0.4134690761566162 2022-07-01 00:41:07.793691
Epoch:[ 102 12 ] loss: 0.41017946600914 2022-07-01 00:41:08.216523
Epoch:[ 102 13 ] loss: 0.4126969873905182 2022-07-01 00:41:08.635713
Epoch:[ 102 14 ] loss: 0.4116278886795044 2022-07-01 00:41:09.058610
Epoch:[ 102 15 ] loss: 0.41208767890930176 2022-07-01 00:41:09.479827
Epoch:[ 102 16 ] loss: 0.412584125995636 2022-07-01 00:41:14.635286
Epoch:[ 102 17 ] loss: 0.41051018238067627 2022-07-01 00:41:15.056599
Epoch:[ 102 18 ] loss: 0.41157183051109314 2022-07-01 00:41:15.477577
Epoch:[ 102 19 ] loss: 0.40940216183662415 2022-07-01 00:41:15.897887
Training_Epoch:[ 102 ] Training_loss: 0.4107356026768684 2022-07-01 00:41:15.898664
learning rate:  0.005368709120000003
netparams have been saved once 102
val: 1 0.43258804082870483
val: 2 0.443685919046402
val: 3 0.44778335094451904
val: 4 0.43257981538772583
val: 5 0.44079333543777466
val: 6 0.43322548270225525
val: 7 0.4350588619709015
val: 8 0.4470703601837158
val: 9 0.42263734340667725
val: 10 0.4331267476081848
val: 11 0.4482786953449249
val: 12 0.454963356256485
val: 13 0.4445933997631073
val: 14 0.446880966424942
val: 15 0.431334912776947
val: 16 0.44362175464630127
val: 17 0.4304840564727783
val: 18 0.4408852159976959
val: 19 0.43292728066444397
val: 20 0.4482252299785614
val_Epoch:[ 102 ] val_loss: 0.4395372062921524 2022-07-01 00:41:19.731036
start training 2022-07-01 00:41:19.829962
Epoch:[ 103 0 ] loss: 0.4116310179233551 2022-07-01 00:41:34.371431
Epoch:[ 103 1 ] loss: 0.4123007357120514 2022-07-01 00:41:34.792950
Epoch:[ 103 2 ] loss: 0.4103734791278839 2022-07-01 00:41:35.213377
Epoch:[ 103 3 ] loss: 0.40856611728668213 2022-07-01 00:41:35.635939
Epoch:[ 103 4 ] loss: 0.4117153286933899 2022-07-01 00:41:36.058675
Epoch:[ 103 5 ] loss: 0.40937525033950806 2022-07-01 00:41:36.481402
Epoch:[ 103 6 ] loss: 0.4130060374736786 2022-07-01 00:41:36.902136
Epoch:[ 103 7 ] loss: 0.41083478927612305 2022-07-01 00:41:37.322882
Epoch:[ 103 8 ] loss: 0.4099048972129822 2022-07-01 00:41:37.744241
Epoch:[ 103 9 ] loss: 0.41236427426338196 2022-07-01 00:41:38.160018
Epoch:[ 103 10 ] loss: 0.412197083234787 2022-07-01 00:41:38.579942
Epoch:[ 103 11 ] loss: 0.40998002886772156 2022-07-01 00:41:39.003728
Epoch:[ 103 12 ] loss: 0.41180774569511414 2022-07-01 00:41:39.425041
Epoch:[ 103 13 ] loss: 0.4111980199813843 2022-07-01 00:41:39.844939
Epoch:[ 103 14 ] loss: 0.41145169734954834 2022-07-01 00:41:40.270307
Epoch:[ 103 15 ] loss: 0.41190603375434875 2022-07-01 00:41:40.689034
Epoch:[ 103 16 ] loss: 0.4108690917491913 2022-07-01 00:41:46.371015
Epoch:[ 103 17 ] loss: 0.41407638788223267 2022-07-01 00:41:46.794480
Epoch:[ 103 18 ] loss: 0.41347989439964294 2022-07-01 00:41:47.215315
Epoch:[ 103 19 ] loss: 0.40952447056770325 2022-07-01 00:41:47.639463
Training_Epoch:[ 103 ] Training_loss: 0.41132811903953553 2022-07-01 00:41:47.640142
learning rate:  0.005368709120000003
val: 1 0.44074249267578125
val: 2 0.4506513476371765
val: 3 0.42896685004234314
val: 4 0.43890848755836487
val: 5 0.4427155554294586
val: 6 0.4281209707260132
val: 7 0.4387412369251251
val: 8 0.43996310234069824
val: 9 0.4312388002872467
val: 10 0.42508184909820557
val: 11 0.43724238872528076
val: 12 0.4344059228897095
val: 13 0.4393337070941925
val: 14 0.4281090199947357
val: 15 0.43223676085472107
val: 16 0.43906858563423157
val: 17 0.43077296018600464
val: 18 0.4355563819408417
val: 19 0.4256249666213989
val: 20 0.4389099180698395
val_Epoch:[ 103 ] val_loss: 0.43531956523656845 2022-07-01 00:41:51.414228
start training 2022-07-01 00:41:51.514386
Epoch:[ 104 0 ] loss: 0.41074949502944946 2022-07-01 00:42:05.726149
Epoch:[ 104 1 ] loss: 0.4096427261829376 2022-07-01 00:42:06.421263
Epoch:[ 104 2 ] loss: 0.4084181487560272 2022-07-01 00:42:06.842752
Epoch:[ 104 3 ] loss: 0.4085792303085327 2022-07-01 00:42:07.267104
Epoch:[ 104 4 ] loss: 0.41095948219299316 2022-07-01 00:42:07.690753
Epoch:[ 104 5 ] loss: 0.40866339206695557 2022-07-01 00:42:08.111768
Epoch:[ 104 6 ] loss: 0.4099964201450348 2022-07-01 00:42:08.534258
Epoch:[ 104 7 ] loss: 0.4116165339946747 2022-07-01 00:42:08.955300
Epoch:[ 104 8 ] loss: 0.40865224599838257 2022-07-01 00:42:09.376050
Epoch:[ 104 9 ] loss: 0.41110658645629883 2022-07-01 00:42:09.796931
Epoch:[ 104 10 ] loss: 0.4107005298137665 2022-07-01 00:42:10.213221
Epoch:[ 104 11 ] loss: 0.41071560978889465 2022-07-01 00:42:10.636386
Epoch:[ 104 12 ] loss: 0.41394495964050293 2022-07-01 00:42:11.057268
Epoch:[ 104 13 ] loss: 0.41200312972068787 2022-07-01 00:42:11.477858
Epoch:[ 104 14 ] loss: 0.4137517511844635 2022-07-01 00:42:11.902698
Epoch:[ 104 15 ] loss: 0.4119466245174408 2022-07-01 00:42:12.323632
Epoch:[ 104 16 ] loss: 0.4080932140350342 2022-07-01 00:42:17.176842
Epoch:[ 104 17 ] loss: 0.4129195213317871 2022-07-01 00:42:18.310586
Epoch:[ 104 18 ] loss: 0.41279807686805725 2022-07-01 00:42:18.734129
Epoch:[ 104 19 ] loss: 0.40981659293174744 2022-07-01 00:42:19.154788
Training_Epoch:[ 104 ] Training_loss: 0.41075371354818346 2022-07-01 00:42:19.155479
learning rate:  0.005368709120000003
netparams have been saved once 104
val: 1 0.4306623339653015
val: 2 0.4474356174468994
val: 3 0.43799155950546265
val: 4 0.43045201897621155
val: 5 0.4426950514316559
val: 6 0.4440540373325348
val: 7 0.4340735673904419
val: 8 0.4393102824687958
val: 9 0.4330112636089325
val: 10 0.43617722392082214
val: 11 0.43688634037971497
val: 12 0.44230273365974426
val: 13 0.42372453212738037
val: 14 0.4377152919769287
val: 15 0.4450497329235077
val: 16 0.43669623136520386
val: 17 0.4296104609966278
val: 18 0.4546281397342682
val: 19 0.43875575065612793
val: 20 0.4386037588119507
val_Epoch:[ 104 ] val_loss: 0.4379917964339256 2022-07-01 00:42:22.889722
start training 2022-07-01 00:42:22.989981
Epoch:[ 105 0 ] loss: 0.41104409098625183 2022-07-01 00:42:37.077972
Epoch:[ 105 1 ] loss: 0.4082740843296051 2022-07-01 00:42:37.765479
Epoch:[ 105 2 ] loss: 0.40957653522491455 2022-07-01 00:42:38.185507
Epoch:[ 105 3 ] loss: 0.41103821992874146 2022-07-01 00:42:38.605448
Epoch:[ 105 4 ] loss: 0.40899208188056946 2022-07-01 00:42:39.027485
Epoch:[ 105 5 ] loss: 0.41218671202659607 2022-07-01 00:42:39.448168
Epoch:[ 105 6 ] loss: 0.4103650450706482 2022-07-01 00:42:39.871846
Epoch:[ 105 7 ] loss: 0.408851683139801 2022-07-01 00:42:40.294195
Epoch:[ 105 8 ] loss: 0.40761953592300415 2022-07-01 00:42:40.715291
Epoch:[ 105 9 ] loss: 0.4079325199127197 2022-07-01 00:42:41.134830
Epoch:[ 105 10 ] loss: 0.408231258392334 2022-07-01 00:42:41.555123
Epoch:[ 105 11 ] loss: 0.408654123544693 2022-07-01 00:42:41.977446
Epoch:[ 105 12 ] loss: 0.40782931447029114 2022-07-01 00:42:42.399794
Epoch:[ 105 13 ] loss: 0.41191738843917847 2022-07-01 00:42:42.820100
Epoch:[ 105 14 ] loss: 0.4106203019618988 2022-07-01 00:42:43.240414
Epoch:[ 105 15 ] loss: 0.41198939085006714 2022-07-01 00:42:43.660959
Epoch:[ 105 16 ] loss: 0.410492479801178 2022-07-01 00:42:48.831482
Epoch:[ 105 17 ] loss: 0.41005009412765503 2022-07-01 00:42:49.252272
Epoch:[ 105 18 ] loss: 0.40908005833625793 2022-07-01 00:42:49.674876
Epoch:[ 105 19 ] loss: 0.40979474782943726 2022-07-01 00:42:50.096407
Training_Epoch:[ 105 ] Training_loss: 0.4097269833087921 2022-07-01 00:42:50.097075
learning rate:  0.005368709120000003
val: 1 0.439538836479187
val: 2 0.43961623311042786
val: 3 0.4244135618209839
val: 4 0.4383176267147064
val: 5 0.4453779458999634
val: 6 0.4312903881072998
val: 7 0.4261719584465027
val: 8 0.4449329972267151
val: 9 0.4405502378940582
val: 10 0.4260396361351013
val: 11 0.4263150691986084
val: 12 0.44342419505119324
val: 13 0.4371996223926544
val: 14 0.4268278479576111
val: 15 0.4294491708278656
val: 16 0.4364071786403656
val: 17 0.4317913055419922
val: 18 0.4281109571456909
val: 19 0.4439559578895569
val: 20 0.4368402659893036
val_Epoch:[ 105 ] val_loss: 0.4348285496234894 2022-07-01 00:42:53.814319
start training 2022-07-01 00:42:53.912323
Epoch:[ 106 0 ] loss: 0.4064127206802368 2022-07-01 00:43:08.546626
Epoch:[ 106 1 ] loss: 0.4081811308860779 2022-07-01 00:43:08.965051
Epoch:[ 106 2 ] loss: 0.40888041257858276 2022-07-01 00:43:09.384850
Epoch:[ 106 3 ] loss: 0.40927183628082275 2022-07-01 00:43:09.806020
Epoch:[ 106 4 ] loss: 0.40888711810112 2022-07-01 00:43:10.225303
Epoch:[ 106 5 ] loss: 0.41036882996559143 2022-07-01 00:43:10.646726
Epoch:[ 106 6 ] loss: 0.41006115078926086 2022-07-01 00:43:11.069049
Epoch:[ 106 7 ] loss: 0.4099859297275543 2022-07-01 00:43:11.491657
Epoch:[ 106 8 ] loss: 0.40951505303382874 2022-07-01 00:43:11.905152
Epoch:[ 106 9 ] loss: 0.4085235297679901 2022-07-01 00:43:12.326043
Epoch:[ 106 10 ] loss: 0.40925443172454834 2022-07-01 00:43:12.745984
Epoch:[ 106 11 ] loss: 0.40778854489326477 2022-07-01 00:43:13.164614
Epoch:[ 106 12 ] loss: 0.41014227271080017 2022-07-01 00:43:13.586632
Epoch:[ 106 13 ] loss: 0.4107620120048523 2022-07-01 00:43:14.007089
Epoch:[ 106 14 ] loss: 0.4088519215583801 2022-07-01 00:43:14.427640
Epoch:[ 106 15 ] loss: 0.41251710057258606 2022-07-01 00:43:14.840765
Epoch:[ 106 16 ] loss: 0.4092584550380707 2022-07-01 00:43:20.204523
Epoch:[ 106 17 ] loss: 0.4107150435447693 2022-07-01 00:43:20.623621
Epoch:[ 106 18 ] loss: 0.4094461500644684 2022-07-01 00:43:21.045462
Epoch:[ 106 19 ] loss: 0.4097681939601898 2022-07-01 00:43:21.466437
Training_Epoch:[ 106 ] Training_loss: 0.4094295918941498 2022-07-01 00:43:21.467095
learning rate:  0.005368709120000003
netparams have been saved once 106
val: 1 0.4388863444328308
val: 2 0.4394102394580841
val: 3 0.43711066246032715
val: 4 0.4451264441013336
val: 5 0.42566847801208496
val: 6 0.4313376545906067
val: 7 0.4349474012851715
val: 8 0.43263381719589233
val: 9 0.4358270466327667
val: 10 0.438992440700531
val: 11 0.4426299035549164
val: 12 0.4318757653236389
val: 13 0.44283080101013184
val: 14 0.43396666646003723
val: 15 0.437073290348053
val: 16 0.4483950436115265
val: 17 0.4444681406021118
val: 18 0.42785966396331787
val: 19 0.43167901039123535
val: 20 0.42683979868888855
val_Epoch:[ 106 ] val_loss: 0.4363779306411743 2022-07-01 00:43:25.314080
start training 2022-07-01 00:43:25.411477
Epoch:[ 107 0 ] loss: 0.4113844037055969 2022-07-01 00:43:39.784701
Epoch:[ 107 1 ] loss: 0.4065801799297333 2022-07-01 00:43:40.232704
Epoch:[ 107 2 ] loss: 0.4085037112236023 2022-07-01 00:43:40.653079
Epoch:[ 107 3 ] loss: 0.40920013189315796 2022-07-01 00:43:41.072465
Epoch:[ 107 4 ] loss: 0.4114740192890167 2022-07-01 00:43:41.486483
Epoch:[ 107 5 ] loss: 0.4106791019439697 2022-07-01 00:43:41.906528
Epoch:[ 107 6 ] loss: 0.40808409452438354 2022-07-01 00:43:42.328514
Epoch:[ 107 7 ] loss: 0.40773406624794006 2022-07-01 00:43:42.753557
Epoch:[ 107 8 ] loss: 0.4093872010707855 2022-07-01 00:43:43.176269
Epoch:[ 107 9 ] loss: 0.4075256288051605 2022-07-01 00:43:43.596602
Epoch:[ 107 10 ] loss: 0.40791916847229004 2022-07-01 00:43:44.017632
Epoch:[ 107 11 ] loss: 0.40644901990890503 2022-07-01 00:43:44.438771
Epoch:[ 107 12 ] loss: 0.4058353006839752 2022-07-01 00:43:44.858504
Epoch:[ 107 13 ] loss: 0.41012027859687805 2022-07-01 00:43:45.281391
Epoch:[ 107 14 ] loss: 0.4107287526130676 2022-07-01 00:43:45.704198
Epoch:[ 107 15 ] loss: 0.40741854906082153 2022-07-01 00:43:46.125670
Epoch:[ 107 16 ] loss: 0.4090697169303894 2022-07-01 00:43:51.226405
Epoch:[ 107 17 ] loss: 0.4094223976135254 2022-07-01 00:43:51.646902
Epoch:[ 107 18 ] loss: 0.41059625148773193 2022-07-01 00:43:52.069947
Epoch:[ 107 19 ] loss: 0.4074711203575134 2022-07-01 00:43:52.489692
Training_Epoch:[ 107 ] Training_loss: 0.4087791547179222 2022-07-01 00:43:52.490516
learning rate:  0.005368709120000003
val: 1 0.43057578802108765
val: 2 0.4307405948638916
val: 3 0.4287075400352478
val: 4 0.42763978242874146
val: 5 0.43341976404190063
val: 6 0.43384087085723877
val: 7 0.4381212294101715
val: 8 0.43752166628837585
val: 9 0.4330664873123169
val: 10 0.4404546916484833
val: 11 0.4318845868110657
val: 12 0.45106127858161926
val: 13 0.4299059510231018
val: 14 0.44232794642448425
val: 15 0.42974236607551575
val: 16 0.44316917657852173
val: 17 0.4312097728252411
val: 18 0.4394298195838928
val: 19 0.42506083846092224
val: 20 0.43670177459716797
val_Epoch:[ 107 ] val_loss: 0.4347290962934494 2022-07-01 00:43:56.288503
start training 2022-07-01 00:43:56.388411
Epoch:[ 108 0 ] loss: 0.40858200192451477 2022-07-01 00:44:10.544868
Epoch:[ 108 1 ] loss: 0.4084322154521942 2022-07-01 00:44:11.287536
Epoch:[ 108 2 ] loss: 0.4062137007713318 2022-07-01 00:44:11.708940
Epoch:[ 108 3 ] loss: 0.4067193865776062 2022-07-01 00:44:12.118454
Epoch:[ 108 4 ] loss: 0.4067847728729248 2022-07-01 00:44:12.527681
Epoch:[ 108 5 ] loss: 0.40750107169151306 2022-07-01 00:44:12.938652
Epoch:[ 108 6 ] loss: 0.40667009353637695 2022-07-01 00:44:13.350766
Epoch:[ 108 7 ] loss: 0.4096822440624237 2022-07-01 00:44:13.760495
Epoch:[ 108 8 ] loss: 0.4100393056869507 2022-07-01 00:44:14.177662
Epoch:[ 108 9 ] loss: 0.411343514919281 2022-07-01 00:44:14.586677
Epoch:[ 108 10 ] loss: 0.4060499966144562 2022-07-01 00:44:14.996980
Epoch:[ 108 11 ] loss: 0.408245712518692 2022-07-01 00:44:15.410952
Epoch:[ 108 12 ] loss: 0.4095756709575653 2022-07-01 00:44:15.821148
Epoch:[ 108 13 ] loss: 0.4093230366706848 2022-07-01 00:44:16.229032
Epoch:[ 108 14 ] loss: 0.41010671854019165 2022-07-01 00:44:16.640924
Epoch:[ 108 15 ] loss: 0.41082045435905457 2022-07-01 00:44:17.051478
Epoch:[ 108 16 ] loss: 0.4091660976409912 2022-07-01 00:44:22.389289
Epoch:[ 108 17 ] loss: 0.40832531452178955 2022-07-01 00:44:22.797480
Epoch:[ 108 18 ] loss: 0.41007480025291443 2022-07-01 00:44:23.216769
Epoch:[ 108 19 ] loss: 0.40947553515434265 2022-07-01 00:44:23.625838
Training_Epoch:[ 108 ] Training_loss: 0.40865658223629 2022-07-01 00:44:23.626656
learning rate:  0.005368709120000003
netparams have been saved once 108
val: 1 0.43792012333869934
val: 2 0.4397318661212921
val: 3 0.44515833258628845
val: 4 0.4369151294231415
val: 5 0.43866169452667236
val: 6 0.4393778145313263
val: 7 0.42538753151893616
val: 8 0.4289281964302063
val: 9 0.446071982383728
val: 10 0.4374815821647644
val: 11 0.4405522644519806
val: 12 0.44069477915763855
val: 13 0.42933836579322815
val: 14 0.43369215726852417
val: 15 0.4415525496006012
val: 16 0.4345044195652008
val: 17 0.43926775455474854
val: 18 0.4394044280052185
val: 19 0.4358351230621338
val: 20 0.4315943717956543
val_Epoch:[ 108 ] val_loss: 0.43710352331399915 2022-07-01 00:44:27.578266
start training 2022-07-01 00:44:27.675120
Epoch:[ 109 0 ] loss: 0.40962955355644226 2022-07-01 00:44:42.073064
Epoch:[ 109 1 ] loss: 0.40849852561950684 2022-07-01 00:44:42.494739
Epoch:[ 109 2 ] loss: 0.40621545910835266 2022-07-01 00:44:42.915447
Epoch:[ 109 3 ] loss: 0.407376229763031 2022-07-01 00:44:43.339694
Epoch:[ 109 4 ] loss: 0.41029831767082214 2022-07-01 00:44:43.758905
Epoch:[ 109 5 ] loss: 0.4111557900905609 2022-07-01 00:44:44.178384
Epoch:[ 109 6 ] loss: 0.40957170724868774 2022-07-01 00:44:44.600436
Epoch:[ 109 7 ] loss: 0.4082062840461731 2022-07-01 00:44:45.013169
Epoch:[ 109 8 ] loss: 0.407962441444397 2022-07-01 00:44:45.434626
Epoch:[ 109 9 ] loss: 0.4083791673183441 2022-07-01 00:44:45.856172
Epoch:[ 109 10 ] loss: 0.40977296233177185 2022-07-01 00:44:46.277559
Epoch:[ 109 11 ] loss: 0.40783265233039856 2022-07-01 00:44:46.696821
Epoch:[ 109 12 ] loss: 0.40909162163734436 2022-07-01 00:44:47.114718
Epoch:[ 109 13 ] loss: 0.40789222717285156 2022-07-01 00:44:47.537574
Epoch:[ 109 14 ] loss: 0.4074332118034363 2022-07-01 00:44:47.957832
Epoch:[ 109 15 ] loss: 0.4127022325992584 2022-07-01 00:44:48.379373
Epoch:[ 109 16 ] loss: 0.40639740228652954 2022-07-01 00:44:54.000359
Epoch:[ 109 17 ] loss: 0.4101727604866028 2022-07-01 00:44:54.407940
Epoch:[ 109 18 ] loss: 0.4098176956176758 2022-07-01 00:44:54.819679
Epoch:[ 109 19 ] loss: 0.40863651037216187 2022-07-01 00:44:55.229990
Training_Epoch:[ 109 ] Training_loss: 0.40885213762521744 2022-07-01 00:44:55.230972
learning rate:  0.005368709120000003
val: 1 0.437370240688324
val: 2 0.4472515285015106
val: 3 0.44194138050079346
val: 4 0.4467162489891052
val: 5 0.4421581029891968
val: 6 0.4256216585636139
val: 7 0.43311432003974915
val: 8 0.4362223446369171
val: 9 0.4445298910140991
val: 10 0.4323958158493042
val: 11 0.4380304515361786
val: 12 0.44084635376930237
val: 13 0.43667078018188477
val: 14 0.4309338331222534
val: 15 0.4338238835334778
val: 16 0.43135881423950195
val: 17 0.44326964020729065
val: 18 0.43262210488319397
val: 19 0.4388026297092438
val: 20 0.441694974899292
val_Epoch:[ 109 ] val_loss: 0.43776874989271164 2022-07-01 00:44:59.467181
start training 2022-07-01 00:44:59.566652
Epoch:[ 110 0 ] loss: 0.4083576202392578 2022-07-01 00:45:14.074059
Epoch:[ 110 1 ] loss: 0.40776124596595764 2022-07-01 00:45:14.507527
Epoch:[ 110 2 ] loss: 0.4080777168273926 2022-07-01 00:45:14.923021
Epoch:[ 110 3 ] loss: 0.4062986969947815 2022-07-01 00:45:15.345126
Epoch:[ 110 4 ] loss: 0.40723520517349243 2022-07-01 00:45:15.766946
Epoch:[ 110 5 ] loss: 0.40688833594322205 2022-07-01 00:45:16.187447
Epoch:[ 110 6 ] loss: 0.40755027532577515 2022-07-01 00:45:16.611187
Epoch:[ 110 7 ] loss: 0.4076952040195465 2022-07-01 00:45:17.031478
Epoch:[ 110 8 ] loss: 0.4075845181941986 2022-07-01 00:45:17.450749
Epoch:[ 110 9 ] loss: 0.40717238187789917 2022-07-01 00:45:17.867688
Epoch:[ 110 10 ] loss: 0.40951308608055115 2022-07-01 00:45:18.290557
Epoch:[ 110 11 ] loss: 0.41144832968711853 2022-07-01 00:45:18.713893
Epoch:[ 110 12 ] loss: 0.4044046700000763 2022-07-01 00:45:19.123710
Epoch:[ 110 13 ] loss: 0.4072081446647644 2022-07-01 00:45:19.534070
Epoch:[ 110 14 ] loss: 0.40983086824417114 2022-07-01 00:45:19.943360
Epoch:[ 110 15 ] loss: 0.4069390892982483 2022-07-01 00:45:20.352239
Epoch:[ 110 16 ] loss: 0.4108440577983856 2022-07-01 00:45:25.495568
Epoch:[ 110 17 ] loss: 0.4088193476200104 2022-07-01 00:45:25.906112
Epoch:[ 110 18 ] loss: 0.40774616599082947 2022-07-01 00:45:26.317226
Epoch:[ 110 19 ] loss: 0.4081178605556488 2022-07-01 00:45:26.725102
Training_Epoch:[ 110 ] Training_loss: 0.40797464102506636 2022-07-01 00:45:26.726168
learning rate:  0.005368709120000003
netparams have been saved once 110
val: 1 0.4371821880340576
val: 2 0.4359794855117798
val: 3 0.4264431595802307
val: 4 0.43529826402664185
val: 5 0.43314850330352783
val: 6 0.43237775564193726
val: 7 0.43800151348114014
val: 8 0.4277006983757019
val: 9 0.44318726658821106
val: 10 0.44411179423332214
val: 11 0.4401360750198364
val: 12 0.4336099326610565
val: 13 0.4307120740413666
val: 14 0.43453606963157654
val: 15 0.44383758306503296
val: 16 0.43285346031188965
val: 17 0.4349539875984192
val: 18 0.4285433888435364
val: 19 0.43543416261672974
val: 20 0.44383177161216736
val_Epoch:[ 110 ] val_loss: 0.4355939567089081 2022-07-01 00:45:30.735191
start training 2022-07-01 00:45:30.836561
Epoch:[ 111 0 ] loss: 0.4066285789012909 2022-07-01 00:45:44.847123
Epoch:[ 111 1 ] loss: 0.4081917405128479 2022-07-01 00:45:45.381197
Epoch:[ 111 2 ] loss: 0.40791282057762146 2022-07-01 00:45:45.804810
Epoch:[ 111 3 ] loss: 0.4068928360939026 2022-07-01 00:45:46.226130
Epoch:[ 111 4 ] loss: 0.4078441858291626 2022-07-01 00:45:46.649341
Epoch:[ 111 5 ] loss: 0.40781402587890625 2022-07-01 00:45:47.060721
Epoch:[ 111 6 ] loss: 0.40265366435050964 2022-07-01 00:45:47.469510
Epoch:[ 111 7 ] loss: 0.40628570318222046 2022-07-01 00:45:47.878301
Epoch:[ 111 8 ] loss: 0.40755751729011536 2022-07-01 00:45:48.285947
Epoch:[ 111 9 ] loss: 0.4083324074745178 2022-07-01 00:45:48.693445
Epoch:[ 111 10 ] loss: 0.40560150146484375 2022-07-01 00:45:49.104112
Epoch:[ 111 11 ] loss: 0.40891703963279724 2022-07-01 00:45:49.516229
Epoch:[ 111 12 ] loss: 0.4069662094116211 2022-07-01 00:45:49.925185
Epoch:[ 111 13 ] loss: 0.4101906716823578 2022-07-01 00:45:50.336680
Epoch:[ 111 14 ] loss: 0.40733274817466736 2022-07-01 00:45:50.752648
Epoch:[ 111 15 ] loss: 0.40769702196121216 2022-07-01 00:45:51.161081
Epoch:[ 111 16 ] loss: 0.4054555296897888 2022-07-01 00:45:56.942133
Epoch:[ 111 17 ] loss: 0.4066391885280609 2022-07-01 00:45:57.355886
Epoch:[ 111 18 ] loss: 0.40869757533073425 2022-07-01 00:45:57.777872
Epoch:[ 111 19 ] loss: 0.40680620074272156 2022-07-01 00:45:58.188191
Training_Epoch:[ 111 ] Training_loss: 0.407220858335495 2022-07-01 00:45:58.189251
learning rate:  0.0042949672960000025
val: 1 0.43534162640571594
val: 2 0.43506741523742676
val: 3 0.4254201650619507
val: 4 0.4452812969684601
val: 5 0.4314572215080261
val: 6 0.43414559960365295
val: 7 0.4388126730918884
val: 8 0.4418509900569916
val: 9 0.44287413358688354
val: 10 0.4397885501384735
val: 11 0.44018396735191345
val: 12 0.42610934376716614
val: 13 0.44716620445251465
val: 14 0.43550580739974976
val: 15 0.43963757157325745
val: 16 0.43256670236587524
val: 17 0.4420785903930664
val: 18 0.44595474004745483
val: 19 0.42867279052734375
val: 20 0.4458613395690918
val_Epoch:[ 111 ] val_loss: 0.4376888364553452 2022-07-01 00:46:02.082112
start training 2022-07-01 00:46:02.183290
Epoch:[ 112 0 ] loss: 0.40845802426338196 2022-07-01 00:46:16.087935
Epoch:[ 112 1 ] loss: 0.40747302770614624 2022-07-01 00:46:16.993105
Epoch:[ 112 2 ] loss: 0.40757960081100464 2022-07-01 00:46:17.401324
Epoch:[ 112 3 ] loss: 0.40511998534202576 2022-07-01 00:46:17.810078
Epoch:[ 112 4 ] loss: 0.40749260783195496 2022-07-01 00:46:18.219540
Epoch:[ 112 5 ] loss: 0.4066469073295593 2022-07-01 00:46:18.628848
Epoch:[ 112 6 ] loss: 0.40728551149368286 2022-07-01 00:46:19.039318
Epoch:[ 112 7 ] loss: 0.4059024453163147 2022-07-01 00:46:19.447536
Epoch:[ 112 8 ] loss: 0.4043707549571991 2022-07-01 00:46:19.858126
Epoch:[ 112 9 ] loss: 0.40545183420181274 2022-07-01 00:46:20.265521
Epoch:[ 112 10 ] loss: 0.4060952961444855 2022-07-01 00:46:20.673120
Epoch:[ 112 11 ] loss: 0.4090125262737274 2022-07-01 00:46:21.082990
Epoch:[ 112 12 ] loss: 0.4065878093242645 2022-07-01 00:46:21.493255
Epoch:[ 112 13 ] loss: 0.40558668971061707 2022-07-01 00:46:21.899907
Epoch:[ 112 14 ] loss: 0.40710946917533875 2022-07-01 00:46:22.309067
Epoch:[ 112 15 ] loss: 0.40579134225845337 2022-07-01 00:46:22.717359
Epoch:[ 112 16 ] loss: 0.4106096625328064 2022-07-01 00:46:28.084099
Epoch:[ 112 17 ] loss: 0.40602096915245056 2022-07-01 00:46:28.493844
Epoch:[ 112 18 ] loss: 0.4052604138851166 2022-07-01 00:46:28.908091
Epoch:[ 112 19 ] loss: 0.4081255793571472 2022-07-01 00:46:29.319018
Training_Epoch:[ 112 ] Training_loss: 0.4067990228533745 2022-07-01 00:46:29.319802
learning rate:  0.0042949672960000025
netparams have been saved once 112
val: 1 0.43471503257751465
val: 2 0.43570688366889954
val: 3 0.42662516236305237
val: 4 0.4412209987640381
val: 5 0.43657398223876953
val: 6 0.42901650071144104
val: 7 0.4250834882259369
val: 8 0.43778082728385925
val: 9 0.4394485056400299
val: 10 0.4420449137687683
val: 11 0.4488120973110199
val: 12 0.4275987446308136
val: 13 0.44181984663009644
val: 14 0.44219017028808594
val: 15 0.437238484621048
val: 16 0.4377720355987549
val: 17 0.4406336545944214
val: 18 0.42704716324806213
val: 19 0.4318059980869293
val: 20 0.44547024369239807
val_Epoch:[ 112 ] val_loss: 0.43643023669719694 2022-07-01 00:46:33.143943
start training 2022-07-01 00:46:33.243896
Epoch:[ 113 0 ] loss: 0.40440797805786133 2022-07-01 00:46:47.215026
Epoch:[ 113 1 ] loss: 0.40729209780693054 2022-07-01 00:46:47.909676
Epoch:[ 113 2 ] loss: 0.40472131967544556 2022-07-01 00:46:48.320973
Epoch:[ 113 3 ] loss: 0.40627652406692505 2022-07-01 00:46:48.729765
Epoch:[ 113 4 ] loss: 0.40782150626182556 2022-07-01 00:46:49.141747
Epoch:[ 113 5 ] loss: 0.4077247679233551 2022-07-01 00:46:49.563432
Epoch:[ 113 6 ] loss: 0.4062595069408417 2022-07-01 00:46:49.985567
Epoch:[ 113 7 ] loss: 0.40473487973213196 2022-07-01 00:46:50.408836
Epoch:[ 113 8 ] loss: 0.4067979156970978 2022-07-01 00:46:50.829617
Epoch:[ 113 9 ] loss: 0.40641099214553833 2022-07-01 00:46:51.250739
Epoch:[ 113 10 ] loss: 0.40617313981056213 2022-07-01 00:46:51.671296
Epoch:[ 113 11 ] loss: 0.4098750352859497 2022-07-01 00:46:52.091689
Epoch:[ 113 12 ] loss: 0.4062969982624054 2022-07-01 00:46:52.513764
Epoch:[ 113 13 ] loss: 0.40771815180778503 2022-07-01 00:46:52.935859
Epoch:[ 113 14 ] loss: 0.40658247470855713 2022-07-01 00:46:53.351414
Epoch:[ 113 15 ] loss: 0.406046986579895 2022-07-01 00:46:53.772096
Epoch:[ 113 16 ] loss: 0.4055771827697754 2022-07-01 00:46:58.950572
Epoch:[ 113 17 ] loss: 0.4055255651473999 2022-07-01 00:46:59.577688
Epoch:[ 113 18 ] loss: 0.40508776903152466 2022-07-01 00:46:59.998067
Epoch:[ 113 19 ] loss: 0.4088572859764099 2022-07-01 00:47:00.420356
Training_Epoch:[ 113 ] Training_loss: 0.40650940388441087 2022-07-01 00:47:00.421102
learning rate:  0.0042949672960000025
val: 1 0.4450397491455078
val: 2 0.4421689212322235
val: 3 0.45255255699157715
val: 4 0.42099854350090027
val: 5 0.44062894582748413
val: 6 0.4366694986820221
val: 7 0.43640026450157166
val: 8 0.42565807700157166
val: 9 0.4410199522972107
val: 10 0.42776885628700256
val: 11 0.4368255138397217
val: 12 0.43314334750175476
val: 13 0.43497973680496216
val: 14 0.4424979090690613
val: 15 0.43966183066368103
val: 16 0.4322354793548584
val: 17 0.4325026869773865
val: 18 0.43488261103630066
val: 19 0.44606104493141174
val: 20 0.42867276072502136
val_Epoch:[ 113 ] val_loss: 0.43651841431856153 2022-07-01 00:47:04.182230
start training 2022-07-01 00:47:04.281174
Epoch:[ 114 0 ] loss: 0.4055716395378113 2022-07-01 00:47:19.128786
Epoch:[ 114 1 ] loss: 0.4063878655433655 2022-07-01 00:47:19.537600
Epoch:[ 114 2 ] loss: 0.4079800546169281 2022-07-01 00:47:19.953111
Epoch:[ 114 3 ] loss: 0.40501120686531067 2022-07-01 00:47:20.361566
Epoch:[ 114 4 ] loss: 0.4042043089866638 2022-07-01 00:47:20.772374
Epoch:[ 114 5 ] loss: 0.40394434332847595 2022-07-01 00:47:21.181036
Epoch:[ 114 6 ] loss: 0.4078271985054016 2022-07-01 00:47:21.592263
Epoch:[ 114 7 ] loss: 0.40537717938423157 2022-07-01 00:47:22.002422
Epoch:[ 114 8 ] loss: 0.4048865735530853 2022-07-01 00:47:22.411312
Epoch:[ 114 9 ] loss: 0.4055626690387726 2022-07-01 00:47:22.818194
Epoch:[ 114 10 ] loss: 0.4038882851600647 2022-07-01 00:47:23.231836
Epoch:[ 114 11 ] loss: 0.40369078516960144 2022-07-01 00:47:23.642889
Epoch:[ 114 12 ] loss: 0.4067409932613373 2022-07-01 00:47:24.050766
Epoch:[ 114 13 ] loss: 0.4063899517059326 2022-07-01 00:47:24.465658
Epoch:[ 114 14 ] loss: 0.40773192048072815 2022-07-01 00:47:24.876899
Epoch:[ 114 15 ] loss: 0.4085351228713989 2022-07-01 00:47:25.286416
Epoch:[ 114 16 ] loss: 0.40547892451286316 2022-07-01 00:47:30.462101
Epoch:[ 114 17 ] loss: 0.407723069190979 2022-07-01 00:47:30.872564
Epoch:[ 114 18 ] loss: 0.4082307517528534 2022-07-01 00:47:31.295064
Epoch:[ 114 19 ] loss: 0.4052038788795471 2022-07-01 00:47:31.716921
Training_Epoch:[ 114 ] Training_loss: 0.4060183361172676 2022-07-01 00:47:31.717770
learning rate:  0.0042949672960000025
netparams have been saved once 114
val: 1 0.4538164436817169
val: 2 0.4519166648387909
val: 3 0.4346313774585724
val: 4 0.4330945909023285
val: 5 0.4415684640407562
val: 6 0.4444958567619324
val: 7 0.42419201135635376
val: 8 0.4384134113788605
val: 9 0.4351004660129547
val: 10 0.4370349943637848
val: 11 0.43366706371307373
val: 12 0.44243180751800537
val: 13 0.43278130888938904
val: 14 0.4383407533168793
val: 15 0.4327598810195923
val: 16 0.4397435486316681
val: 17 0.43138208985328674
val: 18 0.42509725689888
val: 19 0.43589887022972107
val: 20 0.4381294548511505
val_Epoch:[ 114 ] val_loss: 0.43722481578588485 2022-07-01 00:47:35.555071
start training 2022-07-01 00:47:35.674745
Epoch:[ 115 0 ] loss: 0.40257254242897034 2022-07-01 00:47:50.058199
Epoch:[ 115 1 ] loss: 0.4086611568927765 2022-07-01 00:47:50.480126
Epoch:[ 115 2 ] loss: 0.4074440598487854 2022-07-01 00:47:50.901608
Epoch:[ 115 3 ] loss: 0.404338538646698 2022-07-01 00:47:51.324322
Epoch:[ 115 4 ] loss: 0.40443262457847595 2022-07-01 00:47:51.743684
Epoch:[ 115 5 ] loss: 0.40673109889030457 2022-07-01 00:47:52.163829
Epoch:[ 115 6 ] loss: 0.4044332802295685 2022-07-01 00:47:52.583886
Epoch:[ 115 7 ] loss: 0.40500378608703613 2022-07-01 00:47:53.002957
Epoch:[ 115 8 ] loss: 0.40741416811943054 2022-07-01 00:47:53.419300
Epoch:[ 115 9 ] loss: 0.4058745801448822 2022-07-01 00:47:53.826558
Epoch:[ 115 10 ] loss: 0.40665552020072937 2022-07-01 00:47:54.236860
Epoch:[ 115 11 ] loss: 0.4037003517150879 2022-07-01 00:47:54.645161
Epoch:[ 115 12 ] loss: 0.40531590580940247 2022-07-01 00:47:55.054944
Epoch:[ 115 13 ] loss: 0.4076295495033264 2022-07-01 00:47:55.462755
Epoch:[ 115 14 ] loss: 0.4026528298854828 2022-07-01 00:47:55.875455
Epoch:[ 115 15 ] loss: 0.40777018666267395 2022-07-01 00:47:56.287391
Epoch:[ 115 16 ] loss: 0.40691667795181274 2022-07-01 00:48:01.823637
Epoch:[ 115 17 ] loss: 0.4069439768791199 2022-07-01 00:48:02.231175
Epoch:[ 115 18 ] loss: 0.4034915268421173 2022-07-01 00:48:02.644825
Epoch:[ 115 19 ] loss: 0.40819451212882996 2022-07-01 00:48:03.054821
Training_Epoch:[ 115 ] Training_loss: 0.40580884367227554 2022-07-01 00:48:03.055680
learning rate:  0.0042949672960000025
val: 1 0.44093239307403564
val: 2 0.4306689500808716
val: 3 0.42770814895629883
val: 4 0.4397192597389221
val: 5 0.4383999705314636
val: 6 0.4323846399784088
val: 7 0.4324812591075897
val: 8 0.43349921703338623
val: 9 0.43384435772895813
val: 10 0.4371340572834015
val: 11 0.43274927139282227
val: 12 0.43857720494270325
val: 13 0.43405064940452576
val: 14 0.4357300400733948
val: 15 0.4386931359767914
val: 16 0.4399265944957733
val: 17 0.4310125708580017
val: 18 0.43271294236183167
val: 19 0.4391854405403137
val: 20 0.4379805028438568
val_Epoch:[ 115 ] val_loss: 0.43536953032016756 2022-07-01 00:48:06.778369
start training 2022-07-01 00:48:06.881677
Epoch:[ 116 0 ] loss: 0.4049761891365051 2022-07-01 00:48:21.160652
Epoch:[ 116 1 ] loss: 0.4063798189163208 2022-07-01 00:48:21.581918
Epoch:[ 116 2 ] loss: 0.40379682183265686 2022-07-01 00:48:22.006999
Epoch:[ 116 3 ] loss: 0.40404707193374634 2022-07-01 00:48:22.426911
Epoch:[ 116 4 ] loss: 0.40447553992271423 2022-07-01 00:48:22.849174
Epoch:[ 116 5 ] loss: 0.40753358602523804 2022-07-01 00:48:23.272589
Epoch:[ 116 6 ] loss: 0.4046787917613983 2022-07-01 00:48:23.692525
Epoch:[ 116 7 ] loss: 0.406298965215683 2022-07-01 00:48:24.112207
Epoch:[ 116 8 ] loss: 0.4074196219444275 2022-07-01 00:48:24.533512
Epoch:[ 116 9 ] loss: 0.4026367962360382 2022-07-01 00:48:24.956081
Epoch:[ 116 10 ] loss: 0.403633177280426 2022-07-01 00:48:25.377318
Epoch:[ 116 11 ] loss: 0.4069706201553345 2022-07-01 00:48:25.796716
Epoch:[ 116 12 ] loss: 0.4053851366043091 2022-07-01 00:48:26.217822
Epoch:[ 116 13 ] loss: 0.40495607256889343 2022-07-01 00:48:26.637803
Epoch:[ 116 14 ] loss: 0.40717238187789917 2022-07-01 00:48:27.057464
Epoch:[ 116 15 ] loss: 0.4057779014110565 2022-07-01 00:48:27.472925
Epoch:[ 116 16 ] loss: 0.41023534536361694 2022-07-01 00:48:32.909471
Epoch:[ 116 17 ] loss: 0.4053715765476227 2022-07-01 00:48:33.333602
Epoch:[ 116 18 ] loss: 0.4026864767074585 2022-07-01 00:48:33.754064
Epoch:[ 116 19 ] loss: 0.40917858481407166 2022-07-01 00:48:34.174328
Training_Epoch:[ 116 ] Training_loss: 0.40568052381277087 2022-07-01 00:48:34.175054
learning rate:  0.0042949672960000025
netparams have been saved once 116
val: 1 0.43016502261161804
val: 2 0.42944449186325073
val: 3 0.4523885250091553
val: 4 0.435823529958725
val: 5 0.42937055230140686
val: 6 0.4314040243625641
val: 7 0.43916672468185425
val: 8 0.4346221089363098
val: 9 0.4299011826515198
val: 10 0.44318249821662903
val: 11 0.42332786321640015
val: 12 0.4437766373157501
val: 13 0.4319818317890167
val: 14 0.44126802682876587
val: 15 0.4358460307121277
val: 16 0.43503132462501526
val: 17 0.42451760172843933
val: 18 0.42535942792892456
val: 19 0.4385882019996643
val: 20 0.44479450583457947
val_Epoch:[ 116 ] val_loss: 0.4349980056285858 2022-07-01 00:48:38.073561
start training 2022-07-01 00:48:38.193955
Epoch:[ 117 0 ] loss: 0.4040015637874603 2022-07-01 00:48:52.228981
Epoch:[ 117 1 ] loss: 0.40499988198280334 2022-07-01 00:48:52.657853
Epoch:[ 117 2 ] loss: 0.4043509364128113 2022-07-01 00:48:53.080064
Epoch:[ 117 3 ] loss: 0.40610167384147644 2022-07-01 00:48:53.501568
Epoch:[ 117 4 ] loss: 0.40501147508621216 2022-07-01 00:48:53.914116
Epoch:[ 117 5 ] loss: 0.4059721827507019 2022-07-01 00:48:54.321888
Epoch:[ 117 6 ] loss: 0.40330860018730164 2022-07-01 00:48:54.728826
Epoch:[ 117 7 ] loss: 0.40692374110221863 2022-07-01 00:48:55.141310
Epoch:[ 117 8 ] loss: 0.4047069847583771 2022-07-01 00:48:55.548635
Epoch:[ 117 9 ] loss: 0.40630248188972473 2022-07-01 00:48:55.958299
Epoch:[ 117 10 ] loss: 0.40409356355667114 2022-07-01 00:48:56.369668
Epoch:[ 117 11 ] loss: 0.4022767245769501 2022-07-01 00:48:56.784592
Epoch:[ 117 12 ] loss: 0.40197789669036865 2022-07-01 00:48:57.192861
Epoch:[ 117 13 ] loss: 0.4057959318161011 2022-07-01 00:48:57.602793
Epoch:[ 117 14 ] loss: 0.4063129723072052 2022-07-01 00:48:58.010426
Epoch:[ 117 15 ] loss: 0.4049350917339325 2022-07-01 00:48:58.418862
Epoch:[ 117 16 ] loss: 0.40374755859375 2022-07-01 00:49:04.277448
Epoch:[ 117 17 ] loss: 0.406904935836792 2022-07-01 00:49:04.687603
Epoch:[ 117 18 ] loss: 0.4049643576145172 2022-07-01 00:49:05.110111
Epoch:[ 117 19 ] loss: 0.4071582853794098 2022-07-01 00:49:05.529695
Training_Epoch:[ 117 ] Training_loss: 0.40499234199523926 2022-07-01 00:49:05.530592
learning rate:  0.0042949672960000025
val: 1 0.4374091625213623
val: 2 0.4296588897705078
val: 3 0.4260282814502716
val: 4 0.42936110496520996
val: 5 0.43303266167640686
val: 6 0.44030749797821045
val: 7 0.4358897805213928
val: 8 0.43662816286087036
val: 9 0.4328654706478119
val: 10 0.43340086936950684
val: 11 0.4445722699165344
val: 12 0.43024495244026184
val: 13 0.42998266220092773
val: 14 0.4451688528060913
val: 15 0.4309006631374359
val: 16 0.4338025152683258
val: 17 0.4389248788356781
val: 18 0.4455028474330902
val: 19 0.41886985301971436
val: 20 0.435371994972229
val_Epoch:[ 117 ] val_loss: 0.43439616858959196 2022-07-01 00:49:09.272640
start training 2022-07-01 00:49:09.375776
Epoch:[ 118 0 ] loss: 0.405010849237442 2022-07-01 00:49:24.083349
Epoch:[ 118 1 ] loss: 0.40493711829185486 2022-07-01 00:49:24.503810
Epoch:[ 118 2 ] loss: 0.4044552743434906 2022-07-01 00:49:24.917612
Epoch:[ 118 3 ] loss: 0.4052782356739044 2022-07-01 00:49:25.333568
Epoch:[ 118 4 ] loss: 0.4034366011619568 2022-07-01 00:49:25.755980
Epoch:[ 118 5 ] loss: 0.4048754572868347 2022-07-01 00:49:26.176590
Epoch:[ 118 6 ] loss: 0.4047415256500244 2022-07-01 00:49:26.596855
Epoch:[ 118 7 ] loss: 0.4075067937374115 2022-07-01 00:49:27.017678
Epoch:[ 118 8 ] loss: 0.40214505791664124 2022-07-01 00:49:27.438719
Epoch:[ 118 9 ] loss: 0.4035017490386963 2022-07-01 00:49:27.857506
Epoch:[ 118 10 ] loss: 0.4064551293849945 2022-07-01 00:49:28.279132
Epoch:[ 118 11 ] loss: 0.40557360649108887 2022-07-01 00:49:28.700918
Epoch:[ 118 12 ] loss: 0.404762327671051 2022-07-01 00:49:29.120610
Epoch:[ 118 13 ] loss: 0.40718695521354675 2022-07-01 00:49:29.539510
Epoch:[ 118 14 ] loss: 0.40433305501937866 2022-07-01 00:49:29.960755
Epoch:[ 118 15 ] loss: 0.40711745619773865 2022-07-01 00:49:30.380389
Epoch:[ 118 16 ] loss: 0.40770193934440613 2022-07-01 00:49:35.633371
Epoch:[ 118 17 ] loss: 0.4036335349082947 2022-07-01 00:49:36.054419
Epoch:[ 118 18 ] loss: 0.40535640716552734 2022-07-01 00:49:36.476400
Epoch:[ 118 19 ] loss: 0.4066176116466522 2022-07-01 00:49:36.896254
Training_Epoch:[ 118 ] Training_loss: 0.4052313342690468 2022-07-01 00:49:36.896940
learning rate:  0.0042949672960000025
netparams have been saved once 118
val: 1 0.43931740522384644
val: 2 0.43199506402015686
val: 3 0.4415838420391083
val: 4 0.44933339953422546
val: 5 0.4426969289779663
val: 6 0.4339260756969452
val: 7 0.4441262185573578
val: 8 0.4353969693183899
val: 9 0.4451131224632263
val: 10 0.4386717677116394
val: 11 0.4354058504104614
val: 12 0.42536449432373047
val: 13 0.430747926235199
val: 14 0.4445236623287201
val: 15 0.43290889263153076
val: 16 0.442036896944046
val: 17 0.43147075176239014
val: 18 0.4281180202960968
val: 19 0.43508294224739075
val: 20 0.4324941337108612
val_Epoch:[ 118 ] val_loss: 0.4370157182216644 2022-07-01 00:49:40.881887
start training 2022-07-01 00:49:41.003230
Epoch:[ 119 0 ] loss: 0.4026371240615845 2022-07-01 00:49:55.193901
Epoch:[ 119 1 ] loss: 0.4025537371635437 2022-07-01 00:49:55.635006
Epoch:[ 119 2 ] loss: 0.4035252034664154 2022-07-01 00:49:56.054537
Epoch:[ 119 3 ] loss: 0.4033587872982025 2022-07-01 00:49:56.474602
Epoch:[ 119 4 ] loss: 0.4062381386756897 2022-07-01 00:49:56.893315
Epoch:[ 119 5 ] loss: 0.4051162302494049 2022-07-01 00:49:57.303138
Epoch:[ 119 6 ] loss: 0.4026848375797272 2022-07-01 00:49:57.712649
Epoch:[ 119 7 ] loss: 0.4042855203151703 2022-07-01 00:49:58.121592
Epoch:[ 119 8 ] loss: 0.4045001268386841 2022-07-01 00:49:58.529850
Epoch:[ 119 9 ] loss: 0.403336763381958 2022-07-01 00:49:58.937038
Epoch:[ 119 10 ] loss: 0.4042048752307892 2022-07-01 00:49:59.344603
Epoch:[ 119 11 ] loss: 0.404601514339447 2022-07-01 00:49:59.753766
Epoch:[ 119 12 ] loss: 0.40721407532691956 2022-07-01 00:50:00.163729
Epoch:[ 119 13 ] loss: 0.4080871641635895 2022-07-01 00:50:00.578502
Epoch:[ 119 14 ] loss: 0.4041823148727417 2022-07-01 00:50:00.986012
Epoch:[ 119 15 ] loss: 0.40399742126464844 2022-07-01 00:50:01.392581
Epoch:[ 119 16 ] loss: 0.40364575386047363 2022-07-01 00:50:07.618622
Epoch:[ 119 17 ] loss: 0.4031851887702942 2022-07-01 00:50:08.026367
Epoch:[ 119 18 ] loss: 0.40573611855506897 2022-07-01 00:50:08.463652
Epoch:[ 119 19 ] loss: 0.40574485063552856 2022-07-01 00:50:08.886061
Training_Epoch:[ 119 ] Training_loss: 0.404441787302494 2022-07-01 00:50:08.886842
learning rate:  0.0042949672960000025
val: 1 0.42379656434059143
val: 2 0.44938766956329346
val: 3 0.4382898509502411
val: 4 0.4366183578968048
val: 5 0.43355029821395874
val: 6 0.44066038727760315
val: 7 0.44317570328712463
val: 8 0.44116124510765076
val: 9 0.4406298100948334
val: 10 0.4390507638454437
val: 11 0.4358712434768677
val: 12 0.43054258823394775
val: 13 0.4362029731273651
val: 14 0.4301440715789795
val: 15 0.43519067764282227
val: 16 0.4385254979133606
val: 17 0.4314152002334595
val: 18 0.4413573741912842
val: 19 0.43284136056900024
val: 20 0.43409305810928345
val_Epoch:[ 119 ] val_loss: 0.43662523478269577 2022-07-01 00:50:12.690173
start training 2022-07-01 00:50:12.791338
Epoch:[ 120 0 ] loss: 0.40430256724357605 2022-07-01 00:50:27.140683
Epoch:[ 120 1 ] loss: 0.40491580963134766 2022-07-01 00:50:27.559044
Epoch:[ 120 2 ] loss: 0.4033867120742798 2022-07-01 00:50:27.979419
Epoch:[ 120 3 ] loss: 0.40237686038017273 2022-07-01 00:50:28.398733
Epoch:[ 120 4 ] loss: 0.40587860345840454 2022-07-01 00:50:28.818822
Epoch:[ 120 5 ] loss: 0.406236857175827 2022-07-01 00:50:29.240503
Epoch:[ 120 6 ] loss: 0.40378546714782715 2022-07-01 00:50:29.661882
Epoch:[ 120 7 ] loss: 0.40693557262420654 2022-07-01 00:50:30.083942
Epoch:[ 120 8 ] loss: 0.4061562418937683 2022-07-01 00:50:30.503561
Epoch:[ 120 9 ] loss: 0.40429478883743286 2022-07-01 00:50:30.923059
Epoch:[ 120 10 ] loss: 0.4042966365814209 2022-07-01 00:50:31.343647
Epoch:[ 120 11 ] loss: 0.4048604667186737 2022-07-01 00:50:31.762947
Epoch:[ 120 12 ] loss: 0.40681517124176025 2022-07-01 00:50:32.184188
Epoch:[ 120 13 ] loss: 0.4027819335460663 2022-07-01 00:50:32.605609
Epoch:[ 120 14 ] loss: 0.40467026829719543 2022-07-01 00:50:33.029022
Epoch:[ 120 15 ] loss: 0.40424612164497375 2022-07-01 00:50:33.442899
Epoch:[ 120 16 ] loss: 0.40689000487327576 2022-07-01 00:50:38.679009
Epoch:[ 120 17 ] loss: 0.40645626187324524 2022-07-01 00:50:39.097760
Epoch:[ 120 18 ] loss: 0.4035141170024872 2022-07-01 00:50:39.517674
Epoch:[ 120 19 ] loss: 0.40616458654403687 2022-07-01 00:50:39.939126
Training_Epoch:[ 120 ] Training_loss: 0.4049482524394989 2022-07-01 00:50:39.939920
learning rate:  0.0042949672960000025
netparams have been saved once 120
val: 1 0.4392563998699188
val: 2 0.44320541620254517
val: 3 0.4255702495574951
val: 4 0.4390884339809418
val: 5 0.4321407377719879
val: 6 0.4385990500450134
val: 7 0.43719980120658875
val: 8 0.443857342004776
val: 9 0.4446999728679657
val: 10 0.43706873059272766
val: 11 0.4323800802230835
val: 12 0.4392539858818054
val: 13 0.4426026940345764
val: 14 0.4388783872127533
val: 15 0.44022542238235474
val: 16 0.4506153464317322
val: 17 0.43574124574661255
val: 18 0.43579208850860596
val: 19 0.44299250841140747
val: 20 0.4405730962753296
val_Epoch:[ 120 ] val_loss: 0.43898704946041106 2022-07-01 00:50:43.914765
start training 2022-07-01 00:50:44.034283
Epoch:[ 121 0 ] loss: 0.403759241104126 2022-07-01 00:50:57.992029
Epoch:[ 121 1 ] loss: 0.40532979369163513 2022-07-01 00:50:58.433481
Epoch:[ 121 2 ] loss: 0.40469643473625183 2022-07-01 00:50:58.855694
Epoch:[ 121 3 ] loss: 0.4050500690937042 2022-07-01 00:50:59.276876
Epoch:[ 121 4 ] loss: 0.4040551483631134 2022-07-01 00:50:59.696490
Epoch:[ 121 5 ] loss: 0.4041173756122589 2022-07-01 00:51:00.116061
Epoch:[ 121 6 ] loss: 0.40371087193489075 2022-07-01 00:51:00.538521
Epoch:[ 121 7 ] loss: 0.4057618975639343 2022-07-01 00:51:00.948208
Epoch:[ 121 8 ] loss: 0.40384674072265625 2022-07-01 00:51:01.365707
Epoch:[ 121 9 ] loss: 0.4027681052684784 2022-07-01 00:51:01.774504
Epoch:[ 121 10 ] loss: 0.40346911549568176 2022-07-01 00:51:02.193994
Epoch:[ 121 11 ] loss: 0.40327659249305725 2022-07-01 00:51:02.602061
Epoch:[ 121 12 ] loss: 0.4025055766105652 2022-07-01 00:51:03.010772
Epoch:[ 121 13 ] loss: 0.4044191837310791 2022-07-01 00:51:03.420507
Epoch:[ 121 14 ] loss: 0.4028935730457306 2022-07-01 00:51:03.830036
Epoch:[ 121 15 ] loss: 0.401739239692688 2022-07-01 00:51:04.240200
Epoch:[ 121 16 ] loss: 0.4021678864955902 2022-07-01 00:51:10.044547
Epoch:[ 121 17 ] loss: 0.4035889208316803 2022-07-01 00:51:10.465500
Epoch:[ 121 18 ] loss: 0.40561869740486145 2022-07-01 00:51:10.894003
Epoch:[ 121 19 ] loss: 0.40350404381752014 2022-07-01 00:51:11.312903
Training_Epoch:[ 121 ] Training_loss: 0.40381392538547517 2022-07-01 00:51:11.313673
learning rate:  0.0034359738368000023
val: 1 0.444939523935318
val: 2 0.4480893909931183
val: 3 0.4358620345592499
val: 4 0.4326551556587219
val: 5 0.4333796799182892
val: 6 0.4261566698551178
val: 7 0.4415428638458252
val: 8 0.42346349358558655
val: 9 0.4371853768825531
val: 10 0.44016385078430176
val: 11 0.43257930874824524
val: 12 0.4422469139099121
val: 13 0.4329647719860077
val: 14 0.4384375512599945
val: 15 0.4444103240966797
val: 16 0.44120997190475464
val: 17 0.4296889305114746
val: 18 0.4215123951435089
val: 19 0.42733338475227356
val: 20 0.44277748465538025
val_Epoch:[ 121 ] val_loss: 0.43582995384931567 2022-07-01 00:51:15.039933
start training 2022-07-01 00:51:15.143675
Epoch:[ 122 0 ] loss: 0.4027673006057739 2022-07-01 00:51:29.440225
Epoch:[ 122 1 ] loss: 0.4017656743526459 2022-07-01 00:51:29.883818
Epoch:[ 122 2 ] loss: 0.40227842330932617 2022-07-01 00:51:30.302490
Epoch:[ 122 3 ] loss: 0.40205758810043335 2022-07-01 00:51:30.715450
Epoch:[ 122 4 ] loss: 0.40317004919052124 2022-07-01 00:51:31.127944
Epoch:[ 122 5 ] loss: 0.40267398953437805 2022-07-01 00:51:31.538934
Epoch:[ 122 6 ] loss: 0.405408650636673 2022-07-01 00:51:31.951451
Epoch:[ 122 7 ] loss: 0.4011681377887726 2022-07-01 00:51:32.362988
Epoch:[ 122 8 ] loss: 0.40093690156936646 2022-07-01 00:51:32.774304
Epoch:[ 122 9 ] loss: 0.40040770173072815 2022-07-01 00:51:33.184166
Epoch:[ 122 10 ] loss: 0.4028039872646332 2022-07-01 00:51:33.594563
Epoch:[ 122 11 ] loss: 0.4006236493587494 2022-07-01 00:51:34.011558
Epoch:[ 122 12 ] loss: 0.4023384153842926 2022-07-01 00:51:34.426082
Epoch:[ 122 13 ] loss: 0.40359294414520264 2022-07-01 00:51:34.841998
Epoch:[ 122 14 ] loss: 0.4039967358112335 2022-07-01 00:51:35.253903
Epoch:[ 122 15 ] loss: 0.40149015188217163 2022-07-01 00:51:35.666779
Epoch:[ 122 16 ] loss: 0.40443992614746094 2022-07-01 00:51:41.168152
Epoch:[ 122 17 ] loss: 0.4045695662498474 2022-07-01 00:51:41.581538
Epoch:[ 122 18 ] loss: 0.40442898869514465 2022-07-01 00:51:42.004193
Epoch:[ 122 19 ] loss: 0.4058399200439453 2022-07-01 00:51:42.423596
Training_Epoch:[ 122 ] Training_loss: 0.402837935090065 2022-07-01 00:51:42.424512
learning rate:  0.0034359738368000023
netparams have been saved once 122
val: 1 0.4325198531150818
val: 2 0.4368191361427307
val: 3 0.4259055554866791
val: 4 0.4301096498966217
val: 5 0.43407952785491943
val: 6 0.4253694415092468
val: 7 0.45159152150154114
val: 8 0.44056203961372375
val: 9 0.4273849129676819
val: 10 0.4321140944957733
val: 11 0.4348472058773041
val: 12 0.43073391914367676
val: 13 0.4364320635795593
val: 14 0.44505125284194946
val: 15 0.42605680227279663
val: 16 0.4393368363380432
val: 17 0.45248979330062866
val: 18 0.43375304341316223
val: 19 0.43338900804519653
val: 20 0.4323422312736511
val_Epoch:[ 122 ] val_loss: 0.4350443944334984 2022-07-01 00:51:46.268450
start training 2022-07-01 00:51:46.373278
Epoch:[ 123 0 ] loss: 0.4034336805343628 2022-07-01 00:52:00.848299
Epoch:[ 123 1 ] loss: 0.40171483159065247 2022-07-01 00:52:01.299018
Epoch:[ 123 2 ] loss: 0.4022717773914337 2022-07-01 00:52:01.720460
Epoch:[ 123 3 ] loss: 0.40459251403808594 2022-07-01 00:52:02.141650
Epoch:[ 123 4 ] loss: 0.4009154438972473 2022-07-01 00:52:02.563075
Epoch:[ 123 5 ] loss: 0.3994259834289551 2022-07-01 00:52:02.986513
Epoch:[ 123 6 ] loss: 0.4043051302433014 2022-07-01 00:52:03.410296
Epoch:[ 123 7 ] loss: 0.40100130438804626 2022-07-01 00:52:03.825466
Epoch:[ 123 8 ] loss: 0.40304678678512573 2022-07-01 00:52:04.250536
Epoch:[ 123 9 ] loss: 0.40279579162597656 2022-07-01 00:52:04.672183
Epoch:[ 123 10 ] loss: 0.4042629599571228 2022-07-01 00:52:05.095515
Epoch:[ 123 11 ] loss: 0.40276432037353516 2022-07-01 00:52:05.518030
Epoch:[ 123 12 ] loss: 0.4030246436595917 2022-07-01 00:52:05.937876
Epoch:[ 123 13 ] loss: 0.40215983986854553 2022-07-01 00:52:06.359449
Epoch:[ 123 14 ] loss: 0.40155619382858276 2022-07-01 00:52:06.779599
Epoch:[ 123 15 ] loss: 0.40334552526474 2022-07-01 00:52:07.202353
Epoch:[ 123 16 ] loss: 0.40149351954460144 2022-07-01 00:52:12.949261
Epoch:[ 123 17 ] loss: 0.4039698541164398 2022-07-01 00:52:13.368551
Epoch:[ 123 18 ] loss: 0.4010026752948761 2022-07-01 00:52:13.798938
Epoch:[ 123 19 ] loss: 0.40089207887649536 2022-07-01 00:52:14.222060
Training_Epoch:[ 123 ] Training_loss: 0.4023987427353859 2022-07-01 00:52:14.222733
learning rate:  0.0034359738368000023
val: 1 0.43877536058425903
val: 2 0.437730610370636
val: 3 0.4324127435684204
val: 4 0.4271939694881439
val: 5 0.4377075135707855
val: 6 0.43829846382141113
val: 7 0.4401518404483795
val: 8 0.4301146864891052
val: 9 0.436351478099823
val: 10 0.4429042935371399
val: 11 0.43886426091194153
val: 12 0.4353075623512268
val: 13 0.45171013474464417
val: 14 0.4354204535484314
val: 15 0.4472258687019348
val: 16 0.4337998926639557
val: 17 0.4371400773525238
val: 18 0.4347979724407196
val: 19 0.43967515230178833
val: 20 0.43928003311157227
val_Epoch:[ 123 ] val_loss: 0.4377431184053421 2022-07-01 00:52:17.992982
start training 2022-07-01 00:52:18.099363
Epoch:[ 124 0 ] loss: 0.40066707134246826 2022-07-01 00:52:33.015661
Epoch:[ 124 1 ] loss: 0.40554389357566833 2022-07-01 00:52:33.429074
Epoch:[ 124 2 ] loss: 0.4044179618358612 2022-07-01 00:52:33.850862
Epoch:[ 124 3 ] loss: 0.4030870497226715 2022-07-01 00:52:34.274991
Epoch:[ 124 4 ] loss: 0.4017666280269623 2022-07-01 00:52:34.698098
Epoch:[ 124 5 ] loss: 0.4015350639820099 2022-07-01 00:52:35.118948
Epoch:[ 124 6 ] loss: 0.4033477306365967 2022-07-01 00:52:35.539997
Epoch:[ 124 7 ] loss: 0.402261346578598 2022-07-01 00:52:35.962119
Epoch:[ 124 8 ] loss: 0.40350446105003357 2022-07-01 00:52:36.382486
Epoch:[ 124 9 ] loss: 0.4022340178489685 2022-07-01 00:52:36.803775
Epoch:[ 124 10 ] loss: 0.4017712473869324 2022-07-01 00:52:37.227247
Epoch:[ 124 11 ] loss: 0.4019235074520111 2022-07-01 00:52:37.649926
Epoch:[ 124 12 ] loss: 0.4002839922904968 2022-07-01 00:52:38.073327
Epoch:[ 124 13 ] loss: 0.4017661213874817 2022-07-01 00:52:38.495072
Epoch:[ 124 14 ] loss: 0.4020557701587677 2022-07-01 00:52:38.915830
Epoch:[ 124 15 ] loss: 0.40179580450057983 2022-07-01 00:52:39.328478
Epoch:[ 124 16 ] loss: 0.40347957611083984 2022-07-01 00:52:45.011475
Epoch:[ 124 17 ] loss: 0.40470609068870544 2022-07-01 00:52:45.436321
Epoch:[ 124 18 ] loss: 0.40038904547691345 2022-07-01 00:52:45.864685
Epoch:[ 124 19 ] loss: 0.4024353623390198 2022-07-01 00:52:46.283639
Training_Epoch:[ 124 ] Training_loss: 0.4024485871195793 2022-07-01 00:52:46.284512
learning rate:  0.0034359738368000023
netparams have been saved once 124
val: 1 0.43611106276512146
val: 2 0.42722436785697937
val: 3 0.4300047755241394
val: 4 0.43973684310913086
val: 5 0.4470597207546234
val: 6 0.43969208002090454
val: 7 0.4418700933456421
val: 8 0.4294220805168152
val: 9 0.4329361915588379
val: 10 0.4378150403499603
val: 11 0.42756566405296326
val: 12 0.44420325756073
val: 13 0.42861077189445496
val: 14 0.440338671207428
val: 15 0.4301081597805023
val: 16 0.44466689229011536
val: 17 0.4421742260456085
val: 18 0.4461756944656372
val: 19 0.429241418838501
val: 20 0.44996267557144165
val_Epoch:[ 124 ] val_loss: 0.43724598437547685 2022-07-01 00:52:50.111465
start training 2022-07-01 00:52:50.217126
Epoch:[ 125 0 ] loss: 0.40102726221084595 2022-07-01 00:53:04.238628
Epoch:[ 125 1 ] loss: 0.40359362959861755 2022-07-01 00:53:04.685998
Epoch:[ 125 2 ] loss: 0.4032253921031952 2022-07-01 00:53:05.105799
Epoch:[ 125 3 ] loss: 0.40214475989341736 2022-07-01 00:53:05.527617
Epoch:[ 125 4 ] loss: 0.4020085334777832 2022-07-01 00:53:05.943110
Epoch:[ 125 5 ] loss: 0.40439337491989136 2022-07-01 00:53:06.365731
Epoch:[ 125 6 ] loss: 0.4044138193130493 2022-07-01 00:53:06.785276
Epoch:[ 125 7 ] loss: 0.40208789706230164 2022-07-01 00:53:07.205479
Epoch:[ 125 8 ] loss: 0.4031854271888733 2022-07-01 00:53:07.627465
Epoch:[ 125 9 ] loss: 0.40287816524505615 2022-07-01 00:53:08.050373
Epoch:[ 125 10 ] loss: 0.3994441032409668 2022-07-01 00:53:08.472713
Epoch:[ 125 11 ] loss: 0.39936918020248413 2022-07-01 00:53:08.896347
Epoch:[ 125 12 ] loss: 0.4031612277030945 2022-07-01 00:53:09.324947
Epoch:[ 125 13 ] loss: 0.40250346064567566 2022-07-01 00:53:09.748650
Epoch:[ 125 14 ] loss: 0.4036024510860443 2022-07-01 00:53:10.170107
Epoch:[ 125 15 ] loss: 0.40269607305526733 2022-07-01 00:53:10.590442
Epoch:[ 125 16 ] loss: 0.4032513499259949 2022-07-01 00:53:16.493359
Epoch:[ 125 17 ] loss: 0.4020705223083496 2022-07-01 00:53:16.914684
Epoch:[ 125 18 ] loss: 0.4021097421646118 2022-07-01 00:53:17.337726
Epoch:[ 125 19 ] loss: 0.3993409276008606 2022-07-01 00:53:17.765868
Training_Epoch:[ 125 ] Training_loss: 0.402325364947319 2022-07-01 00:53:17.766607
learning rate:  0.0034359738368000023
val: 1 0.4374890625476837
val: 2 0.43779903650283813
val: 3 0.4346736967563629
val: 4 0.44349563121795654
val: 5 0.4280683398246765
val: 6 0.4379657506942749
val: 7 0.4478903114795685
val: 8 0.4299381375312805
val: 9 0.43980711698532104
val: 10 0.42551612854003906
val: 11 0.4363533854484558
val: 12 0.4403045177459717
val: 13 0.4395548701286316
val: 14 0.43692460656166077
val: 15 0.4369882643222809
val: 16 0.43170788884162903
val: 17 0.42994919419288635
val: 18 0.4408353269100189
val: 19 0.42473477125167847
val: 20 0.4478428065776825
val_Epoch:[ 125 ] val_loss: 0.4363919422030449 2022-07-01 00:53:21.560422
start training 2022-07-01 00:53:21.665344
Epoch:[ 126 0 ] loss: 0.4017464220523834 2022-07-01 00:53:36.187958
Epoch:[ 126 1 ] loss: 0.40121492743492126 2022-07-01 00:53:36.622283
Epoch:[ 126 2 ] loss: 0.40151533484458923 2022-07-01 00:53:37.044268
Epoch:[ 126 3 ] loss: 0.40050604939460754 2022-07-01 00:53:37.463692
Epoch:[ 126 4 ] loss: 0.40400925278663635 2022-07-01 00:53:37.885127
Epoch:[ 126 5 ] loss: 0.39869439601898193 2022-07-01 00:53:38.306199
Epoch:[ 126 6 ] loss: 0.401596337556839 2022-07-01 00:53:38.726867
Epoch:[ 126 7 ] loss: 0.40256860852241516 2022-07-01 00:53:39.146715
Epoch:[ 126 8 ] loss: 0.40580299496650696 2022-07-01 00:53:39.560276
Epoch:[ 126 9 ] loss: 0.40281975269317627 2022-07-01 00:53:39.981189
Epoch:[ 126 10 ] loss: 0.40229499340057373 2022-07-01 00:53:40.400757
Epoch:[ 126 11 ] loss: 0.40104997158050537 2022-07-01 00:53:40.822788
Epoch:[ 126 12 ] loss: 0.40201088786125183 2022-07-01 00:53:41.245335
Epoch:[ 126 13 ] loss: 0.401685893535614 2022-07-01 00:53:41.665739
Epoch:[ 126 14 ] loss: 0.401839941740036 2022-07-01 00:53:42.085257
Epoch:[ 126 15 ] loss: 0.401271790266037 2022-07-01 00:53:42.508797
Epoch:[ 126 16 ] loss: 0.4048565924167633 2022-07-01 00:53:47.836876
Epoch:[ 126 17 ] loss: 0.40358951687812805 2022-07-01 00:53:48.255418
Epoch:[ 126 18 ] loss: 0.4021492600440979 2022-07-01 00:53:48.678998
Epoch:[ 126 19 ] loss: 0.40340521931648254 2022-07-01 00:53:49.101622
Training_Epoch:[ 126 ] Training_loss: 0.40223140716552735 2022-07-01 00:53:49.102373
learning rate:  0.0034359738368000023
netparams have been saved once 126
val: 1 0.43894749879837036
val: 2 0.44853582978248596
val: 3 0.4282476007938385
val: 4 0.42562606930732727
val: 5 0.42638099193573
val: 6 0.44294801354408264
val: 7 0.43173521757125854
val: 8 0.43266475200653076
val: 9 0.4403250217437744
val: 10 0.4344906806945801
val: 11 0.43375447392463684
val: 12 0.4333990216255188
val: 13 0.44743266701698303
val: 14 0.4377155601978302
val: 15 0.4401880204677582
val: 16 0.441112756729126
val: 17 0.4346057176589966
val: 18 0.4267314672470093
val: 19 0.4429033100605011
val: 20 0.4390040338039398
val_Epoch:[ 126 ] val_loss: 0.43633743524551394 2022-07-01 00:53:52.957906
start training 2022-07-01 00:53:53.058701
Epoch:[ 127 0 ] loss: 0.40349552035331726 2022-07-01 00:54:07.445848
Epoch:[ 127 1 ] loss: 0.3999096155166626 2022-07-01 00:54:07.864827
Epoch:[ 127 2 ] loss: 0.4020022749900818 2022-07-01 00:54:08.286757
Epoch:[ 127 3 ] loss: 0.4011697769165039 2022-07-01 00:54:08.708179
Epoch:[ 127 4 ] loss: 0.4041076898574829 2022-07-01 00:54:09.126779
Epoch:[ 127 5 ] loss: 0.4015420079231262 2022-07-01 00:54:09.550140
Epoch:[ 127 6 ] loss: 0.40112385153770447 2022-07-01 00:54:09.971779
Epoch:[ 127 7 ] loss: 0.4033580720424652 2022-07-01 00:54:10.392274
Epoch:[ 127 8 ] loss: 0.40288108587265015 2022-07-01 00:54:10.810814
Epoch:[ 127 9 ] loss: 0.39840784668922424 2022-07-01 00:54:11.230627
Epoch:[ 127 10 ] loss: 0.4021562337875366 2022-07-01 00:54:11.652557
Epoch:[ 127 11 ] loss: 0.4015822410583496 2022-07-01 00:54:12.072718
Epoch:[ 127 12 ] loss: 0.4034729301929474 2022-07-01 00:54:12.493747
Epoch:[ 127 13 ] loss: 0.4018917381763458 2022-07-01 00:54:12.914163
Epoch:[ 127 14 ] loss: 0.4010482728481293 2022-07-01 00:54:13.337219
Epoch:[ 127 15 ] loss: 0.4004199504852295 2022-07-01 00:54:13.751876
Epoch:[ 127 16 ] loss: 0.40204018354415894 2022-07-01 00:54:19.297568
Epoch:[ 127 17 ] loss: 0.40192902088165283 2022-07-01 00:54:19.717238
Epoch:[ 127 18 ] loss: 0.40211057662963867 2022-07-01 00:54:20.137163
Epoch:[ 127 19 ] loss: 0.3996804654598236 2022-07-01 00:54:20.559782
Training_Epoch:[ 127 ] Training_loss: 0.40171646773815156 2022-07-01 00:54:20.560620
learning rate:  0.0034359738368000023
val: 1 0.4386688768863678
val: 2 0.42912063002586365
val: 3 0.43013831973075867
val: 4 0.4464414715766907
val: 5 0.43958568572998047
val: 6 0.44142353534698486
val: 7 0.45489421486854553
val: 8 0.43945127725601196
val: 9 0.4326333701610565
val: 10 0.4268580973148346
val: 11 0.4380956292152405
val: 12 0.44375693798065186
val: 13 0.43867191672325134
val: 14 0.4436682164669037
val: 15 0.4356602430343628
val: 16 0.44473400712013245
val: 17 0.43786412477493286
val: 18 0.436165452003479
val: 19 0.43057453632354736
val: 20 0.43207868933677673
val_Epoch:[ 127 ] val_loss: 0.4380242615938187 2022-07-01 00:54:24.361375
start training 2022-07-01 00:54:24.461833
Epoch:[ 128 0 ] loss: 0.3982674181461334 2022-07-01 00:54:38.952055
Epoch:[ 128 1 ] loss: 0.3997191786766052 2022-07-01 00:54:39.372409
Epoch:[ 128 2 ] loss: 0.4009670317173004 2022-07-01 00:54:39.793136
Epoch:[ 128 3 ] loss: 0.3995765447616577 2022-07-01 00:54:40.217926
Epoch:[ 128 4 ] loss: 0.39840444922447205 2022-07-01 00:54:40.639321
Epoch:[ 128 5 ] loss: 0.40198808908462524 2022-07-01 00:54:41.059300
Epoch:[ 128 6 ] loss: 0.40231260657310486 2022-07-01 00:54:41.481498
Epoch:[ 128 7 ] loss: 0.4024296700954437 2022-07-01 00:54:41.903461
Epoch:[ 128 8 ] loss: 0.40137049555778503 2022-07-01 00:54:42.325102
Epoch:[ 128 9 ] loss: 0.401513010263443 2022-07-01 00:54:42.745811
Epoch:[ 128 10 ] loss: 0.40192940831184387 2022-07-01 00:54:43.166420
Epoch:[ 128 11 ] loss: 0.39985883235931396 2022-07-01 00:54:43.586633
Epoch:[ 128 12 ] loss: 0.4023424983024597 2022-07-01 00:54:44.007454
Epoch:[ 128 13 ] loss: 0.4010215103626251 2022-07-01 00:54:44.429614
Epoch:[ 128 14 ] loss: 0.402528315782547 2022-07-01 00:54:44.851578
Epoch:[ 128 15 ] loss: 0.4023132920265198 2022-07-01 00:54:45.266208
Epoch:[ 128 16 ] loss: 0.40117359161376953 2022-07-01 00:54:50.963813
Epoch:[ 128 17 ] loss: 0.40198975801467896 2022-07-01 00:54:51.384190
Epoch:[ 128 18 ] loss: 0.4019235670566559 2022-07-01 00:54:51.806149
Epoch:[ 128 19 ] loss: 0.402794748544693 2022-07-01 00:54:52.224552
Training_Epoch:[ 128 ] Training_loss: 0.4012212008237839 2022-07-01 00:54:52.225192
learning rate:  0.0034359738368000023
netparams have been saved once 128
val: 1 0.4327588975429535
val: 2 0.4357951283454895
val: 3 0.4425230324268341
val: 4 0.44163644313812256
val: 5 0.446420282125473
val: 6 0.44234126806259155
val: 7 0.42623457312583923
val: 8 0.4302677512168884
val: 9 0.43908292055130005
val: 10 0.4320754110813141
val: 11 0.44633248448371887
val: 12 0.4462881088256836
val: 13 0.43127328157424927
val: 14 0.4268145263195038
val: 15 0.4465188980102539
val: 16 0.4387660622596741
val: 17 0.44016900658607483
val: 18 0.4279913902282715
val: 19 0.4301961660385132
val: 20 0.43822285532951355
val_Epoch:[ 128 ] val_loss: 0.43708542436361314 2022-07-01 00:54:56.046926
start training 2022-07-01 00:54:56.149831
Epoch:[ 129 0 ] loss: 0.4015263319015503 2022-07-01 00:55:10.652005
Epoch:[ 129 1 ] loss: 0.4033017158508301 2022-07-01 00:55:11.073412
Epoch:[ 129 2 ] loss: 0.4013539254665375 2022-07-01 00:55:11.495259
Epoch:[ 129 3 ] loss: 0.3993280231952667 2022-07-01 00:55:11.914422
Epoch:[ 129 4 ] loss: 0.4028204083442688 2022-07-01 00:55:12.335988
Epoch:[ 129 5 ] loss: 0.400206595659256 2022-07-01 00:55:12.756796
Epoch:[ 129 6 ] loss: 0.4005071520805359 2022-07-01 00:55:13.170268
Epoch:[ 129 7 ] loss: 0.40015697479248047 2022-07-01 00:55:13.592638
Epoch:[ 129 8 ] loss: 0.400844007730484 2022-07-01 00:55:14.010514
Epoch:[ 129 9 ] loss: 0.4005897343158722 2022-07-01 00:55:14.430836
Epoch:[ 129 10 ] loss: 0.40313300490379333 2022-07-01 00:55:14.851342
Epoch:[ 129 11 ] loss: 0.4033554792404175 2022-07-01 00:55:15.272891
Epoch:[ 129 12 ] loss: 0.3996506333351135 2022-07-01 00:55:15.693205
Epoch:[ 129 13 ] loss: 0.401782751083374 2022-07-01 00:55:16.114739
Epoch:[ 129 14 ] loss: 0.4015211760997772 2022-07-01 00:55:16.537245
Epoch:[ 129 15 ] loss: 0.4018201529979706 2022-07-01 00:55:16.958924
Epoch:[ 129 16 ] loss: 0.40176886320114136 2022-07-01 00:55:22.692162
Epoch:[ 129 17 ] loss: 0.4003428816795349 2022-07-01 00:55:23.114064
Epoch:[ 129 18 ] loss: 0.4008077383041382 2022-07-01 00:55:23.535859
Epoch:[ 129 19 ] loss: 0.400805801153183 2022-07-01 00:55:23.956527
Training_Epoch:[ 129 ] Training_loss: 0.4012811675667763 2022-07-01 00:55:23.957188
learning rate:  0.0034359738368000023
val: 1 0.4401375651359558
val: 2 0.44599196314811707
val: 3 0.43453407287597656
val: 4 0.4343019425868988
val: 5 0.4377118647098541
val: 6 0.431833416223526
val: 7 0.4547378122806549
val: 8 0.4355829656124115
val: 9 0.43694084882736206
val: 10 0.43413877487182617
val: 11 0.4319095015525818
val: 12 0.4279201030731201
val: 13 0.4181705415248871
val: 14 0.44563767313957214
val: 15 0.4342942237854004
val: 16 0.4409027397632599
val: 17 0.43860089778900146
val: 18 0.4361562728881836
val: 19 0.442199170589447
val: 20 0.43219226598739624
val_Epoch:[ 129 ] val_loss: 0.43669473081827165 2022-07-01 00:55:27.708125
start training 2022-07-01 00:55:27.811467
Epoch:[ 130 0 ] loss: 0.40133604407310486 2022-07-01 00:55:42.726413
Epoch:[ 130 1 ] loss: 0.40190452337265015 2022-07-01 00:55:43.150132
Epoch:[ 130 2 ] loss: 0.4005589485168457 2022-07-01 00:55:43.571684
Epoch:[ 130 3 ] loss: 0.39908912777900696 2022-07-01 00:55:43.993919
Epoch:[ 130 4 ] loss: 0.4013744294643402 2022-07-01 00:55:44.416359
Epoch:[ 130 5 ] loss: 0.40038055181503296 2022-07-01 00:55:44.836954
Epoch:[ 130 6 ] loss: 0.40135297179222107 2022-07-01 00:55:45.257238
Epoch:[ 130 7 ] loss: 0.4013543725013733 2022-07-01 00:55:45.677955
Epoch:[ 130 8 ] loss: 0.40137818455696106 2022-07-01 00:55:46.100369
Epoch:[ 130 9 ] loss: 0.4024386405944824 2022-07-01 00:55:46.522793
Epoch:[ 130 10 ] loss: 0.4005456268787384 2022-07-01 00:55:46.944267
Epoch:[ 130 11 ] loss: 0.40093058347702026 2022-07-01 00:55:47.367699
Epoch:[ 130 12 ] loss: 0.3989924192428589 2022-07-01 00:55:47.791958
Epoch:[ 130 13 ] loss: 0.39863210916519165 2022-07-01 00:55:48.212252
Epoch:[ 130 14 ] loss: 0.40400850772857666 2022-07-01 00:55:48.632213
Epoch:[ 130 15 ] loss: 0.3998275101184845 2022-07-01 00:55:49.048278
Epoch:[ 130 16 ] loss: 0.4009266495704651 2022-07-01 00:55:54.073011
Epoch:[ 130 17 ] loss: 0.4025157690048218 2022-07-01 00:55:54.492642
Epoch:[ 130 18 ] loss: 0.40097784996032715 2022-07-01 00:55:54.914037
Epoch:[ 130 19 ] loss: 0.40164992213249207 2022-07-01 00:55:55.334938
Training_Epoch:[ 130 ] Training_loss: 0.40100873708724977 2022-07-01 00:55:55.335641
learning rate:  0.0034359738368000023
netparams have been saved once 130
val: 1 0.4408312737941742
val: 2 0.4390273094177246
val: 3 0.4398355782032013
val: 4 0.43155601620674133
val: 5 0.429450660943985
val: 6 0.4405535161495209
val: 7 0.4375738203525543
val: 8 0.4390656352043152
val: 9 0.43331360816955566
val: 10 0.4423297643661499
val: 11 0.4370322525501251
val: 12 0.44024714827537537
val: 13 0.4385262727737427
val: 14 0.43013671040534973
val: 15 0.434139221906662
val: 16 0.42698878049850464
val: 17 0.43106475472450256
val: 18 0.43223637342453003
val: 19 0.43993741273880005
val: 20 0.4410800337791443
val_Epoch:[ 130 ] val_loss: 0.43624630719423296 2022-07-01 00:55:59.151213
start training 2022-07-01 00:55:59.253123
Epoch:[ 131 0 ] loss: 0.39855116605758667 2022-07-01 00:56:13.072690
Epoch:[ 131 1 ] loss: 0.3983766734600067 2022-07-01 00:56:13.513978
Epoch:[ 131 2 ] loss: 0.3989282548427582 2022-07-01 00:56:13.954839
Epoch:[ 131 3 ] loss: 0.4004470109939575 2022-07-01 00:56:14.375806
Epoch:[ 131 4 ] loss: 0.39960137009620667 2022-07-01 00:56:14.799055
Epoch:[ 131 5 ] loss: 0.3979383707046509 2022-07-01 00:56:15.218495
Epoch:[ 131 6 ] loss: 0.400285542011261 2022-07-01 00:56:15.639857
Epoch:[ 131 7 ] loss: 0.40067028999328613 2022-07-01 00:56:16.063821
Epoch:[ 131 8 ] loss: 0.4010547995567322 2022-07-01 00:56:16.483931
Epoch:[ 131 9 ] loss: 0.39820513129234314 2022-07-01 00:56:16.904878
Epoch:[ 131 10 ] loss: 0.39981329441070557 2022-07-01 00:56:17.327457
Epoch:[ 131 11 ] loss: 0.4012487232685089 2022-07-01 00:56:17.749214
Epoch:[ 131 12 ] loss: 0.4023387134075165 2022-07-01 00:56:18.169894
Epoch:[ 131 13 ] loss: 0.39850857853889465 2022-07-01 00:56:18.594313
Epoch:[ 131 14 ] loss: 0.4002358019351959 2022-07-01 00:56:19.015604
Epoch:[ 131 15 ] loss: 0.4000362753868103 2022-07-01 00:56:19.435649
Epoch:[ 131 16 ] loss: 0.39902180433273315 2022-07-01 00:56:24.844006
Epoch:[ 131 17 ] loss: 0.39938807487487793 2022-07-01 00:56:25.287506
Epoch:[ 131 18 ] loss: 0.402817964553833 2022-07-01 00:56:25.715607
Epoch:[ 131 19 ] loss: 0.3998975455760956 2022-07-01 00:56:26.138597
Training_Epoch:[ 131 ] Training_loss: 0.39986826926469804 2022-07-01 00:56:26.139312
learning rate:  0.002748779069440002
val: 1 0.44219648838043213
val: 2 0.4347001314163208
val: 3 0.43227559328079224
val: 4 0.4497860372066498
val: 5 0.430221825838089
val: 6 0.4488818645477295
val: 7 0.43635231256484985
val: 8 0.43410661816596985
val: 9 0.4245493710041046
val: 10 0.46271565556526184
val: 11 0.42895713448524475
val: 12 0.4287891387939453
val: 13 0.42786216735839844
val: 14 0.43307772278785706
val: 15 0.4258018136024475
val: 16 0.43257471919059753
val: 17 0.4366128444671631
val: 18 0.4533666968345642
val: 19 0.4399369955062866
val: 20 0.44410210847854614
val_Epoch:[ 131 ] val_loss: 0.4373433619737625 2022-07-01 00:56:29.825259
start training 2022-07-01 00:56:29.927533
Epoch:[ 132 0 ] loss: 0.3991965651512146 2022-07-01 00:56:44.020239
Epoch:[ 132 1 ] loss: 0.3984653055667877 2022-07-01 00:56:44.472883
Epoch:[ 132 2 ] loss: 0.3991048336029053 2022-07-01 00:56:44.912551
Epoch:[ 132 3 ] loss: 0.3989260792732239 2022-07-01 00:56:45.335462
Epoch:[ 132 4 ] loss: 0.4013863801956177 2022-07-01 00:56:45.757829
Epoch:[ 132 5 ] loss: 0.3980880379676819 2022-07-01 00:56:46.181198
Epoch:[ 132 6 ] loss: 0.3976835012435913 2022-07-01 00:56:46.606065
Epoch:[ 132 7 ] loss: 0.40066686272621155 2022-07-01 00:56:47.025738
Epoch:[ 132 8 ] loss: 0.39736074209213257 2022-07-01 00:56:47.446495
Epoch:[ 132 9 ] loss: 0.39985719323158264 2022-07-01 00:56:47.865857
Epoch:[ 132 10 ] loss: 0.39976152777671814 2022-07-01 00:56:48.285506
Epoch:[ 132 11 ] loss: 0.39857202768325806 2022-07-01 00:56:48.695753
Epoch:[ 132 12 ] loss: 0.39839938282966614 2022-07-01 00:56:49.103901
Epoch:[ 132 13 ] loss: 0.3993629217147827 2022-07-01 00:56:49.512358
Epoch:[ 132 14 ] loss: 0.39999544620513916 2022-07-01 00:56:49.922293
Epoch:[ 132 15 ] loss: 0.4004684090614319 2022-07-01 00:56:50.331772
Epoch:[ 132 16 ] loss: 0.39962533116340637 2022-07-01 00:56:56.023856
Epoch:[ 132 17 ] loss: 0.40135031938552856 2022-07-01 00:56:56.433492
Epoch:[ 132 18 ] loss: 0.3999573588371277 2022-07-01 00:56:56.851328
Epoch:[ 132 19 ] loss: 0.4011888802051544 2022-07-01 00:56:57.268656
Training_Epoch:[ 132 ] Training_loss: 0.3994708552956581 2022-07-01 00:56:57.269381
learning rate:  0.002748779069440002
netparams have been saved once 132
val: 1 0.43104279041290283
val: 2 0.4417692720890045
val: 3 0.4397757947444916
val: 4 0.4292556047439575
val: 5 0.43749701976776123
val: 6 0.44147276878356934
val: 7 0.42396289110183716
val: 8 0.44908222556114197
val: 9 0.43266919255256653
val: 10 0.44405069947242737
val: 11 0.4384165406227112
val: 12 0.43672579526901245
val: 13 0.4354779124259949
val: 14 0.43829116225242615
val: 15 0.44451695680618286
val: 16 0.4390052556991577
val: 17 0.44135943055152893
val: 18 0.4305424988269806
val: 19 0.4329944849014282
val: 20 0.438383013010025
val_Epoch:[ 132 ] val_loss: 0.4373145654797554 2022-07-01 00:57:01.117172
start training 2022-07-01 00:57:01.219764
Epoch:[ 133 0 ] loss: 0.4010981023311615 2022-07-01 00:57:15.217514
Epoch:[ 133 1 ] loss: 0.4009134769439697 2022-07-01 00:57:15.737310
Epoch:[ 133 2 ] loss: 0.39672422409057617 2022-07-01 00:57:16.160627
Epoch:[ 133 3 ] loss: 0.39693930745124817 2022-07-01 00:57:16.581324
Epoch:[ 133 4 ] loss: 0.4006170630455017 2022-07-01 00:57:17.003087
Epoch:[ 133 5 ] loss: 0.39907774329185486 2022-07-01 00:57:17.424870
Epoch:[ 133 6 ] loss: 0.3973369896411896 2022-07-01 00:57:17.846472
Epoch:[ 133 7 ] loss: 0.39891335368156433 2022-07-01 00:57:18.269492
Epoch:[ 133 8 ] loss: 0.4005507826805115 2022-07-01 00:57:18.690831
Epoch:[ 133 9 ] loss: 0.39516302943229675 2022-07-01 00:57:19.110197
Epoch:[ 133 10 ] loss: 0.3979830741882324 2022-07-01 00:57:19.530376
Epoch:[ 133 11 ] loss: 0.39946213364601135 2022-07-01 00:57:19.945828
Epoch:[ 133 12 ] loss: 0.3988305926322937 2022-07-01 00:57:20.367822
Epoch:[ 133 13 ] loss: 0.3986034095287323 2022-07-01 00:57:20.790633
Epoch:[ 133 14 ] loss: 0.39853593707084656 2022-07-01 00:57:21.212645
Epoch:[ 133 15 ] loss: 0.40003734827041626 2022-07-01 00:57:21.632314
Epoch:[ 133 16 ] loss: 0.40215399861335754 2022-07-01 00:57:27.607544
Epoch:[ 133 17 ] loss: 0.40039488673210144 2022-07-01 00:57:28.026048
Epoch:[ 133 18 ] loss: 0.39906108379364014 2022-07-01 00:57:28.456546
Epoch:[ 133 19 ] loss: 0.3988906145095825 2022-07-01 00:57:28.876740
Training_Epoch:[ 133 ] Training_loss: 0.3990643575787544 2022-07-01 00:57:28.877407
learning rate:  0.002748779069440002
val: 1 0.45038291811943054
val: 2 0.4396868944168091
val: 3 0.43625298142433167
val: 4 0.44704246520996094
val: 5 0.4334065914154053
val: 6 0.4418901205062866
val: 7 0.44078269600868225
val: 8 0.4316004514694214
val: 9 0.4364631474018097
val: 10 0.4357973039150238
val: 11 0.4381107985973358
val: 12 0.4411236345767975
val: 13 0.4344736337661743
val: 14 0.4286918044090271
val: 15 0.4452837109565735
val: 16 0.4344698488712311
val: 17 0.44224533438682556
val: 18 0.4325334429740906
val: 19 0.4385834038257599
val: 20 0.4425787925720215
val_Epoch:[ 133 ] val_loss: 0.4385699987411499 2022-07-01 00:57:32.674374
start training 2022-07-01 00:57:32.777840
Epoch:[ 134 0 ] loss: 0.39749544858932495 2022-07-01 00:57:46.964087
Epoch:[ 134 1 ] loss: 0.3977099657058716 2022-07-01 00:57:47.404139
Epoch:[ 134 2 ] loss: 0.4004572629928589 2022-07-01 00:57:47.824740
Epoch:[ 134 3 ] loss: 0.3982072174549103 2022-07-01 00:57:48.238426
Epoch:[ 134 4 ] loss: 0.3997184932231903 2022-07-01 00:57:48.659990
Epoch:[ 134 5 ] loss: 0.39669540524482727 2022-07-01 00:57:49.081978
Epoch:[ 134 6 ] loss: 0.4011884927749634 2022-07-01 00:57:49.503578
Epoch:[ 134 7 ] loss: 0.3994131088256836 2022-07-01 00:57:49.926797
Epoch:[ 134 8 ] loss: 0.4007120132446289 2022-07-01 00:57:50.346663
Epoch:[ 134 9 ] loss: 0.39901968836784363 2022-07-01 00:57:50.766857
Epoch:[ 134 10 ] loss: 0.40075913071632385 2022-07-01 00:57:51.187489
Epoch:[ 134 11 ] loss: 0.3982561528682709 2022-07-01 00:57:51.608806
Epoch:[ 134 12 ] loss: 0.39619576930999756 2022-07-01 00:57:52.031968
Epoch:[ 134 13 ] loss: 0.39941591024398804 2022-07-01 00:57:52.457444
Epoch:[ 134 14 ] loss: 0.40051960945129395 2022-07-01 00:57:52.880793
Epoch:[ 134 15 ] loss: 0.39925551414489746 2022-07-01 00:57:53.301951
Epoch:[ 134 16 ] loss: 0.4008025527000427 2022-07-01 00:57:58.682239
Epoch:[ 134 17 ] loss: 0.39790964126586914 2022-07-01 00:57:59.104631
Epoch:[ 134 18 ] loss: 0.39883026480674744 2022-07-01 00:57:59.525161
Epoch:[ 134 19 ] loss: 0.3990805149078369 2022-07-01 00:57:59.946379
Training_Epoch:[ 134 ] Training_loss: 0.3990821078419685 2022-07-01 00:57:59.947050
learning rate:  0.002748779069440002
netparams have been saved once 134
val: 1 0.4351612627506256
val: 2 0.4308815002441406
val: 3 0.44696664810180664
val: 4 0.43080946803092957
val: 5 0.442659854888916
val: 6 0.43586012721061707
val: 7 0.44829657673835754
val: 8 0.4389021098613739
val: 9 0.4441768527030945
val: 10 0.4318740665912628
val: 11 0.4454007148742676
val: 12 0.43207383155822754
val: 13 0.4399557113647461
val: 14 0.4267057776451111
val: 15 0.4453309178352356
val: 16 0.4275639057159424
val: 17 0.43776947259902954
val: 18 0.4398077428340912
val: 19 0.4459916055202484
val: 20 0.4367707669734955
val_Epoch:[ 134 ] val_loss: 0.43814794570207594 2022-07-01 00:58:03.766351
start training 2022-07-01 00:58:03.869771
Epoch:[ 135 0 ] loss: 0.39687249064445496 2022-07-01 00:58:18.021060
Epoch:[ 135 1 ] loss: 0.39863893389701843 2022-07-01 00:58:18.467502
Epoch:[ 135 2 ] loss: 0.3982386887073517 2022-07-01 00:58:18.888959
Epoch:[ 135 3 ] loss: 0.3979380130767822 2022-07-01 00:58:19.312122
Epoch:[ 135 4 ] loss: 0.39864441752433777 2022-07-01 00:58:19.732440
Epoch:[ 135 5 ] loss: 0.3994259238243103 2022-07-01 00:58:20.145989
Epoch:[ 135 6 ] loss: 0.3971879482269287 2022-07-01 00:58:20.568118
Epoch:[ 135 7 ] loss: 0.4009019434452057 2022-07-01 00:58:20.990556
Epoch:[ 135 8 ] loss: 0.39722222089767456 2022-07-01 00:58:21.411157
Epoch:[ 135 9 ] loss: 0.39961016178131104 2022-07-01 00:58:21.832022
Epoch:[ 135 10 ] loss: 0.39866945147514343 2022-07-01 00:58:22.252406
Epoch:[ 135 11 ] loss: 0.4014746844768524 2022-07-01 00:58:22.672917
Epoch:[ 135 12 ] loss: 0.39956822991371155 2022-07-01 00:58:23.092341
Epoch:[ 135 13 ] loss: 0.39920341968536377 2022-07-01 00:58:23.513950
Epoch:[ 135 14 ] loss: 0.3962085545063019 2022-07-01 00:58:23.936732
Epoch:[ 135 15 ] loss: 0.4002728760242462 2022-07-01 00:58:24.356724
Epoch:[ 135 16 ] loss: 0.39995723962783813 2022-07-01 00:58:30.006875
Epoch:[ 135 17 ] loss: 0.4001002907752991 2022-07-01 00:58:30.427362
Epoch:[ 135 18 ] loss: 0.3985905349254608 2022-07-01 00:58:30.848349
Epoch:[ 135 19 ] loss: 0.4005486071109772 2022-07-01 00:58:31.267556
Training_Epoch:[ 135 ] Training_loss: 0.3989637315273285 2022-07-01 00:58:31.268232
learning rate:  0.002748779069440002
val: 1 0.43630146980285645
val: 2 0.43360573053359985
val: 3 0.43854856491088867
val: 4 0.43229904770851135
val: 5 0.434183806180954
val: 6 0.433915913105011
val: 7 0.4432736933231354
val: 8 0.43322134017944336
val: 9 0.4429183304309845
val: 10 0.429242879152298
val: 11 0.44811996817588806
val: 12 0.4255051910877228
val: 13 0.44129621982574463
val: 14 0.43762513995170593
val: 15 0.4430699944496155
val: 16 0.4331018030643463
val: 17 0.43436694145202637
val: 18 0.44375160336494446
val: 19 0.4312448501586914
val: 20 0.43241578340530396
val_Epoch:[ 135 ] val_loss: 0.4364004135131836 2022-07-01 00:58:35.019477
start training 2022-07-01 00:58:35.125006
Epoch:[ 136 0 ] loss: 0.39834022521972656 2022-07-01 00:58:49.800340
Epoch:[ 136 1 ] loss: 0.3980237543582916 2022-07-01 00:58:50.223388
Epoch:[ 136 2 ] loss: 0.3984106481075287 2022-07-01 00:58:50.645322
Epoch:[ 136 3 ] loss: 0.396581768989563 2022-07-01 00:58:51.065740
Epoch:[ 136 4 ] loss: 0.4003159701824188 2022-07-01 00:58:51.486695
Epoch:[ 136 5 ] loss: 0.3978412449359894 2022-07-01 00:58:51.907199
Epoch:[ 136 6 ] loss: 0.3979211151599884 2022-07-01 00:58:52.321861
Epoch:[ 136 7 ] loss: 0.39802467823028564 2022-07-01 00:58:52.743262
Epoch:[ 136 8 ] loss: 0.3993765115737915 2022-07-01 00:58:53.168420
Epoch:[ 136 9 ] loss: 0.39835676550865173 2022-07-01 00:58:53.591221
Epoch:[ 136 10 ] loss: 0.39892664551734924 2022-07-01 00:58:54.012028
Epoch:[ 136 11 ] loss: 0.40147271752357483 2022-07-01 00:58:54.429664
Epoch:[ 136 12 ] loss: 0.3997216522693634 2022-07-01 00:58:54.852231
Epoch:[ 136 13 ] loss: 0.3981958031654358 2022-07-01 00:58:55.272650
Epoch:[ 136 14 ] loss: 0.3963579833507538 2022-07-01 00:58:55.697236
Epoch:[ 136 15 ] loss: 0.40330249071121216 2022-07-01 00:58:56.119779
Epoch:[ 136 16 ] loss: 0.3991737365722656 2022-07-01 00:59:01.585071
Epoch:[ 136 17 ] loss: 0.4021787941455841 2022-07-01 00:59:02.004559
Epoch:[ 136 18 ] loss: 0.39833030104637146 2022-07-01 00:59:02.426809
Epoch:[ 136 19 ] loss: 0.39728856086730957 2022-07-01 00:59:02.847105
Training_Epoch:[ 136 ] Training_loss: 0.39890706837177276 2022-07-01 00:59:02.847803
learning rate:  0.002748779069440002
netparams have been saved once 136
val: 1 0.4426538050174713
val: 2 0.4320403039455414
val: 3 0.44231459498405457
val: 4 0.4423104524612427
val: 5 0.4454359710216522
val: 6 0.4495253264904022
val: 7 0.4246395230293274
val: 8 0.4349856972694397
val: 9 0.435167133808136
val: 10 0.4346010088920593
val: 11 0.4398215115070343
val: 12 0.4373505115509033
val: 13 0.4445848762989044
val: 14 0.4426347315311432
val: 15 0.4338797926902771
val: 16 0.44353556632995605
val: 17 0.4367743134498596
val: 18 0.4300675094127655
val: 19 0.42820101976394653
val: 20 0.43253520131111145
val_Epoch:[ 136 ] val_loss: 0.4376529425382614 2022-07-01 00:59:06.688997
start training 2022-07-01 00:59:06.791222
Epoch:[ 137 0 ] loss: 0.3980897068977356 2022-07-01 00:59:20.821736
Epoch:[ 137 1 ] loss: 0.39595696330070496 2022-07-01 00:59:21.256263
Epoch:[ 137 2 ] loss: 0.4013398587703705 2022-07-01 00:59:21.679064
Epoch:[ 137 3 ] loss: 0.4005511999130249 2022-07-01 00:59:22.094254
Epoch:[ 137 4 ] loss: 0.4007177948951721 2022-07-01 00:59:22.515292
Epoch:[ 137 5 ] loss: 0.39868539571762085 2022-07-01 00:59:22.924505
Epoch:[ 137 6 ] loss: 0.3988358676433563 2022-07-01 00:59:23.333865
Epoch:[ 137 7 ] loss: 0.40137535333633423 2022-07-01 00:59:23.743603
Epoch:[ 137 8 ] loss: 0.39822977781295776 2022-07-01 00:59:24.155723
Epoch:[ 137 9 ] loss: 0.3970377445220947 2022-07-01 00:59:24.564547
Epoch:[ 137 10 ] loss: 0.4020777940750122 2022-07-01 00:59:24.975434
Epoch:[ 137 11 ] loss: 0.398777037858963 2022-07-01 00:59:25.385747
Epoch:[ 137 12 ] loss: 0.39725908637046814 2022-07-01 00:59:25.794087
Epoch:[ 137 13 ] loss: 0.3992997407913208 2022-07-01 00:59:26.201987
Epoch:[ 137 14 ] loss: 0.3973604440689087 2022-07-01 00:59:26.612020
Epoch:[ 137 15 ] loss: 0.39917102456092834 2022-07-01 00:59:27.022230
Epoch:[ 137 16 ] loss: 0.40103113651275635 2022-07-01 00:59:32.819762
Epoch:[ 137 17 ] loss: 0.39765414595603943 2022-07-01 00:59:33.232980
Epoch:[ 137 18 ] loss: 0.4002642333507538 2022-07-01 00:59:33.652375
Epoch:[ 137 19 ] loss: 0.3970637023448944 2022-07-01 00:59:34.065500
Training_Epoch:[ 137 ] Training_loss: 0.39903890043497087 2022-07-01 00:59:34.066628
learning rate:  0.002748779069440002
val: 1 0.44030672311782837
val: 2 0.4331553280353546
val: 3 0.4413486421108246
val: 4 0.4326626658439636
val: 5 0.43931278586387634
val: 6 0.4321785271167755
val: 7 0.4363084137439728
val: 8 0.42708900570869446
val: 9 0.4559352695941925
val: 10 0.43599796295166016
val: 11 0.4438127875328064
val: 12 0.44972336292266846
val: 13 0.44883155822753906
val: 14 0.43632879853248596
val: 15 0.43547630310058594
val: 16 0.44696128368377686
val: 17 0.43907248973846436
val: 18 0.43679365515708923
val: 19 0.436027854681015
val: 20 0.429536372423172
val_Epoch:[ 137 ] val_loss: 0.4388429895043373 2022-07-01 00:59:37.909989
start training 2022-07-01 00:59:38.012259
Epoch:[ 138 0 ] loss: 0.39863789081573486 2022-07-01 00:59:52.210546
Epoch:[ 138 1 ] loss: 0.3970639109611511 2022-07-01 00:59:52.655640
Epoch:[ 138 2 ] loss: 0.3973987102508545 2022-07-01 00:59:53.078546
Epoch:[ 138 3 ] loss: 0.3970959186553955 2022-07-01 00:59:53.499496
Epoch:[ 138 4 ] loss: 0.4000962972640991 2022-07-01 00:59:53.921895
Epoch:[ 138 5 ] loss: 0.39749962091445923 2022-07-01 00:59:54.342200
Epoch:[ 138 6 ] loss: 0.3976875841617584 2022-07-01 00:59:54.764269
Epoch:[ 138 7 ] loss: 0.3986956775188446 2022-07-01 00:59:55.184106
Epoch:[ 138 8 ] loss: 0.4010504186153412 2022-07-01 00:59:55.603575
Epoch:[ 138 9 ] loss: 0.399808406829834 2022-07-01 00:59:56.024942
Epoch:[ 138 10 ] loss: 0.3980048894882202 2022-07-01 00:59:56.447229
Epoch:[ 138 11 ] loss: 0.3991377353668213 2022-07-01 00:59:56.870304
Epoch:[ 138 12 ] loss: 0.3978370428085327 2022-07-01 00:59:57.292005
Epoch:[ 138 13 ] loss: 0.3973481059074402 2022-07-01 00:59:57.705448
Epoch:[ 138 14 ] loss: 0.3978176712989807 2022-07-01 00:59:58.115014
Epoch:[ 138 15 ] loss: 0.3972971439361572 2022-07-01 00:59:58.522784
Epoch:[ 138 16 ] loss: 0.39935508370399475 2022-07-01 01:00:04.035590
Epoch:[ 138 17 ] loss: 0.40277495980262756 2022-07-01 01:00:04.457421
Epoch:[ 138 18 ] loss: 0.39810970425605774 2022-07-01 01:00:04.879567
Epoch:[ 138 19 ] loss: 0.3995705544948578 2022-07-01 01:00:05.299510
Training_Epoch:[ 138 ] Training_loss: 0.39861436635255815 2022-07-01 01:00:05.300217
learning rate:  0.002748779069440002
netparams have been saved once 138
val: 1 0.42564138770103455
val: 2 0.4398511052131653
val: 3 0.4535072445869446
val: 4 0.43724921345710754
val: 5 0.44892850518226624
val: 6 0.424864262342453
val: 7 0.4385543465614319
val: 8 0.4400491714477539
val: 9 0.436796635389328
val: 10 0.427198201417923
val: 11 0.4293334186077118
val: 12 0.4375755786895752
val: 13 0.43525415658950806
val: 14 0.4407911002635956
val: 15 0.4479898512363434
val: 16 0.458223819732666
val: 17 0.442808598279953
val: 18 0.4448390007019043
val: 19 0.4361781179904938
val: 20 0.44214099645614624
val_Epoch:[ 138 ] val_loss: 0.43938873559236524 2022-07-01 01:00:09.167908
start training 2022-07-01 01:00:09.269440
Epoch:[ 139 0 ] loss: 0.4006997346878052 2022-07-01 01:00:23.753065
Epoch:[ 139 1 ] loss: 0.39632511138916016 2022-07-01 01:00:24.172879
Epoch:[ 139 2 ] loss: 0.3964507579803467 2022-07-01 01:00:24.592838
Epoch:[ 139 3 ] loss: 0.3989819586277008 2022-07-01 01:00:25.013761
Epoch:[ 139 4 ] loss: 0.3959583342075348 2022-07-01 01:00:25.434521
Epoch:[ 139 5 ] loss: 0.3975640833377838 2022-07-01 01:00:25.854889
Epoch:[ 139 6 ] loss: 0.40047332644462585 2022-07-01 01:00:26.274779
Epoch:[ 139 7 ] loss: 0.39766982197761536 2022-07-01 01:00:26.695224
Epoch:[ 139 8 ] loss: 0.40129679441452026 2022-07-01 01:00:27.115905
Epoch:[ 139 9 ] loss: 0.40095749497413635 2022-07-01 01:00:27.535482
Epoch:[ 139 10 ] loss: 0.3995659649372101 2022-07-01 01:00:27.957678
Epoch:[ 139 11 ] loss: 0.3986915349960327 2022-07-01 01:00:28.379123
Epoch:[ 139 12 ] loss: 0.39805158972740173 2022-07-01 01:00:28.799595
Epoch:[ 139 13 ] loss: 0.3987748920917511 2022-07-01 01:00:29.219812
Epoch:[ 139 14 ] loss: 0.3992134630680084 2022-07-01 01:00:29.633929
Epoch:[ 139 15 ] loss: 0.4002149999141693 2022-07-01 01:00:30.048060
Epoch:[ 139 16 ] loss: 0.39841780066490173 2022-07-01 01:00:35.546666
Epoch:[ 139 17 ] loss: 0.40055322647094727 2022-07-01 01:00:35.966430
Epoch:[ 139 18 ] loss: 0.39959320425987244 2022-07-01 01:00:36.395629
Epoch:[ 139 19 ] loss: 0.40136146545410156 2022-07-01 01:00:36.815507
Training_Epoch:[ 139 ] Training_loss: 0.3990407779812813 2022-07-01 01:00:36.816206
learning rate:  0.002748779069440002
val: 1 0.43579357862472534
val: 2 0.43459582328796387
val: 3 0.4400533437728882
val: 4 0.4321401119232178
val: 5 0.45592716336250305
val: 6 0.42995205521583557
val: 7 0.4321087598800659
val: 8 0.42517760396003723
val: 9 0.4434965252876282
val: 10 0.4405893087387085
val: 11 0.43728938698768616
val: 12 0.44345006346702576
val: 13 0.4290216863155365
val: 14 0.4435732066631317
val: 15 0.43309736251831055
val: 16 0.4453068971633911
val: 17 0.42999017238616943
val: 18 0.438401997089386
val: 19 0.4378608763217926
val: 20 0.4283141493797302
val_Epoch:[ 139 ] val_loss: 0.4368070036172867 2022-07-01 01:00:40.588469
start training 2022-07-01 01:00:40.689943
Epoch:[ 140 0 ] loss: 0.3985147178173065 2022-07-01 01:00:55.487034
Epoch:[ 140 1 ] loss: 0.4012419879436493 2022-07-01 01:00:55.896113
Epoch:[ 140 2 ] loss: 0.3999512493610382 2022-07-01 01:00:56.305306
Epoch:[ 140 3 ] loss: 0.39776885509490967 2022-07-01 01:00:56.713247
Epoch:[ 140 4 ] loss: 0.3969458341598511 2022-07-01 01:00:57.124322
Epoch:[ 140 5 ] loss: 0.40175655484199524 2022-07-01 01:00:57.534920
Epoch:[ 140 6 ] loss: 0.39892223477363586 2022-07-01 01:00:57.947904
Epoch:[ 140 7 ] loss: 0.39581337571144104 2022-07-01 01:00:58.357300
Epoch:[ 140 8 ] loss: 0.39785102009773254 2022-07-01 01:00:58.767222
Epoch:[ 140 9 ] loss: 0.40024250745773315 2022-07-01 01:00:59.174581
Epoch:[ 140 10 ] loss: 0.39670178294181824 2022-07-01 01:00:59.582138
Epoch:[ 140 11 ] loss: 0.39721205830574036 2022-07-01 01:00:59.991629
Epoch:[ 140 12 ] loss: 0.3953699469566345 2022-07-01 01:01:00.409041
Epoch:[ 140 13 ] loss: 0.3973880708217621 2022-07-01 01:01:00.820038
Epoch:[ 140 14 ] loss: 0.39637401700019836 2022-07-01 01:01:01.229089
Epoch:[ 140 15 ] loss: 0.3990061283111572 2022-07-01 01:01:01.639046
Epoch:[ 140 16 ] loss: 0.39983031153678894 2022-07-01 01:01:06.792849
Epoch:[ 140 17 ] loss: 0.3997093439102173 2022-07-01 01:01:07.202504
Epoch:[ 140 18 ] loss: 0.395795613527298 2022-07-01 01:01:07.626413
Epoch:[ 140 19 ] loss: 0.40095916390419006 2022-07-01 01:01:08.048806
Training_Epoch:[ 140 ] Training_loss: 0.39836773872375486 2022-07-01 01:01:08.049610
learning rate:  0.002748779069440002
netparams have been saved once 140
val: 1 0.43633225560188293
val: 2 0.4247038960456848
val: 3 0.4501897990703583
val: 4 0.447294145822525
val: 5 0.42665156722068787
val: 6 0.45114263892173767
val: 7 0.4433820843696594
val: 8 0.43834319710731506
val: 9 0.45769599080085754
val: 10 0.42963364720344543
val: 11 0.42880281805992126
val: 12 0.4281891882419586
val: 13 0.4350503087043762
val: 14 0.4466552734375
val: 15 0.4383133053779602
val: 16 0.4324861466884613
val: 17 0.4440805912017822
val: 18 0.4381888508796692
val: 19 0.43240267038345337
val: 20 0.43015438318252563
val_Epoch:[ 140 ] val_loss: 0.4379846379160881 2022-07-01 01:01:11.880056
start training 2022-07-01 01:01:11.983439
Epoch:[ 141 0 ] loss: 0.39629673957824707 2022-07-01 01:01:26.445011
Epoch:[ 141 1 ] loss: 0.39670535922050476 2022-07-01 01:01:26.865143
Epoch:[ 141 2 ] loss: 0.396628737449646 2022-07-01 01:01:27.284594
Epoch:[ 141 3 ] loss: 0.39781615138053894 2022-07-01 01:01:27.703678
Epoch:[ 141 4 ] loss: 0.3959602415561676 2022-07-01 01:01:28.122732
Epoch:[ 141 5 ] loss: 0.3965644836425781 2022-07-01 01:01:28.537379
Epoch:[ 141 6 ] loss: 0.3981660008430481 2022-07-01 01:01:28.958795
Epoch:[ 141 7 ] loss: 0.3982715606689453 2022-07-01 01:01:29.379204
Epoch:[ 141 8 ] loss: 0.3974763751029968 2022-07-01 01:01:29.801322
Epoch:[ 141 9 ] loss: 0.3976527452468872 2022-07-01 01:01:30.219776
Epoch:[ 141 10 ] loss: 0.3949899971485138 2022-07-01 01:01:30.633198
Epoch:[ 141 11 ] loss: 0.39887306094169617 2022-07-01 01:01:31.052064
Epoch:[ 141 12 ] loss: 0.3975578844547272 2022-07-01 01:01:31.472594
Epoch:[ 141 13 ] loss: 0.3977316915988922 2022-07-01 01:01:31.893739
Epoch:[ 141 14 ] loss: 0.39771270751953125 2022-07-01 01:01:32.313159
Epoch:[ 141 15 ] loss: 0.39742815494537354 2022-07-01 01:01:32.733734
Epoch:[ 141 16 ] loss: 0.39920514822006226 2022-07-01 01:01:38.016531
Epoch:[ 141 17 ] loss: 0.3962962329387665 2022-07-01 01:01:38.435797
Epoch:[ 141 18 ] loss: 0.3965247571468353 2022-07-01 01:01:38.862306
Epoch:[ 141 19 ] loss: 0.3967383801937103 2022-07-01 01:01:39.281764
Training_Epoch:[ 141 ] Training_loss: 0.3972298204898834 2022-07-01 01:01:39.282480
learning rate:  0.002199023255552002
val: 1 0.43552252650260925
val: 2 0.45362588763237
val: 3 0.42998477816581726
val: 4 0.4281195402145386
val: 5 0.43853023648262024
val: 6 0.4249322712421417
val: 7 0.43703123927116394
val: 8 0.4378117620944977
val: 9 0.4368986189365387
val: 10 0.43567806482315063
val: 11 0.44727623462677
val: 12 0.44081971049308777
val: 13 0.4529154598712921
val: 14 0.44193825125694275
val: 15 0.4499329626560211
val: 16 0.4400559663772583
val: 17 0.4303379952907562
val: 18 0.43902355432510376
val: 19 0.4355262517929077
val: 20 0.4341047704219818
val_Epoch:[ 141 ] val_loss: 0.4385033041238785 2022-07-01 01:01:43.097066
start training 2022-07-01 01:01:43.201692
Epoch:[ 142 0 ] loss: 0.39350056648254395 2022-07-01 01:01:57.655183
Epoch:[ 142 1 ] loss: 0.3967911899089813 2022-07-01 01:01:58.075861
Epoch:[ 142 2 ] loss: 0.3992118239402771 2022-07-01 01:01:58.495981
Epoch:[ 142 3 ] loss: 0.3961705267429352 2022-07-01 01:01:58.916492
Epoch:[ 142 4 ] loss: 0.3963651955127716 2022-07-01 01:01:59.337235
Epoch:[ 142 5 ] loss: 0.3979039788246155 2022-07-01 01:01:59.757330
Epoch:[ 142 6 ] loss: 0.39728131890296936 2022-07-01 01:02:00.179285
Epoch:[ 142 7 ] loss: 0.39712774753570557 2022-07-01 01:02:00.596278
Epoch:[ 142 8 ] loss: 0.3972052037715912 2022-07-01 01:02:01.019341
Epoch:[ 142 9 ] loss: 0.39517807960510254 2022-07-01 01:02:01.432792
Epoch:[ 142 10 ] loss: 0.3988814353942871 2022-07-01 01:02:01.853539
Epoch:[ 142 11 ] loss: 0.39846497774124146 2022-07-01 01:02:02.276622
Epoch:[ 142 12 ] loss: 0.3963884711265564 2022-07-01 01:02:02.696654
Epoch:[ 142 13 ] loss: 0.3950948417186737 2022-07-01 01:02:03.118438
Epoch:[ 142 14 ] loss: 0.3971262574195862 2022-07-01 01:02:03.528869
Epoch:[ 142 15 ] loss: 0.39649564027786255 2022-07-01 01:02:03.938242
Epoch:[ 142 16 ] loss: 0.3954051434993744 2022-07-01 01:02:09.272029
Epoch:[ 142 17 ] loss: 0.39740851521492004 2022-07-01 01:02:09.681631
Epoch:[ 142 18 ] loss: 0.3969758450984955 2022-07-01 01:02:10.098298
Epoch:[ 142 19 ] loss: 0.39640286564826965 2022-07-01 01:02:10.507580
Training_Epoch:[ 142 ] Training_loss: 0.39676898121833803 2022-07-01 01:02:10.508289
learning rate:  0.002199023255552002
netparams have been saved once 142
val: 1 0.436909943819046
val: 2 0.43902480602264404
val: 3 0.4332565665245056
val: 4 0.44178542494773865
val: 5 0.4455876350402832
val: 6 0.44165876507759094
val: 7 0.4435899257659912
val: 8 0.43728962540626526
val: 9 0.44685837626457214
val: 10 0.43033501505851746
val: 11 0.44350865483283997
val: 12 0.45616549253463745
val: 13 0.4422552287578583
val: 14 0.43808767199516296
val: 15 0.4264968931674957
val: 16 0.4269283413887024
val: 17 0.44581353664398193
val: 18 0.4408734440803528
val: 19 0.43846943974494934
val: 20 0.42800289392471313
val_Epoch:[ 142 ] val_loss: 0.43914488404989244 2022-07-01 01:02:14.268823
start training 2022-07-01 01:02:14.372581
Epoch:[ 143 0 ] loss: 0.3976503908634186 2022-07-01 01:02:28.219594
Epoch:[ 143 1 ] loss: 0.3952464461326599 2022-07-01 01:02:28.643227
Epoch:[ 143 2 ] loss: 0.39676570892333984 2022-07-01 01:02:29.084107
Epoch:[ 143 3 ] loss: 0.39587149024009705 2022-07-01 01:02:29.504933
Epoch:[ 143 4 ] loss: 0.39468082785606384 2022-07-01 01:02:29.925428
Epoch:[ 143 5 ] loss: 0.3951776921749115 2022-07-01 01:02:30.343905
Epoch:[ 143 6 ] loss: 0.3971445858478546 2022-07-01 01:02:30.762487
Epoch:[ 143 7 ] loss: 0.3976293206214905 2022-07-01 01:02:31.183709
Epoch:[ 143 8 ] loss: 0.39715102314949036 2022-07-01 01:02:31.605216
Epoch:[ 143 9 ] loss: 0.39623400568962097 2022-07-01 01:02:32.024796
Epoch:[ 143 10 ] loss: 0.39772990345954895 2022-07-01 01:02:32.447013
Epoch:[ 143 11 ] loss: 0.3960736393928528 2022-07-01 01:02:32.866859
Epoch:[ 143 12 ] loss: 0.396212100982666 2022-07-01 01:02:33.286605
Epoch:[ 143 13 ] loss: 0.39822918176651 2022-07-01 01:02:33.704442
Epoch:[ 143 14 ] loss: 0.3955586552619934 2022-07-01 01:02:34.125867
Epoch:[ 143 15 ] loss: 0.39634379744529724 2022-07-01 01:02:34.547856
Epoch:[ 143 16 ] loss: 0.39377763867378235 2022-07-01 01:02:39.817937
Epoch:[ 143 17 ] loss: 0.3957017660140991 2022-07-01 01:02:40.236654
Epoch:[ 143 18 ] loss: 0.3973838686943054 2022-07-01 01:02:40.657560
Epoch:[ 143 19 ] loss: 0.3983932435512543 2022-07-01 01:02:41.077058
Training_Epoch:[ 143 ] Training_loss: 0.39644776433706286 2022-07-01 01:02:41.077738
learning rate:  0.002199023255552002
val: 1 0.43131041526794434
val: 2 0.44501635432243347
val: 3 0.4384239912033081
val: 4 0.4364136755466461
val: 5 0.43110182881355286
val: 6 0.45131343603134155
val: 7 0.43376749753952026
val: 8 0.444273978471756
val: 9 0.43381884694099426
val: 10 0.4432622194290161
val: 11 0.44847536087036133
val: 12 0.43192747235298157
val: 13 0.43118658661842346
val: 14 0.4345806837081909
val: 15 0.4349800646305084
val: 16 0.4423058331012726
val: 17 0.4347533583641052
val: 18 0.44720274209976196
val: 19 0.44472089409828186
val: 20 0.439325749874115
val_Epoch:[ 143 ] val_loss: 0.4389080494642258 2022-07-01 01:02:44.909130
start training 2022-07-01 01:02:45.015272
Epoch:[ 144 0 ] loss: 0.39551833271980286 2022-07-01 01:02:58.984882
Epoch:[ 144 1 ] loss: 0.39527538418769836 2022-07-01 01:02:59.426786
Epoch:[ 144 2 ] loss: 0.39688101410865784 2022-07-01 01:02:59.869001
Epoch:[ 144 3 ] loss: 0.39768683910369873 2022-07-01 01:03:00.292451
Epoch:[ 144 4 ] loss: 0.3975756764411926 2022-07-01 01:03:00.713895
Epoch:[ 144 5 ] loss: 0.3939119279384613 2022-07-01 01:03:01.127590
Epoch:[ 144 6 ] loss: 0.39641815423965454 2022-07-01 01:03:01.540552
Epoch:[ 144 7 ] loss: 0.39595186710357666 2022-07-01 01:03:01.953460
Epoch:[ 144 8 ] loss: 0.3968547582626343 2022-07-01 01:03:02.367375
Epoch:[ 144 9 ] loss: 0.3962262272834778 2022-07-01 01:03:02.778510
Epoch:[ 144 10 ] loss: 0.3972617983818054 2022-07-01 01:03:03.191012
Epoch:[ 144 11 ] loss: 0.39748117327690125 2022-07-01 01:03:03.605773
Epoch:[ 144 12 ] loss: 0.39521437883377075 2022-07-01 01:03:04.021554
Epoch:[ 144 13 ] loss: 0.39791572093963623 2022-07-01 01:03:04.430629
Epoch:[ 144 14 ] loss: 0.3959704637527466 2022-07-01 01:03:04.839690
Epoch:[ 144 15 ] loss: 0.3963812589645386 2022-07-01 01:03:05.250742
Epoch:[ 144 16 ] loss: 0.39433997869491577 2022-07-01 01:03:10.957713
Epoch:[ 144 17 ] loss: 0.3975425362586975 2022-07-01 01:03:11.366380
Epoch:[ 144 18 ] loss: 0.39659586548805237 2022-07-01 01:03:11.787114
Epoch:[ 144 19 ] loss: 0.397562175989151 2022-07-01 01:03:12.207832
Training_Epoch:[ 144 ] Training_loss: 0.39642827659845353 2022-07-01 01:03:12.208711
learning rate:  0.002199023255552002
netparams have been saved once 144
val: 1 0.4394517242908478
val: 2 0.4404674470424652
val: 3 0.43288329243659973
val: 4 0.428045392036438
val: 5 0.44375765323638916
val: 6 0.4277431070804596
val: 7 0.4345017075538635
val: 8 0.4362277090549469
val: 9 0.43536072969436646
val: 10 0.4422144591808319
val: 11 0.44758763909339905
val: 12 0.43262678384780884
val: 13 0.4508729875087738
val: 14 0.4389782249927521
val: 15 0.43786585330963135
val: 16 0.44148486852645874
val: 17 0.4358183443546295
val: 18 0.43526411056518555
val: 19 0.44031089544296265
val: 20 0.4324043393135071
val_Epoch:[ 144 ] val_loss: 0.4376933634281158 2022-07-01 01:03:16.052560
start training 2022-07-01 01:03:16.160392
Epoch:[ 145 0 ] loss: 0.3959457278251648 2022-07-01 01:03:30.845868
Epoch:[ 145 1 ] loss: 0.3951904773712158 2022-07-01 01:03:31.269230
Epoch:[ 145 2 ] loss: 0.39653313159942627 2022-07-01 01:03:31.686320
Epoch:[ 145 3 ] loss: 0.3975169360637665 2022-07-01 01:03:32.107732
Epoch:[ 145 4 ] loss: 0.3970983028411865 2022-07-01 01:03:32.531208
Epoch:[ 145 5 ] loss: 0.39957958459854126 2022-07-01 01:03:32.954721
Epoch:[ 145 6 ] loss: 0.3978598713874817 2022-07-01 01:03:33.374819
Epoch:[ 145 7 ] loss: 0.39718809723854065 2022-07-01 01:03:33.792974
Epoch:[ 145 8 ] loss: 0.3921697735786438 2022-07-01 01:03:34.213038
Epoch:[ 145 9 ] loss: 0.39665183424949646 2022-07-01 01:03:34.637395
Epoch:[ 145 10 ] loss: 0.39500582218170166 2022-07-01 01:03:35.058905
Epoch:[ 145 11 ] loss: 0.3967553377151489 2022-07-01 01:03:35.479266
Epoch:[ 145 12 ] loss: 0.3956873416900635 2022-07-01 01:03:35.901831
Epoch:[ 145 13 ] loss: 0.3967159688472748 2022-07-01 01:03:36.322655
Epoch:[ 145 14 ] loss: 0.396820068359375 2022-07-01 01:03:36.743479
Epoch:[ 145 15 ] loss: 0.3968932628631592 2022-07-01 01:03:37.164042
Epoch:[ 145 16 ] loss: 0.3977702558040619 2022-07-01 01:03:42.554642
Epoch:[ 145 17 ] loss: 0.3958747982978821 2022-07-01 01:03:42.978746
Epoch:[ 145 18 ] loss: 0.39765042066574097 2022-07-01 01:03:43.400890
Epoch:[ 145 19 ] loss: 0.39632242918014526 2022-07-01 01:03:43.823401
Training_Epoch:[ 145 ] Training_loss: 0.3965614721179008 2022-07-01 01:03:43.824126
learning rate:  0.002199023255552002
val: 1 0.44620877504348755
val: 2 0.4313531517982483
val: 3 0.4345427453517914
val: 4 0.4411223828792572
val: 5 0.44441813230514526
val: 6 0.42607131600379944
val: 7 0.4528197646141052
val: 8 0.4483502507209778
val: 9 0.4329659342765808
val: 10 0.4291476011276245
val: 11 0.44317176938056946
val: 12 0.44419217109680176
val: 13 0.4339209496974945
val: 14 0.43949055671691895
val: 15 0.43119511008262634
val: 16 0.44324377179145813
val: 17 0.4294302761554718
val: 18 0.43217000365257263
val: 19 0.43616488575935364
val: 20 0.434327095746994
val_Epoch:[ 145 ] val_loss: 0.4377153322100639 2022-07-01 01:03:47.614114
start training 2022-07-01 01:03:47.722206
Epoch:[ 146 0 ] loss: 0.3960702121257782 2022-07-01 01:04:02.137530
Epoch:[ 146 1 ] loss: 0.39536553621292114 2022-07-01 01:04:02.655736
Epoch:[ 146 2 ] loss: 0.39755240082740784 2022-07-01 01:04:03.075290
Epoch:[ 146 3 ] loss: 0.3981894552707672 2022-07-01 01:04:03.495067
Epoch:[ 146 4 ] loss: 0.39736610651016235 2022-07-01 01:04:03.920186
Epoch:[ 146 5 ] loss: 0.39397332072257996 2022-07-01 01:04:04.340461
Epoch:[ 146 6 ] loss: 0.39586374163627625 2022-07-01 01:04:04.762666
Epoch:[ 146 7 ] loss: 0.39470407366752625 2022-07-01 01:04:05.183821
Epoch:[ 146 8 ] loss: 0.3950592875480652 2022-07-01 01:04:05.597643
Epoch:[ 146 9 ] loss: 0.3967996835708618 2022-07-01 01:04:06.019727
Epoch:[ 146 10 ] loss: 0.39721494913101196 2022-07-01 01:04:06.440925
Epoch:[ 146 11 ] loss: 0.3975480794906616 2022-07-01 01:04:06.864427
Epoch:[ 146 12 ] loss: 0.3962346315383911 2022-07-01 01:04:07.284541
Epoch:[ 146 13 ] loss: 0.4004354178905487 2022-07-01 01:04:07.705637
Epoch:[ 146 14 ] loss: 0.3986349403858185 2022-07-01 01:04:08.127708
Epoch:[ 146 15 ] loss: 0.3981351852416992 2022-07-01 01:04:08.547799
Epoch:[ 146 16 ] loss: 0.39453843235969543 2022-07-01 01:04:13.712775
Epoch:[ 146 17 ] loss: 0.3945985436439514 2022-07-01 01:04:14.135604
Epoch:[ 146 18 ] loss: 0.39743223786354065 2022-07-01 01:04:14.566705
Epoch:[ 146 19 ] loss: 0.3947732448577881 2022-07-01 01:04:14.992934
Training_Epoch:[ 146 ] Training_loss: 0.39652447402477264 2022-07-01 01:04:14.993683
learning rate:  0.002199023255552002
netparams have been saved once 146
val: 1 0.42903977632522583
val: 2 0.44229835271835327
val: 3 0.4537109434604645
val: 4 0.4245010018348694
val: 5 0.4473440945148468
val: 6 0.4442523717880249
val: 7 0.43773916363716125
val: 8 0.44465911388397217
val: 9 0.4386689066886902
val: 10 0.4467338025569916
val: 11 0.4337354004383087
val: 12 0.44164028763771057
val: 13 0.44777336716651917
val: 14 0.42878755927085876
val: 15 0.4327794909477234
val: 16 0.43515661358833313
val: 17 0.42890286445617676
val: 18 0.4436914324760437
val: 19 0.43384984135627747
val: 20 0.44339412450790405
val_Epoch:[ 146 ] val_loss: 0.4389329254627228 2022-07-01 01:04:18.796186
start training 2022-07-01 01:04:18.904887
Epoch:[ 147 0 ] loss: 0.39298635721206665 2022-07-01 01:04:33.659925
Epoch:[ 147 1 ] loss: 0.3979484438896179 2022-07-01 01:04:34.074841
Epoch:[ 147 2 ] loss: 0.3959592580795288 2022-07-01 01:04:34.497498
Epoch:[ 147 3 ] loss: 0.39649349451065063 2022-07-01 01:04:34.919854
Epoch:[ 147 4 ] loss: 0.39587441086769104 2022-07-01 01:04:35.347836
Epoch:[ 147 5 ] loss: 0.3958354592323303 2022-07-01 01:04:35.785786
Epoch:[ 147 6 ] loss: 0.39665108919143677 2022-07-01 01:04:36.222147
Epoch:[ 147 7 ] loss: 0.39720696210861206 2022-07-01 01:04:36.643189
Epoch:[ 147 8 ] loss: 0.39624717831611633 2022-07-01 01:04:37.079900
Epoch:[ 147 9 ] loss: 0.395689994096756 2022-07-01 01:04:37.500896
Epoch:[ 147 10 ] loss: 0.39584240317344666 2022-07-01 01:04:37.931581
Epoch:[ 147 11 ] loss: 0.3963141441345215 2022-07-01 01:04:38.353173
Epoch:[ 147 12 ] loss: 0.3967225253582001 2022-07-01 01:04:38.791788
Epoch:[ 147 13 ] loss: 0.3962833881378174 2022-07-01 01:04:39.213917
Epoch:[ 147 14 ] loss: 0.39618000388145447 2022-07-01 01:04:39.652776
Epoch:[ 147 15 ] loss: 0.3938065469264984 2022-07-01 01:04:40.072314
Epoch:[ 147 16 ] loss: 0.3980166018009186 2022-07-01 01:04:45.305630
Epoch:[ 147 17 ] loss: 0.398086816072464 2022-07-01 01:04:45.724658
Epoch:[ 147 18 ] loss: 0.39739230275154114 2022-07-01 01:04:46.147374
Epoch:[ 147 19 ] loss: 0.39719894528388977 2022-07-01 01:04:46.568272
Training_Epoch:[ 147 ] Training_loss: 0.3963368162512779 2022-07-01 01:04:46.568935
learning rate:  0.002199023255552002
val: 1 0.44106385111808777
val: 2 0.440471351146698
val: 3 0.4448833167552948
val: 4 0.4323652982711792
val: 5 0.4482765197753906
val: 6 0.4418071210384369
val: 7 0.4421898424625397
val: 8 0.42897769808769226
val: 9 0.4412940442562103
val: 10 0.4427027404308319
val: 11 0.4347710609436035
val: 12 0.4403572082519531
val: 13 0.43590909242630005
val: 14 0.4267980456352234
val: 15 0.4418085515499115
val: 16 0.44572871923446655
val: 17 0.4490598738193512
val: 18 0.4433637857437134
val: 19 0.4369850158691406
val: 20 0.4336986839771271
val_Epoch:[ 147 ] val_loss: 0.4396255910396576 2022-07-01 01:04:50.330937
start training 2022-07-01 01:04:50.435099
Epoch:[ 148 0 ] loss: 0.3961035907268524 2022-07-01 01:05:04.912032
Epoch:[ 148 1 ] loss: 0.39493170380592346 2022-07-01 01:05:05.357273
Epoch:[ 148 2 ] loss: 0.39651137590408325 2022-07-01 01:05:05.782082
Epoch:[ 148 3 ] loss: 0.3953675925731659 2022-07-01 01:05:06.202430
Epoch:[ 148 4 ] loss: 0.3967568874359131 2022-07-01 01:05:06.622585
Epoch:[ 148 5 ] loss: 0.39763540029525757 2022-07-01 01:05:07.044681
Epoch:[ 148 6 ] loss: 0.39521798491477966 2022-07-01 01:05:07.460918
Epoch:[ 148 7 ] loss: 0.39657455682754517 2022-07-01 01:05:07.882329
Epoch:[ 148 8 ] loss: 0.3971443772315979 2022-07-01 01:05:08.302643
Epoch:[ 148 9 ] loss: 0.39644280076026917 2022-07-01 01:05:08.723047
Epoch:[ 148 10 ] loss: 0.3976006805896759 2022-07-01 01:05:09.144379
Epoch:[ 148 11 ] loss: 0.3954066038131714 2022-07-01 01:05:09.563972
Epoch:[ 148 12 ] loss: 0.3972429931163788 2022-07-01 01:05:09.985644
Epoch:[ 148 13 ] loss: 0.3934810757637024 2022-07-01 01:05:10.407986
Epoch:[ 148 14 ] loss: 0.39538562297821045 2022-07-01 01:05:10.831151
Epoch:[ 148 15 ] loss: 0.394968181848526 2022-07-01 01:05:11.251740
Epoch:[ 148 16 ] loss: 0.39479923248291016 2022-07-01 01:05:16.766366
Epoch:[ 148 17 ] loss: 0.3948545753955841 2022-07-01 01:05:17.186181
Epoch:[ 148 18 ] loss: 0.39590132236480713 2022-07-01 01:05:17.615068
Epoch:[ 148 19 ] loss: 0.3952166438102722 2022-07-01 01:05:18.036694
Training_Epoch:[ 148 ] Training_loss: 0.3958771601319313 2022-07-01 01:05:18.037344
learning rate:  0.002199023255552002
netparams have been saved once 148
val: 1 0.4519612193107605
val: 2 0.44007062911987305
val: 3 0.44122210144996643
val: 4 0.4502170979976654
val: 5 0.4407818019390106
val: 6 0.4346669614315033
val: 7 0.42400938272476196
val: 8 0.43820327520370483
val: 9 0.43737685680389404
val: 10 0.43213436007499695
val: 11 0.43913111090660095
val: 12 0.4353979229927063
val: 13 0.4353910982608795
val: 14 0.4375004172325134
val: 15 0.43307965993881226
val: 16 0.43432357907295227
val: 17 0.45186492800712585
val: 18 0.432076632976532
val: 19 0.44806233048439026
val: 20 0.42997419834136963
val_Epoch:[ 148 ] val_loss: 0.438372278213501 2022-07-01 01:05:21.941141
start training 2022-07-01 01:05:22.045097
Epoch:[ 149 0 ] loss: 0.395729660987854 2022-07-01 01:05:36.429620
Epoch:[ 149 1 ] loss: 0.3945472836494446 2022-07-01 01:05:36.882746
Epoch:[ 149 2 ] loss: 0.39544805884361267 2022-07-01 01:05:37.302920
Epoch:[ 149 3 ] loss: 0.39600348472595215 2022-07-01 01:05:37.726946
Epoch:[ 149 4 ] loss: 0.39544978737831116 2022-07-01 01:05:38.147435
Epoch:[ 149 5 ] loss: 0.3956204354763031 2022-07-01 01:05:38.566989
Epoch:[ 149 6 ] loss: 0.3937746584415436 2022-07-01 01:05:38.988596
Epoch:[ 149 7 ] loss: 0.395814448595047 2022-07-01 01:05:39.411811
Epoch:[ 149 8 ] loss: 0.3954739570617676 2022-07-01 01:05:39.834281
Epoch:[ 149 9 ] loss: 0.3954399526119232 2022-07-01 01:05:40.254229
Epoch:[ 149 10 ] loss: 0.39622944593429565 2022-07-01 01:05:40.675790
Epoch:[ 149 11 ] loss: 0.3964850604534149 2022-07-01 01:05:41.095996
Epoch:[ 149 12 ] loss: 0.3937551975250244 2022-07-01 01:05:41.510233
Epoch:[ 149 13 ] loss: 0.3966939151287079 2022-07-01 01:05:41.931881
Epoch:[ 149 14 ] loss: 0.39688819646835327 2022-07-01 01:05:42.353959
Epoch:[ 149 15 ] loss: 0.39791253209114075 2022-07-01 01:05:42.776531
Epoch:[ 149 16 ] loss: 0.39543309807777405 2022-07-01 01:05:47.901940
Epoch:[ 149 17 ] loss: 0.3958716094493866 2022-07-01 01:05:48.322159
Epoch:[ 149 18 ] loss: 0.3968021869659424 2022-07-01 01:05:48.743368
Epoch:[ 149 19 ] loss: 0.3947501480579376 2022-07-01 01:05:49.163709
Training_Epoch:[ 149 ] Training_loss: 0.39570615589618685 2022-07-01 01:05:49.164357
learning rate:  0.002199023255552002
val: 1 0.43155214190483093
val: 2 0.4373008608818054
val: 3 0.4441782534122467
val: 4 0.43082207441329956
val: 5 0.44090479612350464
val: 6 0.4305324852466583
val: 7 0.4455677270889282
val: 8 0.4364801347255707
val: 9 0.4495526850223541
val: 10 0.4336826503276825
val: 11 0.432339608669281
val: 12 0.43747156858444214
val: 13 0.4415664076805115
val: 14 0.4414512813091278
val: 15 0.4415346384048462
val: 16 0.45292946696281433
val: 17 0.4395718276500702
val: 18 0.42972543835639954
val: 19 0.4377237856388092
val: 20 0.4404287338256836
val_Epoch:[ 149 ] val_loss: 0.43876582831144334 2022-07-01 01:05:52.920788
start training 2022-07-01 01:05:53.029183
Epoch:[ 150 0 ] loss: 0.3954877555370331 2022-07-01 01:06:07.677984
Epoch:[ 150 1 ] loss: 0.39683592319488525 2022-07-01 01:06:08.099749
Epoch:[ 150 2 ] loss: 0.396001935005188 2022-07-01 01:06:08.521896
Epoch:[ 150 3 ] loss: 0.3944700062274933 2022-07-01 01:06:08.942626
Epoch:[ 150 4 ] loss: 0.39591526985168457 2022-07-01 01:06:09.355302
Epoch:[ 150 5 ] loss: 0.39637234807014465 2022-07-01 01:06:09.775497
Epoch:[ 150 6 ] loss: 0.39587488770484924 2022-07-01 01:06:10.194842
Epoch:[ 150 7 ] loss: 0.39379197359085083 2022-07-01 01:06:10.616845
Epoch:[ 150 8 ] loss: 0.3945803642272949 2022-07-01 01:06:11.032667
Epoch:[ 150 9 ] loss: 0.39573055505752563 2022-07-01 01:06:11.452813
Epoch:[ 150 10 ] loss: 0.39688315987586975 2022-07-01 01:06:11.873560
Epoch:[ 150 11 ] loss: 0.39665260910987854 2022-07-01 01:06:12.293909
Epoch:[ 150 12 ] loss: 0.3947698175907135 2022-07-01 01:06:12.714362
Epoch:[ 150 13 ] loss: 0.3972835838794708 2022-07-01 01:06:13.133558
Epoch:[ 150 14 ] loss: 0.39661264419555664 2022-07-01 01:06:13.558560
Epoch:[ 150 15 ] loss: 0.39645519852638245 2022-07-01 01:06:13.979747
Epoch:[ 150 16 ] loss: 0.3961333632469177 2022-07-01 01:06:19.102960
Epoch:[ 150 17 ] loss: 0.3969132900238037 2022-07-01 01:06:19.588253
Epoch:[ 150 18 ] loss: 0.39628681540489197 2022-07-01 01:06:20.010107
Epoch:[ 150 19 ] loss: 0.3970877528190613 2022-07-01 01:06:20.432166
Training_Epoch:[ 150 ] Training_loss: 0.39600696265697477 2022-07-01 01:06:20.432870
learning rate:  0.002199023255552002
netparams have been saved once 150
val: 1 0.4405568242073059
val: 2 0.440960556268692
val: 3 0.4473990499973297
val: 4 0.4388352930545807
val: 5 0.4478261470794678
val: 6 0.4336819052696228
val: 7 0.434379905462265
val: 8 0.4317472279071808
val: 9 0.43347659707069397
val: 10 0.4379393458366394
val: 11 0.4386708736419678
val: 12 0.4467178285121918
val: 13 0.43661653995513916
val: 14 0.4370952248573303
val: 15 0.4420378506183624
val: 16 0.434234082698822
val: 17 0.4408912658691406
val: 18 0.44584330916404724
val: 19 0.4583452045917511
val: 20 0.42862147092819214
val_Epoch:[ 150 ] val_loss: 0.43979382514953613 2022-07-01 01:06:24.254282
start training 2022-07-01 01:06:24.358631
Epoch:[ 151 0 ] loss: 0.39358487725257874 2022-07-01 01:06:38.752840
Epoch:[ 151 1 ] loss: 0.3949040174484253 2022-07-01 01:06:39.184532
Epoch:[ 151 2 ] loss: 0.3978278636932373 2022-07-01 01:06:39.607337
Epoch:[ 151 3 ] loss: 0.39358553290367126 2022-07-01 01:06:40.024246
Epoch:[ 151 4 ] loss: 0.39553046226501465 2022-07-01 01:06:40.446498
Epoch:[ 151 5 ] loss: 0.3952825665473938 2022-07-01 01:06:40.867531
Epoch:[ 151 6 ] loss: 0.39445430040359497 2022-07-01 01:06:41.287660
Epoch:[ 151 7 ] loss: 0.3968699276447296 2022-07-01 01:06:41.707153
Epoch:[ 151 8 ] loss: 0.3939150273799896 2022-07-01 01:06:42.128599
Epoch:[ 151 9 ] loss: 0.39779698848724365 2022-07-01 01:06:42.549035
Epoch:[ 151 10 ] loss: 0.3942718207836151 2022-07-01 01:06:42.970532
Epoch:[ 151 11 ] loss: 0.3937093913555145 2022-07-01 01:06:43.392566
Epoch:[ 151 12 ] loss: 0.3938402235507965 2022-07-01 01:06:43.812890
Epoch:[ 151 13 ] loss: 0.392416387796402 2022-07-01 01:06:44.233110
Epoch:[ 151 14 ] loss: 0.3930637836456299 2022-07-01 01:06:44.652927
Epoch:[ 151 15 ] loss: 0.3983990252017975 2022-07-01 01:06:45.068215
Epoch:[ 151 16 ] loss: 0.39588111639022827 2022-07-01 01:06:50.243530
Epoch:[ 151 17 ] loss: 0.3967689871788025 2022-07-01 01:06:50.663158
Epoch:[ 151 18 ] loss: 0.3940623998641968 2022-07-01 01:06:51.084037
Epoch:[ 151 19 ] loss: 0.39419203996658325 2022-07-01 01:06:51.502508
Training_Epoch:[ 151 ] Training_loss: 0.39501783698797227 2022-07-01 01:06:51.503195
learning rate:  0.0017592186044416017
val: 1 0.44425296783447266
val: 2 0.4349024295806885
val: 3 0.43653613328933716
val: 4 0.43784573674201965
val: 5 0.43872568011283875
val: 6 0.4415382444858551
val: 7 0.4430851340293884
val: 8 0.43965229392051697
val: 9 0.42879727482795715
val: 10 0.44483354687690735
val: 11 0.43885424733161926
val: 12 0.45295459032058716
val: 13 0.4342281222343445
val: 14 0.4307021200656891
val: 15 0.44168251752853394
val: 16 0.4346048831939697
val: 17 0.4455295205116272
val: 18 0.42957666516304016
val: 19 0.4299241304397583
val: 20 0.4432339072227478
val_Epoch:[ 151 ] val_loss: 0.43857300728559495 2022-07-01 01:06:55.258435
start training 2022-07-01 01:06:55.361913
Epoch:[ 152 0 ] loss: 0.3944177031517029 2022-07-01 01:07:09.242413
Epoch:[ 152 1 ] loss: 0.3941536843776703 2022-07-01 01:07:10.001633
Epoch:[ 152 2 ] loss: 0.39391452074050903 2022-07-01 01:07:10.424095
Epoch:[ 152 3 ] loss: 0.3958071768283844 2022-07-01 01:07:10.843864
Epoch:[ 152 4 ] loss: 0.3937441408634186 2022-07-01 01:07:11.264739
Epoch:[ 152 5 ] loss: 0.39392226934432983 2022-07-01 01:07:11.683647
Epoch:[ 152 6 ] loss: 0.3957803547382355 2022-07-01 01:07:12.104608
Epoch:[ 152 7 ] loss: 0.3961063325405121 2022-07-01 01:07:12.524176
Epoch:[ 152 8 ] loss: 0.39484620094299316 2022-07-01 01:07:12.942657
Epoch:[ 152 9 ] loss: 0.3970383107662201 2022-07-01 01:07:13.363057
Epoch:[ 152 10 ] loss: 0.3961294889450073 2022-07-01 01:07:13.785775
Epoch:[ 152 11 ] loss: 0.39263734221458435 2022-07-01 01:07:14.205523
Epoch:[ 152 12 ] loss: 0.39487653970718384 2022-07-01 01:07:14.625714
Epoch:[ 152 13 ] loss: 0.3950100243091583 2022-07-01 01:07:15.045854
Epoch:[ 152 14 ] loss: 0.39190539717674255 2022-07-01 01:07:15.466342
Epoch:[ 152 15 ] loss: 0.39270830154418945 2022-07-01 01:07:15.881760
Epoch:[ 152 16 ] loss: 0.3944760262966156 2022-07-01 01:07:20.987712
Epoch:[ 152 17 ] loss: 0.39309555292129517 2022-07-01 01:07:21.712326
Epoch:[ 152 18 ] loss: 0.3943055272102356 2022-07-01 01:07:22.133023
Epoch:[ 152 19 ] loss: 0.39355581998825073 2022-07-01 01:07:22.552125
Training_Epoch:[ 152 ] Training_loss: 0.3944215357303619 2022-07-01 01:07:22.552812
learning rate:  0.0017592186044416017
netparams have been saved once 152
val: 1 0.4391268193721771
val: 2 0.44526058435440063
val: 3 0.4378003478050232
val: 4 0.4312623143196106
val: 5 0.44255807995796204
val: 6 0.43093276023864746
val: 7 0.43995097279548645
val: 8 0.43454745411872864
val: 9 0.44234663248062134
val: 10 0.44370782375335693
val: 11 0.43901196122169495
val: 12 0.43437519669532776
val: 13 0.45238372683525085
val: 14 0.4448266327381134
val: 15 0.4366816282272339
val: 16 0.4394216239452362
val: 17 0.43266141414642334
val: 18 0.4401998221874237
val: 19 0.42743659019470215
val: 20 0.43994060158729553
val_Epoch:[ 152 ] val_loss: 0.4387216493487358 2022-07-01 01:07:26.381836
start training 2022-07-01 01:07:26.485011
Epoch:[ 153 0 ] loss: 0.3932822346687317 2022-07-01 01:07:40.999136
Epoch:[ 153 1 ] loss: 0.39605408906936646 2022-07-01 01:07:41.419850
Epoch:[ 153 2 ] loss: 0.395926296710968 2022-07-01 01:07:41.839653
Epoch:[ 153 3 ] loss: 0.39673349261283875 2022-07-01 01:07:42.261896
Epoch:[ 153 4 ] loss: 0.39487507939338684 2022-07-01 01:07:42.685308
Epoch:[ 153 5 ] loss: 0.39378243684768677 2022-07-01 01:07:43.106686
Epoch:[ 153 6 ] loss: 0.39395079016685486 2022-07-01 01:07:43.528739
Epoch:[ 153 7 ] loss: 0.39531654119491577 2022-07-01 01:07:43.944120
Epoch:[ 153 8 ] loss: 0.39525750279426575 2022-07-01 01:07:44.365142
Epoch:[ 153 9 ] loss: 0.39396747946739197 2022-07-01 01:07:44.784572
Epoch:[ 153 10 ] loss: 0.3908906579017639 2022-07-01 01:07:45.200960
Epoch:[ 153 11 ] loss: 0.3924492299556732 2022-07-01 01:07:45.623791
Epoch:[ 153 12 ] loss: 0.3944029211997986 2022-07-01 01:07:46.044324
Epoch:[ 153 13 ] loss: 0.3955368101596832 2022-07-01 01:07:46.464273
Epoch:[ 153 14 ] loss: 0.39380139112472534 2022-07-01 01:07:46.885750
Epoch:[ 153 15 ] loss: 0.39543095231056213 2022-07-01 01:07:47.305414
Epoch:[ 153 16 ] loss: 0.3955860137939453 2022-07-01 01:07:53.000286
Epoch:[ 153 17 ] loss: 0.39464470744132996 2022-07-01 01:07:53.420993
Epoch:[ 153 18 ] loss: 0.39506393671035767 2022-07-01 01:07:53.844187
Epoch:[ 153 19 ] loss: 0.3945475220680237 2022-07-01 01:07:54.266992
Training_Epoch:[ 153 ] Training_loss: 0.3945750042796135 2022-07-01 01:07:54.267760
learning rate:  0.0017592186044416017
val: 1 0.4399314224720001
val: 2 0.4468894898891449
val: 3 0.449697345495224
val: 4 0.434225857257843
val: 5 0.43523985147476196
val: 6 0.4377632737159729
val: 7 0.45633381605148315
val: 8 0.44093453884124756
val: 9 0.4443034827709198
val: 10 0.4420524835586548
val: 11 0.4319211542606354
val: 12 0.4311006963253021
val: 13 0.44582897424697876
val: 14 0.4276379942893982
val: 15 0.4344290792942047
val: 16 0.45195242762565613
val: 17 0.4339885115623474
val: 18 0.442931205034256
val: 19 0.43647390604019165
val: 20 0.4388495981693268
val_Epoch:[ 153 ] val_loss: 0.4401242554187775 2022-07-01 01:07:58.056549
start training 2022-07-01 01:07:58.165195
Epoch:[ 154 0 ] loss: 0.3941190838813782 2022-07-01 01:08:12.687338
Epoch:[ 154 1 ] loss: 0.393535315990448 2022-07-01 01:08:13.102539
Epoch:[ 154 2 ] loss: 0.39228639006614685 2022-07-01 01:08:13.524254
Epoch:[ 154 3 ] loss: 0.3950309455394745 2022-07-01 01:08:13.944846
Epoch:[ 154 4 ] loss: 0.39268243312835693 2022-07-01 01:08:14.360527
Epoch:[ 154 5 ] loss: 0.3938262164592743 2022-07-01 01:08:14.783020
Epoch:[ 154 6 ] loss: 0.39676526188850403 2022-07-01 01:08:15.205162
Epoch:[ 154 7 ] loss: 0.39410582184791565 2022-07-01 01:08:15.626125
Epoch:[ 154 8 ] loss: 0.3943033218383789 2022-07-01 01:08:16.046273
Epoch:[ 154 9 ] loss: 0.3932657241821289 2022-07-01 01:08:16.466256
Epoch:[ 154 10 ] loss: 0.39511343836784363 2022-07-01 01:08:16.885860
Epoch:[ 154 11 ] loss: 0.39490628242492676 2022-07-01 01:08:17.307450
Epoch:[ 154 12 ] loss: 0.39505138993263245 2022-07-01 01:08:17.729246
Epoch:[ 154 13 ] loss: 0.39648860692977905 2022-07-01 01:08:18.150506
Epoch:[ 154 14 ] loss: 0.3952200710773468 2022-07-01 01:08:18.571164
Epoch:[ 154 15 ] loss: 0.3932785987854004 2022-07-01 01:08:18.991702
Epoch:[ 154 16 ] loss: 0.39328619837760925 2022-07-01 01:08:24.630224
Epoch:[ 154 17 ] loss: 0.3935432732105255 2022-07-01 01:08:25.089051
Epoch:[ 154 18 ] loss: 0.39527714252471924 2022-07-01 01:08:25.517726
Epoch:[ 154 19 ] loss: 0.39489734172821045 2022-07-01 01:08:25.939295
Training_Epoch:[ 154 ] Training_loss: 0.39434914290905 2022-07-01 01:08:25.940021
learning rate:  0.0017592186044416017
netparams have been saved once 154
val: 1 0.43358513712882996
val: 2 0.43577855825424194
val: 3 0.4437466561794281
val: 4 0.44925373792648315
val: 5 0.4480421543121338
val: 6 0.4360450506210327
val: 7 0.43317657709121704
val: 8 0.4351498484611511
val: 9 0.4339998960494995
val: 10 0.4363904297351837
val: 11 0.4465239942073822
val: 12 0.44188830256462097
val: 13 0.44349706172943115
val: 14 0.4444693326950073
val: 15 0.44409435987472534
val: 16 0.42944806814193726
val: 17 0.4388464093208313
val: 18 0.4358793795108795
val: 19 0.4385170340538025
val: 20 0.43029308319091797
val_Epoch:[ 154 ] val_loss: 0.43893125355243684 2022-07-01 01:08:29.747980
start training 2022-07-01 01:08:29.851609
Epoch:[ 155 0 ] loss: 0.3914836645126343 2022-07-01 01:08:43.919838
Epoch:[ 155 1 ] loss: 0.39645975828170776 2022-07-01 01:08:44.362835
Epoch:[ 155 2 ] loss: 0.39341020584106445 2022-07-01 01:08:44.781991
Epoch:[ 155 3 ] loss: 0.39232635498046875 2022-07-01 01:08:45.202941
Epoch:[ 155 4 ] loss: 0.39361056685447693 2022-07-01 01:08:45.622528
Epoch:[ 155 5 ] loss: 0.3934437036514282 2022-07-01 01:08:46.042634
Epoch:[ 155 6 ] loss: 0.3927769064903259 2022-07-01 01:08:46.464610
Epoch:[ 155 7 ] loss: 0.3950340449810028 2022-07-01 01:08:46.884648
Epoch:[ 155 8 ] loss: 0.39290985465049744 2022-07-01 01:08:47.306415
Epoch:[ 155 9 ] loss: 0.3928970992565155 2022-07-01 01:08:47.723795
Epoch:[ 155 10 ] loss: 0.39299625158309937 2022-07-01 01:08:48.143325
Epoch:[ 155 11 ] loss: 0.39311039447784424 2022-07-01 01:08:48.562523
Epoch:[ 155 12 ] loss: 0.395820677280426 2022-07-01 01:08:48.982981
Epoch:[ 155 13 ] loss: 0.39293473958969116 2022-07-01 01:08:49.404039
Epoch:[ 155 14 ] loss: 0.39479440450668335 2022-07-01 01:08:49.824663
Epoch:[ 155 15 ] loss: 0.3922998011112213 2022-07-01 01:08:50.238252
Epoch:[ 155 16 ] loss: 0.3950033485889435 2022-07-01 01:08:55.838319
Epoch:[ 155 17 ] loss: 0.3958083391189575 2022-07-01 01:08:56.257705
Epoch:[ 155 18 ] loss: 0.39551568031311035 2022-07-01 01:08:56.678457
Epoch:[ 155 19 ] loss: 0.3945619761943817 2022-07-01 01:08:57.098842
Training_Epoch:[ 155 ] Training_loss: 0.393859888613224 2022-07-01 01:08:57.099525
learning rate:  0.0017592186044416017
val: 1 0.44573938846588135
val: 2 0.43062111735343933
val: 3 0.4429885149002075
val: 4 0.4339917004108429
val: 5 0.4388332962989807
val: 6 0.45081639289855957
val: 7 0.4528457224369049
val: 8 0.4413928985595703
val: 9 0.43757200241088867
val: 10 0.4516467750072479
val: 11 0.4465304911136627
val: 12 0.4281470477581024
val: 13 0.43889835476875305
val: 14 0.4235316812992096
val: 15 0.43612009286880493
val: 16 0.44261693954467773
val: 17 0.42640143632888794
val: 18 0.44845110177993774
val: 19 0.4394914507865906
val: 20 0.43467849493026733
val_Epoch:[ 155 ] val_loss: 0.4395657449960709 2022-07-01 01:09:00.891161
start training 2022-07-01 01:09:00.996080
Epoch:[ 156 0 ] loss: 0.3929910659790039 2022-07-01 01:09:15.391889
Epoch:[ 156 1 ] loss: 0.39633917808532715 2022-07-01 01:09:15.824296
Epoch:[ 156 2 ] loss: 0.393281489610672 2022-07-01 01:09:16.244066
Epoch:[ 156 3 ] loss: 0.3927852511405945 2022-07-01 01:09:16.663540
Epoch:[ 156 4 ] loss: 0.39627015590667725 2022-07-01 01:09:17.083952
Epoch:[ 156 5 ] loss: 0.39391258358955383 2022-07-01 01:09:17.504125
Epoch:[ 156 6 ] loss: 0.39366602897644043 2022-07-01 01:09:17.926351
Epoch:[ 156 7 ] loss: 0.39461684226989746 2022-07-01 01:09:18.347318
Epoch:[ 156 8 ] loss: 0.39335349202156067 2022-07-01 01:09:18.761175
Epoch:[ 156 9 ] loss: 0.3920878469944 2022-07-01 01:09:19.180827
Epoch:[ 156 10 ] loss: 0.3923358619213104 2022-07-01 01:09:19.602384
Epoch:[ 156 11 ] loss: 0.39272499084472656 2022-07-01 01:09:20.024488
Epoch:[ 156 12 ] loss: 0.39222452044487 2022-07-01 01:09:20.443679
Epoch:[ 156 13 ] loss: 0.3953785300254822 2022-07-01 01:09:20.865459
Epoch:[ 156 14 ] loss: 0.3923393487930298 2022-07-01 01:09:21.288015
Epoch:[ 156 15 ] loss: 0.39310264587402344 2022-07-01 01:09:21.711087
Epoch:[ 156 16 ] loss: 0.3924427330493927 2022-07-01 01:09:27.462030
Epoch:[ 156 17 ] loss: 0.3952378034591675 2022-07-01 01:09:27.882230
Epoch:[ 156 18 ] loss: 0.3946631848812103 2022-07-01 01:09:28.305811
Epoch:[ 156 19 ] loss: 0.3947434723377228 2022-07-01 01:09:28.724354
Training_Epoch:[ 156 ] Training_loss: 0.39372485131025314 2022-07-01 01:09:28.725043
learning rate:  0.0017592186044416017
netparams have been saved once 156
val: 1 0.44654494524002075
val: 2 0.43407532572746277
val: 3 0.43446001410484314
val: 4 0.4384334981441498
val: 5 0.44222649931907654
val: 6 0.4431852102279663
val: 7 0.44356149435043335
val: 8 0.44380924105644226
val: 9 0.4421415627002716
val: 10 0.4280146062374115
val: 11 0.43681126832962036
val: 12 0.42847758531570435
val: 13 0.43945324420928955
val: 14 0.441799134016037
val: 15 0.4545430541038513
val: 16 0.43672439455986023
val: 17 0.4362569749355316
val: 18 0.4383634924888611
val: 19 0.43402594327926636
val: 20 0.4355957508087158
val_Epoch:[ 156 ] val_loss: 0.4389251619577408 2022-07-01 01:09:32.548099
start training 2022-07-01 01:09:32.656183
Epoch:[ 157 0 ] loss: 0.39158597588539124 2022-07-01 01:09:47.289371
Epoch:[ 157 1 ] loss: 0.3919885456562042 2022-07-01 01:09:47.712747
Epoch:[ 157 2 ] loss: 0.39575114846229553 2022-07-01 01:09:48.133525
Epoch:[ 157 3 ] loss: 0.3923766016960144 2022-07-01 01:09:48.554255
Epoch:[ 157 4 ] loss: 0.39201819896698 2022-07-01 01:09:48.974628
Epoch:[ 157 5 ] loss: 0.3914508521556854 2022-07-01 01:09:49.396662
Epoch:[ 157 6 ] loss: 0.39218056201934814 2022-07-01 01:09:49.816951
Epoch:[ 157 7 ] loss: 0.39477524161338806 2022-07-01 01:09:50.232356
Epoch:[ 157 8 ] loss: 0.39519819617271423 2022-07-01 01:09:50.653761
Epoch:[ 157 9 ] loss: 0.3926481008529663 2022-07-01 01:09:51.073292
Epoch:[ 157 10 ] loss: 0.3947818875312805 2022-07-01 01:09:51.493168
Epoch:[ 157 11 ] loss: 0.39357709884643555 2022-07-01 01:09:51.913812
Epoch:[ 157 12 ] loss: 0.39449945092201233 2022-07-01 01:09:52.335627
Epoch:[ 157 13 ] loss: 0.39600807428359985 2022-07-01 01:09:52.756297
Epoch:[ 157 14 ] loss: 0.39367911219596863 2022-07-01 01:09:53.173595
Epoch:[ 157 15 ] loss: 0.39540302753448486 2022-07-01 01:09:53.595030
Epoch:[ 157 16 ] loss: 0.39266276359558105 2022-07-01 01:09:58.676009
Epoch:[ 157 17 ] loss: 0.3922460675239563 2022-07-01 01:09:59.100446
Epoch:[ 157 18 ] loss: 0.3940162658691406 2022-07-01 01:09:59.521474
Epoch:[ 157 19 ] loss: 0.39471709728240967 2022-07-01 01:09:59.943747
Training_Epoch:[ 157 ] Training_loss: 0.39357821345329286 2022-07-01 01:09:59.944457
learning rate:  0.0017592186044416017
val: 1 0.44695615768432617
val: 2 0.42805489897727966
val: 3 0.45034122467041016
val: 4 0.4312664270401001
val: 5 0.4489787220954895
val: 6 0.43121665716171265
val: 7 0.4409318268299103
val: 8 0.4426947832107544
val: 9 0.4491266906261444
val: 10 0.43906891345977783
val: 11 0.43708088994026184
val: 12 0.44732460379600525
val: 13 0.43285539746284485
val: 14 0.42824453115463257
val: 15 0.4349187910556793
val: 16 0.44228923320770264
val: 17 0.44981151819229126
val: 18 0.45258820056915283
val: 19 0.4338434636592865
val: 20 0.43099239468574524
val_Epoch:[ 157 ] val_loss: 0.4399292662739754 2022-07-01 01:10:03.705612
start training 2022-07-01 01:10:03.811100
Epoch:[ 158 0 ] loss: 0.39449405670166016 2022-07-01 01:10:17.926339
Epoch:[ 158 1 ] loss: 0.3933084309101105 2022-07-01 01:10:18.364028
Epoch:[ 158 2 ] loss: 0.3934932053089142 2022-07-01 01:10:18.787906
Epoch:[ 158 3 ] loss: 0.39351725578308105 2022-07-01 01:10:19.209813
Epoch:[ 158 4 ] loss: 0.3908483684062958 2022-07-01 01:10:19.619080
Epoch:[ 158 5 ] loss: 0.3927779495716095 2022-07-01 01:10:20.027732
Epoch:[ 158 6 ] loss: 0.39370694756507874 2022-07-01 01:10:20.436214
Epoch:[ 158 7 ] loss: 0.39254534244537354 2022-07-01 01:10:20.844965
Epoch:[ 158 8 ] loss: 0.39044997096061707 2022-07-01 01:10:21.267035
Epoch:[ 158 9 ] loss: 0.3927224576473236 2022-07-01 01:10:21.688672
Epoch:[ 158 10 ] loss: 0.39393940567970276 2022-07-01 01:10:22.111847
Epoch:[ 158 11 ] loss: 0.3941473960876465 2022-07-01 01:10:22.532374
Epoch:[ 158 12 ] loss: 0.39391112327575684 2022-07-01 01:10:22.944620
Epoch:[ 158 13 ] loss: 0.3933708667755127 2022-07-01 01:10:23.365262
Epoch:[ 158 14 ] loss: 0.39517495036125183 2022-07-01 01:10:23.779724
Epoch:[ 158 15 ] loss: 0.39359068870544434 2022-07-01 01:10:24.201879
Epoch:[ 158 16 ] loss: 0.3937095105648041 2022-07-01 01:10:29.642528
Epoch:[ 158 17 ] loss: 0.3947303295135498 2022-07-01 01:10:30.062873
Epoch:[ 158 18 ] loss: 0.39692097902297974 2022-07-01 01:10:30.487111
Epoch:[ 158 19 ] loss: 0.3940350115299225 2022-07-01 01:10:30.907470
Training_Epoch:[ 158 ] Training_loss: 0.39356971234083177 2022-07-01 01:10:30.908198
learning rate:  0.0017592186044416017
netparams have been saved once 158
val: 1 0.44359883666038513
val: 2 0.42569494247436523
val: 3 0.4397135376930237
val: 4 0.4330398142337799
val: 5 0.43251481652259827
val: 6 0.4431905448436737
val: 7 0.4202738404273987
val: 8 0.43885961174964905
val: 9 0.4508805572986603
val: 10 0.44090157747268677
val: 11 0.43156957626342773
val: 12 0.43735837936401367
val: 13 0.43990272283554077
val: 14 0.440746545791626
val: 15 0.4475637674331665
val: 16 0.4354020059108734
val: 17 0.44974207878112793
val: 18 0.4384671449661255
val: 19 0.4365653693675995
val: 20 0.4438972771167755
val_Epoch:[ 158 ] val_loss: 0.4384941473603249 2022-07-01 01:10:34.742793
start training 2022-07-01 01:10:34.851608
Epoch:[ 159 0 ] loss: 0.3938733637332916 2022-07-01 01:10:49.067406
Epoch:[ 159 1 ] loss: 0.3950127959251404 2022-07-01 01:10:49.590093
Epoch:[ 159 2 ] loss: 0.3910510241985321 2022-07-01 01:10:50.012206
Epoch:[ 159 3 ] loss: 0.39131417870521545 2022-07-01 01:10:50.434641
Epoch:[ 159 4 ] loss: 0.3913266658782959 2022-07-01 01:10:50.856749
Epoch:[ 159 5 ] loss: 0.39194101095199585 2022-07-01 01:10:51.275921
Epoch:[ 159 6 ] loss: 0.39472290873527527 2022-07-01 01:10:51.690614
Epoch:[ 159 7 ] loss: 0.39112547039985657 2022-07-01 01:10:52.115791
Epoch:[ 159 8 ] loss: 0.3940815031528473 2022-07-01 01:10:52.535826
Epoch:[ 159 9 ] loss: 0.3937126398086548 2022-07-01 01:10:52.957894
Epoch:[ 159 10 ] loss: 0.3945103585720062 2022-07-01 01:10:53.380050
Epoch:[ 159 11 ] loss: 0.3939454257488251 2022-07-01 01:10:53.800971
Epoch:[ 159 12 ] loss: 0.39294955134391785 2022-07-01 01:10:54.222842
Epoch:[ 159 13 ] loss: 0.3928006589412689 2022-07-01 01:10:54.643200
Epoch:[ 159 14 ] loss: 0.39478832483291626 2022-07-01 01:10:55.063579
Epoch:[ 159 15 ] loss: 0.395484983921051 2022-07-01 01:10:55.484243
Epoch:[ 159 16 ] loss: 0.3936908543109894 2022-07-01 01:11:00.501258
Epoch:[ 159 17 ] loss: 0.39331814646720886 2022-07-01 01:11:01.063032
Epoch:[ 159 18 ] loss: 0.3943473994731903 2022-07-01 01:11:01.491388
Epoch:[ 159 19 ] loss: 0.3965843617916107 2022-07-01 01:11:01.911253
Training_Epoch:[ 159 ] Training_loss: 0.3935290813446045 2022-07-01 01:11:01.911888
learning rate:  0.0017592186044416017
val: 1 0.45065605640411377
val: 2 0.43601393699645996
val: 3 0.4482939839363098
val: 4 0.43856701254844666
val: 5 0.4401911199092865
val: 6 0.45001599192619324
val: 7 0.43592557311058044
val: 8 0.4307573437690735
val: 9 0.43816041946411133
val: 10 0.4416262209415436
val: 11 0.44285234808921814
val: 12 0.4401427209377289
val: 13 0.4336498975753784
val: 14 0.42908304929733276
val: 15 0.43123096227645874
val: 16 0.4589080512523651
val: 17 0.4416133165359497
val: 18 0.438323050737381
val: 19 0.4452880024909973
val: 20 0.4373711049556732
val_Epoch:[ 159 ] val_loss: 0.4404335081577301 2022-07-01 01:11:05.660458
start training 2022-07-01 01:11:05.767988
Epoch:[ 160 0 ] loss: 0.39558541774749756 2022-07-01 01:11:20.549680
Epoch:[ 160 1 ] loss: 0.3921722173690796 2022-07-01 01:11:20.962643
Epoch:[ 160 2 ] loss: 0.3926115334033966 2022-07-01 01:11:21.383081
Epoch:[ 160 3 ] loss: 0.3934817910194397 2022-07-01 01:11:21.804694
Epoch:[ 160 4 ] loss: 0.3926900625228882 2022-07-01 01:11:22.226879
Epoch:[ 160 5 ] loss: 0.3930191099643707 2022-07-01 01:11:22.647297
Epoch:[ 160 6 ] loss: 0.39560288190841675 2022-07-01 01:11:23.066503
Epoch:[ 160 7 ] loss: 0.39427754282951355 2022-07-01 01:11:23.480318
Epoch:[ 160 8 ] loss: 0.3922056555747986 2022-07-01 01:11:23.898988
Epoch:[ 160 9 ] loss: 0.3946080803871155 2022-07-01 01:11:24.317818
Epoch:[ 160 10 ] loss: 0.3923845887184143 2022-07-01 01:11:24.738715
Epoch:[ 160 11 ] loss: 0.3922358453273773 2022-07-01 01:11:25.160780
Epoch:[ 160 12 ] loss: 0.39288341999053955 2022-07-01 01:11:25.581480
Epoch:[ 160 13 ] loss: 0.3942869007587433 2022-07-01 01:11:26.000484
Epoch:[ 160 14 ] loss: 0.3927537202835083 2022-07-01 01:11:26.419914
Epoch:[ 160 15 ] loss: 0.39499446749687195 2022-07-01 01:11:26.839160
Epoch:[ 160 16 ] loss: 0.3930203318595886 2022-07-01 01:11:32.008656
Epoch:[ 160 17 ] loss: 0.3934343755245209 2022-07-01 01:11:32.929138
Epoch:[ 160 18 ] loss: 0.3954940140247345 2022-07-01 01:11:33.351295
Epoch:[ 160 19 ] loss: 0.3944873511791229 2022-07-01 01:11:33.770875
Training_Epoch:[ 160 ] Training_loss: 0.39361146539449693 2022-07-01 01:11:33.771521
learning rate:  0.0017592186044416017
netparams have been saved once 160
val: 1 0.4345899522304535
val: 2 0.4315119683742523
val: 3 0.4380839765071869
val: 4 0.43995627760887146
val: 5 0.4489942193031311
val: 6 0.44321879744529724
val: 7 0.4467097520828247
val: 8 0.4330160319805145
val: 9 0.4485848844051361
val: 10 0.4393477141857147
val: 11 0.4479653537273407
val: 12 0.45136702060699463
val: 13 0.45179593563079834
val: 14 0.445376992225647
val: 15 0.43742772936820984
val: 16 0.44144192337989807
val: 17 0.430383563041687
val: 18 0.4383544921875
val: 19 0.44077301025390625
val: 20 0.4260348379611969
val_Epoch:[ 160 ] val_loss: 0.4407467216253281 2022-07-01 01:11:37.530374
start training 2022-07-01 01:11:37.637603
Epoch:[ 161 0 ] loss: 0.3938128352165222 2022-07-01 01:11:52.139339
Epoch:[ 161 1 ] loss: 0.39257264137268066 2022-07-01 01:11:52.558322
Epoch:[ 161 2 ] loss: 0.3940688371658325 2022-07-01 01:11:52.978722
Epoch:[ 161 3 ] loss: 0.39191344380378723 2022-07-01 01:11:53.398398
Epoch:[ 161 4 ] loss: 0.3948249816894531 2022-07-01 01:11:53.821135
Epoch:[ 161 5 ] loss: 0.3931298851966858 2022-07-01 01:11:54.242205
Epoch:[ 161 6 ] loss: 0.3938678205013275 2022-07-01 01:11:54.662403
Epoch:[ 161 7 ] loss: 0.3924984037876129 2022-07-01 01:11:55.083163
Epoch:[ 161 8 ] loss: 0.3956908583641052 2022-07-01 01:11:55.504772
Epoch:[ 161 9 ] loss: 0.3903672695159912 2022-07-01 01:11:55.924152
Epoch:[ 161 10 ] loss: 0.3946821689605713 2022-07-01 01:11:56.341272
Epoch:[ 161 11 ] loss: 0.3931342661380768 2022-07-01 01:11:56.763086
Epoch:[ 161 12 ] loss: 0.391488254070282 2022-07-01 01:11:57.185988
Epoch:[ 161 13 ] loss: 0.39217668771743774 2022-07-01 01:11:57.608636
Epoch:[ 161 14 ] loss: 0.3948326110839844 2022-07-01 01:11:58.024548
Epoch:[ 161 15 ] loss: 0.3904465138912201 2022-07-01 01:11:58.445230
Epoch:[ 161 16 ] loss: 0.3944269120693207 2022-07-01 01:12:03.463261
Epoch:[ 161 17 ] loss: 0.3942471444606781 2022-07-01 01:12:03.896534
Epoch:[ 161 18 ] loss: 0.3942316770553589 2022-07-01 01:12:04.327149
Epoch:[ 161 19 ] loss: 0.39075908064842224 2022-07-01 01:12:04.737367
Training_Epoch:[ 161 ] Training_loss: 0.39315861463546753 2022-07-01 01:12:04.738049
learning rate:  0.0014073748835532814
val: 1 0.4439011812210083
val: 2 0.4417203962802887
val: 3 0.44891706109046936
val: 4 0.4354856312274933
val: 5 0.4364786446094513
val: 6 0.44034263491630554
val: 7 0.43329641222953796
val: 8 0.4397583305835724
val: 9 0.4311867654323578
val: 10 0.4477453827857971
val: 11 0.4321938753128052
val: 12 0.43925637006759644
val: 13 0.457025408744812
val: 14 0.4490731656551361
val: 15 0.4462409019470215
val: 16 0.4333146810531616
val: 17 0.43740707635879517
val: 18 0.43886110186576843
val: 19 0.44405853748321533
val: 20 0.4395792484283447
val_Epoch:[ 161 ] val_loss: 0.4407921403646469 2022-07-01 01:12:08.494592
start training 2022-07-01 01:12:08.603130
Epoch:[ 162 0 ] loss: 0.3922719657421112 2022-07-01 01:12:23.639434
Epoch:[ 162 1 ] loss: 0.39172524213790894 2022-07-01 01:12:24.058634
Epoch:[ 162 2 ] loss: 0.3940143883228302 2022-07-01 01:12:24.478488
Epoch:[ 162 3 ] loss: 0.39461666345596313 2022-07-01 01:12:24.898674
Epoch:[ 162 4 ] loss: 0.39155474305152893 2022-07-01 01:12:25.318185
Epoch:[ 162 5 ] loss: 0.39261293411254883 2022-07-01 01:12:25.739999
Epoch:[ 162 6 ] loss: 0.3909139037132263 2022-07-01 01:12:26.162943
Epoch:[ 162 7 ] loss: 0.39205774664878845 2022-07-01 01:12:26.584621
Epoch:[ 162 8 ] loss: 0.3929281234741211 2022-07-01 01:12:27.006385
Epoch:[ 162 9 ] loss: 0.39321327209472656 2022-07-01 01:12:27.427653
Epoch:[ 162 10 ] loss: 0.3927291929721832 2022-07-01 01:12:27.848411
Epoch:[ 162 11 ] loss: 0.39077067375183105 2022-07-01 01:12:28.268808
Epoch:[ 162 12 ] loss: 0.3948976993560791 2022-07-01 01:12:28.691056
Epoch:[ 162 13 ] loss: 0.3939521610736847 2022-07-01 01:12:29.111840
Epoch:[ 162 14 ] loss: 0.3938882052898407 2022-07-01 01:12:29.527266
Epoch:[ 162 15 ] loss: 0.3931712806224823 2022-07-01 01:12:29.949391
Epoch:[ 162 16 ] loss: 0.39235955476760864 2022-07-01 01:12:34.998581
Epoch:[ 162 17 ] loss: 0.3950235843658447 2022-07-01 01:12:35.417437
Epoch:[ 162 18 ] loss: 0.39183980226516724 2022-07-01 01:12:35.837688
Epoch:[ 162 19 ] loss: 0.39267808198928833 2022-07-01 01:12:36.259244
Training_Epoch:[ 162 ] Training_loss: 0.3928609609603882 2022-07-01 01:12:36.259947
learning rate:  0.0014073748835532814
netparams have been saved once 162
val: 1 0.4375113844871521
val: 2 0.433830201625824
val: 3 0.43934187293052673
val: 4 0.441073477268219
val: 5 0.4503604769706726
val: 6 0.43541398644447327
val: 7 0.44434162974357605
val: 8 0.4365563690662384
val: 9 0.4446781277656555
val: 10 0.4370974898338318
val: 11 0.43359026312828064
val: 12 0.44467806816101074
val: 13 0.44185110926628113
val: 14 0.4330032765865326
val: 15 0.43060731887817383
val: 16 0.4470752477645874
val: 17 0.4354819357395172
val: 18 0.4512464106082916
val: 19 0.4326862692832947
val: 20 0.4384390115737915
val_Epoch:[ 162 ] val_loss: 0.43944319635629653 2022-07-01 01:12:40.065553
start training 2022-07-01 01:12:40.172155
Epoch:[ 163 0 ] loss: 0.3929067552089691 2022-07-01 01:12:54.160090
Epoch:[ 163 1 ] loss: 0.39265647530555725 2022-07-01 01:12:54.622715
Epoch:[ 163 2 ] loss: 0.39221295714378357 2022-07-01 01:12:55.064112
Epoch:[ 163 3 ] loss: 0.3918501138687134 2022-07-01 01:12:55.487518
Epoch:[ 163 4 ] loss: 0.3929358720779419 2022-07-01 01:12:55.904478
Epoch:[ 163 5 ] loss: 0.39272186160087585 2022-07-01 01:12:56.324051
Epoch:[ 163 6 ] loss: 0.3945864140987396 2022-07-01 01:12:56.749402
Epoch:[ 163 7 ] loss: 0.3878931701183319 2022-07-01 01:12:57.171884
Epoch:[ 163 8 ] loss: 0.3892047703266144 2022-07-01 01:12:57.592416
Epoch:[ 163 9 ] loss: 0.39330267906188965 2022-07-01 01:12:58.011580
Epoch:[ 163 10 ] loss: 0.39186182618141174 2022-07-01 01:12:58.431237
Epoch:[ 163 11 ] loss: 0.39136478304862976 2022-07-01 01:12:58.851327
Epoch:[ 163 12 ] loss: 0.39218229055404663 2022-07-01 01:12:59.269767
Epoch:[ 163 13 ] loss: 0.39177238941192627 2022-07-01 01:12:59.690365
Epoch:[ 163 14 ] loss: 0.3942120671272278 2022-07-01 01:13:00.112457
Epoch:[ 163 15 ] loss: 0.3913862705230713 2022-07-01 01:13:00.532838
Epoch:[ 163 16 ] loss: 0.39331355690956116 2022-07-01 01:13:05.846990
Epoch:[ 163 17 ] loss: 0.39169830083847046 2022-07-01 01:13:06.285849
Epoch:[ 163 18 ] loss: 0.3911249339580536 2022-07-01 01:13:06.706500
Epoch:[ 163 19 ] loss: 0.39408424496650696 2022-07-01 01:13:07.125944
Training_Epoch:[ 163 ] Training_loss: 0.3921635866165161 2022-07-01 01:13:07.126568
learning rate:  0.0014073748835532814
val: 1 0.4522157311439514
val: 2 0.45134836435317993
val: 3 0.43477943539619446
val: 4 0.4288911521434784
val: 5 0.4441457688808441
val: 6 0.44133687019348145
val: 7 0.44864973425865173
val: 8 0.43155989050865173
val: 9 0.4352931082248688
val: 10 0.4428752362728119
val: 11 0.43735751509666443
val: 12 0.4316173791885376
val: 13 0.4385351240634918
val: 14 0.45007309317588806
val: 15 0.4297456741333008
val: 16 0.44217491149902344
val: 17 0.45167967677116394
val: 18 0.4333156645298004
val: 19 0.44172078371047974
val: 20 0.4296301305294037
val_Epoch:[ 163 ] val_loss: 0.4398472622036934 2022-07-01 01:13:10.852150
start training 2022-07-01 01:13:10.959610
Epoch:[ 164 0 ] loss: 0.3924289643764496 2022-07-01 01:13:25.236318
Epoch:[ 164 1 ] loss: 0.39114728569984436 2022-07-01 01:13:25.666381
Epoch:[ 164 2 ] loss: 0.3922854959964752 2022-07-01 01:13:26.081821
Epoch:[ 164 3 ] loss: 0.3910139501094818 2022-07-01 01:13:26.502917
Epoch:[ 164 4 ] loss: 0.3923689126968384 2022-07-01 01:13:26.925567
Epoch:[ 164 5 ] loss: 0.3916642963886261 2022-07-01 01:13:27.344944
Epoch:[ 164 6 ] loss: 0.39172106981277466 2022-07-01 01:13:27.765491
Epoch:[ 164 7 ] loss: 0.3912268579006195 2022-07-01 01:13:28.186483
Epoch:[ 164 8 ] loss: 0.39213064312934875 2022-07-01 01:13:28.597111
Epoch:[ 164 9 ] loss: 0.3928591012954712 2022-07-01 01:13:29.005458
Epoch:[ 164 10 ] loss: 0.3910774886608124 2022-07-01 01:13:29.413604
Epoch:[ 164 11 ] loss: 0.3917373716831207 2022-07-01 01:13:29.822720
Epoch:[ 164 12 ] loss: 0.3942389488220215 2022-07-01 01:13:30.231757
Epoch:[ 164 13 ] loss: 0.39437514543533325 2022-07-01 01:13:30.637999
Epoch:[ 164 14 ] loss: 0.39163681864738464 2022-07-01 01:13:31.047804
Epoch:[ 164 15 ] loss: 0.3915516436100006 2022-07-01 01:13:31.459611
Epoch:[ 164 16 ] loss: 0.39082470536231995 2022-07-01 01:13:37.004676
Epoch:[ 164 17 ] loss: 0.3928872048854828 2022-07-01 01:13:37.417932
Epoch:[ 164 18 ] loss: 0.39265912771224976 2022-07-01 01:13:37.839324
Epoch:[ 164 19 ] loss: 0.39535772800445557 2022-07-01 01:13:38.259200
Training_Epoch:[ 164 ] Training_loss: 0.3922596380114555 2022-07-01 01:13:38.259967
learning rate:  0.0014073748835532814
netparams have been saved once 164
val: 1 0.4269011914730072
val: 2 0.44439393281936646
val: 3 0.4354788362979889
val: 4 0.43621841073036194
val: 5 0.4541771113872528
val: 6 0.45054829120635986
val: 7 0.42471691966056824
val: 8 0.45004802942276
val: 9 0.4399528205394745
val: 10 0.44106417894363403
val: 11 0.43678390979766846
val: 12 0.4469996690750122
val: 13 0.4408135712146759
val: 14 0.43739548325538635
val: 15 0.44570663571357727
val: 16 0.4437495470046997
val: 17 0.436856746673584
val: 18 0.43799856305122375
val: 19 0.4276711940765381
val: 20 0.4314478933811188
val_Epoch:[ 164 ] val_loss: 0.4394461467862129 2022-07-01 01:13:42.035112
start training 2022-07-01 01:13:42.140727
Epoch:[ 165 0 ] loss: 0.39014819264411926 2022-07-01 01:13:56.939044
Epoch:[ 165 1 ] loss: 0.3940100371837616 2022-07-01 01:13:57.360153
Epoch:[ 165 2 ] loss: 0.39188918471336365 2022-07-01 01:13:57.781343
Epoch:[ 165 3 ] loss: 0.39246976375579834 2022-07-01 01:13:58.202549
Epoch:[ 165 4 ] loss: 0.38867539167404175 2022-07-01 01:13:58.623001
Epoch:[ 165 5 ] loss: 0.39111632108688354 2022-07-01 01:13:59.041468
Epoch:[ 165 6 ] loss: 0.39126816391944885 2022-07-01 01:13:59.460732
Epoch:[ 165 7 ] loss: 0.3934454321861267 2022-07-01 01:13:59.880139
Epoch:[ 165 8 ] loss: 0.3936552107334137 2022-07-01 01:14:00.301229
Epoch:[ 165 9 ] loss: 0.39254483580589294 2022-07-01 01:14:00.722323
Epoch:[ 165 10 ] loss: 0.39104774594306946 2022-07-01 01:14:01.143070
Epoch:[ 165 11 ] loss: 0.39121824502944946 2022-07-01 01:14:01.563116
Epoch:[ 165 12 ] loss: 0.39281415939331055 2022-07-01 01:14:01.985854
Epoch:[ 165 13 ] loss: 0.3935328722000122 2022-07-01 01:14:02.405535
Epoch:[ 165 14 ] loss: 0.39409634470939636 2022-07-01 01:14:02.818553
Epoch:[ 165 15 ] loss: 0.39506661891937256 2022-07-01 01:14:03.240872
Epoch:[ 165 16 ] loss: 0.39304524660110474 2022-07-01 01:14:08.445948
Epoch:[ 165 17 ] loss: 0.39034390449523926 2022-07-01 01:14:08.866722
Epoch:[ 165 18 ] loss: 0.3917650282382965 2022-07-01 01:14:09.287774
Epoch:[ 165 19 ] loss: 0.39461439847946167 2022-07-01 01:14:09.725504
Training_Epoch:[ 165 ] Training_loss: 0.39233835488557817 2022-07-01 01:14:09.726417
learning rate:  0.0014073748835532814
val: 1 0.43729719519615173
val: 2 0.44620761275291443
val: 3 0.4310144782066345
val: 4 0.43764060735702515
val: 5 0.4324291944503784
val: 6 0.4394506812095642
val: 7 0.4508257508277893
val: 8 0.43063780665397644
val: 9 0.43630078434944153
val: 10 0.4387646019458771
val: 11 0.45086708664894104
val: 12 0.4503215551376343
val: 13 0.4331657886505127
val: 14 0.45271944999694824
val: 15 0.4375857710838318
val: 16 0.43883854150772095
val: 17 0.43767550587654114
val: 18 0.4455237090587616
val: 19 0.4480534493923187
val: 20 0.43912357091903687
val_Epoch:[ 165 ] val_loss: 0.4407221570611 2022-07-01 01:14:13.571055
start training 2022-07-01 01:14:13.675554
Epoch:[ 166 0 ] loss: 0.39226946234703064 2022-07-01 01:14:27.961525
Epoch:[ 166 1 ] loss: 0.3914700448513031 2022-07-01 01:14:28.409421
Epoch:[ 166 2 ] loss: 0.39100784063339233 2022-07-01 01:14:28.831081
Epoch:[ 166 3 ] loss: 0.3951134979724884 2022-07-01 01:14:29.247311
Epoch:[ 166 4 ] loss: 0.3892650008201599 2022-07-01 01:14:29.669756
Epoch:[ 166 5 ] loss: 0.38939207792282104 2022-07-01 01:14:30.088878
Epoch:[ 166 6 ] loss: 0.3910458981990814 2022-07-01 01:14:30.507988
Epoch:[ 166 7 ] loss: 0.3935120701789856 2022-07-01 01:14:30.928255
Epoch:[ 166 8 ] loss: 0.3904293179512024 2022-07-01 01:14:31.348812
Epoch:[ 166 9 ] loss: 0.39446336030960083 2022-07-01 01:14:31.769797
Epoch:[ 166 10 ] loss: 0.39369237422943115 2022-07-01 01:14:32.194161
Epoch:[ 166 11 ] loss: 0.39499765634536743 2022-07-01 01:14:32.614151
Epoch:[ 166 12 ] loss: 0.3931303322315216 2022-07-01 01:14:33.036449
Epoch:[ 166 13 ] loss: 0.39031967520713806 2022-07-01 01:14:33.457081
Epoch:[ 166 14 ] loss: 0.3935042917728424 2022-07-01 01:14:33.880284
Epoch:[ 166 15 ] loss: 0.39087411761283875 2022-07-01 01:14:34.301263
Epoch:[ 166 16 ] loss: 0.39247292280197144 2022-07-01 01:14:39.680027
Epoch:[ 166 17 ] loss: 0.3904343545436859 2022-07-01 01:14:40.104692
Epoch:[ 166 18 ] loss: 0.39392149448394775 2022-07-01 01:14:40.538450
Epoch:[ 166 19 ] loss: 0.39399075508117676 2022-07-01 01:14:41.009635
Training_Epoch:[ 166 ] Training_loss: 0.39226532727479935 2022-07-01 01:14:41.010467
learning rate:  0.0014073748835532814
netparams have been saved once 166
val: 1 0.4420681595802307
val: 2 0.44406062364578247
val: 3 0.4443210959434509
val: 4 0.4437982738018036
val: 5 0.4359408915042877
val: 6 0.4409789741039276
val: 7 0.44051244854927063
val: 8 0.44848912954330444
val: 9 0.42965248227119446
val: 10 0.4538711905479431
val: 11 0.4399052858352661
val: 12 0.44016170501708984
val: 13 0.437834233045578
val: 14 0.4491380453109741
val: 15 0.44548723101615906
val: 16 0.4466742277145386
val: 17 0.4314609169960022
val: 18 0.43713730573654175
val: 19 0.4369610548019409
val: 20 0.436946302652359
val_Epoch:[ 166 ] val_loss: 0.44126997888088226 2022-07-01 01:14:44.852284
start training 2022-07-01 01:14:44.957452
Epoch:[ 167 0 ] loss: 0.39279690384864807 2022-07-01 01:14:59.579084
Epoch:[ 167 1 ] loss: 0.3925732374191284 2022-07-01 01:15:00.001896
Epoch:[ 167 2 ] loss: 0.39178362488746643 2022-07-01 01:15:00.424800
Epoch:[ 167 3 ] loss: 0.3904711604118347 2022-07-01 01:15:00.843668
Epoch:[ 167 4 ] loss: 0.3925471305847168 2022-07-01 01:15:01.268382
Epoch:[ 167 5 ] loss: 0.3922024369239807 2022-07-01 01:15:01.692161
Epoch:[ 167 6 ] loss: 0.39133670926094055 2022-07-01 01:15:02.116167
Epoch:[ 167 7 ] loss: 0.39162006974220276 2022-07-01 01:15:02.536190
Epoch:[ 167 8 ] loss: 0.39082071185112 2022-07-01 01:15:02.959064
Epoch:[ 167 9 ] loss: 0.39448410272598267 2022-07-01 01:15:03.377664
Epoch:[ 167 10 ] loss: 0.39193564653396606 2022-07-01 01:15:03.799180
Epoch:[ 167 11 ] loss: 0.39317893981933594 2022-07-01 01:15:04.215590
Epoch:[ 167 12 ] loss: 0.39249736070632935 2022-07-01 01:15:04.635644
Epoch:[ 167 13 ] loss: 0.39480000734329224 2022-07-01 01:15:05.055877
Epoch:[ 167 14 ] loss: 0.39299529790878296 2022-07-01 01:15:05.476188
Epoch:[ 167 15 ] loss: 0.39222317934036255 2022-07-01 01:15:05.897274
Epoch:[ 167 16 ] loss: 0.3929890990257263 2022-07-01 01:15:11.671298
Epoch:[ 167 17 ] loss: 0.3921225666999817 2022-07-01 01:15:12.092123
Epoch:[ 167 18 ] loss: 0.38998663425445557 2022-07-01 01:15:12.524521
Epoch:[ 167 19 ] loss: 0.39176782965660095 2022-07-01 01:15:12.945213
Training_Epoch:[ 167 ] Training_loss: 0.39225663244724274 2022-07-01 01:15:12.945898
learning rate:  0.0014073748835532814
val: 1 0.43149659037590027
val: 2 0.4372543692588806
val: 3 0.45306673645973206
val: 4 0.4434606432914734
val: 5 0.443768173456192
val: 6 0.43962934613227844
val: 7 0.43738698959350586
val: 8 0.4438517391681671
val: 9 0.445641428232193
val: 10 0.4452962279319763
val: 11 0.43790191411972046
val: 12 0.4496777057647705
val: 13 0.4359917938709259
val: 14 0.4419146478176117
val: 15 0.4361693263053894
val: 16 0.43591439723968506
val: 17 0.4503666162490845
val: 18 0.444051593542099
val: 19 0.44444739818573
val: 20 0.432937890291214
val_Epoch:[ 167 ] val_loss: 0.44151127636432647 2022-07-01 01:15:16.706049
start training 2022-07-01 01:15:16.810522
Epoch:[ 168 0 ] loss: 0.39106374979019165 2022-07-01 01:15:31.613952
Epoch:[ 168 1 ] loss: 0.39145854115486145 2022-07-01 01:15:32.035509
Epoch:[ 168 2 ] loss: 0.3923294246196747 2022-07-01 01:15:32.450385
Epoch:[ 168 3 ] loss: 0.39258435368537903 2022-07-01 01:15:32.870241
Epoch:[ 168 4 ] loss: 0.39168477058410645 2022-07-01 01:15:33.292060
Epoch:[ 168 5 ] loss: 0.3908604085445404 2022-07-01 01:15:33.712879
Epoch:[ 168 6 ] loss: 0.3905794024467468 2022-07-01 01:15:34.134277
Epoch:[ 168 7 ] loss: 0.39005351066589355 2022-07-01 01:15:34.556228
Epoch:[ 168 8 ] loss: 0.3915046453475952 2022-07-01 01:15:34.976478
Epoch:[ 168 9 ] loss: 0.3909102976322174 2022-07-01 01:15:35.395146
Epoch:[ 168 10 ] loss: 0.3934890925884247 2022-07-01 01:15:35.817104
Epoch:[ 168 11 ] loss: 0.3912401795387268 2022-07-01 01:15:36.237717
Epoch:[ 168 12 ] loss: 0.394491970539093 2022-07-01 01:15:36.658045
Epoch:[ 168 13 ] loss: 0.3935510218143463 2022-07-01 01:15:37.079138
Epoch:[ 168 14 ] loss: 0.3900603652000427 2022-07-01 01:15:37.497361
Epoch:[ 168 15 ] loss: 0.39368289709091187 2022-07-01 01:15:37.919883
Epoch:[ 168 16 ] loss: 0.3915966749191284 2022-07-01 01:15:43.205598
Epoch:[ 168 17 ] loss: 0.39470142126083374 2022-07-01 01:15:43.623590
Epoch:[ 168 18 ] loss: 0.3928805887699127 2022-07-01 01:15:44.069076
Epoch:[ 168 19 ] loss: 0.39301177859306335 2022-07-01 01:15:44.494792
Training_Epoch:[ 168 ] Training_loss: 0.3920867547392845 2022-07-01 01:15:44.495631
learning rate:  0.0014073748835532814
netparams have been saved once 168
val: 1 0.4412258565425873
val: 2 0.4412582516670227
val: 3 0.4378833472728729
val: 4 0.44956347346305847
val: 5 0.4420894682407379
val: 6 0.4420948326587677
val: 7 0.4337136149406433
val: 8 0.43586602807044983
val: 9 0.429993599653244
val: 10 0.4471554160118103
val: 11 0.445339173078537
val: 12 0.4443206489086151
val: 13 0.44664686918258667
val: 14 0.431416392326355
val: 15 0.43727490305900574
val: 16 0.44499361515045166
val: 17 0.44390955567359924
val: 18 0.43826785683631897
val: 19 0.43521398305892944
val: 20 0.45012781023979187
val_Epoch:[ 168 ] val_loss: 0.44091773480176927 2022-07-01 01:15:48.309677
start training 2022-07-01 01:15:48.412723
Epoch:[ 169 0 ] loss: 0.3949138820171356 2022-07-01 01:16:02.441592
Epoch:[ 169 1 ] loss: 0.39328286051750183 2022-07-01 01:16:03.445191
Epoch:[ 169 2 ] loss: 0.39155590534210205 2022-07-01 01:16:03.866038
Epoch:[ 169 3 ] loss: 0.3924424350261688 2022-07-01 01:16:04.288242
Epoch:[ 169 4 ] loss: 0.3919368386268616 2022-07-01 01:16:04.707586
Epoch:[ 169 5 ] loss: 0.3904670774936676 2022-07-01 01:16:05.130202
Epoch:[ 169 6 ] loss: 0.3930043578147888 2022-07-01 01:16:05.556650
Epoch:[ 169 7 ] loss: 0.3941963315010071 2022-07-01 01:16:05.980337
Epoch:[ 169 8 ] loss: 0.3916262984275818 2022-07-01 01:16:06.404886
Epoch:[ 169 9 ] loss: 0.39187324047088623 2022-07-01 01:16:06.824473
Epoch:[ 169 10 ] loss: 0.3904666006565094 2022-07-01 01:16:07.246802
Epoch:[ 169 11 ] loss: 0.3889562785625458 2022-07-01 01:16:07.667315
Epoch:[ 169 12 ] loss: 0.3895786702632904 2022-07-01 01:16:08.093030
Epoch:[ 169 13 ] loss: 0.3921933174133301 2022-07-01 01:16:08.514564
Epoch:[ 169 14 ] loss: 0.39047014713287354 2022-07-01 01:16:08.936703
Epoch:[ 169 15 ] loss: 0.3905995190143585 2022-07-01 01:16:09.357820
Epoch:[ 169 16 ] loss: 0.39294499158859253 2022-07-01 01:16:14.338010
Epoch:[ 169 17 ] loss: 0.3940383195877075 2022-07-01 01:16:14.916417
Epoch:[ 169 18 ] loss: 0.39434927701950073 2022-07-01 01:16:15.337214
Epoch:[ 169 19 ] loss: 0.3912178575992584 2022-07-01 01:16:15.759082
Training_Epoch:[ 169 ] Training_loss: 0.3920057103037834 2022-07-01 01:16:15.759760
learning rate:  0.0014073748835532814
val: 1 0.4454971253871918
val: 2 0.43339258432388306
val: 3 0.4335218369960785
val: 4 0.4503020942211151
val: 5 0.4449205696582794
val: 6 0.43921807408332825
val: 7 0.4453446567058563
val: 8 0.44630083441734314
val: 9 0.4427897036075592
val: 10 0.4367048442363739
val: 11 0.4458893835544586
val: 12 0.43279320001602173
val: 13 0.44783031940460205
val: 14 0.4361175000667572
val: 15 0.441114604473114
val: 16 0.4364093244075775
val: 17 0.4447191059589386
val: 18 0.4341469407081604
val: 19 0.4418455958366394
val: 20 0.44948992133140564
val_Epoch:[ 169 ] val_loss: 0.4414174109697342 2022-07-01 01:16:19.549916
start training 2022-07-01 01:16:19.718080
Epoch:[ 170 0 ] loss: 0.39257919788360596 2022-07-01 01:16:34.086432
Epoch:[ 170 1 ] loss: 0.3923717141151428 2022-07-01 01:16:34.515678
Epoch:[ 170 2 ] loss: 0.38894057273864746 2022-07-01 01:16:34.934921
Epoch:[ 170 3 ] loss: 0.3922158479690552 2022-07-01 01:16:35.357756
Epoch:[ 170 4 ] loss: 0.3933075964450836 2022-07-01 01:16:35.772499
Epoch:[ 170 5 ] loss: 0.3922760784626007 2022-07-01 01:16:36.192688
Epoch:[ 170 6 ] loss: 0.3915005326271057 2022-07-01 01:16:36.614890
Epoch:[ 170 7 ] loss: 0.38954779505729675 2022-07-01 01:16:37.037469
Epoch:[ 170 8 ] loss: 0.3911644518375397 2022-07-01 01:16:37.457672
Epoch:[ 170 9 ] loss: 0.38994312286376953 2022-07-01 01:16:37.877569
Epoch:[ 170 10 ] loss: 0.3943564295768738 2022-07-01 01:16:38.297811
Epoch:[ 170 11 ] loss: 0.3913089334964752 2022-07-01 01:16:38.719776
Epoch:[ 170 12 ] loss: 0.3933897614479065 2022-07-01 01:16:39.140075
Epoch:[ 170 13 ] loss: 0.39148634672164917 2022-07-01 01:16:39.561999
Epoch:[ 170 14 ] loss: 0.38928404450416565 2022-07-01 01:16:39.984010
Epoch:[ 170 15 ] loss: 0.39306288957595825 2022-07-01 01:16:40.407151
Epoch:[ 170 16 ] loss: 0.39123740792274475 2022-07-01 01:16:45.902039
Epoch:[ 170 17 ] loss: 0.3939296007156372 2022-07-01 01:16:46.322046
Epoch:[ 170 18 ] loss: 0.39059752225875854 2022-07-01 01:16:46.743090
Epoch:[ 170 19 ] loss: 0.39148780703544617 2022-07-01 01:16:47.161427
Training_Epoch:[ 170 ] Training_loss: 0.39169938266277315 2022-07-01 01:16:47.162141
learning rate:  0.0014073748835532814
netparams have been saved once 170
val: 1 0.4389056861400604
val: 2 0.44740933179855347
val: 3 0.44116687774658203
val: 4 0.4415692090988159
val: 5 0.44438767433166504
val: 6 0.4299997389316559
val: 7 0.43420544266700745
val: 8 0.4289937913417816
val: 9 0.4435681402683258
val: 10 0.4481702148914337
val: 11 0.4454974830150604
val: 12 0.4471205174922943
val: 13 0.44766873121261597
val: 14 0.4347762167453766
val: 15 0.4344179630279541
val: 16 0.452614426612854
val: 17 0.4414457380771637
val: 18 0.434024453163147
val: 19 0.44742491841316223
val: 20 0.4355294406414032
val_Epoch:[ 170 ] val_loss: 0.44094479978084566 2022-07-01 01:16:50.967345
start training 2022-07-01 01:16:51.070316
Epoch:[ 171 0 ] loss: 0.38943448662757874 2022-07-01 01:17:05.744195
Epoch:[ 171 1 ] loss: 0.3912912607192993 2022-07-01 01:17:06.164084
Epoch:[ 171 2 ] loss: 0.38906747102737427 2022-07-01 01:17:06.585292
Epoch:[ 171 3 ] loss: 0.39143961668014526 2022-07-01 01:17:07.004440
Epoch:[ 171 4 ] loss: 0.39329707622528076 2022-07-01 01:17:07.423927
Epoch:[ 171 5 ] loss: 0.39400577545166016 2022-07-01 01:17:07.843833
Epoch:[ 171 6 ] loss: 0.39098450541496277 2022-07-01 01:17:08.262667
Epoch:[ 171 7 ] loss: 0.39132803678512573 2022-07-01 01:17:08.683652
Epoch:[ 171 8 ] loss: 0.3927946984767914 2022-07-01 01:17:09.105041
Epoch:[ 171 9 ] loss: 0.39255696535110474 2022-07-01 01:17:09.525878
Epoch:[ 171 10 ] loss: 0.38971295952796936 2022-07-01 01:17:09.947373
Epoch:[ 171 11 ] loss: 0.39195969700813293 2022-07-01 01:17:10.368219
Epoch:[ 171 12 ] loss: 0.3927347958087921 2022-07-01 01:17:10.789083
Epoch:[ 171 13 ] loss: 0.3920047879219055 2022-07-01 01:17:11.208185
Epoch:[ 171 14 ] loss: 0.3926072418689728 2022-07-01 01:17:11.630059
Epoch:[ 171 15 ] loss: 0.3909415900707245 2022-07-01 01:17:12.045596
Epoch:[ 171 16 ] loss: 0.3903779983520508 2022-07-01 01:17:17.158787
Epoch:[ 171 17 ] loss: 0.3914138674736023 2022-07-01 01:17:17.577984
Epoch:[ 171 18 ] loss: 0.3905121684074402 2022-07-01 01:17:17.998985
Epoch:[ 171 19 ] loss: 0.3906349539756775 2022-07-01 01:17:18.418824
Training_Epoch:[ 171 ] Training_loss: 0.39145499765872954 2022-07-01 01:17:18.419539
learning rate:  0.0011258999068426252
val: 1 0.4460880756378174
val: 2 0.45028194785118103
val: 3 0.4425676465034485
val: 4 0.44590169191360474
val: 5 0.4322396218776703
val: 6 0.44233790040016174
val: 7 0.4294079840183258
val: 8 0.44634678959846497
val: 9 0.43735235929489136
val: 10 0.4411066174507141
val: 11 0.4445664584636688
val: 12 0.43833649158477783
val: 13 0.4417095184326172
val: 14 0.4435547888278961
val: 15 0.4423988461494446
val: 16 0.4485647678375244
val: 17 0.4516226053237915
val: 18 0.4406639039516449
val: 19 0.43389710783958435
val: 20 0.44095972180366516
val_Epoch:[ 171 ] val_loss: 0.44199524223804476 2022-07-01 01:17:22.156800
start training 2022-07-01 01:17:22.261222
Epoch:[ 172 0 ] loss: 0.38977953791618347 2022-07-01 01:17:36.963017
Epoch:[ 172 1 ] loss: 0.39074379205703735 2022-07-01 01:17:37.383334
Epoch:[ 172 2 ] loss: 0.3909992575645447 2022-07-01 01:17:37.808185
Epoch:[ 172 3 ] loss: 0.3886735439300537 2022-07-01 01:17:38.229075
Epoch:[ 172 4 ] loss: 0.39390480518341064 2022-07-01 01:17:38.649715
Epoch:[ 172 5 ] loss: 0.39275500178337097 2022-07-01 01:17:39.068699
Epoch:[ 172 6 ] loss: 0.3895072042942047 2022-07-01 01:17:39.489338
Epoch:[ 172 7 ] loss: 0.39114347100257874 2022-07-01 01:17:39.902295
Epoch:[ 172 8 ] loss: 0.38840728998184204 2022-07-01 01:17:40.323253
Epoch:[ 172 9 ] loss: 0.3900303244590759 2022-07-01 01:17:40.744299
Epoch:[ 172 10 ] loss: 0.3920448124408722 2022-07-01 01:17:41.166960
Epoch:[ 172 11 ] loss: 0.3893531262874603 2022-07-01 01:17:41.585939
Epoch:[ 172 12 ] loss: 0.39159226417541504 2022-07-01 01:17:42.006702
Epoch:[ 172 13 ] loss: 0.39282676577568054 2022-07-01 01:17:42.420250
Epoch:[ 172 14 ] loss: 0.39200663566589355 2022-07-01 01:17:42.839705
Epoch:[ 172 15 ] loss: 0.38997846841812134 2022-07-01 01:17:43.261645
Epoch:[ 172 16 ] loss: 0.38967615365982056 2022-07-01 01:17:48.708447
Epoch:[ 172 17 ] loss: 0.3948136270046234 2022-07-01 01:17:49.130975
Epoch:[ 172 18 ] loss: 0.3926486670970917 2022-07-01 01:17:49.550900
Epoch:[ 172 19 ] loss: 0.3903980851173401 2022-07-01 01:17:49.969831
Training_Epoch:[ 172 ] Training_loss: 0.39106414169073106 2022-07-01 01:17:49.970485
learning rate:  0.0011258999068426252
netparams have been saved once 172
val: 1 0.43014249205589294
val: 2 0.43528512120246887
val: 3 0.43906012177467346
val: 4 0.44441691040992737
val: 5 0.434464693069458
val: 6 0.4466360807418823
val: 7 0.4394223690032959
val: 8 0.4598773121833801
val: 9 0.4373045265674591
val: 10 0.4261850118637085
val: 11 0.4475694000720978
val: 12 0.44128966331481934
val: 13 0.43546971678733826
val: 14 0.4387863576412201
val: 15 0.45096805691719055
val: 16 0.442179799079895
val: 17 0.4519551992416382
val: 18 0.4345878064632416
val: 19 0.4385620355606079
val: 20 0.44516006112098694
val_Epoch:[ 172 ] val_loss: 0.4409661367535591 2022-07-01 01:17:53.749001
start training 2022-07-01 01:17:53.858970
Epoch:[ 173 0 ] loss: 0.38996458053588867 2022-07-01 01:18:08.575472
Epoch:[ 173 1 ] loss: 0.38907599449157715 2022-07-01 01:18:08.995805
Epoch:[ 173 2 ] loss: 0.39225491881370544 2022-07-01 01:18:09.418064
Epoch:[ 173 3 ] loss: 0.3909735381603241 2022-07-01 01:18:09.839522
Epoch:[ 173 4 ] loss: 0.3901267945766449 2022-07-01 01:18:10.253763
Epoch:[ 173 5 ] loss: 0.3897087574005127 2022-07-01 01:18:10.667529
Epoch:[ 173 6 ] loss: 0.3917694687843323 2022-07-01 01:18:11.087984
Epoch:[ 173 7 ] loss: 0.3892531394958496 2022-07-01 01:18:11.509401
Epoch:[ 173 8 ] loss: 0.3898712396621704 2022-07-01 01:18:11.929587
Epoch:[ 173 9 ] loss: 0.3894535005092621 2022-07-01 01:18:12.351355
Epoch:[ 173 10 ] loss: 0.39372149109840393 2022-07-01 01:18:12.775304
Epoch:[ 173 11 ] loss: 0.39260926842689514 2022-07-01 01:18:13.196223
Epoch:[ 173 12 ] loss: 0.39079803228378296 2022-07-01 01:18:13.617158
Epoch:[ 173 13 ] loss: 0.38947275280952454 2022-07-01 01:18:14.038233
Epoch:[ 173 14 ] loss: 0.39056965708732605 2022-07-01 01:18:14.459484
Epoch:[ 173 15 ] loss: 0.3903001844882965 2022-07-01 01:18:14.884741
Epoch:[ 173 16 ] loss: 0.38922813534736633 2022-07-01 01:18:20.121039
Epoch:[ 173 17 ] loss: 0.39212825894355774 2022-07-01 01:18:20.542177
Epoch:[ 173 18 ] loss: 0.3933160901069641 2022-07-01 01:18:20.963552
Epoch:[ 173 19 ] loss: 0.3913022577762604 2022-07-01 01:18:21.383973
Training_Epoch:[ 173 ] Training_loss: 0.39079490303993225 2022-07-01 01:18:21.384649
learning rate:  0.0011258999068426252
val: 1 0.44482603669166565
val: 2 0.446465402841568
val: 3 0.4307321012020111
val: 4 0.4409017264842987
val: 5 0.44138264656066895
val: 6 0.440579354763031
val: 7 0.4367842674255371
val: 8 0.4377916753292084
val: 9 0.44385257363319397
val: 10 0.4311456084251404
val: 11 0.4494049549102783
val: 12 0.44125863909721375
val: 13 0.44784700870513916
val: 14 0.4356103539466858
val: 15 0.4530564248561859
val: 16 0.4526255130767822
val: 17 0.4463241696357727
val: 18 0.4446844756603241
val: 19 0.4470027685165405
val: 20 0.4482973515987396
val_Epoch:[ 173 ] val_loss: 0.4430286526679993 2022-07-01 01:18:25.194550
start training 2022-07-01 01:18:25.302870
Epoch:[ 174 0 ] loss: 0.38981741666793823 2022-07-01 01:18:39.283467
Epoch:[ 174 1 ] loss: 0.389262318611145 2022-07-01 01:18:40.102056
Epoch:[ 174 2 ] loss: 0.3891216218471527 2022-07-01 01:18:40.522019
Epoch:[ 174 3 ] loss: 0.3916274905204773 2022-07-01 01:18:40.943760
Epoch:[ 174 4 ] loss: 0.39440101385116577 2022-07-01 01:18:41.367103
Epoch:[ 174 5 ] loss: 0.38826388120651245 2022-07-01 01:18:41.782542
Epoch:[ 174 6 ] loss: 0.39394110441207886 2022-07-01 01:18:42.202719
Epoch:[ 174 7 ] loss: 0.3899771571159363 2022-07-01 01:18:42.622704
Epoch:[ 174 8 ] loss: 0.39182427525520325 2022-07-01 01:18:43.044088
Epoch:[ 174 9 ] loss: 0.3934648931026459 2022-07-01 01:18:43.462726
Epoch:[ 174 10 ] loss: 0.3889268934726715 2022-07-01 01:18:43.884669
Epoch:[ 174 11 ] loss: 0.3905494809150696 2022-07-01 01:18:44.307819
Epoch:[ 174 12 ] loss: 0.39225250482559204 2022-07-01 01:18:44.728548
Epoch:[ 174 13 ] loss: 0.38985690474510193 2022-07-01 01:18:45.149149
Epoch:[ 174 14 ] loss: 0.3906991183757782 2022-07-01 01:18:45.570156
Epoch:[ 174 15 ] loss: 0.389960378408432 2022-07-01 01:18:45.990221
Epoch:[ 174 16 ] loss: 0.3889297544956207 2022-07-01 01:18:51.525569
Epoch:[ 174 17 ] loss: 0.3898966610431671 2022-07-01 01:18:51.947495
Epoch:[ 174 18 ] loss: 0.3905123472213745 2022-07-01 01:18:52.370612
Epoch:[ 174 19 ] loss: 0.39237406849861145 2022-07-01 01:18:52.790373
Training_Epoch:[ 174 ] Training_loss: 0.39078296422958375 2022-07-01 01:18:52.791087
learning rate:  0.0011258999068426252
netparams have been saved once 174
val: 1 0.4436408281326294
val: 2 0.44057339429855347
val: 3 0.44044119119644165
val: 4 0.43824732303619385
val: 5 0.44554468989372253
val: 6 0.42983514070510864
val: 7 0.44342154264450073
val: 8 0.44010064005851746
val: 9 0.45333489775657654
val: 10 0.4486302435398102
val: 11 0.4363963007926941
val: 12 0.44622763991355896
val: 13 0.4470064640045166
val: 14 0.454263836145401
val: 15 0.42988401651382446
val: 16 0.4377346336841583
val: 17 0.4267549216747284
val: 18 0.4435863494873047
val: 19 0.4289270043373108
val: 20 0.4516260027885437
val_Epoch:[ 174 ] val_loss: 0.4413088530302048 2022-07-01 01:18:56.552673
start training 2022-07-01 01:18:56.658489
Epoch:[ 175 0 ] loss: 0.39146140217781067 2022-07-01 01:19:10.596592
Epoch:[ 175 1 ] loss: 0.39149704575538635 2022-07-01 01:19:11.345897
Epoch:[ 175 2 ] loss: 0.39135876297950745 2022-07-01 01:19:11.765471
Epoch:[ 175 3 ] loss: 0.3903762996196747 2022-07-01 01:19:12.186221
Epoch:[ 175 4 ] loss: 0.39119574427604675 2022-07-01 01:19:12.608319
Epoch:[ 175 5 ] loss: 0.3909945487976074 2022-07-01 01:19:13.030092
Epoch:[ 175 6 ] loss: 0.38623884320259094 2022-07-01 01:19:13.450967
Epoch:[ 175 7 ] loss: 0.3888046145439148 2022-07-01 01:19:13.870451
Epoch:[ 175 8 ] loss: 0.39183977246284485 2022-07-01 01:19:14.290234
Epoch:[ 175 9 ] loss: 0.389359712600708 2022-07-01 01:19:14.709830
Epoch:[ 175 10 ] loss: 0.3926781713962555 2022-07-01 01:19:15.123368
Epoch:[ 175 11 ] loss: 0.3888203799724579 2022-07-01 01:19:15.544746
Epoch:[ 175 12 ] loss: 0.3928755819797516 2022-07-01 01:19:15.966798
Epoch:[ 175 13 ] loss: 0.39248114824295044 2022-07-01 01:19:16.386998
Epoch:[ 175 14 ] loss: 0.392318457365036 2022-07-01 01:19:16.807365
Epoch:[ 175 15 ] loss: 0.3926200866699219 2022-07-01 01:19:17.228112
Epoch:[ 175 16 ] loss: 0.39160069823265076 2022-07-01 01:19:22.366097
Epoch:[ 175 17 ] loss: 0.39069491624832153 2022-07-01 01:19:23.165264
Epoch:[ 175 18 ] loss: 0.3892867863178253 2022-07-01 01:19:23.587784
Epoch:[ 175 19 ] loss: 0.39077651500701904 2022-07-01 01:19:24.010031
Training_Epoch:[ 175 ] Training_loss: 0.3908639743924141 2022-07-01 01:19:24.010815
learning rate:  0.0011258999068426252
val: 1 0.43723756074905396
val: 2 0.4421669840812683
val: 3 0.4394523501396179
val: 4 0.43332338333129883
val: 5 0.4419479966163635
val: 6 0.4477136731147766
val: 7 0.45174267888069153
val: 8 0.4342898726463318
val: 9 0.44703492522239685
val: 10 0.43825843930244446
val: 11 0.44872233271598816
val: 12 0.43615013360977173
val: 13 0.4280061721801758
val: 14 0.43953168392181396
val: 15 0.4466627538204193
val: 16 0.43783605098724365
val: 17 0.44034135341644287
val: 18 0.4376237988471985
val: 19 0.43579548597335815
val: 20 0.44512391090393066
val_Epoch:[ 175 ] val_loss: 0.44044807702302935 2022-07-01 01:19:27.683504
start training 2022-07-01 01:19:27.788306
Epoch:[ 176 0 ] loss: 0.3913601338863373 2022-07-01 01:19:42.893095
Epoch:[ 176 1 ] loss: 0.390792578458786 2022-07-01 01:19:43.312352
Epoch:[ 176 2 ] loss: 0.3901652693748474 2022-07-01 01:19:43.734602
Epoch:[ 176 3 ] loss: 0.38988932967185974 2022-07-01 01:19:44.158180
Epoch:[ 176 4 ] loss: 0.39120689034461975 2022-07-01 01:19:44.572024
Epoch:[ 176 5 ] loss: 0.3909689486026764 2022-07-01 01:19:44.994245
Epoch:[ 176 6 ] loss: 0.3890813887119293 2022-07-01 01:19:45.417243
Epoch:[ 176 7 ] loss: 0.3881192207336426 2022-07-01 01:19:45.832585
Epoch:[ 176 8 ] loss: 0.3940965533256531 2022-07-01 01:19:46.253413
Epoch:[ 176 9 ] loss: 0.39080190658569336 2022-07-01 01:19:46.673795
Epoch:[ 176 10 ] loss: 0.3921484649181366 2022-07-01 01:19:47.094992
Epoch:[ 176 11 ] loss: 0.38792070746421814 2022-07-01 01:19:47.515692
Epoch:[ 176 12 ] loss: 0.38804253935813904 2022-07-01 01:19:47.937840
Epoch:[ 176 13 ] loss: 0.3948962688446045 2022-07-01 01:19:48.360726
Epoch:[ 176 14 ] loss: 0.3894241750240326 2022-07-01 01:19:48.777732
Epoch:[ 176 15 ] loss: 0.39050766825675964 2022-07-01 01:19:49.187209
Epoch:[ 176 16 ] loss: 0.3898334205150604 2022-07-01 01:19:54.140786
Epoch:[ 176 17 ] loss: 0.3915084898471832 2022-07-01 01:19:54.548017
Epoch:[ 176 18 ] loss: 0.39044395089149475 2022-07-01 01:19:54.975269
Epoch:[ 176 19 ] loss: 0.3917351961135864 2022-07-01 01:19:55.399028
Training_Epoch:[ 176 ] Training_loss: 0.390647155046463 2022-07-01 01:19:55.399779
learning rate:  0.0011258999068426252
netparams have been saved once 176
val: 1 0.43836286664009094
val: 2 0.4385073781013489
val: 3 0.4465063214302063
val: 4 0.4308125078678131
val: 5 0.4378235638141632
val: 6 0.45148560404777527
val: 7 0.44683414697647095
val: 8 0.42728209495544434
val: 9 0.4478107690811157
val: 10 0.44582128524780273
val: 11 0.44433462619781494
val: 12 0.45148780941963196
val: 13 0.45121821761131287
val: 14 0.44483745098114014
val: 15 0.44232767820358276
val: 16 0.44155821204185486
val: 17 0.4369242489337921
val: 18 0.4371963143348694
val: 19 0.44016820192337036
val: 20 0.4382375478744507
val_Epoch:[ 176 ] val_loss: 0.4419768422842026 2022-07-01 01:19:59.310281
start training 2022-07-01 01:19:59.418521
Epoch:[ 177 0 ] loss: 0.39075785875320435 2022-07-01 01:20:13.362351
Epoch:[ 177 1 ] loss: 0.3923048973083496 2022-07-01 01:20:13.822547
Epoch:[ 177 2 ] loss: 0.3905903398990631 2022-07-01 01:20:14.334646
Epoch:[ 177 3 ] loss: 0.39135006070137024 2022-07-01 01:20:14.758439
Epoch:[ 177 4 ] loss: 0.3902943432331085 2022-07-01 01:20:15.180591
Epoch:[ 177 5 ] loss: 0.39226222038269043 2022-07-01 01:20:15.600499
Epoch:[ 177 6 ] loss: 0.3917413651943207 2022-07-01 01:20:16.021598
Epoch:[ 177 7 ] loss: 0.389224648475647 2022-07-01 01:20:16.443313
Epoch:[ 177 8 ] loss: 0.3906676173210144 2022-07-01 01:20:16.863860
Epoch:[ 177 9 ] loss: 0.3935125768184662 2022-07-01 01:20:17.287507
Epoch:[ 177 10 ] loss: 0.3898853659629822 2022-07-01 01:20:17.707593
Epoch:[ 177 11 ] loss: 0.3893257677555084 2022-07-01 01:20:18.129828
Epoch:[ 177 12 ] loss: 0.3906036913394928 2022-07-01 01:20:18.549485
Epoch:[ 177 13 ] loss: 0.39050447940826416 2022-07-01 01:20:18.970601
Epoch:[ 177 14 ] loss: 0.3916221261024475 2022-07-01 01:20:19.393172
Epoch:[ 177 15 ] loss: 0.3900822401046753 2022-07-01 01:20:19.814486
Epoch:[ 177 16 ] loss: 0.3892114460468292 2022-07-01 01:20:25.733928
Epoch:[ 177 17 ] loss: 0.390995055437088 2022-07-01 01:20:26.153358
Epoch:[ 177 18 ] loss: 0.39062952995300293 2022-07-01 01:20:26.574131
Epoch:[ 177 19 ] loss: 0.3917524218559265 2022-07-01 01:20:26.993434
Training_Epoch:[ 177 ] Training_loss: 0.39086590260267257 2022-07-01 01:20:26.994103
learning rate:  0.0011258999068426252
val: 1 0.43122613430023193
val: 2 0.438193678855896
val: 3 0.43760889768600464
val: 4 0.4349521994590759
val: 5 0.4370117783546448
val: 6 0.4460066854953766
val: 7 0.4380110800266266
val: 8 0.44368597865104675
val: 9 0.4479973614215851
val: 10 0.43956732749938965
val: 11 0.4435330331325531
val: 12 0.44809073209762573
val: 13 0.4469907581806183
val: 14 0.44582679867744446
val: 15 0.44986820220947266
val: 16 0.4380401074886322
val: 17 0.44402310252189636
val: 18 0.44387713074684143
val: 19 0.4439670443534851
val: 20 0.44193413853645325
val_Epoch:[ 177 ] val_loss: 0.442020608484745 2022-07-01 01:20:30.700196
start training 2022-07-01 01:20:30.804665
Epoch:[ 178 0 ] loss: 0.3899456560611725 2022-07-01 01:20:45.505184
Epoch:[ 178 1 ] loss: 0.3915300667285919 2022-07-01 01:20:45.926441
Epoch:[ 178 2 ] loss: 0.3897504508495331 2022-07-01 01:20:46.350387
Epoch:[ 178 3 ] loss: 0.39121052622795105 2022-07-01 01:20:46.760642
Epoch:[ 178 4 ] loss: 0.39069807529449463 2022-07-01 01:20:47.170502
Epoch:[ 178 5 ] loss: 0.3890708386898041 2022-07-01 01:20:47.581696
Epoch:[ 178 6 ] loss: 0.3902412950992584 2022-07-01 01:20:47.990634
Epoch:[ 178 7 ] loss: 0.39209747314453125 2022-07-01 01:20:48.407353
Epoch:[ 178 8 ] loss: 0.3917679190635681 2022-07-01 01:20:48.817890
Epoch:[ 178 9 ] loss: 0.3923172354698181 2022-07-01 01:20:49.227604
Epoch:[ 178 10 ] loss: 0.3902533948421478 2022-07-01 01:20:49.636048
Epoch:[ 178 11 ] loss: 0.38848572969436646 2022-07-01 01:20:50.052857
Epoch:[ 178 12 ] loss: 0.3921251893043518 2022-07-01 01:20:50.463483
Epoch:[ 178 13 ] loss: 0.3900747299194336 2022-07-01 01:20:50.874465
Epoch:[ 178 14 ] loss: 0.3896726369857788 2022-07-01 01:20:51.286462
Epoch:[ 178 15 ] loss: 0.38987764716148376 2022-07-01 01:20:51.697150
Epoch:[ 178 16 ] loss: 0.39146220684051514 2022-07-01 01:20:57.023070
Epoch:[ 178 17 ] loss: 0.39354756474494934 2022-07-01 01:20:57.433137
Epoch:[ 178 18 ] loss: 0.39124733209609985 2022-07-01 01:20:57.863204
Epoch:[ 178 19 ] loss: 0.3888232111930847 2022-07-01 01:20:58.282851
Training_Epoch:[ 178 ] Training_loss: 0.3907099589705467 2022-07-01 01:20:58.283686
learning rate:  0.0011258999068426252
netparams have been saved once 178
val: 1 0.44987761974334717
val: 2 0.44743043184280396
val: 3 0.44576239585876465
val: 4 0.43952319025993347
val: 5 0.4300081133842468
val: 6 0.4311537444591522
val: 7 0.44272518157958984
val: 8 0.4450354278087616
val: 9 0.4445493221282959
val: 10 0.44831424951553345
val: 11 0.43500179052352905
val: 12 0.43578481674194336
val: 13 0.45485198497772217
val: 14 0.43801647424697876
val: 15 0.4459960162639618
val: 16 0.4318997263908386
val: 17 0.4441981315612793
val: 18 0.4465935230255127
val: 19 0.44389963150024414
val: 20 0.43743932247161865
val_Epoch:[ 178 ] val_loss: 0.4419030547142029 2022-07-01 01:21:02.020972
start training 2022-07-01 01:21:02.127679
Epoch:[ 179 0 ] loss: 0.39022529125213623 2022-07-01 01:21:16.052777
Epoch:[ 179 1 ] loss: 0.38864731788635254 2022-07-01 01:21:16.493537
Epoch:[ 179 2 ] loss: 0.38992026448249817 2022-07-01 01:21:16.918672
Epoch:[ 179 3 ] loss: 0.3878602683544159 2022-07-01 01:21:17.338791
Epoch:[ 179 4 ] loss: 0.3928702473640442 2022-07-01 01:21:17.758505
Epoch:[ 179 5 ] loss: 0.3907192051410675 2022-07-01 01:21:18.182235
Epoch:[ 179 6 ] loss: 0.38793715834617615 2022-07-01 01:21:18.603692
Epoch:[ 179 7 ] loss: 0.3900219202041626 2022-07-01 01:21:19.024009
Epoch:[ 179 8 ] loss: 0.38874879479408264 2022-07-01 01:21:19.436568
Epoch:[ 179 9 ] loss: 0.39418208599090576 2022-07-01 01:21:19.847338
Epoch:[ 179 10 ] loss: 0.3882400691509247 2022-07-01 01:21:20.256250
Epoch:[ 179 11 ] loss: 0.39074796438217163 2022-07-01 01:21:20.664511
Epoch:[ 179 12 ] loss: 0.3905826508998871 2022-07-01 01:21:21.074211
Epoch:[ 179 13 ] loss: 0.3900011479854584 2022-07-01 01:21:21.484715
Epoch:[ 179 14 ] loss: 0.39306601881980896 2022-07-01 01:21:21.895231
Epoch:[ 179 15 ] loss: 0.3911992013454437 2022-07-01 01:21:22.305959
Epoch:[ 179 16 ] loss: 0.3909431993961334 2022-07-01 01:21:27.917598
Epoch:[ 179 17 ] loss: 0.39171841740608215 2022-07-01 01:21:28.327981
Epoch:[ 179 18 ] loss: 0.39077499508857727 2022-07-01 01:21:28.749425
Epoch:[ 179 19 ] loss: 0.39212900400161743 2022-07-01 01:21:29.170195
Training_Epoch:[ 179 ] Training_loss: 0.39052676111459733 2022-07-01 01:21:29.170923
learning rate:  0.0011258999068426252
val: 1 0.4406633675098419
val: 2 0.45326703786849976
val: 3 0.4390147924423218
val: 4 0.4463058114051819
val: 5 0.44780516624450684
val: 6 0.4575709104537964
val: 7 0.4499630630016327
val: 8 0.43938401341438293
val: 9 0.4518130123615265
val: 10 0.4393521547317505
val: 11 0.44083699584007263
val: 12 0.4308021664619446
val: 13 0.4555681049823761
val: 14 0.43828070163726807
val: 15 0.4406651556491852
val: 16 0.43994057178497314
val: 17 0.43825629353523254
val: 18 0.4428677260875702
val: 19 0.4442268908023834
val: 20 0.4189039170742035
val_Epoch:[ 179 ] val_loss: 0.4427743926644325 2022-07-01 01:21:32.943346
start training 2022-07-01 01:21:33.047801
Epoch:[ 180 0 ] loss: 0.39142465591430664 2022-07-01 01:21:47.651106
Epoch:[ 180 1 ] loss: 0.3895815312862396 2022-07-01 01:21:48.069640
Epoch:[ 180 2 ] loss: 0.3920113742351532 2022-07-01 01:21:48.485413
Epoch:[ 180 3 ] loss: 0.3911553621292114 2022-07-01 01:21:48.906537
Epoch:[ 180 4 ] loss: 0.3878635764122009 2022-07-01 01:21:49.325926
Epoch:[ 180 5 ] loss: 0.3885684907436371 2022-07-01 01:21:49.744655
Epoch:[ 180 6 ] loss: 0.3897828757762909 2022-07-01 01:21:50.163291
Epoch:[ 180 7 ] loss: 0.38975441455841064 2022-07-01 01:21:50.584712
Epoch:[ 180 8 ] loss: 0.3913459777832031 2022-07-01 01:21:50.997732
Epoch:[ 180 9 ] loss: 0.392546147108078 2022-07-01 01:21:51.417712
Epoch:[ 180 10 ] loss: 0.39129838347435 2022-07-01 01:21:51.838992
Epoch:[ 180 11 ] loss: 0.3921263515949249 2022-07-01 01:21:52.262046
Epoch:[ 180 12 ] loss: 0.39102333784103394 2022-07-01 01:21:52.681535
Epoch:[ 180 13 ] loss: 0.3889581561088562 2022-07-01 01:21:53.102356
Epoch:[ 180 14 ] loss: 0.3928534984588623 2022-07-01 01:21:53.522578
Epoch:[ 180 15 ] loss: 0.38970667123794556 2022-07-01 01:21:53.943626
Epoch:[ 180 16 ] loss: 0.39182811975479126 2022-07-01 01:21:59.283992
Epoch:[ 180 17 ] loss: 0.3907511532306671 2022-07-01 01:21:59.703767
Epoch:[ 180 18 ] loss: 0.39171719551086426 2022-07-01 01:22:00.125639
Epoch:[ 180 19 ] loss: 0.3867852985858917 2022-07-01 01:22:00.545565
Training_Epoch:[ 180 ] Training_loss: 0.3905541285872459 2022-07-01 01:22:00.546269
learning rate:  0.0011258999068426252
netparams have been saved once 180
val: 1 0.44750916957855225
val: 2 0.44363123178482056
val: 3 0.4390875995159149
val: 4 0.4446602463722229
val: 5 0.4389204680919647
val: 6 0.44650745391845703
val: 7 0.4381662607192993
val: 8 0.44430825114250183
val: 9 0.45357733964920044
val: 10 0.43679702281951904
val: 11 0.4478541314601898
val: 12 0.44842082262039185
val: 13 0.4338393211364746
val: 14 0.4293704926967621
val: 15 0.45336058735847473
val: 16 0.43428000807762146
val: 17 0.43011805415153503
val: 18 0.43778371810913086
val: 19 0.43771079182624817
val: 20 0.4462231695652008
val_Epoch:[ 180 ] val_loss: 0.44160630702972414 2022-07-01 01:22:04.342259
start training 2022-07-01 01:22:04.446554
Epoch:[ 181 0 ] loss: 0.38997042179107666 2022-07-01 01:22:18.288510
Epoch:[ 181 1 ] loss: 0.3930242955684662 2022-07-01 01:22:18.733068
Epoch:[ 181 2 ] loss: 0.3913382887840271 2022-07-01 01:22:19.156127
Epoch:[ 181 3 ] loss: 0.38922318816185 2022-07-01 01:22:19.577885
Epoch:[ 181 4 ] loss: 0.39160671830177307 2022-07-01 01:22:19.999249
Epoch:[ 181 5 ] loss: 0.39099907875061035 2022-07-01 01:22:20.419358
Epoch:[ 181 6 ] loss: 0.3887488543987274 2022-07-01 01:22:20.840042
Epoch:[ 181 7 ] loss: 0.39033573865890503 2022-07-01 01:22:21.260175
Epoch:[ 181 8 ] loss: 0.3901808559894562 2022-07-01 01:22:21.679562
Epoch:[ 181 9 ] loss: 0.3912919759750366 2022-07-01 01:22:22.098649
Epoch:[ 181 10 ] loss: 0.3892521560192108 2022-07-01 01:22:22.522511
Epoch:[ 181 11 ] loss: 0.38850900530815125 2022-07-01 01:22:22.943513
Epoch:[ 181 12 ] loss: 0.38778549432754517 2022-07-01 01:22:23.363836
Epoch:[ 181 13 ] loss: 0.39218395948410034 2022-07-01 01:22:23.787172
Epoch:[ 181 14 ] loss: 0.3902253210544586 2022-07-01 01:22:24.201782
Epoch:[ 181 15 ] loss: 0.38941386342048645 2022-07-01 01:22:24.621992
Epoch:[ 181 16 ] loss: 0.3912084400653839 2022-07-01 01:22:30.254115
Epoch:[ 181 17 ] loss: 0.39100709557533264 2022-07-01 01:22:30.675369
Epoch:[ 181 18 ] loss: 0.39064714312553406 2022-07-01 01:22:31.097335
Epoch:[ 181 19 ] loss: 0.39191681146621704 2022-07-01 01:22:31.520244
Training_Epoch:[ 181 ] Training_loss: 0.3904434353113174 2022-07-01 01:22:31.520913
learning rate:  0.0009007199254741002
val: 1 0.4339747130870819
val: 2 0.43541231751441956
val: 3 0.4387587904930115
val: 4 0.44474825263023376
val: 5 0.43835359811782837
val: 6 0.4391450583934784
val: 7 0.44773611426353455
val: 8 0.4377606511116028
val: 9 0.4523054361343384
val: 10 0.4341828525066376
val: 11 0.4433838427066803
val: 12 0.45323145389556885
val: 13 0.45779111981391907
val: 14 0.43928804993629456
val: 15 0.4345585107803345
val: 16 0.4380201995372772
val: 17 0.4460245966911316
val: 18 0.4491117000579834
val: 19 0.4346064329147339
val: 20 0.44329431653022766
val_Epoch:[ 181 ] val_loss: 0.44208440035581587 2022-07-01 01:22:35.215770
start training 2022-07-01 01:22:35.318658
Epoch:[ 182 0 ] loss: 0.3903493881225586 2022-07-01 01:22:50.155114
Epoch:[ 182 1 ] loss: 0.38803523778915405 2022-07-01 01:22:50.575794
Epoch:[ 182 2 ] loss: 0.38765382766723633 2022-07-01 01:22:50.997230
Epoch:[ 182 3 ] loss: 0.39003631472587585 2022-07-01 01:22:51.417354
Epoch:[ 182 4 ] loss: 0.39075586199760437 2022-07-01 01:22:51.839099
Epoch:[ 182 5 ] loss: 0.3876414895057678 2022-07-01 01:22:52.261435
Epoch:[ 182 6 ] loss: 0.3913034498691559 2022-07-01 01:22:52.675960
Epoch:[ 182 7 ] loss: 0.3889962434768677 2022-07-01 01:22:53.098594
Epoch:[ 182 8 ] loss: 0.3880353569984436 2022-07-01 01:22:53.519658
Epoch:[ 182 9 ] loss: 0.3904964029788971 2022-07-01 01:22:53.939817
Epoch:[ 182 10 ] loss: 0.3896607458591461 2022-07-01 01:22:54.360059
Epoch:[ 182 11 ] loss: 0.3913479149341583 2022-07-01 01:22:54.781723
Epoch:[ 182 12 ] loss: 0.39039212465286255 2022-07-01 01:22:55.204470
Epoch:[ 182 13 ] loss: 0.39085108041763306 2022-07-01 01:22:55.625298
Epoch:[ 182 14 ] loss: 0.3886829614639282 2022-07-01 01:22:56.045610
Epoch:[ 182 15 ] loss: 0.39157378673553467 2022-07-01 01:22:56.466245
Epoch:[ 182 16 ] loss: 0.38866615295410156 2022-07-01 01:23:01.739877
Epoch:[ 182 17 ] loss: 0.39262935519218445 2022-07-01 01:23:02.158238
Epoch:[ 182 18 ] loss: 0.38973286747932434 2022-07-01 01:23:02.580522
Epoch:[ 182 19 ] loss: 0.3905239999294281 2022-07-01 01:23:03.002803
Training_Epoch:[ 182 ] Training_loss: 0.3898682281374931 2022-07-01 01:23:03.003440
learning rate:  0.0009007199254741002
netparams have been saved once 182
val: 1 0.42561495304107666
val: 2 0.442579448223114
val: 3 0.44672539830207825
val: 4 0.4517363905906677
val: 5 0.4378713071346283
val: 6 0.44178640842437744
val: 7 0.43263694643974304
val: 8 0.4403822422027588
val: 9 0.42835524678230286
val: 10 0.45581698417663574
val: 11 0.4345177412033081
val: 12 0.4359966516494751
val: 13 0.42896464467048645
val: 14 0.4377260208129883
val: 15 0.4592120945453644
val: 16 0.4575766324996948
val: 17 0.4551457464694977
val: 18 0.44721734523773193
val: 19 0.44828546047210693
val: 20 0.4575452506542206
val_Epoch:[ 182 ] val_loss: 0.44328464567661285 2022-07-01 01:23:06.761710
start training 2022-07-01 01:23:06.867053
Epoch:[ 183 0 ] loss: 0.3902321457862854 2022-07-01 01:23:21.513425
Epoch:[ 183 1 ] loss: 0.3891724944114685 2022-07-01 01:23:21.928417
Epoch:[ 183 2 ] loss: 0.3885253965854645 2022-07-01 01:23:22.349225
Epoch:[ 183 3 ] loss: 0.3889886140823364 2022-07-01 01:23:22.768477
Epoch:[ 183 4 ] loss: 0.38702288269996643 2022-07-01 01:23:23.188548
Epoch:[ 183 5 ] loss: 0.3889104425907135 2022-07-01 01:23:23.609661
Epoch:[ 183 6 ] loss: 0.38982775807380676 2022-07-01 01:23:24.031774
Epoch:[ 183 7 ] loss: 0.38978806138038635 2022-07-01 01:23:24.452659
Epoch:[ 183 8 ] loss: 0.38989412784576416 2022-07-01 01:23:24.873253
Epoch:[ 183 9 ] loss: 0.3881077468395233 2022-07-01 01:23:25.292539
Epoch:[ 183 10 ] loss: 0.3903179168701172 2022-07-01 01:23:25.712546
Epoch:[ 183 11 ] loss: 0.38877159357070923 2022-07-01 01:23:26.132242
Epoch:[ 183 12 ] loss: 0.38899803161621094 2022-07-01 01:23:26.553343
Epoch:[ 183 13 ] loss: 0.39015141129493713 2022-07-01 01:23:26.969794
Epoch:[ 183 14 ] loss: 0.38891544938087463 2022-07-01 01:23:27.390752
Epoch:[ 183 15 ] loss: 0.388552725315094 2022-07-01 01:23:27.810252
Epoch:[ 183 16 ] loss: 0.3917144536972046 2022-07-01 01:23:33.343475
Epoch:[ 183 17 ] loss: 0.3922080993652344 2022-07-01 01:23:33.939375
Epoch:[ 183 18 ] loss: 0.39044126868247986 2022-07-01 01:23:34.359049
Epoch:[ 183 19 ] loss: 0.3890440762042999 2022-07-01 01:23:34.780020
Training_Epoch:[ 183 ] Training_loss: 0.38947923481464386 2022-07-01 01:23:34.780702
learning rate:  0.0009007199254741002
val: 1 0.4386714994907379
val: 2 0.44135400652885437
val: 3 0.43405696749687195
val: 4 0.4458530843257904
val: 5 0.4374183714389801
val: 6 0.4462396502494812
val: 7 0.4468025267124176
val: 8 0.4356917440891266
val: 9 0.4464581608772278
val: 10 0.4511062800884247
val: 11 0.43492791056632996
val: 12 0.4555089771747589
val: 13 0.45141443610191345
val: 14 0.44709622859954834
val: 15 0.4351138174533844
val: 16 0.432462215423584
val: 17 0.4344191551208496
val: 18 0.4436821937561035
val: 19 0.45081937313079834
val: 20 0.44099634885787964
val_Epoch:[ 183 ] val_loss: 0.4425046473741531 2022-07-01 01:23:38.520968
start training 2022-07-01 01:23:38.628144
Epoch:[ 184 0 ] loss: 0.38704216480255127 2022-07-01 01:23:53.567748
Epoch:[ 184 1 ] loss: 0.3885791301727295 2022-07-01 01:23:53.981778
Epoch:[ 184 2 ] loss: 0.3891655504703522 2022-07-01 01:23:54.402456
Epoch:[ 184 3 ] loss: 0.3885788023471832 2022-07-01 01:23:54.822042
Epoch:[ 184 4 ] loss: 0.3888755440711975 2022-07-01 01:23:55.245534
Epoch:[ 184 5 ] loss: 0.38932257890701294 2022-07-01 01:23:55.665895
Epoch:[ 184 6 ] loss: 0.38912174105644226 2022-07-01 01:23:56.087096
Epoch:[ 184 7 ] loss: 0.3907450735569 2022-07-01 01:23:56.509076
Epoch:[ 184 8 ] loss: 0.38949117064476013 2022-07-01 01:23:56.929113
Epoch:[ 184 9 ] loss: 0.38906723260879517 2022-07-01 01:23:57.349267
Epoch:[ 184 10 ] loss: 0.39198511838912964 2022-07-01 01:23:57.766076
Epoch:[ 184 11 ] loss: 0.3883119821548462 2022-07-01 01:23:58.186627
Epoch:[ 184 12 ] loss: 0.390497088432312 2022-07-01 01:23:58.607106
Epoch:[ 184 13 ] loss: 0.3897051513195038 2022-07-01 01:23:59.028326
Epoch:[ 184 14 ] loss: 0.38821274042129517 2022-07-01 01:23:59.451460
Epoch:[ 184 15 ] loss: 0.3897821009159088 2022-07-01 01:23:59.873691
Epoch:[ 184 16 ] loss: 0.3892652690410614 2022-07-01 01:24:05.070693
Epoch:[ 184 17 ] loss: 0.39021745324134827 2022-07-01 01:24:05.490750
Epoch:[ 184 18 ] loss: 0.3903561532497406 2022-07-01 01:24:05.911606
Epoch:[ 184 19 ] loss: 0.3925763964653015 2022-07-01 01:24:06.330772
Training_Epoch:[ 184 ] Training_loss: 0.38954492211341857 2022-07-01 01:24:06.331399
learning rate:  0.0009007199254741002
netparams have been saved once 184
val: 1 0.4449344575405121
val: 2 0.44602906703948975
val: 3 0.44216474890708923
val: 4 0.4369489848613739
val: 5 0.44544845819473267
val: 6 0.4399235248565674
val: 7 0.4356840252876282
val: 8 0.44255587458610535
val: 9 0.441195011138916
val: 10 0.4367125630378723
val: 11 0.422677606344223
val: 12 0.4283827245235443
val: 13 0.45791250467300415
val: 14 0.43641364574432373
val: 15 0.45005279779434204
val: 16 0.44063982367515564
val: 17 0.4563941955566406
val: 18 0.4414985179901123
val: 19 0.43721991777420044
val: 20 0.4417552649974823
val_Epoch:[ 184 ] val_loss: 0.44122718572616576 2022-07-01 01:24:10.096046
start training 2022-07-01 01:24:10.202889
Epoch:[ 185 0 ] loss: 0.3907233476638794 2022-07-01 01:24:24.752550
Epoch:[ 185 1 ] loss: 0.3891412615776062 2022-07-01 01:24:25.174335
Epoch:[ 185 2 ] loss: 0.388410359621048 2022-07-01 01:24:25.595306
Epoch:[ 185 3 ] loss: 0.3880416750907898 2022-07-01 01:24:26.009679
Epoch:[ 185 4 ] loss: 0.39128661155700684 2022-07-01 01:24:26.428545
Epoch:[ 185 5 ] loss: 0.3890458643436432 2022-07-01 01:24:26.850662
Epoch:[ 185 6 ] loss: 0.39059126377105713 2022-07-01 01:24:27.270122
Epoch:[ 185 7 ] loss: 0.3875718116760254 2022-07-01 01:24:27.691996
Epoch:[ 185 8 ] loss: 0.3882027566432953 2022-07-01 01:24:28.115559
Epoch:[ 185 9 ] loss: 0.3907991647720337 2022-07-01 01:24:28.535791
Epoch:[ 185 10 ] loss: 0.3903518319129944 2022-07-01 01:24:28.956065
Epoch:[ 185 11 ] loss: 0.39194461703300476 2022-07-01 01:24:29.376672
Epoch:[ 185 12 ] loss: 0.3887525498867035 2022-07-01 01:24:29.796914
Epoch:[ 185 13 ] loss: 0.3889950215816498 2022-07-01 01:24:30.216052
Epoch:[ 185 14 ] loss: 0.3877147436141968 2022-07-01 01:24:30.638495
Epoch:[ 185 15 ] loss: 0.39166733622550964 2022-07-01 01:24:31.054672
Epoch:[ 185 16 ] loss: 0.3898313343524933 2022-07-01 01:24:36.262001
Epoch:[ 185 17 ] loss: 0.3899663984775543 2022-07-01 01:24:36.681017
Epoch:[ 185 18 ] loss: 0.3883810341358185 2022-07-01 01:24:37.101914
Epoch:[ 185 19 ] loss: 0.38880854845046997 2022-07-01 01:24:37.527164
Training_Epoch:[ 185 ] Training_loss: 0.389511376619339 2022-07-01 01:24:37.527805
learning rate:  0.0009007199254741002
val: 1 0.45590537786483765
val: 2 0.43551120162010193
val: 3 0.43717220425605774
val: 4 0.45114970207214355
val: 5 0.4546038508415222
val: 6 0.43895214796066284
val: 7 0.4297345280647278
val: 8 0.4527651071548462
val: 9 0.43663057684898376
val: 10 0.44560542702674866
val: 11 0.43386387825012207
val: 12 0.43519461154937744
val: 13 0.43847063183784485
val: 14 0.4409519135951996
val: 15 0.44626978039741516
val: 16 0.4392203390598297
val: 17 0.45654410123825073
val: 18 0.4365277886390686
val: 19 0.4377850890159607
val: 20 0.4425896406173706
val_Epoch:[ 185 ] val_loss: 0.4422723948955536 2022-07-01 01:24:41.305765
start training 2022-07-01 01:24:41.411903
Epoch:[ 186 0 ] loss: 0.3904951214790344 2022-07-01 01:24:55.470489
Epoch:[ 186 1 ] loss: 0.38989439606666565 2022-07-01 01:24:55.927617
Epoch:[ 186 2 ] loss: 0.38851311802864075 2022-07-01 01:24:56.374203
Epoch:[ 186 3 ] loss: 0.3887782692909241 2022-07-01 01:24:56.794256
Epoch:[ 186 4 ] loss: 0.38860785961151123 2022-07-01 01:24:57.215074
Epoch:[ 186 5 ] loss: 0.39183494448661804 2022-07-01 01:24:57.639555
Epoch:[ 186 6 ] loss: 0.3904263973236084 2022-07-01 01:24:58.060654
Epoch:[ 186 7 ] loss: 0.38719338178634644 2022-07-01 01:24:58.480780
Epoch:[ 186 8 ] loss: 0.3905126452445984 2022-07-01 01:24:58.903502
Epoch:[ 186 9 ] loss: 0.38975098729133606 2022-07-01 01:24:59.323708
Epoch:[ 186 10 ] loss: 0.38914692401885986 2022-07-01 01:24:59.744832
Epoch:[ 186 11 ] loss: 0.3867933452129364 2022-07-01 01:25:00.167849
Epoch:[ 186 12 ] loss: 0.3876369297504425 2022-07-01 01:25:00.589670
Epoch:[ 186 13 ] loss: 0.39167332649230957 2022-07-01 01:25:01.010339
Epoch:[ 186 14 ] loss: 0.38873252272605896 2022-07-01 01:25:01.430428
Epoch:[ 186 15 ] loss: 0.38969770073890686 2022-07-01 01:25:01.852570
Epoch:[ 186 16 ] loss: 0.3911832273006439 2022-07-01 01:25:07.390509
Epoch:[ 186 17 ] loss: 0.38894471526145935 2022-07-01 01:25:07.812978
Epoch:[ 186 18 ] loss: 0.3916497826576233 2022-07-01 01:25:08.233830
Epoch:[ 186 19 ] loss: 0.38799652457237244 2022-07-01 01:25:08.653577
Training_Epoch:[ 186 ] Training_loss: 0.3894731059670448 2022-07-01 01:25:08.654211
learning rate:  0.0009007199254741002
netparams have been saved once 186
val: 1 0.42867663502693176
val: 2 0.46249088644981384
val: 3 0.44361671805381775
val: 4 0.43510064482688904
val: 5 0.447500616312027
val: 6 0.44352585077285767
val: 7 0.4427398443222046
val: 8 0.4268006384372711
val: 9 0.4502500593662262
val: 10 0.4542804956436157
val: 11 0.454241007566452
val: 12 0.442818820476532
val: 13 0.43960630893707275
val: 14 0.43769752979278564
val: 15 0.44026967883110046
val: 16 0.4384031295776367
val: 17 0.4383713901042938
val: 18 0.45481204986572266
val: 19 0.43691131472587585
val: 20 0.43341895937919617
val_Epoch:[ 186 ] val_loss: 0.44257662892341615 2022-07-01 01:25:12.448872
start training 2022-07-01 01:25:12.552636
Epoch:[ 187 0 ] loss: 0.38813167810440063 2022-07-01 01:25:27.365932
Epoch:[ 187 1 ] loss: 0.38820627331733704 2022-07-01 01:25:27.785104
Epoch:[ 187 2 ] loss: 0.38891348242759705 2022-07-01 01:25:28.207519
Epoch:[ 187 3 ] loss: 0.38787174224853516 2022-07-01 01:25:28.629409
Epoch:[ 187 4 ] loss: 0.38823556900024414 2022-07-01 01:25:29.050513
Epoch:[ 187 5 ] loss: 0.3908778727054596 2022-07-01 01:25:29.471015
Epoch:[ 187 6 ] loss: 0.39041516184806824 2022-07-01 01:25:29.892635
Epoch:[ 187 7 ] loss: 0.3890828490257263 2022-07-01 01:25:30.312857
Epoch:[ 187 8 ] loss: 0.39063820242881775 2022-07-01 01:25:30.732437
Epoch:[ 187 9 ] loss: 0.38982251286506653 2022-07-01 01:25:31.147272
Epoch:[ 187 10 ] loss: 0.38968437910079956 2022-07-01 01:25:31.570198
Epoch:[ 187 11 ] loss: 0.38846659660339355 2022-07-01 01:25:31.993316
Epoch:[ 187 12 ] loss: 0.3886793255805969 2022-07-01 01:25:32.413635
Epoch:[ 187 13 ] loss: 0.3889925181865692 2022-07-01 01:25:32.834409
Epoch:[ 187 14 ] loss: 0.39132359623908997 2022-07-01 01:25:33.254826
Epoch:[ 187 15 ] loss: 0.3915945589542389 2022-07-01 01:25:33.673856
Epoch:[ 187 16 ] loss: 0.38955390453338623 2022-07-01 01:25:38.889409
Epoch:[ 187 17 ] loss: 0.39126914739608765 2022-07-01 01:25:39.316951
Epoch:[ 187 18 ] loss: 0.3885476589202881 2022-07-01 01:25:39.740837
Epoch:[ 187 19 ] loss: 0.39015766978263855 2022-07-01 01:25:40.161014
Training_Epoch:[ 187 ] Training_loss: 0.38952323496341706 2022-07-01 01:25:40.161765
learning rate:  0.0009007199254741002
val: 1 0.4415356516838074
val: 2 0.4262956976890564
val: 3 0.4439374804496765
val: 4 0.4360724985599518
val: 5 0.4396761655807495
val: 6 0.43198591470718384
val: 7 0.44026538729667664
val: 8 0.43828198313713074
val: 9 0.45318177342414856
val: 10 0.44146034121513367
val: 11 0.4455612897872925
val: 12 0.4492398798465729
val: 13 0.44218841195106506
val: 14 0.4374370872974396
val: 15 0.4428119957447052
val: 16 0.4296168386936188
val: 17 0.4379088580608368
val: 18 0.45211315155029297
val: 19 0.4495295584201813
val: 20 0.4464811086654663
val_Epoch:[ 187 ] val_loss: 0.4412790536880493 2022-07-01 01:25:43.987119
start training 2022-07-01 01:25:44.090539
Epoch:[ 188 0 ] loss: 0.3895033597946167 2022-07-01 01:25:58.433417
Epoch:[ 188 1 ] loss: 0.38852328062057495 2022-07-01 01:25:58.874416
Epoch:[ 188 2 ] loss: 0.38858991861343384 2022-07-01 01:25:59.296327
Epoch:[ 188 3 ] loss: 0.38963913917541504 2022-07-01 01:25:59.717864
Epoch:[ 188 4 ] loss: 0.3910812735557556 2022-07-01 01:26:00.139815
Epoch:[ 188 5 ] loss: 0.39094290137290955 2022-07-01 01:26:00.562047
Epoch:[ 188 6 ] loss: 0.3905859589576721 2022-07-01 01:26:00.981673
Epoch:[ 188 7 ] loss: 0.3908521831035614 2022-07-01 01:26:01.401088
Epoch:[ 188 8 ] loss: 0.39115312695503235 2022-07-01 01:26:01.817658
Epoch:[ 188 9 ] loss: 0.38941821455955505 2022-07-01 01:26:02.236501
Epoch:[ 188 10 ] loss: 0.38969871401786804 2022-07-01 01:26:02.658973
Epoch:[ 188 11 ] loss: 0.3873152434825897 2022-07-01 01:26:03.079965
Epoch:[ 188 12 ] loss: 0.38908711075782776 2022-07-01 01:26:03.502032
Epoch:[ 188 13 ] loss: 0.3905220031738281 2022-07-01 01:26:03.922883
Epoch:[ 188 14 ] loss: 0.39089304208755493 2022-07-01 01:26:04.345075
Epoch:[ 188 15 ] loss: 0.38766053318977356 2022-07-01 01:26:04.765750
Epoch:[ 188 16 ] loss: 0.3891713619232178 2022-07-01 01:26:10.135511
Epoch:[ 188 17 ] loss: 0.389591246843338 2022-07-01 01:26:10.556227
Epoch:[ 188 18 ] loss: 0.3895720839500427 2022-07-01 01:26:10.978299
Epoch:[ 188 19 ] loss: 0.38760384917259216 2022-07-01 01:26:11.398149
Training_Epoch:[ 188 ] Training_loss: 0.38957022726535795 2022-07-01 01:26:11.398891
learning rate:  0.0009007199254741002
netparams have been saved once 188
val: 1 0.4464687705039978
val: 2 0.45009753108024597
val: 3 0.4296310544013977
val: 4 0.4404013752937317
val: 5 0.4440379738807678
val: 6 0.44652172923088074
val: 7 0.4628784954547882
val: 8 0.44609975814819336
val: 9 0.43125447630882263
val: 10 0.4480888545513153
val: 11 0.44565409421920776
val: 12 0.440768837928772
val: 13 0.4439796805381775
val: 14 0.4437027871608734
val: 15 0.43784570693969727
val: 16 0.4387933611869812
val: 17 0.4427757263183594
val: 18 0.42969751358032227
val: 19 0.4413597583770752
val: 20 0.43599143624305725
val_Epoch:[ 188 ] val_loss: 0.4423024460673332 2022-07-01 01:26:15.215787
start training 2022-07-01 01:26:15.317602
Epoch:[ 189 0 ] loss: 0.38780322670936584 2022-07-01 01:26:30.152917
Epoch:[ 189 1 ] loss: 0.38942134380340576 2022-07-01 01:26:30.572047
Epoch:[ 189 2 ] loss: 0.3900674879550934 2022-07-01 01:26:30.993435
Epoch:[ 189 3 ] loss: 0.38891568779945374 2022-07-01 01:26:31.416599
Epoch:[ 189 4 ] loss: 0.388347864151001 2022-07-01 01:26:31.840022
Epoch:[ 189 5 ] loss: 0.38946735858917236 2022-07-01 01:26:32.261845
Epoch:[ 189 6 ] loss: 0.3885703682899475 2022-07-01 01:26:32.684634
Epoch:[ 189 7 ] loss: 0.38969770073890686 2022-07-01 01:26:33.106933
Epoch:[ 189 8 ] loss: 0.3884011507034302 2022-07-01 01:26:33.531308
Epoch:[ 189 9 ] loss: 0.3883499801158905 2022-07-01 01:26:33.954919
Epoch:[ 189 10 ] loss: 0.3907874524593353 2022-07-01 01:26:34.377777
Epoch:[ 189 11 ] loss: 0.39057716727256775 2022-07-01 01:26:34.799378
Epoch:[ 189 12 ] loss: 0.38986027240753174 2022-07-01 01:26:35.220771
Epoch:[ 189 13 ] loss: 0.3882092833518982 2022-07-01 01:26:35.636211
Epoch:[ 189 14 ] loss: 0.39100223779678345 2022-07-01 01:26:36.058752
Epoch:[ 189 15 ] loss: 0.38855135440826416 2022-07-01 01:26:36.478695
Epoch:[ 189 16 ] loss: 0.3897663950920105 2022-07-01 01:26:41.867900
Epoch:[ 189 17 ] loss: 0.38968053460121155 2022-07-01 01:26:42.299621
Epoch:[ 189 18 ] loss: 0.3917144536972046 2022-07-01 01:26:42.722752
Epoch:[ 189 19 ] loss: 0.38971084356307983 2022-07-01 01:26:43.143681
Training_Epoch:[ 189 ] Training_loss: 0.3894451081752777 2022-07-01 01:26:43.144372
learning rate:  0.0009007199254741002
val: 1 0.4498218595981598
val: 2 0.4384946823120117
val: 3 0.4390496611595154
val: 4 0.4432492256164551
val: 5 0.43877753615379333
val: 6 0.43546485900878906
val: 7 0.4453126788139343
val: 8 0.44087085127830505
val: 9 0.4447346329689026
val: 10 0.42951536178588867
val: 11 0.45212239027023315
val: 12 0.4419466257095337
val: 13 0.4312744140625
val: 14 0.45059993863105774
val: 15 0.4417935609817505
val: 16 0.44229599833488464
val: 17 0.44006019830703735
val: 18 0.4428872764110565
val: 19 0.4481828510761261
val: 20 0.4291558861732483
val_Epoch:[ 189 ] val_loss: 0.44128052443265914 2022-07-01 01:26:46.889206
start training 2022-07-01 01:26:46.993934
Epoch:[ 190 0 ] loss: 0.38867443799972534 2022-07-01 01:27:01.832519
Epoch:[ 190 1 ] loss: 0.3901340961456299 2022-07-01 01:27:02.251834
Epoch:[ 190 2 ] loss: 0.3895464241504669 2022-07-01 01:27:02.675204
Epoch:[ 190 3 ] loss: 0.3871735632419586 2022-07-01 01:27:03.098339
Epoch:[ 190 4 ] loss: 0.38886314630508423 2022-07-01 01:27:03.514466
Epoch:[ 190 5 ] loss: 0.3889507055282593 2022-07-01 01:27:03.937718
Epoch:[ 190 6 ] loss: 0.38866323232650757 2022-07-01 01:27:04.359768
Epoch:[ 190 7 ] loss: 0.39012032747268677 2022-07-01 01:27:04.783119
Epoch:[ 190 8 ] loss: 0.39178743958473206 2022-07-01 01:27:05.206304
Epoch:[ 190 9 ] loss: 0.3883054256439209 2022-07-01 01:27:05.630366
Epoch:[ 190 10 ] loss: 0.386703759431839 2022-07-01 01:27:06.050319
Epoch:[ 190 11 ] loss: 0.3903025686740875 2022-07-01 01:27:06.469555
Epoch:[ 190 12 ] loss: 0.3900824785232544 2022-07-01 01:27:06.895928
Epoch:[ 190 13 ] loss: 0.38907235860824585 2022-07-01 01:27:07.321400
Epoch:[ 190 14 ] loss: 0.3909966051578522 2022-07-01 01:27:07.737371
Epoch:[ 190 15 ] loss: 0.38815969228744507 2022-07-01 01:27:08.157724
Epoch:[ 190 16 ] loss: 0.3894291818141937 2022-07-01 01:27:13.403969
Epoch:[ 190 17 ] loss: 0.3917916417121887 2022-07-01 01:27:13.826062
Epoch:[ 190 18 ] loss: 0.38857340812683105 2022-07-01 01:27:14.248759
Epoch:[ 190 19 ] loss: 0.388304203748703 2022-07-01 01:27:14.672135
Training_Epoch:[ 190 ] Training_loss: 0.3892817348241806 2022-07-01 01:27:14.672797
learning rate:  0.0009007199254741002
netparams have been saved once 190
val: 1 0.43737971782684326
val: 2 0.4377659857273102
val: 3 0.44474315643310547
val: 4 0.42070770263671875
val: 5 0.4377717971801758
val: 6 0.4409380853176117
val: 7 0.4468235969543457
val: 8 0.4435938894748688
val: 9 0.43191060423851013
val: 10 0.44212764501571655
val: 11 0.446729451417923
val: 12 0.4441363513469696
val: 13 0.45588672161102295
val: 14 0.43631216883659363
val: 15 0.4517385959625244
val: 16 0.4428233206272125
val: 17 0.4504897892475128
val: 18 0.4494881331920624
val: 19 0.4509398937225342
val: 20 0.4379071891307831
val_Epoch:[ 190 ] val_loss: 0.44251068979501723 2022-07-01 01:27:18.499864
start training 2022-07-01 01:27:18.606124
Epoch:[ 191 0 ] loss: 0.38851746916770935 2022-07-01 01:27:33.268800
Epoch:[ 191 1 ] loss: 0.3896576464176178 2022-07-01 01:27:33.701055
Epoch:[ 191 2 ] loss: 0.38625314831733704 2022-07-01 01:27:34.123110
Epoch:[ 191 3 ] loss: 0.38755080103874207 2022-07-01 01:27:34.543675
Epoch:[ 191 4 ] loss: 0.3896178901195526 2022-07-01 01:27:34.964901
Epoch:[ 191 5 ] loss: 0.3914656639099121 2022-07-01 01:27:35.385397
Epoch:[ 191 6 ] loss: 0.3878055810928345 2022-07-01 01:27:35.810524
Epoch:[ 191 7 ] loss: 0.38868051767349243 2022-07-01 01:27:36.233673
Epoch:[ 191 8 ] loss: 0.39033687114715576 2022-07-01 01:27:36.656254
Epoch:[ 191 9 ] loss: 0.38912639021873474 2022-07-01 01:27:37.079394
Epoch:[ 191 10 ] loss: 0.38893765211105347 2022-07-01 01:27:37.501004
Epoch:[ 191 11 ] loss: 0.3903881907463074 2022-07-01 01:27:37.916067
Epoch:[ 191 12 ] loss: 0.389007031917572 2022-07-01 01:27:38.340576
Epoch:[ 191 13 ] loss: 0.3901117146015167 2022-07-01 01:27:38.763209
Epoch:[ 191 14 ] loss: 0.3878437280654907 2022-07-01 01:27:39.186080
Epoch:[ 191 15 ] loss: 0.38862454891204834 2022-07-01 01:27:39.607153
Epoch:[ 191 16 ] loss: 0.3898259997367859 2022-07-01 01:27:45.323789
Epoch:[ 191 17 ] loss: 0.38910436630249023 2022-07-01 01:27:45.744811
Epoch:[ 191 18 ] loss: 0.3888932168483734 2022-07-01 01:27:46.174547
Epoch:[ 191 19 ] loss: 0.3867988884449005 2022-07-01 01:27:46.593900
Training_Epoch:[ 191 ] Training_loss: 0.38892736583948134 2022-07-01 01:27:46.594656
learning rate:  0.0007205759403792802
val: 1 0.43970027565956116
val: 2 0.44745567440986633
val: 3 0.4388565123081207
val: 4 0.43460848927497864
val: 5 0.4442162811756134
val: 6 0.4416612684726715
val: 7 0.4500693678855896
val: 8 0.4549511969089508
val: 9 0.4378766417503357
val: 10 0.4478825330734253
val: 11 0.44245538115501404
val: 12 0.45110148191452026
val: 13 0.43678978085517883
val: 14 0.44810786843299866
val: 15 0.435590922832489
val: 16 0.43392813205718994
val: 17 0.4417654573917389
val: 18 0.43518969416618347
val: 19 0.44779354333877563
val: 20 0.44839510321617126
val_Epoch:[ 191 ] val_loss: 0.44291978031396867 2022-07-01 01:27:50.331616
start training 2022-07-01 01:27:50.436958
Epoch:[ 192 0 ] loss: 0.38868826627731323 2022-07-01 01:28:04.591384
Epoch:[ 192 1 ] loss: 0.3906184136867523 2022-07-01 01:28:05.181646
Epoch:[ 192 2 ] loss: 0.3862319886684418 2022-07-01 01:28:05.603122
Epoch:[ 192 3 ] loss: 0.38859298825263977 2022-07-01 01:28:06.023626
Epoch:[ 192 4 ] loss: 0.3905055522918701 2022-07-01 01:28:06.447075
Epoch:[ 192 5 ] loss: 0.38552722334861755 2022-07-01 01:28:06.866949
Epoch:[ 192 6 ] loss: 0.3869949281215668 2022-07-01 01:28:07.287443
Epoch:[ 192 7 ] loss: 0.39122632145881653 2022-07-01 01:28:07.709513
Epoch:[ 192 8 ] loss: 0.3892233073711395 2022-07-01 01:28:08.131305
Epoch:[ 192 9 ] loss: 0.3877752721309662 2022-07-01 01:28:08.545499
Epoch:[ 192 10 ] loss: 0.3886762857437134 2022-07-01 01:28:08.968595
Epoch:[ 192 11 ] loss: 0.3879013955593109 2022-07-01 01:28:09.388554
Epoch:[ 192 12 ] loss: 0.3892829120159149 2022-07-01 01:28:09.811469
Epoch:[ 192 13 ] loss: 0.3902992904186249 2022-07-01 01:28:10.230615
Epoch:[ 192 14 ] loss: 0.3915991485118866 2022-07-01 01:28:10.652232
Epoch:[ 192 15 ] loss: 0.3872981667518616 2022-07-01 01:28:11.075359
Epoch:[ 192 16 ] loss: 0.38920894265174866 2022-07-01 01:28:16.621838
Epoch:[ 192 17 ] loss: 0.3903196156024933 2022-07-01 01:28:17.040882
Epoch:[ 192 18 ] loss: 0.38743364810943604 2022-07-01 01:28:17.461654
Epoch:[ 192 19 ] loss: 0.38848647475242615 2022-07-01 01:28:17.881199
Training_Epoch:[ 192 ] Training_loss: 0.388794507086277 2022-07-01 01:28:17.881881
learning rate:  0.0007205759403792802
netparams have been saved once 192
val: 1 0.44879239797592163
val: 2 0.43672770261764526
val: 3 0.4373931288719177
val: 4 0.45290660858154297
val: 5 0.4421948492527008
val: 6 0.43409472703933716
val: 7 0.44434550404548645
val: 8 0.4343215823173523
val: 9 0.4397149085998535
val: 10 0.44153112173080444
val: 11 0.45622938871383667
val: 12 0.44770190119743347
val: 13 0.45495519042015076
val: 14 0.4432585835456848
val: 15 0.4428614377975464
val: 16 0.446968138217926
val: 17 0.4408669173717499
val: 18 0.44533559679985046
val: 19 0.43860623240470886
val: 20 0.43983185291290283
val_Epoch:[ 192 ] val_loss: 0.44343188852071763 2022-07-01 01:28:21.677114
start training 2022-07-01 01:28:21.783560
Epoch:[ 193 0 ] loss: 0.3899387717247009 2022-07-01 01:28:36.039247
Epoch:[ 193 1 ] loss: 0.3880581855773926 2022-07-01 01:28:36.476218
Epoch:[ 193 2 ] loss: 0.3886745870113373 2022-07-01 01:28:36.898982
Epoch:[ 193 3 ] loss: 0.3885137438774109 2022-07-01 01:28:37.319070
Epoch:[ 193 4 ] loss: 0.38928577303886414 2022-07-01 01:28:37.741896
Epoch:[ 193 5 ] loss: 0.3862176239490509 2022-07-01 01:28:38.163551
Epoch:[ 193 6 ] loss: 0.38662460446357727 2022-07-01 01:28:38.585415
Epoch:[ 193 7 ] loss: 0.3876259922981262 2022-07-01 01:28:38.999262
Epoch:[ 193 8 ] loss: 0.391401082277298 2022-07-01 01:28:39.421943
Epoch:[ 193 9 ] loss: 0.38715988397598267 2022-07-01 01:28:39.844602
Epoch:[ 193 10 ] loss: 0.39006564021110535 2022-07-01 01:28:40.264936
Epoch:[ 193 11 ] loss: 0.3892740309238434 2022-07-01 01:28:40.685188
Epoch:[ 193 12 ] loss: 0.38861602544784546 2022-07-01 01:28:41.105782
Epoch:[ 193 13 ] loss: 0.3899858593940735 2022-07-01 01:28:41.528937
Epoch:[ 193 14 ] loss: 0.38931772112846375 2022-07-01 01:28:41.948306
Epoch:[ 193 15 ] loss: 0.38847747445106506 2022-07-01 01:28:42.369552
Epoch:[ 193 16 ] loss: 0.3882884681224823 2022-07-01 01:28:48.028885
Epoch:[ 193 17 ] loss: 0.3868155777454376 2022-07-01 01:28:48.450898
Epoch:[ 193 18 ] loss: 0.38816314935684204 2022-07-01 01:28:48.877527
Epoch:[ 193 19 ] loss: 0.3897695541381836 2022-07-01 01:28:49.298416
Training_Epoch:[ 193 ] Training_loss: 0.38861368745565417 2022-07-01 01:28:49.299064
learning rate:  0.0007205759403792802
val: 1 0.44233062863349915
val: 2 0.4397852420806885
val: 3 0.44206011295318604
val: 4 0.45329779386520386
val: 5 0.44839611649513245
val: 6 0.4344187378883362
val: 7 0.4435946047306061
val: 8 0.435096800327301
val: 9 0.4348788857460022
val: 10 0.44816774129867554
val: 11 0.4374629557132721
val: 12 0.443038672208786
val: 13 0.4477478861808777
val: 14 0.44142553210258484
val: 15 0.43496158719062805
val: 16 0.4510703384876251
val: 17 0.45000120997428894
val: 18 0.44732728600502014
val: 19 0.43464258313179016
val: 20 0.44907334446907043
val_Epoch:[ 193 ] val_loss: 0.44293890297412875 2022-07-01 01:28:53.055760
start training 2022-07-01 01:28:53.162010
Epoch:[ 194 0 ] loss: 0.3877376616001129 2022-07-01 01:29:07.003296
Epoch:[ 194 1 ] loss: 0.3899843692779541 2022-07-01 01:29:07.435393
Epoch:[ 194 2 ] loss: 0.38867974281311035 2022-07-01 01:29:07.944763
Epoch:[ 194 3 ] loss: 0.38703978061676025 2022-07-01 01:29:08.366034
Epoch:[ 194 4 ] loss: 0.38744667172431946 2022-07-01 01:29:08.789995
Epoch:[ 194 5 ] loss: 0.389521062374115 2022-07-01 01:29:09.208550
Epoch:[ 194 6 ] loss: 0.38718077540397644 2022-07-01 01:29:09.628831
Epoch:[ 194 7 ] loss: 0.38848206400871277 2022-07-01 01:29:10.053095
Epoch:[ 194 8 ] loss: 0.3896791934967041 2022-07-01 01:29:10.472396
Epoch:[ 194 9 ] loss: 0.3882347345352173 2022-07-01 01:29:10.893750
Epoch:[ 194 10 ] loss: 0.3875506818294525 2022-07-01 01:29:11.316129
Epoch:[ 194 11 ] loss: 0.38619598746299744 2022-07-01 01:29:11.737706
Epoch:[ 194 12 ] loss: 0.38959628343582153 2022-07-01 01:29:12.158241
Epoch:[ 194 13 ] loss: 0.3901091516017914 2022-07-01 01:29:12.579386
Epoch:[ 194 14 ] loss: 0.3899688720703125 2022-07-01 01:29:13.001448
Epoch:[ 194 15 ] loss: 0.39013153314590454 2022-07-01 01:29:13.420976
Epoch:[ 194 16 ] loss: 0.3880811333656311 2022-07-01 01:29:19.004234
Epoch:[ 194 17 ] loss: 0.3885817527770996 2022-07-01 01:29:19.424168
Epoch:[ 194 18 ] loss: 0.38931623101234436 2022-07-01 01:29:19.847667
Epoch:[ 194 19 ] loss: 0.3909781575202942 2022-07-01 01:29:20.269179
Training_Epoch:[ 194 ] Training_loss: 0.3887247920036316 2022-07-01 01:29:20.269855
learning rate:  0.0007205759403792802
netparams have been saved once 194
val: 1 0.440608948469162
val: 2 0.4242217540740967
val: 3 0.44259199500083923
val: 4 0.45493584871292114
val: 5 0.44770845770835876
val: 6 0.4411657154560089
val: 7 0.4536125957965851
val: 8 0.4399143159389496
val: 9 0.4336884319782257
val: 10 0.4342048168182373
val: 11 0.44108515977859497
val: 12 0.45083919167518616
val: 13 0.44280004501342773
val: 14 0.4468725323677063
val: 15 0.4362751543521881
val: 16 0.44209328293800354
val: 17 0.44629666209220886
val: 18 0.4501304626464844
val: 19 0.4576911926269531
val: 20 0.4334720969200134
val_Epoch:[ 194 ] val_loss: 0.44301043301820753 2022-07-01 01:29:24.107216
start training 2022-07-01 01:29:24.213460
Epoch:[ 195 0 ] loss: 0.3859412372112274 2022-07-01 01:29:38.147539
Epoch:[ 195 1 ] loss: 0.38738158345222473 2022-07-01 01:29:38.623178
Epoch:[ 195 2 ] loss: 0.3875935971736908 2022-07-01 01:29:39.191152
Epoch:[ 195 3 ] loss: 0.38923734426498413 2022-07-01 01:29:39.613399
Epoch:[ 195 4 ] loss: 0.39073529839515686 2022-07-01 01:29:40.035334
Epoch:[ 195 5 ] loss: 0.3885311484336853 2022-07-01 01:29:40.455452
Epoch:[ 195 6 ] loss: 0.38777005672454834 2022-07-01 01:29:40.875805
Epoch:[ 195 7 ] loss: 0.3880245089530945 2022-07-01 01:29:41.296132
Epoch:[ 195 8 ] loss: 0.3864845037460327 2022-07-01 01:29:41.716742
Epoch:[ 195 9 ] loss: 0.3866671919822693 2022-07-01 01:29:42.137000
Epoch:[ 195 10 ] loss: 0.3892408013343811 2022-07-01 01:29:42.559109
Epoch:[ 195 11 ] loss: 0.3903835415840149 2022-07-01 01:29:42.981646
Epoch:[ 195 12 ] loss: 0.3885016143321991 2022-07-01 01:29:43.403151
Epoch:[ 195 13 ] loss: 0.3877023160457611 2022-07-01 01:29:43.825837
Epoch:[ 195 14 ] loss: 0.38737162947654724 2022-07-01 01:29:44.247074
Epoch:[ 195 15 ] loss: 0.38971391320228577 2022-07-01 01:29:44.666846
Epoch:[ 195 16 ] loss: 0.3893078565597534 2022-07-01 01:29:49.791539
Epoch:[ 195 17 ] loss: 0.3912884294986725 2022-07-01 01:29:50.700247
Epoch:[ 195 18 ] loss: 0.3898395001888275 2022-07-01 01:29:51.122226
Epoch:[ 195 19 ] loss: 0.3875763416290283 2022-07-01 01:29:51.544297
Training_Epoch:[ 195 ] Training_loss: 0.38846462070941923 2022-07-01 01:29:51.544977
learning rate:  0.0007205759403792802
val: 1 0.4534356892108917
val: 2 0.4496653974056244
val: 3 0.444966197013855
val: 4 0.45128536224365234
val: 5 0.43130290508270264
val: 6 0.4332425892353058
val: 7 0.44021183252334595
val: 8 0.4437355697154999
val: 9 0.45235300064086914
val: 10 0.44778433442115784
val: 11 0.440832257270813
val: 12 0.4385834336280823
val: 13 0.4347628057003021
val: 14 0.4347291588783264
val: 15 0.44928520917892456
val: 16 0.44294941425323486
val: 17 0.4397612512111664
val: 18 0.43346092104911804
val: 19 0.4479609727859497
val: 20 0.44878941774368286
val_Epoch:[ 195 ] val_loss: 0.44295488595962523 2022-07-01 01:29:55.358733
start training 2022-07-01 01:29:55.466220
Epoch:[ 196 0 ] loss: 0.3888515532016754 2022-07-01 01:30:09.612912
Epoch:[ 196 1 ] loss: 0.3878437578678131 2022-07-01 01:30:10.055037
Epoch:[ 196 2 ] loss: 0.39031946659088135 2022-07-01 01:30:10.477035
Epoch:[ 196 3 ] loss: 0.38909581303596497 2022-07-01 01:30:10.899684
Epoch:[ 196 4 ] loss: 0.3884422481060028 2022-07-01 01:30:11.320029
Epoch:[ 196 5 ] loss: 0.38824403285980225 2022-07-01 01:30:11.741695
Epoch:[ 196 6 ] loss: 0.3885524570941925 2022-07-01 01:30:12.163238
Epoch:[ 196 7 ] loss: 0.3868884742259979 2022-07-01 01:30:12.576583
Epoch:[ 196 8 ] loss: 0.3870878219604492 2022-07-01 01:30:12.995713
Epoch:[ 196 9 ] loss: 0.3873531222343445 2022-07-01 01:30:13.417831
Epoch:[ 196 10 ] loss: 0.38950854539871216 2022-07-01 01:30:13.836962
Epoch:[ 196 11 ] loss: 0.38833102583885193 2022-07-01 01:30:14.257632
Epoch:[ 196 12 ] loss: 0.3871438503265381 2022-07-01 01:30:14.679064
Epoch:[ 196 13 ] loss: 0.3880406320095062 2022-07-01 01:30:15.098931
Epoch:[ 196 14 ] loss: 0.3881617784500122 2022-07-01 01:30:15.519199
Epoch:[ 196 15 ] loss: 0.39028915762901306 2022-07-01 01:30:15.940592
Epoch:[ 196 16 ] loss: 0.38937968015670776 2022-07-01 01:30:21.568201
Epoch:[ 196 17 ] loss: 0.3881562352180481 2022-07-01 01:30:21.986637
Epoch:[ 196 18 ] loss: 0.38940462470054626 2022-07-01 01:30:22.408899
Epoch:[ 196 19 ] loss: 0.3882591724395752 2022-07-01 01:30:22.830844
Training_Epoch:[ 196 ] Training_loss: 0.38846767246723174 2022-07-01 01:30:22.831536
learning rate:  0.0007205759403792802
netparams have been saved once 196
val: 1 0.4388110339641571
val: 2 0.4381307065486908
val: 3 0.46015140414237976
val: 4 0.4515950381755829
val: 5 0.45445069670677185
val: 6 0.4451577663421631
val: 7 0.44338512420654297
val: 8 0.43387967348098755
val: 9 0.4396963119506836
val: 10 0.4400409162044525
val: 11 0.4330870807170868
val: 12 0.4408137798309326
val: 13 0.4495280981063843
val: 14 0.43452778458595276
val: 15 0.45004409551620483
val: 16 0.45174509286880493
val: 17 0.4396228790283203
val: 18 0.43756377696990967
val: 19 0.4463764429092407
val: 20 0.4419367015361786
val_Epoch:[ 196 ] val_loss: 0.44352722018957136 2022-07-01 01:30:26.644153
start training 2022-07-01 01:30:26.748529
Epoch:[ 197 0 ] loss: 0.3857729434967041 2022-07-01 01:30:41.431798
Epoch:[ 197 1 ] loss: 0.38741952180862427 2022-07-01 01:30:41.851263
Epoch:[ 197 2 ] loss: 0.3898448646068573 2022-07-01 01:30:42.271930
Epoch:[ 197 3 ] loss: 0.3906138241291046 2022-07-01 01:30:42.691245
Epoch:[ 197 4 ] loss: 0.3880898058414459 2022-07-01 01:30:43.110830
Epoch:[ 197 5 ] loss: 0.3901383578777313 2022-07-01 01:30:43.526673
Epoch:[ 197 6 ] loss: 0.3896251618862152 2022-07-01 01:30:43.948435
Epoch:[ 197 7 ] loss: 0.3886336088180542 2022-07-01 01:30:44.368433
Epoch:[ 197 8 ] loss: 0.38694947957992554 2022-07-01 01:30:44.789063
Epoch:[ 197 9 ] loss: 0.38761675357818604 2022-07-01 01:30:45.208769
Epoch:[ 197 10 ] loss: 0.3887907564640045 2022-07-01 01:30:45.628467
Epoch:[ 197 11 ] loss: 0.3889376223087311 2022-07-01 01:30:46.048770
Epoch:[ 197 12 ] loss: 0.38721537590026855 2022-07-01 01:30:46.469893
Epoch:[ 197 13 ] loss: 0.38761839270591736 2022-07-01 01:30:46.892033
Epoch:[ 197 14 ] loss: 0.3893812894821167 2022-07-01 01:30:47.306993
Epoch:[ 197 15 ] loss: 0.3913285732269287 2022-07-01 01:30:47.726106
Epoch:[ 197 16 ] loss: 0.38814637064933777 2022-07-01 01:30:53.484007
Epoch:[ 197 17 ] loss: 0.3888540267944336 2022-07-01 01:30:53.902709
Epoch:[ 197 18 ] loss: 0.38896238803863525 2022-07-01 01:30:54.322404
Epoch:[ 197 19 ] loss: 0.38723981380462646 2022-07-01 01:30:54.744183
Training_Epoch:[ 197 ] Training_loss: 0.3885589465498924 2022-07-01 01:30:54.744807
learning rate:  0.0007205759403792802
val: 1 0.4410698711872101
val: 2 0.4459730088710785
val: 3 0.45890772342681885
val: 4 0.44317835569381714
val: 5 0.44058284163475037
val: 6 0.43770095705986023
val: 7 0.43987488746643066
val: 8 0.4504428505897522
val: 9 0.45646631717681885
val: 10 0.4391666650772095
val: 11 0.44267261028289795
val: 12 0.43036794662475586
val: 13 0.44007670879364014
val: 14 0.43151092529296875
val: 15 0.4333866536617279
val: 16 0.4496830701828003
val: 17 0.4340991675853729
val: 18 0.44573974609375
val: 19 0.44718098640441895
val: 20 0.4454142153263092
val_Epoch:[ 197 ] val_loss: 0.4426747754216194 2022-07-01 01:30:58.604577
start training 2022-07-01 01:30:58.713322
Epoch:[ 198 0 ] loss: 0.39107388257980347 2022-07-01 01:31:13.163353
Epoch:[ 198 1 ] loss: 0.3890325129032135 2022-07-01 01:31:13.602377
Epoch:[ 198 2 ] loss: 0.3877504765987396 2022-07-01 01:31:14.022557
Epoch:[ 198 3 ] loss: 0.38518184423446655 2022-07-01 01:31:14.442352
Epoch:[ 198 4 ] loss: 0.38653525710105896 2022-07-01 01:31:14.864376
Epoch:[ 198 5 ] loss: 0.3888351023197174 2022-07-01 01:31:15.285075
Epoch:[ 198 6 ] loss: 0.3905138075351715 2022-07-01 01:31:15.706615
Epoch:[ 198 7 ] loss: 0.387935996055603 2022-07-01 01:31:16.128502
Epoch:[ 198 8 ] loss: 0.39102205634117126 2022-07-01 01:31:16.545219
Epoch:[ 198 9 ] loss: 0.38871076703071594 2022-07-01 01:31:16.974139
Epoch:[ 198 10 ] loss: 0.3892824053764343 2022-07-01 01:31:17.395487
Epoch:[ 198 11 ] loss: 0.38821542263031006 2022-07-01 01:31:17.815770
Epoch:[ 198 12 ] loss: 0.3888436257839203 2022-07-01 01:31:18.235298
Epoch:[ 198 13 ] loss: 0.3874613642692566 2022-07-01 01:31:18.656140
Epoch:[ 198 14 ] loss: 0.3891059458255768 2022-07-01 01:31:19.066596
Epoch:[ 198 15 ] loss: 0.38839465379714966 2022-07-01 01:31:19.476105
Epoch:[ 198 16 ] loss: 0.39113491773605347 2022-07-01 01:31:24.976257
Epoch:[ 198 17 ] loss: 0.38901081681251526 2022-07-01 01:31:25.384817
Epoch:[ 198 18 ] loss: 0.3869975209236145 2022-07-01 01:31:25.817662
Epoch:[ 198 19 ] loss: 0.3896254003047943 2022-07-01 01:31:26.237726
Training_Epoch:[ 198 ] Training_loss: 0.3887331888079643 2022-07-01 01:31:26.238428
learning rate:  0.0007205759403792802
netparams have been saved once 198
val: 1 0.42936503887176514
val: 2 0.4406755268573761
val: 3 0.4411827325820923
val: 4 0.4485214948654175
val: 5 0.44702228903770447
val: 6 0.44649815559387207
val: 7 0.4411565363407135
val: 8 0.44484367966651917
val: 9 0.44368302822113037
val: 10 0.44002023339271545
val: 11 0.4385688304901123
val: 12 0.4407069683074951
val: 13 0.4354811906814575
val: 14 0.4437443017959595
val: 15 0.43259912729263306
val: 16 0.4531606137752533
val: 17 0.4600566029548645
val: 18 0.43575409054756165
val: 19 0.44454702734947205
val: 20 0.44436928629875183
val_Epoch:[ 198 ] val_loss: 0.44259783774614336 2022-07-01 01:31:30.111990
start training 2022-07-01 01:31:30.218375
Epoch:[ 199 0 ] loss: 0.3863345682621002 2022-07-01 01:31:44.380536
Epoch:[ 199 1 ] loss: 0.3910427689552307 2022-07-01 01:31:44.985613
Epoch:[ 199 2 ] loss: 0.38787758350372314 2022-07-01 01:31:45.402601
Epoch:[ 199 3 ] loss: 0.388020396232605 2022-07-01 01:31:45.823513
Epoch:[ 199 4 ] loss: 0.38645580410957336 2022-07-01 01:31:46.246163
Epoch:[ 199 5 ] loss: 0.388378769159317 2022-07-01 01:31:46.665637
Epoch:[ 199 6 ] loss: 0.3872300088405609 2022-07-01 01:31:47.085051
Epoch:[ 199 7 ] loss: 0.3886053264141083 2022-07-01 01:31:47.507615
Epoch:[ 199 8 ] loss: 0.38797029852867126 2022-07-01 01:31:47.930514
Epoch:[ 199 9 ] loss: 0.39074617624282837 2022-07-01 01:31:48.352554
Epoch:[ 199 10 ] loss: 0.38770657777786255 2022-07-01 01:31:48.774037
Epoch:[ 199 11 ] loss: 0.38853490352630615 2022-07-01 01:31:49.194631
Epoch:[ 199 12 ] loss: 0.38797640800476074 2022-07-01 01:31:49.614589
Epoch:[ 199 13 ] loss: 0.38694635033607483 2022-07-01 01:31:50.034569
Epoch:[ 199 14 ] loss: 0.3893541991710663 2022-07-01 01:31:50.457817
Epoch:[ 199 15 ] loss: 0.3900794982910156 2022-07-01 01:31:50.879559
Epoch:[ 199 16 ] loss: 0.38745981454849243 2022-07-01 01:31:56.130455
Epoch:[ 199 17 ] loss: 0.39029598236083984 2022-07-01 01:31:56.957752
Epoch:[ 199 18 ] loss: 0.38657146692276 2022-07-01 01:31:57.384593
Epoch:[ 199 19 ] loss: 0.39184388518333435 2022-07-01 01:31:57.803241
Training_Epoch:[ 199 ] Training_loss: 0.38847153931856154 2022-07-01 01:31:57.803944
learning rate:  0.0007205759403792802
val: 1 0.4359285831451416
val: 2 0.44555628299713135
val: 3 0.43934711813926697
val: 4 0.43926486372947693
val: 5 0.4367152154445648
val: 6 0.43560001254081726
val: 7 0.46483808755874634
val: 8 0.44471219182014465
val: 9 0.4594411551952362
val: 10 0.4467814862728119
val: 11 0.4536799192428589
val: 12 0.4300466477870941
val: 13 0.4423210024833679
val: 14 0.453284353017807
val: 15 0.4262522757053375
val: 16 0.4399551451206207
val: 17 0.44847315549850464
val: 18 0.4527077376842499
val: 19 0.4446170926094055
val: 20 0.4442891776561737
val_Epoch:[ 199 ] val_loss: 0.4441905751824379 2022-07-01 01:32:01.544599
start training 2022-07-01 01:32:01.651071
Epoch:[ 200 0 ] loss: 0.38671424984931946 2022-07-01 01:32:15.875721
Epoch:[ 200 1 ] loss: 0.38679420948028564 2022-07-01 01:32:16.296397
Epoch:[ 200 2 ] loss: 0.38864198327064514 2022-07-01 01:32:16.707345
Epoch:[ 200 3 ] loss: 0.3875410556793213 2022-07-01 01:32:17.129723
Epoch:[ 200 4 ] loss: 0.3875865638256073 2022-07-01 01:32:17.550425
Epoch:[ 200 5 ] loss: 0.3896328806877136 2022-07-01 01:32:17.970935
Epoch:[ 200 6 ] loss: 0.39079993963241577 2022-07-01 01:32:18.391027
Epoch:[ 200 7 ] loss: 0.3888373076915741 2022-07-01 01:32:18.812767
Epoch:[ 200 8 ] loss: 0.3888556659221649 2022-07-01 01:32:19.234975
Epoch:[ 200 9 ] loss: 0.38867995142936707 2022-07-01 01:32:19.657505
Epoch:[ 200 10 ] loss: 0.38954639434814453 2022-07-01 01:32:20.080886
Epoch:[ 200 11 ] loss: 0.3878105878829956 2022-07-01 01:32:20.495506
Epoch:[ 200 12 ] loss: 0.3884285092353821 2022-07-01 01:32:20.917411
Epoch:[ 200 13 ] loss: 0.38979339599609375 2022-07-01 01:32:21.340373
Epoch:[ 200 14 ] loss: 0.3868466019630432 2022-07-01 01:32:21.761896
Epoch:[ 200 15 ] loss: 0.38901662826538086 2022-07-01 01:32:22.183688
Epoch:[ 200 16 ] loss: 0.3875192105770111 2022-07-01 01:32:27.719534
Epoch:[ 200 17 ] loss: 0.38713526725769043 2022-07-01 01:32:28.139895
Epoch:[ 200 18 ] loss: 0.3874925374984741 2022-07-01 01:32:28.567366
Epoch:[ 200 19 ] loss: 0.3904058337211609 2022-07-01 01:32:28.986997
Training_Epoch:[ 200 ] Training_loss: 0.38840393871068957 2022-07-01 01:32:28.987733
learning rate:  0.0007205759403792802
netparams have been saved once 200
val: 1 0.44281259179115295
val: 2 0.4380141496658325
val: 3 0.4436340630054474
val: 4 0.4493657946586609
val: 5 0.4474657475948334
val: 6 0.4489814043045044
val: 7 0.43661531805992126
val: 8 0.43626636266708374
val: 9 0.44880062341690063
val: 10 0.4380597472190857
val: 11 0.43685436248779297
val: 12 0.4544365108013153
val: 13 0.4390732944011688
val: 14 0.45524075627326965
val: 15 0.4508783519268036
val: 16 0.44483688473701477
val: 17 0.4512659013271332
val: 18 0.4444541931152344
val: 19 0.45251333713531494
val: 20 0.4316956400871277
val_Epoch:[ 200 ] val_loss: 0.4445632517337799 2022-07-01 01:32:32.806502
start training 2022-07-01 01:32:32.911822
Epoch:[ 201 0 ] loss: 0.3887157738208771 2022-07-01 01:32:47.406606
Epoch:[ 201 1 ] loss: 0.38616693019866943 2022-07-01 01:32:47.861562
Epoch:[ 201 2 ] loss: 0.3894449472427368 2022-07-01 01:32:48.277928
Epoch:[ 201 3 ] loss: 0.3882420063018799 2022-07-01 01:32:48.700121
Epoch:[ 201 4 ] loss: 0.3879225254058838 2022-07-01 01:32:49.120653
Epoch:[ 201 5 ] loss: 0.38965263962745667 2022-07-01 01:32:49.541264
Epoch:[ 201 6 ] loss: 0.3859958350658417 2022-07-01 01:32:49.963126
Epoch:[ 201 7 ] loss: 0.3865007162094116 2022-07-01 01:32:50.383640
Epoch:[ 201 8 ] loss: 0.3889763653278351 2022-07-01 01:32:50.804523
Epoch:[ 201 9 ] loss: 0.3881925642490387 2022-07-01 01:32:51.220155
Epoch:[ 201 10 ] loss: 0.3903336524963379 2022-07-01 01:32:51.645548
Epoch:[ 201 11 ] loss: 0.3863064646720886 2022-07-01 01:32:52.066559
Epoch:[ 201 12 ] loss: 0.387643963098526 2022-07-01 01:32:52.487268
Epoch:[ 201 13 ] loss: 0.3878471255302429 2022-07-01 01:32:52.909156
Epoch:[ 201 14 ] loss: 0.389758437871933 2022-07-01 01:32:53.329861
Epoch:[ 201 15 ] loss: 0.3885039985179901 2022-07-01 01:32:53.749700
Epoch:[ 201 16 ] loss: 0.38706064224243164 2022-07-01 01:32:58.987501
Epoch:[ 201 17 ] loss: 0.38994550704956055 2022-07-01 01:32:59.409292
Epoch:[ 201 18 ] loss: 0.38884004950523376 2022-07-01 01:32:59.854100
Epoch:[ 201 19 ] loss: 0.38626644015312195 2022-07-01 01:33:00.275325
Training_Epoch:[ 201 ] Training_loss: 0.38811582922935484 2022-07-01 01:33:00.276132
learning rate:  0.0005764607523034242
val: 1 0.4455533027648926
val: 2 0.4448254108428955
val: 3 0.45508691668510437
val: 4 0.44397324323654175
val: 5 0.441087007522583
val: 6 0.43333670496940613
val: 7 0.43594247102737427
val: 8 0.4446467161178589
val: 9 0.4279307723045349
val: 10 0.433307021856308
val: 11 0.4423738121986389
val: 12 0.45342743396759033
val: 13 0.44790953397750854
val: 14 0.43356356024742126
val: 15 0.4477751851081848
val: 16 0.4573582112789154
val: 17 0.4454900324344635
val: 18 0.4578181803226471
val: 19 0.4435887634754181
val: 20 0.4499483108520508
val_Epoch:[ 201 ] val_loss: 0.4442471295595169 2022-07-01 01:33:04.122603
start training 2022-07-01 01:33:04.238560
Epoch:[ 202 0 ] loss: 0.3885006308555603 2022-07-01 01:33:19.140880
Epoch:[ 202 1 ] loss: 0.3880254030227661 2022-07-01 01:33:19.565767
Epoch:[ 202 2 ] loss: 0.3873782455921173 2022-07-01 01:33:19.992060
Epoch:[ 202 3 ] loss: 0.38721221685409546 2022-07-01 01:33:20.419649
Epoch:[ 202 4 ] loss: 0.39101341366767883 2022-07-01 01:33:20.847179
Epoch:[ 202 5 ] loss: 0.3882424831390381 2022-07-01 01:33:21.273830
Epoch:[ 202 6 ] loss: 0.387606143951416 2022-07-01 01:33:21.700241
Epoch:[ 202 7 ] loss: 0.3868856132030487 2022-07-01 01:33:22.120508
Epoch:[ 202 8 ] loss: 0.3856773376464844 2022-07-01 01:33:22.544167
Epoch:[ 202 9 ] loss: 0.3892211318016052 2022-07-01 01:33:22.970110
Epoch:[ 202 10 ] loss: 0.3897979259490967 2022-07-01 01:33:23.397412
Epoch:[ 202 11 ] loss: 0.38712960481643677 2022-07-01 01:33:23.825690
Epoch:[ 202 12 ] loss: 0.38948094844818115 2022-07-01 01:33:24.246375
Epoch:[ 202 13 ] loss: 0.38695183396339417 2022-07-01 01:33:24.671510
Epoch:[ 202 14 ] loss: 0.3864699900150299 2022-07-01 01:33:25.098531
Epoch:[ 202 15 ] loss: 0.38705092668533325 2022-07-01 01:33:25.524074
Epoch:[ 202 16 ] loss: 0.3884567320346832 2022-07-01 01:33:30.655203
Epoch:[ 202 17 ] loss: 0.3884134292602539 2022-07-01 01:33:31.091343
Epoch:[ 202 18 ] loss: 0.38853833079338074 2022-07-01 01:33:31.537651
Epoch:[ 202 19 ] loss: 0.3881685733795166 2022-07-01 01:33:31.973321
Training_Epoch:[ 202 ] Training_loss: 0.38801104575395584 2022-07-01 01:33:31.974058
learning rate:  0.0005764607523034242
netparams have been saved once 202
val: 1 0.44646039605140686
val: 2 0.44604986906051636
val: 3 0.4465583264827728
val: 4 0.4356766939163208
val: 5 0.4437151253223419
val: 6 0.43813061714172363
val: 7 0.4461955726146698
val: 8 0.4379764497280121
val: 9 0.45567694306373596
val: 10 0.4495927691459656
val: 11 0.4328277111053467
val: 12 0.445549339056015
val: 13 0.43772798776626587
val: 14 0.44391530752182007
val: 15 0.44830432534217834
val: 16 0.43957287073135376
val: 17 0.436630517244339
val: 18 0.4468565583229065
val: 19 0.45164307951927185
val: 20 0.4381842613220215
val_Epoch:[ 202 ] val_loss: 0.4433622360229492 2022-07-01 01:33:35.901648
start training 2022-07-01 01:33:36.072488
Epoch:[ 203 0 ] loss: 0.38725292682647705 2022-07-01 01:33:50.193805
Epoch:[ 203 1 ] loss: 0.3875664174556732 2022-07-01 01:33:50.633046
Epoch:[ 203 2 ] loss: 0.38896098732948303 2022-07-01 01:33:51.077335
Epoch:[ 203 3 ] loss: 0.3890340328216553 2022-07-01 01:33:51.497244
Epoch:[ 203 4 ] loss: 0.38755708932876587 2022-07-01 01:33:51.919801
Epoch:[ 203 5 ] loss: 0.38790762424468994 2022-07-01 01:33:52.342059
Epoch:[ 203 6 ] loss: 0.3868492841720581 2022-07-01 01:33:52.763413
Epoch:[ 203 7 ] loss: 0.387410968542099 2022-07-01 01:33:53.187179
Epoch:[ 203 8 ] loss: 0.38851305842399597 2022-07-01 01:33:53.608337
Epoch:[ 203 9 ] loss: 0.38710057735443115 2022-07-01 01:33:54.025427
Epoch:[ 203 10 ] loss: 0.38877367973327637 2022-07-01 01:33:54.439755
Epoch:[ 203 11 ] loss: 0.3886537253856659 2022-07-01 01:33:54.861729
Epoch:[ 203 12 ] loss: 0.38701799511909485 2022-07-01 01:33:55.285285
Epoch:[ 203 13 ] loss: 0.38911592960357666 2022-07-01 01:33:55.706464
Epoch:[ 203 14 ] loss: 0.3885597288608551 2022-07-01 01:33:56.127497
Epoch:[ 203 15 ] loss: 0.3865504562854767 2022-07-01 01:33:56.552019
Epoch:[ 203 16 ] loss: 0.3902961313724518 2022-07-01 01:34:02.272709
Epoch:[ 203 17 ] loss: 0.3874540627002716 2022-07-01 01:34:02.692413
Epoch:[ 203 18 ] loss: 0.389291912317276 2022-07-01 01:34:03.115334
Epoch:[ 203 19 ] loss: 0.38894137740135193 2022-07-01 01:34:03.538226
Training_Epoch:[ 203 ] Training_loss: 0.38814039826393126 2022-07-01 01:34:03.538951
learning rate:  0.0005764607523034242
val: 1 0.44545209407806396
val: 2 0.4435805678367615
val: 3 0.4492131471633911
val: 4 0.4355132281780243
val: 5 0.4497935473918915
val: 6 0.44137468934059143
val: 7 0.4490405321121216
val: 8 0.4430329501628876
val: 9 0.4599126875400543
val: 10 0.43880587816238403
val: 11 0.4472023546695709
val: 12 0.44004520773887634
val: 13 0.438666969537735
val: 14 0.4326387643814087
val: 15 0.44613462686538696
val: 16 0.4366624653339386
val: 17 0.43892204761505127
val: 18 0.4530371427536011
val: 19 0.4374481439590454
val: 20 0.44699010252952576
val_Epoch:[ 203 ] val_loss: 0.44367335736751556 2022-07-01 01:34:07.311511
start training 2022-07-01 01:34:07.417725
Epoch:[ 204 0 ] loss: 0.3872584104537964 2022-07-01 01:34:22.460777
Epoch:[ 204 1 ] loss: 0.39051005244255066 2022-07-01 01:34:22.873842
Epoch:[ 204 2 ] loss: 0.3882581889629364 2022-07-01 01:34:23.293834
Epoch:[ 204 3 ] loss: 0.38923969864845276 2022-07-01 01:34:23.713378
Epoch:[ 204 4 ] loss: 0.38798555731773376 2022-07-01 01:34:24.132730
Epoch:[ 204 5 ] loss: 0.38915690779685974 2022-07-01 01:34:24.554966
Epoch:[ 204 6 ] loss: 0.3867419958114624 2022-07-01 01:34:24.976130
Epoch:[ 204 7 ] loss: 0.3876057267189026 2022-07-01 01:34:25.396271
Epoch:[ 204 8 ] loss: 0.38887083530426025 2022-07-01 01:34:25.816240
Epoch:[ 204 9 ] loss: 0.38745594024658203 2022-07-01 01:34:26.235661
Epoch:[ 204 10 ] loss: 0.38662901520729065 2022-07-01 01:34:26.656495
Epoch:[ 204 11 ] loss: 0.38804417848587036 2022-07-01 01:34:27.075759
Epoch:[ 204 12 ] loss: 0.3895163834095001 2022-07-01 01:34:27.498088
Epoch:[ 204 13 ] loss: 0.38609233498573303 2022-07-01 01:34:27.920198
Epoch:[ 204 14 ] loss: 0.3867538869380951 2022-07-01 01:34:28.341146
Epoch:[ 204 15 ] loss: 0.3881015479564667 2022-07-01 01:34:28.763456
Epoch:[ 204 16 ] loss: 0.3857744038105011 2022-07-01 01:34:34.181488
Epoch:[ 204 17 ] loss: 0.38966113328933716 2022-07-01 01:34:34.599975
Epoch:[ 204 18 ] loss: 0.3893375098705292 2022-07-01 01:34:35.020264
Epoch:[ 204 19 ] loss: 0.3888220191001892 2022-07-01 01:34:35.441574
Training_Epoch:[ 204 ] Training_loss: 0.3880907863378525 2022-07-01 01:34:35.442268
learning rate:  0.0005764607523034242
netparams have been saved once 204
val: 1 0.4480293393135071
val: 2 0.4441227614879608
val: 3 0.44853952527046204
val: 4 0.444339781999588
val: 5 0.4481600224971771
val: 6 0.45005354285240173
val: 7 0.4363456964492798
val: 8 0.4427778720855713
val: 9 0.43977972865104675
val: 10 0.43855419754981995
val: 11 0.443787544965744
val: 12 0.4459795653820038
val: 13 0.44591766595840454
val: 14 0.435350239276886
val: 15 0.4550250768661499
val: 16 0.4454103112220764
val: 17 0.438179075717926
val: 18 0.43871843814849854
val: 19 0.4390585720539093
val: 20 0.44008153676986694
val_Epoch:[ 204 ] val_loss: 0.443410524725914 2022-07-01 01:34:39.274510
start training 2022-07-01 01:34:39.400273
Epoch:[ 205 0 ] loss: 0.3865028917789459 2022-07-01 01:34:54.099275
Epoch:[ 205 1 ] loss: 0.38855138421058655 2022-07-01 01:34:54.519594
Epoch:[ 205 2 ] loss: 0.38746923208236694 2022-07-01 01:34:54.940137
Epoch:[ 205 3 ] loss: 0.38558071851730347 2022-07-01 01:34:55.360132
Epoch:[ 205 4 ] loss: 0.3894684612751007 2022-07-01 01:34:55.773731
Epoch:[ 205 5 ] loss: 0.38643988966941833 2022-07-01 01:34:56.193491
Epoch:[ 205 6 ] loss: 0.38854318857192993 2022-07-01 01:34:56.615374
Epoch:[ 205 7 ] loss: 0.3874180018901825 2022-07-01 01:34:57.037241
Epoch:[ 205 8 ] loss: 0.3897053599357605 2022-07-01 01:34:57.457982
Epoch:[ 205 9 ] loss: 0.3884308636188507 2022-07-01 01:34:57.877632
Epoch:[ 205 10 ] loss: 0.3858810365200043 2022-07-01 01:34:58.297927
Epoch:[ 205 11 ] loss: 0.38821128010749817 2022-07-01 01:34:58.714446
Epoch:[ 205 12 ] loss: 0.38823920488357544 2022-07-01 01:34:59.134273
Epoch:[ 205 13 ] loss: 0.3873032033443451 2022-07-01 01:34:59.557879
Epoch:[ 205 14 ] loss: 0.39196866750717163 2022-07-01 01:34:59.980466
Epoch:[ 205 15 ] loss: 0.38831037282943726 2022-07-01 01:35:00.401563
Epoch:[ 205 16 ] loss: 0.38653433322906494 2022-07-01 01:35:05.791261
Epoch:[ 205 17 ] loss: 0.3875529170036316 2022-07-01 01:35:06.212222
Epoch:[ 205 18 ] loss: 0.3861875832080841 2022-07-01 01:35:06.633789
Epoch:[ 205 19 ] loss: 0.38931912183761597 2022-07-01 01:35:07.052320
Training_Epoch:[ 205 ] Training_loss: 0.3878808856010437 2022-07-01 01:35:07.052990
learning rate:  0.0005764607523034242
val: 1 0.445637971162796
val: 2 0.43787309527397156
val: 3 0.44674915075302124
val: 4 0.4450247287750244
val: 5 0.4372081756591797
val: 6 0.42728671431541443
val: 7 0.45056793093681335
val: 8 0.44990724325180054
val: 9 0.4478495419025421
val: 10 0.44416284561157227
val: 11 0.44578516483306885
val: 12 0.44120216369628906
val: 13 0.4560283422470093
val: 14 0.4376881420612335
val: 15 0.435371994972229
val: 16 0.44623324275016785
val: 17 0.44513988494873047
val: 18 0.4506775140762329
val: 19 0.44433125853538513
val: 20 0.452770859003067
val_Epoch:[ 205 ] val_loss: 0.4443747982382774 2022-07-01 01:35:10.826498
start training 2022-07-01 01:35:10.931467
Epoch:[ 206 0 ] loss: 0.389469176530838 2022-07-01 01:35:25.316381
Epoch:[ 206 1 ] loss: 0.3866238296031952 2022-07-01 01:35:25.749860
Epoch:[ 206 2 ] loss: 0.38731080293655396 2022-07-01 01:35:26.170800
Epoch:[ 206 3 ] loss: 0.38729849457740784 2022-07-01 01:35:26.585132
Epoch:[ 206 4 ] loss: 0.38549914956092834 2022-07-01 01:35:26.994673
Epoch:[ 206 5 ] loss: 0.38724371790885925 2022-07-01 01:35:27.403889
Epoch:[ 206 6 ] loss: 0.3887287974357605 2022-07-01 01:35:27.812870
Epoch:[ 206 7 ] loss: 0.387253999710083 2022-07-01 01:35:28.225862
Epoch:[ 206 8 ] loss: 0.38750579953193665 2022-07-01 01:35:28.636620
Epoch:[ 206 9 ] loss: 0.3866006135940552 2022-07-01 01:35:29.044397
Epoch:[ 206 10 ] loss: 0.3862548768520355 2022-07-01 01:35:29.454793
Epoch:[ 206 11 ] loss: 0.3901914656162262 2022-07-01 01:35:29.864888
Epoch:[ 206 12 ] loss: 0.3886514902114868 2022-07-01 01:35:30.273689
Epoch:[ 206 13 ] loss: 0.38780370354652405 2022-07-01 01:35:30.684647
Epoch:[ 206 14 ] loss: 0.38895735144615173 2022-07-01 01:35:31.095315
Epoch:[ 206 15 ] loss: 0.3883121907711029 2022-07-01 01:35:31.514370
Epoch:[ 206 16 ] loss: 0.3900943696498871 2022-07-01 01:35:36.996418
Epoch:[ 206 17 ] loss: 0.38673338294029236 2022-07-01 01:35:37.406822
Epoch:[ 206 18 ] loss: 0.38766083121299744 2022-07-01 01:35:37.828314
Epoch:[ 206 19 ] loss: 0.3894348442554474 2022-07-01 01:35:38.236119
Training_Epoch:[ 206 ] Training_loss: 0.3878814443945885 2022-07-01 01:35:38.236841
learning rate:  0.0005764607523034242
netparams have been saved once 206
val: 1 0.44135400652885437
val: 2 0.4436178505420685
val: 3 0.43935567140579224
val: 4 0.4523266851902008
val: 5 0.4489098787307739
val: 6 0.44799283146858215
val: 7 0.4453790783882141
val: 8 0.44548165798187256
val: 9 0.4440523386001587
val: 10 0.4301481246948242
val: 11 0.43787285685539246
val: 12 0.4409697651863098
val: 13 0.4305206835269928
val: 14 0.4565803110599518
val: 15 0.45119422674179077
val: 16 0.4534226059913635
val: 17 0.43154245615005493
val: 18 0.4432901442050934
val: 19 0.4451667368412018
val: 20 0.4496892988681793
val_Epoch:[ 206 ] val_loss: 0.44394336044788363 2022-07-01 01:35:42.194499
start training 2022-07-01 01:35:42.315153
Epoch:[ 207 0 ] loss: 0.3888823688030243 2022-07-01 01:35:57.220986
Epoch:[ 207 1 ] loss: 0.3871314525604248 2022-07-01 01:35:57.639953
Epoch:[ 207 2 ] loss: 0.390545129776001 2022-07-01 01:35:58.062683
Epoch:[ 207 3 ] loss: 0.38769757747650146 2022-07-01 01:35:58.483950
Epoch:[ 207 4 ] loss: 0.38761478662490845 2022-07-01 01:35:58.904445
Epoch:[ 207 5 ] loss: 0.38800889253616333 2022-07-01 01:35:59.325722
Epoch:[ 207 6 ] loss: 0.3879907429218292 2022-07-01 01:35:59.747069
Epoch:[ 207 7 ] loss: 0.386033833026886 2022-07-01 01:36:00.167303
Epoch:[ 207 8 ] loss: 0.3891531825065613 2022-07-01 01:36:00.590131
Epoch:[ 207 9 ] loss: 0.3882486820220947 2022-07-01 01:36:01.012416
Epoch:[ 207 10 ] loss: 0.38644853234291077 2022-07-01 01:36:01.433971
Epoch:[ 207 11 ] loss: 0.3866455554962158 2022-07-01 01:36:01.855031
Epoch:[ 207 12 ] loss: 0.38654598593711853 2022-07-01 01:36:02.276395
Epoch:[ 207 13 ] loss: 0.38575220108032227 2022-07-01 01:36:02.690689
Epoch:[ 207 14 ] loss: 0.3856474459171295 2022-07-01 01:36:03.112023
Epoch:[ 207 15 ] loss: 0.387201189994812 2022-07-01 01:36:03.533704
Epoch:[ 207 16 ] loss: 0.3916512727737427 2022-07-01 01:36:08.961374
Epoch:[ 207 17 ] loss: 0.38879650831222534 2022-07-01 01:36:09.380126
Epoch:[ 207 18 ] loss: 0.3885674774646759 2022-07-01 01:36:09.801495
Epoch:[ 207 19 ] loss: 0.38635221123695374 2022-07-01 01:36:10.223315
Training_Epoch:[ 207 ] Training_loss: 0.38774575144052503 2022-07-01 01:36:10.224065
learning rate:  0.0005764607523034242
val: 1 0.4480772316455841
val: 2 0.45256301760673523
val: 3 0.45059847831726074
val: 4 0.4481599032878876
val: 5 0.44692039489746094
val: 6 0.44469156861305237
val: 7 0.4463713765144348
val: 8 0.44207075238227844
val: 9 0.4420011341571808
val: 10 0.4287866950035095
val: 11 0.44878050684928894
val: 12 0.43763279914855957
val: 13 0.44143617153167725
val: 14 0.4370538294315338
val: 15 0.4378994107246399
val: 16 0.4318860173225403
val: 17 0.44782423973083496
val: 18 0.4599469304084778
val: 19 0.4454864263534546
val: 20 0.4468625485897064
val_Epoch:[ 207 ] val_loss: 0.4442524716258049 2022-07-01 01:36:13.982205
start training 2022-07-01 01:36:14.082693
Epoch:[ 208 0 ] loss: 0.3871877193450928 2022-07-01 01:36:28.815529
Epoch:[ 208 1 ] loss: 0.3859935402870178 2022-07-01 01:36:29.229311
Epoch:[ 208 2 ] loss: 0.38804787397384644 2022-07-01 01:36:29.652444
Epoch:[ 208 3 ] loss: 0.38921722769737244 2022-07-01 01:36:30.073619
Epoch:[ 208 4 ] loss: 0.3860858082771301 2022-07-01 01:36:30.494424
Epoch:[ 208 5 ] loss: 0.38730737566947937 2022-07-01 01:36:30.914564
Epoch:[ 208 6 ] loss: 0.3871479630470276 2022-07-01 01:36:31.336894
Epoch:[ 208 7 ] loss: 0.387759804725647 2022-07-01 01:36:31.757773
Epoch:[ 208 8 ] loss: 0.3874717652797699 2022-07-01 01:36:32.178258
Epoch:[ 208 9 ] loss: 0.3870431184768677 2022-07-01 01:36:32.599333
Epoch:[ 208 10 ] loss: 0.3862015902996063 2022-07-01 01:36:33.016688
Epoch:[ 208 11 ] loss: 0.3884090185165405 2022-07-01 01:36:33.437758
Epoch:[ 208 12 ] loss: 0.3891872763633728 2022-07-01 01:36:33.858413
Epoch:[ 208 13 ] loss: 0.3873592019081116 2022-07-01 01:36:34.278559
Epoch:[ 208 14 ] loss: 0.38935455679893494 2022-07-01 01:36:34.699413
Epoch:[ 208 15 ] loss: 0.3876727223396301 2022-07-01 01:36:35.118813
Epoch:[ 208 16 ] loss: 0.38804247975349426 2022-07-01 01:36:40.404091
Epoch:[ 208 17 ] loss: 0.3867083191871643 2022-07-01 01:36:40.826260
Epoch:[ 208 18 ] loss: 0.3874242603778839 2022-07-01 01:36:41.250451
Epoch:[ 208 19 ] loss: 0.3888632655143738 2022-07-01 01:36:41.671911
Training_Epoch:[ 208 ] Training_loss: 0.38762424439191817 2022-07-01 01:36:41.672703
learning rate:  0.0005764607523034242
netparams have been saved once 208
val: 1 0.45319226384162903
val: 2 0.44608837366104126
val: 3 0.4407828748226166
val: 4 0.43879690766334534
val: 5 0.437908798456192
val: 6 0.45513755083084106
val: 7 0.4367399215698242
val: 8 0.4462850093841553
val: 9 0.4366011321544647
val: 10 0.4431164264678955
val: 11 0.4509508013725281
val: 12 0.43467357754707336
val: 13 0.4499181807041168
val: 14 0.4440688192844391
val: 15 0.43823519349098206
val: 16 0.44436174631118774
val: 17 0.4485240578651428
val: 18 0.4453293979167938
val: 19 0.4416390359401703
val: 20 0.4421198070049286
val_Epoch:[ 208 ] val_loss: 0.4437234938144684 2022-07-01 01:36:45.558378
start training 2022-07-01 01:36:45.662899
Epoch:[ 209 0 ] loss: 0.3872782289981842 2022-07-01 01:36:59.838188
Epoch:[ 209 1 ] loss: 0.38706135749816895 2022-07-01 01:37:00.275309
Epoch:[ 209 2 ] loss: 0.38620010018348694 2022-07-01 01:37:00.699279
Epoch:[ 209 3 ] loss: 0.38889628648757935 2022-07-01 01:37:01.121177
Epoch:[ 209 4 ] loss: 0.3861443102359772 2022-07-01 01:37:01.543880
Epoch:[ 209 5 ] loss: 0.3884708881378174 2022-07-01 01:37:01.966638
Epoch:[ 209 6 ] loss: 0.3889558017253876 2022-07-01 01:37:02.389781
Epoch:[ 209 7 ] loss: 0.38809889554977417 2022-07-01 01:37:02.813081
Epoch:[ 209 8 ] loss: 0.3879445493221283 2022-07-01 01:37:03.236177
Epoch:[ 209 9 ] loss: 0.3871120810508728 2022-07-01 01:37:03.657042
Epoch:[ 209 10 ] loss: 0.3863798975944519 2022-07-01 01:37:04.080843
Epoch:[ 209 11 ] loss: 0.38812291622161865 2022-07-01 01:37:04.503379
Epoch:[ 209 12 ] loss: 0.386415034532547 2022-07-01 01:37:04.926642
Epoch:[ 209 13 ] loss: 0.38988643884658813 2022-07-01 01:37:05.350329
Epoch:[ 209 14 ] loss: 0.38764688372612 2022-07-01 01:37:05.774817
Epoch:[ 209 15 ] loss: 0.38988152146339417 2022-07-01 01:37:06.192607
Epoch:[ 209 16 ] loss: 0.38840869069099426 2022-07-01 01:37:12.157406
Epoch:[ 209 17 ] loss: 0.3837715983390808 2022-07-01 01:37:12.579843
Epoch:[ 209 18 ] loss: 0.38679468631744385 2022-07-01 01:37:13.002714
Epoch:[ 209 19 ] loss: 0.3881637752056122 2022-07-01 01:37:13.426020
Training_Epoch:[ 209 ] Training_loss: 0.38758169710636137 2022-07-01 01:37:13.426706
learning rate:  0.0005764607523034242
val: 1 0.44018423557281494
val: 2 0.4361969530582428
val: 3 0.45487964153289795
val: 4 0.43806540966033936
val: 5 0.44270190596580505
val: 6 0.4465009272098541
val: 7 0.4370136857032776
val: 8 0.44309335947036743
val: 9 0.4354701042175293
val: 10 0.42970460653305054
val: 11 0.4513491988182068
val: 12 0.43787887692451477
val: 13 0.4496360123157501
val: 14 0.4438559412956238
val: 15 0.44636446237564087
val: 16 0.4389290511608124
val: 17 0.4509623646736145
val: 18 0.4513142704963684
val: 19 0.4439343214035034
val: 20 0.45568692684173584
val_Epoch:[ 209 ] val_loss: 0.4436861127614975 2022-07-01 01:37:17.223465
start training 2022-07-01 01:37:17.327950
Epoch:[ 210 0 ] loss: 0.3875011205673218 2022-07-01 01:37:31.585575
Epoch:[ 210 1 ] loss: 0.3886122703552246 2022-07-01 01:37:32.315642
Epoch:[ 210 2 ] loss: 0.3872166574001312 2022-07-01 01:37:32.738980
Epoch:[ 210 3 ] loss: 0.389355331659317 2022-07-01 01:37:33.164367
Epoch:[ 210 4 ] loss: 0.38536810874938965 2022-07-01 01:37:33.587385
Epoch:[ 210 5 ] loss: 0.38731682300567627 2022-07-01 01:37:34.013316
Epoch:[ 210 6 ] loss: 0.3851191997528076 2022-07-01 01:37:34.436435
Epoch:[ 210 7 ] loss: 0.38598498702049255 2022-07-01 01:37:34.857673
Epoch:[ 210 8 ] loss: 0.3879862129688263 2022-07-01 01:37:35.278455
Epoch:[ 210 9 ] loss: 0.38730132579803467 2022-07-01 01:37:35.701035
Epoch:[ 210 10 ] loss: 0.38623079657554626 2022-07-01 01:37:36.120473
Epoch:[ 210 11 ] loss: 0.39030367136001587 2022-07-01 01:37:36.542752
Epoch:[ 210 12 ] loss: 0.38886842131614685 2022-07-01 01:37:36.966369
Epoch:[ 210 13 ] loss: 0.3900132477283478 2022-07-01 01:37:37.388809
Epoch:[ 210 14 ] loss: 0.3873039186000824 2022-07-01 01:37:37.812926
Epoch:[ 210 15 ] loss: 0.38775527477264404 2022-07-01 01:37:38.235234
Epoch:[ 210 16 ] loss: 0.38906538486480713 2022-07-01 01:37:43.293135
Epoch:[ 210 17 ] loss: 0.38677847385406494 2022-07-01 01:37:44.473005
Epoch:[ 210 18 ] loss: 0.38571450114250183 2022-07-01 01:37:44.894688
Epoch:[ 210 19 ] loss: 0.38897576928138733 2022-07-01 01:37:45.316451
Training_Epoch:[ 210 ] Training_loss: 0.3876385748386383 2022-07-01 01:37:45.317174
learning rate:  0.0005764607523034242
netparams have been saved once 210
val: 1 0.443541020154953
val: 2 0.43206825852394104
val: 3 0.4478551149368286
val: 4 0.4323674142360687
val: 5 0.4558001160621643
val: 6 0.4430842697620392
val: 7 0.45893001556396484
val: 8 0.4395633935928345
val: 9 0.4406609833240509
val: 10 0.44610509276390076
val: 11 0.4377688765525818
val: 12 0.43944251537323
val: 13 0.4397558271884918
val: 14 0.45161256194114685
val: 15 0.4392992854118347
val: 16 0.4577076733112335
val: 17 0.43415015935897827
val: 18 0.4458472430706024
val: 19 0.45107391476631165
val: 20 0.43699344992637634
val_Epoch:[ 210 ] val_loss: 0.44368135929107666 2022-07-01 01:37:49.170239
start training 2022-07-01 01:37:49.273631
Epoch:[ 211 0 ] loss: 0.38794443011283875 2022-07-01 01:38:03.231687
Epoch:[ 211 1 ] loss: 0.38799604773521423 2022-07-01 01:38:03.697597
Epoch:[ 211 2 ] loss: 0.3869648873806 2022-07-01 01:38:04.137677
Epoch:[ 211 3 ] loss: 0.3864351809024811 2022-07-01 01:38:04.557168
Epoch:[ 211 4 ] loss: 0.3880423903465271 2022-07-01 01:38:04.980230
Epoch:[ 211 5 ] loss: 0.3880033493041992 2022-07-01 01:38:05.401844
Epoch:[ 211 6 ] loss: 0.3864562511444092 2022-07-01 01:38:05.824968
Epoch:[ 211 7 ] loss: 0.3853408694267273 2022-07-01 01:38:06.248106
Epoch:[ 211 8 ] loss: 0.3869584798812866 2022-07-01 01:38:06.671145
Epoch:[ 211 9 ] loss: 0.3917903006076813 2022-07-01 01:38:07.090837
Epoch:[ 211 10 ] loss: 0.38857242465019226 2022-07-01 01:38:07.511921
Epoch:[ 211 11 ] loss: 0.3869602382183075 2022-07-01 01:38:07.932662
Epoch:[ 211 12 ] loss: 0.3870028555393219 2022-07-01 01:38:08.353892
Epoch:[ 211 13 ] loss: 0.3861333429813385 2022-07-01 01:38:08.775951
Epoch:[ 211 14 ] loss: 0.3892386853694916 2022-07-01 01:38:09.199900
Epoch:[ 211 15 ] loss: 0.38800933957099915 2022-07-01 01:38:09.625211
Epoch:[ 211 16 ] loss: 0.38678109645843506 2022-07-01 01:38:15.279712
Epoch:[ 211 17 ] loss: 0.38791826367378235 2022-07-01 01:38:16.121929
Epoch:[ 211 18 ] loss: 0.3869093060493469 2022-07-01 01:38:16.542799
Epoch:[ 211 19 ] loss: 0.39029911160469055 2022-07-01 01:38:16.963703
Training_Epoch:[ 211 ] Training_loss: 0.3876878425478935 2022-07-01 01:38:16.964378
learning rate:  0.00046116860184273935
val: 1 0.4511542320251465
val: 2 0.447824090719223
val: 3 0.4526544511318207
val: 4 0.4288136065006256
val: 5 0.4526926577091217
val: 6 0.4531891644001007
val: 7 0.44682490825653076
val: 8 0.4309142827987671
val: 9 0.43350744247436523
val: 10 0.44263431429862976
val: 11 0.4479984939098358
val: 12 0.4389316737651825
val: 13 0.4450819790363312
val: 14 0.45165905356407166
val: 15 0.4436895251274109
val: 16 0.4331747591495514
val: 17 0.44032156467437744
val: 18 0.44587892293930054
val: 19 0.4454323351383209
val: 20 0.4402182102203369
val_Epoch:[ 211 ] val_loss: 0.4436297833919525 2022-07-01 01:38:20.776875
start training 2022-07-01 01:38:20.877174
Epoch:[ 212 0 ] loss: 0.3839074671268463 2022-07-01 01:38:35.100182
Epoch:[ 212 1 ] loss: 0.3891200125217438 2022-07-01 01:38:35.784351
Epoch:[ 212 2 ] loss: 0.38583987951278687 2022-07-01 01:38:36.207413
Epoch:[ 212 3 ] loss: 0.3866562247276306 2022-07-01 01:38:36.631571
Epoch:[ 212 4 ] loss: 0.3873416483402252 2022-07-01 01:38:37.052043
Epoch:[ 212 5 ] loss: 0.3873063623905182 2022-07-01 01:38:37.473303
Epoch:[ 212 6 ] loss: 0.3880719244480133 2022-07-01 01:38:37.896220
Epoch:[ 212 7 ] loss: 0.38813525438308716 2022-07-01 01:38:38.320249
Epoch:[ 212 8 ] loss: 0.389227956533432 2022-07-01 01:38:38.743242
Epoch:[ 212 9 ] loss: 0.3880079984664917 2022-07-01 01:38:39.160525
Epoch:[ 212 10 ] loss: 0.38764655590057373 2022-07-01 01:38:39.586004
Epoch:[ 212 11 ] loss: 0.38618239760398865 2022-07-01 01:38:40.009353
Epoch:[ 212 12 ] loss: 0.3884146809577942 2022-07-01 01:38:40.429091
Epoch:[ 212 13 ] loss: 0.3876459002494812 2022-07-01 01:38:40.852047
Epoch:[ 212 14 ] loss: 0.38735994696617126 2022-07-01 01:38:41.274741
Epoch:[ 212 15 ] loss: 0.3873937129974365 2022-07-01 01:38:41.695778
Epoch:[ 212 16 ] loss: 0.3867228031158447 2022-07-01 01:38:47.865561
Epoch:[ 212 17 ] loss: 0.39101076126098633 2022-07-01 01:38:48.286078
Epoch:[ 212 18 ] loss: 0.38599827885627747 2022-07-01 01:38:48.707798
Epoch:[ 212 19 ] loss: 0.38621804118156433 2022-07-01 01:38:49.128578
Training_Epoch:[ 212 ] Training_loss: 0.38741039037704467 2022-07-01 01:38:49.129293
learning rate:  0.00046116860184273935
netparams have been saved once 212
val: 1 0.4353320598602295
val: 2 0.44677606225013733
val: 3 0.4507288634777069
val: 4 0.4440024495124817
val: 5 0.4412170350551605
val: 6 0.43605005741119385
val: 7 0.4410749077796936
val: 8 0.45260030031204224
val: 9 0.45472320914268494
val: 10 0.4420522451400757
val: 11 0.44756805896759033
val: 12 0.44784706830978394
val: 13 0.4520527124404907
val: 14 0.43187546730041504
val: 15 0.44206002354621887
val: 16 0.44238486886024475
val: 17 0.45212870836257935
val: 18 0.44355058670043945
val: 19 0.43569597601890564
val: 20 0.44293203949928284
val_Epoch:[ 212 ] val_loss: 0.4441326349973679 2022-07-01 01:38:53.022956
start training 2022-07-01 01:38:53.126160
Epoch:[ 213 0 ] loss: 0.3871748447418213 2022-07-01 01:39:07.424205
Epoch:[ 213 1 ] loss: 0.38714468479156494 2022-07-01 01:39:07.870755
Epoch:[ 213 2 ] loss: 0.3877304494380951 2022-07-01 01:39:08.288438
Epoch:[ 213 3 ] loss: 0.3873656988143921 2022-07-01 01:39:08.708747
Epoch:[ 213 4 ] loss: 0.38682493567466736 2022-07-01 01:39:09.129618
Epoch:[ 213 5 ] loss: 0.3892022967338562 2022-07-01 01:39:09.549368
Epoch:[ 213 6 ] loss: 0.38508692383766174 2022-07-01 01:39:09.969588
Epoch:[ 213 7 ] loss: 0.38683682680130005 2022-07-01 01:39:10.391611
Epoch:[ 213 8 ] loss: 0.3864177465438843 2022-07-01 01:39:10.814675
Epoch:[ 213 9 ] loss: 0.38697364926338196 2022-07-01 01:39:11.235963
Epoch:[ 213 10 ] loss: 0.3870392143726349 2022-07-01 01:39:11.655963
Epoch:[ 213 11 ] loss: 0.3876539468765259 2022-07-01 01:39:12.077507
Epoch:[ 213 12 ] loss: 0.3896429240703583 2022-07-01 01:39:12.498440
Epoch:[ 213 13 ] loss: 0.38739389181137085 2022-07-01 01:39:12.918181
Epoch:[ 213 14 ] loss: 0.3867015838623047 2022-07-01 01:39:13.340444
Epoch:[ 213 15 ] loss: 0.3874453008174896 2022-07-01 01:39:13.763246
Epoch:[ 213 16 ] loss: 0.3889268934726715 2022-07-01 01:39:19.487468
Epoch:[ 213 17 ] loss: 0.38875943422317505 2022-07-01 01:39:19.910134
Epoch:[ 213 18 ] loss: 0.38582295179367065 2022-07-01 01:39:20.331429
Epoch:[ 213 19 ] loss: 0.3869229257106781 2022-07-01 01:39:20.751994
Training_Epoch:[ 213 ] Training_loss: 0.3873533561825752 2022-07-01 01:39:20.752669
learning rate:  0.00046116860184273935
val: 1 0.4346814751625061
val: 2 0.44981464743614197
val: 3 0.44609612226486206
val: 4 0.44175073504447937
val: 5 0.4459620416164398
val: 6 0.43806129693984985
val: 7 0.4504915773868561
val: 8 0.44980108737945557
val: 9 0.44431859254837036
val: 10 0.44136178493499756
val: 11 0.44607558846473694
val: 12 0.4529801607131958
val: 13 0.4410783648490906
val: 14 0.4592849612236023
val: 15 0.44837310910224915
val: 16 0.4423747956752777
val: 17 0.4330003559589386
val: 18 0.42788243293762207
val: 19 0.4362386465072632
val: 20 0.4539506137371063
val_Epoch:[ 213 ] val_loss: 0.44417891949415206 2022-07-01 01:39:24.508903
start training 2022-07-01 01:39:24.609250
Epoch:[ 214 0 ] loss: 0.38664498925209045 2022-07-01 01:39:39.435377
Epoch:[ 214 1 ] loss: 0.3866277039051056 2022-07-01 01:39:39.857164
Epoch:[ 214 2 ] loss: 0.38741230964660645 2022-07-01 01:39:40.280116
Epoch:[ 214 3 ] loss: 0.38907474279403687 2022-07-01 01:39:40.701697
Epoch:[ 214 4 ] loss: 0.38792917132377625 2022-07-01 01:39:41.122907
Epoch:[ 214 5 ] loss: 0.3859749734401703 2022-07-01 01:39:41.544172
Epoch:[ 214 6 ] loss: 0.38647398352622986 2022-07-01 01:39:41.966270
Epoch:[ 214 7 ] loss: 0.3845372498035431 2022-07-01 01:39:42.385616
Epoch:[ 214 8 ] loss: 0.3868105709552765 2022-07-01 01:39:42.807543
Epoch:[ 214 9 ] loss: 0.3867923319339752 2022-07-01 01:39:43.230347
Epoch:[ 214 10 ] loss: 0.3873170018196106 2022-07-01 01:39:43.651828
Epoch:[ 214 11 ] loss: 0.3855831027030945 2022-07-01 01:39:44.076129
Epoch:[ 214 12 ] loss: 0.3861234188079834 2022-07-01 01:39:44.496992
Epoch:[ 214 13 ] loss: 0.3866455852985382 2022-07-01 01:39:44.917852
Epoch:[ 214 14 ] loss: 0.3888481855392456 2022-07-01 01:39:45.332143
Epoch:[ 214 15 ] loss: 0.38705405592918396 2022-07-01 01:39:45.753855
Epoch:[ 214 16 ] loss: 0.38830190896987915 2022-07-01 01:39:51.492154
Epoch:[ 214 17 ] loss: 0.3892023265361786 2022-07-01 01:39:51.912340
Epoch:[ 214 18 ] loss: 0.3881009519100189 2022-07-01 01:39:52.339672
Epoch:[ 214 19 ] loss: 0.38778573274612427 2022-07-01 01:39:52.760464
Training_Epoch:[ 214 ] Training_loss: 0.3871620148420334 2022-07-01 01:39:52.761179
learning rate:  0.00046116860184273935
netparams have been saved once 214
val: 1 0.4260486662387848
val: 2 0.4429314434528351
val: 3 0.44690588116645813
val: 4 0.4551270306110382
val: 5 0.440812349319458
val: 6 0.4440194070339203
val: 7 0.4456522762775421
val: 8 0.4473240375518799
val: 9 0.44207340478897095
val: 10 0.4637751877307892
val: 11 0.44589361548423767
val: 12 0.44822338223457336
val: 13 0.45811113715171814
val: 14 0.444254070520401
val: 15 0.43528613448143005
val: 16 0.4374319911003113
val: 17 0.435921847820282
val: 18 0.44036272168159485
val: 19 0.44141685962677
val: 20 0.44533881545066833
val_Epoch:[ 214 ] val_loss: 0.4443455129861832 2022-07-01 01:39:56.758057
start training 2022-07-01 01:39:56.863765
Epoch:[ 215 0 ] loss: 0.386529803276062 2022-07-01 01:40:11.758941
Epoch:[ 215 1 ] loss: 0.38709619641304016 2022-07-01 01:40:12.178989
Epoch:[ 215 2 ] loss: 0.3883775770664215 2022-07-01 01:40:12.602361
Epoch:[ 215 3 ] loss: 0.3869795799255371 2022-07-01 01:40:13.025985
Epoch:[ 215 4 ] loss: 0.3872235417366028 2022-07-01 01:40:13.449920
Epoch:[ 215 5 ] loss: 0.38811206817626953 2022-07-01 01:40:13.870019
Epoch:[ 215 6 ] loss: 0.3869423568248749 2022-07-01 01:40:14.284184
Epoch:[ 215 7 ] loss: 0.3856874108314514 2022-07-01 01:40:14.705067
Epoch:[ 215 8 ] loss: 0.38679108023643494 2022-07-01 01:40:15.125702
Epoch:[ 215 9 ] loss: 0.3846745193004608 2022-07-01 01:40:15.548200
Epoch:[ 215 10 ] loss: 0.3890949785709381 2022-07-01 01:40:15.969725
Epoch:[ 215 11 ] loss: 0.38873812556266785 2022-07-01 01:40:16.386777
Epoch:[ 215 12 ] loss: 0.38733839988708496 2022-07-01 01:40:16.807712
Epoch:[ 215 13 ] loss: 0.3855404257774353 2022-07-01 01:40:17.229901
Epoch:[ 215 14 ] loss: 0.38654375076293945 2022-07-01 01:40:17.651523
Epoch:[ 215 15 ] loss: 0.38615602254867554 2022-07-01 01:40:18.071959
Epoch:[ 215 16 ] loss: 0.3877929747104645 2022-07-01 01:40:23.524263
Epoch:[ 215 17 ] loss: 0.3860864043235779 2022-07-01 01:40:23.947358
Epoch:[ 215 18 ] loss: 0.38836169242858887 2022-07-01 01:40:24.369695
Epoch:[ 215 19 ] loss: 0.3883993625640869 2022-07-01 01:40:24.794806
Training_Epoch:[ 215 ] Training_loss: 0.38712331354618074 2022-07-01 01:40:24.795511
learning rate:  0.00046116860184273935
val: 1 0.4474509656429291
val: 2 0.45815423130989075
val: 3 0.4412909746170044
val: 4 0.45151278376579285
val: 5 0.4409903585910797
val: 6 0.45446279644966125
val: 7 0.4294987618923187
val: 8 0.44475919008255005
val: 9 0.4596722722053528
val: 10 0.42893052101135254
val: 11 0.4326663017272949
val: 12 0.45351696014404297
val: 13 0.44205811619758606
val: 14 0.44005605578422546
val: 15 0.4402359127998352
val: 16 0.45153263211250305
val: 17 0.43825775384902954
val: 18 0.4458877444267273
val: 19 0.44741472601890564
val: 20 0.4392234981060028
val_Epoch:[ 215 ] val_loss: 0.44437862783670423 2022-07-01 01:40:28.638916
start training 2022-07-01 01:40:28.738854
Epoch:[ 216 0 ] loss: 0.38760513067245483 2022-07-01 01:40:43.094161
Epoch:[ 216 1 ] loss: 0.38754358887672424 2022-07-01 01:40:43.537121
Epoch:[ 216 2 ] loss: 0.38628366589546204 2022-07-01 01:40:43.957778
Epoch:[ 216 3 ] loss: 0.38765713572502136 2022-07-01 01:40:44.378125
Epoch:[ 216 4 ] loss: 0.38620299100875854 2022-07-01 01:40:44.800797
Epoch:[ 216 5 ] loss: 0.3849809765815735 2022-07-01 01:40:45.221420
Epoch:[ 216 6 ] loss: 0.3860127925872803 2022-07-01 01:40:45.635426
Epoch:[ 216 7 ] loss: 0.38620731234550476 2022-07-01 01:40:46.056315
Epoch:[ 216 8 ] loss: 0.38728752732276917 2022-07-01 01:40:46.475028
Epoch:[ 216 9 ] loss: 0.3856886923313141 2022-07-01 01:40:46.894514
Epoch:[ 216 10 ] loss: 0.3891257345676422 2022-07-01 01:40:47.316765
Epoch:[ 216 11 ] loss: 0.38953661918640137 2022-07-01 01:40:47.739200
Epoch:[ 216 12 ] loss: 0.3875863552093506 2022-07-01 01:40:48.159540
Epoch:[ 216 13 ] loss: 0.3888569176197052 2022-07-01 01:40:48.578749
Epoch:[ 216 14 ] loss: 0.38627615571022034 2022-07-01 01:40:49.000192
Epoch:[ 216 15 ] loss: 0.38733524084091187 2022-07-01 01:40:49.419594
Epoch:[ 216 16 ] loss: 0.3854689300060272 2022-07-01 01:40:55.051531
Epoch:[ 216 17 ] loss: 0.385964035987854 2022-07-01 01:40:55.471649
Epoch:[ 216 18 ] loss: 0.38733211159706116 2022-07-01 01:40:55.900336
Epoch:[ 216 19 ] loss: 0.38749316334724426 2022-07-01 01:40:56.320561
Training_Epoch:[ 216 ] Training_loss: 0.38702225387096406 2022-07-01 01:40:56.321268
learning rate:  0.00046116860184273935
netparams have been saved once 216
val: 1 0.43537798523902893
val: 2 0.4390512704849243
val: 3 0.4450875520706177
val: 4 0.4496760964393616
val: 5 0.437857985496521
val: 6 0.4362586736679077
val: 7 0.44866564869880676
val: 8 0.4458538889884949
val: 9 0.4487716257572174
val: 10 0.4348476231098175
val: 11 0.4489765167236328
val: 12 0.4598902463912964
val: 13 0.43764176964759827
val: 14 0.43417465686798096
val: 15 0.4479013681411743
val: 16 0.4461187422275543
val: 17 0.4479708671569824
val: 18 0.46292340755462646
val: 19 0.4421263337135315
val: 20 0.4408532679080963
val_Epoch:[ 216 ] val_loss: 0.44450127631425856 2022-07-01 01:41:00.216825
start training 2022-07-01 01:41:00.319938
Epoch:[ 217 0 ] loss: 0.3860955238342285 2022-07-01 01:41:14.353629
Epoch:[ 217 1 ] loss: 0.38690871000289917 2022-07-01 01:41:14.781449
Epoch:[ 217 2 ] loss: 0.38769474625587463 2022-07-01 01:41:15.238977
Epoch:[ 217 3 ] loss: 0.3872033953666687 2022-07-01 01:41:15.659529
Epoch:[ 217 4 ] loss: 0.3895159363746643 2022-07-01 01:41:16.080666
Epoch:[ 217 5 ] loss: 0.3879994750022888 2022-07-01 01:41:16.503253
Epoch:[ 217 6 ] loss: 0.3864637315273285 2022-07-01 01:41:16.924643
Epoch:[ 217 7 ] loss: 0.3864372968673706 2022-07-01 01:41:17.344488
Epoch:[ 217 8 ] loss: 0.39158162474632263 2022-07-01 01:41:17.759301
Epoch:[ 217 9 ] loss: 0.38670653104782104 2022-07-01 01:41:18.178447
Epoch:[ 217 10 ] loss: 0.3863600492477417 2022-07-01 01:41:18.598067
Epoch:[ 217 11 ] loss: 0.3850153684616089 2022-07-01 01:41:19.019946
Epoch:[ 217 12 ] loss: 0.3864908516407013 2022-07-01 01:41:19.442267
Epoch:[ 217 13 ] loss: 0.3874591588973999 2022-07-01 01:41:19.863306
Epoch:[ 217 14 ] loss: 0.38842931389808655 2022-07-01 01:41:20.285509
Epoch:[ 217 15 ] loss: 0.385093092918396 2022-07-01 01:41:20.706101
Epoch:[ 217 16 ] loss: 0.3880614936351776 2022-07-01 01:41:26.360049
Epoch:[ 217 17 ] loss: 0.3876792788505554 2022-07-01 01:41:26.779412
Epoch:[ 217 18 ] loss: 0.38766148686408997 2022-07-01 01:41:27.201442
Epoch:[ 217 19 ] loss: 0.3894115090370178 2022-07-01 01:41:27.623126
Training_Epoch:[ 217 ] Training_loss: 0.3874134287238121 2022-07-01 01:41:27.623794
learning rate:  0.00046116860184273935
val: 1 0.4448889493942261
val: 2 0.44749096035957336
val: 3 0.4419343173503876
val: 4 0.4433566927909851
val: 5 0.43394964933395386
val: 6 0.43840914964675903
val: 7 0.43292203545570374
val: 8 0.4364444613456726
val: 9 0.4386000633239746
val: 10 0.451788067817688
val: 11 0.4468807578086853
val: 12 0.4483655095100403
val: 13 0.44120877981185913
val: 14 0.44540539383888245
val: 15 0.4469492435455322
val: 16 0.4521298110485077
val: 17 0.44120192527770996
val: 18 0.46362319588661194
val: 19 0.4547806680202484
val: 20 0.45473331212997437
val_Epoch:[ 217 ] val_loss: 0.44525314718484876 2022-07-01 01:41:31.380071
start training 2022-07-01 01:41:31.484631
Epoch:[ 218 0 ] loss: 0.387062668800354 2022-07-01 01:41:46.275096
Epoch:[ 218 1 ] loss: 0.3880089223384857 2022-07-01 01:41:46.695010
Epoch:[ 218 2 ] loss: 0.3877682685852051 2022-07-01 01:41:47.116104
Epoch:[ 218 3 ] loss: 0.38932716846466064 2022-07-01 01:41:47.540593
Epoch:[ 218 4 ] loss: 0.38679420948028564 2022-07-01 01:41:47.960432
Epoch:[ 218 5 ] loss: 0.3872988224029541 2022-07-01 01:41:48.382485
Epoch:[ 218 6 ] loss: 0.388508141040802 2022-07-01 01:41:48.798124
Epoch:[ 218 7 ] loss: 0.3888286054134369 2022-07-01 01:41:49.219534
Epoch:[ 218 8 ] loss: 0.38695162534713745 2022-07-01 01:41:49.641344
Epoch:[ 218 9 ] loss: 0.3842027485370636 2022-07-01 01:41:50.055094
Epoch:[ 218 10 ] loss: 0.38616377115249634 2022-07-01 01:41:50.476747
Epoch:[ 218 11 ] loss: 0.3863886594772339 2022-07-01 01:41:50.897247
Epoch:[ 218 12 ] loss: 0.3874998390674591 2022-07-01 01:41:51.319102
Epoch:[ 218 13 ] loss: 0.3882395029067993 2022-07-01 01:41:51.740899
Epoch:[ 218 14 ] loss: 0.3865875005722046 2022-07-01 01:41:52.163434
Epoch:[ 218 15 ] loss: 0.38796475529670715 2022-07-01 01:41:52.583742
Epoch:[ 218 16 ] loss: 0.3879050016403198 2022-07-01 01:41:57.468595
Epoch:[ 218 17 ] loss: 0.3878895938396454 2022-07-01 01:41:57.887894
Epoch:[ 218 18 ] loss: 0.3872252404689789 2022-07-01 01:41:58.308223
Epoch:[ 218 19 ] loss: 0.38753238320350647 2022-07-01 01:41:58.731700
Training_Epoch:[ 218 ] Training_loss: 0.3874073714017868 2022-07-01 01:41:58.732396
learning rate:  0.00046116860184273935
netparams have been saved once 218
val: 1 0.45031312108039856
val: 2 0.45442381501197815
val: 3 0.44107499718666077
val: 4 0.44319501519203186
val: 5 0.45741572976112366
val: 6 0.443145215511322
val: 7 0.43596917390823364
val: 8 0.4384973645210266
val: 9 0.44122830033302307
val: 10 0.44224125146865845
val: 11 0.45520514249801636
val: 12 0.447218656539917
val: 13 0.43836280703544617
val: 14 0.44469329714775085
val: 15 0.4320342540740967
val: 16 0.43405207991600037
val: 17 0.4405244290828705
val: 18 0.456320583820343
val: 19 0.4534653425216675
val: 20 0.4438815116882324
val_Epoch:[ 218 ] val_loss: 0.4446631044149399 2022-07-01 01:42:02.525699
start training 2022-07-01 01:42:02.626099
Epoch:[ 219 0 ] loss: 0.3892233073711395 2022-07-01 01:42:16.489133
Epoch:[ 219 1 ] loss: 0.3882112503051758 2022-07-01 01:42:17.137330
Epoch:[ 219 2 ] loss: 0.3884391486644745 2022-07-01 01:42:17.558483
Epoch:[ 219 3 ] loss: 0.3848523199558258 2022-07-01 01:42:17.979679
Epoch:[ 219 4 ] loss: 0.38514041900634766 2022-07-01 01:42:18.399211
Epoch:[ 219 5 ] loss: 0.38847416639328003 2022-07-01 01:42:18.812898
Epoch:[ 219 6 ] loss: 0.3866349458694458 2022-07-01 01:42:19.235607
Epoch:[ 219 7 ] loss: 0.3893411159515381 2022-07-01 01:42:19.658694
Epoch:[ 219 8 ] loss: 0.3893074691295624 2022-07-01 01:42:20.079677
Epoch:[ 219 9 ] loss: 0.387127161026001 2022-07-01 01:42:20.501218
Epoch:[ 219 10 ] loss: 0.38776108622550964 2022-07-01 01:42:20.921235
Epoch:[ 219 11 ] loss: 0.386617511510849 2022-07-01 01:42:21.344778
Epoch:[ 219 12 ] loss: 0.38715028762817383 2022-07-01 01:42:21.764174
Epoch:[ 219 13 ] loss: 0.38615095615386963 2022-07-01 01:42:22.186540
Epoch:[ 219 14 ] loss: 0.38633179664611816 2022-07-01 01:42:22.608099
Epoch:[ 219 15 ] loss: 0.3860434889793396 2022-07-01 01:42:23.028634
Epoch:[ 219 16 ] loss: 0.38790789246559143 2022-07-01 01:42:28.351340
Epoch:[ 219 17 ] loss: 0.3848600685596466 2022-07-01 01:42:29.233456
Epoch:[ 219 18 ] loss: 0.3843954801559448 2022-07-01 01:42:29.654808
Epoch:[ 219 19 ] loss: 0.38852930068969727 2022-07-01 01:42:30.073725
Training_Epoch:[ 219 ] Training_loss: 0.3871249586343765 2022-07-01 01:42:30.074366
learning rate:  0.00046116860184273935
val: 1 0.43527576327323914
val: 2 0.45234760642051697
val: 3 0.46123361587524414
val: 4 0.4390944242477417
val: 5 0.4373639225959778
val: 6 0.43762966990470886
val: 7 0.44903093576431274
val: 8 0.4321649968624115
val: 9 0.4381871223449707
val: 10 0.4377686381340027
val: 11 0.4432283639907837
val: 12 0.44300419092178345
val: 13 0.44995447993278503
val: 14 0.43575751781463623
val: 15 0.4544842541217804
val: 16 0.45555558800697327
val: 17 0.44223642349243164
val: 18 0.45829591155052185
val: 19 0.4512448310852051
val: 20 0.4417278468608856
val_Epoch:[ 219 ] val_loss: 0.4447793051600456 2022-07-01 01:42:33.787056
start training 2022-07-01 01:42:33.886763
Epoch:[ 220 0 ] loss: 0.3867550492286682 2022-07-01 01:42:48.335995
Epoch:[ 220 1 ] loss: 0.3880901336669922 2022-07-01 01:42:48.782491
Epoch:[ 220 2 ] loss: 0.38485267758369446 2022-07-01 01:42:49.195087
Epoch:[ 220 3 ] loss: 0.38817980885505676 2022-07-01 01:42:49.601729
Epoch:[ 220 4 ] loss: 0.3876965641975403 2022-07-01 01:42:50.010861
Epoch:[ 220 5 ] loss: 0.38925862312316895 2022-07-01 01:42:50.419113
Epoch:[ 220 6 ] loss: 0.38457682728767395 2022-07-01 01:42:50.826409
Epoch:[ 220 7 ] loss: 0.38624924421310425 2022-07-01 01:42:51.236966
Epoch:[ 220 8 ] loss: 0.38776516914367676 2022-07-01 01:42:51.645672
Epoch:[ 220 9 ] loss: 0.3871769607067108 2022-07-01 01:42:52.056911
Epoch:[ 220 10 ] loss: 0.3866274356842041 2022-07-01 01:42:52.464831
Epoch:[ 220 11 ] loss: 0.38955435156822205 2022-07-01 01:42:52.873716
Epoch:[ 220 12 ] loss: 0.3874485492706299 2022-07-01 01:42:53.281225
Epoch:[ 220 13 ] loss: 0.3878963589668274 2022-07-01 01:42:53.694617
Epoch:[ 220 14 ] loss: 0.3848996162414551 2022-07-01 01:42:54.104517
Epoch:[ 220 15 ] loss: 0.3859662711620331 2022-07-01 01:42:54.515756
Epoch:[ 220 16 ] loss: 0.386199027299881 2022-07-01 01:43:00.010297
Epoch:[ 220 17 ] loss: 0.388028621673584 2022-07-01 01:43:00.417589
Epoch:[ 220 18 ] loss: 0.38822996616363525 2022-07-01 01:43:00.837684
Epoch:[ 220 19 ] loss: 0.38646399974823 2022-07-01 01:43:01.256632
Training_Epoch:[ 220 ] Training_loss: 0.3870957627892494 2022-07-01 01:43:01.257421
learning rate:  0.00046116860184273935
netparams have been saved once 220
val: 1 0.45054376125335693
val: 2 0.44759777188301086
val: 3 0.450419157743454
val: 4 0.4540272057056427
val: 5 0.44906970858573914
val: 6 0.43959933519363403
val: 7 0.44129011034965515
val: 8 0.4317222833633423
val: 9 0.4462807774543762
val: 10 0.445059597492218
val: 11 0.4384142756462097
val: 12 0.4442399740219116
val: 13 0.43546050786972046
val: 14 0.43799301981925964
val: 15 0.4455054700374603
val: 16 0.4471043050289154
val: 17 0.43427619338035583
val: 18 0.4406416714191437
val: 19 0.4571879506111145
val: 20 0.4539106786251068
val_Epoch:[ 220 ] val_loss: 0.44451718777418137 2022-07-01 01:43:05.108598
start training 2022-07-01 01:43:05.211198
Epoch:[ 221 0 ] loss: 0.38761666417121887 2022-07-01 01:43:20.069508
Epoch:[ 221 1 ] loss: 0.38630303740501404 2022-07-01 01:43:20.491344
Epoch:[ 221 2 ] loss: 0.385094553232193 2022-07-01 01:43:20.906847
Epoch:[ 221 3 ] loss: 0.3843000829219818 2022-07-01 01:43:21.329661
Epoch:[ 221 4 ] loss: 0.3869457542896271 2022-07-01 01:43:21.751590
Epoch:[ 221 5 ] loss: 0.38567879796028137 2022-07-01 01:43:22.171083
Epoch:[ 221 6 ] loss: 0.38653263449668884 2022-07-01 01:43:22.592093
Epoch:[ 221 7 ] loss: 0.3894537091255188 2022-07-01 01:43:23.010974
Epoch:[ 221 8 ] loss: 0.3854864239692688 2022-07-01 01:43:23.433108
Epoch:[ 221 9 ] loss: 0.3849421739578247 2022-07-01 01:43:23.857914
Epoch:[ 221 10 ] loss: 0.3865908086299896 2022-07-01 01:43:24.278350
Epoch:[ 221 11 ] loss: 0.3862341344356537 2022-07-01 01:43:24.698252
Epoch:[ 221 12 ] loss: 0.3868069052696228 2022-07-01 01:43:25.117424
Epoch:[ 221 13 ] loss: 0.3876499533653259 2022-07-01 01:43:25.538314
Epoch:[ 221 14 ] loss: 0.3862135112285614 2022-07-01 01:43:25.958155
Epoch:[ 221 15 ] loss: 0.38751572370529175 2022-07-01 01:43:26.380247
Epoch:[ 221 16 ] loss: 0.38927003741264343 2022-07-01 01:43:31.598464
Epoch:[ 221 17 ] loss: 0.3876466453075409 2022-07-01 01:43:32.017506
Epoch:[ 221 18 ] loss: 0.3880463242530823 2022-07-01 01:43:32.437853
Epoch:[ 221 19 ] loss: 0.3877210319042206 2022-07-01 01:43:32.858217
Training_Epoch:[ 221 ] Training_loss: 0.3868024453520775 2022-07-01 01:43:32.858912
learning rate:  0.0003689348814741915
val: 1 0.44447198510169983
val: 2 0.4508514106273651
val: 3 0.4463462829589844
val: 4 0.4552164375782013
val: 5 0.4377802014350891
val: 6 0.43853455781936646
val: 7 0.45160871744155884
val: 8 0.437734991312027
val: 9 0.4481351673603058
val: 10 0.45109593868255615
val: 11 0.4361971914768219
val: 12 0.43422770500183105
val: 13 0.43762362003326416
val: 14 0.45948877930641174
val: 15 0.438933789730072
val: 16 0.4582465887069702
val: 17 0.4496959447860718
val: 18 0.4396766424179077
val: 19 0.4346555471420288
val: 20 0.44219517707824707
val_Epoch:[ 221 ] val_loss: 0.444635833799839 2022-07-01 01:43:36.600623
start training 2022-07-01 01:43:36.698915
Epoch:[ 222 0 ] loss: 0.3872336745262146 2022-07-01 01:43:50.698325
Epoch:[ 222 1 ] loss: 0.3853541612625122 2022-07-01 01:43:51.246354
Epoch:[ 222 2 ] loss: 0.38695138692855835 2022-07-01 01:43:51.668419
Epoch:[ 222 3 ] loss: 0.38511526584625244 2022-07-01 01:43:52.089405
Epoch:[ 222 4 ] loss: 0.3874620199203491 2022-07-01 01:43:52.513079
Epoch:[ 222 5 ] loss: 0.38660556077957153 2022-07-01 01:43:52.934475
Epoch:[ 222 6 ] loss: 0.3839910924434662 2022-07-01 01:43:53.356079
Epoch:[ 222 7 ] loss: 0.38574525713920593 2022-07-01 01:43:53.769856
Epoch:[ 222 8 ] loss: 0.3876917362213135 2022-07-01 01:43:54.189559
Epoch:[ 222 9 ] loss: 0.3880525529384613 2022-07-01 01:43:54.610820
Epoch:[ 222 10 ] loss: 0.38777151703834534 2022-07-01 01:43:55.032506
Epoch:[ 222 11 ] loss: 0.3850604295730591 2022-07-01 01:43:55.454250
Epoch:[ 222 12 ] loss: 0.3878142237663269 2022-07-01 01:43:55.874082
Epoch:[ 222 13 ] loss: 0.38759636878967285 2022-07-01 01:43:56.293629
Epoch:[ 222 14 ] loss: 0.38648977875709534 2022-07-01 01:43:56.713685
Epoch:[ 222 15 ] loss: 0.38781094551086426 2022-07-01 01:43:57.132797
Epoch:[ 222 16 ] loss: 0.388854444026947 2022-07-01 01:44:02.559675
Epoch:[ 222 17 ] loss: 0.38778427243232727 2022-07-01 01:44:02.981100
Epoch:[ 222 18 ] loss: 0.38658392429351807 2022-07-01 01:44:03.402664
Epoch:[ 222 19 ] loss: 0.38614025712013245 2022-07-01 01:44:03.823209
Training_Epoch:[ 222 ] Training_loss: 0.38680544346570966 2022-07-01 01:44:03.823849
learning rate:  0.0003689348814741915
netparams have been saved once 222
val: 1 0.4507789611816406
val: 2 0.43563973903656006
val: 3 0.4513736665248871
val: 4 0.445575088262558
val: 5 0.44376233220100403
val: 6 0.4445963203907013
val: 7 0.44306641817092896
val: 8 0.45467573404312134
val: 9 0.44400230050086975
val: 10 0.4370245933532715
val: 11 0.4595244526863098
val: 12 0.4622021019458771
val: 13 0.4417683780193329
val: 14 0.43517374992370605
val: 15 0.43726909160614014
val: 16 0.4374990463256836
val: 17 0.4394741654396057
val: 18 0.44384950399398804
val: 19 0.4378608465194702
val: 20 0.45435306429862976
val_Epoch:[ 222 ] val_loss: 0.4449734777212143 2022-07-01 01:44:07.591167
start training 2022-07-01 01:44:07.690207
Epoch:[ 223 0 ] loss: 0.38852348923683167 2022-07-01 01:44:22.203425
Epoch:[ 223 1 ] loss: 0.38799673318862915 2022-07-01 01:44:22.624706
Epoch:[ 223 2 ] loss: 0.3882795572280884 2022-07-01 01:44:23.044951
Epoch:[ 223 3 ] loss: 0.3874293863773346 2022-07-01 01:44:23.467444
Epoch:[ 223 4 ] loss: 0.3839839696884155 2022-07-01 01:44:23.889163
Epoch:[ 223 5 ] loss: 0.38529807329177856 2022-07-01 01:44:24.310492
Epoch:[ 223 6 ] loss: 0.38606297969818115 2022-07-01 01:44:24.735362
Epoch:[ 223 7 ] loss: 0.3869115114212036 2022-07-01 01:44:25.150253
Epoch:[ 223 8 ] loss: 0.38464751839637756 2022-07-01 01:44:25.570260
Epoch:[ 223 9 ] loss: 0.3890584111213684 2022-07-01 01:44:25.990143
Epoch:[ 223 10 ] loss: 0.38904818892478943 2022-07-01 01:44:26.412022
Epoch:[ 223 11 ] loss: 0.38592395186424255 2022-07-01 01:44:26.834230
Epoch:[ 223 12 ] loss: 0.3865363895893097 2022-07-01 01:44:27.258228
Epoch:[ 223 13 ] loss: 0.3876132667064667 2022-07-01 01:44:27.679068
Epoch:[ 223 14 ] loss: 0.38629037141799927 2022-07-01 01:44:28.101258
Epoch:[ 223 15 ] loss: 0.3854450285434723 2022-07-01 01:44:28.516125
Epoch:[ 223 16 ] loss: 0.3869825303554535 2022-07-01 01:44:33.956909
Epoch:[ 223 17 ] loss: 0.3870798349380493 2022-07-01 01:44:34.377972
Epoch:[ 223 18 ] loss: 0.3860795497894287 2022-07-01 01:44:34.807018
Epoch:[ 223 19 ] loss: 0.3867453634738922 2022-07-01 01:44:35.228162
Training_Epoch:[ 223 ] Training_loss: 0.3867968052625656 2022-07-01 01:44:35.228913
learning rate:  0.0003689348814741915
val: 1 0.4603566527366638
val: 2 0.45018139481544495
val: 3 0.4432376027107239
val: 4 0.42566046118736267
val: 5 0.44089528918266296
val: 6 0.44611504673957825
val: 7 0.44578006863594055
val: 8 0.4415544867515564
val: 9 0.4397936165332794
val: 10 0.4500657618045807
val: 11 0.4484381079673767
val: 12 0.4438585638999939
val: 13 0.4412063658237457
val: 14 0.4513948857784271
val: 15 0.4615572690963745
val: 16 0.4352620840072632
val: 17 0.4288029074668884
val: 18 0.4394579827785492
val: 19 0.45266205072402954
val: 20 0.4363694489002228
val_Epoch:[ 223 ] val_loss: 0.4441325023770332 2022-07-01 01:44:38.998993
start training 2022-07-01 01:44:39.101632
Epoch:[ 224 0 ] loss: 0.38810157775878906 2022-07-01 01:44:54.110966
Epoch:[ 224 1 ] loss: 0.3842599391937256 2022-07-01 01:44:54.525741
Epoch:[ 224 2 ] loss: 0.38683801889419556 2022-07-01 01:44:54.946021
Epoch:[ 224 3 ] loss: 0.38725730776786804 2022-07-01 01:44:55.366113
Epoch:[ 224 4 ] loss: 0.3857414722442627 2022-07-01 01:44:55.787381
Epoch:[ 224 5 ] loss: 0.3909192383289337 2022-07-01 01:44:56.209655
Epoch:[ 224 6 ] loss: 0.38554564118385315 2022-07-01 01:44:56.631122
Epoch:[ 224 7 ] loss: 0.38808009028434753 2022-07-01 01:44:57.051658
Epoch:[ 224 8 ] loss: 0.38586676120758057 2022-07-01 01:44:57.465682
Epoch:[ 224 9 ] loss: 0.38561415672302246 2022-07-01 01:44:57.876625
Epoch:[ 224 10 ] loss: 0.3869893550872803 2022-07-01 01:44:58.285383
Epoch:[ 224 11 ] loss: 0.38632097840309143 2022-07-01 01:44:58.697591
Epoch:[ 224 12 ] loss: 0.38722291588783264 2022-07-01 01:44:59.108988
Epoch:[ 224 13 ] loss: 0.38773244619369507 2022-07-01 01:44:59.518293
Epoch:[ 224 14 ] loss: 0.38783660531044006 2022-07-01 01:44:59.927264
Epoch:[ 224 15 ] loss: 0.3867700397968292 2022-07-01 01:45:00.343320
Epoch:[ 224 16 ] loss: 0.38603919744491577 2022-07-01 01:45:05.414489
Epoch:[ 224 17 ] loss: 0.38584786653518677 2022-07-01 01:45:05.823651
Epoch:[ 224 18 ] loss: 0.38647258281707764 2022-07-01 01:45:06.235846
Epoch:[ 224 19 ] loss: 0.3868541419506073 2022-07-01 01:45:06.646455
Training_Epoch:[ 224 ] Training_loss: 0.3868155166506767 2022-07-01 01:45:06.647549
learning rate:  0.0003689348814741915
netparams have been saved once 224
val: 1 0.4452311098575592
val: 2 0.450417160987854
val: 3 0.44024303555488586
val: 4 0.4453214108943939
val: 5 0.44748595356941223
val: 6 0.44667863845825195
val: 7 0.4286383390426636
val: 8 0.44579002261161804
val: 9 0.43944796919822693
val: 10 0.4693138599395752
val: 11 0.4403727054595947
val: 12 0.43988993763923645
val: 13 0.4501991271972656
val: 14 0.4495038390159607
val: 15 0.4492715895175934
val: 16 0.4514746367931366
val: 17 0.43800288438796997
val: 18 0.437623530626297
val: 19 0.44173941016197205
val: 20 0.4456980526447296
val_Epoch:[ 224 ] val_loss: 0.44511716067790985 2022-07-01 01:45:10.529878
start training 2022-07-01 01:45:10.629649
Epoch:[ 225 0 ] loss: 0.38463401794433594 2022-07-01 01:45:25.730892
Epoch:[ 225 1 ] loss: 0.3850076496601105 2022-07-01 01:45:26.140506
Epoch:[ 225 2 ] loss: 0.3853071331977844 2022-07-01 01:45:26.549742
Epoch:[ 225 3 ] loss: 0.38545554876327515 2022-07-01 01:45:26.961465
Epoch:[ 225 4 ] loss: 0.38640207052230835 2022-07-01 01:45:27.370564
Epoch:[ 225 5 ] loss: 0.38813167810440063 2022-07-01 01:45:27.780846
Epoch:[ 225 6 ] loss: 0.38579705357551575 2022-07-01 01:45:28.191047
Epoch:[ 225 7 ] loss: 0.3880632519721985 2022-07-01 01:45:28.600815
Epoch:[ 225 8 ] loss: 0.38647592067718506 2022-07-01 01:45:29.010781
Epoch:[ 225 9 ] loss: 0.3866775929927826 2022-07-01 01:45:29.425761
Epoch:[ 225 10 ] loss: 0.38697850704193115 2022-07-01 01:45:29.836208
Epoch:[ 225 11 ] loss: 0.38662829995155334 2022-07-01 01:45:30.244168
Epoch:[ 225 12 ] loss: 0.38652339577674866 2022-07-01 01:45:30.654845
Epoch:[ 225 13 ] loss: 0.38732102513313293 2022-07-01 01:45:31.063936
Epoch:[ 225 14 ] loss: 0.3854813277721405 2022-07-01 01:45:31.472012
Epoch:[ 225 15 ] loss: 0.38788384199142456 2022-07-01 01:45:31.887889
Epoch:[ 225 16 ] loss: 0.385687917470932 2022-07-01 01:45:37.184514
Epoch:[ 225 17 ] loss: 0.3884653151035309 2022-07-01 01:45:37.602957
Epoch:[ 225 18 ] loss: 0.38804906606674194 2022-07-01 01:45:38.029769
Epoch:[ 225 19 ] loss: 0.3895789682865143 2022-07-01 01:45:38.452724
Training_Epoch:[ 225 ] Training_loss: 0.38672747910022737 2022-07-01 01:45:38.453544
learning rate:  0.0003689348814741915
val: 1 0.45053598284721375
val: 2 0.43613529205322266
val: 3 0.439250111579895
val: 4 0.4486260414123535
val: 5 0.44238507747650146
val: 6 0.4526546895503998
val: 7 0.4635359048843384
val: 8 0.44140419363975525
val: 9 0.4485374689102173
val: 10 0.4543862044811249
val: 11 0.4457148313522339
val: 12 0.43452462553977966
val: 13 0.43457019329071045
val: 14 0.4478706121444702
val: 15 0.44483327865600586
val: 16 0.4434899091720581
val: 17 0.4487253427505493
val: 18 0.4279373288154602
val: 19 0.44012346863746643
val: 20 0.4429780840873718
val_Epoch:[ 225 ] val_loss: 0.4444109320640564 2022-07-01 01:45:42.292741
start training 2022-07-01 01:45:42.393803
Epoch:[ 226 0 ] loss: 0.3856964111328125 2022-07-01 01:45:56.810710
Epoch:[ 226 1 ] loss: 0.38710981607437134 2022-07-01 01:45:57.221353
Epoch:[ 226 2 ] loss: 0.3869311511516571 2022-07-01 01:45:57.630618
Epoch:[ 226 3 ] loss: 0.3874056935310364 2022-07-01 01:45:58.040575
Epoch:[ 226 4 ] loss: 0.386412650346756 2022-07-01 01:45:58.450152
Epoch:[ 226 5 ] loss: 0.387692391872406 2022-07-01 01:45:58.864910
Epoch:[ 226 6 ] loss: 0.38554179668426514 2022-07-01 01:45:59.276321
Epoch:[ 226 7 ] loss: 0.3879110813140869 2022-07-01 01:45:59.686153
Epoch:[ 226 8 ] loss: 0.3872615396976471 2022-07-01 01:46:00.096491
Epoch:[ 226 9 ] loss: 0.38550224900245667 2022-07-01 01:46:00.504903
Epoch:[ 226 10 ] loss: 0.38593193888664246 2022-07-01 01:46:00.917367
Epoch:[ 226 11 ] loss: 0.38563084602355957 2022-07-01 01:46:01.327892
Epoch:[ 226 12 ] loss: 0.384736567735672 2022-07-01 01:46:01.735732
Epoch:[ 226 13 ] loss: 0.38342297077178955 2022-07-01 01:46:02.144573
Epoch:[ 226 14 ] loss: 0.3870212435722351 2022-07-01 01:46:02.555638
Epoch:[ 226 15 ] loss: 0.38451147079467773 2022-07-01 01:46:02.965006
Epoch:[ 226 16 ] loss: 0.38807937502861023 2022-07-01 01:46:08.853010
Epoch:[ 226 17 ] loss: 0.3878695070743561 2022-07-01 01:46:09.262134
Epoch:[ 226 18 ] loss: 0.38950175046920776 2022-07-01 01:46:09.679316
Epoch:[ 226 19 ] loss: 0.3888055384159088 2022-07-01 01:46:10.087560
Training_Epoch:[ 226 ] Training_loss: 0.3866487994790077 2022-07-01 01:46:10.088516
learning rate:  0.0003689348814741915
netparams have been saved once 226
val: 1 0.44024965167045593
val: 2 0.448371946811676
val: 3 0.44203194975852966
val: 4 0.45675843954086304
val: 5 0.43445488810539246
val: 6 0.4435904324054718
val: 7 0.44490689039230347
val: 8 0.45110735297203064
val: 9 0.4415583610534668
val: 10 0.4362584948539734
val: 11 0.4347158372402191
val: 12 0.45618054270744324
val: 13 0.4534910321235657
val: 14 0.4417552947998047
val: 15 0.44283443689346313
val: 16 0.444527268409729
val: 17 0.44883590936660767
val: 18 0.44871780276298523
val: 19 0.44138064980506897
val: 20 0.4455051124095917
val_Epoch:[ 226 ] val_loss: 0.4448616147041321 2022-07-01 01:46:14.141620
start training 2022-07-01 01:46:14.242486
Epoch:[ 227 0 ] loss: 0.38575324416160583 2022-07-01 01:46:28.387195
Epoch:[ 227 1 ] loss: 0.3872642517089844 2022-07-01 01:46:29.183626
Epoch:[ 227 2 ] loss: 0.3871302902698517 2022-07-01 01:46:29.604855
Epoch:[ 227 3 ] loss: 0.3858790695667267 2022-07-01 01:46:30.026031
Epoch:[ 227 4 ] loss: 0.38717836141586304 2022-07-01 01:46:30.447665
Epoch:[ 227 5 ] loss: 0.38566750288009644 2022-07-01 01:46:30.867696
Epoch:[ 227 6 ] loss: 0.3855558931827545 2022-07-01 01:46:31.288093
Epoch:[ 227 7 ] loss: 0.3889804184436798 2022-07-01 01:46:31.710111
Epoch:[ 227 8 ] loss: 0.3854480981826782 2022-07-01 01:46:32.132667
Epoch:[ 227 9 ] loss: 0.38658660650253296 2022-07-01 01:46:32.554082
Epoch:[ 227 10 ] loss: 0.3859403431415558 2022-07-01 01:46:32.975930
Epoch:[ 227 11 ] loss: 0.38967958092689514 2022-07-01 01:46:33.396476
Epoch:[ 227 12 ] loss: 0.38645118474960327 2022-07-01 01:46:33.817204
Epoch:[ 227 13 ] loss: 0.3844568133354187 2022-07-01 01:46:34.237185
Epoch:[ 227 14 ] loss: 0.3865892291069031 2022-07-01 01:46:34.659783
Epoch:[ 227 15 ] loss: 0.38811585307121277 2022-07-01 01:46:35.081358
Epoch:[ 227 16 ] loss: 0.3863218426704407 2022-07-01 01:46:40.751162
Epoch:[ 227 17 ] loss: 0.385856032371521 2022-07-01 01:46:41.170065
Epoch:[ 227 18 ] loss: 0.3877914249897003 2022-07-01 01:46:41.593976
Epoch:[ 227 19 ] loss: 0.387723445892334 2022-07-01 01:46:42.013983
Training_Epoch:[ 227 ] Training_loss: 0.3867184743285179 2022-07-01 01:46:42.014677
learning rate:  0.0003689348814741915
val: 1 0.45460373163223267
val: 2 0.4352410137653351
val: 3 0.44720134139060974
val: 4 0.4384537935256958
val: 5 0.4532786011695862
val: 6 0.45016518235206604
val: 7 0.45371362566947937
val: 8 0.4518740177154541
val: 9 0.43928828835487366
val: 10 0.43402546644210815
val: 11 0.44309675693511963
val: 12 0.45093658566474915
val: 13 0.4392935633659363
val: 14 0.4610998034477234
val: 15 0.4385114014148712
val: 16 0.45341381430625916
val: 17 0.43643948435783386
val: 18 0.4420282244682312
val: 19 0.44623681902885437
val: 20 0.4399215579032898
val_Epoch:[ 227 ] val_loss: 0.44544115364551545 2022-07-01 01:46:45.789879
start training 2022-07-01 01:46:45.893428
Epoch:[ 228 0 ] loss: 0.3854874074459076 2022-07-01 01:47:00.088557
Epoch:[ 228 1 ] loss: 0.3867875337600708 2022-07-01 01:47:00.535476
Epoch:[ 228 2 ] loss: 0.38762813806533813 2022-07-01 01:47:00.957626
Epoch:[ 228 3 ] loss: 0.38617217540740967 2022-07-01 01:47:01.378271
Epoch:[ 228 4 ] loss: 0.38669851422309875 2022-07-01 01:47:01.797556
Epoch:[ 228 5 ] loss: 0.385540634393692 2022-07-01 01:47:02.219971
Epoch:[ 228 6 ] loss: 0.38825225830078125 2022-07-01 01:47:02.638975
Epoch:[ 228 7 ] loss: 0.38642945885658264 2022-07-01 01:47:03.051870
Epoch:[ 228 8 ] loss: 0.3850797116756439 2022-07-01 01:47:03.476492
Epoch:[ 228 9 ] loss: 0.3871108293533325 2022-07-01 01:47:03.897248
Epoch:[ 228 10 ] loss: 0.38705721497535706 2022-07-01 01:47:04.318216
Epoch:[ 228 11 ] loss: 0.38665294647216797 2022-07-01 01:47:04.737662
Epoch:[ 228 12 ] loss: 0.3849177062511444 2022-07-01 01:47:05.158375
Epoch:[ 228 13 ] loss: 0.38736504316329956 2022-07-01 01:47:05.576485
Epoch:[ 228 14 ] loss: 0.38630595803260803 2022-07-01 01:47:05.994852
Epoch:[ 228 15 ] loss: 0.3881036043167114 2022-07-01 01:47:06.415860
Epoch:[ 228 16 ] loss: 0.3858185112476349 2022-07-01 01:47:11.836213
Epoch:[ 228 17 ] loss: 0.3854619264602661 2022-07-01 01:47:12.332699
Epoch:[ 228 18 ] loss: 0.3860302269458771 2022-07-01 01:47:12.752512
Epoch:[ 228 19 ] loss: 0.3884713649749756 2022-07-01 01:47:13.169913
Training_Epoch:[ 228 ] Training_loss: 0.386568558216095 2022-07-01 01:47:13.170608
learning rate:  0.0003689348814741915
netparams have been saved once 228
val: 1 0.44362178444862366
val: 2 0.4434775114059448
val: 3 0.4499932527542114
val: 4 0.43978095054626465
val: 5 0.43208596110343933
val: 6 0.45424118638038635
val: 7 0.4405783712863922
val: 8 0.449083149433136
val: 9 0.44870930910110474
val: 10 0.43116942048072815
val: 11 0.447329580783844
val: 12 0.4435980021953583
val: 13 0.44244828820228577
val: 14 0.44488099217414856
val: 15 0.454641729593277
val: 16 0.44560927152633667
val: 17 0.4445020258426666
val: 18 0.4469911456108093
val: 19 0.4505063593387604
val: 20 0.4460701048374176
val_Epoch:[ 228 ] val_loss: 0.44496591985225675 2022-07-01 01:47:16.977006
start training 2022-07-01 01:47:17.075650
Epoch:[ 229 0 ] loss: 0.3859255611896515 2022-07-01 01:47:31.451421
Epoch:[ 229 1 ] loss: 0.38733118772506714 2022-07-01 01:47:31.885882
Epoch:[ 229 2 ] loss: 0.38482019305229187 2022-07-01 01:47:32.308265
Epoch:[ 229 3 ] loss: 0.38728034496307373 2022-07-01 01:47:32.730851
Epoch:[ 229 4 ] loss: 0.3861214220523834 2022-07-01 01:47:33.151179
Epoch:[ 229 5 ] loss: 0.38642197847366333 2022-07-01 01:47:33.572521
Epoch:[ 229 6 ] loss: 0.3880032002925873 2022-07-01 01:47:33.996407
Epoch:[ 229 7 ] loss: 0.3882397711277008 2022-07-01 01:47:34.418949
Epoch:[ 229 8 ] loss: 0.3851813077926636 2022-07-01 01:47:34.839705
Epoch:[ 229 9 ] loss: 0.3853469491004944 2022-07-01 01:47:35.262082
Epoch:[ 229 10 ] loss: 0.38553109765052795 2022-07-01 01:47:35.684810
Epoch:[ 229 11 ] loss: 0.38777822256088257 2022-07-01 01:47:36.105060
Epoch:[ 229 12 ] loss: 0.38573116064071655 2022-07-01 01:47:36.519148
Epoch:[ 229 13 ] loss: 0.38798022270202637 2022-07-01 01:47:36.940526
Epoch:[ 229 14 ] loss: 0.3880862891674042 2022-07-01 01:47:37.359812
Epoch:[ 229 15 ] loss: 0.38534122705459595 2022-07-01 01:47:37.779577
Epoch:[ 229 16 ] loss: 0.3879266083240509 2022-07-01 01:47:43.105162
Epoch:[ 229 17 ] loss: 0.3883250653743744 2022-07-01 01:47:43.527117
Epoch:[ 229 18 ] loss: 0.38676658272743225 2022-07-01 01:47:43.950367
Epoch:[ 229 19 ] loss: 0.38683027029037476 2022-07-01 01:47:44.371562
Training_Epoch:[ 229 ] Training_loss: 0.38674843311309814 2022-07-01 01:47:44.372299
learning rate:  0.0003689348814741915
val: 1 0.44377732276916504
val: 2 0.45147693157196045
val: 3 0.44982385635375977
val: 4 0.4560924172401428
val: 5 0.44765910506248474
val: 6 0.4475536048412323
val: 7 0.442676842212677
val: 8 0.4365406334400177
val: 9 0.4468499720096588
val: 10 0.44489485025405884
val: 11 0.44588780403137207
val: 12 0.44770288467407227
val: 13 0.44639939069747925
val: 14 0.4359012544155121
val: 15 0.4610365331172943
val: 16 0.4527687132358551
val: 17 0.4316040873527527
val: 18 0.4451296031475067
val: 19 0.4476575255393982
val: 20 0.4283541738986969
val_Epoch:[ 229 ] val_loss: 0.44548937529325483 2022-07-01 01:47:48.173984
start training 2022-07-01 01:47:48.276271
Epoch:[ 230 0 ] loss: 0.38763943314552307 2022-07-01 01:48:02.448089
Epoch:[ 230 1 ] loss: 0.38716524839401245 2022-07-01 01:48:02.868404
Epoch:[ 230 2 ] loss: 0.3907182514667511 2022-07-01 01:48:03.288050
Epoch:[ 230 3 ] loss: 0.3878920078277588 2022-07-01 01:48:03.700229
Epoch:[ 230 4 ] loss: 0.3871026337146759 2022-07-01 01:48:04.123313
Epoch:[ 230 5 ] loss: 0.38492366671562195 2022-07-01 01:48:04.548257
Epoch:[ 230 6 ] loss: 0.38570311665534973 2022-07-01 01:48:04.971038
Epoch:[ 230 7 ] loss: 0.3852151334285736 2022-07-01 01:48:05.391697
Epoch:[ 230 8 ] loss: 0.38714146614074707 2022-07-01 01:48:05.812787
Epoch:[ 230 9 ] loss: 0.3859359323978424 2022-07-01 01:48:06.232194
Epoch:[ 230 10 ] loss: 0.38562387228012085 2022-07-01 01:48:06.654564
Epoch:[ 230 11 ] loss: 0.3874075710773468 2022-07-01 01:48:07.078082
Epoch:[ 230 12 ] loss: 0.3852443993091583 2022-07-01 01:48:07.495045
Epoch:[ 230 13 ] loss: 0.3857254981994629 2022-07-01 01:48:07.915069
Epoch:[ 230 14 ] loss: 0.3863363265991211 2022-07-01 01:48:08.337159
Epoch:[ 230 15 ] loss: 0.3862800896167755 2022-07-01 01:48:08.758297
Epoch:[ 230 16 ] loss: 0.38582801818847656 2022-07-01 01:48:14.278946
Epoch:[ 230 17 ] loss: 0.3869166970252991 2022-07-01 01:48:14.700344
Epoch:[ 230 18 ] loss: 0.38806840777397156 2022-07-01 01:48:15.123369
Epoch:[ 230 19 ] loss: 0.3855764865875244 2022-07-01 01:48:15.543640
Training_Epoch:[ 230 ] Training_loss: 0.38662221282720566 2022-07-01 01:48:15.544337
learning rate:  0.0003689348814741915
netparams have been saved once 230
val: 1 0.4299648702144623
val: 2 0.4580899178981781
val: 3 0.428666889667511
val: 4 0.44413506984710693
val: 5 0.45599618554115295
val: 6 0.4436020851135254
val: 7 0.4523145854473114
val: 8 0.4446142017841339
val: 9 0.452455073595047
val: 10 0.44028744101524353
val: 11 0.4416227638721466
val: 12 0.44390255212783813
val: 13 0.45064061880111694
val: 14 0.4450136721134186
val: 15 0.4454714059829712
val: 16 0.4399058520793915
val: 17 0.44846808910369873
val: 18 0.44576969742774963
val: 19 0.44454410672187805
val: 20 0.4383675456047058
val_Epoch:[ 230 ] val_loss: 0.44469163119792937 2022-07-01 01:48:19.341180
start training 2022-07-01 01:48:19.442143
Epoch:[ 231 0 ] loss: 0.38476917147636414 2022-07-01 01:48:34.403071
Epoch:[ 231 1 ] loss: 0.38393861055374146 2022-07-01 01:48:34.826975
Epoch:[ 231 2 ] loss: 0.38698482513427734 2022-07-01 01:48:35.248210
Epoch:[ 231 3 ] loss: 0.38764676451683044 2022-07-01 01:48:35.668397
Epoch:[ 231 4 ] loss: 0.3861376941204071 2022-07-01 01:48:36.088400
Epoch:[ 231 5 ] loss: 0.38423413038253784 2022-07-01 01:48:36.507432
Epoch:[ 231 6 ] loss: 0.38666027784347534 2022-07-01 01:48:36.930290
Epoch:[ 231 7 ] loss: 0.3860359787940979 2022-07-01 01:48:37.350518
Epoch:[ 231 8 ] loss: 0.3873797059059143 2022-07-01 01:48:37.774284
Epoch:[ 231 9 ] loss: 0.3910962641239166 2022-07-01 01:48:38.196421
Epoch:[ 231 10 ] loss: 0.38683047890663147 2022-07-01 01:48:38.617501
Epoch:[ 231 11 ] loss: 0.389209508895874 2022-07-01 01:48:39.037793
Epoch:[ 231 12 ] loss: 0.3865652084350586 2022-07-01 01:48:39.461881
Epoch:[ 231 13 ] loss: 0.3853587508201599 2022-07-01 01:48:39.882824
Epoch:[ 231 14 ] loss: 0.38668206334114075 2022-07-01 01:48:40.308460
Epoch:[ 231 15 ] loss: 0.3851323127746582 2022-07-01 01:48:40.730659
Epoch:[ 231 16 ] loss: 0.3866851031780243 2022-07-01 01:48:46.453934
Epoch:[ 231 17 ] loss: 0.38638201355934143 2022-07-01 01:48:46.876779
Epoch:[ 231 18 ] loss: 0.38658857345581055 2022-07-01 01:48:47.308461
Epoch:[ 231 19 ] loss: 0.3853228688240051 2022-07-01 01:48:47.729975
Training_Epoch:[ 231 ] Training_loss: 0.38648201525211334 2022-07-01 01:48:47.730773
learning rate:  0.00029514790517935324
val: 1 0.43773218989372253
val: 2 0.4580220580101013
val: 3 0.44691726565361023
val: 4 0.4480534791946411
val: 5 0.43271321058273315
val: 6 0.44015365839004517
val: 7 0.4458698332309723
val: 8 0.4388521611690521
val: 9 0.4560583531856537
val: 10 0.4396362006664276
val: 11 0.4429077208042145
val: 12 0.4502468705177307
val: 13 0.44621583819389343
val: 14 0.4471830427646637
val: 15 0.4383584260940552
val: 16 0.44764915108680725
val: 17 0.4351434111595154
val: 18 0.45548245310783386
val: 19 0.44566524028778076
val: 20 0.44417867064476013
val_Epoch:[ 231 ] val_loss: 0.4448519617319107 2022-07-01 01:48:51.557913
start training 2022-07-01 01:48:51.659712
Epoch:[ 232 0 ] loss: 0.3864465057849884 2022-07-01 01:49:05.775752
Epoch:[ 232 1 ] loss: 0.38833996653556824 2022-07-01 01:49:06.294776
Epoch:[ 232 2 ] loss: 0.38434526324272156 2022-07-01 01:49:06.717340
Epoch:[ 232 3 ] loss: 0.38589128851890564 2022-07-01 01:49:07.139468
Epoch:[ 232 4 ] loss: 0.3873201012611389 2022-07-01 01:49:07.562274
Epoch:[ 232 5 ] loss: 0.38494250178337097 2022-07-01 01:49:07.984617
Epoch:[ 232 6 ] loss: 0.3850170075893402 2022-07-01 01:49:08.400587
Epoch:[ 232 7 ] loss: 0.38864627480506897 2022-07-01 01:49:08.822448
Epoch:[ 232 8 ] loss: 0.3886442184448242 2022-07-01 01:49:09.246003
Epoch:[ 232 9 ] loss: 0.38875481486320496 2022-07-01 01:49:09.667188
Epoch:[ 232 10 ] loss: 0.38691624999046326 2022-07-01 01:49:10.089851
Epoch:[ 232 11 ] loss: 0.3858332931995392 2022-07-01 01:49:10.512081
Epoch:[ 232 12 ] loss: 0.3850427269935608 2022-07-01 01:49:10.934432
Epoch:[ 232 13 ] loss: 0.38652580976486206 2022-07-01 01:49:11.356633
Epoch:[ 232 14 ] loss: 0.38858628273010254 2022-07-01 01:49:11.779532
Epoch:[ 232 15 ] loss: 0.3860235810279846 2022-07-01 01:49:12.200896
Epoch:[ 232 16 ] loss: 0.3866996169090271 2022-07-01 01:49:17.705267
Epoch:[ 232 17 ] loss: 0.38766586780548096 2022-07-01 01:49:18.124745
Epoch:[ 232 18 ] loss: 0.38841983675956726 2022-07-01 01:49:18.547447
Epoch:[ 232 19 ] loss: 0.38527604937553406 2022-07-01 01:49:18.969549
Training_Epoch:[ 232 ] Training_loss: 0.3867668628692627 2022-07-01 01:49:18.970204
learning rate:  0.00029514790517935324
netparams have been saved once 232
val: 1 0.42618584632873535
val: 2 0.4439445436000824
val: 3 0.44865652918815613
val: 4 0.4589952528476715
val: 5 0.4497750699520111
val: 6 0.4454388916492462
val: 7 0.4477570354938507
val: 8 0.4424273371696472
val: 9 0.43656817078590393
val: 10 0.44128182530403137
val: 11 0.43303269147872925
val: 12 0.4531952142715454
val: 13 0.44459041953086853
val: 14 0.44224610924720764
val: 15 0.4469490349292755
val: 16 0.44710248708724976
val: 17 0.4537040889263153
val: 18 0.4485154151916504
val: 19 0.44566720724105835
val: 20 0.43817460536956787
val_Epoch:[ 232 ] val_loss: 0.4447103887796402 2022-07-01 01:49:22.814283
start training 2022-07-01 01:49:22.923112
Epoch:[ 233 0 ] loss: 0.3860437572002411 2022-07-01 01:49:37.454498
Epoch:[ 233 1 ] loss: 0.38496196269989014 2022-07-01 01:49:37.892574
Epoch:[ 233 2 ] loss: 0.3881095349788666 2022-07-01 01:49:38.316687
Epoch:[ 233 3 ] loss: 0.38469281792640686 2022-07-01 01:49:38.738237
Epoch:[ 233 4 ] loss: 0.3856917917728424 2022-07-01 01:49:39.158657
Epoch:[ 233 5 ] loss: 0.3869751989841461 2022-07-01 01:49:39.578995
Epoch:[ 233 6 ] loss: 0.38631299138069153 2022-07-01 01:49:40.002069
Epoch:[ 233 7 ] loss: 0.38611629605293274 2022-07-01 01:49:40.424547
Epoch:[ 233 8 ] loss: 0.3862820565700531 2022-07-01 01:49:40.848108
Epoch:[ 233 9 ] loss: 0.3858701288700104 2022-07-01 01:49:41.270193
Epoch:[ 233 10 ] loss: 0.3871917128562927 2022-07-01 01:49:41.694213
Epoch:[ 233 11 ] loss: 0.38683590292930603 2022-07-01 01:49:42.111181
Epoch:[ 233 12 ] loss: 0.3869848847389221 2022-07-01 01:49:42.533225
Epoch:[ 233 13 ] loss: 0.3873893916606903 2022-07-01 01:49:42.958872
Epoch:[ 233 14 ] loss: 0.3871789574623108 2022-07-01 01:49:43.385744
Epoch:[ 233 15 ] loss: 0.3872968554496765 2022-07-01 01:49:43.807259
Epoch:[ 233 16 ] loss: 0.38660138845443726 2022-07-01 01:49:49.267200
Epoch:[ 233 17 ] loss: 0.3855803608894348 2022-07-01 01:49:49.748139
Epoch:[ 233 18 ] loss: 0.38696762919425964 2022-07-01 01:49:50.168942
Epoch:[ 233 19 ] loss: 0.38552024960517883 2022-07-01 01:49:50.588035
Training_Epoch:[ 233 ] Training_loss: 0.3864301934838295 2022-07-01 01:49:50.588816
learning rate:  0.00029514790517935324
val: 1 0.4391922354698181
val: 2 0.4348464906215668
val: 3 0.45045942068099976
val: 4 0.44642892479896545
val: 5 0.45435184240341187
val: 6 0.43317580223083496
val: 7 0.44579795002937317
val: 8 0.44643813371658325
val: 9 0.4419901669025421
val: 10 0.4422931373119354
val: 11 0.4437878131866455
val: 12 0.44547414779663086
val: 13 0.42416200041770935
val: 14 0.4348239004611969
val: 15 0.4488462507724762
val: 16 0.4542072117328644
val: 17 0.455819308757782
val: 18 0.45648688077926636
val: 19 0.45433905720710754
val: 20 0.44488266110420227
val_Epoch:[ 233 ] val_loss: 0.4448901668190956 2022-07-01 01:49:54.421718
start training 2022-07-01 01:49:54.527180
Epoch:[ 234 0 ] loss: 0.3871482014656067 2022-07-01 01:50:08.995396
Epoch:[ 234 1 ] loss: 0.3840673267841339 2022-07-01 01:50:09.441418
Epoch:[ 234 2 ] loss: 0.38528645038604736 2022-07-01 01:50:09.862032
Epoch:[ 234 3 ] loss: 0.384655237197876 2022-07-01 01:50:10.285239
Epoch:[ 234 4 ] loss: 0.38473886251449585 2022-07-01 01:50:10.705901
Epoch:[ 234 5 ] loss: 0.38379356265068054 2022-07-01 01:50:11.130276
Epoch:[ 234 6 ] loss: 0.38653308153152466 2022-07-01 01:50:11.554326
Epoch:[ 234 7 ] loss: 0.38765954971313477 2022-07-01 01:50:11.977375
Epoch:[ 234 8 ] loss: 0.38674965500831604 2022-07-01 01:50:12.398779
Epoch:[ 234 9 ] loss: 0.387496680021286 2022-07-01 01:50:12.819464
Epoch:[ 234 10 ] loss: 0.389206200838089 2022-07-01 01:50:13.239475
Epoch:[ 234 11 ] loss: 0.38589712977409363 2022-07-01 01:50:13.665593
Epoch:[ 234 12 ] loss: 0.3836871385574341 2022-07-01 01:50:14.086198
Epoch:[ 234 13 ] loss: 0.3874484598636627 2022-07-01 01:50:14.502416
Epoch:[ 234 14 ] loss: 0.38660261034965515 2022-07-01 01:50:14.923525
Epoch:[ 234 15 ] loss: 0.38797155022621155 2022-07-01 01:50:15.345147
Epoch:[ 234 16 ] loss: 0.3901994824409485 2022-07-01 01:50:21.094664
Epoch:[ 234 17 ] loss: 0.38706398010253906 2022-07-01 01:50:21.515961
Epoch:[ 234 18 ] loss: 0.3879512548446655 2022-07-01 01:50:21.937626
Epoch:[ 234 19 ] loss: 0.3842991590499878 2022-07-01 01:50:22.359983
Training_Epoch:[ 234 ] Training_loss: 0.38642277866601943 2022-07-01 01:50:22.360684
learning rate:  0.00029514790517935324
netparams have been saved once 234
val: 1 0.44295865297317505
val: 2 0.4441574513912201
val: 3 0.44716447591781616
val: 4 0.4601213037967682
val: 5 0.4476371109485626
val: 6 0.43903908133506775
val: 7 0.44379231333732605
val: 8 0.4422319531440735
val: 9 0.44283005595207214
val: 10 0.4496009051799774
val: 11 0.4518464505672455
val: 12 0.4299572706222534
val: 13 0.4387577772140503
val: 14 0.45135247707366943
val: 15 0.43683746457099915
val: 16 0.4416843056678772
val: 17 0.447437047958374
val: 18 0.46096310019493103
val: 19 0.44866833090782166
val: 20 0.43160635232925415
val_Epoch:[ 234 ] val_loss: 0.44493219405412676 2022-07-01 01:50:26.190403
start training 2022-07-01 01:50:26.290540
Epoch:[ 235 0 ] loss: 0.38479870557785034 2022-07-01 01:50:40.075468
Epoch:[ 235 1 ] loss: 0.3855723738670349 2022-07-01 01:50:40.518798
Epoch:[ 235 2 ] loss: 0.38544005155563354 2022-07-01 01:50:40.943858
Epoch:[ 235 3 ] loss: 0.3866564929485321 2022-07-01 01:50:41.364709
Epoch:[ 235 4 ] loss: 0.38588330149650574 2022-07-01 01:50:41.784499
Epoch:[ 235 5 ] loss: 0.38700050115585327 2022-07-01 01:50:42.204677
Epoch:[ 235 6 ] loss: 0.3865775465965271 2022-07-01 01:50:42.624411
Epoch:[ 235 7 ] loss: 0.38851284980773926 2022-07-01 01:50:43.034790
Epoch:[ 235 8 ] loss: 0.3867083191871643 2022-07-01 01:50:43.447251
Epoch:[ 235 9 ] loss: 0.3882943093776703 2022-07-01 01:50:43.856074
Epoch:[ 235 10 ] loss: 0.38605719804763794 2022-07-01 01:50:44.266704
Epoch:[ 235 11 ] loss: 0.3858674466609955 2022-07-01 01:50:44.676476
Epoch:[ 235 12 ] loss: 0.3862602412700653 2022-07-01 01:50:45.085037
Epoch:[ 235 13 ] loss: 0.38527151942253113 2022-07-01 01:50:45.493262
Epoch:[ 235 14 ] loss: 0.38877376914024353 2022-07-01 01:50:45.901813
Epoch:[ 235 15 ] loss: 0.38814982771873474 2022-07-01 01:50:46.312667
Epoch:[ 235 16 ] loss: 0.3873346149921417 2022-07-01 01:50:51.976228
Epoch:[ 235 17 ] loss: 0.38304612040519714 2022-07-01 01:50:52.395396
Epoch:[ 235 18 ] loss: 0.3865292966365814 2022-07-01 01:50:52.815470
Epoch:[ 235 19 ] loss: 0.3875555694103241 2022-07-01 01:50:53.234741
Training_Epoch:[ 235 ] Training_loss: 0.38651450276374816 2022-07-01 01:50:53.235466
learning rate:  0.00029514790517935324
val: 1 0.4443402886390686
val: 2 0.4439621567726135
val: 3 0.4454452693462372
val: 4 0.4321950674057007
val: 5 0.46245837211608887
val: 6 0.43921345472335815
val: 7 0.44832319021224976
val: 8 0.4425947964191437
val: 9 0.45570677518844604
val: 10 0.44786539673805237
val: 11 0.43228965997695923
val: 12 0.43734875321388245
val: 13 0.4353412985801697
val: 14 0.4603651762008667
val: 15 0.43739524483680725
val: 16 0.43271854519844055
val: 17 0.4460327625274658
val: 18 0.46433570981025696
val: 19 0.4394458830356598
val: 20 0.44415441155433655
val_Epoch:[ 235 ] val_loss: 0.4445766106247902 2022-07-01 01:50:56.993601
start training 2022-07-01 01:50:57.094236
Epoch:[ 236 0 ] loss: 0.38699889183044434 2022-07-01 01:51:12.045863
Epoch:[ 236 1 ] loss: 0.3878045380115509 2022-07-01 01:51:12.465861
Epoch:[ 236 2 ] loss: 0.38642239570617676 2022-07-01 01:51:12.888126
Epoch:[ 236 3 ] loss: 0.3842197358608246 2022-07-01 01:51:13.310678
Epoch:[ 236 4 ] loss: 0.38698163628578186 2022-07-01 01:51:13.733124
Epoch:[ 236 5 ] loss: 0.38472646474838257 2022-07-01 01:51:14.153178
Epoch:[ 236 6 ] loss: 0.38434717059135437 2022-07-01 01:51:14.568485
Epoch:[ 236 7 ] loss: 0.38929304480552673 2022-07-01 01:51:14.990759
Epoch:[ 236 8 ] loss: 0.387681782245636 2022-07-01 01:51:15.404639
Epoch:[ 236 9 ] loss: 0.38693296909332275 2022-07-01 01:51:15.829000
Epoch:[ 236 10 ] loss: 0.3867139220237732 2022-07-01 01:51:16.251267
Epoch:[ 236 11 ] loss: 0.3886792063713074 2022-07-01 01:51:16.673423
Epoch:[ 236 12 ] loss: 0.38412514328956604 2022-07-01 01:51:17.097191
Epoch:[ 236 13 ] loss: 0.38585594296455383 2022-07-01 01:51:17.516812
Epoch:[ 236 14 ] loss: 0.3842349946498871 2022-07-01 01:51:17.937374
Epoch:[ 236 15 ] loss: 0.38633304834365845 2022-07-01 01:51:18.359735
Epoch:[ 236 16 ] loss: 0.38654419779777527 2022-07-01 01:51:23.990252
Epoch:[ 236 17 ] loss: 0.38455018401145935 2022-07-01 01:51:24.411062
Epoch:[ 236 18 ] loss: 0.3867883086204529 2022-07-01 01:51:24.832731
Epoch:[ 236 19 ] loss: 0.3868952989578247 2022-07-01 01:51:25.254932
Training_Epoch:[ 236 ] Training_loss: 0.386306443810463 2022-07-01 01:51:25.255597
learning rate:  0.00029514790517935324
netparams have been saved once 236
val: 1 0.45371192693710327
val: 2 0.4513620436191559
val: 3 0.4546823799610138
val: 4 0.4325847029685974
val: 5 0.4488588273525238
val: 6 0.4471323788166046
val: 7 0.4434567093849182
val: 8 0.4478355348110199
val: 9 0.4475401043891907
val: 10 0.4499359726905823
val: 11 0.44105687737464905
val: 12 0.4265410602092743
val: 13 0.45720168948173523
val: 14 0.4358462691307068
val: 15 0.4457753300666809
val: 16 0.43851664662361145
val: 17 0.44811391830444336
val: 18 0.4420706331729889
val: 19 0.4456687271595001
val: 20 0.4537737965583801
val_Epoch:[ 236 ] val_loss: 0.445583276450634 2022-07-01 01:51:29.041604
start training 2022-07-01 01:51:29.144985
Epoch:[ 237 0 ] loss: 0.38767367601394653 2022-07-01 01:51:43.358747
Epoch:[ 237 1 ] loss: 0.3842471241950989 2022-07-01 01:51:43.789918
Epoch:[ 237 2 ] loss: 0.38705888390541077 2022-07-01 01:51:44.214216
Epoch:[ 237 3 ] loss: 0.3877145051956177 2022-07-01 01:51:44.636533
Epoch:[ 237 4 ] loss: 0.38737109303474426 2022-07-01 01:51:45.058551
Epoch:[ 237 5 ] loss: 0.38453856110572815 2022-07-01 01:51:45.476819
Epoch:[ 237 6 ] loss: 0.38554131984710693 2022-07-01 01:51:45.885795
Epoch:[ 237 7 ] loss: 0.3866423964500427 2022-07-01 01:51:46.294988
Epoch:[ 237 8 ] loss: 0.3881480395793915 2022-07-01 01:51:46.703401
Epoch:[ 237 9 ] loss: 0.3838833272457123 2022-07-01 01:51:47.111258
Epoch:[ 237 10 ] loss: 0.388376384973526 2022-07-01 01:51:47.521386
Epoch:[ 237 11 ] loss: 0.3873355984687805 2022-07-01 01:51:47.932586
Epoch:[ 237 12 ] loss: 0.3868797719478607 2022-07-01 01:51:48.347329
Epoch:[ 237 13 ] loss: 0.38558971881866455 2022-07-01 01:51:48.758514
Epoch:[ 237 14 ] loss: 0.3851625323295593 2022-07-01 01:51:49.168310
Epoch:[ 237 15 ] loss: 0.38516291975975037 2022-07-01 01:51:49.576976
Epoch:[ 237 16 ] loss: 0.38359957933425903 2022-07-01 01:51:55.228706
Epoch:[ 237 17 ] loss: 0.3879455029964447 2022-07-01 01:51:55.637699
Epoch:[ 237 18 ] loss: 0.3866994380950928 2022-07-01 01:51:56.061390
Epoch:[ 237 19 ] loss: 0.38784217834472656 2022-07-01 01:51:56.482255
Training_Epoch:[ 237 ] Training_loss: 0.3863706275820732 2022-07-01 01:51:56.483005
learning rate:  0.00029514790517935324
val: 1 0.4589448869228363
val: 2 0.45410946011543274
val: 3 0.439552366733551
val: 4 0.438996821641922
val: 5 0.45448631048202515
val: 6 0.44878777861595154
val: 7 0.45582115650177
val: 8 0.43283382058143616
val: 9 0.4311373829841614
val: 10 0.4247654676437378
val: 11 0.43871742486953735
val: 12 0.4586370587348938
val: 13 0.4506928026676178
val: 14 0.44449082016944885
val: 15 0.4425179660320282
val: 16 0.4429495334625244
val: 17 0.43737465143203735
val: 18 0.4488651156425476
val: 19 0.4443674087524414
val: 20 0.4577052891254425
val_Epoch:[ 237 ] val_loss: 0.4452876761555672 2022-07-01 01:52:00.230847
start training 2022-07-01 01:52:00.333534
Epoch:[ 238 0 ] loss: 0.38673678040504456 2022-07-01 01:52:14.708085
Epoch:[ 238 1 ] loss: 0.383183091878891 2022-07-01 01:52:15.275005
Epoch:[ 238 2 ] loss: 0.3872218728065491 2022-07-01 01:52:15.694269
Epoch:[ 238 3 ] loss: 0.3835858702659607 2022-07-01 01:52:16.101673
Epoch:[ 238 4 ] loss: 0.38679978251457214 2022-07-01 01:52:16.511424
Epoch:[ 238 5 ] loss: 0.3859967589378357 2022-07-01 01:52:16.921719
Epoch:[ 238 6 ] loss: 0.38676193356513977 2022-07-01 01:52:17.337973
Epoch:[ 238 7 ] loss: 0.38692551851272583 2022-07-01 01:52:17.747090
Epoch:[ 238 8 ] loss: 0.3871641159057617 2022-07-01 01:52:18.158028
Epoch:[ 238 9 ] loss: 0.38540157675743103 2022-07-01 01:52:18.567093
Epoch:[ 238 10 ] loss: 0.38521090149879456 2022-07-01 01:52:18.975024
Epoch:[ 238 11 ] loss: 0.38939735293388367 2022-07-01 01:52:19.385175
Epoch:[ 238 12 ] loss: 0.38656115531921387 2022-07-01 01:52:19.796651
Epoch:[ 238 13 ] loss: 0.3871649205684662 2022-07-01 01:52:20.205340
Epoch:[ 238 14 ] loss: 0.3875413239002228 2022-07-01 01:52:20.613590
Epoch:[ 238 15 ] loss: 0.38460156321525574 2022-07-01 01:52:21.022214
Epoch:[ 238 16 ] loss: 0.3855951428413391 2022-07-01 01:52:26.411603
Epoch:[ 238 17 ] loss: 0.3872193396091461 2022-07-01 01:52:26.818265
Epoch:[ 238 18 ] loss: 0.3879906237125397 2022-07-01 01:52:27.228425
Epoch:[ 238 19 ] loss: 0.3857755661010742 2022-07-01 01:52:27.639135
Training_Epoch:[ 238 ] Training_loss: 0.3863417595624924 2022-07-01 01:52:27.640249
learning rate:  0.00029514790517935324
netparams have been saved once 238
val: 1 0.4462796151638031
val: 2 0.4408711791038513
val: 3 0.45461201667785645
val: 4 0.44704383611679077
val: 5 0.45663416385650635
val: 6 0.44395169615745544
val: 7 0.44966059923171997
val: 8 0.44620442390441895
val: 9 0.44652727246284485
val: 10 0.4484540522098541
val: 11 0.4291144013404846
val: 12 0.4485691487789154
val: 13 0.4574829936027527
val: 14 0.447525292634964
val: 15 0.42796263098716736
val: 16 0.4358868896961212
val: 17 0.4392642676830292
val: 18 0.4476608335971832
val: 19 0.440125048160553
val: 20 0.4422685205936432
val_Epoch:[ 238 ] val_loss: 0.44480494409799576 2022-07-01 01:52:31.567189
start training 2022-07-01 01:52:31.673187
Epoch:[ 239 0 ] loss: 0.3888758718967438 2022-07-01 01:52:45.815151
Epoch:[ 239 1 ] loss: 0.3862297832965851 2022-07-01 01:52:46.754381
Epoch:[ 239 2 ] loss: 0.384255051612854 2022-07-01 01:52:47.174910
Epoch:[ 239 3 ] loss: 0.38665422797203064 2022-07-01 01:52:47.595207
Epoch:[ 239 4 ] loss: 0.3869147002696991 2022-07-01 01:52:48.015535
Epoch:[ 239 5 ] loss: 0.38397103548049927 2022-07-01 01:52:48.437654
Epoch:[ 239 6 ] loss: 0.38584017753601074 2022-07-01 01:52:48.861694
Epoch:[ 239 7 ] loss: 0.3853611648082733 2022-07-01 01:52:49.282164
Epoch:[ 239 8 ] loss: 0.3870379328727722 2022-07-01 01:52:49.705283
Epoch:[ 239 9 ] loss: 0.3863716125488281 2022-07-01 01:52:50.126010
Epoch:[ 239 10 ] loss: 0.3865269124507904 2022-07-01 01:52:50.547126
Epoch:[ 239 11 ] loss: 0.3851342797279358 2022-07-01 01:52:50.968980
Epoch:[ 239 12 ] loss: 0.3862200081348419 2022-07-01 01:52:51.390254
Epoch:[ 239 13 ] loss: 0.38503706455230713 2022-07-01 01:52:51.812996
Epoch:[ 239 14 ] loss: 0.38680529594421387 2022-07-01 01:52:52.237488
Epoch:[ 239 15 ] loss: 0.38476115465164185 2022-07-01 01:52:52.657610
Epoch:[ 239 16 ] loss: 0.3870261609554291 2022-07-01 01:52:57.774115
Epoch:[ 239 17 ] loss: 0.38728630542755127 2022-07-01 01:52:58.520815
Epoch:[ 239 18 ] loss: 0.3879244923591614 2022-07-01 01:52:58.940849
Epoch:[ 239 19 ] loss: 0.3859681189060211 2022-07-01 01:52:59.362621
Training_Epoch:[ 239 ] Training_loss: 0.3862100675702095 2022-07-01 01:52:59.363369
learning rate:  0.00029514790517935324
val: 1 0.4502829611301422
val: 2 0.44310715794563293
val: 3 0.4529262185096741
val: 4 0.4467105567455292
val: 5 0.4530855715274811
val: 6 0.44219842553138733
val: 7 0.4553601145744324
val: 8 0.4395463168621063
val: 9 0.4468134939670563
val: 10 0.4484591782093048
val: 11 0.44640564918518066
val: 12 0.4481842815876007
val: 13 0.4508180320262909
val: 14 0.4220169484615326
val: 15 0.4415750503540039
val: 16 0.4469436705112457
val: 17 0.45008280873298645
val: 18 0.44466423988342285
val: 19 0.4439614415168762
val: 20 0.4386734366416931
val_Epoch:[ 239 ] val_loss: 0.44559077769517896 2022-07-01 01:53:03.152348
start training 2022-07-01 01:53:03.266411
Epoch:[ 240 0 ] loss: 0.3880738914012909 2022-07-01 01:53:17.391641
Epoch:[ 240 1 ] loss: 0.3841007649898529 2022-07-01 01:53:17.974445
Epoch:[ 240 2 ] loss: 0.38502511382102966 2022-07-01 01:53:18.395308
Epoch:[ 240 3 ] loss: 0.38689690828323364 2022-07-01 01:53:18.815402
Epoch:[ 240 4 ] loss: 0.38549426198005676 2022-07-01 01:53:19.237372
Epoch:[ 240 5 ] loss: 0.38495516777038574 2022-07-01 01:53:19.657911
Epoch:[ 240 6 ] loss: 0.3874583840370178 2022-07-01 01:53:20.073094
Epoch:[ 240 7 ] loss: 0.3835435211658478 2022-07-01 01:53:20.482987
Epoch:[ 240 8 ] loss: 0.38562944531440735 2022-07-01 01:53:20.892310
Epoch:[ 240 9 ] loss: 0.38749054074287415 2022-07-01 01:53:21.308763
Epoch:[ 240 10 ] loss: 0.38587260246276855 2022-07-01 01:53:21.718111
Epoch:[ 240 11 ] loss: 0.38717401027679443 2022-07-01 01:53:22.127153
Epoch:[ 240 12 ] loss: 0.38420888781547546 2022-07-01 01:53:22.534607
Epoch:[ 240 13 ] loss: 0.38730740547180176 2022-07-01 01:53:22.946508
Epoch:[ 240 14 ] loss: 0.3858725130558014 2022-07-01 01:53:23.357707
Epoch:[ 240 15 ] loss: 0.3857728838920593 2022-07-01 01:53:23.769431
Epoch:[ 240 16 ] loss: 0.3856150209903717 2022-07-01 01:53:29.561978
Epoch:[ 240 17 ] loss: 0.3875296115875244 2022-07-01 01:53:29.982464
Epoch:[ 240 18 ] loss: 0.3873308002948761 2022-07-01 01:53:30.403007
Epoch:[ 240 19 ] loss: 0.3879695534706116 2022-07-01 01:53:30.823949
Training_Epoch:[ 240 ] Training_loss: 0.38616606444120405 2022-07-01 01:53:30.824746
learning rate:  0.00029514790517935324
netparams have been saved once 240
val: 1 0.4465312957763672
val: 2 0.4501013159751892
val: 3 0.44508615136146545
val: 4 0.4372789263725281
val: 5 0.4435543417930603
val: 6 0.4430523216724396
val: 7 0.4436684846878052
val: 8 0.4455775320529938
val: 9 0.4469614326953888
val: 10 0.45558589696884155
val: 11 0.4385993778705597
val: 12 0.44811487197875977
val: 13 0.44164419174194336
val: 14 0.44519340991973877
val: 15 0.44426143169403076
val: 16 0.44760993123054504
val: 17 0.4389309287071228
val: 18 0.44926390051841736
val: 19 0.4552668035030365
val: 20 0.43838241696357727
val_Epoch:[ 240 ] val_loss: 0.4452332481741905 2022-07-01 01:53:34.757596
start training 2022-07-01 01:53:34.861900
Epoch:[ 241 0 ] loss: 0.3856086730957031 2022-07-01 01:53:49.227956
Epoch:[ 241 1 ] loss: 0.385995477437973 2022-07-01 01:53:49.699551
Epoch:[ 241 2 ] loss: 0.3854322135448456 2022-07-01 01:53:50.120019
Epoch:[ 241 3 ] loss: 0.38586822152137756 2022-07-01 01:53:50.539707
Epoch:[ 241 4 ] loss: 0.38747578859329224 2022-07-01 01:53:50.958816
Epoch:[ 241 5 ] loss: 0.38517531752586365 2022-07-01 01:53:51.377899
Epoch:[ 241 6 ] loss: 0.3852323293685913 2022-07-01 01:53:51.796796
Epoch:[ 241 7 ] loss: 0.38629284501075745 2022-07-01 01:53:52.217420
Epoch:[ 241 8 ] loss: 0.3862859308719635 2022-07-01 01:53:52.639825
Epoch:[ 241 9 ] loss: 0.3850034177303314 2022-07-01 01:53:53.060174
Epoch:[ 241 10 ] loss: 0.386729896068573 2022-07-01 01:53:53.480493
Epoch:[ 241 11 ] loss: 0.3864470422267914 2022-07-01 01:53:53.902293
Epoch:[ 241 12 ] loss: 0.3858163356781006 2022-07-01 01:53:54.322510
Epoch:[ 241 13 ] loss: 0.38635095953941345 2022-07-01 01:53:54.741632
Epoch:[ 241 14 ] loss: 0.3860786259174347 2022-07-01 01:53:55.163236
Epoch:[ 241 15 ] loss: 0.38518425822257996 2022-07-01 01:53:55.584355
Epoch:[ 241 16 ] loss: 0.38550761342048645 2022-07-01 01:54:01.322771
Epoch:[ 241 17 ] loss: 0.38918396830558777 2022-07-01 01:54:01.741831
Epoch:[ 241 18 ] loss: 0.3873447775840759 2022-07-01 01:54:02.163312
Epoch:[ 241 19 ] loss: 0.385684072971344 2022-07-01 01:54:02.582610
Training_Epoch:[ 241 ] Training_loss: 0.3861348882317543 2022-07-01 01:54:02.583342
learning rate:  0.0002361183241434826
val: 1 0.4434533417224884
val: 2 0.44492751359939575
val: 3 0.4415571689605713
val: 4 0.4360741078853607
val: 5 0.43704503774642944
val: 6 0.44903531670570374
val: 7 0.4401073753833771
val: 8 0.4450541138648987
val: 9 0.4408501386642456
val: 10 0.4464685618877411
val: 11 0.44312888383865356
val: 12 0.46215561032295227
val: 13 0.44804099202156067
val: 14 0.4343671202659607
val: 15 0.4498727321624756
val: 16 0.4317739009857178
val: 17 0.45104333758354187
val: 18 0.44903501868247986
val: 19 0.4432588219642639
val: 20 0.45514246821403503
val_Epoch:[ 241 ] val_loss: 0.44461957812309266 2022-07-01 01:54:06.417606
start training 2022-07-01 01:54:06.541729
Epoch:[ 242 0 ] loss: 0.3866971433162689 2022-07-01 01:54:21.538571
Epoch:[ 242 1 ] loss: 0.38506051898002625 2022-07-01 01:54:21.959852
Epoch:[ 242 2 ] loss: 0.3852236568927765 2022-07-01 01:54:22.381743
Epoch:[ 242 3 ] loss: 0.3876515030860901 2022-07-01 01:54:22.805472
Epoch:[ 242 4 ] loss: 0.3881550133228302 2022-07-01 01:54:23.226054
Epoch:[ 242 5 ] loss: 0.3877446949481964 2022-07-01 01:54:23.646280
Epoch:[ 242 6 ] loss: 0.3855830132961273 2022-07-01 01:54:24.067088
Epoch:[ 242 7 ] loss: 0.3864477872848511 2022-07-01 01:54:24.486324
Epoch:[ 242 8 ] loss: 0.3872815668582916 2022-07-01 01:54:24.909117
Epoch:[ 242 9 ] loss: 0.38502344489097595 2022-07-01 01:54:25.331543
Epoch:[ 242 10 ] loss: 0.38698309659957886 2022-07-01 01:54:25.752148
Epoch:[ 242 11 ] loss: 0.38254281878471375 2022-07-01 01:54:26.171409
Epoch:[ 242 12 ] loss: 0.385210782289505 2022-07-01 01:54:26.591905
Epoch:[ 242 13 ] loss: 0.3859449625015259 2022-07-01 01:54:27.012450
Epoch:[ 242 14 ] loss: 0.38508784770965576 2022-07-01 01:54:27.432240
Epoch:[ 242 15 ] loss: 0.38668712973594666 2022-07-01 01:54:27.848032
Epoch:[ 242 16 ] loss: 0.38554441928863525 2022-07-01 01:54:33.021841
Epoch:[ 242 17 ] loss: 0.3845260739326477 2022-07-01 01:54:33.442680
Epoch:[ 242 18 ] loss: 0.3875422477722168 2022-07-01 01:54:33.863323
Epoch:[ 242 19 ] loss: 0.386106014251709 2022-07-01 01:54:34.284468
Training_Epoch:[ 242 ] Training_loss: 0.38605218678712844 2022-07-01 01:54:34.285135
learning rate:  0.0002361183241434826
netparams have been saved once 242
val: 1 0.44868701696395874
val: 2 0.43915024399757385
val: 3 0.43060970306396484
val: 4 0.4341142475605011
val: 5 0.43717068433761597
val: 6 0.45283326506614685
val: 7 0.43881797790527344
val: 8 0.4456281363964081
val: 9 0.461686372756958
val: 10 0.4458796977996826
val: 11 0.44159695506095886
val: 12 0.4466325044631958
val: 13 0.46092498302459717
val: 14 0.44229620695114136
val: 15 0.4438835680484772
val: 16 0.46475693583488464
val: 17 0.4437592327594757
val: 18 0.4528794586658478
val: 19 0.44614163041114807
val: 20 0.4359549880027771
val_Epoch:[ 242 ] val_loss: 0.44567019045352935 2022-07-01 01:54:38.109717
start training 2022-07-01 01:54:38.209217
Epoch:[ 243 0 ] loss: 0.3850800395011902 2022-07-01 01:54:52.110091
Epoch:[ 243 1 ] loss: 0.3860745429992676 2022-07-01 01:54:53.048904
Epoch:[ 243 2 ] loss: 0.3820544481277466 2022-07-01 01:54:53.460301
Epoch:[ 243 3 ] loss: 0.3870723247528076 2022-07-01 01:54:53.870475
Epoch:[ 243 4 ] loss: 0.38672178983688354 2022-07-01 01:54:54.281762
Epoch:[ 243 5 ] loss: 0.38702553510665894 2022-07-01 01:54:54.691568
Epoch:[ 243 6 ] loss: 0.3844633102416992 2022-07-01 01:54:55.101559
Epoch:[ 243 7 ] loss: 0.38500845432281494 2022-07-01 01:54:55.511814
Epoch:[ 243 8 ] loss: 0.3854215443134308 2022-07-01 01:54:55.922019
Epoch:[ 243 9 ] loss: 0.38520193099975586 2022-07-01 01:54:56.331588
Epoch:[ 243 10 ] loss: 0.3842170536518097 2022-07-01 01:54:56.741867
Epoch:[ 243 11 ] loss: 0.3901315927505493 2022-07-01 01:54:57.152841
Epoch:[ 243 12 ] loss: 0.3888091742992401 2022-07-01 01:54:57.560858
Epoch:[ 243 13 ] loss: 0.38429251313209534 2022-07-01 01:54:57.970813
Epoch:[ 243 14 ] loss: 0.38642802834510803 2022-07-01 01:54:58.380209
Epoch:[ 243 15 ] loss: 0.38705766201019287 2022-07-01 01:54:58.788557
Epoch:[ 243 16 ] loss: 0.3869441747665405 2022-07-01 01:55:04.026620
Epoch:[ 243 17 ] loss: 0.38568150997161865 2022-07-01 01:55:04.438098
Epoch:[ 243 18 ] loss: 0.3855689764022827 2022-07-01 01:55:04.856964
Epoch:[ 243 19 ] loss: 0.38598084449768066 2022-07-01 01:55:05.264958
Training_Epoch:[ 243 ] Training_loss: 0.3859617725014687 2022-07-01 01:55:05.265973
learning rate:  0.0002361183241434826
val: 1 0.44475501775741577
val: 2 0.43495145440101624
val: 3 0.46350860595703125
val: 4 0.44158321619033813
val: 5 0.45668962597846985
val: 6 0.4367285370826721
val: 7 0.44742000102996826
val: 8 0.4451066553592682
val: 9 0.4442519247531891
val: 10 0.43574923276901245
val: 11 0.4472329914569855
val: 12 0.4437342584133148
val: 13 0.43773162364959717
val: 14 0.44953423738479614
val: 15 0.4581388235092163
val: 16 0.4509853422641754
val: 17 0.4415889382362366
val: 18 0.4415982961654663
val: 19 0.43989837169647217
val: 20 0.44668063521385193
val_Epoch:[ 243 ] val_loss: 0.44539338946342466 2022-07-01 01:55:09.164367
start training 2022-07-01 01:55:09.290327
Epoch:[ 244 0 ] loss: 0.3860706388950348 2022-07-01 01:55:23.732851
Epoch:[ 244 1 ] loss: 0.38597333431243896 2022-07-01 01:55:24.196474
Epoch:[ 244 2 ] loss: 0.38406607508659363 2022-07-01 01:55:24.616685
Epoch:[ 244 3 ] loss: 0.38635554909706116 2022-07-01 01:55:25.039403
Epoch:[ 244 4 ] loss: 0.3870006799697876 2022-07-01 01:55:25.461146
Epoch:[ 244 5 ] loss: 0.3879792094230652 2022-07-01 01:55:25.881615
Epoch:[ 244 6 ] loss: 0.3846096992492676 2022-07-01 01:55:26.302595
Epoch:[ 244 7 ] loss: 0.38762086629867554 2022-07-01 01:55:26.715750
Epoch:[ 244 8 ] loss: 0.3874361217021942 2022-07-01 01:55:27.138542
Epoch:[ 244 9 ] loss: 0.38475900888442993 2022-07-01 01:55:27.557441
Epoch:[ 244 10 ] loss: 0.38570156693458557 2022-07-01 01:55:27.979837
Epoch:[ 244 11 ] loss: 0.3883482813835144 2022-07-01 01:55:28.402334
Epoch:[ 244 12 ] loss: 0.3857854902744293 2022-07-01 01:55:28.823290
Epoch:[ 244 13 ] loss: 0.38670822978019714 2022-07-01 01:55:29.242730
Epoch:[ 244 14 ] loss: 0.38673123717308044 2022-07-01 01:55:29.663953
Epoch:[ 244 15 ] loss: 0.38501593470573425 2022-07-01 01:55:30.083885
Epoch:[ 244 16 ] loss: 0.3848840296268463 2022-07-01 01:55:36.172065
Epoch:[ 244 17 ] loss: 0.3845592737197876 2022-07-01 01:55:36.591709
Epoch:[ 244 18 ] loss: 0.3846285939216614 2022-07-01 01:55:37.013906
Epoch:[ 244 19 ] loss: 0.38617023825645447 2022-07-01 01:55:37.435981
Training_Epoch:[ 244 ] Training_loss: 0.386020202934742 2022-07-01 01:55:37.436837
learning rate:  0.0002361183241434826
netparams have been saved once 244
val: 1 0.445998877286911
val: 2 0.43559926748275757
val: 3 0.45188745856285095
val: 4 0.45006459951400757
val: 5 0.44506627321243286
val: 6 0.4499175250530243
val: 7 0.4391099512577057
val: 8 0.45318207144737244
val: 9 0.44129809737205505
val: 10 0.43489667773246765
val: 11 0.44739606976509094
val: 12 0.44080471992492676
val: 13 0.4443338215351105
val: 14 0.4522464871406555
val: 15 0.4492974579334259
val: 16 0.44070351123809814
val: 17 0.4432618021965027
val: 18 0.44495123624801636
val: 19 0.4575329124927521
val: 20 0.4441700279712677
val_Epoch:[ 244 ] val_loss: 0.44558594226837156 2022-07-01 01:55:41.331410
start training 2022-07-01 01:55:41.434813
Epoch:[ 245 0 ] loss: 0.3878360986709595 2022-07-01 01:55:55.652558
Epoch:[ 245 1 ] loss: 0.3862307369709015 2022-07-01 01:55:56.072506
Epoch:[ 245 2 ] loss: 0.38687199354171753 2022-07-01 01:55:56.493459
Epoch:[ 245 3 ] loss: 0.38481605052948 2022-07-01 01:55:56.913725
Epoch:[ 245 4 ] loss: 0.3851926028728485 2022-07-01 01:55:57.335573
Epoch:[ 245 5 ] loss: 0.38536322116851807 2022-07-01 01:55:57.758261
Epoch:[ 245 6 ] loss: 0.3844352960586548 2022-07-01 01:55:58.180364
Epoch:[ 245 7 ] loss: 0.387566477060318 2022-07-01 01:55:58.601255
Epoch:[ 245 8 ] loss: 0.3855447471141815 2022-07-01 01:55:59.023123
Epoch:[ 245 9 ] loss: 0.3870181143283844 2022-07-01 01:55:59.443031
Epoch:[ 245 10 ] loss: 0.38451793789863586 2022-07-01 01:55:59.866722
Epoch:[ 245 11 ] loss: 0.38519662618637085 2022-07-01 01:56:00.288963
Epoch:[ 245 12 ] loss: 0.38397857546806335 2022-07-01 01:56:00.711211
Epoch:[ 245 13 ] loss: 0.38669922947883606 2022-07-01 01:56:01.132742
Epoch:[ 245 14 ] loss: 0.3851756155490875 2022-07-01 01:56:01.553089
Epoch:[ 245 15 ] loss: 0.3880186676979065 2022-07-01 01:56:01.968504
Epoch:[ 245 16 ] loss: 0.3865720331668854 2022-07-01 01:56:07.356201
Epoch:[ 245 17 ] loss: 0.3871558904647827 2022-07-01 01:56:07.777937
Epoch:[ 245 18 ] loss: 0.3852179944515228 2022-07-01 01:56:08.200260
Epoch:[ 245 19 ] loss: 0.3871641457080841 2022-07-01 01:56:08.622384
Training_Epoch:[ 245 ] Training_loss: 0.38602860271930695 2022-07-01 01:56:08.623102
learning rate:  0.0002361183241434826
val: 1 0.4465652406215668
val: 2 0.4422259032726288
val: 3 0.44778335094451904
val: 4 0.4453428387641907
val: 5 0.4442775249481201
val: 6 0.4406884014606476
val: 7 0.45889055728912354
val: 8 0.4332454800605774
val: 9 0.45023927092552185
val: 10 0.4466622471809387
val: 11 0.4539761245250702
val: 12 0.4453964829444885
val: 13 0.4422670602798462
val: 14 0.45255324244499207
val: 15 0.4332652688026428
val: 16 0.44376784563064575
val: 17 0.44794899225234985
val: 18 0.44835513830184937
val: 19 0.44939881563186646
val: 20 0.4376707375049591
val_Epoch:[ 245 ] val_loss: 0.44552602618932724 2022-07-01 01:56:12.468221
start training 2022-07-01 01:56:12.588724
Epoch:[ 246 0 ] loss: 0.38707950711250305 2022-07-01 01:56:26.540603
Epoch:[ 246 1 ] loss: 0.3874927759170532 2022-07-01 01:56:27.458420
Epoch:[ 246 2 ] loss: 0.38437381386756897 2022-07-01 01:56:27.881362
Epoch:[ 246 3 ] loss: 0.388668954372406 2022-07-01 01:56:28.304690
Epoch:[ 246 4 ] loss: 0.38639891147613525 2022-07-01 01:56:28.725391
Epoch:[ 246 5 ] loss: 0.38587141036987305 2022-07-01 01:56:29.148027
Epoch:[ 246 6 ] loss: 0.3853474259376526 2022-07-01 01:56:29.574246
Epoch:[ 246 7 ] loss: 0.3855348825454712 2022-07-01 01:56:29.995594
Epoch:[ 246 8 ] loss: 0.3844466507434845 2022-07-01 01:56:30.409677
Epoch:[ 246 9 ] loss: 0.3853785991668701 2022-07-01 01:56:30.834529
Epoch:[ 246 10 ] loss: 0.3852471709251404 2022-07-01 01:56:31.242879
Epoch:[ 246 11 ] loss: 0.3850354850292206 2022-07-01 01:56:31.650460
Epoch:[ 246 12 ] loss: 0.38432231545448303 2022-07-01 01:56:32.060701
Epoch:[ 246 13 ] loss: 0.38716357946395874 2022-07-01 01:56:32.471932
Epoch:[ 246 14 ] loss: 0.38446325063705444 2022-07-01 01:56:32.882576
Epoch:[ 246 15 ] loss: 0.38613682985305786 2022-07-01 01:56:33.291642
Epoch:[ 246 16 ] loss: 0.38568514585494995 2022-07-01 01:56:38.301324
Epoch:[ 246 17 ] loss: 0.3869067430496216 2022-07-01 01:56:39.081877
Epoch:[ 246 18 ] loss: 0.38872137665748596 2022-07-01 01:56:39.491859
Epoch:[ 246 19 ] loss: 0.38722625374794006 2022-07-01 01:56:39.902594
Training_Epoch:[ 246 ] Training_loss: 0.38607505410909654 2022-07-01 01:56:39.903490
learning rate:  0.0002361183241434826
netparams have been saved once 246
val: 1 0.43921416997909546
val: 2 0.4426115155220032
val: 3 0.45287057757377625
val: 4 0.43771156668663025
val: 5 0.44284588098526
val: 6 0.44684454798698425
val: 7 0.42928844690322876
val: 8 0.45418545603752136
val: 9 0.43468889594078064
val: 10 0.45596522092819214
val: 11 0.4510365128517151
val: 12 0.4420302212238312
val: 13 0.4413034915924072
val: 14 0.44693461060523987
val: 15 0.4428280293941498
val: 16 0.43854495882987976
val: 17 0.4411925971508026
val: 18 0.4638422727584839
val: 19 0.45139142870903015
val: 20 0.45814618468284607
val_Epoch:[ 246 ] val_loss: 0.4456738293170929 2022-07-01 01:56:43.756140
start training 2022-07-01 01:56:43.859653
Epoch:[ 247 0 ] loss: 0.38407161831855774 2022-07-01 01:56:57.812967
Epoch:[ 247 1 ] loss: 0.3852647542953491 2022-07-01 01:56:58.599694
Epoch:[ 247 2 ] loss: 0.3878994286060333 2022-07-01 01:56:59.020182
Epoch:[ 247 3 ] loss: 0.3864242434501648 2022-07-01 01:56:59.438800
Epoch:[ 247 4 ] loss: 0.3850162923336029 2022-07-01 01:56:59.851888
Epoch:[ 247 5 ] loss: 0.3848118782043457 2022-07-01 01:57:00.270654
Epoch:[ 247 6 ] loss: 0.38592270016670227 2022-07-01 01:57:00.692590
Epoch:[ 247 7 ] loss: 0.3840115964412689 2022-07-01 01:57:01.113900
Epoch:[ 247 8 ] loss: 0.3870247006416321 2022-07-01 01:57:01.534127
Epoch:[ 247 9 ] loss: 0.3856363296508789 2022-07-01 01:57:01.954502
Epoch:[ 247 10 ] loss: 0.38862091302871704 2022-07-01 01:57:02.377976
Epoch:[ 247 11 ] loss: 0.3878161907196045 2022-07-01 01:57:02.796598
Epoch:[ 247 12 ] loss: 0.38693296909332275 2022-07-01 01:57:03.216498
Epoch:[ 247 13 ] loss: 0.38406288623809814 2022-07-01 01:57:03.637396
Epoch:[ 247 14 ] loss: 0.38751885294914246 2022-07-01 01:57:04.059709
Epoch:[ 247 15 ] loss: 0.3859463930130005 2022-07-01 01:57:04.483008
Epoch:[ 247 16 ] loss: 0.38591381907463074 2022-07-01 01:57:09.905498
Epoch:[ 247 17 ] loss: 0.3843654990196228 2022-07-01 01:57:10.325423
Epoch:[ 247 18 ] loss: 0.387257844209671 2022-07-01 01:57:10.752247
Epoch:[ 247 19 ] loss: 0.3865639269351959 2022-07-01 01:57:11.174780
Training_Epoch:[ 247 ] Training_loss: 0.38605414181947706 2022-07-01 01:57:11.175503
learning rate:  0.0002361183241434826
val: 1 0.4491138756275177
val: 2 0.4368666410446167
val: 3 0.4525529444217682
val: 4 0.4411138594150543
val: 5 0.43289583921432495
val: 6 0.44297680258750916
val: 7 0.45228809118270874
val: 8 0.4508231282234192
val: 9 0.450472891330719
val: 10 0.4445270597934723
val: 11 0.4495660960674286
val: 12 0.4449082911014557
val: 13 0.44149866700172424
val: 14 0.45359328389167786
val: 15 0.4406464397907257
val: 16 0.4424579441547394
val: 17 0.44680872559547424
val: 18 0.44470885396003723
val: 19 0.44861969351768494
val: 20 0.44721516966819763
val_Epoch:[ 247 ] val_loss: 0.4456827148795128 2022-07-01 01:57:15.172547
start training 2022-07-01 01:57:15.277112
Epoch:[ 248 0 ] loss: 0.3858160674571991 2022-07-01 01:57:29.346222
Epoch:[ 248 1 ] loss: 0.3875933289527893 2022-07-01 01:57:30.096818
Epoch:[ 248 2 ] loss: 0.3866489827632904 2022-07-01 01:57:30.513484
Epoch:[ 248 3 ] loss: 0.3870590925216675 2022-07-01 01:57:30.932434
Epoch:[ 248 4 ] loss: 0.38575270771980286 2022-07-01 01:57:31.352606
Epoch:[ 248 5 ] loss: 0.38593539595603943 2022-07-01 01:57:31.775075
Epoch:[ 248 6 ] loss: 0.3842451274394989 2022-07-01 01:57:32.195131
Epoch:[ 248 7 ] loss: 0.3839583396911621 2022-07-01 01:57:32.617247
Epoch:[ 248 8 ] loss: 0.38699325919151306 2022-07-01 01:57:33.042321
Epoch:[ 248 9 ] loss: 0.38797727227211 2022-07-01 01:57:33.462499
Epoch:[ 248 10 ] loss: 0.3852255940437317 2022-07-01 01:57:33.881939
Epoch:[ 248 11 ] loss: 0.3836783170700073 2022-07-01 01:57:34.302662
Epoch:[ 248 12 ] loss: 0.3853527009487152 2022-07-01 01:57:34.725012
Epoch:[ 248 13 ] loss: 0.3865804374217987 2022-07-01 01:57:35.144223
Epoch:[ 248 14 ] loss: 0.38505908846855164 2022-07-01 01:57:35.565978
Epoch:[ 248 15 ] loss: 0.3861955404281616 2022-07-01 01:57:35.987952
Epoch:[ 248 16 ] loss: 0.3850228190422058 2022-07-01 01:57:41.042324
Epoch:[ 248 17 ] loss: 0.3872087597846985 2022-07-01 01:57:42.041514
Epoch:[ 248 18 ] loss: 0.3853014409542084 2022-07-01 01:57:42.462725
Epoch:[ 248 19 ] loss: 0.3879656493663788 2022-07-01 01:57:42.882634
Training_Epoch:[ 248 ] Training_loss: 0.3859784960746765 2022-07-01 01:57:42.883296
learning rate:  0.0002361183241434826
netparams have been saved once 248
val: 1 0.43984562158584595
val: 2 0.43150684237480164
val: 3 0.44338253140449524
val: 4 0.4491337537765503
val: 5 0.44267526268959045
val: 6 0.44320207834243774
val: 7 0.45892322063446045
val: 8 0.4477435052394867
val: 9 0.43968141078948975
val: 10 0.4405357539653778
val: 11 0.4411199986934662
val: 12 0.4631187319755554
val: 13 0.44507643580436707
val: 14 0.45458805561065674
val: 15 0.44318920373916626
val: 16 0.4477686285972595
val: 17 0.433117538690567
val: 18 0.4355457127094269
val: 19 0.4448995590209961
val: 20 0.45618951320648193
val_Epoch:[ 248 ] val_loss: 0.44506216794252396 2022-07-01 01:57:46.735823
start training 2022-07-01 01:57:46.841237
Epoch:[ 249 0 ] loss: 0.3871065080165863 2022-07-01 01:58:00.954540
Epoch:[ 249 1 ] loss: 0.38679608702659607 2022-07-01 01:58:01.420152
Epoch:[ 249 2 ] loss: 0.3851088583469391 2022-07-01 01:58:01.836299
Epoch:[ 249 3 ] loss: 0.38660404086112976 2022-07-01 01:58:02.257392
Epoch:[ 249 4 ] loss: 0.38700854778289795 2022-07-01 01:58:02.665140
Epoch:[ 249 5 ] loss: 0.38386860489845276 2022-07-01 01:58:03.073503
Epoch:[ 249 6 ] loss: 0.3860304057598114 2022-07-01 01:58:03.481055
Epoch:[ 249 7 ] loss: 0.3853263556957245 2022-07-01 01:58:03.889651
Epoch:[ 249 8 ] loss: 0.38654381036758423 2022-07-01 01:58:04.300401
Epoch:[ 249 9 ] loss: 0.3874020278453827 2022-07-01 01:58:04.715072
Epoch:[ 249 10 ] loss: 0.38615697622299194 2022-07-01 01:58:05.122979
Epoch:[ 249 11 ] loss: 0.38385921716690063 2022-07-01 01:58:05.531335
Epoch:[ 249 12 ] loss: 0.38413187861442566 2022-07-01 01:58:05.940919
Epoch:[ 249 13 ] loss: 0.3855990171432495 2022-07-01 01:58:06.348634
Epoch:[ 249 14 ] loss: 0.38747522234916687 2022-07-01 01:58:06.757114
Epoch:[ 249 15 ] loss: 0.38529354333877563 2022-07-01 01:58:07.168680
Epoch:[ 249 16 ] loss: 0.3885369300842285 2022-07-01 01:58:12.790610
Epoch:[ 249 17 ] loss: 0.3854496479034424 2022-07-01 01:58:13.199662
Epoch:[ 249 18 ] loss: 0.38358795642852783 2022-07-01 01:58:13.805727
Epoch:[ 249 19 ] loss: 0.38675203919410706 2022-07-01 01:58:14.225211
Training_Epoch:[ 249 ] Training_loss: 0.38593188375234605 2022-07-01 01:58:14.225995
learning rate:  0.0002361183241434826
val: 1 0.446914404630661
val: 2 0.43775418400764465
val: 3 0.4440780282020569
val: 4 0.44430044293403625
val: 5 0.4476656913757324
val: 6 0.4358483850955963
val: 7 0.4490782618522644
val: 8 0.44031578302383423
val: 9 0.44984957575798035
val: 10 0.4448469579219818
val: 11 0.43854647874832153
val: 12 0.46195095777511597
val: 13 0.4432591199874878
val: 14 0.45630282163619995
val: 15 0.4492369294166565
val: 16 0.4432307183742523
val: 17 0.43574681878089905
val: 18 0.44941431283950806
val: 19 0.44031649827957153
val: 20 0.43975719809532166
val_Epoch:[ 249 ] val_loss: 0.44492067843675615 2022-07-01 01:58:17.989507
start training 2022-07-01 01:58:18.092156
Epoch:[ 250 0 ] loss: 0.38617101311683655 2022-07-01 01:58:32.354382
Epoch:[ 250 1 ] loss: 0.38758599758148193 2022-07-01 01:58:32.774598
Epoch:[ 250 2 ] loss: 0.38569003343582153 2022-07-01 01:58:33.196602
Epoch:[ 250 3 ] loss: 0.3874863088130951 2022-07-01 01:58:33.618664
Epoch:[ 250 4 ] loss: 0.38492482900619507 2022-07-01 01:58:34.039874
Epoch:[ 250 5 ] loss: 0.38650819659233093 2022-07-01 01:58:34.458987
Epoch:[ 250 6 ] loss: 0.38595885038375854 2022-07-01 01:58:34.881786
Epoch:[ 250 7 ] loss: 0.3843177258968353 2022-07-01 01:58:35.292689
Epoch:[ 250 8 ] loss: 0.3856368064880371 2022-07-01 01:58:35.714237
Epoch:[ 250 9 ] loss: 0.3849833011627197 2022-07-01 01:58:36.137225
Epoch:[ 250 10 ] loss: 0.3842916786670685 2022-07-01 01:58:36.559634
Epoch:[ 250 11 ] loss: 0.3866710960865021 2022-07-01 01:58:36.980748
Epoch:[ 250 12 ] loss: 0.38617369532585144 2022-07-01 01:58:37.405346
Epoch:[ 250 13 ] loss: 0.38630416989326477 2022-07-01 01:58:37.826534
Epoch:[ 250 14 ] loss: 0.38433632254600525 2022-07-01 01:58:38.247094
Epoch:[ 250 15 ] loss: 0.3846108317375183 2022-07-01 01:58:38.664681
Epoch:[ 250 16 ] loss: 0.3855654299259186 2022-07-01 01:58:44.199433
Epoch:[ 250 17 ] loss: 0.38714829087257385 2022-07-01 01:58:44.620214
Epoch:[ 250 18 ] loss: 0.3862418234348297 2022-07-01 01:58:45.050023
Epoch:[ 250 19 ] loss: 0.3872186243534088 2022-07-01 01:58:45.471062
Training_Epoch:[ 250 ] Training_loss: 0.38589125126600266 2022-07-01 01:58:45.471975
learning rate:  0.0002361183241434826
netparams have been saved once 250
val: 1 0.4471104145050049
val: 2 0.4393845796585083
val: 3 0.4590006172657013
val: 4 0.4398954212665558
val: 5 0.4473232924938202
val: 6 0.44558554887771606
val: 7 0.4386802017688751
val: 8 0.4444117844104767
val: 9 0.44556739926338196
val: 10 0.44949397444725037
val: 11 0.45204994082450867
val: 12 0.4442104995250702
val: 13 0.4558887481689453
val: 14 0.44318875670433044
val: 15 0.4442062973976135
val: 16 0.44899141788482666
val: 17 0.4456585943698883
val: 18 0.4440973103046417
val: 19 0.424332857131958
val: 20 0.45953384041786194
val_Epoch:[ 250 ] val_loss: 0.4459305748343468 2022-07-01 01:58:49.282731
