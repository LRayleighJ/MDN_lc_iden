GPU: True
80
start training 2022-06-30 23:21:00.944641
Epoch:[ 1 0 ] loss: 0.6984596252441406 2022-06-30 23:21:25.253936
Epoch:[ 1 1 ] loss: 0.6825357675552368 2022-06-30 23:21:25.770619
Epoch:[ 1 2 ] loss: 0.6548095941543579 2022-06-30 23:21:26.223019
Epoch:[ 1 3 ] loss: 0.6525712013244629 2022-06-30 23:21:26.673846
Epoch:[ 1 4 ] loss: 0.6316362023353577 2022-06-30 23:21:27.127368
Epoch:[ 1 5 ] loss: 0.6351611614227295 2022-06-30 23:21:27.575085
Epoch:[ 1 6 ] loss: 0.6255806684494019 2022-06-30 23:21:28.025110
Epoch:[ 1 7 ] loss: 0.6233500242233276 2022-06-30 23:21:28.474308
Epoch:[ 1 8 ] loss: 0.6192945241928101 2022-06-30 23:21:28.923446
Epoch:[ 1 9 ] loss: 0.6187952756881714 2022-06-30 23:21:29.372226
Epoch:[ 1 10 ] loss: 0.6172884702682495 2022-06-30 23:21:29.815879
Epoch:[ 1 11 ] loss: 0.6155253648757935 2022-06-30 23:21:30.262042
Epoch:[ 1 12 ] loss: 0.6091291308403015 2022-06-30 23:21:30.708875
Epoch:[ 1 13 ] loss: 0.610553503036499 2022-06-30 23:21:31.161170
Epoch:[ 1 14 ] loss: 0.6112494468688965 2022-06-30 23:21:31.608249
Epoch:[ 1 15 ] loss: 0.6048244833946228 2022-06-30 23:21:32.056993
Epoch:[ 1 16 ] loss: 0.6012911200523376 2022-06-30 23:21:32.506138
Epoch:[ 1 17 ] loss: 0.5979994535446167 2022-06-30 23:21:32.954333
Epoch:[ 1 18 ] loss: 0.5964246988296509 2022-06-30 23:21:33.411558
Epoch:[ 1 19 ] loss: 0.5988313555717468 2022-06-30 23:21:33.843954
Training_Epoch:[ 1 ] Training_loss: 0.6252655535936356 2022-06-30 23:21:33.844616
learning rate:  0.05
val: 1 0.7937483191490173
val: 2 0.7622745633125305
val: 3 0.7898479700088501
val: 4 0.7610604763031006
val: 5 0.7885565757751465
val: 6 0.7750181555747986
val: 7 0.7918567657470703
val: 8 0.7960873246192932
val: 9 0.7890802025794983
val: 10 0.7841167449951172
val: 11 0.7747793197631836
val: 12 0.7947248220443726
val: 13 0.7720739841461182
val: 14 0.7776966094970703
val: 15 0.7694709897041321
val: 16 0.770942747592926
val: 17 0.7762051224708557
val: 18 0.7852671146392822
val: 19 0.7912769913673401
val: 20 0.7718287706375122
val_Epoch:[ 1 ] val_loss: 0.7807956784963608 2022-06-30 23:21:37.402944
start training 2022-06-30 23:21:37.509767
Epoch:[ 2 0 ] loss: 0.5963482856750488 2022-06-30 23:21:51.844335
Epoch:[ 2 1 ] loss: 0.5959940552711487 2022-06-30 23:21:52.292969
Epoch:[ 2 2 ] loss: 0.5943151712417603 2022-06-30 23:21:52.718005
Epoch:[ 2 3 ] loss: 0.5933154225349426 2022-06-30 23:21:53.144930
Epoch:[ 2 4 ] loss: 0.5919302701950073 2022-06-30 23:21:53.572140
Epoch:[ 2 5 ] loss: 0.5904154181480408 2022-06-30 23:21:54.002693
Epoch:[ 2 6 ] loss: 0.587335467338562 2022-06-30 23:21:54.430233
Epoch:[ 2 7 ] loss: 0.5891444683074951 2022-06-30 23:21:54.857966
Epoch:[ 2 8 ] loss: 0.5858244895935059 2022-06-30 23:21:55.288606
Epoch:[ 2 9 ] loss: 0.5862823128700256 2022-06-30 23:21:55.714662
Epoch:[ 2 10 ] loss: 0.5812299251556396 2022-06-30 23:21:56.144447
Epoch:[ 2 11 ] loss: 0.5853920578956604 2022-06-30 23:21:56.569035
Epoch:[ 2 12 ] loss: 0.5852903127670288 2022-06-30 23:21:56.998618
Epoch:[ 2 13 ] loss: 0.5806394815444946 2022-06-30 23:21:57.426867
Epoch:[ 2 14 ] loss: 0.579415500164032 2022-06-30 23:21:57.853846
Epoch:[ 2 15 ] loss: 0.5789830684661865 2022-06-30 23:21:58.283048
Epoch:[ 2 16 ] loss: 0.5776664614677429 2022-06-30 23:22:03.535999
Epoch:[ 2 17 ] loss: 0.5770501494407654 2022-06-30 23:22:03.967212
Epoch:[ 2 18 ] loss: 0.5767949819564819 2022-06-30 23:22:04.401640
Epoch:[ 2 19 ] loss: 0.5795338153839111 2022-06-30 23:22:04.826957
Training_Epoch:[ 2 ] Training_loss: 0.585645055770874 2022-06-30 23:22:04.827638
learning rate:  0.05
netparams have been saved once 2
val: 1 0.7006317377090454
val: 2 0.730760931968689
val: 3 0.6979470252990723
val: 4 0.7086690664291382
val: 5 0.7115205526351929
val: 6 0.7028433084487915
val: 7 0.7048889398574829
val: 8 0.7011430263519287
val: 9 0.7108700275421143
val: 10 0.7073341608047485
val: 11 0.7189078330993652
val: 12 0.7130801677703857
val: 13 0.6997132301330566
val: 14 0.709216296672821
val: 15 0.7150803804397583
val: 16 0.7260603904724121
val: 17 0.7196475863456726
val: 18 0.703592836856842
val: 19 0.7164486646652222
val: 20 0.7217824459075928
val_Epoch:[ 2 ] val_loss: 0.7110069304704666 2022-06-30 23:22:08.539739
start training 2022-06-30 23:22:08.640203
Epoch:[ 3 0 ] loss: 0.5744813680648804 2022-06-30 23:22:22.584156
Epoch:[ 3 1 ] loss: 0.574914813041687 2022-06-30 23:22:23.162803
Epoch:[ 3 2 ] loss: 0.578249454498291 2022-06-30 23:22:23.616319
Epoch:[ 3 3 ] loss: 0.5743540525436401 2022-06-30 23:22:24.045809
Epoch:[ 3 4 ] loss: 0.5709770917892456 2022-06-30 23:22:24.477011
Epoch:[ 3 5 ] loss: 0.5735327005386353 2022-06-30 23:22:24.911862
Epoch:[ 3 6 ] loss: 0.5735752582550049 2022-06-30 23:22:25.342023
Epoch:[ 3 7 ] loss: 0.568865954875946 2022-06-30 23:22:25.772854
Epoch:[ 3 8 ] loss: 0.5669040679931641 2022-06-30 23:22:26.203984
Epoch:[ 3 9 ] loss: 0.5656037330627441 2022-06-30 23:22:26.634151
Epoch:[ 3 10 ] loss: 0.5712481141090393 2022-06-30 23:22:27.063535
Epoch:[ 3 11 ] loss: 0.5626490116119385 2022-06-30 23:22:27.493393
Epoch:[ 3 12 ] loss: 0.5628514885902405 2022-06-30 23:22:27.923598
Epoch:[ 3 13 ] loss: 0.5656054019927979 2022-06-30 23:22:28.353842
Epoch:[ 3 14 ] loss: 0.5631260275840759 2022-06-30 23:22:28.784377
Epoch:[ 3 15 ] loss: 0.5624648928642273 2022-06-30 23:22:29.215621
Epoch:[ 3 16 ] loss: 0.563249945640564 2022-06-30 23:22:34.504326
Epoch:[ 3 17 ] loss: 0.5601208806037903 2022-06-30 23:22:34.938012
Epoch:[ 3 18 ] loss: 0.5619052648544312 2022-06-30 23:22:35.374822
Epoch:[ 3 19 ] loss: 0.5610722899436951 2022-06-30 23:22:35.802850
Training_Epoch:[ 3 ] Training_loss: 0.567787590622902 2022-06-30 23:22:35.803508
learning rate:  0.05
val: 1 0.5697876214981079
val: 2 0.563644289970398
val: 3 0.565606415271759
val: 4 0.5645536780357361
val: 5 0.5766049027442932
val: 6 0.570979118347168
val: 7 0.5716440081596375
val: 8 0.5732290744781494
val: 9 0.5721374154090881
val: 10 0.5714775919914246
val: 11 0.5598562955856323
val: 12 0.5621606111526489
val: 13 0.5649535059928894
val: 14 0.5564548373222351
val: 15 0.5684162378311157
val: 16 0.554371178150177
val: 17 0.5745941996574402
val: 18 0.5709413290023804
val: 19 0.5671079158782959
val: 20 0.5679334998130798
val_Epoch:[ 3 ] val_loss: 0.5673226863145828 2022-06-30 23:22:39.481667
start training 2022-06-30 23:22:39.580460
Epoch:[ 4 0 ] loss: 0.5589909553527832 2022-06-30 23:22:54.659101
Epoch:[ 4 1 ] loss: 0.5591020584106445 2022-06-30 23:22:55.087451
Epoch:[ 4 2 ] loss: 0.5566586256027222 2022-06-30 23:22:55.515796
Epoch:[ 4 3 ] loss: 0.560366690158844 2022-06-30 23:22:55.943400
Epoch:[ 4 4 ] loss: 0.5613991618156433 2022-06-30 23:22:56.374401
Epoch:[ 4 5 ] loss: 0.5614995956420898 2022-06-30 23:22:56.807144
Epoch:[ 4 6 ] loss: 0.5599853992462158 2022-06-30 23:22:57.233069
Epoch:[ 4 7 ] loss: 0.5608518719673157 2022-06-30 23:22:57.659019
Epoch:[ 4 8 ] loss: 0.5541110634803772 2022-06-30 23:22:58.088487
Epoch:[ 4 9 ] loss: 0.5574829578399658 2022-06-30 23:22:58.523841
Epoch:[ 4 10 ] loss: 0.5510072112083435 2022-06-30 23:22:58.951290
Epoch:[ 4 11 ] loss: 0.5574422478675842 2022-06-30 23:22:59.381014
Epoch:[ 4 12 ] loss: 0.553083598613739 2022-06-30 23:22:59.809433
Epoch:[ 4 13 ] loss: 0.5547162890434265 2022-06-30 23:23:00.239300
Epoch:[ 4 14 ] loss: 0.5511249303817749 2022-06-30 23:23:00.667266
Epoch:[ 4 15 ] loss: 0.5484545230865479 2022-06-30 23:23:01.096064
Epoch:[ 4 16 ] loss: 0.5525956153869629 2022-06-30 23:23:06.492324
Epoch:[ 4 17 ] loss: 0.5512990951538086 2022-06-30 23:23:06.918429
Epoch:[ 4 18 ] loss: 0.5516562461853027 2022-06-30 23:23:07.355798
Epoch:[ 4 19 ] loss: 0.5540938973426819 2022-06-30 23:23:07.791126
Training_Epoch:[ 4 ] Training_loss: 0.5557961016893387 2022-06-30 23:23:07.791796
learning rate:  0.05
netparams have been saved once 4
val: 1 0.5576789379119873
val: 2 0.572820246219635
val: 3 0.5570175647735596
val: 4 0.5588973760604858
val: 5 0.57187819480896
val: 6 0.5648333430290222
val: 7 0.5550549626350403
val: 8 0.5676739811897278
val: 9 0.5589202642440796
val: 10 0.5590466260910034
val: 11 0.5656534433364868
val: 12 0.5620144009590149
val: 13 0.5661885738372803
val: 14 0.5665388703346252
val: 15 0.566698431968689
val: 16 0.576890230178833
val: 17 0.5529235601425171
val: 18 0.5528891086578369
val: 19 0.5608813166618347
val: 20 0.5529212355613708
val_Epoch:[ 4 ] val_loss: 0.5623710334300995 2022-06-30 23:23:11.525344
start training 2022-06-30 23:23:11.622099
Epoch:[ 5 0 ] loss: 0.5484299659729004 2022-06-30 23:23:26.454059
Epoch:[ 5 1 ] loss: 0.5520837903022766 2022-06-30 23:23:26.882679
Epoch:[ 5 2 ] loss: 0.5459206104278564 2022-06-30 23:23:27.313573
Epoch:[ 5 3 ] loss: 0.5479187369346619 2022-06-30 23:23:27.745017
Epoch:[ 5 4 ] loss: 0.5479735732078552 2022-06-30 23:23:28.177113
Epoch:[ 5 5 ] loss: 0.5503113865852356 2022-06-30 23:23:28.606119
Epoch:[ 5 6 ] loss: 0.5501834750175476 2022-06-30 23:23:29.035984
Epoch:[ 5 7 ] loss: 0.5461518168449402 2022-06-30 23:23:29.464409
Epoch:[ 5 8 ] loss: 0.543717622756958 2022-06-30 23:23:29.901256
Epoch:[ 5 9 ] loss: 0.5465553998947144 2022-06-30 23:23:30.332869
Epoch:[ 5 10 ] loss: 0.5426356196403503 2022-06-30 23:23:30.762636
Epoch:[ 5 11 ] loss: 0.5456799864768982 2022-06-30 23:23:31.196657
Epoch:[ 5 12 ] loss: 0.5437769889831543 2022-06-30 23:23:31.629145
Epoch:[ 5 13 ] loss: 0.5483112335205078 2022-06-30 23:23:32.063193
Epoch:[ 5 14 ] loss: 0.5502510070800781 2022-06-30 23:23:32.491749
Epoch:[ 5 15 ] loss: 0.5459570288658142 2022-06-30 23:23:32.921078
Epoch:[ 5 16 ] loss: 0.5463184714317322 2022-06-30 23:23:37.891201
Epoch:[ 5 17 ] loss: 0.5450207591056824 2022-06-30 23:23:38.321482
Epoch:[ 5 18 ] loss: 0.5452495217323303 2022-06-30 23:23:38.762148
Epoch:[ 5 19 ] loss: 0.5434293746948242 2022-06-30 23:23:39.194109
Training_Epoch:[ 5 ] Training_loss: 0.5467938184738159 2022-06-30 23:23:39.194721
learning rate:  0.05
val: 1 0.5379936099052429
val: 2 0.5456186532974243
val: 3 0.5537737607955933
val: 4 0.5376222133636475
val: 5 0.5422062277793884
val: 6 0.547764241695404
val: 7 0.541458010673523
val: 8 0.5540538430213928
val: 9 0.5603843927383423
val: 10 0.5459656119346619
val: 11 0.5484678745269775
val: 12 0.5579135417938232
val: 13 0.547156035900116
val: 14 0.5387489199638367
val: 15 0.5462620854377747
val: 16 0.5420122146606445
val: 17 0.5477259159088135
val: 18 0.5556878447532654
val: 19 0.5428737998008728
val: 20 0.5524543523788452
val_Epoch:[ 5 ] val_loss: 0.5473071575164795 2022-06-30 23:23:42.791012
start training 2022-06-30 23:23:42.886120
Epoch:[ 6 0 ] loss: 0.5431773066520691 2022-06-30 23:23:57.156959
Epoch:[ 6 1 ] loss: 0.5417122840881348 2022-06-30 23:23:57.685007
Epoch:[ 6 2 ] loss: 0.5394703149795532 2022-06-30 23:23:58.119356
Epoch:[ 6 3 ] loss: 0.5398670434951782 2022-06-30 23:23:58.550851
Epoch:[ 6 4 ] loss: 0.538903534412384 2022-06-30 23:23:58.981578
Epoch:[ 6 5 ] loss: 0.538875162601471 2022-06-30 23:23:59.410129
Epoch:[ 6 6 ] loss: 0.5335383415222168 2022-06-30 23:23:59.839086
Epoch:[ 6 7 ] loss: 0.536419689655304 2022-06-30 23:24:00.270834
Epoch:[ 6 8 ] loss: 0.5333107709884644 2022-06-30 23:24:00.701515
Epoch:[ 6 9 ] loss: 0.5414740443229675 2022-06-30 23:24:01.132289
Epoch:[ 6 10 ] loss: 0.5401091575622559 2022-06-30 23:24:01.562664
Epoch:[ 6 11 ] loss: 0.5514130592346191 2022-06-30 23:24:01.998641
Epoch:[ 6 12 ] loss: 0.5433928966522217 2022-06-30 23:24:02.428939
Epoch:[ 6 13 ] loss: 0.5414155125617981 2022-06-30 23:24:02.859106
Epoch:[ 6 14 ] loss: 0.5425797700881958 2022-06-30 23:24:03.289650
Epoch:[ 6 15 ] loss: 0.5420752763748169 2022-06-30 23:24:03.717873
Epoch:[ 6 16 ] loss: 0.5405581593513489 2022-06-30 23:24:08.908196
Epoch:[ 6 17 ] loss: 0.5401396155357361 2022-06-30 23:24:09.341404
Epoch:[ 6 18 ] loss: 0.5365205407142639 2022-06-30 23:24:09.781524
Epoch:[ 6 19 ] loss: 0.5393859148025513 2022-06-30 23:24:10.210395
Training_Epoch:[ 6 ] Training_loss: 0.5402169197797775 2022-06-30 23:24:10.211032
learning rate:  0.05
netparams have been saved once 6
val: 1 0.8584040999412537
val: 2 0.8624095320701599
val: 3 0.8463358879089355
val: 4 0.8774455785751343
val: 5 0.8628184795379639
val: 6 0.8537931442260742
val: 7 0.8731614947319031
val: 8 0.868130087852478
val: 9 0.8716803193092346
val: 10 0.864672839641571
val: 11 0.8620805144309998
val: 12 0.8683941960334778
val: 13 0.8551902770996094
val: 14 0.8631476759910583
val: 15 0.8687883019447327
val: 16 0.8623510599136353
val: 17 0.8548749685287476
val: 18 0.862066924571991
val: 19 0.8596401214599609
val: 20 0.8573131561279297
val_Epoch:[ 6 ] val_loss: 0.8626349329948425 2022-06-30 23:24:13.827199
start training 2022-06-30 23:24:13.925667
Epoch:[ 7 0 ] loss: 0.5347872972488403 2022-06-30 23:24:28.700597
Epoch:[ 7 1 ] loss: 0.5362867116928101 2022-06-30 23:24:29.131194
Epoch:[ 7 2 ] loss: 0.5316075682640076 2022-06-30 23:24:29.560104
Epoch:[ 7 3 ] loss: 0.5365520119667053 2022-06-30 23:24:29.987490
Epoch:[ 7 4 ] loss: 0.5367324352264404 2022-06-30 23:24:30.418856
Epoch:[ 7 5 ] loss: 0.5367160439491272 2022-06-30 23:24:30.850147
Epoch:[ 7 6 ] loss: 0.5301815271377563 2022-06-30 23:24:31.285250
Epoch:[ 7 7 ] loss: 0.5308687686920166 2022-06-30 23:24:31.713780
Epoch:[ 7 8 ] loss: 0.5341182351112366 2022-06-30 23:24:32.148805
Epoch:[ 7 9 ] loss: 0.5283922553062439 2022-06-30 23:24:32.578913
Epoch:[ 7 10 ] loss: 0.5307165384292603 2022-06-30 23:24:33.009046
Epoch:[ 7 11 ] loss: 0.5280603766441345 2022-06-30 23:24:33.441235
Epoch:[ 7 12 ] loss: 0.529580295085907 2022-06-30 23:24:33.873536
Epoch:[ 7 13 ] loss: 0.5311267375946045 2022-06-30 23:24:34.313207
Epoch:[ 7 14 ] loss: 0.5251740217208862 2022-06-30 23:24:34.742002
Epoch:[ 7 15 ] loss: 0.5296335816383362 2022-06-30 23:24:35.172134
Epoch:[ 7 16 ] loss: 0.5283859968185425 2022-06-30 23:24:40.259165
Epoch:[ 7 17 ] loss: 0.5295712947845459 2022-06-30 23:24:40.688145
Epoch:[ 7 18 ] loss: 0.5290760397911072 2022-06-30 23:24:41.140487
Epoch:[ 7 19 ] loss: 0.5247995853424072 2022-06-30 23:24:41.577608
Training_Epoch:[ 7 ] Training_loss: 0.5311183661222458 2022-06-30 23:24:41.578246
learning rate:  0.05
val: 1 0.5559648275375366
val: 2 0.5690035223960876
val: 3 0.5684008002281189
val: 4 0.5519784688949585
val: 5 0.5674628615379333
val: 6 0.5379310250282288
val: 7 0.559311032295227
val: 8 0.5604002475738525
val: 9 0.5582695007324219
val: 10 0.5596688985824585
val: 11 0.5645835995674133
val: 12 0.5739778876304626
val: 13 0.5526613593101501
val: 14 0.561663031578064
val: 15 0.5775294303894043
val: 16 0.5619080662727356
val: 17 0.556001603603363
val: 18 0.5691813230514526
val: 19 0.5652661323547363
val: 20 0.5496640801429749
val_Epoch:[ 7 ] val_loss: 0.561041384935379 2022-06-30 23:24:45.204238
start training 2022-06-30 23:24:45.302637
Epoch:[ 8 0 ] loss: 0.5271914601325989 2022-06-30 23:25:00.001832
Epoch:[ 8 1 ] loss: 0.5282366275787354 2022-06-30 23:25:00.456168
Epoch:[ 8 2 ] loss: 0.5254287123680115 2022-06-30 23:25:00.886023
Epoch:[ 8 3 ] loss: 0.5258737802505493 2022-06-30 23:25:01.316895
Epoch:[ 8 4 ] loss: 0.5278821587562561 2022-06-30 23:25:01.750605
Epoch:[ 8 5 ] loss: 0.5270965099334717 2022-06-30 23:25:02.181687
Epoch:[ 8 6 ] loss: 0.5290145874023438 2022-06-30 23:25:02.612246
Epoch:[ 8 7 ] loss: 0.5265592932701111 2022-06-30 23:25:03.041893
Epoch:[ 8 8 ] loss: 0.5277473330497742 2022-06-30 23:25:03.473766
Epoch:[ 8 9 ] loss: 0.5191449522972107 2022-06-30 23:25:03.907926
Epoch:[ 8 10 ] loss: 0.5224989652633667 2022-06-30 23:25:04.337499
Epoch:[ 8 11 ] loss: 0.5256808400154114 2022-06-30 23:25:04.765971
Epoch:[ 8 12 ] loss: 0.5228064060211182 2022-06-30 23:25:05.196764
Epoch:[ 8 13 ] loss: 0.5192612409591675 2022-06-30 23:25:05.632304
Epoch:[ 8 14 ] loss: 0.5241103172302246 2022-06-30 23:25:06.062156
Epoch:[ 8 15 ] loss: 0.5172554850578308 2022-06-30 23:25:06.492297
Epoch:[ 8 16 ] loss: 0.5187771320343018 2022-06-30 23:25:11.520629
Epoch:[ 8 17 ] loss: 0.5177198052406311 2022-06-30 23:25:12.176028
Epoch:[ 8 18 ] loss: 0.5193113684654236 2022-06-30 23:25:12.607961
Epoch:[ 8 19 ] loss: 0.518758237361908 2022-06-30 23:25:13.042706
Training_Epoch:[ 8 ] Training_loss: 0.5235177606344223 2022-06-30 23:25:13.043322
learning rate:  0.05
netparams have been saved once 8
val: 1 0.5437334775924683
val: 2 0.5441791415214539
val: 3 0.5401980876922607
val: 4 0.5516384840011597
val: 5 0.5334509611129761
val: 6 0.5334386229515076
val: 7 0.5311455726623535
val: 8 0.5510475039482117
val: 9 0.5276798009872437
val: 10 0.5389894247055054
val: 11 0.541797399520874
val: 12 0.5366321206092834
val: 13 0.5417395830154419
val: 14 0.537384033203125
val: 15 0.5505325794219971
val: 16 0.5300959944725037
val: 17 0.5448153018951416
val: 18 0.5395104289054871
val: 19 0.5433001518249512
val: 20 0.5365219712257385
val_Epoch:[ 8 ] val_loss: 0.5398915320634842 2022-06-30 23:25:16.739299
start training 2022-06-30 23:25:16.839075
Epoch:[ 9 0 ] loss: 0.5171614289283752 2022-06-30 23:25:31.231506
Epoch:[ 9 1 ] loss: 0.5194007158279419 2022-06-30 23:25:31.681275
Epoch:[ 9 2 ] loss: 0.5214059352874756 2022-06-30 23:25:32.116203
Epoch:[ 9 3 ] loss: 0.5195926427841187 2022-06-30 23:25:32.545403
Epoch:[ 9 4 ] loss: 0.5262883305549622 2022-06-30 23:25:32.976834
Epoch:[ 9 5 ] loss: 0.5156121253967285 2022-06-30 23:25:33.404948
Epoch:[ 9 6 ] loss: 0.5221847891807556 2022-06-30 23:25:33.835976
Epoch:[ 9 7 ] loss: 0.5143409967422485 2022-06-30 23:25:34.266773
Epoch:[ 9 8 ] loss: 0.5204269886016846 2022-06-30 23:25:34.699054
Epoch:[ 9 9 ] loss: 0.5177597999572754 2022-06-30 23:25:35.129571
Epoch:[ 9 10 ] loss: 0.5173758864402771 2022-06-30 23:25:35.558394
Epoch:[ 9 11 ] loss: 0.514747142791748 2022-06-30 23:25:35.994923
Epoch:[ 9 12 ] loss: 0.5162096619606018 2022-06-30 23:25:36.434552
Epoch:[ 9 13 ] loss: 0.5128299593925476 2022-06-30 23:25:36.869424
Epoch:[ 9 14 ] loss: 0.5124292969703674 2022-06-30 23:25:37.300156
Epoch:[ 9 15 ] loss: 0.5121238231658936 2022-06-30 23:25:37.730310
Epoch:[ 9 16 ] loss: 0.5133104920387268 2022-06-30 23:25:42.642921
Epoch:[ 9 17 ] loss: 0.5157272219657898 2022-06-30 23:25:43.071806
Epoch:[ 9 18 ] loss: 0.5155888199806213 2022-06-30 23:25:43.512369
Epoch:[ 9 19 ] loss: 0.5182693600654602 2022-06-30 23:25:43.945907
Training_Epoch:[ 9 ] Training_loss: 0.51713927090168 2022-06-30 23:25:43.946577
learning rate:  0.05
val: 1 0.5301381349563599
val: 2 0.5437912940979004
val: 3 0.5596244931221008
val: 4 0.5318055152893066
val: 5 0.5307747721672058
val: 6 0.531969428062439
val: 7 0.5211452841758728
val: 8 0.5400515794754028
val: 9 0.5387222766876221
val: 10 0.5347214937210083
val: 11 0.5557856559753418
val: 12 0.540718138217926
val: 13 0.5389857292175293
val: 14 0.5383266806602478
val: 15 0.5313655138015747
val: 16 0.5269502997398376
val: 17 0.5338473916053772
val: 18 0.5485401153564453
val: 19 0.5343475341796875
val: 20 0.5327495336532593
val_Epoch:[ 9 ] val_loss: 0.5372180432081223 2022-06-30 23:25:47.602460
start training 2022-06-30 23:25:47.708877
Epoch:[ 10 0 ] loss: 0.5154656767845154 2022-06-30 23:26:02.514837
Epoch:[ 10 1 ] loss: 0.5133256912231445 2022-06-30 23:26:02.946139
Epoch:[ 10 2 ] loss: 0.5156380534172058 2022-06-30 23:26:03.375340
Epoch:[ 10 3 ] loss: 0.512315034866333 2022-06-30 23:26:03.803912
Epoch:[ 10 4 ] loss: 0.5092280507087708 2022-06-30 23:26:04.241798
Epoch:[ 10 5 ] loss: 0.5133576989173889 2022-06-30 23:26:04.670671
Epoch:[ 10 6 ] loss: 0.511512815952301 2022-06-30 23:26:05.098525
Epoch:[ 10 7 ] loss: 0.5130689144134521 2022-06-30 23:26:05.529258
Epoch:[ 10 8 ] loss: 0.511416494846344 2022-06-30 23:26:05.958356
Epoch:[ 10 9 ] loss: 0.5118392705917358 2022-06-30 23:26:06.388160
Epoch:[ 10 10 ] loss: 0.5136995911598206 2022-06-30 23:26:06.815825
Epoch:[ 10 11 ] loss: 0.5135188102722168 2022-06-30 23:26:07.245539
Epoch:[ 10 12 ] loss: 0.5130535364151001 2022-06-30 23:26:07.676517
Epoch:[ 10 13 ] loss: 0.5120859742164612 2022-06-30 23:26:08.104201
Epoch:[ 10 14 ] loss: 0.5121676921844482 2022-06-30 23:26:08.535041
Epoch:[ 10 15 ] loss: 0.5142838358879089 2022-06-30 23:26:08.970691
Epoch:[ 10 16 ] loss: 0.5063743591308594 2022-06-30 23:26:14.054169
Epoch:[ 10 17 ] loss: 0.5117963552474976 2022-06-30 23:26:14.489929
Epoch:[ 10 18 ] loss: 0.5089467167854309 2022-06-30 23:26:14.928583
Epoch:[ 10 19 ] loss: 0.5141599774360657 2022-06-30 23:26:15.358500
Training_Epoch:[ 10 ] Training_loss: 0.5123627275228501 2022-06-30 23:26:15.359115
learning rate:  0.05
netparams have been saved once 10
val: 1 0.548241138458252
val: 2 0.5527069568634033
val: 3 0.5510438084602356
val: 4 0.5390415787696838
val: 5 0.5550885200500488
val: 6 0.5518690943717957
val: 7 0.5462173819541931
val: 8 0.5389567017555237
val: 9 0.5444921851158142
val: 10 0.5484511256217957
val: 11 0.5420323610305786
val: 12 0.5483078956604004
val: 13 0.5465964078903198
val: 14 0.553503692150116
val: 15 0.5504812002182007
val: 16 0.5434731841087341
val: 17 0.5471842288970947
val: 18 0.5524064302444458
val: 19 0.5447723269462585
val: 20 0.5477007031440735
val_Epoch:[ 10 ] val_loss: 0.5476283460855484 2022-06-30 23:26:19.044093
start training 2022-06-30 23:26:19.138199
Epoch:[ 11 0 ] loss: 0.5102803707122803 2022-06-30 23:26:33.354554
Epoch:[ 11 1 ] loss: 0.5099586844444275 2022-06-30 23:26:33.798608
Epoch:[ 11 2 ] loss: 0.5121963620185852 2022-06-30 23:26:34.247946
Epoch:[ 11 3 ] loss: 0.5064448714256287 2022-06-30 23:26:34.675106
Epoch:[ 11 4 ] loss: 0.5097923278808594 2022-06-30 23:26:35.104670
Epoch:[ 11 5 ] loss: 0.5110114812850952 2022-06-30 23:26:35.534733
Epoch:[ 11 6 ] loss: 0.5079333782196045 2022-06-30 23:26:35.961147
Epoch:[ 11 7 ] loss: 0.507449746131897 2022-06-30 23:26:36.387570
Epoch:[ 11 8 ] loss: 0.5078462362289429 2022-06-30 23:26:36.815407
Epoch:[ 11 9 ] loss: 0.5038595199584961 2022-06-30 23:26:37.243273
Epoch:[ 11 10 ] loss: 0.5097718834877014 2022-06-30 23:26:37.669715
Epoch:[ 11 11 ] loss: 0.5052539110183716 2022-06-30 23:26:38.096173
Epoch:[ 11 12 ] loss: 0.5051494240760803 2022-06-30 23:26:38.525074
Epoch:[ 11 13 ] loss: 0.5053066611289978 2022-06-30 23:26:38.955638
Epoch:[ 11 14 ] loss: 0.5093144774436951 2022-06-30 23:26:39.385001
Epoch:[ 11 15 ] loss: 0.5070231556892395 2022-06-30 23:26:39.812429
Epoch:[ 11 16 ] loss: 0.5040478110313416 2022-06-30 23:26:45.636387
Epoch:[ 11 17 ] loss: 0.5056598782539368 2022-06-30 23:26:46.062400
Epoch:[ 11 18 ] loss: 0.5057956576347351 2022-06-30 23:26:46.498669
Epoch:[ 11 19 ] loss: 0.5088733434677124 2022-06-30 23:26:46.924575
Training_Epoch:[ 11 ] Training_loss: 0.5076484590768814 2022-06-30 23:26:46.925228
learning rate:  0.04000000000000001
val: 1 0.52010178565979
val: 2 0.5234525203704834
val: 3 0.5179747343063354
val: 4 0.5310068726539612
val: 5 0.5295888781547546
val: 6 0.5214405655860901
val: 7 0.5083285570144653
val: 8 0.5266995429992676
val: 9 0.5222569704055786
val: 10 0.517134964466095
val: 11 0.5163275003433228
val: 12 0.5213809013366699
val: 13 0.5155775547027588
val: 14 0.5288320183753967
val: 15 0.5189825296401978
val: 16 0.5259197354316711
val: 17 0.5188658833503723
val: 18 0.514467179775238
val: 19 0.527926504611969
val: 20 0.5074223875999451
val_Epoch:[ 11 ] val_loss: 0.5206843793392182 2022-06-30 23:26:50.553610
start training 2022-06-30 23:26:50.667888
Epoch:[ 12 0 ] loss: 0.5022201538085938 2022-06-30 23:27:04.857398
Epoch:[ 12 1 ] loss: 0.5033464431762695 2022-06-30 23:27:05.732621
Epoch:[ 12 2 ] loss: 0.5045027732849121 2022-06-30 23:27:06.165365
Epoch:[ 12 3 ] loss: 0.5041723251342773 2022-06-30 23:27:06.593929
Epoch:[ 12 4 ] loss: 0.5072289109230042 2022-06-30 23:27:07.021559
Epoch:[ 12 5 ] loss: 0.5029876232147217 2022-06-30 23:27:07.446091
Epoch:[ 12 6 ] loss: 0.5062896609306335 2022-06-30 23:27:07.873814
Epoch:[ 12 7 ] loss: 0.5060867667198181 2022-06-30 23:27:08.299110
Epoch:[ 12 8 ] loss: 0.5056307911872864 2022-06-30 23:27:08.728964
Epoch:[ 12 9 ] loss: 0.5026565790176392 2022-06-30 23:27:09.156057
Epoch:[ 12 10 ] loss: 0.5003368854522705 2022-06-30 23:27:09.583395
Epoch:[ 12 11 ] loss: 0.505338728427887 2022-06-30 23:27:10.010503
Epoch:[ 12 12 ] loss: 0.5050970911979675 2022-06-30 23:27:10.439538
Epoch:[ 12 13 ] loss: 0.504054844379425 2022-06-30 23:27:10.870237
Epoch:[ 12 14 ] loss: 0.5015373229980469 2022-06-30 23:27:11.295700
Epoch:[ 12 15 ] loss: 0.5053987503051758 2022-06-30 23:27:11.720196
Epoch:[ 12 16 ] loss: 0.505682110786438 2022-06-30 23:27:17.156782
Epoch:[ 12 17 ] loss: 0.5064375400543213 2022-06-30 23:27:17.585582
Epoch:[ 12 18 ] loss: 0.5023546814918518 2022-06-30 23:27:18.022110
Epoch:[ 12 19 ] loss: 0.5020405054092407 2022-06-30 23:27:18.447219
Training_Epoch:[ 12 ] Training_loss: 0.504170024394989 2022-06-30 23:27:18.447848
learning rate:  0.04000000000000001
netparams have been saved once 12
val: 1 0.511447012424469
val: 2 0.5203536152839661
val: 3 0.5066013932228088
val: 4 0.5140208601951599
val: 5 0.5080927014350891
val: 6 0.5197917819023132
val: 7 0.5010230541229248
val: 8 0.5151116847991943
val: 9 0.5147587060928345
val: 10 0.5109871625900269
val: 11 0.5016003847122192
val: 12 0.5124906301498413
val: 13 0.5024594664573669
val: 14 0.5204892754554749
val: 15 0.5130354166030884
val: 16 0.5144675374031067
val: 17 0.5151215195655823
val: 18 0.5086432099342346
val: 19 0.5130364894866943
val: 20 0.5089350938796997
val_Epoch:[ 12 ] val_loss: 0.5116233497858047 2022-06-30 23:27:22.143039
start training 2022-06-30 23:27:22.242495
Epoch:[ 13 0 ] loss: 0.5049221515655518 2022-06-30 23:27:36.292664
Epoch:[ 13 1 ] loss: 0.5021069645881653 2022-06-30 23:27:36.724756
Epoch:[ 13 2 ] loss: 0.506051778793335 2022-06-30 23:27:37.163810
Epoch:[ 13 3 ] loss: 0.5076996088027954 2022-06-30 23:27:37.592001
Epoch:[ 13 4 ] loss: 0.505176842212677 2022-06-30 23:27:38.022728
Epoch:[ 13 5 ] loss: 0.5026570558547974 2022-06-30 23:27:38.449027
Epoch:[ 13 6 ] loss: 0.5045529007911682 2022-06-30 23:27:38.875359
Epoch:[ 13 7 ] loss: 0.4975699484348297 2022-06-30 23:27:39.302251
Epoch:[ 13 8 ] loss: 0.5041615962982178 2022-06-30 23:27:39.729395
Epoch:[ 13 9 ] loss: 0.5055556297302246 2022-06-30 23:27:40.152827
Epoch:[ 13 10 ] loss: 0.5042927861213684 2022-06-30 23:27:40.570637
Epoch:[ 13 11 ] loss: 0.5014499425888062 2022-06-30 23:27:40.997969
Epoch:[ 13 12 ] loss: 0.501573920249939 2022-06-30 23:27:41.428319
Epoch:[ 13 13 ] loss: 0.49961063265800476 2022-06-30 23:27:41.854434
Epoch:[ 13 14 ] loss: 0.501133918762207 2022-06-30 23:27:42.285286
Epoch:[ 13 15 ] loss: 0.50456303358078 2022-06-30 23:27:42.715309
Epoch:[ 13 16 ] loss: 0.49883753061294556 2022-06-30 23:27:47.993758
Epoch:[ 13 17 ] loss: 0.5003149509429932 2022-06-30 23:27:48.426898
Epoch:[ 13 18 ] loss: 0.5031014680862427 2022-06-30 23:27:48.852962
Epoch:[ 13 19 ] loss: 0.5024874806404114 2022-06-30 23:27:49.283843
Training_Epoch:[ 13 ] Training_loss: 0.502891007065773 2022-06-30 23:27:49.284489
learning rate:  0.04000000000000001
val: 1 0.5625470280647278
val: 2 0.5371555089950562
val: 3 0.558491051197052
val: 4 0.564066469669342
val: 5 0.5556329488754272
val: 6 0.566573441028595
val: 7 0.5431477427482605
val: 8 0.5483579039573669
val: 9 0.5520838499069214
val: 10 0.5455769300460815
val: 11 0.5628548264503479
val: 12 0.5477553009986877
val: 13 0.5374393463134766
val: 14 0.5616602897644043
val: 15 0.5500515103340149
val: 16 0.5553086996078491
val: 17 0.5563930869102478
val: 18 0.5437564849853516
val: 19 0.5456157326698303
val: 20 0.5461351275444031
val_Epoch:[ 13 ] val_loss: 0.5520301640033722 2022-06-30 23:27:53.012143
start training 2022-06-30 23:27:53.128255
Epoch:[ 14 0 ] loss: 0.49977877736091614 2022-06-30 23:28:08.144128
Epoch:[ 14 1 ] loss: 0.5013032555580139 2022-06-30 23:28:08.570321
Epoch:[ 14 2 ] loss: 0.5013529062271118 2022-06-30 23:28:08.995426
Epoch:[ 14 3 ] loss: 0.5005061626434326 2022-06-30 23:28:09.421579
Epoch:[ 14 4 ] loss: 0.5022339224815369 2022-06-30 23:28:09.849084
Epoch:[ 14 5 ] loss: 0.5004975199699402 2022-06-30 23:28:10.283378
Epoch:[ 14 6 ] loss: 0.5022458434104919 2022-06-30 23:28:10.710229
Epoch:[ 14 7 ] loss: 0.5010741949081421 2022-06-30 23:28:11.136578
Epoch:[ 14 8 ] loss: 0.5020348429679871 2022-06-30 23:28:11.569072
Epoch:[ 14 9 ] loss: 0.49885615706443787 2022-06-30 23:28:11.996717
Epoch:[ 14 10 ] loss: 0.4989188611507416 2022-06-30 23:28:12.421917
Epoch:[ 14 11 ] loss: 0.5017326474189758 2022-06-30 23:28:12.849788
Epoch:[ 14 12 ] loss: 0.5072271227836609 2022-06-30 23:28:13.278170
Epoch:[ 14 13 ] loss: 0.5048837661743164 2022-06-30 23:28:13.705752
Epoch:[ 14 14 ] loss: 0.502352237701416 2022-06-30 23:28:14.132224
Epoch:[ 14 15 ] loss: 0.5019196271896362 2022-06-30 23:28:14.560464
Epoch:[ 14 16 ] loss: 0.5007843375205994 2022-06-30 23:28:19.517751
Epoch:[ 14 17 ] loss: 0.49737173318862915 2022-06-30 23:28:19.947118
Epoch:[ 14 18 ] loss: 0.4986449182033539 2022-06-30 23:28:20.387382
Epoch:[ 14 19 ] loss: 0.5035662651062012 2022-06-30 23:28:20.813844
Training_Epoch:[ 14 ] Training_loss: 0.5013642549514771 2022-06-30 23:28:20.814460
learning rate:  0.04000000000000001
netparams have been saved once 14
val: 1 0.5643376708030701
val: 2 0.5712618827819824
val: 3 0.5639152526855469
val: 4 0.5610470771789551
val: 5 0.5565950274467468
val: 6 0.5590949058532715
val: 7 0.5532939434051514
val: 8 0.5622432827949524
val: 9 0.5523690581321716
val: 10 0.556123673915863
val: 11 0.5720509886741638
val: 12 0.556165874004364
val: 13 0.5694526433944702
val: 14 0.5639675259590149
val: 15 0.5534142851829529
val: 16 0.5600871443748474
val: 17 0.5673749446868896
val: 18 0.5493773221969604
val: 19 0.5571282505989075
val: 20 0.5531226992607117
val_Epoch:[ 14 ] val_loss: 0.5601211726665497 2022-06-30 23:28:24.549413
start training 2022-06-30 23:28:24.651894
Epoch:[ 15 0 ] loss: 0.5030261278152466 2022-06-30 23:28:39.183710
Epoch:[ 15 1 ] loss: 0.5015908479690552 2022-06-30 23:28:39.632449
Epoch:[ 15 2 ] loss: 0.50234454870224 2022-06-30 23:28:40.062266
Epoch:[ 15 3 ] loss: 0.4971800446510315 2022-06-30 23:28:40.491233
Epoch:[ 15 4 ] loss: 0.5031145215034485 2022-06-30 23:28:40.923924
Epoch:[ 15 5 ] loss: 0.500359058380127 2022-06-30 23:28:41.355365
Epoch:[ 15 6 ] loss: 0.4995339810848236 2022-06-30 23:28:41.787074
Epoch:[ 15 7 ] loss: 0.49889707565307617 2022-06-30 23:28:42.221300
Epoch:[ 15 8 ] loss: 0.49777570366859436 2022-06-30 23:28:42.653631
Epoch:[ 15 9 ] loss: 0.4986107647418976 2022-06-30 23:28:43.082833
Epoch:[ 15 10 ] loss: 0.497260183095932 2022-06-30 23:28:43.510535
Epoch:[ 15 11 ] loss: 0.5013523101806641 2022-06-30 23:28:43.938989
Epoch:[ 15 12 ] loss: 0.4978015422821045 2022-06-30 23:28:44.369509
Epoch:[ 15 13 ] loss: 0.5036654472351074 2022-06-30 23:28:44.807710
Epoch:[ 15 14 ] loss: 0.5002709031105042 2022-06-30 23:28:45.237736
Epoch:[ 15 15 ] loss: 0.501043438911438 2022-06-30 23:28:45.668611
Epoch:[ 15 16 ] loss: 0.500391960144043 2022-06-30 23:28:50.383446
Epoch:[ 15 17 ] loss: 0.49499115347862244 2022-06-30 23:28:50.814154
Epoch:[ 15 18 ] loss: 0.5007143020629883 2022-06-30 23:28:51.258075
Epoch:[ 15 19 ] loss: 0.4963729977607727 2022-06-30 23:28:51.693950
Training_Epoch:[ 15 ] Training_loss: 0.49981484562158585 2022-06-30 23:28:51.694631
learning rate:  0.04000000000000001
val: 1 0.5123457908630371
val: 2 0.514061450958252
val: 3 0.5220668315887451
val: 4 0.5164304375648499
val: 5 0.5096418261528015
val: 6 0.5000156760215759
val: 7 0.5155254006385803
val: 8 0.5156996846199036
val: 9 0.5118787884712219
val: 10 0.5130615234375
val: 11 0.5039701461791992
val: 12 0.4986862540245056
val: 13 0.5273611545562744
val: 14 0.4973752796649933
val: 15 0.5189321041107178
val: 16 0.5104166865348816
val: 17 0.5165824890136719
val: 18 0.5169607400894165
val: 19 0.5064119100570679
val: 20 0.4971325695514679
val_Epoch:[ 15 ] val_loss: 0.5112278372049331 2022-06-30 23:28:55.390653
start training 2022-06-30 23:28:55.509482
Epoch:[ 16 0 ] loss: 0.49589401483535767 2022-06-30 23:29:09.864301
Epoch:[ 16 1 ] loss: 0.4937303960323334 2022-06-30 23:29:10.285225
Epoch:[ 16 2 ] loss: 0.4968715310096741 2022-06-30 23:29:10.713062
Epoch:[ 16 3 ] loss: 0.4984491765499115 2022-06-30 23:29:11.142741
Epoch:[ 16 4 ] loss: 0.49413222074508667 2022-06-30 23:29:11.577427
Epoch:[ 16 5 ] loss: 0.49898630380630493 2022-06-30 23:29:12.005552
Epoch:[ 16 6 ] loss: 0.4964815676212311 2022-06-30 23:29:12.436460
Epoch:[ 16 7 ] loss: 0.4991212785243988 2022-06-30 23:29:12.867627
Epoch:[ 16 8 ] loss: 0.4977126121520996 2022-06-30 23:29:13.299649
Epoch:[ 16 9 ] loss: 0.4966360032558441 2022-06-30 23:29:13.731528
Epoch:[ 16 10 ] loss: 0.4996461570262909 2022-06-30 23:29:14.165941
Epoch:[ 16 11 ] loss: 0.49874064326286316 2022-06-30 23:29:14.595344
Epoch:[ 16 12 ] loss: 0.49389931559562683 2022-06-30 23:29:15.028046
Epoch:[ 16 13 ] loss: 0.5021399855613708 2022-06-30 23:29:15.459957
Epoch:[ 16 14 ] loss: 0.49923011660575867 2022-06-30 23:29:15.891525
Epoch:[ 16 15 ] loss: 0.49681007862091064 2022-06-30 23:29:16.323766
Epoch:[ 16 16 ] loss: 0.4969635009765625 2022-06-30 23:29:21.649374
Epoch:[ 16 17 ] loss: 0.49707862734794617 2022-06-30 23:29:22.077462
Epoch:[ 16 18 ] loss: 0.49275439977645874 2022-06-30 23:29:22.517460
Epoch:[ 16 19 ] loss: 0.49748024344444275 2022-06-30 23:29:22.945687
Training_Epoch:[ 16 ] Training_loss: 0.49713790863752366 2022-06-30 23:29:22.946326
learning rate:  0.04000000000000001
netparams have been saved once 16
val: 1 0.5269643068313599
val: 2 0.5382875204086304
val: 3 0.538313627243042
val: 4 0.5324113965034485
val: 5 0.5329116582870483
val: 6 0.5391630530357361
val: 7 0.5255401730537415
val: 8 0.5241152048110962
val: 9 0.5289878845214844
val: 10 0.517798662185669
val: 11 0.5412843823432922
val: 12 0.528113842010498
val: 13 0.535809338092804
val: 14 0.5271493196487427
val: 15 0.5274592638015747
val: 16 0.5316784977912903
val: 17 0.5356481075286865
val: 18 0.520425021648407
val: 19 0.5238980650901794
val: 20 0.5286540985107422
val_Epoch:[ 16 ] val_loss: 0.5302306711673737 2022-06-30 23:29:26.645210
start training 2022-06-30 23:29:26.749839
